[
  {
    "arxiv_id": "2306.17190v1",
    "title": "Classification and Explanation of Distributed Denial-of-Service (DDoS) Attack Detection using Machine Learning and Shapley Additive Explanation (SHAP) Methods",
    "authors": "Yuanyuan Wei; Julian Jang-Jaccard; Amardeep Singh; Fariza Sabrina; Seyit Camtepe",
    "abstract": "DDoS attacks involve overwhelming a target system with a large number of requests or traffic from multiple sources, disrupting the normal traffic of a targeted server, service, or network. Distinguishing between legitimate traffic and malicious traffic is a challenging task. It is possible to classify legitimate traffic and malicious traffic and analysis the network traffic by using machine learning and deep learning techniques. However, an inter-model explanation implemented to classify a traffic flow whether is benign or malicious is an important investigation of the inner working theory of the model to increase the trustworthiness of the model. Explainable Artificial Intelligence (XAI) can explain the decision-making of the machine learning models that can be classified and identify DDoS traffic. In this context, we proposed a framework that can not only classify legitimate traffic and malicious traffic of DDoS attacks but also use SHAP to explain the decision-making of the classifier model. To address this concern, we first adopt feature selection techniques to select the top 20 important features based on feature importance techniques (e.g., XGB-based SHAP feature importance). Following that, the Multi-layer Perceptron Network (MLP) part of our proposed model uses the optimized features of the DDoS attack dataset as inputs to classify legitimate and malicious traffic. We perform extensive experiments with all features and selected features. The evaluation results show that the model performance with selected features achieves above 99\\% accuracy. Finally, to provide interpretability, XAI can be adopted to explain the model performance between the prediction results and features based on global and local explanations by SHAP, which can better explain the results achieved by our proposed framework.",
    "published_date": "2023-06-27",
    "pdf_link": "https://arxiv.org/pdf/2306.17190v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "DDoS attack detection and explanation (benign vs malicious classification; one-to-one and one-to-all settings)",
      "attack_types": [
        "DDoS",
        "DNS",
        "SNMP",
        "LDAP",
        "NetBIOS"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Feed-forward Neural Network (MLP)",
        "specific": "Multi-Layer Perceptron with 3 hidden layers [23, 15, 10], sigmoid output",
        "novel_contribution": "Used with a combined feature selection pipeline (XGBoost-based feature importance, permutation importance, SHAP importance) selecting top-20 features for DDoS detection"
      },
      {
        "type": "primary",
        "category": "Feature Selection",
        "specific": "XGBoost-based feature importance; Permutation feature importance; SHAP feature importance",
        "novel_contribution": "Combination and frequency-based aggregation to select top 20 features across attack types (one-to-one and one-to-all)"
      },
      {
        "type": "primary",
        "category": "XAI / Post-hoc Explainer",
        "specific": "SHAP (Kernel SHAP)",
        "novel_contribution": "Global (summary, dependence plots) and local explanations for correctly classified benign/malicious and misclassified samples; SHAP also used to drive feature selection"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CICDDoS2019",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/ddos-2019.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can SHAP-driven feature importance effectively select a compact subset (top-20) of features that improves DDoS detection performance over using all features?",
        "Can SHAP provide meaningful global and local explanations for MLP-based DDoS detectors, including correctly classified and misclassified traffic?"
      ],
      "gaps_identified": [
        "DDoS detection models are often black boxes lacking transparent explanations for decisions",
        "Using all features can reduce efficiency and potentially degrade performance compared to optimized feature subsets"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve trustworthiness and efficiency of DDoS detection by combining high-performance ML with explainable AI to understand model decisions and reduce feature space.",
      "potential_research_ideas": [
        "Evaluate generalization and transferability across multiple datasets (e.g., CICIDS2017, NSL-KDD) and real network traces",
        "Online/streaming DDoS detection with concept-drift handling and incremental SHAP explanations",
        "Adversarially robust DDoS detection with robustness-aware training and explanation stress-testing",
        "Hierarchical multi-class classification across specific DDoS subtypes with explanation per subtype",
        "Stability analysis of feature attributions across training runs and time; attribution regularization",
        "Real-time SHAP approximation methods (e.g., TreeSHAP-compatible ensembles) for production latency",
        "Data-centric improvements: denoising, class-imbalance handling, and label quality assessment guided by explanations",
        "Combine temporal models (e.g., LSTM/TCN) or flow-graph GNNs with SHAP/GraphSHAP for sequence/structure-aware detection"
      ],
      "architectural_improvement_recommendations": [
        "Ensemble MLP with tree-based models (e.g., XGBoost) to enable faster TreeSHAP and potentially higher accuracy",
        "Calibrated probabilities (Platt/Isotonic) and cost-sensitive thresholds for imbalanced attack prevalence",
        "Feature selection stability via bootstrapping and consensus ranking across importance methods",
        "Attack-type-aware multi-head output (binary + subtype) to leverage shared representations",
        "Adopt mixed categorical-numerical embeddings and batch normalization/dropout tuning for robustness",
        "Integrate drift detection (ADWIN/KS-test) to trigger model/explanation updates",
        "Automated hyperparameter optimization (Bayesian search) with explanation consistency constraints"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "TensorFlow",
        "scikit-learn",
        "SHAP"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "CPU: 3.4GHz Intel Core i5; RAM: 16GB; OS: macOS Big Sur 11.4; Packages: tensorflow 2.0.0, sklearn 0.24.1"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Need for trust and interpretability of detections for operators",
        "Feature computation and selection pipeline integration with real-time traffic"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Combination feature selection framework using three XGBoost-based importance techniques (XGB-based feature importance, permutation importance, SHAP importance) to select top-20 features",
      "Novel two-component framework: MLP for DDoS classification plus SHAP for transparent explanation of contributing features",
      "XAI-based SHAP interpretation for both global (summary, dependence plots) and local explanations, including correctly classified benign/malicious and misclassified traffic",
      "Extensive evaluation on CICDDoS2019 showing selected features yield higher performance than using all features; reported “above 99% accuracy” and >99% accuracy in both one-to-one and one-to-all classifications"
    ]
  },
  {
    "arxiv_id": "2306.14750v1",
    "title": "Ensemble of Random and Isolation Forests for Graph-Based Intrusion Detection in Containers",
    "authors": "Alfonso Iacovazzi; Shahid Raza",
    "abstract": "We propose a novel solution combining supervised and unsupervised machine learning models for intrusion detection at kernel level in cloud containers. In particular, the proposed solution is built over an ensemble of random and isolation forests trained on sequences of system calls that are collected at the hosting machine's kernel level. The sequence of system calls are translated into a weighted and directed graph to obtain a compact description of the container behavior, which is given as input to the ensemble model. We executed a set of experiments in a controlled environment in order to test our solution against the two most common threats that have been identified in cloud containers, and our results show that we can achieve high detection rates and low false positives in the tested attacks.",
    "published_date": "2023-06-26",
    "pdf_link": "https://arxiv.org/pdf/2306.14750v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cloud/Container Security",
      "subdomain": "Host-based Intrusion Detection (HIDS)",
      "specific_problem": "Kernel-level system-call graph–based intrusion detection in Docker containers to both verify expected workload and detect malicious behavior",
      "attack_types": [
        "cryptojacking/cryptomining",
        "backdoor/remote control"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Graph Embedding",
        "specific": "Anonymous Walks (graph random-walk–based embedding)",
        "novel_contribution": "First use of anonymous walks to embed sequences of system calls for intrusion detection (as claimed by authors)."
      },
      {
        "type": "primary",
        "category": "Ensemble/Decision Trees",
        "specific": "Random Forest (classifier)",
        "novel_contribution": "Used to distinguish among multiple benign container workloads before anomaly scoring."
      },
      {
        "type": "primary",
        "category": "Anomaly Detection",
        "specific": "Isolation Forest (ensemble of independent IFs)",
        "novel_contribution": "N independent IFs (one per workload) operating on RF output probabilities with decision rules to flag anomalies."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Public system-call dataset (unspecified)",
        "type": "public",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Authors' collected container system-call traces (CloudSuite workloads: data analytics, media streaming, web search; benign, cryptominer, backdoor/remote control)",
        "type": "private",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "detection rate (true positive rate)",
      "false positive rate",
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a host-based monitor classify which benign workload is running in each container using kernel-level system-call behavior?",
        "Can anomalies/malicious behaviors within containers be detected at the hosting OS without accessing container internals?"
      ],
      "gaps_identified": [
        "Need for host-based monitoring that does not access container resources directly in public cloud settings.",
        "Supervised approaches for specific threats (e.g., cryptomining) struggle to detect unknown behaviors.",
        "Existing deep learning approaches for containers report high false positive rates (~10% cited) and limited practicality.",
        "Classical BoSC features ignore dependencies among adjacent system calls; need representations capturing relations/dependencies."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Cloud providers must detect malicious activity in containers without intrusive access to customer resources; kernel-level system calls observable at the host can enable scalable monitoring.",
      "potential_research_ideas": [
        "Evaluate the approach across broader, more diverse container workloads and multi-tenant clusters to assess generalization and drift.",
        "Augment graph features with temporal/sequential models (e.g., self-supervised sequence modeling over syscall graphs) to capture longer dependencies.",
        "Investigate graph neural networks on syscall graphs for end-to-end learning versus fixed anonymous-walk embeddings.",
        "Integrate multi-modal telemetry (e.g., lightweight network/CPU/memory signals) for robust detection with late fusion.",
        "Develop online/continual learning to handle workload updates and concept drift in long-running services.",
        "Study adversarial robustness against mimicry/poisoning of syscall patterns in containerized environments.",
        "Add explainability by mapping influential anonymous-walk motifs back to syscall bi-grams and processes for operator insight.",
        "Extend from single-host to cluster-wide detection using federated or distributed learning respecting tenant isolation."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment the final IF stage with calibrated one-class classifiers per workload (e.g., Deep SVDD, OC-SVM, LOF) and compare to IF ensemble.",
        "Learn adaptive anomaly thresholds per workload using validation quantiles or conformal prediction for controlled false alarm rates.",
        "Jointly train a multi-task model producing both workload classification and anomaly scores to share representation efficiently.",
        "Use learned graph embeddings (e.g., node2vec/GRAPE or GNN-based readouts) and compare with anonymous-walk embeddings.",
        "Incorporate process/context metadata (process IDs, namespaces, cgroups) to disambiguate concurrent activities within a container.",
        "Implement drift detectors (e.g., ADWIN) to trigger retraining/threshold updates for evolving workloads.",
        "Calibrate RF output probabilities (Platt/Isotonic) before feeding IFs to improve separability.",
        "Harden against adversarial manipulation via augmentation of near-boundary syscall patterns and detection of improbable walk motifs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Host operating system monitoring Docker containers (kernel-level system calls)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Description of a data repository of kernel-level system-call traces from Dockerized CloudSuite workloads in an emulated environment.",
      "Graph representation of system-call sequences using random walks and anonymous-walk embeddings to capture dependencies and frequency.",
      "Three-stage intrusion detection mechanism: anonymous-walk embedding, Random Forest workload classifier, and ensemble of Isolation Forests for anomaly scoring.",
      "Evaluation on two datasets (one public repository dataset and one collected by the authors) showing high detection rates and low false positives on tested attacks.",
      "Claimed first use of anonymous walks to embed system-call sequences for intrusion detection."
    ]
  },
  {
    "arxiv_id": "2306.16701v1",
    "title": "TrojanNet: Detecting Trojans in Quantum Circuits using Machine Learning",
    "authors": "Subrata Das; Swaroop Ghosh",
    "abstract": "Quantum computing holds tremendous potential for various applications, but its security remains a crucial concern. Quantum circuits need high-quality compilers to optimize the depth and gate count to boost the success probability on current noisy quantum computers. There is a rise of efficient but unreliable/untrusted compilers; however, they present a risk of tampering such as Trojan insertion. We propose TrojanNet, a novel approach to enhance the security of quantum circuits by detecting and classifying Trojan-inserted circuits. In particular, we focus on the Quantum Approximate Optimization Algorithm (QAOA) circuit that is popular in solving a wide range of optimization problems. We investigate the impact of Trojan insertion on QAOA circuits and develop a Convolutional Neural Network (CNN) model, referred to as TrojanNet, to identify their presence accurately. Using the Qiskit framework, we generate 12 diverse datasets by introducing variations in Trojan gate types, the number of gates, insertion locations, and compiler backends. These datasets consist of both original Trojan-free QAOA circuits and their corresponding Trojan-inserted counterparts. The generated datasets are then utilized for training and evaluating the TrojanNet model. Experimental results showcase an average accuracy of 98.80% and an average F1-score of 98.53% in effectively detecting and classifying Trojan-inserted QAOA circuits. Finally, we conduct a performance comparison between TrojanNet and existing machine learning-based Trojan detection methods specifically designed for conventional netlists.",
    "published_date": "2023-06-29",
    "pdf_link": "https://arxiv.org/pdf/2306.16701v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Quantum Computing Security",
      "subdomain": "Hardware Trojan Detection",
      "specific_problem": "Detecting Trojan insertions in compiled quantum circuits (QAOA) produced by untrusted compilers",
      "attack_types": [
        "Hardware Trojan via extra gate insertion",
        "Compiler tampering",
        "Gate-level manipulation of QAOA circuits"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "Domain-tailored CNN (TrojanNet) trained on representations of compiled QAOA circuits to capture disruptions in alternating cost/mixing layer patterns indicative of Trojan gate insertions"
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Artificial Immune Systems",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "QAOA TrojanNet Datasets (12 variants)",
        "type": "synthetic",
        "domain": "quantum_circuits",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Graph Neural Network (GNN) golden reference-free HT detection (RTL and gate-level netlists)",
        "paper_reference": "[18]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Artificial Immune Systems (AIS) for RTL Trojan detection",
        "paper_reference": "[19]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Gradient boosting-based RTL HT detection with server-client updates",
        "paper_reference": "[20]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1-score",
      "Approximation Ratio (AR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Lack of studies focusing on Trojan insertion methods and detection mechanisms in quantum circuits (e.g., QAOA) compared to traditional IC netlists"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Untrusted third-party quantum compilers may insert Trojan gates during optimization, threatening the integrity and performance of QAOA circuits; need methods to detect such tampering.",
      "potential_research_ideas": [
        "Generalize TrojanNet beyond QAOA to other quantum algorithms (e.g., VQE, Grover, variational algorithms) and multi-problem instances.",
        "Develop compiler-agnostic representations (e.g., gate-sequence Transformers or graph-based DAG encoders) to improve cross-compiler generalization.",
        "Create open benchmark suites for quantum Trojan detection with standardized protocols and diverse hardware noise models.",
        "Integrate novelty/out-of-distribution detection to flag unseen Trojan types and insertion strategies without labeled data.",
        "Adversarial training and robust learning against evasive Trojan strategies that mimic legitimate circuit patterns.",
        "Localize Trojans (not only detect) using explainability/attribution methods to highlight suspect subcircuits.",
        "Self-supervised or contrastive pretraining on large corpora of quantum circuits to reduce labeled data needs.",
        "Co-design detection with hardware/runtime telemetry (e.g., error syndromes, calibration drift) to enhance detection under realistic noise."
      ],
      "architectural_improvement_recommendations": [
        "Augment CNN with graph-based encoders (e.g., GNN over the circuit DAG) or hybrid CNN+Transformer over gate sequences for richer structural features.",
        "Multi-view learning: combine images/embeddings of circuit layers, DAG features (critical path), and compiler metadata into a late-fusion model.",
        "Curriculum and hard-negative mining with progressively stealthier Trojan insertions to improve robustness.",
        "Domain-specific data augmentation that preserves circuit semantics (gate commutation, template rewrites) to increase generalization.",
        "Meta-learning across compiler backends to quickly adapt to new compilers with few labeled samples."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Qiskit"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Compiled circuits are transformed into forms that are not easily inspectable or discernible, making Trojan detection challenging (post-compilation)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Propose TrojanNet, a CNN-based detector to identify Trojan-inserted QAOA circuits.",
      "Heuristic vulnerability analysis to find most impactful Trojan insertion locations and gate types in QAOA circuits (critical/non-critical paths; front/middle/back).",
      "Generate 12 datasets of Trojan-free and Trojan-inserted QAOA circuits by varying Trojan gate type, number, insertion location, and compiler backends using Qiskit.",
      "Experimental validation showing high detection performance and comparison to ML-based HT detection methods for conventional netlists.",
      "\"Experimental results showcase an average accuracy of 98.80% and an average F1-score of 98.53% in effectively detecting and classifying Trojan-inserted QAOA circuits.\""
    ]
  },
  {
    "arxiv_id": "2306.16087v2",
    "title": "Discerning Reliable Cyber Threat Indicators for Timely Cyber Threat Intelligence",
    "authors": "Dincy R Arikkat; Vinod P.; Rafidha Rehiman K. A.; Andrea Di Sorbo; Corrado A. Visaggio; Mauro Conti",
    "abstract": "In today's dynamic cybersecurity landscape, timely and accurate threat intelligence is essential for proactive defense. This study explores the potential of social media platforms as a valuable resource for extracting actionable Indicators of Compromise (IoCs). Utilizing a Convolutional Neural Network (CNN), we achieved an F1-score of 98.80% and a detection rate of 99.65%, filtering vast social media data to identify key IoCs, including IP addresses, URLs, file hashes, domain addresses, and CVE IDs. These indicators are critical for detecting potential threats and vulnerabilities, and their relevance was evaluated using metrics such as correctness, timeliness, and overlap. Our analysis shows that URLs emerged as the most frequently shared IoC, with 48.67% representing valid threats. To further investigate the role of automated accounts in disseminating IoCs, we applied several machine learning models, with XGBoost delivering the highest performance achieving a macro F1-score of 0.814 and a weighted F1-score of 0.925. These findings highlight the growing significance of social media as a reliable source of actionable threat intelligence, offering valuable insights for cybersecurity professionals to stay ahead of emerging threats.",
    "published_date": "2023-06-28",
    "pdf_link": "https://arxiv.org/pdf/2306.16087v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Threat Intelligence",
      "subdomain": "Open-Source Intelligence (OSINT) for CTI",
      "specific_problem": "Extracting and validating Indicators of Compromise (IoCs) from social media and identifying automated accounts disseminating IoCs",
      "attack_types": [
        "general cyber threats",
        "malware distribution",
        "phishing",
        "vulnerability exploitation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "Applied to filter large-scale social media posts and identify IoC-bearing content, achieving F1=98.80% and detection rate=99.65%."
      },
      {
        "type": "primary",
        "category": "Gradient Boosting (XGBoost)",
        "specific": "XGBoost",
        "novel_contribution": "Best-performing model for classifying automated vs human-operated accounts sharing IoCs (macro F1=0.814, weighted F1=0.925)."
      },
      {
        "type": "primary",
        "category": "Rule-based",
        "specific": "Regular Expressions",
        "novel_contribution": "Regex patterns used to harvest and extract IoCs (IP, URL, domain, hash, CVE) from social posts before validation."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Rule-based"
    ],
    "datasets": [
      {
        "name": "OPTIMA-CTI Twitter-CTI dataset",
        "type": "public",
        "domain": "social_media_posts",
        "link": "https://github.com/OPTIMA-CTI/Twitter-CTI.git",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "VirusTotal",
        "type": "public",
        "domain": "threat_intel_feeds",
        "link": "https://www.virustotal.com",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "AlienVault OTX",
        "type": "public",
        "domain": "threat_intel_feeds",
        "link": "https://otx.alienvault.com",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "URLHaus",
        "type": "public",
        "domain": "threat_intel_feeds",
        "link": "https://urlhaus.abuse.ch",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MalwareBazaar",
        "type": "public",
        "domain": "threat_intel_feeds",
        "link": "https://bazaar.abuse.ch",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MISP",
        "type": "public",
        "domain": "threat_intel_feeds",
        "link": "https://www.misp-project.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CVE Database (MITRE)",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://cve.mitre.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NVD (National Vulnerability Database)",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://nvd.nist.gov",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "F1-score",
      "macro F1-score",
      "weighted F1-score",
      "detection rate",
      "correctness",
      "timeliness (ΔT)",
      "overlap"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: Which kinds of IoCs are mainly transmitted through social media?",
        "RQ2: To what extent IoCs extracted from social media accounts are reliable?",
        "RQ2.1 (Correctness): What percentage of IoCs are reported malicious by different threat intelligence services?",
        "RQ2.2 (Timeliness): How fast does social media share its IoCs compared to other threat intelligence services?",
        "RQ2.3 (Overlap): How many IoCs in social media exist in other Threat Intelligence Services?",
        "RQ3: To what proportion are the automated accounts delivering IoCs through social media?"
      ],
      "gaps_identified": [
        "Latency and gaps between vulnerability notification and NVD publication hinder timely CTI.",
        "Few studies systematically evaluate the reliability (correctness, timeliness, overlap) of IoCs disseminated via social media.",
        "Prior work has not examined the role of automated accounts in delivering IoCs on social media.",
        "Manual analysis of high-volume, unstructured social media data is time-consuming and error-prone."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Provide timely, actionable threat intelligence by leveraging social media to extract and validate IoCs, overcoming delays in traditional databases (e.g., NVD) and addressing the volume/noise challenges and the influence of automated accounts.",
      "potential_research_ideas": [
        "Extend beyond Twitter/X to multi-platform OSINT (Reddit, Telegram, GitHub issues, dark web forums) with cross-source fusion and deduplication.",
        "Integrate transformer-based NLP (e.g., BERT/Longformer) for IoC-bearing post detection and fine-grained IoC extraction vs regex-only patterns.",
        "Develop a unified reliability scoring model that jointly optimizes correctness, timeliness, and overlap using probabilistic calibration and uncertainty estimation.",
        "Construct a graph-based model (GNN) of accounts, posts, and IoCs to jointly infer credibility of sources and artifacts and to detect coordinated bot activity.",
        "Cross-lingual CTI extraction and validation to cover non-English posts and region-specific threats.",
        "Real-time streaming pipeline with incremental learning and concept drift handling for evolving threat vocabularies and bot behaviors.",
        "Adversarially robust bot detection against evasion (e.g., content paraphrasing, timing obfuscation).",
        "Causal analysis of how early social-media IoCs translate into downstream prevention outcomes (e.g., blocklists, EDR detections)."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment CNN with pretrained language models (e.g., BERT/RoBERTa) fine-tuned for IoC-post detection to improve generalization.",
        "Use hybrid extraction: regex + neural sequence labeling (BiLSTM-CRF or Transformer token classification) to capture obfuscated or atypical IoCs.",
        "For bot detection, ensemble XGBoost with deep sequential/time-series models (e.g., Temporal CNN or Transformer) over posting behavior.",
        "Introduce graph features (retweet/reply/mention networks) and use GNNs (GraphSAGE/GAT) for bot detection and source credibility scoring.",
        "Apply weak supervision (e.g., Snorkel) and active learning to reduce manual labeling for both tasks.",
        "Incorporate model calibration and uncertainty thresholds to triage IoCs for human review.",
        "Add SHAP-based global explanations and feature attribution logging to support analyst trust and auditing.",
        "Time-aware evaluation with rolling-origin splits to mitigate temporal leakage in performance estimates."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "High-volume, noisy, and unstructured social-media data streams.",
        "Need for reliable verification of IoCs against multiple TIS with differing latencies.",
        "Presence of automated accounts that may disseminate misleading or low-quality IoCs.",
        "Aligning timestamps and deduplicating IoCs across heterogeneous sources."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Automated approach to harvest and extract IoCs (IP, URL, domain, file hash, CVE) from social media.",
      "Reliability analysis of social-media IoCs via correctness, timeliness, and overlap using VirusTotal, AlienVault OTX, URLHaus, MalwareBazaar, MISP, and CVE database.",
      "Released a comprehensive dataset of account-level, post-level, and temporal features for classifying automated vs human-operated accounts (public GitHub repository).",
      "Implemented ML/DL-based bot detection; XGBoost achieved macro F1=0.814 and weighted F1=0.925; applied XAI to interpret model decisions.",
      "Empirical findings: CNN achieved F1=98.80% and detection rate=99.65% for filtering IoC-bearing social posts; URLs are the most frequently shared IoC, with 48.67% valid threats; file hashes were highly reliable (98.08% confirmed)."
    ]
  },
  {
    "arxiv_id": "2306.14497v1",
    "title": "Your Code is 0000: An Analysis of the Disposable Phone Numbers Ecosystem",
    "authors": "José Miguel Moreno; Srdjan Matic; Narseo Vallina-Rodriguez; Juan Tapiador",
    "abstract": "Short Message Service (SMS) is a popular channel for online service providers to verify accounts and authenticate users registered to a particular service. Specialized applications, called Public SMS Gateways (PSGs), offer free Disposable Phone Numbers (DPNs) that can be used to receive SMS messages. DPNs allow users to protect their privacy when creating online accounts. However, they can also be abused for fraudulent activities and to bypass security mechanisms like Two-Factor Authentication (2FA). In this paper, we perform a large-scale and longitudinal study of the DPN ecosystem by monitoring 17,141 unique DPNs in 29 PSGs over the course of 12 months. Using a dataset of over 70M messages, we provide an overview of the ecosystem and study the different services that offer DPNs and their relationships. Next, we build a framework that (i) identifies and classifies the purpose of an SMS; and (ii) accurately attributes every message to more than 200 popular Internet services that require SMS for creating registered accounts. Our results indicate that the DPN ecosystem is globally used to support fraudulent account creation and access, and that this issue is ubiquitous and affects all major Internet platforms and specialized online services.",
    "published_date": "2023-06-26",
    "pdf_link": "https://arxiv.org/pdf/2306.14497v1",
    "paper_types": [
      "empirical_analysis",
      "new_dataset"
    ],
    "security_domain": {
      "primary": "Account/Web Security",
      "subdomain": "Authentication and Account Abuse Prevention",
      "specific_problem": "Abuse of disposable/public SMS phone numbers to bypass SMS-based verification and 2FA and to enable fraudulent account creation and access",
      "attack_types": [
        "account fraud",
        "fake account creation",
        "2FA bypass",
        "OTP abuse",
        "single-use link abuse"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Clustering/Locality-Sensitive Hashing",
        "specific": "SimHash near-duplicate detection with Hamming distance threshold",
        "novel_contribution": "Used to cluster normalized SMS templates at scale for purpose inference; empirical threshold 10 on 64-bit hashes validated against 10k messages"
      },
      {
        "type": "primary",
        "category": "Rule-based NLP/Keyword Matching",
        "specific": null,
        "novel_contribution": "Curated 1.7k service-related keywords to attribute SMS to 212 services; iterative refinement to reduce mislabels"
      },
      {
        "type": "primary",
        "category": "Language Identification",
        "specific": "franc (JavaScript) with Unicode script heuristics",
        "novel_contribution": "Hybrid script/substring heuristics + franc for short SMS language detection to support multinational service attribution"
      },
      {
        "type": "primary",
        "category": "Pattern Mining/Regex",
        "specific": null,
        "novel_contribution": "Normalization replacing identifiers (e.g., URL{36}, NUMERIC{4}, IP) to template messages and derive purpose labels aligned with NIST SP 800-63B"
      },
      {
        "type": "baseline",
        "category": "Tokenization/Word Segmentation",
        "specific": "WordSegment (Python)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised (clustering/templates via SimHash)",
      "Rule-based/Pattern-based",
      "Weak supervision (manual labeling of clusters to derive rules)"
    ],
    "datasets": [
      {
        "name": "DPN SMS dataset (70.95M messages from 17,141 DPNs across 29 PSGs over ~12 months)",
        "type": "proprietary",
        "domain": "sms_messages",
        "link": null,
        "is_new_contribution": true,
        "availability": "available_on_request"
      },
      {
        "name": "CSV lists of analyzed gateways and services (artifact)",
        "type": "public",
        "domain": "sms_messages",
        "link": "https://github.com/josemmo/your-code-is-0000",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Tranco top-3M list (NK2W, generated 2021-06-14)",
        "type": "public",
        "domain": "web_ranking",
        "link": "https://tranco-list.eu/list/NK2W",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Tranco top-3M list (JX5LY, generated 2022-12-11) for follow-up PSG discovery",
        "type": "public",
        "domain": "web_ranking",
        "link": "https://tranco-list.eu/list/JX5LY",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How widely used are DPNs?",
        "What services are sending messages to DPNs?",
        "What is their potential for abuse?"
      ],
      "gaps_identified": [
        "The DPN ecosystem remains relatively unexplored; the last systematic study dates to 2018, prior to the surge of SMS-based 2FA.",
        "Assumptions that phone numbers are uniquely linked to individuals do not hold with DPNs, undermining SMS-based verification/2FA.",
        "Global and longitudinal measurements at current scale (tens of millions of messages) were missing."
      ],
      "limitations": [
        "Did not circumvent CAPTCHAs or JS challenges on PSGs; potential sampling bias and missed gateways/messages.",
        "Some PSGs show only the latest n messages; despite adaptive crawl rates, messages could be missed.",
        "Lack of unique message IDs; deduplication relies on composite keys (receiver, sender, timestamp, content).",
        "Potential inaccuracy of sender information due to Caller ID lookup issues (short codes/sender IDs).",
        "Service attribution via keywords can misattribute when messages mention a service name without being sent by it (though measured accuracy is high).",
        "Automated purpose labeling accuracy is 91.3%; mislabels arise, especially around 'activity' tokens.",
        "Network downtimes and infrastructure upgrades caused days with lower counts (data gaps).",
        "Coverage limited to public SMS gateways; results may not generalize to private/premium DPN services.",
        "No effort to deanonymize or link messages to actual users; privacy constraints limit ground-truth validation.",
        "No full longitudinal provider-lifespan analysis; PSG ecosystem is volatile with ~1-year lifespan."
      ],
      "future_work": [],
      "motivation": "Understand the scale, actors, and abuse potential of disposable/public SMS numbers as they relate to modern SMS-based account verification and 2FA.",
      "potential_research_ideas": [
        "Design and evaluate provider-side detectors for DPN usage at registration and 2FA (e.g., phone-number reputation models leveraging carrier/type, gateway reuse, and temporal behavior).",
        "Develop multilingual, template-robust OTP/URL extraction models (e.g., transformer-based NER) and compare against regex-based methods on short-text SMS.",
        "Construct a cross-platform graph of PSGs, DPN reuse/rotation, and service interactions to detect gateway clusters and shared infrastructure (graph mining, community detection).",
        "Assess defense-in-depth alternatives to SMS 2FA in high-risk contexts (e.g., WebAuthn), quantifying the reduction in abuse when DPNs are blocked.",
        "Create a standardized public benchmark for DPN detection and SMS purpose classification with shared evaluation protocols and privacy-preserving samples.",
        "Investigate real-time intervention strategies with mobile carriers/ESMEs (e.g., Twilio/Bandwidth) for throttling or flagging DPN-associated OTP traffic without harming legitimate users."
      ],
      "architectural_improvement_recommendations": [
        "Augment keyword-based service attribution with supervised or contrastive text encoders (e.g., multilingual sentence transformers) to reduce false negatives on short messages.",
        "Replace purely regex-based identifier extraction with hybrid NER models trained on annotated SMS to improve robustness to obfuscation and mixed-language texts.",
        "Introduce active learning over message clusters to iteratively refine purpose labels with minimal manual effort.",
        "Model sender normalization using probabilistic mapping from short codes/sender IDs to services to address Caller ID inaccuracies.",
        "Incorporate number-type intelligence (mobile vs VoIP vs short code) and carrier metadata into attribution and abuse scoring.",
        "Add temporal anomaly detection (e.g., burst detection per DPN-service pair) to capture coordinated abuse waves."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": "https://github.com/josemmo/your-code-is-0000",
      "frameworks": [
        "Playwright",
        "Chromium",
        "Python",
        "JavaScript",
        "franc (language ID)",
        "WordSegment"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Anti-bot protections on PSGs (CAPTCHAs, JS challenges) impede crawling.",
        "Volatility of PSGs (approximately 1-year lifespan) affects continuous monitoring.",
        "Inbox size limits and rate adaptation can cause message loss.",
        "Timezone inconsistencies and lack of unique message IDs complicate deduplication and timing.",
        "Ethical and privacy constraints limit deeper linkage/validation."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Large-scale and longitudinal measurement of the DPN ecosystem: 70,951,728 SMS across 17,141 DPNs and 29 PSGs over ~12 months; more than 1.4M messages per week.",
      "Service attribution framework mapping messages to 212 unique services using curated keywords with measured accuracy of 99.10% on 4k manually labeled messages.",
      "Purpose identification framework using normalized templates, identifier patterns, SimHash clustering, and NIST SP 800-63B-aligned labels; automated labeling accuracy 91.3% on 1k clusters.",
      "Evidence that nearly 80% of messages contain OTPs or single-use links, indicating high potential for abuse tied to verification/2FA.",
      "Characterization of DPN dynamics including number rotation and infrastructure reuse across gateways; observation of ecosystem volatility (~1-year lifespan).",
      "Research artifacts: CSV files of analyzed gateways and identified services released; full dataset available on request under IRB conditions."
    ]
  },
  {
    "arxiv_id": "2306.14090v1",
    "title": "Federated Learning Approach for Distributed Ransomware Analysis",
    "authors": "Aldin Vehabovic; Hadi Zanddizari; Farook Shaikh; Nasir Ghani; Morteza Safaei Pour; Elias Bou-Harb; Jorge Crichigno",
    "abstract": "Researchers have proposed a wide range of ransomware detection and analysis schemes. However, most of these efforts have focused on older families targeting Windows 7/8 systems. Hence there is a critical need to develop efficient solutions to tackle the latest threats, many of which may have relatively fewer samples to analyze. This paper presents a machine learning (ML) framework for early ransomware detection and attribution. The solution pursues a data-centric approach which uses a minimalist ransomware dataset and implements static analysis using portable executable (PE) files. Results for several ML classifiers confirm strong performance in terms of accuracy and zero-day threat detection.",
    "published_date": "2023-06-25",
    "pdf_link": "https://arxiv.org/pdf/2306.14090v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Ransomware Detection and Attribution",
      "specific_problem": "Early ransomware detection and family attribution via static PE-file analysis using a federated learning (cross-silo) framework",
      "attack_types": [
        "Ransomware",
        "Babuk/Babyk",
        "BlackCat",
        "Chaos",
        "DJVu/STOP",
        "Hive",
        "LockBit",
        "Netwalker",
        "Sodinokibi/REvil",
        "WannaCry"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "FedAvg (synchronous server-client aggregation)",
        "novel_contribution": "First application of federated learning for ransomware detection and attribution with a distributed ransomware analysis (DRA) architecture"
      },
      {
        "type": "primary",
        "category": "DNN",
        "specific": "Neural-network based classifiers (e.g., FNN/DNN; CNN/LSTM discussed as options)",
        "novel_contribution": "Decentralized neural network classifiers trained under FL for static PE-based ransomware detection and attribution"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "New ransomware repository (Windows 10/11) with 9 families: Babuk/Babyk, BlackCat, Chaos, DJVu/STOP, Hive, LockBit, Netwalker, Sodinokibi/REvil, WannaCry",
        "type": "proprietary",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "zero-day detection rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Most prior ransomware studies focus on older families targeting Windows 7/8 (mid-2010s).",
        "Centralized ML training raises data privacy and scalability concerns; moving sensitive data off-site is problematic.",
        "Bandwidth and compute burdens at a single centralized facility hinder real-world applicability.",
        "Newer ransomware families often have relatively fewer samples; need data-centric ML effective with constrained datasets.",
        "Early-stage detection (distribution/delivery) is preferable; static analysis can be more expedient than latent dynamic methods.",
        "Attribution (family classification) is a logical step after detection and is under-addressed in many works."
      ],
      "limitations": [
        "\"it is assumed that the whole setup operates in a trusted manner\" (trusted clients, authenticated/encrypted communications).",
        "Evaluation in this paper focuses on the case of static analysis using PE-file features; dynamic analysis not evaluated.",
        "The curated ransomware repository is intentionally limited to under 1,500 binaries to model realistic scenarios (data scarcity)."
      ],
      "future_work": [],
      "motivation": "Address privacy and scalability barriers of centralized ransomware analysis and shift focus to up-to-date Windows 10/11 ransomware families with limited samples by leveraging federated learning for early detection and attribution.",
      "potential_research_ideas": [
        "Extend DRA to dynamic host and network telemetry (API call sequences, network flows) and evaluate multi-modal fusion under FL.",
        "Investigate zero-shot/few-shot attribution for emerging families using metric learning or prototype-based personalized FL.",
        "Study robustness to non-IID client data distributions (cross-silo heterogeneity) with algorithms like FedProx, SCAFFOLD, or adaptive weighting.",
        "Integrate secure aggregation and differential privacy to quantify and strengthen privacy guarantees beyond the baseline FL setup.",
        "Evaluate resilience to adversarial/Byzantine clients (model poisoning, backdoors) and incorporate robust aggregation (Krum, Trimmed Mean, FLTrust).",
        "Communication-efficient FL for malware (quantization/sparsification, partial model updates) to scale cross-silo deployments.",
        "Build a public benchmark with standardized PE features and protocols for FL-based ransomware analysis to facilitate reproducibility.",
        "Leverage transformer models over byte/section sequences or API-call sequences with parameter-efficient FL (e.g., FedAdapter, LoRA)."
      ],
      "architectural_improvement_recommendations": [
        "Adopt robust FL optimizers for non-IID data (FedProx or SCAFFOLD) and compare against FedAvg.",
        "Introduce personalized FL layers or adapters to balance global detection with client-specific distributions.",
        "Add secure aggregation and optional DP-SGD to the training pipeline for formal privacy protection.",
        "Use hybrid multi-task heads for joint detection (malicious vs benign) and family attribution within a single FL model.",
        "Incorporate model compression (pruning/quantization) and gradient sparsification to reduce communication overhead.",
        "Evaluate CNNs on byte-level PE representations and transformers on PE section/token sequences for richer static features.",
        "Implement cross-validation protocols for zero-day scenarios (leave-one-family-out) to rigorously quantify generalization."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Cross-silo federated learning among vetted institutional client sites coordinated by a central server",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Data privacy concerns prevent sharing raw binaries and logs across organizations.",
        "Bandwidth transfer overheads and centralized compute burdens limit centralized approaches.",
        "Scarcity of samples for newly emerging ransomware families.",
        "Requirement for trusted clients and secure communications (authentication and encryption)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Novel distributed ransomware analysis (DRA) architecture for ransomware detection and attribution using federated learning.",
      "Curation and use of a new ransomware dataset repository with recent Windows 10/11 families; repository limited to under 1,500 binaries to reflect realistic data scarcity.",
      "Detailed evaluation of the DRA framework for static analysis with rapid/lightweight PE-file feature extraction using decentralized NN-based classifiers.",
      "First known study applying federated learning to ransomware detection and attribution."
    ]
  },
  {
    "arxiv_id": "2306.11018v2",
    "title": "Cyber Key Terrain Identification Using Adjusted PageRank Centrality",
    "authors": "Lukáš Sadlek; Pavel Čeleda",
    "abstract": "The cyber terrain contains devices, network services, cyber personas, and other network entities involved in network operations. Designing a method that automatically identifies key network entities to network operations is challenging. However, such a method is essential for determining which cyber assets should the cyber defense focus on. In this paper, we propose an approach for the classification of IP addresses belonging to cyber key terrain according to their network position using the PageRank centrality computation adjusted by machine learning. We used hill climbing and random walk algorithms to distinguish PageRank's damping factors based on source and destination ports captured in IP flows. The one-time learning phase on a static data sample allows near-real-time stream-based classification of key hosts from IP flow data in operational conditions without maintaining a complete network graph. We evaluated the approach on a dataset from a cyber defense exercise and on data from the campus network. The results show that cyber key terrain identification using the adjusted computation of centrality is more precise than its original version.",
    "published_date": "2023-06-19",
    "pdf_link": "https://arxiv.org/pdf/2306.11018v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Network Situational Awareness / Asset Management",
      "specific_problem": "Cyber key terrain (critical host) identification from IP flow data using adjusted centrality",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Graph algorithm / Centrality",
        "specific": "PageRank (static) with port-pair-specific damping factors",
        "novel_contribution": "Adjust PageRank by learning per (source port, destination port) damping factors to optimize F1 for key-host classification"
      },
      {
        "type": "primary",
        "category": "Graph algorithm / Centrality",
        "specific": "Temporal/Streaming PageRank (as in [18])",
        "novel_contribution": "Integrate learned per-edge damping factors into a streaming PageRank to enable near-real-time processing without maintaining a full graph"
      },
      {
        "type": "primary",
        "category": "Heuristic optimization",
        "specific": "Hill Climbing with heuristics (maximum, minimum, average, smallest-difference)",
        "novel_contribution": "Used to search damping-factor space; ties broken via four custom heuristics to improve F1"
      },
      {
        "type": "primary",
        "category": "Heuristic optimization",
        "specific": "Random Walk (stochastic local search)",
        "novel_contribution": "Injected with 0.1 probability to escape local optima when learning damping factors"
      },
      {
        "type": "baseline",
        "category": "Graph algorithm / Centrality",
        "specific": "Default PageRank (damping factor 0.85)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Heuristic optimization"
    ],
    "datasets": [
      {
        "name": "Cyber defense exercise 2019 IP flow dataset (teams 1–6)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Masaryk University campus network IP flow data",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Default PageRank (d=0.85) on cyber-defense exercise Team 1 (learning on static graph)",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "0.75 (Minimum heuristic)",
        "baseline_result": "0.03"
      },
      {
        "method_name": "Default PageRank (d=0.85) on cyber-defense exercise Team 2 (learning on static graph)",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "0.77 (Minimum heuristic)",
        "baseline_result": "0.02"
      },
      {
        "method_name": "Default PageRank (d=0.85) on cyber-defense exercise Team 3 (learning on static graph)",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "0.72 (Minimum heuristic)",
        "baseline_result": "0.04"
      },
      {
        "method_name": "Default PageRank (d=0.85) on cyber-defense exercise Team 4 (learning on static graph)",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "0.74 (Minimum heuristic)",
        "baseline_result": "0.04"
      },
      {
        "method_name": "Default PageRank (d=0.85) on cyber-defense exercise Team 5 (learning on static graph)",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "0.77 (Minimum heuristic)",
        "baseline_result": "0.05"
      },
      {
        "method_name": "Default PageRank (d=0.85) on cyber-defense exercise Team 6 (learning on static graph)",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "0.60 (Minimum heuristic)",
        "baseline_result": "0.09"
      },
      {
        "method_name": "Default PageRank (d=0.85) on University 10-minute sample (learning on static graph)",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "0.84 (Minimum/Maximum heuristics)",
        "baseline_result": "0.65"
      },
      {
        "method_name": "Default PageRank (d=0.85) on University 1-hour sample (learning on static graph)",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "0.75 (Minimum/Average heuristics)",
        "baseline_result": "0.47"
      }
    ],
    "performance_metrics_used": [
      "F1 score",
      "Runtime (preprocessing, learning time, computation time)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to determine which IP addresses from cyber terrain are the key according to the network communication?",
        "Does adjusting the PageRank centrality lead to better correctness of determining the cyber key terrain, and can it process IP flows from the real-world network?"
      ],
      "gaps_identified": [
        "Dynamic nature of cyber key terrain complicates identification; aging out old data and modeling information flows are required.",
        "Prior work often uses high-level mission models without detailing how to populate them from raw data; manual mission modeling is infeasible for large networks.",
        "Centrality methods are not directly applicable to network data if they treat all vertices/edges equally; network-specific adjustments are needed."
      ],
      "limitations": [
        "Streaming values fluctuate; noncritical devices may temporarily have high centrality, requiring evaluation over longer windows.",
        "Must relearn damping factors if the distribution of frequent IPs/port-pairs changes considerably (concept drift).",
        "Learning relies on labeled ground truth of critical hosts for optimization (manual labeling noted for exercise data).",
        "Static learning graphs exclude low-frequency port-pairs (thresholding at 0.5%/0.1%), which may omit rare but important services.",
        "Local optima possible with hill climbing; only partially mitigated by random walk probability 0.1.",
        "Assumption that one edge corresponds to one IP flow; reply direction ignored (only forward direction used)."
      ],
      "future_work": [],
      "motivation": "Enable automated identification of critical network assets (cyber key terrain) from raw IP flow data so cyber defense can prioritize protection, by adapting centrality to computer-network specifics.",
      "potential_research_ideas": [
        "Online/continual learning of damping factors to adapt to concept drift without full retraining.",
        "Incorporate additional flow features (bytes, packets, durations, service/application labels) as edge weights or features in centrality computation.",
        "Compare and/or ensemble multiple centrality measures (betweenness, closeness, eigenvector) with learned weights for criticality scoring.",
        "Learn service-level or role-level damping factors (e.g., per application protocol) and generalize to unseen port-pairs via embeddings.",
        "Integrate active learning to reduce manual labeling effort for critical assets, prioritizing uncertain hosts.",
        "Extend to multi-tenant/segmented networks and evaluate cross-domain generalization; transfer or meta-learn damping priors.",
        "Formulate as differentiable objective and apply Bayesian optimization, CMA-ES, or bandit strategies for more sample-efficient search.",
        "Use temporal decay and seasonality modeling to stabilize streaming scores and reduce transient false positives.",
        "Jointly model host criticality and dependency graphs extracted from other telemetry (DNS, authentication logs) for richer context.",
        "Assess robustness to adversarial traffic manipulation and design defenses (evasion-resistant centrality)."
      ],
      "architectural_improvement_recommendations": [
        "Replace hill climbing + random walk with stronger black-box optimizers (Bayesian optimization, CMA-ES, simulated annealing) to search damping-factor space more efficiently.",
        "Model edge weights using flow volume/duration and incorporate time-decay kernels; learn both damping factors and weights.",
        "Generalize to port/service embeddings learned from co-occurrence, enabling smoothing for unseen or rare port-pairs.",
        "Adopt adaptive classification thresholds (e.g., percentile-based or calibrated via validation) instead of fixed 1/n.",
        "Implement online/streaming parameter adaptation with drift detection (e.g., ADWIN) to trigger re-learning.",
        "Use parallelized/approximate streaming PageRank with sketching to scale to higher flow rates.",
        "Add confidence intervals or stability scores over a sliding window to reduce actioning on transient spikes."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Python"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Implemented in Python; evaluated on a PC with 16 GB RAM, 4 CPU cores @ 3.3 GHz. Example times (per team static learning/computation): preprocessing 0.09–1.35 s; learning 30.20 s–17.49 min (1000 iterations, random-walk prob 0.1); static computation 0.58–2.06 s. Streaming uses linear memory in #vertices and processes edges in one pass (β=0.5)."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Campus/enterprise network (Masaryk University) and cyber defense exercise environment",
      "scalability_discussed": true,
      "inference_time": "Streaming PageRank processes edges in one pass; example static computation 0.6–2.1 s for team graphs; near-real-time claimed for streaming variant.",
      "deployment_challenges": [
        "Requires labeled critical hosts for initial learning/validation.",
        "Needs re-learning when traffic/port-pair distributions shift (concept drift).",
        "Transient centrality spikes can cause false positives; requires windowed aggregation.",
        "Low-frequency but important services may be filtered by port-pair frequency thresholding."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces an adjusted PageRank centrality with port-pair-specific damping factors learned via hill climbing and random walk to classify critical IP addresses.",
      "Provides a streaming computation variant that uses the learned per-edge damping factors, enabling near-real-time processing of IP flows without maintaining a full network graph.",
      "Designs and evaluates four tie-breaking heuristics for hill climbing (maximum, minimum, average, smallest-difference).",
      "Demonstrates substantial F1 improvements over default PageRank on a public cyber-defense exercise dataset (six teams) and campus network data.",
      "Implements a one-time learning phase on static samples followed by stream-based classification, with practical runtime and linear memory characteristics."
    ]
  },
  {
    "arxiv_id": "2306.10634v2",
    "title": "Understanding the Cryptocurrency Free Giveaway Scam Disseminated on Twitter Lists",
    "authors": "Kai Li; Darren Lee; Shixuan Guan",
    "abstract": "This paper presents a comprehensive analysis of the cryptocurrency free giveaway scam disseminated in a new distribution channel, Twitter lists. To collect and detect the scam in this channel, unlike existing scam detection systems that rely on manual effort, this paper develops a fully automated scam detection system, \\textit{GiveawayScamHunter}, to continuously collect lists from Twitter and utilize a Nature-Language-Processing (NLP) model to automatically detect the free giveaway scam and extract the scam cryptocurrency address.   By running \\textit{GiveawayScamHunter} from June 2022 to June 2023, we detected 95,111 free giveaway scam lists on Twitter that were created by thousands of Twitter accounts. Through analyzing the list creator accounts, our work reveals that scammers have combined different strategies to spread the scam, including compromising popular accounts and creating spam accounts on Twitter. Our analysis result shows that 43.9\\% of spam accounts still remain active as of this writing. Furthermore, we collected 327 free giveaway domains and 121 new scam cryptocurrency addresses. By tracking the transactions of the scam cryptocurrency addresses, this work uncovers that over 365 victims have been attacked by the scam, resulting in an estimated financial loss of 872K USD.   Overall, this work sheds light on the tactics, scale, and impact of free giveaway scams disseminated on Twitter lists, emphasizing the urgent need for effective detection and prevention mechanisms to protect social media users from such fraudulent activity.",
    "published_date": "2023-06-18",
    "pdf_link": "https://arxiv.org/pdf/2306.10634v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Social Network Security",
      "subdomain": "Online Fraud and Scam Detection",
      "specific_problem": "Detection and measurement of cryptocurrency free giveaway scams disseminated via Twitter Lists, with extraction of associated scam domains and cryptocurrency addresses",
      "attack_types": [
        "Cryptocurrency free giveaway scam",
        "Impersonation",
        "Account compromise",
        "Spam dissemination/abuse of Twitter Lists (permission-less pushing)",
        "Social engineering"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "NLP Text Classifier (AllenNLP)",
        "specific": null,
        "novel_contribution": "A fully automated pipeline that uses an NLP text classifier on Twitter List titles and descriptions to detect free giveaway scam lists, replacing prior manual/heuristic workflows"
      },
      {
        "type": "primary",
        "category": "Rule-based",
        "specific": "Regular expressions for blockchain address patterns; URLExtract for URL parsing",
        "novel_contribution": "Automated extraction of URLs from list descriptions and regex-based extraction of multi-chain cryptocurrency addresses from scam webpages"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Rule-based"
    ],
    "datasets": [
      {
        "name": "GiveawayScamHunter Twitter Lists Corpus (703,576 lists; 95,111 labeled scams)",
        "type": "proprietary",
        "domain": "social_media_lists",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Annotated Twitter List Titles/Descriptions for Scam Classification (2,000 labeled samples; 27.9% scams; train/test split described)",
        "type": "proprietary",
        "domain": "social_media_text",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Free Giveaway Domains Collected from Twitter Lists (327 domains)",
        "type": "proprietary",
        "domain": "web_domains",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Scam Cryptocurrency Addresses Extracted from Giveaway Websites (121 addresses across BTC/ETH/BNB/ADA/XRP)",
        "type": "proprietary",
        "domain": "blockchain_addresses",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Blockchain Transaction Histories for Scam Addresses",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Twitter List Creator Accounts and Metadata (84,654 unique creators; status, followers, tweets)",
        "type": "proprietary",
        "domain": "social_media_accounts",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can we detect cryptocurrency free giveaway scams disseminated via the previously unstudied Twitter Lists channel using a fully automated approach?",
        "What is the scale and temporal trend of these scams on Twitter Lists, and how do they correlate with broader cryptocurrency market movements?",
        "What tactics do scammers use (e.g., account compromise vs. spam account creation) and how active/visible are the scam lists (members/followers)?",
        "Which cryptocurrencies are targeted and what are the resulting on-chain victimization and financial losses?",
        "Can we automatically extract giveaway domains and multi-chain scam addresses from linked webpages at scale?"
      ],
      "gaps_identified": [
        "“Existing work ... focus on some known distribution channels or rely on heuristics to detect the free giveaway scheme, thus cannot cover scam instances spread in new channels.”",
        "“They all rely on manual effort to assess the collected data to identify the scam, which is tedious and cannot scale to analyze a large amount of social network data.”"
      ],
      "limitations": [
        "Observed 2023 decrease in scam lists may be due to limited collection period: “this significant decrease in scam lists could be attributed to the shorter collection period in 2023.”",
        "Model performance reported on a relatively small manually annotated set (2,000 lists; 27.9% scams), which may limit generalization to edge cases or adversarial text.",
        "Dependence on Twitter Developer API and List functionality; platform policy or API changes could impact data collection.",
        "Language and translation pipeline may introduce errors despite use of Google Translation API; coverage of non-English content depends on translation quality."
      ],
      "future_work": [],
      "motivation": "To identify and analyze a previously unreported distribution channel (Twitter Lists) for cryptocurrency free giveaway scams and to replace manual/heuristic detection with a fully automated, scalable system.",
      "potential_research_ideas": [
        "Develop multimodal detection that fuses list text with linked webpage content features and on-chain signals for end-to-end scam risk scoring.",
        "Leverage graph-based models (e.g., GNNs) over creator–list–member networks to detect coordinated campaigns and compromised high-reputation accounts.",
        "Cross-platform correlation (Twitter, YouTube, Telegram, domains, CT logs) to build a unified scam knowledge graph and detect campaign migration across channels.",
        "Build early-warning and victim-protection tooling (browser extensions or Twitter plugins) that flags suspicious lists and domains in real time.",
        "Adversarially robust NLP for scam text that resists obfuscations (emoji/slang/encoding), including robust tokenization and character-level models.",
        "Automate detection of fake on-page transaction widgets (e.g., DOM pattern analysis, screenshot OCR) to verify giveaway site spoofing tactics.",
        "Active learning with human-in-the-loop to continually improve classifier on hard negatives and new scam templates.",
        "Internationalization: specialized models per language family to reduce dependence on machine translation.",
        "Econometric analysis linking market volatility with scam surges to forecast campaign spikes and pre-empt enforcement."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment the AllenNLP text classifier with a modern transformer encoder (e.g., RoBERTa/DeBERTa) fine-tuned for short, noisy social text.",
        "Incorporate a graph neural network over creator–member–follower interactions and temporal posting behavior to detect coordinated list-creation patterns.",
        "Add a webpage rendering stage (headless browser) to handle dynamic content and detect cloaking; integrate DOM and text features into classification.",
        "Integrate on-chain analytics: anomaly detection over incoming transactions to newly extracted addresses to prioritize active scams.",
        "Implement adversarial training and data augmentation (emoji/slang/obfuscation tactics) to improve robustness.",
        "Introduce confidence estimation and explainability (e.g., attention/attribution over n-grams) to aid triage and analyst trust.",
        "Build a near-real-time streaming pipeline with rate-limit aware collectors and back-pressure handling for API robustness."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "AllenNLP"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Dependence on Twitter Developer API endpoints and rate limits for continuous list collection.",
        "Platform policy or feature changes (e.g., List notifications) may affect data visibility and collection.",
        "High volume of noisy lists and multilingual content requiring robust preprocessing and translation.",
        "Active evasion and account churn by scammers (compromised and spam accounts)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "New distribution channel: Identified Twitter Lists as an abused channel for free giveaway scams due to its permission-less and pushing features.",
      "New scam detection system: Developed GiveawayScamHunter, a fully automated system using an NLP model to detect scams and extract cryptocurrency addresses.",
      "New scams and spam accounts: Collected 95,111 scam lists, identified 84,654 creator accounts (43.9% active; 56.1% suspended), 327 domains, and 121 new scam addresses (most not reported previously).",
      "New understandings: Quantified tactics, scale, and impact, including “over 365 victims” and “an estimated financial loss of 872K USD,” and observed correlations between scam surges and crypto market trends."
    ]
  },
  {
    "arxiv_id": "2306.11206v1",
    "title": "UVSCAN: Detecting Third-Party Component Usage Violations in IoT Firmware",
    "authors": "Binbin Zhao; Shouling Ji; Xuhong Zhang; Yuan Tian; Qinying Wang; Yuwen Pu; Chenyang Lyu; Raheem Beyah",
    "abstract": "Nowadays, IoT devices integrate a wealth of third-party components (TPCs) in firmware to shorten the development cycle. TPCs usually have strict usage specifications, e.g., checking the return value of the function. Violating the usage specifications of TPCs can cause serious consequences, e.g., NULL pointer dereference. Therefore, this massive amount of TPC integrations, if not properly implemented, will lead to pervasive vulnerabilities in IoT devices. Detecting vulnerabilities automatically in TPC integration is challenging from several perspectives: (1) There is a gap between the high-level specifications from TPC documents, and the low-level implementations in the IoT firmware. (2) IoT firmware is mostly the closed-source binary, which loses a lot of information when compiling from the source code and has diverse architectures.   To address these challenges, we design and implement UVScan, an automated and scalable system to detect TPC usage violations in IoT firmware. In UVScan, we first propose a novel natural language processing (NLP)-based rule extraction framework, which extracts API specifications from inconsistently formatted TPC documents. We then design a rule-driven NLP-guided binary analysis engine, which maps the logical information from the high-level TPC document to the low-level binary, and detects TPC usage violations in IoT firmware across different architectures. We evaluate UVScan from four perspectives on four popular TPCs and six ground-truth datasets. The results show that UVScan achieves more than 70% precision and recall, and has a significant performance improvement compared with even the source-level API misuse detectors.",
    "published_date": "2023-06-20",
    "pdf_link": "https://arxiv.org/pdf/2306.11206v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Firmware Security and Analysis",
      "specific_problem": "Detecting third-party component (TPC) API usage violations in closed-source IoT firmware binaries across architectures",
      "attack_types": [
        "Denial-of-Service (DoS)",
        "Man-in-the-Middle (MITM)",
        "NULL pointer dereference",
        "Authorization bypass",
        "Privilege escalation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN (BiLSTM)",
        "specific": null,
        "novel_contribution": "Customized BiLSTM with multi-head self-attention for sentiment-based document distillation to filter relevant API descriptions from heterogeneous TPC documents"
      },
      {
        "type": "primary",
        "category": "Attention",
        "specific": "Multi-head self-attention",
        "novel_contribution": "Used within the sentiment model to capture target-dependent sentiment and inter-word dependencies after coreference resolution"
      },
      {
        "type": "primary",
        "category": "MRC/QA",
        "specific": null,
        "novel_contribution": "Customized Machine Reading Comprehension with well-designed query questions and a manually constructed dataset to extract precise API specifications from TPC documents"
      },
      {
        "type": "baseline",
        "category": "Coreference Resolution",
        "specific": "WL-Coref",
        "novel_contribution": "Off-the-shelf model used to resolve pronouns and entities in TPC documents prior to sentiment modeling"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Rule-based"
    ],
    "datasets": [
      {
        "name": "Manually labeled API description relevance dataset (for sentiment model)",
        "type": "proprietary",
        "domain": "documentation_text",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Manually annotated MRC dataset for API specification extraction",
        "type": "proprietary",
        "domain": "documentation_text",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Six ground-truth datasets for TPC usage violation detection",
        "type": "proprietary",
        "domain": "firmware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Large-scale IoT firmware corpus",
        "type": "proprietary",
        "domain": "firmware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Advance",
        "paper_reference": "[30]",
        "metric": "precision, recall",
        "their_result": "“more than 70% precision and recall” (UVSCAN on ground-truth datasets)",
        "baseline_result": null
      },
      {
        "method_name": "APISAN",
        "paper_reference": "[45]",
        "metric": "precision, recall",
        "their_result": "“has a significant performance improvement compared with even the source-level API misuse detectors”",
        "baseline_result": null
      },
      {
        "method_name": "APEx",
        "paper_reference": "[26]",
        "metric": "precision, recall",
        "their_result": "“has a significant performance improvement compared with even the source-level API misuse detectors”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall",
      "number_of_detected_violations",
      "vendor_confirmations",
      "CVE_count"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Gap between high-level TPC document specifications and low-level binary implementations in IoT firmware",
        "Existing NLP methods work well only on well-formatted TPC documents and struggle with unusual or ambiguous specifications",
        "Example-based API spec inference can be incorrect/incomplete due to insufficient coverage of usage examples",
        "IoT firmware is typically closed-source binaries with missing symbols and diverse architectures, complicating analysis",
        "Lack of binary-level analysis tools (no CodeQL-like capability) for usage violation detection"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Widespread integration of TPCs in IoT firmware and strict API usage specifications; misuses cause severe vulnerabilities while most firmware is closed-source binaries across architectures, necessitating an automated, scalable, binary-level violation detection approach.",
      "potential_research_ideas": [
        "Leverage large language models fine-tuned on code+docs to improve API specification extraction across heterogeneous TPC documents and reduce manual annotation requirements",
        "Develop hybrid static–dynamic analysis to validate potential violations at runtime on emulated firmware to reduce false positives",
        "Automate checker synthesis to extend beyond four violation categories (e.g., concurrency, resource leaks, memory lifetime, crypto misuse patterns)",
        "Create a cross-architecture IR lifting pipeline (e.g., to LLVM/VEX) and learn mappings from binary patterns to API semantics using contrastive learning with source/ABI signatures",
        "Active learning loop with vendor-confirmed vulnerabilities to iteratively improve both the NLP extraction and binary checkers",
        "Assess and harden the system against adversarially written or obfuscated documentation/specs and obfuscated binaries",
        "Construct a public benchmark of TPC usage violations with labeled binaries and documents to standardize evaluation"
      ],
      "architectural_improvement_recommendations": [
        "Replace BiLSTM+attention with a transformer-based encoder (e.g., RoBERTa/BERT variants) fine-tuned for target-dependent sentiment and spec extraction",
        "Adopt retrieval-augmented MRC with document chunking and structural cues (tables, headers) to improve precision on messy vendor docs",
        "Integrate type/signature recovery and decompilation (e.g., Ghidra/angr/RetDec) into fact extraction to enrich Datalog facts for argument and return-value reasoning",
        "Lift binaries to a unified IR before fact generation to improve cross-architecture consistency and rule coverage",
        "Incorporate temporal logic or finite-state automata in rules to better capture causality/ordering constraints beyond simple patterns",
        "Use symbolic execution selectively for argument constraint validation and path feasibility checks to cut false positives",
        "Implement feedback-driven rule refinement using confirmed findings to auto-tune thresholds and patterns"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/BBge/IoT-CVE",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Closed-source IoT firmware images across architectures (x86, ARM, MIPS); routers and IoT gateways",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Binary-level analysis with missing symbols and stripped binaries",
        "Cross-architecture diversity complicates instruction and control-flow analysis",
        "Reliance on correctness and completeness of TPC documentation for rule extraction",
        "Accurate TPC identification within heterogeneous firmware images"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "UVSCAN: an automated, scalable binary-level system for detecting TPC usage violations in IoT firmware, mapping high-level TPC document specifications to binary analysis",
      "Novel NLP-based rule extraction framework: target-dependent sentiment model (coreference + BiLSTM with multi-head self-attention) and MRC-driven extraction with custom queries and a manually constructed dataset",
      "NLP-guided programming expression generation via dependency parsing and semantic pattern mapping",
      "Rule-driven binary analysis engine using Datalog (Soufflé) facts and customized violation-targeted checkers covering deprecated API, return value, argument, and causality violations",
      "Evaluation on four TPCs and six ground-truth datasets with “more than 70% precision and recall,” outperforming state-of-the-art source-level API misuse detectors (Advance, APISAN, APEx)",
      "Large-scale measurement on 4,545 firmware images detecting 27,621 usage violations; case studies demonstrating DoS and MITM impacts; 206 vendor-confirmed vulnerabilities and seven CVE IDs assigned"
    ]
  },
  {
    "arxiv_id": "2306.15588v1",
    "title": "Developing and Deploying Security Applications for In-Vehicle Networks",
    "authors": "Samuel C Hollifield; Pablo Moriano; William L Lambert; Joel Asiamah; Isaac Sikkema; Michael D Iannacone",
    "abstract": "Radiological material transportation is primarily facilitated by heavy-duty on-road vehicles. Modern vehicles have dozens of electronic control units or ECUs, which are small, embedded computers that communicate with sensors and each other for vehicle functionality. ECUs use a standardized network architecture--Controller Area Network or CAN--which presents grave security concerns that have been exploited by researchers and hackers alike. For instance, ECUs can be impersonated by adversaries who have infiltrated an automotive CAN and disable or invoke unintended vehicle functions such as brakes, acceleration, or safety mechanisms. Further, the quality of security approaches varies wildly between manufacturers. Thus, research and development of after-market security solutions have grown remarkably in recent years. Many researchers are exploring deployable intrusion detection and prevention mechanisms using machine learning and data science techniques. However, there is a gap between developing security system algorithms and deploying prototype security appliances in-vehicle. In this paper, we, a research team at Oak Ridge National Laboratory working in this space, highlight challenges in the development pipeline, and provide techniques to standardize methodology and overcome technological hurdles.",
    "published_date": "2023-06-27",
    "pdf_link": "https://arxiv.org/pdf/2306.15588v1",
    "paper_types": [
      "position",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Automotive Security",
      "subdomain": "In-vehicle Network Security (CAN bus)",
      "specific_problem": "Bridging the gap from IDS algorithm research to deployable in-vehicle CAN security appliances; guidance on developing, testing (hardware-in-the-loop), and deploying CAN intrusion detection/prevention systems",
      "attack_types": [
        "Fabrication (message injection)",
        "Suspension (DoS/silencing ECUs)",
        "Masquerade (ECU impersonation)",
        "Address-claim attacks (SAE J1939)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Statistical/Time-series modeling",
        "specific": null,
        "novel_contribution": "Uses frequency-based modeling of Arbitration ID (AID) timing for fabrication/suspension detection; contribution of this paper is the engineering pipeline and deployment practices rather than a new model"
      },
      {
        "type": "baseline",
        "category": "Clustering",
        "specific": "Hierarchical clustering",
        "novel_contribution": "Cited as a scalable approach to detect similarities across CAN signals for masquerade attacks (Moriano et al.)"
      },
      {
        "type": "baseline",
        "category": "Deep Learning (Time-series)",
        "specific": null,
        "novel_contribution": "Cited deep-learning method for masquerade detection on real and synthetic datasets (Hanselmann et al.)"
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Supervised",
      "Rule-based"
    ],
    "datasets": [
      {
        "name": "Open-source CAN datasets (unspecified)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "In-house CAN traffic logs for replay in testbed",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Deep-learning signal-based masquerade detector",
        "paper_reference": "Hanselmann et al. (as cited)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Hierarchical clustering for CAN signal similarity",
        "paper_reference": "Moriano et al. (as cited)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Four competing frequency-based methods for fabrication detection",
        "paper_reference": "[8] (as cited)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can researchers reliably transition CAN IDS algorithms from desktop development to embedded, in-vehicle deployment?",
        "What hardware, software, and testbed practices reduce cost and time-to-deploy for CAN security appliances?",
        "How to validate IDSs using hardware-in-the-loop while preserving CAN physical-layer properties and enabling remote, repeatable testing?"
      ],
      "gaps_identified": [
        "Gap between algorithmic IDS research and deployable in-vehicle prototypes",
        "Inconsistent defensive tooling across manufacturers; lack of standard methodology for aftermarket CAN security",
        "Difficulty obtaining safe, repeatable CAN data and vehicles for testing; need for hardware-in-the-loop testbeds",
        "Embedded/ARM deployment hurdles (dependencies, streaming performance, resource constraints)",
        "Environmental and operational deployment issues (power draw/battery drain, bitrate variability, mounting, heat/humidity/vibration)",
        "Limited approaches for masquerade detection at scale across many AIDs"
      ],
      "limitations": [
        "Paper focuses on process and engineering guidance; no new dataset or full quantitative evaluation provided",
        "Attack detection details and comparative results are referenced to prior work; this paper does not report new metrics",
        "Vehicle-agnostic deployment remains a target outcome and may require further adaptation per vehicle (e.g., bitrate, network access)"
      ],
      "future_work": [
        "Refine and validate algorithms during heavy-duty truck pilot deployments toward vehicle-agnostic operation",
        "Expand coverage to additional CAN networks (including internal buses) and attack classes (e.g., J1939 address-claim)",
        "Integrate prevention/response mechanisms alongside detection",
        "Automate safe bitrate detection and broader on-vehicle diagnostics",
        "Harden environmental resilience (cooling, power management, vibration-tolerant enclosures)"
      ],
      "motivation": "Accelerate and standardize the pipeline from CAN IDS research to robust, deployable, aftermarket in-vehicle security solutions for heavy-duty vehicles transporting radiological materials.",
      "potential_research_ideas": [
        "Release a standardized, open CAN IDS hardware-in-the-loop benchmark with labeled attacks (including J1939) to enable reproducible evaluation",
        "Develop self-supervised representations of CAN signals for cross-vehicle transfer (vehicle-agnostic models)",
        "TinyML implementations of masquerade detectors for microcontrollers with quantization/pruning and on-device feature extraction",
        "Hybrid rule+ML frameworks combining frequency anomaly detection with learned signal models to reduce false positives",
        "Online/continual learning with drift detection for changing vehicle conditions and maintenance modes",
        "Cross-bus correlation (multiple CANs, LIN, FlexRay) to improve detection fidelity and attack attribution",
        "Safe, passive auto-bitrate inference and multi-rate adaptation without risking bus disruption",
        "Power-aware scheduling and duty-cycling to prevent battery drain during parked states",
        "Explainability modules that map anomalies to specific signals/AIDs with human-readable rationales",
        "Formal verification of safety properties for IDS appliances connected to safety-critical buses"
      ],
      "architectural_improvement_recommendations": [
        "Adopt streaming-first architectures with lock-free queues/zero-copy CAN ingestion on embedded Linux",
        "Implement lightweight temporal models (e.g., TCNs or GRU/LSTM) with INT8 quantization and TensorRT/ONNX Runtime for Jetson-class devices",
        "Use hierarchical modeling: per-AID frequency rules + cluster-based signal models + global correlation layer",
        "Add watchdogs and fail-safe modes to ensure no unintended transmission during bitrate detection or failures",
        "Containerize components (e.g., Docker on ARM) with OTA secure update and signed artifacts",
        "Structured logging and on-device buffering with privacy-aware redaction; remote telemetry via secure gateway",
        "Modular driver abstraction for SocketCAN/can-utils to swap between virtual, testbed, and in-vehicle buses"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Python",
        "NumPy",
        "pandas",
        "scikit-learn",
        "Linux SocketCAN",
        "can-utils"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Engineering validated on Raspberry Pi 4 (≈15W), Nvidia Jetson Xavier/AGX (≈10–30W), and microcontrollers (0.5–1W). Embedded ARM deployment; streaming on-device inference; attention to battery draw and thermal limits."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Heavy-duty trucks (in-vehicle CAN; pilot deployments); hardware-in-the-loop testbed with simulated ECUs",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "ARM/embedded porting and dependency resolution for streaming workloads",
        "Power management; risk of draining 12V battery if always-on",
        "CAN bitrate variability and safe auto-detection without transmitting",
        "Physical mounting constraints; interference with cabin space",
        "Environmental stressors (heat >140°F, humidity, vibration) requiring cooling/enclosures",
        "Access to multiple CANs beyond OBD; bitrate mismatches and error frames",
        "Data scarcity and need for realistic attack traffic; reliance on pre-recorded logs for replay",
        "Ensuring detector is passive and does not flood the bus if misconfigured"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Articulates an end-to-end pipeline for developing, testing, and deploying CAN IDS on embedded hardware",
      "Design and use of a CAN hardware-in-the-loop testbed with simulated ECUs using SocketCAN and can-utils",
      "Practical guidance for hardware selection (microcontroller vs SBC vs AI-accelerated), power budgeting, and deployment trade-offs",
      "Operational recommendations for prototype deployment: power delivery, safe CAN access, auto-bitrate detection, and mounting",
      "Environmental resilience considerations for in-vehicle electronics (thermal, vibration, humidity)",
      "Process standardization to reduce development time and cost for aftermarket CAN security appliances"
    ]
  },
  {
    "arxiv_id": "2306.07685v2",
    "title": "Few-shot Multi-domain Knowledge Rearming for Context-aware Defence against Advanced Persistent Threats",
    "authors": "Gaolei Li; Yuanyuan Zhao; Wenqi Wei; Yuchen Liu",
    "abstract": "Advanced persistent threats (APTs) have novel features such as multi-stage penetration, highly-tailored intention, and evasive tactics. APTs defense requires fusing multi-dimensional Cyber threat intelligence data to identify attack intentions and conducts efficient knowledge discovery strategies by data-driven machine learning to recognize entity relationships. However, data-driven machine learning lacks generalization ability on fresh or unknown samples, reducing the accuracy and practicality of the defense model. Besides, the private deployment of these APT defense models on heterogeneous environments and various network devices requires significant investment in context awareness (such as known attack entities, continuous network states, and current security strategies). In this paper, we propose a few-shot multi-domain knowledge rearming (FMKR) scheme for context-aware defense against APTs. By completing multiple small tasks that are generated from different network domains with meta-learning, the FMKR firstly trains a model with good discrimination and generalization ability for fresh and unknown APT attacks. In each FMKR task, both threat intelligence and local entities are fused into the support/query sets in meta-learning to identify possible attack stages. Secondly, to rearm current security strategies, an finetuning-based deployment mechanism is proposed to transfer learned knowledge into the student model, while minimizing the defense cost. Compared to multiple model replacement strategies, the FMKR provides a faster response to attack behaviors while consuming less scheduling cost. Based on the feedback from multiple real users of the Industrial Internet of Things (IIoT) over 2 months, we demonstrate that the proposed scheme can improve the defense satisfaction rate.",
    "published_date": "2023-06-13",
    "pdf_link": "https://arxiv.org/pdf/2306.07685v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Advanced Persistent Threat (APT) Detection",
      "specific_problem": "Few-shot, context-aware, multi-stage APT stage identification and rapid cross-domain deployment in heterogeneous IIoT environments",
      "attack_types": [
        "Reconnaissance",
        "Establish Foothold",
        "Lateral Movement",
        "Data Exfiltration",
        "Unknown/novel APT variants"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Meta-learning",
        "specific": "MAML-like episodic training (inner/outer loops)",
        "novel_contribution": "Few-shot multi-domain knowledge rearming (FMKR): meta-learning across tasks constructed from different network domains with fused traffic+syslog support/query sets to generalize to unknown APT stages"
      },
      {
        "type": "primary",
        "category": "Transfer learning",
        "specific": "Fine-tuning with layer freezing/extension and classifier replacement",
        "novel_contribution": "On-demand finetuning-based deployment mechanism; freeze M layers, extend N new layers, replace classification head to adapt per-domain with minimal cost; cloud-edge synergistic training and model replacement"
      },
      {
        "type": "primary",
        "category": "Cost-sensitive learning",
        "specific": "Class-balanced cross-entropy (cost ratio weighting)",
        "novel_contribution": "Class equilibrium loss to handle extreme class imbalance across APT stages"
      },
      {
        "type": "primary",
        "category": "Multi-modal fusion",
        "specific": "Timestamp-aligned fusion of network traffic and syslog",
        "novel_contribution": "Support/query construction from fused modalities with 2s alignment window to inject contextual entities into meta-tasks"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Few-shot",
      "Meta-learning",
      "Transfer learning"
    ],
    "datasets": [
      {
        "name": "Fused IIoT traffic+syslog dataset (constructed in this work)",
        "type": "proprietary",
        "domain": "network_traffic, log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "defense satisfaction rate",
      "response latency",
      "scheduling cost"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to train APT detectors that generalize to fresh/unknown samples with very few and imbalanced labels across domains?",
        "How to fuse multi-dimensional threat intelligence (traffic, syslog, entities) for stage-wise APT identification?",
        "How to rapidly and cost-effectively deploy/upfit models across heterogeneous IIoT environments with contextual awareness?"
      ],
      "gaps_identified": [
        "Data-driven ML lacks generalization on fresh/unknown APT samples, reducing accuracy/practicality.",
        "Heterogeneous, privately deployed environments require significant investment for context awareness and model adaptation.",
        "Severe class imbalance across APT stages (e.g., very few Data Exfiltration samples) hurts detection.",
        "Existing few-shot works have low practicality: hard to run across heterogeneous devices, do not consider current defense strategies, and knowledge transfer across domains is difficult."
      ],
      "limitations": [
        "Label fusion via timestamps alone is inefficient for hidden/latent IIoT attack behaviors (authors note limitation of pure timestamp labeling).",
        "Details of datasets and code are not provided; reproducibility and independent validation are unclear.",
        "Quantitative comparisons to named baselines are not presented in the provided text."
      ],
      "future_work": [],
      "motivation": "Improve reliability, adaptability, and deployment efficiency of context-aware APT defense under few/imbalanced samples and heterogeneous IIoT environments.",
      "potential_research_ideas": [
        "Integrate an ATT&CK-aligned knowledge graph and graph neural networks to model entity-stage relations for improved few-shot generalization.",
        "Develop domain generalization/meta-regularization to reduce or eliminate per-domain fine-tuning and improve out-of-domain robustness.",
        "Add continual learning with drift detection to adapt to evolving TTPs without catastrophic forgetting.",
        "Incorporate uncertainty estimation and selective abstention to reduce false positives/negatives in high-risk stages (e.g., data exfiltration).",
        "Combine self-supervised pretraining on large unlabeled traffic/logs (e.g., contrastive learning) before FMKR to improve representation quality.",
        "Evaluate adversarial robustness (evasion/poisoning) and harden with adversarial training or certified defenses.",
        "Design privacy-preserving or federated FMKR for multi-tenant IIoT without sharing raw logs/traffic.",
        "Publicly release a standardized fused traffic+syslog APT-stage dataset and benchmarks for reproducibility.",
        "Lightweight distillation to tiny edge models with latency/energy constraints and dynamic per-domain adapters."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment the base encoder with temporal transformers or TCNs for traffic+log sequences; add cross-modal attention for fusion.",
        "Adopt metric-learning few-shot heads (prototypical networks, relation networks) on top of the meta-learned encoder to stabilize low-shot stage classification.",
        "Introduce episodic domain-adversarial objectives or style augmentation to improve cross-domain invariance.",
        "Use hierarchical multi-task outputs aligned with ATT&CK (tactics -> techniques) to exploit label structure and reduce data needs.",
        "Add uncertainty-aware calibration (temperature scaling, evidential DL) and cost-sensitive decision thresholds per stage.",
        "Implement online fine-tuning with replay buffers and regularization (e.g., EWC) to mitigate forgetting across domains.",
        "Automate model replacement and adapter selection via reinforcement learning under latency/cost constraints."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Industrial IoT (IIoT) enterprise networks with cloud-edge synergy; 5G/6G-enabled IIoT edge devices",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Heterogeneous devices and private deployments across domains",
        "High cost/complexity for context awareness and model updates",
        "Severe class imbalance and scarcity of labeled APT-stage data",
        "Coordinating cloud-edge training and model replacement without service disruption"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposed FMKR, a few-shot multi-domain knowledge rearming scheme that frames context-aware APT defense as meta-learning tasks with fused threat intelligence and local entities.",
      "Introduced a finetuning-based deployment mechanism (freeze M layers, extend N layers, replace classifier) to rearm current security strategies and adapt per-domain at low cost with cloud-edge synergy and model replacement.",
      "Designed a class equilibrium loss to mitigate extreme class imbalance across APT stages.",
      "Demonstrated feasibility via simulations on datasets and real observations in IIoT; reported improved defense satisfaction rate over 2 months from multiple real users."
    ]
  },
  {
    "arxiv_id": "2306.12338v2",
    "title": "Do you still need a manual smart contract audit?",
    "authors": "Isaac David; Liyi Zhou; Kaihua Qin; Dawn Song; Lorenzo Cavallaro; Arthur Gervais",
    "abstract": "We investigate the feasibility of employing large language models (LLMs) for conducting the security audit of smart contracts, a traditionally time-consuming and costly process. Our research focuses on the optimization of prompt engineering for enhanced security analysis, and we evaluate the performance and accuracy of LLMs using a benchmark dataset comprising 52 Decentralized Finance (DeFi) smart contracts that have previously been compromised.   Our findings reveal that, when applied to vulnerable contracts, both GPT-4 and Claude models correctly identify the vulnerability type in 40% of the cases. However, these models also demonstrate a high false positive rate, necessitating continued involvement from manual auditors. The LLMs tested outperform a random model by 20% in terms of F1-score.   To ensure the integrity of our study, we conduct mutation testing on five newly developed and ostensibly secure smart contracts, into which we manually insert two and 15 vulnerabilities each. This testing yielded a remarkable best-case 78.7% true positive rate for the GPT-4-32k model. We tested both, asking the models to perform a binary classification on whether a contract is vulnerable, and a non-binary prompt. We also examined the influence of model temperature variations and context length on the LLM's performance.   Despite the potential for many further enhancements, this work lays the groundwork for a more efficient and economical approach to smart contract security audits.",
    "published_date": "2023-06-21",
    "pdf_link": "https://arxiv.org/pdf/2306.12338v2",
    "paper_types": [
      "empirical_analysis",
      "benchmark",
      "new_dataset"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Security / Auditing",
      "specific_problem": "Assessing feasibility and effectiveness of large language models (LLMs) to detect vulnerabilities in DeFi smart contracts via prompt engineering and binary/non-binary auditing prompts",
      "attack_types": [
        "Reentrancy",
        "On-chain oracle manipulation",
        "Governance attack",
        "Visibility errors (including unrestricted action)",
        "Token standard incompatibility",
        "Absence of code logic or sanity check",
        "Flash liquidity borrow/purchase/mint/deposit",
        "Frontrunning",
        "Deployment mistake",
        "Other unsafe DeFi protocol dependency",
        "Delegatecall injection",
        "Unsafe call to phantom function",
        "Direct call to untrusted contract",
        "Insider trade or other activities",
        "Locked or frozen tokens",
        "Unfair slippage protection",
        "Unfair liquidity providing",
        "Fake tokens",
        "Other coding mistakes",
        "Other unfair or unsafe DeFi protocol interaction",
        "Inconsistent access control",
        "Arithmetic mistakes"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Large Language Model (Transformer)",
        "specific": "GPT-4-32k",
        "novel_contribution": "Prompt-engineering for binary and non-binary vulnerability detection; evaluation of temperature and context-length; few-shot chain-of-thought case studies for recent exploits"
      },
      {
        "type": "primary",
        "category": "Large Language Model (Transformer)",
        "specific": "Claude-v1.3-100k",
        "novel_contribution": "Same evaluation protocol as GPT-4 with emphasis on long-context prompts; observations about binary-output adherence degrading with longer context"
      },
      {
        "type": "baseline",
        "category": "Random classifier",
        "specific": null,
        "novel_contribution": "Used as a random baseline for F1 and FP comparisons"
      }
    ],
    "learning_paradigm": [
      "Zero-shot",
      "Few-shot"
    ],
    "datasets": [
      {
        "name": "52 DeFi attacked smart contracts (curated from DeFi Attack SoK and Etherscan)",
        "type": "public",
        "domain": "smart_contract_source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Five synthetic smart contracts with injected vulnerabilities (mutation testing)",
        "type": "synthetic",
        "domain": "smart_contract_source_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "DeFi Attack SoK [51] (source for attack ground-truth categories)",
        "type": "public",
        "domain": "attack_taxonomy/incident_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random model",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "“We find that ... GPT-4-32k has a better overall F1-score of 0.077 compared to 0.076 for Claude-v1.3-100k.”",
        "baseline_result": "“The LLMs’ F1 score is 20% higher than the random baseline” (exact random F1 not reported)."
      },
      {
        "method_name": "Random model",
        "paper_reference": null,
        "metric": "TP/TN/FP/FN (aggregate across 52×38 checks)",
        "their_result": "GPT-4-32k: TP=32, TN=1128, FP=740, FN=41; Claude-v1.3-100k: TP=26, TN=1290, FP=578, FN=47",
        "baseline_result": "Random: TP=36.54, TN=960.62, FP=962.42, FN=39.21 (fractional from expectation)"
      }
    ],
    "performance_metrics_used": [
      "Hit rate on vulnerable contracts",
      "True Positives (TP)",
      "True Negatives (TN)",
      "False Positives (FP)",
      "False Negatives (FN)",
      "F1-score",
      "True Positive Rate (mutation testing)",
      "False Positive Rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can off-the-shelf LLMs (GPT-4-32k, Claude-v1.3-100k) identify security vulnerabilities in DeFi smart contracts?",
        "What prompt-engineering strategies (binary vs non-binary, chain-of-thought/few-shot) improve detection?",
        "How do temperature and context length influence detection performance and binary-output adherence?",
        "Do LLMs generalize to unseen vulnerabilities via mutation testing on newly written contracts?"
      ],
      "gaps_identified": [
        "Manual smart contract audits are time-consuming and costly for DeFi-scale codebases.",
        "Existing tools miss classes of DeFi protocol-level issues (e.g., oracle manipulation) and require expert effort.",
        "LLMs may have been trained on public incidents, confounding real generalization assessment.",
        "Long-context handling can degrade instruction adherence (binary YES/NO).",
        "Ground-truth incompleteness: attacked contracts may contain unreported vulnerabilities, complicating FP estimation."
      ],
      "limitations": [
        "Unknown LLM training data; possible data leakage from public incident reports.",
        "Binary classification compliance issues (models sometimes omit YES/NO).",
        "High false positive rates requiring expensive manual triage.",
        "GPT-4-32k context truncation for 7 contracts; naive truncation used.",
        "Observed degradation of binary compliance with very long contexts (Claude 100k).",
        "Audit completeness: identifying a class is insufficient without precise exploit PoC."
      ],
      "future_work": [
        "Source-code compression/segmentation with hierarchical or multi-turn analysis instead of naive truncation.",
        "Quantitatively study long-context effects on instruction following and accuracy.",
        "Explore chained queries and retrieval-augmented auditing with documentation/ABI/bytecode.",
        "Reduce false positives via calibration, self-consistency, or verifier-in-the-loop designs.",
        "Broaden evaluation to more attack classes and newer LLMs; release standardized benchmark suites."
      ],
      "motivation": "Reduce cost and improve efficiency of DeFi smart contract auditing by leveraging LLMs capable of processing large code contexts.",
      "potential_research_ideas": [
        "Hybrid auditor combining LLM reasoning with static analysis/symbolic execution to auto-verify flagged findings and cut false positives.",
        "Hierarchical auditing: function-level chunking with retrieval and a coordinator agent performing cross-file/global checks (storage/layout/oracle flows).",
        "Constrained decoding or toolformer-style function calls to enforce YES/NO outputs and structured evidence (locations, code spans).",
        "Verifier-in-the-loop: auto-generate minimal PoCs or invariants and validate via fuzzers/SMT, feeding outcomes back to the LLM for self-refinement.",
        "Curriculum fine-tuning on curated vulnerability corpora (code+labels+patches) and synthetic hard negatives to improve precision.",
        "RAG over on-chain data/ABIs and prior incidents to contextualize DeFi protocol interactions (e.g., price oracles, AMM math).",
        "Self-consistency ensembles across temperatures/seeds with majority voting and calibration to lower FP.",
        "Multi-agent auditing (finder, skeptic, prover) with debate to increase precision and require proof sketches before positive labels."
      ],
      "architectural_improvement_recommendations": [
        "Adopt hierarchical chunking with retrieval to avoid truncation; aggregate via a supervisor prompt with structured schemas for findings.",
        "Integrate static analyzers (Slither/Mythril), symbolic executors, and fuzzers; require tool-backed evidence before labeling YES.",
        "Use structured output (JSON schema) and constrained decoding to enforce binary outputs and include code locations and rationale.",
        "Set temperature to 0 for classification; use self-consistency only for exploration; calibrate thresholds via validation set.",
        "Apply few-shot exemplars per vulnerability type with minimal tokens; employ function and storage-layout summaries to save context.",
        "Employ program analysis graphs (CFG/DFG/AST) as auxiliary inputs via serialization to improve reasoning over control/state flows."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "OpenAI GPT-4 API",
        "Anthropic Claude API"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "3,952 API queries for 52×38×2 evaluation with 13s delay between calls; ~USD 2,000 for GPT-4-32k evaluation; mutation testing: 760 API calls, ~USD 400; models: GPT-4-32k (32k tokens) and Claude-v1.3-100k (100k tokens)."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Public Ethereum/DeFi smart contracts (auditing context)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High false positive rate requiring manual triage.",
        "Context length/segmentation for large codebases.",
        "Instruction-following degradation with very long contexts.",
        "Unknown training data provenance; potential leakage.",
        "API rate limits and monetary cost."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First empirical study applying LLMs to smart contract security audits focused on DeFi protocols.",
      "Prompt-engineering methodology for binary and non-binary auditing, including chain-of-thought case studies.",
      "Quantitative evaluation on 52 DeFi attacks across 38 vulnerability types; ~40% hit rate on vulnerable contracts.",
      "Demonstrated that GPT-4 and Claude outperform a random baseline by ~20% F1, with fewer false positives.",
      "Introduced five new synthetic contracts with injected vulnerabilities and achieved up to 78.7–78.8% TPR in mutation testing.",
      "Analyzed effects of context length and temperature on LLM auditing performance and output adherence."
    ]
  },
  {
    "arxiv_id": "2306.14027v2",
    "title": "(Security) Assertions by Large Language Models",
    "authors": "Rahul Kande; Hammond Pearce; Benjamin Tan; Brendan Dolan-Gavitt; Shailja Thakur; Ramesh Karri; Jeyavijayan Rajendran",
    "abstract": "The security of computer systems typically relies on a hardware root of trust. As vulnerabilities in hardware can have severe implications on a system, there is a need for techniques to support security verification activities. Assertion-based verification is a popular verification technique that involves capturing design intent in a set of assertions that can be used in formal verification or testing-based checking. However, writing security-centric assertions is a challenging task. In this work, we investigate the use of emerging large language models (LLMs) for code generation in hardware assertion generation for security, where primarily natural language prompts, such as those one would see as code comments in assertion files, are used to produce SystemVerilog assertions. We focus our attention on a popular LLM and characterize its ability to write assertions out of the box, given varying levels of detail in the prompt. We design an evaluation framework that generates a variety of prompts, and we create a benchmark suite comprising real-world hardware designs and corresponding golden reference assertions that we want to generate with the LLM.",
    "published_date": "2023-06-24",
    "pdf_link": "https://arxiv.org/pdf/2306.14027v2",
    "paper_types": [
      "benchmark",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Design Verification and Validation",
      "specific_problem": "Automatic generation of SystemVerilog security assertions from natural language prompts using large language models",
      "attack_types": [
        "Access control/privilege violations (e.g., privileged CSR access by unprivileged user)",
        "Debug/test interface misuse (e.g., JTAG unlock/locked access)",
        "Information leakage (e.g., AES internal registers visibility)",
        "Improper lock/reset initialization and behavior",
        "Timing/reset control faults (e.g., reset not following trigger within bounds)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": null,
        "novel_contribution": "Out-of-the-box prompting of a commercial large language model to generate SystemVerilog security assertions from natural language comments and limited design context, evaluated with a custom simulation-based equivalence framework"
      }
    ],
    "learning_paradigm": [
      "In-context learning (prompting)",
      "Zero-shot",
      "Few-shot (with example assertions)"
    ],
    "datasets": [
      {
        "name": "LLM Hardware Security Assertion Benchmark Suite (BM1–BM10)",
        "type": "public",
        "domain": "hardware_rtl_assertions",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Hack@DAC hardware security competition designs (modules used for BM3–BM8)",
        "type": "public",
        "domain": "hardware_rtl",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "OpenTitan SoC modules (ADC controller, Reset manager) used for BM9–BM10",
        "type": "public",
        "domain": "hardware_rtl",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Manually crafted RTL designs (BM1 Lockable Register, BM2 Traffic Signal Controller)",
        "type": "synthetic",
        "domain": "hardware_rtl",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Functional equivalence to golden assertion under simulation (triggered for the same input sets)",
      "Syntax/typographical correctness (compilability) of generated SVA",
      "Simulation-based pass/fail detection alignment with golden reference"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: Is it possible for LLMs to generate security assertions for hardware?",
        "RQ2: How do LLMs perform on different prompts?"
      ],
      "gaps_identified": [
        "Writing security-centric assertions is challenging, error-prone, and does not scale.",
        "Automated assertion mining tends to produce irrelevant or difficult checks and is not well-suited for security properties.",
        "Security assertions require specialized design/security expertise often unavailable to typical designers.",
        "Existing natural-language-to-assertion efforts are small-scale, often non-security-focused, or require manual checking.",
        "Natural language descriptions of security properties in practice are not automatically leveraged to write assertions."
      ],
      "limitations": [
        "Framework’s syntax fixer can only correct a limited set of syntax/typographical issues.",
        "Source files used in prompts were trimmed and simplified to fewer than 100 lines to fit LLM token limits, potentially reducing available context.",
        "Evaluation focuses on a single popular commercial LLM used out-of-the-box (no fine-tuning)."
      ],
      "future_work": [
        "Train or fine-tune LLMs to rectify common assertion-generation errors identified by the study.",
        "Extend and diversify the benchmark suite and prompts to cover more complex, parameterized, and timing-heavy properties.",
        "Integrate automated assertion generation into design flows to encourage adoption of assertion-based security checking.",
        "Enhance the framework with stronger syntax/semantic validation beyond limited fixes."
      ],
      "motivation": "Encourage adoption of assertion-based security checking by determining faster and easier methods of generating hardware security assertions using LLMs.",
      "potential_research_ideas": [
        "Fine-tune code LLMs on a curated corpus of SystemVerilog assertions (especially security-focused) to improve accuracy and timing semantics.",
        "Combine property mining (from simulation traces or information-flow analysis) with LLM prompting to propose candidate security assertions, then refine via formal feedback.",
        "Use reinforcement learning from verification feedback (model checking/simulation counterexamples) to iteratively improve generated assertions.",
        "Develop retrieval-augmented prompting that finds similar modules/assertions from large hardware repositories to guide generation.",
        "Design constrained decoding or grammar-based generation for SVA to prevent syntactic and certain semantic errors.",
        "Create a multi-agent toolchain where one agent proposes assertions, another validates and explains them, and a third repairs failures using counterexamples.",
        "Map structural RTL context (signal dependency graphs, clock/reset domains) into prompts to improve correct signal selection and timing alignment."
      ],
      "architectural_improvement_recommendations": [
        "Introduce an SVA-aware tokenizer/grammar-constrained decoder to enforce syntactic correctness.",
        "Implement retrieval-augmented generation over a library of vetted security assertions and related RTL patterns.",
        "Incorporate formal verification feedback loops (e.g., counterexample-guided repair) into generation.",
        "Leverage signal graph embeddings or structured prompts encoding clock/reset domains and interface roles.",
        "Adopt self-consistency and ensemble decoding, followed by equivalence checking to select the best assertion.",
        "Augment prompts with automated extraction of relevant signal names and parameter values from RTL to reduce ambiguity."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Uses a commercial LLM API for generation and an HDL simulator for equivalence testing; prompt token limits require trimmed RTL context."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Hardware design verification flow (RTL/SystemVerilog assertions) using EDA simulators",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Limited LLM context window necessitating trimmed RTL files and careful prompt engineering.",
        "Syntactic and semantic errors in generated assertions requiring post-processing and validation.",
        "Dependence on commercial LLMs with opaque training and variable determinism.",
        "Accurate mapping of natural language property descriptions to correct signals and timing semantics.",
        "Security expertise needed to validate assertion intent even when generation is automated."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A framework and benchmarks to evaluate LLMs in generating hardware assertions (including a limited syntax/typographical fixer).",
      "Evaluation of a commercial LLM for generating security assertions for hardware.",
      "An investigation of the effect of different prompt types and detail levels on assertion generation quality.",
      "Open-sourcing of the LLM-based framework and benchmark suite to support further research."
    ]
  },
  {
    "arxiv_id": "2306.15106v1",
    "title": "Improvise, Adapt, Overcome: Dynamic Resiliency Against Unknown Attack Vectors in Microgrid Cybersecurity Games",
    "authors": "Suman Rath; Tapadhir Das; Shamik Sengupta",
    "abstract": "Cyber-physical microgrids are vulnerable to rootkit attacks that manipulate system dynamics to create instabilities in the network. Rootkits tend to hide their access level within microgrid system components to launch sudden attacks that prey on the slow response time of defenders to manipulate system trajectory. This problem can be formulated as a multi-stage, non-cooperative, zero-sum game with the attacker and the defender modeled as opposing players. To solve the game, this paper proposes a deep reinforcement learning-based strategy that dynamically identifies rootkit access levels and isolates incoming manipulations by incorporating changes in the defense plan. A major advantage of the proposed strategy is its ability to establish resiliency without altering the physical transmission/distribution network topology, thereby diminishing potential instability issues. The paper also presents several simulation results and case studies to demonstrate the operating mechanism and robustness of the proposed strategy.",
    "published_date": "2023-06-26",
    "pdf_link": "https://arxiv.org/pdf/2306.15106v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Critical Infrastructure Security",
      "subdomain": "Microgrid/Cyber-Physical Power Systems Security",
      "specific_problem": "Dynamic defense and resiliency against latent, multi-stage rootkit-driven data/command manipulation in microgrid secondary control without altering physical topology",
      "attack_types": [
        "rootkit",
        "false data injection",
        "stealth multi-stage attack",
        "insider compromise"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": "Deep Q-Learning (DQN)",
        "novel_contribution": "DRL-enabled dynamic defense that detects activation of latent attack vectors and adaptively reconfigures secondary control communication adjacency matrix elements to nullify adversarial measurements while maintaining stability"
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning"
    ],
    "datasets": [
      {
        "name": "AC microgrid simulation environment and generated trajectories/case studies",
        "type": "synthetic",
        "domain": "power_systems_time_series (microgrid states, control signals)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "stability via Lyapunov analysis",
      "convergence to nominal frequency and voltage setpoints",
      "frequency deviation from nominal (|ωk−ωn|)",
      "voltage deviation from nominal (|vodk−vodn|)",
      "robustness under latent multi-stage attack scenarios (trajectory maintenance)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a defender dynamically identify the hidden/latent access level of a rootkit and adapt the defense plan online to maintain microgrid stability?",
        "Does a defender strategy exist that can mitigate attacks even when the attacker controls up to (N−1) DG nodes in an N-DG microgrid?",
        "Can deep Q-learning provide an effective game-theoretic solution for dynamic defense by reconfiguring communication topology (adjacency matrix elements) in the secondary control layer without changing the physical network?"
      ],
      "gaps_identified": [
        "Most prior work focuses on data integrity attacks and overlooks malware like rootkits in distributed energy systems.",
        "Common assumption that attackers reveal full access level at first manipulation is unrealistic; real attackers use latent, multi-stage vectors.",
        "Physics-only approaches may not capture increasing model complexities and unknown dynamics; can be manipulated by intelligent adversaries with system knowledge.",
        "Supervised learning requires labeled attack data (often unavailable) and may not capture unknown adversary variables; offline-trained methods are vulnerable to poisoned training data.",
        "State-estimation-based approaches are vulnerable to stealth attacks that manipulate parameters to trick observers."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Rootkits can stealthily hide access levels and manipulate microgrid dynamics in a latent, multi-stage fashion that exploits defenders’ slow reaction time; the authors aim to model this as a multi-stage zero-sum game and devise a DRL-based dynamic defense that ensures resiliency without changing the physical topology.",
      "potential_research_ideas": [
        "Extend to partially observable settings with belief/state uncertainty (POMDP) and opponent modeling of attacker strategies.",
        "Leverage graph neural networks for topology-aware policy learning over dynamic communication graphs.",
        "Incorporate safe RL or constrained RL to guarantee stability margins and respect operational constraints during exploration.",
        "Distributional/robust RL to handle worst-case attack distributions and parameter uncertainties.",
        "Meta-RL or continual RL for rapid adaptation to new attack vectors with minimal samples.",
        "Combine detection (e.g., change-point or residual-based) with control reconfiguration in a joint decision framework.",
        "Hardware-in-the-loop or real testbed validation to assess latency, noise, and actuator limitations.",
        "Formal verification or control-theoretic certificates integrated with RL policies for guaranteed resiliency."
      ],
      "architectural_improvement_recommendations": [
        "Upgrade DQN to Double/Dueling DQN with prioritized experience replay to stabilize learning and improve sample efficiency.",
        "Adopt actor-critic methods (e.g., PPO/SAC) for continuous action spaces and smoother control adjustments of adjacency weights.",
        "Use recurrent policies (LSTM/GRU) for memory of latent attacker behavior and delayed effects.",
        "Integrate model-based RL or MPC-in-the-loop for better sample efficiency and stability guarantees.",
        "Employ graph neural networks to encode the communication graph and enable scalable policy generalization across varying DG counts.",
        "Add uncertainty estimation (e.g., ensemble or Bayesian heads) to trigger conservative actions when confidence is low.",
        "Incorporate explicit safety layers/shields that enforce invariants derived from Lyapunov conditions during policy execution."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Microgrid secondary control communication network (simulated)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Models a rational attacker using latent multi-stage rootkit vectors that gradually reveal access levels and bypass static defenses.",
      "Formulates attacker–defender interaction as a multi-stage, non-cooperative, zero-sum game to select maximum-utility defenses.",
      "Proposes a DRL (deep Q-learning) dynamic defense that detects activation of new attack vectors from environment feedback and mitigates them by adaptively modifying secondary communication matrix elements.",
      "Achieves resiliency without altering the physical transmission/distribution topology, reducing potential instability issues.",
      "Provides simulation results and case studies demonstrating operating mechanism and robustness of the proposed strategy."
    ]
  },
  {
    "arxiv_id": "2306.09448v1",
    "title": "Prevention of cyberattacks in WSN and packet drop by CI framework and information processing protocol using AI and Big Data",
    "authors": "Shreyanth S",
    "abstract": "As the reliance on wireless sensor networks (WSNs) rises in numerous sectors, cyberattack prevention and data transmission integrity become essential problems. This study provides a complete framework to handle these difficulties by integrating a cognitive intelligence (CI) framework, an information processing protocol, and sophisticated artificial intelligence (AI) and big data analytics approaches. The CI architecture is intended to improve WSN security by dynamically reacting to an evolving threat scenario. It employs artificial intelligence algorithms to continuously monitor and analyze network behavior, identifying and mitigating any intrusions in real time. Anomaly detection algorithms are also included in the framework to identify packet drop instances caused by attacks or network congestion. To support the CI architecture, an information processing protocol focusing on efficient and secure data transfer within the WSN is introduced. To protect data integrity and prevent unwanted access, this protocol includes encryption and authentication techniques. Furthermore, it enhances the routing process with the use of AI and big data approaches, providing reliable and timely packet delivery. Extensive simulations and tests are carried out to assess the efficiency of the suggested framework. The findings show that it is capable of detecting and preventing several forms of assaults, including as denial-of-service (DoS) attacks, node compromise, and data tampering. Furthermore, the framework is highly resilient to packet drop occurrences, which improves the WSN's overall reliability and performance",
    "published_date": "2023-06-15",
    "pdf_link": "https://arxiv.org/pdf/2306.09448v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Wireless Sensor Networks (WSN)",
      "specific_problem": "Intrusion detection and prevention with secure, reliable data transmission and packet drop mitigation in WSNs",
      "attack_types": [
        "Denial-of-Service (DoS)",
        "Node compromise",
        "Data tampering"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Anomaly Detection",
        "specific": null,
        "novel_contribution": "Embedded within a Cognitive Intelligence (CI) framework to detect anomalous WSN behaviors linked to intrusions and packet drops in real time"
      },
      {
        "type": "primary",
        "category": "Classical ML",
        "specific": null,
        "novel_contribution": "Use of machine learning and pattern recognition models trained on historical WSN data to identify attack patterns"
      },
      {
        "type": "primary",
        "category": "Big Data Analytics",
        "specific": null,
        "novel_contribution": "Analytics over large WSN data volumes for threat pattern mining and proactive decision-making"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "WSN simulation data",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Design and implement a CI framework that continuously monitors and analyzes WSN behavior in real time to mitigate potential intrusions.",
        "Devise an information processing protocol that ensures secure and efficient data transmission within the WSN, optimizing routing and minimizing packet loss.",
        "Integrate AI and big data techniques to improve the overall security, dependability, and robustness of WSNs."
      ],
      "gaps_identified": [
        "Traditional security measures and routing protocols are insufficient for the constantly changing threat landscape and dynamic nature of WSNs.",
        "Packet drops may result from attacks or congestion and are not proactively handled by conventional approaches.",
        "Need for adaptive, real-time defense and secure, efficient routing in resource-constrained WSNs."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Rising reliance on WSNs across domains increases the need to prevent cyberattacks and ensure reliable, secure data transmission, especially given dynamic threats and packet drop risks.",
      "potential_research_ideas": [
        "Develop and open-source a standardized WSN cyberattack dataset with labeled events (DoS, sinkhole, selective forwarding, data tampering) for benchmarking CI-based IDS.",
        "Design lightweight, on-node anomaly detection using TinyML for energy-constrained sensors with collaborative edge aggregation.",
        "Incorporate graph-based models (e.g., GNNs) for joint topology-aware intrusion detection and secure routing decisions.",
        "Introduce online/continual learning to adapt IDS to evolving traffic patterns and concept drift in long-lived WSN deployments.",
        "Evaluate and harden the framework against adversarial ML (evasion/poisoning) tailored to WSN telemetry.",
        "Integrate federated learning for privacy-preserving cross-node model training without raw data sharing.",
        "Formalize metrics and conduct rigorous comparisons (PDR, latency, energy, detection precision/recall, false positive rate) across standard WSN attack scenarios.",
        "Design a trust and reputation layer to assist CI decisions for node isolation and route selection under compromised nodes."
      ],
      "architectural_improvement_recommendations": [
        "Specify concrete model classes (e.g., Isolation Forest/Autoencoders for anomaly detection; Random Forest/SVM for supervised detection) and feature sets from WSN telemetry.",
        "Adopt a hierarchical architecture: on-node lightweight detectors, cluster-head aggregators, and a sink-side CI controller for global analytics.",
        "Use reinforcement learning for adaptive routing under attack/congestion with constraints on energy and latency.",
        "Implement model compression/pruning/quantization (TinyML) for deployment on sensor-class MCUs.",
        "Add explainability modules (feature attribution, exemplar-based explanations) to aid operator trust and debugging.",
        "Introduce secure model update mechanisms with signed models and Byzantine-robust aggregation for distributed learning.",
        "Incorporate differential privacy or secure aggregation for privacy-preserving analytics beyond transport encryption.",
        "Define and evaluate explicit KPIs (PDR, throughput, E2E delay, energy per delivered packet, detection metrics) and scalability tests (node count, traffic load)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a Cognitive Intelligence (CI) framework for real-time monitoring, anomaly detection, and mitigation of cyberattacks in WSNs.",
      "Introduces an information processing protocol combining encryption/authentication with AI- and big data-assisted adaptive routing for secure and efficient data transfer.",
      "Integrates AI and big data analytics to identify complex attack patterns and enable proactive decision-making in WSNs.",
      "Reports simulation-based evaluation claiming detection and prevention of DoS, node compromise, and data tampering attacks and improved resilience to packet drop events."
    ]
  },
  {
    "arxiv_id": "2306.17002v1",
    "title": "VibHead: An Authentication Scheme for Smart Headsets through Vibration",
    "authors": "Feng Li; Jiayi Zhao; Huan Yang; Dongxiao Yu; Yuanfeng Zhou; Yiran Shen",
    "abstract": "Recent years have witnessed the fast penetration of Virtual Reality (VR) and Augmented Reality (AR) systems into our daily life, the security and privacy issues of the VR/AR applications have been attracting considerable attention. Most VR/AR systems adopt head-mounted devices (i.e., smart headsets) to interact with users and the devices usually store the users' private data. Hence, authentication schemes are desired for the head-mounted devices. Traditional knowledge-based authentication schemes for general personal devices have been proved vulnerable to shoulder-surfing attacks, especially considering the headsets may block the sight of the users. Although the robustness of the knowledge-based authentication can be improved by designing complicated secret codes in virtual space, this approach induces a compromise of usability. Another choice is to leverage the users' biometrics; however, it either relies on highly advanced equipments which may not always be available in commercial headsets or introduce heavy cognitive load to users.   In this paper, we propose a vibration-based authentication scheme, VibHead, for smart headsets. Since the propagation of vibration signals through human heads presents unique patterns for different individuals, VibHead employs a CNN-based model to classify registered legitimate users based the features extracted from the vibration signals. We also design a two-step authentication scheme where the above user classifiers are utilized to distinguish the legitimate user from illegitimate ones. We implement VibHead on a Microsoft HoloLens equipped with a linear motor and an IMU sensor which are commonly used in off-the-shelf personal smart devices. According to the results of our extensive experiments, with short vibration signals ($\\leq 1s$), VibHead has an outstanding authentication accuracy; both FAR and FRR are around 5%.",
    "published_date": "2023-06-29",
    "pdf_link": "https://arxiv.org/pdf/2306.17002v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Authentication and Access Control",
      "subdomain": "Biometric Authentication",
      "specific_problem": "Vibration-based user authentication for smart VR/AR headsets using head-transmitted vibrations",
      "attack_types": [
        "impersonation",
        "shoulder-surfing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Custom dual-encoder CNN operating on raw IMU signals and MFCC features",
        "novel_contribution": "Two-branch CNN encoders (shared architecture with different weights) fuse primitive accelerometer readings and MFCC features from head-transmitted vibrations for per-user classification; used within a two-step authentication scheme."
      },
      {
        "type": "baseline",
        "category": "Feature Engineering",
        "specific": "MFCC",
        "novel_contribution": "MFCC used as an additional feature stream for vibration signal characterization and fused with raw IMU features."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Vibration signals collected on Microsoft HoloLens with linear motor and ADXL375 IMU across five gestures",
        "type": "private",
        "domain": "sensor_time_series",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "FAR",
      "FRR"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Are head-transmitted vibration responses unique enough across individuals to enable reliable user authentication on smart headsets?",
        "How to design a classifier and authentication protocol that remains accurate across typical user gestures (standing, sitting upright, leaning forward/backward, walking)?",
        "What signal features (raw IMU vs. MFCC) and model architecture best capture discriminative patterns in head vibration propagation?"
      ],
      "gaps_identified": [
        "Knowledge-based authentication in VR/AR is vulnerable to shoulder-surfing and hurts usability with complex virtual passwords.",
        "Gaze/eye-tracking biometrics often require specialized hardware not always available on commercial headsets or impose heavy cognitive load.",
        "Prior vibration-based authentication systems focus on hand-held/hand-made devices (phones, watches, surfaces); designing vibration-based authentication for smart headsets remains open."
      ],
      "limitations": [
        "Current commercial headsets typically lack built-in vibration motors and IMU access is often closed; the prototype uses add-on hardware. Quote: “current smart headset products available in market have no build-in motors and the interface to IMU sensors is usually closed.”",
        "Evaluation focuses on five typical authentication gestures; broader activity coverage and environmental factors are not explored in the provided text.",
        "Threat model assumes attackers cannot tamper with software/data and cannot attack during registration."
      ],
      "future_work": [],
      "motivation": "VR/AR headsets store sensitive personal data; traditional knowledge-based authentication is vulnerable to shoulder-surfing and can be unusable in VR/AR; gaze/gesture biometrics either need advanced equipment or are burdensome; vibration through the head may encode unique patterns usable for authentication.",
      "potential_research_ideas": [
        "Design active excitation signals beyond a single 300 Hz tone (e.g., multi-tone or chirp sweeps) and learn optimal probing waveforms to maximize discriminability and robustness.",
        "Open-set and one-/few-shot user authentication to support enrolling new users with minimal samples and rejecting unknowns.",
        "Domain adaptation and calibration-free methods to handle headset repositioning, different devices, and session variability.",
        "Continuous or opportunistic re-authentication during normal headset use using passive or low-amplitude vibrations.",
        "Robustness studies against sophisticated spoofing (e.g., mechanical couplers, 3D-printed headforms, replay via bone-conduction) and countermeasures.",
        "Privacy-preserving learning (federated/distillation) to avoid uploading raw vibration traces.",
        "Fairness analysis across demographics (head size, hair, facial structure) and ergonomic conditions (tightness, padding)."
      ],
      "architectural_improvement_recommendations": [
        "Introduce attention-based fusion at multiple stages to weight informative time-frequency regions across the raw and MFCC branches.",
        "Evaluate temporal models (TCN/1D CNN with dilations, BiLSTM, or small Transformers) to capture longer context within ≤1 s windows.",
        "Adopt metric learning (triplet/contrastive losses) to improve inter-user separation and support open-set rejection via distance thresholds.",
        "Use data augmentation in the frequency and time domains (SpecAugment-like masks, jitter, amplitude scaling) to improve robustness to pose/fit variations.",
        "Calibrate a user-specific thresholding scheme with score normalization and calibration (e.g., Platt scaling) for the two-step authenticator.",
        "Learned excitation: co-optimize the probe waveform with the classifier via differentiable or black-box optimization subject to comfort/power constraints.",
        "Model compression/distillation and quantization-aware training for on-device inference."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Smart headset (Microsoft HoloLens) with add-on linear motor and IMU (ADXL375)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Lack of built-in vibration actuators and limited IMU access on current headsets; requires hardware integration.",
        "Fit/placement variability across users and sessions can change vibration paths.",
        "User comfort and safety of active vibration, power consumption of motor.",
        "Environmental and motion noise (e.g., walking) affecting IMU readings.",
        "Operational constraints around registration procedure and guided gestures."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes VibHead, a vibration-based authentication scheme for smart headsets using a linear motor and IMU sensors.",
      "Demonstrates that “the propagation of vibration signals through human heads presents unique patterns for different individuals.”",
      "Designs a CNN-based dual-encoder classifier that fuses primitive accelerometer readings with MFCC features.",
      "Introduces a two-step authentication scheme built on user-specific classifiers to distinguish legitimate from illegitimate users.",
      "Implements a prototype on Microsoft HoloLens with commonly available components (linear motor and IMU).",
      "Reports strong performance with short vibrations: “with short vibration signals (≤1s), VibHead has an outstanding authentication accuracy; both FAR and FRR are around 5%.”"
    ]
  },
  {
    "arxiv_id": "2306.08495v3",
    "title": "Single-board Device Individual Authentication based on Hardware Performance and Autoencoder Transformer Models",
    "authors": "Pedro Miguel Sánchez Sánchez; Alberto Huertas Celdrán; Gérôme Bovet; Gregorio Martínez Pérez",
    "abstract": "The proliferation of the Internet of Things (IoT) has led to the emergence of crowdsensing applications, where a multitude of interconnected devices collaboratively collect and analyze data. Ensuring the authenticity and integrity of the data collected by these devices is crucial for reliable decision-making and maintaining trust in the system. Traditional authentication methods are often vulnerable to attacks or can be easily duplicated, posing challenges to securing crowdsensing applications. Besides, current solutions leveraging device behavior are mostly focused on device identification, which is a simpler task than authentication. To address these issues, an individual IoT device authentication framework based on hardware behavior fingerprinting and Transformer autoencoders is proposed in this work. This solution leverages the inherent imperfections and variations in IoT device hardware to differentiate between devices with identical specifications. By monitoring and analyzing the behavior of key hardware components, such as the CPU, GPU, RAM, and Storage on devices, unique fingerprints for each device are created. The performance samples are considered as time series data and used to train outlier detection transformer models, one per device and aiming to model its normal data distribution. Then, the framework is validated within a spectrum crowdsensing system leveraging Raspberry Pi devices. After a pool of experiments, the model from each device is able to individually authenticate it between the 45 devices employed for validation. An average True Positive Rate (TPR) of 0.74+-0.13 and an average maximum False Positive Rate (FPR) of 0.06+-0.09 demonstrate the effectiveness of this approach in enhancing authentication, security, and trust in crowdsensing applications.",
    "published_date": "2023-06-14",
    "pdf_link": "https://arxiv.org/pdf/2306.08495v3",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Device Authentication",
      "specific_problem": "Individual authentication of single-board IoT devices using hardware performance fingerprinting with Transformer autoencoders (one-class anomaly detection)",
      "attack_types": [
        "Device impersonation",
        "Sybil",
        "Replay",
        "Physical tampering",
        "Advanced Persistent Threat (APT)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Transformer Autoencoder",
        "novel_contribution": "One autoencoder Transformer per device trained on legitimate performance time series for outlier detection-based authentication"
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "1D-CNN",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "One-class (anomaly detection)"
    ],
    "datasets": [
      {
        "name": "ElectroSense Raspberry Pi hardware performance dataset (45 devices)",
        "type": "proprietary",
        "domain": "device_hardware_performance",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "LSTM",
        "paper_reference": null,
        "metric": "TPR, FPR",
        "their_result": "Average TPR 0.74 ± 0.13; average maximum FPR 0.06 ± 0.09",
        "baseline_result": null
      },
      {
        "method_name": "1D-CNN",
        "paper_reference": null,
        "metric": "TPR, FPR",
        "their_result": "Average TPR 0.74 ± 0.13; average maximum FPR 0.06 ± 0.09",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "True Positive Rate (TPR)",
      "False Positive Rate (FPR)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can inherent hardware performance variations in identical single-board devices be used for individual device authentication via time-series anomaly detection?",
        "Do Transformer-based autoencoders outperform common deep learning baselines for this authentication task in a real-world crowdsensing deployment?"
      ],
      "gaps_identified": [
        "Most prior work targets device identification rather than authentication (verification) using anomaly detection.",
        "Transformer-based methods had not been applied to hardware-based individual authentication.",
        "Many existing solutions are evaluated in simulated/isolated environments rather than real-world deployments.",
        "Classification-based approaches are ill-suited for dynamic scenarios or large numbers of devices for authentication."
      ],
      "limitations": [
        "Assumes the legitimate administrator retains control of devices so that authentication tasks can be executed.",
        "Requires component isolation and stable operating conditions (fixed frequencies, disabled optimizations) to capture fine-grained hardware performance variations.",
        "One-model-per-device approach can imply management and training overhead as the number of devices scales.",
        "Reported average TPR of 0.74 suggests room for improvement in sensitivity on some devices; FPR variance (0.06 ± 0.09) indicates device-specific variability."
      ],
      "future_work": [
        "Adapting the solution to new device models with different hardware components.",
        "Further optimization and broader deployment in real-world applications (as suggested by the validation and discussion)."
      ],
      "motivation": "Improve trust in crowdsensing systems by authenticating individual IoT devices using tamper-resistant hardware performance fingerprints, addressing vulnerabilities of traditional software-based authentication.",
      "potential_research_ideas": [
        "Adversarially robust authentication: evaluate and harden against spoofing/evasion where attackers attempt to mimic hardware performance traces.",
        "Continual/online learning to adapt per-device models over time without catastrophic forgetting.",
        "Federated or on-device incremental learning to reduce server dependence and preserve privacy.",
        "Multi-modal fingerprints combining performance metrics with power consumption, clock skew, or thermal behavior.",
        "Cross-device meta-learning to accelerate onboarding of new device models with few normal samples.",
        "Uncertainty-aware authentication with Bayesian or ensemble Transformers for calibrated thresholds and risk scoring.",
        "Domain adaptation to handle firmware updates, environmental changes, or hardware aging effects."
      ],
      "architectural_improvement_recommendations": [
        "Use a hybrid architecture combining Transformer encoder with temporal convolution blocks to capture multi-scale patterns.",
        "Contrastive/self-supervised pretraining across devices to learn robust representations before per-device fine-tuning.",
        "Latent-space density estimation (e.g., normalizing flows) or one-class objectives (Deep SVDD) on the Transformer embeddings.",
        "Ensemble multiple component-specific models (CPU/GPU/RAM/Storage) with attention-based late fusion.",
        "Incorporate graph structure among hardware components (Graph Transformer) to model inter-component dependencies.",
        "Calibrate anomaly thresholds per device via extreme value theory or quantile-based calibration."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Spectrum crowdsensing platform (ElectroSense) with Raspberry Pi devices; client-server architecture (data collection on device, training/evaluation on server)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Need to configure fixed component frequencies and disable optimizations (e.g., address randomization) to ensure stability.",
        "Component isolation to avoid kernel interruptions during measurements.",
        "Per-device model training and management overhead as device fleet grows.",
        "Heterogeneity across Raspberry Pi models and potential environmental variability."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A framework leveraging Transformer-based autoencoder models and hardware performance fingerprinting for individual authentication of single-board devices.",
      "Threat model detailing security problems in hardware-based authentication for IoT (impersonation, Sybil, replay, physical attacks, APT).",
      "Deployment and validation in the ElectroSense crowdsensing platform using 45 Raspberry Pi devices (Pi 4, Pi 3, Pi 1, Pi Zero).",
      "Demonstrated average TPR of 0.74 ± 0.13 and average maximum FPR of 0.06 ± 0.09; improves over LSTM and 1D-CNN baselines.",
      "Discussion on adapting the solution to new device models with different hardware components.",
      "Validation code made available (citation [35])."
    ]
  },
  {
    "arxiv_id": "2306.09057v1",
    "title": "A Learning Assisted Method for Uncovering Power Grid Generation and Distribution System Vulnerabilities",
    "authors": "Suman Maiti; Anjana B; Sunandan Adhikary; Ipsita Koley; Soumyajit Dey",
    "abstract": "Intelligent attackers can suitably tamper sensor/actuator data at various Smart grid surfaces causing intentional power oscillations, which if left undetected, can lead to voltage disruptions. We develop a novel combination of formal methods and machine learning tools that learns power system dynamics with the objective of generating unsafe yet stealthy false data based attack sequences. We enable the grid with anomaly detectors in a generalized manner so that it is difficult for an attacker to remain undetected. Our methodology, when applied on an IEEE 14 bus power grid model, uncovers stealthy attack vectors even in presence of such detectors.",
    "published_date": "2023-06-15",
    "pdf_link": "https://arxiv.org/pdf/2306.09057v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cyber-Physical Systems Security",
      "subdomain": "Power Grid / Smart Grid Security",
      "specific_problem": "Synthesis of stealthy false data injection and load alteration attacks against AGC-equipped power grids under norm-based anomaly detectors",
      "attack_types": [
        "False Data Injection (FDIA)",
        "Load Alteration Attack (LAA)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning (Actor-Critic)",
        "specific": "Deep Deterministic Policy Gradient (DDPG)",
        "novel_contribution": "Learns load alteration attack sequences that prolong transient behavior while maintaining detector stealth, providing probabilistic LAA seeds for the formal falsification stage"
      },
      {
        "type": "primary",
        "category": "Falsification / Stochastic Optimization",
        "specific": "S-TaLiRo",
        "novel_contribution": "Searches FDIA sequences that, when combined with learned LAA, are formally guaranteed to violate safety while remaining stealthy until violation"
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Optimization-based falsification",
      "Formal methods"
    ],
    "datasets": [
      {
        "name": "IEEE 14-bus power grid model (Simulink)",
        "type": "public",
        "domain": "power_grid_simulation",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Real-time Hardware-in-the-Loop (HIL) setup runs",
        "type": "proprietary",
        "domain": "power_grid_simulation",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "LAA only (no FDIA)",
        "paper_reference": null,
        "metric": "Detector stealth and unsafe duration (frequency outside 60±0.5 Hz band)",
        "their_result": "Combined LAA+FDIA: \"significant and fast change in frequency ... without the residue crossing the threshold\"",
        "baseline_result": "\"for an optimal LAA sequence, the frequency ... deviated from its safety range (60±0.5) for a small fraction of time. The attack remained stealthy ... for a period of more than 1 second\""
      },
      {
        "method_name": "FDIA only (no LAA)",
        "paper_reference": null,
        "metric": "Detection time and unsafe duration",
        "their_result": "Combined LAA+FDIA remained below threshold while driving frequency significantly outside safety",
        "baseline_result": "\"the FDIA got detected at 0.3 second ... while the frequency ... deviated significantly ... but only for a small fraction of time\""
      }
    ],
    "performance_metrics_used": [
      "Infinity-norm of Kalman filter residue (||r||_∞) vs threshold",
      "Frequency deviation outside safety band (60 ± 0.5 Hz)",
      "Detection time (time to threshold crossing)",
      "Formal falsification of safety (violation of STL/specification via S-TaLiRo)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to synthesize combined LAA and FDIA sequences that push grid outputs beyond safety while the anomaly detector is not triggered?",
        "Can a two-phase approach (RL for LAA + formal falsification for FDIA) uncover stealthy multivariate attack vectors against AGC-equipped grids with generalized norm-based detectors?"
      ],
      "gaps_identified": [
        "Prominent detection methods ignore transient vulnerabilities or are model-specific",
        "Learning-based/data-driven attack strategies do not guarantee stealth or success",
        "Prior synthesis approaches often scale only to a single variable/attack surface",
        "Some prior works emphasize coordination over synthesis and success guarantees"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Uncover lethal and stealthy multivariate attacks against smart grids by considering transient dynamics and generalized norm-based detectors, providing a CAD flow for vulnerability analysis.",
      "potential_research_ideas": [
        "Defender-side design: Develop detection schemes robust to joint LAA+FDIA that monitor transient dynamics (e.g., dynamic thresholds, multi-sensor cross-checks, active watermarking).",
        "Scale and stress-test: Evaluate on larger benchmarks (IEEE 57/118-bus) and diverse operating conditions to study scalability and generalization.",
        "Partial knowledge and constraints: Constrain the attacker with limited topology/measurement access and attack budgets to assess practicality and derive robust strategies.",
        "Surrogate-assisted falsification: Train neural surrogate models (e.g., neural ODEs) to accelerate the falsification search for FDIA.",
        "Multi-agent attack synthesis: Use multi-agent RL to coordinate multiple circuit breakers and sensor channels with communication constraints.",
        "End-to-end differentiable search: Incorporate smooth robustness measures to enable gradient-based FDIA search jointly with RL for faster convergence.",
        "Transfer and online adaptation: Study transferability of learned LAA policies across grid configurations and online adaptation under changing loads."
      ],
      "architectural_improvement_recommendations": [
        "Replace vanilla DDPG with constrained/safe RL (e.g., Lagrangian SAC/PPO) to encode stealthiness as a hard constraint during LAA training.",
        "Adopt model-based RL or differentiable simulation (where feasible) to reduce sample complexity and improve policy quality.",
        "Hybrid search: Seed S-TaLiRo with RL-learned priors and use parallelizable optimizers (CMA-ES/CEM/Bayesian optimization) to broaden FDIA exploration.",
        "Hierarchical co-optimization: Train a high-level RL coordinator to schedule LAA episodes while a lower-level falsifier searches FDIA, sharing a common stealth/violation objective.",
        "Use surrogate robustness predictors to guide S-TaLiRo sampling toward promising regions (active learning)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Simulink",
        "S-TaLiRo"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Real-time hardware-in-loop (HIL) setup",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Two-phase attack synthesis framework combining RL-learned LAA with formal falsification-based FDIA search",
      "Generalized norm-based anomaly detection modeling and attacker design that targets multiple attack surfaces",
      "Application and visualization on an IEEE 14-bus model with real-time HIL implementation demonstrating stealthy attack vectors",
      "Partitioning synthesis between probabilistic learning and stochastic formal engine to uncover multivariate stealthy attacks in a scalable way"
    ]
  },
  {
    "arxiv_id": "2306.09451v1",
    "title": "Host-Based Network Intrusion Detection via Feature Flattening and Two-stage Collaborative Classifier",
    "authors": "Zhiyan Chen; Murat Simsek; Burak Kantarci; Mehran Bagheri; Petar Djukic",
    "abstract": "Network Intrusion Detection Systems (NIDS) have been extensively investigated by monitoring real network traffic and analyzing suspicious activities. However, there are limitations in detecting specific types of attacks with NIDS, such as Advanced Persistent Threats (APT). Additionally, NIDS is restricted in observing complete traffic information due to encrypted traffic or a lack of authority. To address these limitations, a Host-based Intrusion Detection system (HIDS) evaluates resources in the host, including logs, files, and folders, to identify APT attacks that routinely inject malicious files into victimized nodes. In this study, a hybrid network intrusion detection system that combines NIDS and HIDS is proposed to improve intrusion detection performance. The feature flattening technique is applied to flatten two-dimensional host-based features into one-dimensional vectors, which can be directly used by traditional Machine Learning (ML) models. A two-stage collaborative classifier is introduced that deploys two levels of ML algorithms to identify network intrusions. In the first stage, a binary classifier is used to detect benign samples. All detected attack types undergo a multi-class classifier to reduce the complexity of the original problem and improve the overall detection performance. The proposed method is shown to generalize across two well-known datasets, CICIDS 2018 and NDSec-1. Performance of XGBoost, which represents conventional ML, is evaluated. Combining host and network features enhances attack detection performance (macro average F1 score) by 8.1% under the CICIDS 2018 dataset and 3.7% under the NDSec-1 dataset. Meanwhile, the two-stage collaborative classifier improves detection performance for most single classes, especially for DoS-LOIC-UDP and DoS-SlowHTTPTest, with improvements of 30.7% and 84.3%, respectively, when compared with the traditional ML XGBoost.",
    "published_date": "2023-06-15",
    "pdf_link": "https://arxiv.org/pdf/2306.09451v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Hybrid host- and network-based intrusion detection using feature flattening and a two-stage (binary-then-multiclass) collaborative classifier",
      "attack_types": [
        "DDoS (HOIC, LOIC-HTTP, LOIC-UDP)",
        "DoS (GoldenEye, Hulk, SlowHTTPTest, Slowloris)",
        "Botnet",
        "Brute Force (FTP, SSH, Web/XSS)",
        "Probe",
        "Web Attack",
        "Exploit",
        "Malware",
        "Infiltration",
        "SQL Injection",
        "APT (motivation for host-based analysis)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Meta-classifier/Hierarchical",
        "specific": "Two-stage collaborative classifier (Stage-1: binary; Stage-2: multiclass)",
        "novel_contribution": "Reduces complexity by filtering benign traffic first, then classifying attacks; shown to improve macro-F1 and per-class F1 over traditional single-stage ML"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT (pretrained) for text embedding of host logs/messages",
        "novel_contribution": "Transforms host-based textual logs (events/messages) into numeric matrices enabling ML; then flattened to integrate with network features"
      },
      {
        "type": "primary",
        "category": "Feature Engineering/Preprocessing",
        "specific": "Feature flattening",
        "novel_contribution": "Maps 2D host feature matrices (event, message) into 1D vectors to be consumed by traditional ML models jointly with network flow features"
      },
      {
        "type": "baseline",
        "category": "Boosting",
        "specific": "XGBoost",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CICIDS 2018",
        "type": "public",
        "domain": "network_traffic_and_host_logs",
        "link": "https://www.unb.ca/cic/datasets/ids-2018.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NDSec-1",
        "type": "public",
        "domain": "network_traffic_and_host_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Network-only features (NIDS) vs. Hybrid (NIDS+HIDS)",
        "paper_reference": null,
        "metric": "Macro average F1",
        "their_result": "CICIDS2018: 0.9993 (macro F1) with hybrid features; NDSec-1: 0.8913 (macro F1) with hybrid",
        "baseline_result": "CICIDS2018: 0.9246 (macro F1) with network-only; NDSec-1: 0.8595 (macro F1) with network-only"
      },
      {
        "method_name": "Traditional ML (single-stage XGBoost) vs. Two-stage collaborative classifier",
        "paper_reference": null,
        "metric": "Per-class F1",
        "their_result": "Improvements of 30.7% (DoS-LOIC-UDP) and 84.3% (DoS-SlowHTTPTest) reported for two-stage classifier",
        "baseline_result": "Traditional ML XGBoost per-class F1 lower by 30.7% and 84.3% respectively (exact baseline F1 values not fully provided)"
      }
    ],
    "performance_metrics_used": [
      "F1 score (macro average)",
      "F1 score (per-class)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does combining host and network features (HIDS+NIDS) improve intrusion detection performance compared to network-only features?",
        "Can feature flattening of 2D host log embeddings enable effective use of traditional ML models?",
        "Can a two-stage collaborative (binary-then-multiclass) classifier reduce complexity and improve detection, especially per-class F1 for difficult attacks?"
      ],
      "gaps_identified": [
        "Few public datasets include host information; most IDS research relies only on network traffic features.",
        "Limited ML-based frameworks that integrate both HIDS and NIDS.",
        "NIDS is limited by encrypted traffic and struggles with APT-style attacks that manifest in host artifacts."
      ],
      "limitations": [
        "Rare classes in CICIDS2018 (BruteForce-Web, BruteForce-XSS, Infiltration, SQL Injection) were removed due to very few samples (<50).",
        "Evaluation limited to two public datasets; no real-time or operational deployment results.",
        "Comparison focuses on traditional ML (XGBoost); deep learning architectures were not evaluated in this work.",
        "HIDS components increase costs and require collection/management of massive and sensitive host data (general limitation of HIDS)."
      ],
      "future_work": [
        "Apply deep learning models to the hybrid HIDS+NIDS framework.",
        "Extend evaluation and testing in real-time or operational environments."
      ],
      "motivation": "Address NIDS limitations in encrypted traffic and APT detection by incorporating host-based logs; provide an ML-amenable pipeline via feature flattening and a two-stage classifier to improve accuracy and reduce complexity.",
      "potential_research_ideas": [
        "Design an end-to-end multimodal deep model that jointly encodes network flows and host logs (e.g., late fusion of flow encoders and log transformers) instead of flattening.",
        "Self-supervised pretraining on large unlabeled host logs and network flows (contrastive/cross-modal) to improve generalization.",
        "Online and incremental learning to handle evolving attacks and class imbalance while maintaining low false alarms in the first-stage binary filter.",
        "Federated or privacy-preserving training for host-log modeling across multiple organizations.",
        "Graph-based modeling of hosts, processes, and network connections to capture lateral movement/APTs.",
        "Temporal/sequential modeling of host events/messages (e.g., transformer/TCN) to exploit ordering rather than flattened features.",
        "Robustness testing and defenses against adversarial manipulation of logs and flow features.",
        "Explainability for hybrid IDS decisions to aid analysts and reduce alert fatigue."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment feature flattening with sequence models on host events/messages (fine-tune BERT or use LONG-sequence transformers) and fuse with flow features via attention.",
        "Use calibrated gating or confidence-based routing between Stage-1 and Stage-2 to control false negatives/positives; employ cost-sensitive or focal losses for imbalance.",
        "Introduce dimensionality reduction/feature selection (e.g., PCA, mutual information, tree-based selection) to shrink very large host feature spaces (e.g., 76,800 and 393,216 dims).",
        "Evaluate alternative classifiers beyond XGBoost in each stage (e.g., LightGBM, CatBoost, calibrated SVM, shallow neural nets) and ensembles.",
        "Add drift detection and periodic recalibration of the Stage-1 threshold to maintain performance as traffic patterns change.",
        "Integrate explanation methods (e.g., SHAP) for both stages and for feature groups (flow vs. host) to provide insights to operators."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Need to deploy and manage HIDS components on host devices, with connectivity to central analysis.",
        "Collection and management of massive and sensitive host data.",
        "Encrypted network traffic limits NIDS visibility; requires reliance on host data.",
        "Imbalanced datasets (large benign majority) increase training complexity and risk of false alarms."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Integration of network flow and host log features for ML-based intrusion detection using public datasets.",
      "Feature flattening of 2D host features into 1D vectors to enable traditional ML usage.",
      "Two-stage collaborative classifier (binary then multiclass) to reduce complexity and improve detection performance.",
      "Demonstrated generalization across CICIDS2018 and NDSec-1 with improved macro F1 and significant per-class gains over traditional ML XGBoost."
    ]
  },
  {
    "arxiv_id": "2306.17193v2",
    "title": "Uncovering the Limits of Machine Learning for Automatic Vulnerability Detection",
    "authors": "Niklas Risse; Marcel Böhme",
    "abstract": "Recent results of machine learning for automatic vulnerability detection (ML4VD) have been very promising. Given only the source code of a function $f$, ML4VD techniques can decide if $f$ contains a security flaw with up to 70% accuracy. However, as evident in our own experiments, the same top-performing models are unable to distinguish between functions that contain a vulnerability and functions where the vulnerability is patched. So, how can we explain this contradiction and how can we improve the way we evaluate ML4VD techniques to get a better picture of their actual capabilities?   In this paper, we identify overfitting to unrelated features and out-of-distribution generalization as two problems, which are not captured by the traditional approach of evaluating ML4VD techniques. As a remedy, we propose a novel benchmarking methodology to help researchers better evaluate the true capabilities and limits of ML4VD techniques. Specifically, we propose (i) to augment the training and validation dataset according to our cross-validation algorithm, where a semantic preserving transformation is applied during the augmentation of either the training set or the testing set, and (ii) to augment the testing set with code snippets where the vulnerabilities are patched.   Using six ML4VD techniques and two datasets, we find (a) that state-of-the-art models severely overfit to unrelated features for predicting the vulnerabilities in the testing data, (b) that the performance gained by data augmentation does not generalize beyond the specific augmentations applied during training, and (c) that state-of-the-art ML4VD techniques are unable to distinguish vulnerable functions from their patches.",
    "published_date": "2023-06-28",
    "pdf_link": "https://arxiv.org/pdf/2306.17193v2",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_dataset"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection",
      "specific_problem": "Evaluating robustness and generalization of ML-based source-code vulnerability detectors; distinguishing vulnerable functions from their patched counterparts",
      "attack_types": [
        "software vulnerabilities (general)",
        "integer overflow (example)"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Transformer (token-based LLMs)",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CodeXGLUE/Devign vulnerability detection dataset",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VulnPatchPairs (VPP)",
        "type": "public",
        "domain": "source_code",
        "link": "https://github.com/niklasrisse/VPP",
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "\"So, how can we explain this contradiction and how can we improve the way we evaluate ML4VD techniques to get a better picture of their actual capabilities?\"",
        "Do ML4VD techniques overfit to unrelated (label-unrelated) features introduced by semantic-preserving code transformations?",
        "Does performance gained via data augmentation generalize beyond the specific transformations applied during training?",
        "Are ML4VD techniques able to distinguish vulnerable functions from their patched counterparts (i.e., generalize to a modified detection setting)?"
      ],
      "gaps_identified": [
        "\"we identify overfitting to unrelated features and out-of-distribution generalization as two problems, which are not captured by the traditional approach of evaluating ML4VD techniques.\"",
        "\"state-of-the-art models severely overfit to unrelated features for predicting the vulnerabilities in the testing data\"",
        "\"the performance gained by data augmentation does not generalize beyond the specific augmentations applied during training\"",
        "\"state-of-the-art ML4VD techniques are unable to distinguish vulnerable functions from their patches\""
      ],
      "limitations": [
        "All evaluated techniques \"happen to be token-based large language models (LLMs)\" (limited model family).",
        "Empirical evaluation uses two popular vulnerability detection datasets for Algorithm 1 (exact names unspecified in provided text).",
        "VulnPatchPairs is derived from CodeXGLUE/Devign and limited to C functions.",
        "Results are based on 11 implemented semantic-preserving transformations; other transformations not studied."
      ],
      "future_work": [
        "Use the proposed Algorithms 1 and 2 as a general methodology to evaluate additional ML4VD techniques (models, datasets, languages)."
      ],
      "motivation": "High benchmark scores for ML4VD (up to ~70% accuracy) contrast with failures such as inability to distinguish vulnerable from patched functions; need improved evaluation to reveal true capabilities and limits.",
      "potential_research_ideas": [
        "Design invariance-driven training that enforces prediction consistency across a diverse family of semantic-preserving transformations (e.g., group-invariant or causality-inspired objectives).",
        "Leverage vulnerability–patch pairs for contrastive learning to learn representations aligned with label-inverting changes while being invariant to label-unrelated changes.",
        "Incorporate program-analysis-informed intermediate representations (e.g., SSA/IR, AST/CFG/CDG) to reduce reliance on superficial lexical features.",
        "Develop augmentation generators covering orthogonal transformation families (identifier, control-flow neutral insertions, constant folding, reordering) and use adversarial training against them.",
        "Introduce patch-diff-aware architectures that explicitly model code changes (e.g., dual-encoder or Siamese networks) to classify vulnerable vs. patched.",
        "Apply OOD detection/calibration to flag low-confidence predictions under unseen transformations or patch-like changes.",
        "Use test-time augmentation over multiple semantic-preserving transforms and aggregate predictions to improve robustness.",
        "Benchmark cross-project and cross-language generalization with the proposed methodology and additional datasets."
      ],
      "architectural_improvement_recommendations": [
        "Add a transformation-consistency loss (e.g., KL consistency or contrastive invariance) across multiple semantic-preserving transforms during training.",
        "Adopt hybrid models combining token LLMs with structured program graphs (AST/CFG) and data-flow features to mitigate overreliance on identifiers/comments.",
        "Introduce a dual-branch patch-diff encoder (context branch + change branch) with contrastive supervision using vulnerability–patch pairs.",
        "Use curriculum/adversarial augmentation: progressively harder, diverse transformations with adversarial selection to minimize augmentation-specific overfitting.",
        "Employ causal representation learning to mask or randomize superficial features (identifiers, formatting) and regularize towards invariant causal features.",
        "Implement uncertainty estimation and OOD detectors (e.g., energy-based or ensemble methods) to abstain on transformed/unseen distributions."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/niklasrisse/USENIX_2024",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Models may rely on label-unrelated features and are brittle to semantic-preserving code changes.",
        "Performance gains from augmentation may not transfer to unseen transformations (augmentation-specific overfitting).",
        "Inability to distinguish vulnerable from patched code undermines practical usefulness in remediation workflows.",
        "Poor OOD generalization can lead to unreliable results on real-world code bases."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes two benchmarking algorithms: Algorithm 1 (detecting overfitting to code changes) and Algorithm 2 (distinguishing vulnerabilities vs. patches).",
      "Implements 11 semantic-preserving transformations and evaluates six state-of-the-art ML4VD techniques on two vulnerability detection datasets.",
      "Introduces a new dataset, VulnPatchPairs (26.2k C functions; 50% vulnerable, 50% patched), publicly available at https://github.com/niklasrisse/VPP.",
      "Empirically demonstrates: (a) severe overfitting to unrelated features; (b) augmentation gains do not generalize to different transforms; (c) inability to distinguish vulnerable from patched functions (accuracy worse than random on average).",
      "Releases all code and results for reproducibility: https://github.com/niklasrisse/USENIX_2024.",
      "Reports quantitative effects: \"69.0% and 66.2% average restoration of accuracy/f1-score\" when training and testing augmentations match; and additional \"30.2% and 77.5% average decrease\" when they differ; and that models on VPP perform \"worse than random guessing.\""
    ]
  },
  {
    "arxiv_id": "2306.10420v1",
    "title": "Federated Learning Based Distributed Localization of False Data Injection Attacks on Smart Grids",
    "authors": "Cihat Keçeci; Katherine R. Davis; Erchin Serpedin",
    "abstract": "Data analysis and monitoring on smart grids are jeopardized by attacks on cyber-physical systems. False data injection attack (FDIA) is one of the classes of those attacks that target the smart measurement devices by injecting malicious data. The employment of machine learning techniques in the detection and localization of FDIA is proven to provide effective results. Training of such models requires centralized processing of sensitive user data that may not be plausible in a practical scenario. By employing federated learning for the detection of FDIA attacks, it is possible to train a model for the detection and localization of the attacks while preserving the privacy of sensitive user data. However, federated learning introduces new problems such as the personalization of the detectors in each node. In this paper, we propose a federated learning-based scheme combined with a hybrid deep neural network architecture that exploits the local correlations between the connected power buses by employing graph neural networks as well as the temporal patterns in the data by using LSTM layers. The proposed mechanism offers flexible and efficient training of an FDIA detector in a distributed setup while preserving the privacy of the clients. We validate the proposed architecture by extensive simulations on the IEEE 57, 118, and 300 bus systems and real electricity load data.",
    "published_date": "2023-06-17",
    "pdf_link": "https://arxiv.org/pdf/2306.10420v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Smart Grid Security",
      "subdomain": "Intrusion Detection in Cyber-Physical Power Systems",
      "specific_problem": "Distributed detection and localization of False Data Injection Attacks (FDIA) on smart grids with privacy preservation via federated learning",
      "attack_types": [
        "False Data Injection (FDIA)",
        "Random attack (uniform/Gaussian perturbation)",
        "Replay attack",
        "Scale attack"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Graph Convolutional Network (GCN)",
        "novel_contribution": "Used as graph-level layers trained with a FedGraph aggregation scheme to capture local spatial correlations across buses in a federated setting"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Stacked LSTM",
        "novel_contribution": "Used as shared feature extractors to capture temporal patterns; trained federatedly (FedAvg/FedOpt-style) across heterogeneous clients"
      },
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "FedGraph",
        "novel_contribution": "Layer-wise federated aggregation of GCN layers using cross-client hidden embeddings to preserve privacy while leveraging graph structure across partitions"
      },
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "FedAvg / FedADAM (FedOpt)",
        "novel_contribution": "Federated optimization of LSTM feature extractor layers; Algorithm 1 uses an ADAM-style server optimizer for aggregation"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Federated Transformer [22]",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "Federated LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "Federated MLP",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Federated Learning"
    ],
    "datasets": [
      {
        "name": "IEEE 57-bus test system",
        "type": "public",
        "domain": "power_system_topology",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IEEE 118-bus test system",
        "type": "public",
        "domain": "power_system_topology",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IEEE 300-bus test system",
        "type": "public",
        "domain": "power_system_topology",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ERCOT hourly electricity load dataset",
        "type": "public",
        "domain": "electricity_load_timeseries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Simulated FDIA measurement dataset (IEEE bus topologies + ERCOT load + synthetic attacks)",
        "type": "synthetic",
        "domain": "smart_grid_measurements",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Federated Transformer",
        "paper_reference": "[22]",
        "metric": "F1-Score, Detection Rate (DR), False Alarm Rate (FR)",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Federated LSTM",
        "paper_reference": null,
        "metric": "F1-Score, Detection Rate (DR), False Alarm Rate (FR)",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Federated MLP",
        "paper_reference": null,
        "metric": "F1-Score, Detection Rate (DR), False Alarm Rate (FR)",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "F1-Score",
      "Detection Rate (DR)",
      "False Alarm Rate (FR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can FDIA detection and localization be trained in a distributed, privacy-preserving manner across multiple grid operators?",
        "How to jointly model temporal load patterns and spatial grid topology for improved FDIA detection under federated non-IID data?",
        "Can a federated approach that respects arbitrary client graph partitions outperform per-bus horizontal FL methods?"
      ],
      "gaps_identified": [
        "Centralized training requires sharing sensitive electricity data, which is impractical due to privacy concerns.",
        "Standard FedAvg struggles with non-IID data common in federated smart grid settings.",
        "Existing FL-based FDIA detection (e.g., transformer-based horizontal FL) requires identical data shapes per client and trains at bus-level, failing to leverage grid graph structure.",
        "Conventional deterministic/bad-data detection methods underperform due to complex, dynamic grid behavior and sophisticated attacks."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Enable privacy-preserving, efficient, and accurate distributed FDIA detection/localization by leveraging federated learning to avoid sharing sensitive data, while capturing both temporal and spatial correlations via a hybrid LSTM+GCN architecture.",
      "potential_research_ideas": [
        "Personalized federated learning for client-specific adaptations (e.g., pFedMe, FedPer, or meta-learning) to handle heterogeneity and personalization needs mentioned.",
        "Robust/secure aggregation against poisoning or Byzantine clients during federated training, specifically tailored to grid data and FDIA threat models.",
        "Differential privacy or secure aggregation to provide formal privacy guarantees beyond FL, assessing utility-privacy trade-offs for FDIA tasks.",
        "Self-supervised or contrastive pretraining on unlabeled grid data to reduce label dependence and improve generalization under non-IID conditions.",
        "Temporal graph models (e.g., TGNs, graph transformers) for richer spatio-temporal dependencies compared to LSTM+GCN stacking.",
        "Asynchronous or hierarchical FL across utility regions/substations to reduce communication overhead and improve scalability.",
        "Communication-efficient FL (compression/quantization) given potentially many clients (buses/subnetworks).",
        "Comprehensive evaluation against adaptive/stealthy FDIA strategies co-optimized to evade graph-temporal detectors.",
        "Multi-task learning for simultaneous detection, localization, and attack-type classification (random/replay/scale).",
        "Domain adaptation across different grid topologies and seasons for improved transferability."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment GCN with Graph Attention Networks or graph transformers to capture variable neighborhood importance and long-range dependencies.",
        "Use temporal convolutional networks or bidirectional LSTM/Transformers for improved temporal modeling and latency control.",
        "Add residual/skip connections and layer normalization to stabilize deeper hybrid stacks.",
        "Adopt FedProx/FedOpt variants and client clustering to mitigate non-IID drift; explore personalized heads on shared backbone.",
        "Incorporate topology-aware positional encodings and learnable edge features (e.g., line admittance) into GNN layers.",
        "Apply adversarial training and consistency regularization using strong FDIA generators to harden robustness.",
        "Use secure aggregation and DP-SGD at server/client to strengthen privacy with measured utility impact."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "TensorFlow"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Privacy-preserving collaboration across utilities without sharing raw data.",
        "Non-IID and heterogeneous client data/topologies leading to personalization needs.",
        "Communication and coordination overhead for federated training, especially with FedGraph embedding exchanges.",
        "Modeling both temporal and spatial dependencies efficiently on edge infrastructure."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": true
    },
    "contributions": [
      "A novel federated learning framework for distributed detection and localization of FDIA attacks using a hybrid LSTM+GCN architecture.",
      "Two-layer training scheme: LSTM feature-extractor layers (federatedly aggregated) to capture temporal patterns; GCN layers (via FedGraph) to capture local spatial correlations among buses.",
      "Generalizable to arbitrary client graph partitions; not restricted to per-bus horizontal FL.",
      "Extensive simulations on IEEE 57, 118, and 300-bus systems with real ERCOT load data; reports improved F1-Score, detection rate, and false alarm rate over federated transformer, LSTM, and MLP baselines.",
      "Claims uniform distribution of error metrics across clients, indicating fairness across participants."
    ]
  },
  {
    "arxiv_id": "2306.08853v2",
    "title": "In Search of netUnicorn: A Data-Collection Platform to Develop Generalizable ML Models for Network Security Problems",
    "authors": "Roman Beltiukov; Wenbo Guo; Arpit Gupta; Walter Willinger",
    "abstract": "The remarkable success of the use of machine learning-based solutions for network security problems has been impeded by the developed ML models' inability to maintain efficacy when used in different network environments exhibiting different network behaviors. This issue is commonly referred to as the generalizability problem of ML models. The community has recognized the critical role that training datasets play in this context and has developed various techniques to improve dataset curation to overcome this problem. Unfortunately, these methods are generally ill-suited or even counterproductive in the network security domain, where they often result in unrealistic or poor-quality datasets.   To address this issue, we propose an augmented ML pipeline that leverages explainable ML tools to guide the network data collection in an iterative fashion. To ensure the data's realism and quality, we require that the new datasets should be endogenously collected in this iterative process, thus advocating for a gradual removal of data-related problems to improve model generalizability. To realize this capability, we develop a data-collection platform, netUnicorn, that takes inspiration from the classic \"hourglass\" model and is implemented as its \"thin waist\" to simplify data collection for different learning problems from diverse network environments. The proposed system decouples data-collection intents from the deployment mechanisms and disaggregates these high-level intents into smaller reusable, self-contained tasks.   We demonstrate how netUnicorn simplifies collecting data for different learning problems from multiple network environments and how the proposed iterative data collection improves a model's generalizability.",
    "published_date": "2023-06-15",
    "pdf_link": "https://arxiv.org/pdf/2306.08853v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "ML generalizability and data collection for security",
      "specific_problem": "Explainability-guided endogenous network data collection to improve cross-environment generalizability of ML-based security models",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Explainability (global surrogate model)",
        "specific": "Trustee (global decision-tree surrogate)",
        "novel_contribution": "Use of global explainability to diagnose inductive biases and drive iterative, targeted data collection in a closed-loop pipeline"
      },
      {
        "type": "primary",
        "category": "Data-centric ML pipeline",
        "specific": "Closed-loop ML workflow with iterative, in-vivo data collection",
        "novel_contribution": "Augmented ML pipeline that integrates explainability and a flexible data-collection platform (netUnicorn) to iteratively curate higher-quality, more generalizable training data"
      },
      {
        "type": "baseline",
        "category": "Explainability (local methods)",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "netUnicorn-collected datasets (this paper)",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://netunicorn.cs.ucsb.edu",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "DARPA 1998",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-IDS intrusion detection datasets",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a closed-loop, explainability-guided data collection process improve the cross-environment generalizability of ML models for network security?",
        "Can a platform (netUnicorn) provide a thin-waist abstraction that decouples data-collection intents from mechanisms to simplify high-quality, in-vivo data collection across diverse network environments?"
      ],
      "gaps_identified": [
        "Existing data augmentation methods from CV/NLP are ill-suited for network data and can produce unrealistic or semantically invalid traffic.",
        "Standard ML pipelines obscure the role of training data and rarely leverage explainability to find inductive biases.",
        "Lack of endogenous (in-vivo) data collection across diverse network environments leads to poor-quality or non-representative datasets.",
        "Shortcut learning and out-of-distribution issues frequently undermine generalizability of network security ML models.",
        "Open-loop pipelines lack means to flexibly collect targeted new data across different environments and learning problems."
      ],
      "limitations": [
        "The proposed approach does not guarantee model generalizability; it aims to reduce inductive biases and OOD issues.",
        "Generalizability depends on careful consideration of the production network infrastructure and traffic characteristics.",
        "Effectiveness depends on the choice and fidelity of explainability tools and on access to diverse environments for data collection."
      ],
      "future_work": [
        "Careful consideration and validation on production network infrastructures and traffic before generalizability can be guaranteed.",
        "Broader instantiations of the closed-loop pipeline across more security tasks and environments."
      ],
      "motivation": "ML models for network security often fail to generalize across different network environments due to dataset issues; existing augmentation/collection methods are ill-suited, requiring an explainability-guided, endogenous data collection approach.",
      "potential_research_ideas": [
        "Integrate uncertainty estimation and OOD detectors to automatically prioritize data-collection intents in the next iteration.",
        "Develop privacy-preserving in-vivo collection (e.g., federated orchestration over netUnicorn) to enable multi-organization generalization without sharing raw traffic.",
        "Create benchmarking suites of cross-environment generalizability tasks curated via netUnicorn with standardized splits and metadata.",
        "Learn a policy (e.g., reinforcement learning) that maps explainability outputs to optimal next-round data-collection intents.",
        "Extend the approach to encrypted traffic classification using flow-level features and programmable data-plane telemetry."
      ],
      "architectural_improvement_recommendations": [
        "Add an active-learning loop that selects samples/environments based on model uncertainty and explainability-derived feature gaps.",
        "Incorporate OOD detection and drift monitoring into the pipeline to trigger targeted data-collection intents.",
        "Provide a declarative policy language with static checking for semantic validity of network data-collection tasks.",
        "Support privacy layers (tokenization, aggregation, differential privacy) within netUnicorn tasks to broaden deployability.",
        "Add a registry of reusable, parameterized tasks with provenance and quality metrics for easier reproducibility."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://netunicorn.cs.ucsb.edu",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Multiple, disparate network environments using programmable data-plane targets and virtualized infrastructures",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Encrypted traffic and privacy constraints complicate labeling and context.",
        "Heterogeneity across network environments (protocols, user populations, topologies).",
        "Ensuring semantic realism requires in-vivo collection and access to infrastructure.",
        "Operational overhead of orchestrating tasks across diverse environments."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A novel closed-loop ML pipeline that integrates explainability to guide iterative, targeted data collection aimed at improving generalizability.",
      "Design and implementation of netUnicorn, a data-collection platform acting as a thin waist to decouple intents from mechanisms and disaggregate into reusable tasks.",
      "Extensive evaluation demonstrating netUnicorn’s capability to collect data for multiple learning problems across multiple environments and showing improved generalizability via iterative collection.",
      "Release of full source code and datasets used in the paper via three repositories (system code, tasks/pipelines, and supplemental materials)."
    ]
  },
  {
    "arxiv_id": "2306.10912v4",
    "title": "Jamming Detection in Low-BER Mobile Indoor Scenarios via Deep Learning",
    "authors": "Savio Sciancalepore; Fabrice Kusters; Nada Khaled Abdelhadi; Gabriele Oligeri",
    "abstract": "The current state of the art on jamming detection relies on link-layer metrics. A few examples are the bit-error-rate (BER), the packet delivery ratio, the throughput, and the increase in the signal-to-noise ratio (SNR). As a result, these techniques can only detect jamming \\emph{ex-post}, i.e., once the attack has already taken down the communication link. These solutions are unfit for mobile devices, e.g., drones, which might lose the connection to the remote controller, being unable to predict the attack.   Our solution is rooted in the idea that a drone unknowingly flying toward a jammed area is experiencing an increasing effect of the jamming, e.g., in terms of BER and SNR. Therefore, drones might use the above-mentioned phenomenon to detect jamming before the decrease of the BER and the increase of the SNR completely disrupt the communication link. Such an approach would allow drones and their pilots to make informed decisions and maintain complete control of navigation, enhancing security and safety.   This paper proposes Bloodhound+, a solution for jamming detection on mobile devices in low-BER regimes. Our approach analyzes raw physical-layer information (I-Q samples) acquired from the wireless channel. We assemble this information into grayscale images and use sparse autoencoders to detect image anomalies caused by jamming attacks. To test our solution against a wide set of configurations, we acquired a large dataset of indoor measurements using multiple hardware, jamming strategies, and communication parameters. Our results indicate that Bloodhound+ can detect indoor jamming up to 20 meters from the jamming source at the minimum available relative jamming power, with a minimum accuracy of 99.7\\%. Our solution is also robust to various sampling rates adopted by the jammer and to the type of signal used for jamming.",
    "published_date": "2023-06-19",
    "pdf_link": "https://arxiv.org/pdf/2306.10912v4",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Wireless Security",
      "subdomain": "Jamming Detection",
      "specific_problem": "Early detection of RF jamming in low-BER indoor mobile scenarios (UAV/drone) using anomaly detection on I-Q samples",
      "attack_types": [
        "Jamming",
        "AWGN jamming",
        "Single-tone jamming",
        "Deceptive jamming (BPSK)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": "Sparse autoencoder (one-class anomaly detector)",
        "novel_contribution": "Transforms sequences of raw I-Q samples into grayscale images and applies a one-class sparse autoencoder to detect anomalies indicative of jamming in a low-BER regime"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "CNN on I-Q samples (from prior work [16])",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Improved CNN-based method on I-Q samples (from prior work [17])",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "One-class anomaly detection"
    ],
    "datasets": [
      {
        "name": "BloodHound+ Indoor Jamming I-Q Dataset",
        "type": "private",
        "domain": "wireless_IQ_samples",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CNN-based jamming detector on I-Q samples (prior BloodHound)",
        "paper_reference": "[16]",
        "metric": "accuracy",
        "their_result": "“accuracy of 0.997 when the adversary jams at a distance of 10m from the target with a Relative Jamming Power (RJP) of 0.1.”",
        "baseline_result": null
      },
      {
        "method_name": "Improved CNN-based methodology on I-Q samples",
        "paper_reference": "[17]",
        "metric": "accuracy",
        "their_result": "Claims to outperform [16] and [17] across RJP, distance, samples-per-image, training set size, and hardware invariance",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "detection range (meters from jammer)",
      "relative jamming power (RJP)",
      "operating BER regime (~1e−6)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can jamming be detected preemptively in a low-BER regime, before link-layer metrics (BER/PDR/SNR) degrade enough to disrupt communication?",
        "Do raw PHY I-Q sample patterns, represented as images, enable robust early jamming detection under mobility?",
        "How robust is the approach to distance from jammer, RJP, sampling-rate mismatches, jamming signal type (tone, Gaussian, deceptive), number of samples per image, training set size, and hardware variation?"
      ],
      "gaps_identified": [
        "Most existing jamming detection relies on link-layer metrics and detects attacks ex-post after link disruption.",
        "Prior works often do not target low-BER regimes required for mobile scenarios like drones.",
        "Limited consideration of strong adversaries using deceptive jamming or sampling-rate variations.",
        "Indoor mobile drone scenarios are underexplored for jamming detection."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Enable proactive jamming detection for mobile drones in indoor environments to maintain control and safety by identifying jamming before communication degrades.",
      "potential_research_ideas": [
        "Extend the method to additional modulations and protocols (e.g., QPSK, QAM, OFDM/Wi-Fi) and multi-band operation.",
        "Incorporate temporal/sequential modeling (e.g., LSTM/Transformer over latent codes) for early-warning detection with fewer samples.",
        "Domain adaptation and transfer learning to generalize across environments, hardware, and outdoor settings.",
        "Fusion of PHY-layer anomaly scores with link-layer metrics (BER/PDR/SNR) for improved robustness and interpretability.",
        "Robustness against adaptive adversaries that mimic normal distributions; investigate adversarial training and detection under deceptive strategies.",
        "Lightweight embedded implementations for onboard UAV deployment, including quantization and pruning.",
        "Online/continual learning to adapt thresholds and models to environmental drift without catastrophic forgetting."
      ],
      "architectural_improvement_recommendations": [
        "Replace or complement sparse autoencoders with convolutional/variational autoencoders to better capture spatial structure in I-Q images.",
        "Use contrastive or self-supervised pretraining on I-Q sequences before one-class fine-tuning.",
        "Apply one-class SVM/Deep SVDD on learned latent representations to sharpen decision boundaries.",
        "Incorporate multi-resolution inputs (e.g., images and spectrograms) and attention to focus on discriminative regions.",
        "Calibrate thresholds using extreme value theory or ROC-based operating points tailored to safety-critical false-alarm budgets."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Indoor wireless testbed with SDRs emulating UAV-GCS links (Ettus X310 and LimeSDR)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Acquiring and processing raw I-Q samples on resource-constrained UAV hardware",
        "Threshold selection and model calibration per environment",
        "Generalization across different radios and sampling rates in the field",
        "Balancing number of samples per image with detection latency and compute overhead",
        "Power and compute budget constraints for onboard inference"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes BloodHound+, a jamming detection method that converts raw I-Q samples into grayscale images and uses sparse autoencoders for one-class anomaly detection.",
      "Targets low-BER mobile indoor scenarios (e.g., drones) to detect jamming preemptively before link disruption.",
      "“Bloodhound+ can detect indoor jamming up to 20 meters from the jamming source at the minimum available relative jamming power, with a minimum accuracy of 99.7%.”",
      "Demonstrates robustness to jammer sampling rates and jamming signal types (tone, Gaussian, deceptive).",
      "Uses a stronger adversary model including knowledge of modulation and sampling rates enabling optimized and deceptive jamming.",
      "Provides an extensive indoor measurement campaign across multiple hardware (Ettus X310 and LimeSDR), configurations, and parameters; includes new LimeSDR data.",
      "Shows improved performance over prior CNN-based methods [16], [17] with respect to RJP, distance from jammer, samples per image, training set size, and hardware invariance.",
      "Demonstrates detection at very low BER (≈1e−6) where competing solutions fail."
    ]
  },
  {
    "arxiv_id": "2306.14263v2",
    "title": "Revolutionizing Cyber Threat Detection with Large Language Models: A privacy-preserving BERT-based Lightweight Model for IoT/IIoT Devices",
    "authors": "Mohamed Amine Ferrag; Mthandazo Ndhlovu; Norbert Tihanyi; Lucas C. Cordeiro; Merouane Debbah; Thierry Lestable; Narinderjit Singh Thandi",
    "abstract": "The field of Natural Language Processing (NLP) is currently undergoing a revolutionary transformation driven by the power of pre-trained Large Language Models (LLMs) based on groundbreaking Transformer architectures. As the frequency and diversity of cybersecurity attacks continue to rise, the importance of incident detection has significantly increased. IoT devices are expanding rapidly, resulting in a growing need for efficient techniques to autonomously identify network-based attacks in IoT networks with both high precision and minimal computational requirements. This paper presents SecurityBERT, a novel architecture that leverages the Bidirectional Encoder Representations from Transformers (BERT) model for cyber threat detection in IoT networks. During the training of SecurityBERT, we incorporated a novel privacy-preserving encoding technique called Privacy-Preserving Fixed-Length Encoding (PPFLE). We effectively represented network traffic data in a structured format by combining PPFLE with the Byte-level Byte-Pair Encoder (BBPE) Tokenizer. Our research demonstrates that SecurityBERT outperforms traditional Machine Learning (ML) and Deep Learning (DL) methods, such as Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs), in cyber threat detection. Employing the Edge-IIoTset cybersecurity dataset, our experimental analysis shows that SecurityBERT achieved an impressive 98.2% overall accuracy in identifying fourteen distinct attack types, surpassing previous records set by hybrid solutions such as GAN-Transformer-based architectures and CNN-LSTM models. With an inference time of less than 0.15 seconds on an average CPU and a compact model size of just 16.7MB, SecurityBERT is ideally suited for real-life traffic analysis and a suitable choice for deployment on resource-constrained IoT devices.",
    "published_date": "2023-06-25",
    "pdf_link": "https://arxiv.org/pdf/2306.14263v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Network-based multi-class attack detection on IoT/IIoT traffic using a lightweight BERT model with privacy-preserving encoding",
      "attack_types": [
        "TCP SYN flood",
        "UDP flood",
        "HTTP flood",
        "ICMP flood",
        "Port scanning",
        "OS fingerprinting",
        "Vulnerability scanning",
        "DNS spoofing",
        "ARP spoofing",
        "Cross-Site Scripting (XSS)",
        "SQL injection",
        "File uploading attack",
        "Backdoor",
        "Password cracking",
        "Ransomware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT",
        "novel_contribution": "SecurityBERT: a 15-layer BERT-based architecture (~11M parameters) trained on PPFLE-encoded IoT network traffic for multi-class attack detection"
      },
      {
        "type": "primary",
        "category": "Preprocessing/Encoding",
        "specific": "Privacy-Preserving Fixed-Length Encoding (PPFLE)",
        "novel_contribution": "Hash-based encoding of column-name$value pairs to create fixed-length, privacy-preserving textual sequences better aligned to BERT while hiding sensitive network data"
      },
      {
        "type": "primary",
        "category": "Tokenizer",
        "specific": "Byte-level Byte-Pair Encoding (BBPE)",
        "novel_contribution": "Combined with PPFLE to effectively tokenize hashed sequences derived from network flows"
      },
      {
        "type": "primary",
        "category": "Linear Classifier",
        "specific": "Softmax layer",
        "novel_contribution": "Fine-tuning head for multi-category classification over 14 attack types"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Hybrid",
        "specific": "GAN-Transformer",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Hybrid",
        "specific": "CNN-LSTM",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Edge-IIoTset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CNN",
        "paper_reference": null,
        "metric": "overall accuracy",
        "their_result": "98.2% overall accuracy",
        "baseline_result": null
      },
      {
        "method_name": "RNN",
        "paper_reference": null,
        "metric": "overall accuracy",
        "their_result": "98.2% overall accuracy",
        "baseline_result": null
      },
      {
        "method_name": "GAN-Transformer-based architectures",
        "paper_reference": null,
        "metric": "overall accuracy",
        "their_result": "98.2% overall accuracy",
        "baseline_result": null
      },
      {
        "method_name": "CNN-LSTM",
        "paper_reference": null,
        "metric": "overall accuracy",
        "their_result": "98.2% overall accuracy",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "inference time",
      "model size"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a compact BERT-based model achieve real-time inference suitable for embedded IoT/IIoT devices?",
        "Can network traffic be encoded in a privacy-preserving textual form that BERT can learn effectively?",
        "Can such a lightweight, privacy-preserving approach surpass prior ML/DL methods on IoT intrusion detection accuracy?"
      ],
      "gaps_identified": [
        "LLMs with billions of parameters are impractical for embedded/IoT deployment due to computational demands.",
        "Network traffic is largely numerical, posing challenges for language models to capture semantics without specialized encoding.",
        "Many available security datasets rely on artificial scenarios and often lack packet-level data, reducing realism.",
        "Sharing real network traffic for training raises privacy concerns; there is a need for privacy-preserving approaches.",
        "Balancing model complexity for high accuracy against latency/size constraints for real-life traffic analysis is challenging."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Rising IoT cyber threats drive the need for accurate, low-latency, and privacy-preserving intrusion detection deployable on resource-constrained devices.",
      "potential_research_ideas": [
        "Self-supervised pretraining on unlabeled PCAP-derived sequences (e.g., masked token prediction on PPFLE/alternative encodings) to reduce labeled data needs.",
        "Federated learning for on-device/private training across heterogeneous IoT fleets while preserving data locality.",
        "Differential privacy or cryptographic enhancements to PPFLE (e.g., DP noise or salted hashing) with formal privacy guarantees and utility analysis.",
        "Open-set and few-shot detection on emerging/zero-day IoT attacks via metric learning or energy-based modeling.",
        "Concept drift handling for evolving traffic via continual learning or rehearsal-free techniques adapted to PPFLE representations.",
        "Cross-dataset generalization studies (Edge-IIoTset -> other IoT datasets) with domain adaptation.",
        "Adversarial robustness evaluation against evasion/poisoning tailored to hashed/textual encodings; robust training defenses.",
        "Explainability mapping from attention/token importance back to original flow features for analyst trust and root-cause analysis.",
        "Streaming/online inference pipeline for high-throughput gateways with batching, caching, and approximate attention.",
        "Lightweight multimodal fusion (raw numeric features + encoded text) to test if hybrid representations outperform PPFLE-only."
      ],
      "architectural_improvement_recommendations": [
        "Knowledge distillation from a larger Transformer to the 11M-parameter model to further shrink size/latency while preserving accuracy.",
        "Quantization-aware training and structured pruning to reduce model size below 10 MB and accelerate CPU inference.",
        "Explore alternative encoders tailored to numeric data (e.g., TabTransformer, FT-Transformer) and compare to BERT on PPFLE.",
        "Replace or augment BBPE with learned subword units over the hashed vocabulary; evaluate unigram LM tokenization.",
        "Integrate class-imbalance handling (focal loss, reweighting, or mixup) if some attack classes are underrepresented.",
        "Hybrid input: concatenate learned embeddings of raw normalized numeric features with PPFLE token embeddings.",
        "Efficient attention mechanisms (Linformer/Performer) to improve scalability for longer sequences or higher throughput.",
        "Calibrated confidence estimation and rejection option for uncertain samples to improve real-world reliability."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Model size ~16.7MB; ~11M parameters; inference time <0.15 seconds on an average CPU (also stated as <0.3 seconds elsewhere)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Resource-constrained IoT/IIoT edge devices; untrusted servers for inference over privacy-preserving encodings",
      "scalability_discussed": true,
      "inference_time": "<0.15 seconds per sample on an average CPU",
      "deployment_challenges": [
        "Maintaining privacy of training/inference data while preserving discriminative features",
        "Balancing model complexity with latency/size constraints for embedded deployment",
        "Representing numeric network data in a form suitable for language models"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces Privacy-Preserving Fixed-Length Encoding (PPFLE) to convert network traffic into structured, hashed textual sequences.",
      "Designs SecurityBERT: a 15-layer, ~11M-parameter BERT-based lightweight model for multi-class IoT/IIoT attack detection.",
      "Combines PPFLE with a Byte-level BPE tokenizer to effectively represent and tokenize encoded network traffic.",
      "Achieves \"98.2% overall accuracy\" on Edge-IIoTset across fourteen attack types.",
      "Outperforms traditional ML/DL methods and prior hybrid models (e.g., GAN-Transformer, CNN-LSTM) on the same dataset.",
      "Demonstrates practical efficiency: \"inference time of less than 0.15 seconds on an average CPU\" and \"compact model size of just 16.7MB.\"",
      "Proposes a privacy-preserving pipeline enabling classification on untrusted servers while hiding sensitive network data."
    ]
  },
  {
    "arxiv_id": "2306.02165v1",
    "title": "Learning to Defend by Attacking (and Vice-Versa): Transfer of Learning in Cybersecurity Games",
    "authors": "Tailia Malloy; Cleotilde Gonzalez",
    "abstract": "Designing cyber defense systems to account for cognitive biases in human decision making has demonstrated significant success in improving performance against human attackers. However, much of the attention in this area has focused on relatively simple accounts of biases in human attackers, and little is known about adversarial behavior or how defenses could be improved by disrupting attacker's behavior. In this work, we present a novel model of human decision-making inspired by the cognitive faculties of Instance-Based Learning Theory, Theory of Mind, and Transfer of Learning. This model functions by learning from both roles in a security scenario: defender and attacker, and by making predictions of the opponent's beliefs, intentions, and actions. The proposed model can better defend against attacks from a wide range of opponents compared to alternatives that attempt to perform optimally without accounting for human biases. Additionally, the proposed model performs better against a range of human-like behavior by explicitly modeling human transfer of learning, which has not yet been applied to cyber defense scenarios. Results from simulation experiments demonstrate the potential usefulness of cognitively inspired models of agents trained in attack and defense roles and how these insights could potentially be used in real-world cybersecurity.",
    "published_date": "2023-06-03",
    "pdf_link": "https://arxiv.org/pdf/2306.02165v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cyber Defense",
      "subdomain": "Game-theoretic Security (Security Games)",
      "specific_problem": "Defender policy learning against human-like attackers in Stackelberg Security Games with transfer across attacker/defender roles",
      "attack_types": [
        "Strategic asset targeting in Stackelberg Security Games (human-like attackers)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Cognitive Model / Instance-Based Learning",
        "specific": "Instance-Based Theory of Mind (IBToM)",
        "novel_contribution": "Extends Instance-Based Learning Theory with Theory-of-Mind opponent modeling and transfer-of-learning across attacker/defender roles; predicts opponent actions (softmax over opponent option utilities) and uses predictions as features for decision-making and role transfer"
      },
      {
        "type": "baseline",
        "category": "Cognitive Model / Instance-Based Learning",
        "specific": "Standard IBL (without ToM)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Bandit / Reinforcement Learning",
        "specific": "Upper Confidence Bound (UCB)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Online Learning",
      "Bandit Learning",
      "Cognitive Modeling"
    ],
    "datasets": [
      {
        "name": "Synthetic Stackelberg Security Game (two-asset, one-step)",
        "type": "synthetic",
        "domain": "game_simulation",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Upper Confidence Bound (UCB)",
        "paper_reference": "[23]",
        "metric": "Agent reward (zero-sum payoff) over trials/episodes",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Instance-Based Learning (IBL) without ToM",
        "paper_reference": "[8]",
        "metric": "Agent reward (zero-sum payoff) over trials/episodes",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Agent reward (zero-sum payoff)",
      "Average reward over trials/episodes"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a cognitively inspired model that integrates Theory of Mind and transfer of learning improve defender performance in Stackelberg Security Games?",
        "Does learning from both attacker and defender roles enable better transfer and robustness against human-like opponents?",
        "How does an IBToM model compare to optimality-seeking baselines (UCB) and standard IBL without ToM in simulated SSGs?"
      ],
      "gaps_identified": [
        "Prior cyber defense work tends to assume optimal attackers or use simple bias models; little is known about adversarial behavior and how to disrupt attacker behavior.",
        "Transfer of learning has not been applied to cyber defense scenarios in SSGs.",
        "Existing bounded-rational models (e.g., BRQR, SUQR) assume specific deviations and lack explicit Theory-of-Mind reasoning.",
        "Defense systems often do not account for humans’ dynamic, boundedly rational decision-making and role-transfer effects."
      ],
      "limitations": [
        "Evaluation is purely in simulation; no human-subject or real-system validation.",
        "Simplified one-step SSG with two assets; does not cover multi-step, signaling, or more complex environments.",
        "Models are reset each episode; limited exploration of long-horizon memory effects.",
        "No direct comparison to BRQR/SUQR in experiments (authors argue different focus).",
        "No public code or implementation details beyond algorithm and parameters; no statistical tests or numeric summaries reported in text."
      ],
      "future_work": [
        "Test IBToM against human participants controlling attack/defense decisions.",
        "Apply the approach to real-world cyber defense settings and richer SSG variants (multi-step, signaling, resource constraints).",
        "Adapt prior bounded-rational models (BRQR, SUQR) to incorporate ToM and compare.",
        "Explore transfer in larger, multi-asset or networked environments and with partial observability."
      ],
      "motivation": "Improve cyber defense by modeling and leveraging human cognitive processes—bounded rationality, Theory of Mind, and transfer of learning—rather than assuming optimal attackers.",
      "potential_research_ideas": [
        "Human-in-the-loop evaluation: collect attacker/defender human play to calibrate and validate IBToM parameters for improved predictive fidelity.",
        "Extend to multi-stage and signaling SSGs to study deception, commitment, and communication with ToM-based opponent modeling.",
        "Contextual and non-stationary opponent modeling: incorporate contextual bandits/meta-learning to adapt IBToM to evolving attacker strategies.",
        "Population-level ToM: learn distributions over opponent types and perform Bayesian belief updating over ToM models.",
        "Hybrid neuro-cognitive architectures: add lightweight recurrent components to capture temporal patterns while retaining IBL interpretability.",
        "Risk-sensitive and utility-misaligned settings: integrate prospect-theory-like utilities within IBToM to match human risk attitudes.",
        "Model-based ToM planning: simulate counterfactual opponent beliefs/intentions to design proactive defenses and perturb attacker learning.",
        "Cross-domain transfer: test whether attack-role learning in phishing/social engineering games transfers to network defense SSGs."
      ],
      "architectural_improvement_recommendations": [
        "Learn IBL/IBToM parameters (decay, noise, temperatures) via Bayesian inference or gradient-free optimization rather than fixed baselines.",
        "Introduce hierarchical memory and episodic/context embeddings to improve generalization across episodes and assets.",
        "Augment opponent modeling with uncertainty estimates (e.g., Bayesian softmax) for robust decision-making under sparse observations.",
        "Upgrade to contextual bandits or model-based RL for environments with richer state and partial observability.",
        "Incorporate mixture-of-ToM models and perform online opponent type inference.",
        "Integrate signaling/deception modules to co-optimize defense coverage and information revelation."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Bridging from simplified SSG simulations to complex enterprise environments.",
        "Need for human-behavior data to calibrate ToM and transfer mechanisms.",
        "Observability of attacker actions/outcomes in real deployments may be limited or delayed.",
        "Robustness to diverse, adaptive, and deceptive adversaries beyond simulated models."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes Instance-Based Theory of Mind (IBToM), a novel cognitive model that integrates IBLT, ToM, and transfer of learning for cybersecurity games.",
      "Introduces a ToM-inspired training paradigm that learns from both attacker and defender roles and predicts opponent beliefs/actions.",
      "Demonstrates via simulations that IBToM outperforms UCB and standard IBL in defending against a range of opponent types and in role transfer within SSGs.",
      "Highlights the relevance of cognitively inspired models for real-world cyber defense and outlines future human-centered evaluations."
    ]
  },
  {
    "arxiv_id": "2306.06255v1",
    "title": "Early Malware Detection and Next-Action Prediction",
    "authors": "Zahra Jamadi; Amir G. Aghdam",
    "abstract": "In this paper, we propose a framework for early-stage malware detection and mitigation by leveraging natural language processing (NLP) techniques and machine learning algorithms. Our primary contribution is presenting an approach for predicting the upcoming actions of malware by treating application programming interface (API) call sequences as natural language inputs and employing text classification methods, specifically a Bi-LSTM neural network, to predict the next API call. This enables proactive threat identification and mitigation, demonstrating the effectiveness of applying NLP principles to API call sequences. The Bi-LSTM model is evaluated using two datasets. %The model achieved an accuracy of 93.6\\% and 88.8\\% for the %first and second dataset respectively. Additionally, by modeling consecutive API calls as 2-gram and 3-gram strings, we extract new features to be further processed using a Bagging-XGBoost algorithm, effectively predicting malware presence at its early stages. The accuracy of the proposed framework is evaluated by simulations.",
    "published_date": "2023-06-09",
    "pdf_link": "https://arxiv.org/pdf/2306.06255v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Behavior-based Malware Detection",
      "specific_problem": "Early-stage malware detection from API call sequences and next-API-call (next-action) prediction for proactive mitigation",
      "attack_types": [
        "generic Windows PE malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Bi-LSTM",
        "novel_contribution": "Treats API-call sequences as natural language to predict the next API call(s) one-by-one for upcoming malware action prediction"
      },
      {
        "type": "primary",
        "category": "Ensemble (Gradient Boosting)",
        "specific": "Bagging-XGBoost",
        "novel_contribution": "Early malware detection using 2-gram and 3-gram API-call sequence features with feature importance ranking"
      },
      {
        "type": "primary",
        "category": "Feature Engineering",
        "specific": "N-gram features (2-gram, 3-gram) from API call sequences",
        "novel_contribution": "Models consecutive API calls as n-grams to serve both as inputs for Bi-LSTM and as features for XGBoost with interpretability"
      },
      {
        "type": "baseline",
        "category": "Optimization",
        "specific": "Adam optimizer",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Regularization",
        "specific": "Dropout (0.3)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Training Strategy",
        "specific": "Early stopping",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Data Resampling",
        "specific": "Random Oversampling (to balance malware/goodware in dataset 1)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Oliveira & Sassi (TechRxiv 2019) API call sequences dataset",
        "type": "public",
        "domain": "api_call_sequences",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Catak & Yazı (2019) Benchmark API Call Dataset for Windows PE Malware Classification",
        "type": "public",
        "domain": "api_call_sequences",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "ROC-AUC (per-label)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Signature-based malware detection often fails on unseen threats due to reliance on known patterns",
        "To the best of the authors’ knowledge, no prior research has predicted upcoming malware actions by predicting the next APIs",
        "Label imbalance across API-call labels leads to poor prediction for rare API calls"
      ],
      "limitations": [
        "Label imbalance across API-call labels; rare API calls are harder to predict",
        "Lower performance on longer sequences (dataset 2) compared to shorter sequences (dataset 1)",
        "Evaluation conducted via simulations; real-time/online performance not assessed",
        "Next-API prediction explored one step at a time only",
        "Dataset 1 uses only first 100 non-repeated parent-process API calls, which may limit generalization to full traces"
      ],
      "future_work": [
        "Investigate transformers and attention mechanisms to enhance detection and prediction",
        "Evaluate real-time performance for online malware detection and mitigation",
        "Extend framework to multi-step-ahead API-call prediction"
      ],
      "motivation": "Enable early-stage malware detection and proactive mitigation by leveraging NLP over API-call sequences to anticipate upcoming malicious actions.",
      "potential_research_ideas": [
        "Pretrain transformer language models on large unlabeled API-call corpora (masked/casual LM) and finetune for next-API prediction and early detection",
        "Multi-step sequence forecasting with beam search or scheduled sampling to generate probable future API-call trajectories for mitigation planning",
        "Incorporate API-call arguments, categories, and call stack/context to enrich semantics beyond call identities",
        "Contrastive/self-supervised representation learning on API sequences to reduce reliance on label balance",
        "Model hybrid signals (API calls + registry/file/network events) via multimodal fusion for more robust early detection",
        "Uncertainty-aware predictions (e.g., temperature scaling, conformal prediction) to trigger mitigation only under calibrated confidence",
        "Adversarial robustness studies against API obfuscation/insertion/reordering and design of defenses (e.g., order-invariant encoders, edit-distance regularization)",
        "Federated/continual learning across endpoints for privacy-preserving, adaptive detectors",
        "Causal analysis of API-call dependencies to identify intervention points for automated response",
        "Knowledge-graph or program-graph enriched models (e.g., GNNs) to capture relations among modules/APIs/objects"
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment Bi-LSTM with transformer decoders (causal attention) for longer-range dependencies and parallel training",
        "Use class-imbalance-aware objectives (focal loss, class weights) and label smoothing for next-API classification",
        "Adopt seq2seq architectures to predict k-step future API sequences directly; evaluate with teacher forcing and scheduled sampling",
        "Leverage beam search and top-k/nucleus sampling to generate multiple plausible next actions for mitigation planning",
        "Integrate API-call argument embeddings and contextual metadata (process lineage, DLL/module info) into the model",
        "For detection, combine XGBoost with calibrated probabilities and cost-sensitive thresholds to control false alarms",
        "Employ data augmentation (e.g., Markovian insertion/removal under constraints) to address rare-call sparsity",
        "Real-time streaming pipeline with sliding windows and early-exit criteria to trade off latency vs accuracy"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Real-time/online performance not evaluated; latency and streaming constraints unassessed",
        "Label imbalance causes poor predictions for rare API calls, potentially affecting reliability",
        "Focus on parent-process API calls may miss behaviors in child processes during deployment"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a framework that treats API-call sequences as natural language and uses a Bi-LSTM to predict next API calls (next-action prediction) for proactive mitigation",
      "Performs early malware detection using 2-gram and 3-gram API-call features with a Bagging-XGBoost classifier and identifies important malicious sequences",
      "Reports next-API prediction performance: Dataset 1 Accuracy 93.62%, Precision 93.58%, Recall 93.62%, F1 93.52%; Dataset 2 Accuracy 88.80%, Precision 88.50%, Recall 88.80%, F1 88.48%",
      "Reports early detection performance with Bagging-XGBoost: Accuracy 95.85%, Precision 92.70%, Recall 99.56%, F1 96.00%",
      "Analyzes rare API labels with per-label ROC to diagnose where the model struggles and interprets top malicious API-call sequences via feature importance"
    ]
  },
  {
    "arxiv_id": "2306.14062v2",
    "title": "On the Uses of Large Language Models to Interpret Ambiguous Cyberattack Descriptions",
    "authors": "Reza Fayyazi; Shanchieh Jay Yang",
    "abstract": "The volume, variety, and velocity of change in vulnerabilities and exploits have made incident threat analysis challenging with human expertise and experience along. Tactics, Techniques, and Procedures (TTPs) are to describe how and why attackers exploit vulnerabilities. However, a TTP description written by one security professional can be interpreted very differently by another, leading to confusion in cybersecurity operations or even business, policy, and legal decisions. Meanwhile, advancements in AI have led to the increasing use of Natural Language Processing (NLP) algorithms to assist the various tasks in cyber operations. With the rise of Large Language Models (LLMs), NLP tasks have significantly improved because of the LLM's semantic understanding and scalability. This leads us to question how well LLMs can interpret TTPs or general cyberattack descriptions to inform analysts of the intended purposes of cyberattacks. We propose to analyze and compare the direct use of LLMs (e.g., GPT-3.5) versus supervised fine-tuning (SFT) of small-scale-LLMs (e.g., BERT) to study their capabilities in predicting ATT&CK tactics. Our results reveal that the small-scale-LLMs with SFT provide a more focused and clearer differentiation between the ATT&CK tactics (if such differentiation exists). On the other hand, direct use of LLMs offer a broader interpretation of cyberattack techniques. When treating more general cases, despite the power of LLMs, inherent ambiguity exists and limits their predictive power. We then summarize the challenges and recommend research directions on LLMs to treat the inherent ambiguity of TTP descriptions used in various cyber operations.",
    "published_date": "2023-06-24",
    "pdf_link": "https://arxiv.org/pdf/2306.14062v2",
    "paper_types": [
      "empirical_analysis",
      "new_dataset"
    ],
    "security_domain": {
      "primary": "Threat Intelligence",
      "subdomain": "TTP Extraction and Mapping",
      "specific_problem": "Interpreting cyberattack (TTP) descriptions and predicting MITRE ATT&CK tactics (multi-label classification)",
      "attack_types": [
        "Persistence",
        "Privilege Escalation",
        "Defense Evasion",
        "Execution",
        "Multiple ATT&CK tactics (14 total categories)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT-base",
        "novel_contribution": "Supervised fine-tuning for multi-label ATT&CK tactic prediction with sigmoid outputs and BCE loss; designed to handle tactic overlap/ambiguity with limited labeled data"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "SecureBERT (RoBERTa-base)",
        "novel_contribution": "Supervised fine-tuning of cybersecurity-pretrained language model (on CVE text) for multi-label ATT&CK tactic prediction; compared against BERT-base"
      },
      {
        "type": "primary",
        "category": "LLM (decoder-style)",
        "specific": "GPT-3.5",
        "novel_contribution": "Direct prompted use (zero-/few-shot) to map TTP descriptions to ATT&CK tactics; prompt engineering to elicit multi-label predictions"
      },
      {
        "type": "primary",
        "category": "LLM (decoder-style)",
        "specific": "Google Bard",
        "novel_contribution": "Direct prompted use to map TTP descriptions to ATT&CK tactics; contrasted with SFT of small-scale models"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Zero-shot",
      "Few-shot"
    ],
    "datasets": [
      {
        "name": "Curated MITRE ATT&CK TTP descriptions mapped to 14 tactics (618 descriptions)",
        "type": "public",
        "domain": "ttp_text",
        "link": null,
        "is_new_contribution": true,
        "availability": "available_on_request"
      },
      {
        "name": "Curated CAPEC descriptions referencing ATT&CK mapped to ATT&CK tactics (177 descriptions out of 593 CAPEC entries)",
        "type": "public",
        "domain": "ttp_text",
        "link": null,
        "is_new_contribution": true,
        "availability": "available_on_request"
      },
      {
        "name": "IMDB movie reviews (100 reviews subset)",
        "type": "public",
        "domain": "general_text",
        "link": "https://ai.stanford.edu/~amaas/data/sentiment/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GPT-3.5 (direct prompted use)",
        "paper_reference": "OpenAI GPT-3.5",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Google Bard (direct prompted use)",
        "paper_reference": "Google Bard",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "BERT-base (SFT)",
        "paper_reference": "Devlin et al., 2018",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "SecureBERT (RoBERTa-base, SFT)",
        "paper_reference": "Orbinato et al., SecureBERT",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How well can LLMs interpret TTP or general cyberattack descriptions to predict MITRE ATT&CK tactics?",
        "How does direct use of LLMs (e.g., GPT-3.5/Bard) compare to supervised fine-tuning of small-scale LLMs (BERT/SecureBERT) for this task?",
        "Can LLMs handle the inherent ambiguity and multi-intent overlap present in TTP descriptions?"
      ],
      "gaps_identified": [
        "Lack of publicly available datasets mapping cyberattack/TTP descriptions to ATT&CK tactics",
        "Prior works did not use modern LLMs (e.g., GPT-3.5) for TTP interpretation",
        "Limited handling of multi-label classification and overlapping tactics in prior work",
        "Sentence-level processing in prior work may miss document-level context",
        "No evaluation using CAPEC-versus-ATT&CK mapping as a cross-source test set",
        "Limited comparisons between SecureBERT and BERT in prior literature"
      ],
      "limitations": [
        "Limited labeled data: 618 ATT&CK descriptions and 177 CAPEC descriptions",
        "Descriptions longer than 512 tokens were truncated due to BERT/RoBERTa input limits (6 cases)",
        "CAPEC-to-ATT&CK relevance is indirect and may include human interpretation inconsistencies",
        "Focus on 14 ATT&CK tactics (not full techniques/sub-techniques)",
        "Inherent ambiguity in TTP descriptions limits predictive power even for advanced LLMs"
      ],
      "future_work": [
        "Fine-tune LLMs with prompt adaptation to better handle ambiguity",
        "Explore self-supervised learning to leverage unlabeled cybersecurity text",
        "Investigate reinforcement learning approaches (e.g., RLHF) to treat ambiguity and evolving vulnerabilities",
        "Advance usable-security aspects for assisting cybersecurity operations"
      ],
      "motivation": "Inform the community on appropriate use and realistic expectations of LLMs for interpreting ambiguous TTP descriptions to support cybersecurity operations and decision making.",
      "potential_research_ideas": [
        "Construct a multi-annotator gold-standard dataset for TTP-to-tactic mapping with uncertainty labels to explicitly model ambiguity.",
        "Formulate tactic prediction as a natural language inference (NLI) problem using tactic definitions as hypotheses to improve label disambiguation.",
        "Develop hierarchical multi-label models covering tactics → techniques → sub-techniques with calibrated uncertainty and abstention.",
        "Apply continual learning/domain-adaptive fine-tuning or adapters to track ATT&CK updates and evolving TTPs.",
        "Use weak/distant supervision and self-training to expand training data from CTI reports, CVEs, and blogs.",
        "Study calibration and selective prediction (abstain when uncertain) for analyst-in-the-loop workflows.",
        "Incorporate rationale extraction or chain-of-thought prompting to provide human-interpretable justifications for predicted tactics.",
        "Evaluate retrieval-augmented models leveraging ATT&CK/CAPEC knowledge bases to ground predictions."
      ],
      "architectural_improvement_recommendations": [
        "Adopt long-context transformers (e.g., Longformer/BigBird) to avoid truncation of lengthy TTP descriptions.",
        "Use per-class calibrated thresholds or optimization (e.g., Youden’s J, validation-based) instead of a fixed 0.5 for multi-label decisions.",
        "Address class imbalance with focal loss or class-weighted BCE.",
        "Reframe as pairwise ‘description + tactic definition’ classification (NLI-style) with bi-encoder/cross-encoder architectures.",
        "Leverage parameter-efficient tuning (LoRA/IA3/prompt-tuning) on open-source LLMs for domain adaptation.",
        "Add uncertainty estimation (MC dropout, deep ensembles) and label smoothing to better reflect ambiguity.",
        "Multi-task learning across ATT&CK and CAPEC signals; pre-train with self-supervised objectives on CTI corpora.",
        "Use retrieval-augmented generation to cite relevant ATT&CK techniques and evidence spans from the text."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": "5-fold cross-validation; 25 epochs per fold; batch size 8 to fit GPU memory; AdamW optimizer; BCE loss; learning rate 2e-5; random seed set (519 for training, 42 for CV splits)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Inherent ambiguity and overlapping intents in TTP descriptions",
        "Limited availability of high-quality labeled data",
        "Evolving vulnerabilities and taxonomy updates (ATT&CK versions)",
        "Model input length limits can truncate important context"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First study comparing direct use of LLMs (GPT-3.5, Bard) versus SFT of small-scale LLMs (BERT, SecureBERT) for interpreting TTP descriptions.",
      "Prompt design and supervised fine-tuning setup to handle non-trivial multi-label overlap and ambiguity in TTP descriptions.",
      "Finding: SFT small-scale LLMs yield more precise/clear differentiation among tactics (when differentiation exists), while direct LLM use provides broader but less precise interpretations.",
      "Identification of two inherent types of ambiguity in TTP descriptions, limiting predictive power even for advanced LLMs.",
      "Recommendations for fine-tuning with prompt adaptation and future directions (self-supervised and reinforcement learning) to address ambiguity, evolving vulnerabilities, and usable security needs."
    ]
  },
  {
    "arxiv_id": "2306.10392v1",
    "title": "GlyphNet: Homoglyph domains dataset and detection using attention-based Convolutional Neural Networks",
    "authors": "Akshat Gupta; Laxman Singh Tomar; Ridhima Garg",
    "abstract": "Cyber attacks deceive machines into believing something that does not exist in the first place. However, there are some to which even humans fall prey. One such famous attack that attackers have used over the years to exploit the vulnerability of vision is known to be a Homoglyph attack. It employs a primary yet effective mechanism to create illegitimate domains that are hard to differentiate from legit ones. Moreover, as the difference is pretty indistinguishable for a user to notice, they cannot stop themselves from clicking on these homoglyph domain names. In many cases, that results in either information theft or malware attack on their systems. Existing approaches use simple, string-based comparison techniques applied in primary language-based tasks. Although they are impactful to some extent, they usually fail because they are not robust to different types of homoglyphs and are computationally not feasible because of their time requirement proportional to the string length. Similarly, neural network-based approaches are employed to determine real domain strings from fake ones. Nevertheless, the problem with both methods is that they require paired sequences of real and fake domain strings to work with, which is often not the case in the real world, as the attacker only sends the illegitimate or homoglyph domain to the vulnerable user. Therefore, existing approaches are not suitable for practical scenarios in the real world. In our work, we created GlyphNet, an image dataset that contains 4M domains, both real and homoglyphs. Additionally, we introduce a baseline method for a homoglyph attack detection system using an attention-based convolutional Neural Network. We show that our model can reach state-of-the-art accuracy in detecting homoglyph attacks with a 0.93 AUC on our dataset.",
    "published_date": "2023-06-17",
    "pdf_link": "https://arxiv.org/pdf/2306.10392v1",
    "paper_types": [
      "new_dataset",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Web/Internet Security",
      "subdomain": "URL/Domain Abuse Detection",
      "specific_problem": "Detection of homoglyph (IDN homograph) domain names without requiring paired real/fake strings",
      "attack_types": [
        "Homoglyph attacks",
        "IDN homograph attacks",
        "Domain impersonation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN with Attention",
        "specific": "Convolutional Block Attention Module (CBAM) integrated with Conv2D + MaxPooling blocks",
        "novel_contribution": "Applies an attention-based CNN (CBAM) to rendered domain-name images to detect homoglyphs in an unpaired setting"
      },
      {
        "type": "baseline",
        "category": "Siamese Network (CNN)",
        "specific": "Siamese CNN for image pair similarity",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GAN",
        "specific": "PhishGAN: UNet generator (Pix2Pix-like), CNN classifier with triplet loss",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN (Ensemble)",
        "specific": "Ensemble CNN",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "GlyphNet",
        "type": "public",
        "domain": "rendered_domain_images",
        "link": "https://github.com/Akshat4112/Glyphnet",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Domain and Process Strings (Woodbridge et al., 2018)",
        "type": "proprietary",
        "domain": "paired_domain_strings (rendered to binary images)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Similar and Dissimilar Pairs (Majumder et al., 2020)",
        "type": "proprietary",
        "domain": "paired_domain_strings",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Domains Project (Turkynewych, 2020)",
        "type": "public",
        "domain": "domain_name_list",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Siamese CNN",
        "paper_reference": "Woodbridge et al., 2018",
        "metric": "Accuracy",
        "their_result": "0.93",
        "baseline_result": "0.79"
      },
      {
        "method_name": "Siamese CNN",
        "paper_reference": "Woodbridge et al., 2018",
        "metric": "Precision",
        "their_result": "0.93",
        "baseline_result": "0.78"
      },
      {
        "method_name": "Siamese CNN",
        "paper_reference": "Woodbridge et al., 2018",
        "metric": "Recall",
        "their_result": "0.93",
        "baseline_result": "0.71"
      },
      {
        "method_name": "Siamese CNN",
        "paper_reference": "Woodbridge et al., 2018",
        "metric": "F1-score",
        "their_result": "0.93",
        "baseline_result": "0.74"
      },
      {
        "method_name": "Siamese CNN",
        "paper_reference": "Woodbridge et al., 2018",
        "metric": "AUC",
        "their_result": "0.93",
        "baseline_result": "0.78"
      },
      {
        "method_name": "Ensemble CNN",
        "paper_reference": "Majumder et al., 2020",
        "metric": "Accuracy",
        "their_result": "0.93",
        "baseline_result": "0.83"
      },
      {
        "method_name": "Ensemble CNN",
        "paper_reference": "Majumder et al., 2020",
        "metric": "Precision",
        "their_result": "0.93",
        "baseline_result": "0.82"
      },
      {
        "method_name": "Ensemble CNN",
        "paper_reference": "Majumder et al., 2020",
        "metric": "Recall",
        "their_result": "0.93",
        "baseline_result": "0.79"
      },
      {
        "method_name": "Ensemble CNN",
        "paper_reference": "Majumder et al., 2020",
        "metric": "F1-score",
        "their_result": "0.93",
        "baseline_result": "0.80"
      },
      {
        "method_name": "Ensemble CNN",
        "paper_reference": "Majumder et al., 2020",
        "metric": "AUC",
        "their_result": "0.93",
        "baseline_result": "0.83"
      },
      {
        "method_name": "PhishGAN",
        "paper_reference": "Sern, David, and Hao, 2020",
        "metric": "Accuracy",
        "their_result": "0.93",
        "baseline_result": "0.71"
      },
      {
        "method_name": "PhishGAN",
        "paper_reference": "Sern, David, and Hao, 2020",
        "metric": "Precision",
        "their_result": "0.93",
        "baseline_result": "0.74"
      },
      {
        "method_name": "PhishGAN",
        "paper_reference": "Sern, David, and Hao, 2020",
        "metric": "Recall",
        "their_result": "0.93",
        "baseline_result": "0.65"
      },
      {
        "method_name": "PhishGAN",
        "paper_reference": "Sern, David, and Hao, 2020",
        "metric": "F1-score",
        "their_result": "0.93",
        "baseline_result": "0.69"
      },
      {
        "method_name": "PhishGAN",
        "paper_reference": "Sern, David, and Hao, 2020",
        "metric": "AUC",
        "their_result": "0.93",
        "baseline_result": "0.71"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "AUC"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can homoglyph domains be accurately detected from single unpaired inputs without requiring real/fake pairs?",
        "Does an attention-based CNN (CBAM) on rendered domain images outperform prior string-based and deep-learning baselines?",
        "Can a large-scale rendered image dataset of domain names improve detection performance and generalization?"
      ],
      "gaps_identified": [
        "Existing string-based comparison methods are not robust to diverse homoglyphs and scale poorly with string length.",
        "Many prior neural methods (e.g., Siamese networks) require paired real–fake strings, which are unavailable in realistic settings.",
        "Lack of large, publicly available datasets for homoglyph detection.",
        "GAN-based data generation introduces training instability and limited practical gains."
      ],
      "limitations": [
        "Dataset images are rendered with a single font (Arial) and fixed rendering settings, which may limit generalization across fonts and renderers.",
        "Homoglyphs are synthetically generated via Gaussian sampling over a glyph pool; real attacker distributions may differ.",
        "Training and evaluation are performed on the authors’ synthetic dataset; limited evidence of performance on real-world, live malicious domains.",
        "Colored renderings and conventional data augmentation degraded performance, indicating sensitivity to rendering choices and transformations.",
        "Hardware constraints limited usage to 2M real domains from a larger source list.",
        "Balanced dataset may not reflect real-world class imbalance."
      ],
      "future_work": [],
      "motivation": "Homoglyph attacks exploit visual similarity of characters to deceive users and systems; existing approaches need paired strings or are not robust, motivating an unpaired, robust, and practical detection approach alongside a large public dataset.",
      "potential_research_ideas": [
        "Collect and evaluate on real-world homoglyph domains observed in the wild (e.g., passive DNS, phishing feeds) to validate external validity.",
        "Introduce multi-font, multi-rendering pipelines (different fonts, sizes, anti-aliasing, themes) to improve robustness to font variability.",
        "Combine visual rendering with lexical, WHOIS, DNS, and hosting features in a multimodal model for improved detection.",
        "Explore self-supervised or contrastive pretraining (e.g., SimCLR/MoCo) on massive unlabeled rendered strings to reduce label dependence.",
        "Investigate transformer-based vision models (e.g., ViT, Swin) or hybrid CNN-Transformer backbones for fine-grained glyph features.",
        "Develop character-level sequence models (e.g., CNN-BiLSTM with attention) on raw Unicode/Punycode to complement image models.",
        "Evaluate cross-script coverage and robustness (Latin, Cyrillic, Greek, Armenian, etc.) and extend glyph pools accordingly.",
        "Adversarial robustness study against small rendering perturbations and adaptive attackers selecting tricky homoglyphs.",
        "Calibration and uncertainty estimation for safe deployment (e.g., threshold tuning, abstention, human-in-the-loop).",
        "Online learning/domain adaptation to evolving domain distributions and glyph strategies."
      ],
      "architectural_improvement_recommendations": [
        "Use multi-scale feature extraction with squeeze-and-excitation or improved attention (CBAM + ECA/SE, or Conformer blocks).",
        "Train with a diverse rendering ensemble (fonts, sizes, DPI) and apply test-time augmentation for stability.",
        "Incorporate contrastive objectives (supervised contrastive loss) to separate real vs. homoglyph clusters without needing explicit pairs.",
        "Add hard negative mining by synthesizing visually closest non-homoglyph domains to sharpen decision boundaries.",
        "Hybrid multimodal architecture: fuse image encoder with a text encoder over Unicode/Punycode sequences.",
        "Leverage Grad-CAM or attention rollout to provide token/region-level explanations for flagged domains."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/Akshat4112/Glyphnet",
      "frameworks": [
        "Keras",
        "TensorFlow"
      ],
      "reproducibility_score": "high",
      "computational_requirements": "Not specified; trained for 30 epochs with batch size 256 and RMSProp (lr=1e-4) on ~4M rendered images; GPU recommended."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Proposed as an API or web service to check a domain or process name prior to access",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Generalization to diverse fonts, rendering engines, and display conditions.",
        "Distribution shift from synthetic homoglyph generation to real attacker behavior.",
        "Coverage of non-Latin scripts and new glyph confusables over time.",
        "Potential class imbalance and low base rates in production.",
        "Integration with existing security pipelines (DNS/URL filtering) and managing false positives."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces GlyphNet, a benchmark dataset of 4M rendered images of real and homoglyph domains generated via Gaussian-sampled glyph substitutions.",
      "Proposes an attention-based CNN (CBAM-enhanced) that detects homoglyphs without paired inputs, achieving 0.93 AUC on their dataset.",
      "Provides public release of dataset, code, and trained models under MIT license.",
      "Empirically compares against Siamese CNN, Ensemble CNN, and PhishGAN baselines, showing higher accuracy/precision/recall/F1/AUC."
    ]
  },
  {
    "arxiv_id": "2306.11641v2",
    "title": "SALSA VERDE: a machine learning attack on Learning With Errors with sparse small secrets",
    "authors": "Cathy Yuanchen Li; Emily Wenger; Zeyuan Allen-Zhu; Francois Charton; Kristin Lauter",
    "abstract": "Learning with Errors (LWE) is a hard math problem used in post-quantum cryptography. Homomorphic Encryption (HE) schemes rely on the hardness of the LWE problem for their security, and two LWE-based cryptosystems were recently standardized by NIST for digital signatures and key exchange (KEM). Thus, it is critical to continue assessing the security of LWE and specific parameter choices. For example, HE uses secrets with small entries, and the HE community has considered standardizing small sparse secrets to improve efficiency and functionality. However, prior work, SALSA and PICANTE, showed that ML attacks can recover sparse binary secrets. Building on these, we propose VERDE, an improved ML attack that can recover sparse binary, ternary, and narrow Gaussian secrets. Using improved preprocessing and secret recovery techniques, VERDE can attack LWE with larger dimensions ($n=512$) and smaller moduli ($\\log_2 q=12$ for $n=256$), using less time and power. We propose novel architectures for scaling. Finally, we develop a theory that explains the success of ML LWE attacks.",
    "published_date": "2023-06-20",
    "pdf_link": "https://arxiv.org/pdf/2306.11641v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cryptography",
      "subdomain": "Post-Quantum Cryptanalysis",
      "specific_problem": "Machine-learning-based key recovery attack on Learning With Errors (LWE) with sparse small (binary/ternary/narrow-Gaussian) secrets",
      "attack_types": [
        "key_recovery",
        "cryptanalytic_distinguisher",
        "ML-assisted_lattice_preprocessing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Seq2Seq Transformer with 1-layer encoder (d=1024, 4 heads) and 9-layer decoder (d=512, 4 heads) with shared last 8 layers (Universal Transformer) and copy-gate",
        "novel_contribution": "Applied to LWE b-from-a prediction with specialized tokenization for modular arithmetic; paired with a new two-bit distinguisher for secret recovery"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Encoder-only BERT-like (4 layers, d=512, 4 heads) with rotary word embeddings and EMD auxiliary objective",
        "novel_contribution": "Explores simpler encoder-only alternative and compares to seq2seq for LWE; incorporates modular nature via rotary embeddings and an EMD auxiliary loss"
      },
      {
        "type": "primary",
        "category": "Other",
        "specific": "Two-bit distinguisher for ternary (and extensible to small-Gaussian) secret recovery",
        "novel_contribution": "New recovery method that compares model predictions under coordinate swaps and offset perturbations to infer relative signs/values among nonzero secret positions"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "SALSA (transformer predicting b from a with secret recovery via model queries)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Raw LWE sample pairs {(a,b)} with fixed secret",
        "type": "synthetic",
        "domain": "lwe_samples",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Preprocessed (BKZ-reduced) LWE samples",
        "type": "synthetic",
        "domain": "lwe_samples",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SALSA",
        "paper_reference": "SALS A [58] (as cited in the paper)",
        "metric": "Max dimension and secret sparsity (h), data requirement",
        "their_result": "“S ALSA is a proof of concept, recovering binary secrets with 3 or 4 nonzero bits for problems with dimension up to 128, small instances of LWE solvable via exhaustive search.”",
        "baseline_result": null
      },
      {
        "method_name": "PICANTE",
        "paper_reference": "PICANTE (as cited in the paper)",
        "metric": "Max dimension and Hamming weight (h), data requirement, preprocessing scalability",
        "their_result": "“Overall, P ICANTE can recover binary secrets for dimensions up to 350 and Hamming weight up to 60... reduces the number of LWE samples required for the attack from 4 million in S ALSA to 4n.”",
        "baseline_result": null
      },
      {
        "method_name": "uSVP lattice attack",
        "paper_reference": null,
        "metric": "Runtime vs VERDE; feasibility at given (n, q, h)",
        "their_result": "“V ERDE runs faster than uSVP attacks, at the expense of using more compute resources in parallel (see A.7).” and “We decrease the modulus q, showing V ERDE outperforming uSVP attacks (§5 and §A.7).”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "max_recovered_h (number of nonzero secret entries)",
      "secret_recovery_success_rate (e.g., 8/10)",
      "training_epoch_of_recovery",
      "preprocessing_time (hrs/CPU)",
      "training_time_per_epoch (hrs)",
      "total_attack_time (hrs)",
      "reduction_factor_of_stddev_in_preprocessing",
      "scalability (dimension n, modulus q)",
      "compute_resources (number of CPUs, GPU type/memory)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can ML models recover LWE secrets beyond sparse binary, specifically ternary and narrow-Gaussian secrets?",
        "Can improved preprocessing and recovery techniques scale ML attacks to larger dimensions (n up to 512) and smaller moduli (e.g., log2 q = 12 for n=256)?",
        "Why do ML-based LWE attacks succeed, and what properties of data/secrets drive recoverability?",
        "Can encoder-only architectures match or approach seq2seq transformers for LWE cryptanalysis?"
      ],
      "gaps_identified": [
        "Prior ML attacks (SALSA, PICANTE) focused on sparse binary secrets; lack of methods for ternary and small-Gaussian secrets.",
        "PICANTE preprocessing is costly and does not scale to n > 350; could not finish for n=512, log2 q=45 within a month even with parallelization.",
        "PICANTE relied on large moduli; practical systems often use smaller q.",
        "Out-of-distribution generalization in prior distinguishers reduced recovery reliability.",
        "Full recovery for small-Gaussian secrets is not yet implemented in VERDE (only partial recovery shown)."
      ],
      "limitations": [
        "VERDE targets medium-to-hard LWE problems and does not directly attack standardized NIST parameters or deployed schemes.",
        "Full Gaussian secret recovery not implemented; only partial recovery demonstrated.",
        "Requires substantial computational resources (hundreds of CPUs for preprocessing; V100 32GB GPU for training; 4 million preprocessed samples).",
        "Attack depends on access to many LWE samples with the same secret (assumed eavesdropped).",
        "Comparison to uSVP acknowledges VERDE uses more parallel compute, even if faster in wall-clock time."
      ],
      "future_work": [
        "Implement full recovery for small-Gaussian secrets using the proposed k-class grouping and value assignment strategy.",
        "Further scaling to larger dimensions and even smaller moduli; broader parameter sweeps.",
        "Deepen theoretical analysis (NoMod) and validate predictions across distributions and parameters.",
        "Comprehensive comparisons of encoder-only versus seq2seq architectures and improved inductive biases for modular arithmetic.",
        "Explore application to Ring-/Module-LWE settings used in deployed PQC/KEM/HE schemes."
      ],
      "motivation": "Assess and improve understanding of the security of LWE (central to HE and NIST-standardized schemes) under ML-based attacks, especially for small sparse secrets proposed for efficiency.",
      "potential_research_ideas": [
        "Complete and optimize full Gaussian secret recovery via the proposed class-based two-bit distinguisher with efficient search over class assignments.",
        "Extend VERDE to Ring-/Module-LWE to evaluate structured schemes (e.g., Kyber, Dilithium-like parameter regimes).",
        "Reduce sample complexity below 4n/2M preprocessed samples via active querying strategies for atest or semi/self-supervised objectives leveraging algebraic invariances.",
        "Introduce group-equivariant or modular-arithmetic-aware layers enforcing Z_q^n symmetries (e.g., additive cyclic group equivariance) to improve generalization and data efficiency.",
        "Develop learned or hybrid lattice reduction heuristics to replace/augment BKZ steps, trading CPU preprocessing for GPU-learned reductions.",
        "Transfer learning across (n, q, noise) regimes and curriculum training to reduce time-to-success on new parameter sets.",
        "Design and evaluate cryptographic countermeasures (e.g., secret distributions, masking, sample-limiting protocols) informed by NoMod theory."
      ],
      "architectural_improvement_recommendations": [
        "Adopt modular-arithmetic inductive biases: rotary/circular embeddings tuned to modulus q, or explicit modular addition layers.",
        "Use group-equivariant transformers or Fourier features over Z_q to capture symmetry under coordinate permutations and modular shifts.",
        "Replace seq2seq with deeper encoder-only architectures plus a specialized recovery head that jointly predicts nonzero set and sign/value (multi-task loss combining CE and contrastive invariance).",
        "Employ Mixture-of-Experts or linear-attention variants (e.g., Performer, FlashAttention-2) to scale to larger n with reduced memory.",
        "Improve tokenization beyond base-B digits (e.g., residue number system or learned discrete codes) to reduce sequence length and ease arithmetic.",
        "Integrate differentiable distinguisher objectives during training (contrastive loss under coordinate swaps/offsets) to precondition the model for recovery-time transformations."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "unspecified",
        "fplll (BKZ 2.0)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Training on one NVIDIA V100 32GB GPU; 2 million samples per epoch; ~1.5/1.6/2.5 hours per epoch for n=256/350/512; preprocessing parallelized across hundreds of CPUs (e.g., 2 million/n matrices in parallel); example preprocessing 7.5 hours/CPU per matrix for n=256, log2 q=20; number of CPU cores for full parallelization: 4 million / (2n)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires eavesdropping/collecting 4n raw LWE samples with the same secret and generating 4M preprocessed samples.",
        "Substantial CPU/GPU resources for preprocessing and training.",
        "Attack effectiveness depends on aligning training and testing distributions (in-distribution generalization).",
        "Applicability to standardized schemes not directly demonstrated; parameters differ (e.g., Ring-/Module-LWE)."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces VERDE, an improved ML attack on LWE that recovers sparse binary, ternary, and narrow-Gaussian secrets.",
      "Proposes a novel two-bit distinguisher enabling full recovery for ternary secrets and a path to full recovery for small-Gaussian secrets.",
      "Substantially improves preprocessing (reordered lattice basis, reduced precision, lower ω, interleaved BKZ 2.0 with efficient reductions, adaptive blocksize, early stopping), achieving up to 45× speedup and 20% better reduction quality.",
      "Scales attacks to larger dimensions (n=512) and smaller moduli (e.g., log2 q=12 for n=256) with reduced time/power relative to prior work.",
      "Demonstrates comparable recovery for binary and ternary secrets; partial recovery for small-Gaussian secrets.",
      "Proposes NoMod, a framework to understand why ML-based LWE attacks succeed, and provides heuristic theory that recovery depends on sqrt(h) and the data distribution’s standard deviation.",
      "Compares seq2seq vs encoder-only transformer architectures for this task.",
      "Shows VERDE outperforming uSVP attacks in runtime on tested parameters (though using more parallel compute)."
    ]
  },
  {
    "arxiv_id": "2305.16389v1",
    "title": "FIDS: Fuzzy Intrusion Detection System for simultaneous detection of DoS/DDoS attacks in Cloud computing",
    "authors": "Peyman Khordadpour; Saeed Ahmadi",
    "abstract": "In recent times, I've encountered a principle known as cloud computing, a model that simplifies user access to data and computing power on a demand basis. The main objective of cloud computing is to accommodate users' growing needs by decreasing dependence on human resources, minimizing expenses, and enhancing the speed of data access. Nevertheless, preserving security and privacy in cloud computing systems pose notable challenges. This issue arises because these systems have a distributed structure, which is susceptible to unsanctioned access - a fundamental problem. In the context of cloud computing, the provision of services on demand makes them targets for common assaults like Denial of Service (DoS) attacks, which include Economic Denial of Sustainability (EDoS) and Distributed Denial of Service (DDoS). These onslaughts can be classified into three categories: bandwidth consumption attacks, specific application attacks, and connection layer attacks. Most of the studies conducted in this arena have concentrated on a singular type of attack, with the concurrent detection of multiple DoS attacks often overlooked. This article proposes a suitable method to identify four types of assaults: HTTP, Database, TCP SYN, and DNS Flood. The aim is to present a universal algorithm that performs effectively in detecting all four attacks instead of using separate algorithms for each one. In this technique, seventeen server parameters like memory usage, CPU usage, and input/output counts are extracted and monitored for changes, identifying the failure point using the CUSUM algorithm to calculate the likelihood of each attack. Subsequently, a fuzzy neural network is employed to determine the occurrence of an attack. When compared to the Snort software, the proposed method's results show a significant improvement in the average detection rate, jumping from 57% to 95%.",
    "published_date": "2023-05-25",
    "pdf_link": "https://arxiv.org/pdf/2305.16389v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cloud Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Simultaneous detection of multiple DoS/DDoS/EDoS attack types in cloud VMs using resource-usage and traffic metrics",
      "attack_types": [
        "DoS",
        "DDoS",
        "EDoS",
        "HTTP Flood",
        "Database Query Flood",
        "TCP SYN Flood",
        "DNS Flood"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Fuzzy System / Neuro-Fuzzy",
        "specific": "Fuzzy Neural Network",
        "novel_contribution": "Combines fuzzy neural network decisioning with CUSUM-derived likelihoods over 17 VM/system metrics to jointly detect four attack types in a unified model."
      },
      {
        "type": "primary",
        "category": "Statistical Change Detection",
        "specific": "CUSUM (Cumulative Sum)",
        "novel_contribution": "Applied to time-series of 17 VM/network metrics to locate change points and estimate per-attack likelihoods (including self-starting CUSUM per Taylor)."
      },
      {
        "type": "baseline",
        "category": "Rule-based IDS",
        "specific": "Snort",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Supervised",
      "Hybrid"
    ],
    "datasets": [
      {
        "name": "Cloud VM telemetry and traffic metrics (unnamed)",
        "type": "private",
        "domain": "system_metrics_and_network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Snort (signature-based IDS)",
        "paper_reference": null,
        "metric": "Average detection rate",
        "their_result": "95%",
        "baseline_result": "57%"
      }
    ],
    "performance_metrics_used": [
      "Average detection rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a single, unified algorithm detect multiple DoS/DDoS/EDoS attack types (HTTP, Database, TCP SYN, DNS flood) in cloud environments?",
        "Do resource-usage and traffic-pattern anomalies (captured by 17 VM/system metrics) allow effective detection of such attacks?",
        "Can combining CUSUM-based change detection with a fuzzy neural network reduce false positives and false negatives compared to traditional IDS?"
      ],
      "gaps_identified": [
        "Most prior studies target a single attack type; concurrent detection of multiple DoS attacks is often overlooked.",
        "Much of the literature emphasizes mitigation/defense mechanisms rather than accurate multi-attack identification in clouds."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve precision of cloud IDS for DDOS and EDOS by leveraging deviations in resource consumption and traffic patterns and enabling simultaneous detection of multiple attack types with a single algorithm.",
      "potential_research_ideas": [
        "Create and release a standardized, labeled cloud VM telemetry + network dataset covering diverse DoS/EDoS/DDoS scenarios for benchmarking.",
        "Augment with temporal deep models (e.g., Temporal CNNs, LSTMs, Transformers) over multivariate telemetry to compare with CUSUM + fuzzy NN.",
        "Incorporate online/continual learning for non-stationary workloads and concept drift in multi-tenant clouds.",
        "Fuse packet-level features (flow/NetFlow) with VM-level telemetry via multimodal architectures.",
        "Integrate cost-aware EDoS detection with cloud billing telemetry to distinguish benign load spikes from economic attacks.",
        "Develop adaptive thresholding/auto-tuning of sensitivity based on workload seasonality and per-VM baselines.",
        "Apply explainable fuzzy rule extraction to provide operator-interpretable alerts and root-cause hints.",
        "Evaluate robustness against adversarial load patterns that mimic normal diurnal trends."
      ],
      "architectural_improvement_recommendations": [
        "Replace or complement CUSUM with robust change-point detection (e.g., Bayesian online change-point detection) to handle noise and multi-scale shifts.",
        "Use an interpretable neuro-fuzzy system (e.g., ANFIS) with rule regularization and feature selection over the 17 metrics.",
        "Add drift detection (ADWIN/EDDM) and periodic model recalibration using recent clean data windows.",
        "Calibrate per-service/VM seasonal baselines (weekly/daily patterns) before change detection to reduce false alarms.",
        "Introduce ensemble detection combining statistical detectors with supervised classifiers and a meta-learner.",
        "Incorporate feedback loop with active learning from analyst labels to reduce false positives over time."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Cloud/virtualized IaaS (hypervisor-level resource allocation path)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Accessing per-VM telemetry and packet ratios with low overhead in multi-tenant environments.",
        "Tuning sensitivity thresholds to different workloads and service criticality.",
        "Handling concept drift and legitimate traffic surges (e.g., flash crowds).",
        "Integration with hypervisor/resource scheduler without causing performance degradation.",
        "Label scarcity for supervised components and ground-truth generation."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Unified Fuzzy Intrusion Detection System (FIDS) for simultaneous detection of HTTP, Database, TCP SYN, and DNS flood attacks in cloud environments.",
      "Leverages 17 VM/network metrics; applies CUSUM to compute per-attack change likelihoods followed by a fuzzy neural network decision stage.",
      "Reports significant improvement over Snort with average detection rate increasing from 57% to 95%."
    ]
  },
  {
    "arxiv_id": "2306.13029v2",
    "title": "Decentralized Online Federated G-Network Learning for Lightweight Intrusion Detection",
    "authors": "Mert Nakıp; Baran Can Gül; Erol Gelenbe",
    "abstract": "Cyberattacks are increasingly threatening networked systems, often with the emergence of new types of unknown (zero-day) attacks and the rise of vulnerable devices. Such attacks can also target multiple components of a Supply Chain, which can be protected via Machine Learning (ML)-based Intrusion Detection Systems (IDSs). However, the need to learn large amounts of labelled data often limits the applicability of ML-based IDSs to cybersystems that only have access to private local data, while distributed systems such as Supply Chains have multiple components, each of which must preserve its private data while being targeted by the same attack To address this issue, this paper proposes a novel Decentralized and Online Federated Learning Intrusion Detection (DOF-ID) architecture based on the G-Network model with collaborative learning, that allows each IDS used by a specific component to learn from the experience gained in other components, in addition to its own local data, without violating the data privacy of other components. The performance evaluation results using public Kitsune and Bot-IoT datasets show that DOF-ID significantly improves the intrusion detection performance in all of the collaborating components, with acceptable computation time for online learning.",
    "published_date": "2023-06-22",
    "pdf_link": "https://arxiv.org/pdf/2306.13029v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Decentralized online federated intrusion detection across supply chain/IoT components without sharing raw data",
      "attack_types": [
        "Mirai botnet",
        "DoS HTTP",
        "DDoS HTTP",
        "Zero-day attacks (general motivation)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Random Neural Network / G-Network (DRNN)",
        "specific": "Deep Random Neural Network auto-associative memory",
        "novel_contribution": "Used as a lightweight auto-associative model to learn benign traffic statistics online and within a decentralized federated setting"
      },
      {
        "type": "primary",
        "category": "Rule-based statistical detector",
        "specific": "Statistical Whisker-based Benign Classifier (SWBC)",
        "novel_contribution": "Combines DRNN reconstructions with whisker thresholds and adaptive decision threshold for anomaly detection"
      },
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "Decentralized Federated Update (DFU)",
        "novel_contribution": "Peer-to-peer parameter sharing with selection of concurring nodes and closest-parameter weighted updates; re-adaptation of output layer to local data"
      },
      {
        "type": "primary",
        "category": "Optimization / Training",
        "specific": "FISTA with L1 regularization",
        "novel_contribution": "Used to learn nonnegative hidden-layer weights for DRNN from benign traffic"
      },
      {
        "type": "primary",
        "category": "Shallow model / Linear solver",
        "specific": "Extreme Learning Machine (pseudo-inverse for output layer)",
        "novel_contribution": "Used to compute DRNN output-layer weights and to re-adapt after federated updates"
      },
      {
        "type": "baseline",
        "category": "Local-only learning",
        "specific": "No Federated (local learning only)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Federated parameter averaging",
        "specific": "Average over All Collaborating Nodes",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Federated parameter averaging",
        "specific": "Average with Closest Node (ACN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Federated parameter averaging",
        "specific": "Average with Closest Node per Layer (ACN-L)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised (auto-associative/one-class anomaly detection on benign-only data)",
      "Online Learning",
      "Federated Learning (decentralized, peer-to-peer)"
    ],
    "datasets": [
      {
        "name": "Kitsune (Mirai Botnet subset)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Bot-IoT (DoS HTTP subset)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Bot-IoT (DDoS HTTP subset)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "No Federated (local learning only)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Average over All Collaborating Nodes",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Average with Closest Node (ACN)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Average with Closest Node per Layer (ACN-L)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "ML-based IDS typically require large labeled datasets, which many components cannot share due to privacy and competitive concerns",
        "Centralized FL approaches may require a server-side validation set, potentially violating user data privacy",
        "Attack distributions and traffic characteristics vary across supply chain components; need to share learning without sharing raw data"
      ],
      "limitations": [
        "Assumes instantaneous peer-to-peer parameter exchange; communication time, bandwidth, and energy costs not analyzed",
        "Relies on synchronized time windows across nodes",
        "Evaluation limited to three attack scenarios (Mirai, DoS HTTP, DDoS HTTP) and three simple traffic statistics",
        "Cold-start assumes initial benign-only periods for training"
      ],
      "future_work": [
        "Analyze time, bandwidth, and energy requirements of the P2P parameter exchange in the DOF-ID architecture"
      ],
      "motivation": "Enable components of distributed systems (e.g., supply chains) to collaboratively improve intrusion detection by sharing learned model parameters, not raw data, thereby preserving privacy and addressing scarcity of labeled data and variability in attacks.",
      "potential_research_ideas": [
        "Incorporate richer feature sets (flow-based, temporal, protocol-specific) to improve detection while keeping the model lightweight",
        "Personalized federated learning that adapts aggregation weights based on node similarity, trust, or performance",
        "Robustness against poisoning and backdoor attacks on parameter exchanges, including anomaly detection on received updates",
        "Asynchronous decentralized FL to handle unsynchronized windows and variable communication delays",
        "Integrate privacy guarantees such as secure aggregation and differential privacy for shared parameters",
        "Concept drift detection and adaptive thresholds to handle changing traffic patterns",
        "Graph-based modeling of collaborating nodes to exploit network relationships in aggregation (e.g., GNN over node graph)",
        "Evaluate and extend to multi-class attack categorization beyond binary intrusion decisions"
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment DRNN with temporal models (e.g., lightweight RNN/LSTM/Temporal CNN) to capture sequence dynamics",
        "Use attention mechanisms for feature weighting and adaptive thresholding in SWBC",
        "Introduce trust-weighted or similarity-weighted aggregation instead of nearest-neighbor per-parameter selection",
        "Apply update compression and sparsification to reduce P2P communication overhead",
        "Add uncertainty estimation (e.g., Bayesian layers) to calibrate intrusion probabilities and reduce false alarms",
        "Incorporate formal privacy mechanisms (secure aggregation, DP) into DFU",
        "Move from fixed c parameter to learnable or adaptive aggregation coefficients per layer/parameter"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Experiments on a machine with Apple M1 Pro 8-core 3.2 GHz CPU and 16 GB RAM; authors report acceptable computation time for online learning"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "IoT/supply chain components simulated via public network-traffic datasets",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Synchronization of time windows across nodes",
        "Communication overhead and latency for P2P parameter exchange",
        "Cold-start requirement for benign-only initial training",
        "Potential vulnerability of parameter exchange to adversarial manipulation",
        "Selection/tuning of aggregation coefficient c and concurrence threshold Θ"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes DOF-ID: a Decentralized and Online Federated Learning architecture for IDS across multiple components",
      "Introduces DFU: a decentralized federated update algorithm using concurring-node selection and closest-parameter weighted updates",
      "Implements a lightweight IDS combining DRNN auto-associative memory with a Statistical Whisker-based Benign Classifier",
      "Demonstrates improvement over local-only learning and federated averaging baselines on Kitsune and Bot-IoT subsets with acceptable computation time",
      "Preserves data privacy by sharing only model parameters between nodes, not raw data"
    ]
  },
  {
    "arxiv_id": "2306.12643v1",
    "title": "FLAG: Finding Line Anomalies (in code) with Generative AI",
    "authors": "Baleegh Ahmad; Benjamin Tan; Ramesh Karri; Hammond Pearce",
    "abstract": "Code contains security and functional bugs. The process of identifying and localizing them is difficult and relies on human labor. In this work, we present a novel approach (FLAG) to assist human debuggers. FLAG is based on the lexical capabilities of generative AI, specifically, Large Language Models (LLMs). Here, we input a code file then extract and regenerate each line within that file for self-comparison. By comparing the original code with an LLM-generated alternative, we can flag notable differences as anomalies for further inspection, with features such as distance from comments and LLM confidence also aiding this classification. This reduces the inspection search space for the designer. Unlike other automated approaches in this area, FLAG is language-agnostic, can work on incomplete (and even non-compiling) code and requires no creation of security properties, functional tests or definition of rules. In this work, we explore the features that help LLMs in this classification and evaluate the performance of FLAG on known bugs. We use 121 benchmarks across C, Python and Verilog; with each benchmark containing a known security or functional weakness. We conduct the experiments using two state of the art LLMs in OpenAI's code-davinci-002 and gpt-3.5-turbo, but our approach may be used by other models. FLAG can identify 101 of the defects and helps reduce the search space to 12-17% of source code.",
    "published_date": "2023-06-22",
    "pdf_link": "https://arxiv.org/pdf/2306.12643v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection",
      "specific_problem": "Language-agnostic line-level vulnerability/bug localization in source code via LLM-based self-comparison",
      "attack_types": [
        "CWE-125 Out-of-Bounds Read",
        "Functional defects (non-security)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "OpenAI code-davinci-002 (Codex)",
        "novel_contribution": "Used within FLAG to regenerate each line from surrounding context; differences to original are scored (Levenshtein distance, BLEU-1 for comments, average logprob, distance-from-comment) to flag anomalous lines."
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "OpenAI gpt-3.5-turbo",
        "novel_contribution": "Used in auto-complete and instructed-complete modes for line regeneration and anomaly scoring within FLAG."
      },
      {
        "type": "baseline",
        "category": "Prompting modes",
        "specific": "code-davinci-002: auto-complete vs insertion (suffix)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Prompting modes",
        "specific": "gpt-3.5-turbo: auto-complete vs instructed-complete",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Zero-shot prompting",
      "Heuristic/unsupervised anomaly detection"
    ],
    "datasets": [
      {
        "name": "121-code-benchmarks (C, Python, Verilog) with known security or functional weaknesses",
        "type": "proprietary",
        "domain": "source_code (C, Python, Verilog)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Aizu Online Judge (AOJ)",
        "type": "public",
        "domain": "programming_submissions/source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "QuixBugs",
        "type": "public",
        "domain": "algorithmic_code_snippets (multiple languages)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Number of defects identified (e.g., 101/121)",
      "Search space reduction (% of source lines flagged; 12–17%)",
      "Levenshtein distance (for code line difference)",
      "BLEU-1 (for comment difference)",
      "Average token logprob from LLM (confidence; when available)",
      "Distance from nearest preceding comment"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can the intent conveyed by source code and comments be used with LLMs to flag problems in code, narrowing the extent of manual review needed?",
        "If buggy lines are a minority, can an LLM judge whether a given line is an outlier compared to its context?",
        "What features (e.g., distance to comments, LLM confidence) help LLMs classify lines as buggy or not?"
      ],
      "gaps_identified": [
        "Static detectors require extensive language-specific rules/patterns and typically need compilable/complete code, limiting early-stage detection.",
        "Unit tests require functional specifications and often have limited coverage; they do not necessarily assure security.",
        "Prior ML-based bug detectors often target niche languages/bug types or require test cases; generalizable, language-agnostic methods are lacking.",
        "Formal tools for hardware RTL can miss many security bugs, motivating alternative approaches.",
        "Public API for some LLMs (e.g., gpt-3.5-turbo) does not expose token logprobs needed for confidence features."
      ],
      "limitations": [
        "Context window constraints necessitate truncating prefix/suffix to 50 lines.",
        "LLMs may return empty lines or comments when code is desired, requiring retry heuristics.",
        "logprob features unavailable for gpt-3.5-turbo via the public API.",
        "BLEU-2/3/4 provided negligible signal for comments; only BLEU-1 was useful.",
        "Requires a chosen starting line (after headers/decls) and preprocessing to skip empty lines; heuristics may affect coverage."
      ],
      "future_work": [],
      "motivation": "Reduce human debugging/search effort by leveraging LLM lexical capabilities to highlight anomalous code lines without requiring tests, rules, compilable code, or language-specific tooling.",
      "potential_research_ideas": [
        "Train a lightweight supervised ranker/classifier over FLAG features (ld, BLEU-1, dfc, logprob) to improve prioritization of flagged lines across languages.",
        "Use multi-sample generation (e.g., self-consistency/ensemble of completions) and consensus-based anomaly scoring to reduce false positives.",
        "Incorporate AST-aware or token-level edit distances and semantic similarity to better capture meaningful code differences.",
        "Extend from line-level to block/function-level regeneration to detect multi-line defects and context-dependent issues.",
        "Integrate FLAG with static analysis (AST/data-flow) to cross-validate anomalies and reduce search space further.",
        "Leverage newer LLMs with longer context windows to include more file context and cross-file information.",
        "Augment comment-code alignment with NL-code entailment models for stronger comment-based anomaly signals.",
        "Apply the approach to RTL/hardware code with security-focused feature engineering and validation on hardware CWE datasets.",
        "Calibrate thresholds and features per language and project using small amounts of historical defect data.",
        "Extend FLAG to suggest candidate patches (repair) once an anomalous line is identified, evaluating minimal-diff fixes."
      ],
      "architectural_improvement_recommendations": [
        "Adopt multi-sample decoding (n>1, temperature>0) with agreement scoring; compute per-token anomaly scores for finer-grained highlights.",
        "Incorporate AST parsing to compare structural edits and ignore formatting-only differences; combine with semantic code embeddings.",
        "Use larger-context LLMs and retrieval of project-wide code/comments to provide richer prompts.",
        "Add a learning-to-rank layer trained on labeled anomalies to set adaptive thresholds for ld/BLEU/logprob by language/file type.",
        "Replace BLEU with modern NL similarity/entailment metrics (e.g., sentence embeddings) for comment-code consistency.",
        "Cache and reuse model responses across files/functions to reduce cost and improve scalability; implement prompt optimization.",
        "Where available, use logprob APIs; otherwise approximate confidence via entropy of next-token distributions from open models."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "OpenAI API"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Prompt/context window limits necessitate truncating prefix/suffix to 50 lines.",
        "LLM outputs can be empty or comments instead of code, requiring retries/heuristics.",
        "Line-by-line processing may be costly for large files; careful batching/caching needed."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces FLAG, a language-agnostic LLM-based framework that regenerates each line of code from context and flags anomalies via self-comparison.",
      "Explores and analyzes features (Levenshtein distance, BLEU-1 for comments, distance from comments, average logprob) and LLM prompting modes across languages.",
      "Empirical evaluation on 121 benchmarks (C, Python, Verilog) with known defects; reports identifying 101 defects and reducing inspection search space to 12–17%.",
      "Open-sources the tool and results (reference [32])."
    ]
  },
  {
    "arxiv_id": "2306.04479v1",
    "title": "Vulnerable Smart Contract Function Locating Based on Multi-Relational Nested Graph Convolutional Network",
    "authors": "Haiyang Liu; Yuqi Fan; Lin Feng; Zhenchun Wei",
    "abstract": "The immutable and trustable characteristics of blockchain enable smart contracts to be applied in various fields. Unfortunately, smart contracts are subject to various vulnerabilities, which are frequently exploited by attackers, causing financial damage to users.In this paper, we study the problem of vulnerable smart contract function locating. We construct a novel Multi-Relational Nested contract Graph (MRNG) to better characterize the rich syntactic and semantic information in the smart contract code, including the relationships between data and instructions. An MRNG represents a smart contract, where each node represents a function in the smart contract and each edge describes the calling relationship between the functions. In addition, we create a Multi-Relational Function Graph (MRFG) for each function, which characterizes the corresponding function code. That is, each function is characterized as an MRFG, which corresponds to a node in the MRNG. Each MRFG uses different types of edges to represent the different control and data relationships between nodes within a function. We also propose a Multi-Relational Nested Graph Convolutional Network (MRN-GCN) to process the MRNG. MRN-GCN first extracts and aggregates features from each MRFG, using the edge-enhanced graph convolution network and self-attention mechanism. The extracted feature vector is then assigned to the corresponding node in the MRNG to obtain a new Featured Contract Graph (FCG) for the smart contract. Graph convolution is used to further extract features from the FCG. Finally, a feed forward network with a Sigmoid function is used to locate the vulnerable functions. Experimental results on the real-world smart contract datasets show that model MRN-GCN can effectively improve the accuracy, precision, recall and F1-score performance of vulnerable smart contract function locating.",
    "published_date": "2023-06-07",
    "pdf_link": "https://arxiv.org/pdf/2306.04479v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Security",
      "specific_problem": "Vulnerable smart contract function locating (function-level vulnerability detection)",
      "attack_types": [
        "Arithmetic (integer overflow/underflow)",
        "Reentrancy",
        "Timestamp Dependency"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Multi-Relational Nested Graph Convolutional Network (MRN-GCN)",
        "novel_contribution": "Hierarchical/nested message passing over a Multi-Relational Nested contract Graph (MRNG): per-function Multi-Relational Function Graphs (MRFGs) processed first, aggregated into a Featured Contract Graph (FCG) at contract level, then graph convolution for function-level classification."
      },
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Edge-enhanced GCN",
        "novel_contribution": "Uses multiple edge types to encode control and data relationships within functions for richer relational modeling."
      },
      {
        "type": "primary",
        "category": "Attention",
        "specific": "Self-attention",
        "novel_contribution": "Aggregates node features within MRFGs to emphasize important statements/relations before contract-level propagation."
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": "Feed-forward network with Sigmoid output",
        "novel_contribution": "Binary classification at function level to locate vulnerable functions."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Unspecified real-world smart contract datasets (three vulnerability types)",
        "type": "unknown",
        "domain": "smart_contract_source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "unspecified"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: How to effectively represent the syntactic and semantic information inside a smart contract function?",
        "RQ2: How to describe the impact of invocation relationships between functions in a smart contract on the vulnerability of functions?",
        "RQ3: How to design a neural network that can effectively extract the syntactic and semantic features within and between smart contract functions?"
      ],
      "gaps_identified": [
        "Prior methods miss complex relationships between instructions and data (e.g., statement order, variable data types, control structures) when representing code.",
        "Processing each function independently ignores invocation/call relationships that can cause or influence vulnerabilities across functions.",
        "Stacking many GCN layers can dilute local node features due to over-aggregation, making it hard to balance local and global features."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Enable fine-grained (function-level) vulnerability detection for smart contracts by capturing rich intra-function relations and inter-function call dependencies to improve auditing and debugging efficiency.",
      "potential_research_ideas": [
        "Extend from binary vulnerable/non-vulnerable to multi-label or multi-class detection that identifies specific vulnerability types per function.",
        "Cross-contract and library-level analysis that models external calls and dependencies to capture vulnerabilities spanning multiple contracts.",
        "Integrate dynamic traces (execution paths, symbolic/fuzz traces) with static MRFGs for hybrid graph representations.",
        "Self-supervised or contrastive pretraining on large unlabeled smart contract corpora to improve feature quality under label scarcity.",
        "Incorporate bytecode-level graphs and source-level graphs jointly with alignment to be resilient to missing source code.",
        "Explainability modules (e.g., attention roll-out, GNNExplainer) to highlight statements/edges responsible for vulnerability predictions.",
        "Adversarial robustness evaluation and defenses (evasion/poisoning) tailored to code graphs.",
        "Active learning or weak supervision to reduce labeling cost for function-level vulnerability annotations."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment edge-enhanced GCN with relational graph attention networks (R-GAT) or GINE to better leverage typed edges and mitigate over-smoothing.",
        "Introduce hierarchical pooling/readout (e.g., DiffPool/HierPool) from MRFG to MRNG with residual connections and normalization to preserve local features.",
        "Use bi-level message passing with cross-level attention between MRFG nodes and MRNG nodes for richer interaction.",
        "Add multi-task heads for both vulnerability presence and type classification with class-imbalance handling (focal loss, calibrated thresholds).",
        "Use positional/structural encodings (shortest-path distance, control-depth, dominance frontier features) as node/edge attributes.",
        "Calibrate outputs (temperature scaling) for reliable decision thresholds in audits; report per-function inference confidence."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a Multi-Relational Nested contract Graph (MRNG) where nodes are functions and edges are function-call relations; each function is represented as a Multi-Relational Function Graph (MRFG) encoding control and data relationships with typed edges.",
      "Introduces MRN-GCN, a nested GNN that first extracts features from each MRFG using edge-enhanced graph convolution and self-attention, assigns these to the corresponding MRNG node to form a Featured Contract Graph (FCG), and then performs contract-level graph convolution for function-level classification.",
      "Demonstrates improved accuracy, precision, recall, and F1-score for locating vulnerable functions on real-world smart contract datasets for Arithmetic, Reentrancy, and Timestamp Dependency vulnerabilities."
    ]
  },
  {
    "arxiv_id": "2306.06824v2",
    "title": "SE#PCFG: Semantically Enhanced PCFG for Password Analysis and Cracking",
    "authors": "Yangde Wang; Weidong Qiu; Peng Tang; Hao Tian; Shujun Li",
    "abstract": "Much research has been done on user-generated textual passwords. Surprisingly, semantic information in such passwords remain under-investigated, with passwords created by English- and/or Chinese-speaking users being more studied with limited semantics. This paper fills this gap by proposing a general framework based on semantically enhanced PCFG (probabilistic context-free grammars) named SE#PCFG. It allowed us to consider 43 types of semantic information, the richest set considered so far, for password analysis. Applying SE#PCFG to 17 large leaked password databases of user speaking four languages (English, Chinese, German and French), we demonstrate its usefulness and report a wide range of new insights about password semantics at different levels such as cross-website password correlations. Furthermore, based on SE#PCFG and a new systematic smoothing method, we proposed the Semantically Enhanced Password Cracking Architecture (SEPCA), and compared its performance against three SOTA (state-of-the-art) benchmarks in terms of the password coverage rate: two other PCFG variants and neural network. Our experimental results showed that SEPCA outperformed all the three benchmarks consistently and significantly across 52 test cases, by up to 21.53%, 52.55% and 7.86%, respectively, at the user-level (with duplicate passwords). At the level of unique passwords, SEPCA also beats the three counterparts by up to 43.83%, 94.11% and 11.16%, respectively.",
    "published_date": "2023-06-12",
    "pdf_link": "https://arxiv.org/pdf/2306.06824v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Authentication and Access Control",
      "subdomain": "Password Security / Cracking",
      "specific_problem": "Modeling and exploiting semantic information in user-generated passwords to improve password analysis and offline password guessing coverage",
      "attack_types": [
        "offline_password_cracking",
        "password_guessing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "PCFG",
        "specific": "Semantically Enhanced PCFG (SE#PCFG)",
        "novel_contribution": "General framework that incorporates 43 semantic factor types (SFTs) across four languages; supports multi-level semantic modeling (characters, semantic factors, semantic patterns, semantic structure)."
      },
      {
        "type": "primary",
        "category": "Probabilistic Smoothing",
        "specific": null,
        "novel_contribution": "New general and systematic smoothing method to account for unobserved but plausible passwords within the PCFG/SEPCA pipeline."
      },
      {
        "type": "primary",
        "category": "NLP",
        "specific": "NLTK-based segmentation and POS tagging",
        "novel_contribution": "Integrated use of multiple corpora (e.g., Wikipedia, Wiktionary, Urban Dictionary) and scoring to disambiguate and identify semantic factors within L-segments for multilingual passwords."
      },
      {
        "type": "baseline",
        "category": "PCFG",
        "specific": "Weir et al.’s original/updated PCFG implementation",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "PCFG",
        "specific": "Veras et al.’s Semantic PCFG",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "n-gram language model",
        "specific": "FLA (Fast, Lean, and Accurate) [as described by the paper]",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "CSDN",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Tianya",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "7K7K",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "17173",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "178",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Dodonew",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Twitter",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Webhost",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "RockYou",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MyHeritage",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Gmail",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "8Fit",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Eyeem",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Ge Mix1",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Fr Mix1",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Fr Mix2",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Fr Mix3",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Weir et al.’s PCFG (latest implementation)",
        "paper_reference": "[15], [16] per the paper",
        "metric": "Coverage rate (user-level and unique-password-level) under 5×10^9 guesses across 52 test cases",
        "their_result": "“SEPCA outperformed… by up to 21.53% (user-level), 43.83% (password-level)”",
        "baseline_result": null
      },
      {
        "method_name": "Veras et al.’s Semantic PCFG",
        "paper_reference": "[9], [28] per the paper",
        "metric": "Coverage rate (user-level and unique-password-level) under 5×10^9 guesses across 52 test cases",
        "their_result": "“SEPCA outperformed… by up to 52.55% (user-level), 94.11% (password-level)”",
        "baseline_result": null
      },
      {
        "method_name": "FLA (Fast, Lean, and Accurate)",
        "paper_reference": "[17] per the paper",
        "metric": "Coverage rate (user-level and unique-password-level) under 5×10^9 guesses across 52 test cases",
        "their_result": "“SEPCA also outperformed FLA by up to 7.86% (user-level) and 11.16% (password-level) averagely.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "coverage rate",
      "user-level coverage",
      "unique-password-level coverage",
      "fixed guess budget (5×10^9 guesses)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How can rich, multilingual semantic information be systematically incorporated into PCFGs for password analysis and cracking?",
        "What semantic patterns exist across passwords in different languages (English, Chinese, German, French)?",
        "Are there quantifiable cross-website semantic correlations in user-generated passwords?",
        "Can a general smoothing method improve generalization to unobserved but plausible passwords and enhance cracking coverage?"
      ],
      "gaps_identified": [
        "Semantic information in passwords is under-investigated beyond English/Chinese; prior work considered limited semantics.",
        "Lack of a reconfigurable, general framework to integrate diverse semantic elements for password analysis.",
        "Little quantitative analysis of cross-site semantic correlations.",
        "Limited application of smoothing in PCFG methods to cover unobserved but plausible passwords."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Textual passwords remain dominant; need to better understand user-generated password semantics across languages and improve cracking effectiveness via semantic modeling and smoothing.",
      "potential_research_ideas": [
        "Extend SE#PCFG to more languages (e.g., Spanish, Arabic, Russian) and scripts (e.g., Cyrillic, Arabic) with additional semantic factor types.",
        "Leverage knowledge graphs (e.g., Wikidata) to model relationships between entities in passwords (names, places, brands) for better generalization.",
        "Temporal analysis of semantic drift across sites and time to build time-aware semantic priors for cracking.",
        "User-segment-aware modeling (e.g., by region/website type) to condition semantic patterns for targeted guessing under ethical constraints.",
        "Hybrid neural-PCFG models where neural components score or propose semantic factor combinations while grammar ensures interpretability.",
        "Active/online learning to adapt semantic priors from partial feedback (e.g., breached subsets) while preserving ethics/privacy.",
        "Automatic discovery of new SFTs via unsupervised segmentation on emerging slang/abbreviations and validation against open corpora.",
        "Integrate homograph/leet and Pinyin/romanization variants systematically via phonetic or transliteration models.",
        "Investigate defenses: semantic-aware password strength meters and training that detect risky semantic compositions."
      ],
      "architectural_improvement_recommendations": [
        "Replace hand-crafted smoothing with Bayesian hierarchical smoothing (e.g., Dirichlet priors per SFT/SP) learned from data.",
        "Introduce a trainable scorer over semantic patterns using calibrated likelihoods combining grammar probabilities and corpus-derived priors.",
        "Neural proposal mechanism (e.g., n-gram/RNN/Transformer) to suggest candidate SPs/SFs, filtered and ordered by the PCFG for explainability.",
        "Multilingual tokenizer and language-ID module to route L-segments to appropriate corpora and taggers; ensemble tagging across languages.",
        "Parallelized candidate enumeration and caching with GPU/accelerator support to scale beyond 5×10^9 guesses.",
        "Adaptive website-type and language-conditioned priors within SEPCA to tailor guesses per target setting.",
        "Automatic SFT induction from corpora using statistical tests and subword models (e.g., BPE) with human-in-the-loop validation."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "NLTK"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "SE#PCFG: a semantically enhanced PCFG framework covering 43 semantic factor types across English, Chinese, German, and French.",
      "Systematic, streamlined computational process for identifying semantic factors, including mixed-type SFTs and multilingual NLP segmentation/tagging.",
      "Empirical semantic analysis over 17 large leaked password databases (≈310M passwords), revealing new insights including cross-website correlations.",
      "SEPCA: Semantically Enhanced Password Cracking Architecture with a new general smoothing method to handle unobserved but plausible passwords.",
      "Extensive evaluation on 52 train-target test cases with a fixed guess budget (5×10^9), showing consistent and significant coverage improvements over two PCFG variants and FLA.",
      "Asserts the richest set of semantic elements and the largest multilingual dataset collection for this line of research to date (per authors)."
    ]
  },
  {
    "arxiv_id": "2306.14168v1",
    "title": "FastBCSD: Fast and Efficient Neural Network for Binary Code Similarity Detection",
    "authors": "Chensen Huang; Guibo Zhu; Guojing Ge; Taihao Li; Jinqiao Wang",
    "abstract": "Binary code similarity detection (BCSD) has various applications, including but not limited to vulnerability detection, plagiarism detection, and malware detection. Previous research efforts mainly focus on transforming binary code to assembly code strings using reverse compilation and then using pre-trained deep learning models with large parameters to obtain feature representation vector of binary code. While these models have proven to be effective in representing binary code, their large parameter size leads to considerable computational expenses during both training and inference. In this paper, we present a lightweight neural network, called FastBCSD, that employs a dynamic instruction vector encoding method and takes only assembly code as input feature to achieve comparable accuracy to the pre-training models while reducing the computational resources and time cost.   On the BinaryCorp dataset, our method achieves a similar average MRR score to the state-of-the-art pre-training-based method (jTrans), while on the BinaryCorp 3M dataset, our method even outperforms the latest technology by 0.01. Notably, FastBCSD has a much smaller parameter size (13.4M) compared to jTrans (87.88M), and its latency time is 1/5 of jTrans on NVIDIA GTX 1080Ti.",
    "published_date": "2023-06-25",
    "pdf_link": "https://arxiv.org/pdf/2306.14168v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Binary Analysis",
      "specific_problem": "Binary code similarity detection across compiler optimization levels using assembly input only",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "TextCNN (Siamese architecture)",
        "novel_contribution": "Dynamic instruction vector encoding (opcode + operands + instruction position) fed to a lightweight Siamese TextCNN with cosine loss; achieves comparable MRR to pre-trained Transformers with far fewer parameters and lower latency"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM (Siamese)",
        "novel_contribution": "Alternative extractor within FastBCSD pipeline operating on dynamic instruction vectors"
      },
      {
        "type": "primary",
        "category": "MLP-Mixer",
        "specific": "Modified MLP-Mixer (token-mixing and channel-mixing MLPs)",
        "novel_contribution": "Adapted MLP-Mixer from vision to BCSD by removing per-patch linear embeddings and directly consuming instruction-level embeddings"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "jTrans (BERT-like)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "PalmTree (BERT-based pretraining with MLM/CWP/DUP)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "UniASM (UniLM-inspired)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "SAFE (instruction-as-token embeddings + deep model)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "word2vec+CNN",
        "specific": "Instruction2Vec",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Doc2Vec-like",
        "specific": "Asm2Vec (PV-DM-style)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "Gemini (ACFG + graph embedding)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "handcrafted+GNN",
        "specific": "Genius",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN on raw bytes",
        "specific": "αDiff",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN + pretraining",
        "specific": "OrderMatters (semantic-aware + CNN over CFG adjacency)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "BinaryCorp-3M",
        "type": "public",
        "domain": "assembly_functions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "BinaryCorp-26M",
        "type": "public",
        "domain": "assembly_functions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "BinaryCorp (overall corpus)",
        "type": "public",
        "domain": "binary_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "jTrans",
        "paper_reference": "jTrans (Transformer-based BCSD introducing BinaryCorp)",
        "metric": "Average MRR (BinaryCorp)",
        "their_result": "Similar to jTrans; on BinaryCorp-3M outperforms by 0.01",
        "baseline_result": null
      },
      {
        "method_name": "jTrans",
        "paper_reference": "jTrans (Transformer-based BCSD)",
        "metric": "Recall@1 (function pool size=32, BinaryCorp-3M)",
        "their_result": "Similar to jTrans",
        "baseline_result": "0.538 (recalculated by authors from jTrans table)"
      },
      {
        "method_name": "jTrans",
        "paper_reference": "jTrans (Transformer-based BCSD)",
        "metric": "Parameter count (millions)",
        "their_result": "13.4",
        "baseline_result": "87.88"
      },
      {
        "method_name": "jTrans",
        "paper_reference": "jTrans (Transformer-based BCSD)",
        "metric": "Latency (GTX 1080Ti)",
        "their_result": "1/5 of jTrans",
        "baseline_result": "1x"
      },
      {
        "method_name": "PalmTree",
        "paper_reference": "PalmTree (BERT-based assembly pretraining)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "UniASM",
        "paper_reference": "UniASM (UniLM-inspired assembly model)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "SAFE",
        "paper_reference": "SAFE",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Instruction2Vec",
        "paper_reference": "Instruction2Vec",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Asm2Vec",
        "paper_reference": "Asm2Vec",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Gemini",
        "paper_reference": "Gemini",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Genius",
        "paper_reference": "Genius",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "OrderMatters",
        "paper_reference": "OrderMatters",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "MRR",
      "Recall@k",
      "Recall@1"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a lightweight neural network using only assembly code achieve comparable accuracy to pre-trained Transformer-based BCSD models while greatly reducing computation?",
        "How to avoid the Transformer's 512-token input limit and mitigate OOV without heavy token normalization in BCSD?"
      ],
      "gaps_identified": [
        "Large parameter sizes of BERT/Transformer-based BCSD models hinder real-world deployment",
        "Transformer input length limit (512 tokens) causes information loss for long functions",
        "Excessive token normalization to address OOV can result in information loss"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Develop faster and more efficient BCSD by reducing computational cost and time while maintaining accuracy, and by addressing Transformer sequence length limits and OOV issues.",
      "potential_research_ideas": [
        "Self-supervised or contrastive pretraining tailored to dynamic instruction vectors to further improve accuracy without large models",
        "Cross-architecture and cross-compiler generalization studies (e.g., x86, ARM, MIPS) using the FastBCSD pipeline",
        "Hybrid representations combining instruction-level encoding with control-flow or data-flow (CFG/DFG) features",
        "Knowledge distillation from large pre-trained models (e.g., jTrans) into FastBCSD for additional gains",
        "Tokenization improvements (e.g., subword/BPE for operands) to reduce vocabulary while preserving semantics",
        "Hard negative mining and curriculum strategies to improve Siamese training effectiveness",
        "ANN-based large-scale retrieval pipeline integration for industry-scale function search"
      ],
      "architectural_improvement_recommendations": [
        "Add attention or gated pooling over instruction vectors to better aggregate global context",
        "Introduce hierarchical modeling (instruction -> basic block -> function) with multi-scale CNNs",
        "Incorporate residual or squeeze-and-excitation blocks in TextCNN to enhance feature extraction with minimal parameter increase",
        "Use in-batch hard negative mining and margin scheduling for the cosine loss",
        "Explore lightweight positional encodings and learnable instruction-type embeddings",
        "Quantization and pruning for further latency and memory reduction without accuracy loss",
        "Multi-task objectives (e.g., opcode prediction or lightweight DUP) to regularize representations"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Training/inference on Intel Xeon 10-core 2.20GHz CPU, 256GB RAM, 1× NVIDIA GTX 1080Ti; ~50M training pairs (positive:negative ≈1:19); embeddings dim=192; TextCNN with 6 conv kernels (sizes 5×4 and 3×2), stride=1; batch size 384; LR=0.001; 1 epoch"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "Latency is 1/5 of jTrans on NVIDIA GTX 1080Ti",
      "deployment_challenges": [
        "Large-scale pair sampling and training set construction (50M pairs) can be resource-intensive",
        "Evaluation and retrieval at very large function pool sizes require efficient indexing (tested up to pool size 10,000)",
        "Handling very long functions still requires threshold K for per-instruction tokens (possible information truncation)"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposed FastBCSD with dynamic instruction vector encoding (opcode, operands, position) whose sequence length scales with number of instructions, mitigating Transformer 512-token limits and OOV issues",
      "Lightweight Siamese TextCNN achieving similar average MRR to jTrans and +0.01 on BinaryCorp-3M with far fewer parameters (13.4M vs 87.88M) and 1/5 latency on GTX 1080Ti",
      "Token mining with delimiter-based splitting and frequency filtering (F=32) to preserve semantics without heavy normalization (~40k vocabulary)",
      "Adapted MLP-Mixer architecture to BCSD and compared TextCNN, LSTM, and MLP-Mixer within a unified pipeline",
      "Detailed sampling strategy and training setup for large-scale supervised BCSD using BinaryCorp"
    ]
  },
  {
    "arxiv_id": "2306.08116v1",
    "title": "CipherSniffer: Classifying Cipher Types",
    "authors": "Brendan Artley; Greg Mehdiyev",
    "abstract": "Ciphers are a powerful tool for encrypting communication. There are many different cipher types, which makes it computationally expensive to solve a cipher using brute force. In this paper, we frame the decryption task as a classification problem. We first create a dataset of transpositions, substitutions, text reversals, word reversals, sentence shifts, and unencrypted text. Then, we evaluate the performance of various tokenizer-model combinations on this task.",
    "published_date": "2023-06-13",
    "pdf_link": "https://arxiv.org/pdf/2306.08116v1",
    "paper_types": [
      "empirical_analysis",
      "benchmark",
      "new_dataset"
    ],
    "security_domain": {
      "primary": "Cryptography",
      "subdomain": "Cryptanalysis",
      "specific_problem": "Cipher type classification from ciphertext",
      "attack_types": [
        "Substitution cipher",
        "Transposition cipher",
        "Text reversal",
        "Character shift (Caesar-like)",
        "Word reversal",
        "Unencrypted detection"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT (uncased)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "GRU",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Embedding",
        "specific": "GloVe (pre-trained, frozen)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Embedding",
        "specific": "GloVe (trained on cipher corpus)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Tokenizer",
        "specific": "WordPiece (pre-trained)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Tokenizer",
        "specific": "WordPiece (trained)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Tokenizer",
        "specific": "Byte-Pair Encoding (BPE)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Tokenizer",
        "specific": "Character-level",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Tokenizer",
        "specific": "Word-level",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CipherSniffer CipherData (6-class synthetic ciphers over Gigaword summaries)",
        "type": "synthetic",
        "domain": "encrypted_text",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "English Gigaword (summaries only, cleaned to lowercase ASCII)",
        "type": "public",
        "domain": "text_news_summaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GRU + GloVe (trained on cipher corpus, word-level)",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "97.00%"
      },
      {
        "method_name": "LSTM + BPE (subword)",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "95.76%"
      },
      {
        "method_name": "LSTM + WordPiece (pre-trained, subword)",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "95.68%"
      },
      {
        "method_name": "GRU + WordPiece (pre-trained, subword)",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "95.68%"
      },
      {
        "method_name": "GRU + WordPiece (trained, subword)",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "95.64%"
      },
      {
        "method_name": "GRU + BPE (subword)",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "95.60%"
      },
      {
        "method_name": "LSTM + WordPiece (trained, subword)",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "95.56%"
      },
      {
        "method_name": "LSTM + GloVe (trained, word-level)",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "95.36%"
      },
      {
        "method_name": "LSTM + Character-level",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "90.48%"
      },
      {
        "method_name": "GRU + GloVe (pre-trained, frozen, word-level)",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "88.72%"
      },
      {
        "method_name": "GRU + Character-level",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "88.32%"
      },
      {
        "method_name": "LSTM + GloVe (pre-trained, frozen, word-level)",
        "paper_reference": null,
        "metric": "Overall accuracy",
        "their_result": "99.00% (BERT + WordPiece)",
        "baseline_result": "88.16%"
      },
      {
        "method_name": "GRU + GloVe (trained) vs BERT on Text Reversal",
        "paper_reference": null,
        "metric": "Text Reversal class accuracy",
        "their_result": "90.65% (BERT + WordPiece)",
        "baseline_result": "95.20% (GRU + GloVe trained)"
      },
      {
        "method_name": "Word Reversal best models",
        "paper_reference": null,
        "metric": "Word Reversal class accuracy",
        "their_result": "99.04% (BERT + WordPiece)",
        "baseline_result": "99.04% (GRU + GloVe trained)"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "per-class accuracy",
      "cross-entropy loss (training)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can language models learn to identify classical cipher types from ciphertext by leveraging structural 'cipher hints' rather than semantic meaning?",
        "Which tokenization strategies (word-level, subword-level, character-level) are most effective for cipher-type classification under heavy character shuffling and OOV conditions?",
        "How do different neural architectures (GRU, LSTM, BERT) compare on this classification task?"
      ],
      "gaps_identified": [
        "Consistent difficulty across models in correctly classifying word reversal and text reversal ciphers.",
        "Word-level tokenizers with frozen pre-trained embeddings perform poorly under high OOV induced by ciphers.",
        "Large disparity in model parameter counts (BERT ~109M vs RNNs ~9M) confounds pure architectural comparisons.",
        "Limited training set size due to computational constraints on non-parallelizable RNNs.",
        "Data preprocessing reduced characters to lowercase ASCII, limiting generality to broader alphabets and languages."
      ],
      "limitations": [
        "No extensive hyperparameter tuning conducted due to the number of model–tokenizer combinations.",
        "Training/validation/test sets limited to 55k examples total because of compute constraints.",
        "Evaluation restricted to six classes (five cipher types plus unencrypted) derived from English news summaries.",
        "Character set reduced to 27 symbols (lowercase letters + space) after cleaning.",
        "Single-GPU (Tesla P100) training; potential scaling effects not explored."
      ],
      "future_work": [
        "Investigate the root causes of the difficulty in classifying word reversal and text reversal ciphers and the unexpectedly strong GRU+GloVe performance.",
        "Evaluate SentencePiece tokenization to leverage whitespace and Unicode handling for potentially better cipher hints."
      ],
      "motivation": "Reduce the computational burden of brute-force decipherment by first classifying the cipher type; test whether language models can learn cipher-structural cues and how tokenization affects robustness to character shuffling.",
      "potential_research_ideas": [
        "Extend the label space to include additional classical and polyalphabetic ciphers (e.g., Vigenère, Playfair, Autokey) and mixed/compound ciphers.",
        "Joint multi-task learning that predicts both cipher type and recovers key parameters (e.g., shift amount, permutation pattern).",
        "Pre-train models with self-supervised objectives on large-scale synthetic cipher transformations to learn invariances, then fine-tune for classification.",
        "Introduce character-level or byte-level Transformers with relative position encodings tailored for reversal and transposition invariances.",
        "Contrastive learning between original and ciphered pairs to encourage representation of cipher operations.",
        "Length-controlled studies to quantify performance vs. ciphertext length and assess sample-efficiency across ciphers.",
        "Cross-lingual cipher classification by generating cipher corpora from multiple languages and scripts (Unicode).",
        "Open-world classification (including unknown/novel cipher types) with confidence calibration and OOD detection.",
        "Explainability analyses to localize token/position patterns that drive classification decisions for different cipher types."
      ],
      "architectural_improvement_recommendations": [
        "Adopt SentencePiece or byte-level BPE tokenization to avoid whitespace splitting and improve robustness to shuffling.",
        "Use character-aware or byte-level Transformers with relative/rotary position encodings to better model reversals and transpositions.",
        "Add lightweight convolutional front-ends over characters to capture local n-gram statistics prior to RNN/Transformer backbones.",
        "Incorporate permutation- and reversal-equivariant layers or augmentations to encode inductive biases for these operations.",
        "Apply label smoothing and focal loss for harder classes (word/text reversal) and class-balanced sampling if class difficulties persist.",
        "Ensemble subword and character models to combine complementary strengths on substitution/transposition vs. reversal classes."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "Keras",
        "PyTorch",
        "HuggingFace Tokenizers",
        "Python",
        "GloVe"
      ],
      "reproducibility_score": "high",
      "computational_requirements": "Single NVIDIA Tesla P100 GPU; 10 epochs; learning rate 0.001; batch size 1024."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Generalization from synthetic transformations to real-world ciphertext and diverse cipher families.",
        "Robust handling of high OOV and arbitrary character permutations induced by ciphers.",
        "Sensitivity to tokenizer choice; word-level tokenizers with frozen embeddings underperform.",
        "Compute constraints for training larger datasets or longer sequences, especially for RNNs."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Formulates cipher decryption pre-step as a 6-way classification problem (five cipher types plus unencrypted).",
      "Constructs a synthetic labeled dataset by applying substitution, transposition, word reversal, text reversal, and character shift to English Gigaword summaries.",
      "Comprehensive empirical comparison of model–tokenizer combinations (GRU, LSTM, BERT; word-level, subword-level, character-level; GloVe embeddings).",
      "Finds BERT with WordPiece achieves the highest overall test accuracy of 99.00%; GRU with trained GloVe achieves 97.00% and the best Text Reversal accuracy (95.20%).",
      "Provides open-source code, trained models, and tokenizers to facilitate reproduction."
    ]
  },
  {
    "arxiv_id": "2306.01545v2",
    "title": "PassGPT: Password Modeling and (Guided) Generation with Large Language Models",
    "authors": "Javier Rando; Fernando Perez-Cruz; Briland Hitaj",
    "abstract": "Large language models (LLMs) successfully model natural language from vast amounts of text without the need for explicit supervision. In this paper, we investigate the efficacy of LLMs in modeling passwords. We present PassGPT, a LLM trained on password leaks for password generation. PassGPT outperforms existing methods based on generative adversarial networks (GAN) by guessing twice as many previously unseen passwords. Furthermore, we introduce the concept of guided password generation, where we leverage PassGPT sampling procedure to generate passwords matching arbitrary constraints, a feat lacking in current GAN-based strategies. Lastly, we conduct an in-depth analysis of the entropy and probability distribution that PassGPT defines over passwords and discuss their use in enhancing existing password strength estimators.",
    "published_date": "2023-06-02",
    "pdf_link": "https://arxiv.org/pdf/2306.01545v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Authentication and Access Control",
      "subdomain": "Password Security",
      "specific_problem": "Offline password guessing (password generation) and password strength estimation using LLMs",
      "attack_types": [
        "offline password guessing",
        "password cracking"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer (Autoregressive Language Model)",
        "specific": "GPT-2 style decoder-only transformer",
        "novel_contribution": "Application of an autoregressive LLM (PassGPT) to model and generate passwords character-by-character, enabling guided generation under arbitrary constraints and providing explicit probability distribution over passwords."
      },
      {
        "type": "primary",
        "category": "Vector-Quantized Transformer",
        "specific": "Transformer with vector quantization (inspired by VQ approaches, codebook size 300)",
        "novel_contribution": "PassVQT: enhances transformer with vector-quantized latent space and an autoregressive codes model to increase generation perplexity and assess benefits of quantization for password modeling."
      },
      {
        "type": "baseline",
        "category": "GAN",
        "specific": "PassGAN (Improved Wasserstein GAN) and improved PassGAN (PassGAN+)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Normalizing Flow",
        "specific": "PassFlow (normalizing flows)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised",
      "Unsupervised",
      "Maximum Likelihood (next-token prediction)"
    ],
    "datasets": [
      {
        "name": "RockYou",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "LinkedIn",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "phpBB",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MySpace",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Hotmail",
        "type": "public",
        "domain": "password_leaks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "PassGAN",
        "paper_reference": "[25]",
        "metric": "% of RockYou test (<10 chars) matched at 10^9 guesses",
        "their_result": "41.86% (\"PassGPT recovers 41.9% ... whereas state-of-the-art GAN models matched 23.33%.\")",
        "baseline_result": "15.09%"
      },
      {
        "method_name": "PassGAN (improved PassGAN, PassGAN*)",
        "paper_reference": "[36]",
        "metric": "% of RockYou test (<10 chars) matched at 10^9 guesses",
        "their_result": "41.86%",
        "baseline_result": "23.33%"
      },
      {
        "method_name": "PassGAN",
        "paper_reference": "[25]",
        "metric": "% of RockYou test (<10 chars) matched at 10^8 guesses",
        "their_result": "19.37%",
        "baseline_result": "6.73%"
      },
      {
        "method_name": "PassGAN (improved PassGAN, PassGAN*)",
        "paper_reference": "[36]",
        "metric": "% of RockYou test (<10 chars) matched at 10^8 guesses",
        "their_result": "19.37%",
        "baseline_result": "9.51%"
      },
      {
        "method_name": "PassGAN",
        "paper_reference": "[25]",
        "metric": "% of RockYou test (<10 chars) matched at 10^7 guesses",
        "their_result": "4.25%",
        "baseline_result": "2.04%"
      },
      {
        "method_name": "PassGAN",
        "paper_reference": "[25]",
        "metric": "% of RockYou test (<10 chars) matched at 10^6 guesses",
        "their_result": "0.50%",
        "baseline_result": "0.38%"
      },
      {
        "method_name": "PassGAN",
        "paper_reference": "[25]",
        "metric": "% unique among 10^9 generated samples (novelty)",
        "their_result": "~60% unique for PassGPT (\"PassGPT retains the highest percentage of unique passwords (60%)\")",
        "baseline_result": "~40% unique for PassGAN"
      }
    ],
    "performance_metrics_used": [
      "percentage_of_test_passwords_matched",
      "uniqueness_rate_of_generated_passwords",
      "perplexity (of generated passwords; PassVQT increases perplexity)",
      "entropy/probability analysis of passwords",
      "generalization to unseen datasets/splits"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How effectively can LLMs capture the underlying characteristics and cues hidden in the complex nature of human-generated passwords?"
      ],
      "gaps_identified": [
        "Prior GAN-based approaches lack guided generation under arbitrary constraints.",
        "GAN-based models do not provide an explicit probability distribution over passwords for downstream uses like strength estimation.",
        "Comparisons in literature often focus on a single leak (e.g., RockYou); need better generalization analyses to unseen datasets.",
        "Limited evaluation of longer passwords in prior work; longer passwords are harder to model and guess.",
        "Lack of scalable training on larger leaks due to compute constraints."
      ],
      "limitations": [
        "Our experiments are limited in scale by GPU access. Scaling is a crucial factor to improve performance and training on larger leaks.",
        "Experiments restricted to deep generative models for offline guessing; do not compare to Markov/PCFG or online guessing setups.",
        "Models trained for 1 epoch; potential undertraining due to compute constraints.",
        "Accuracy drops when moving to longer passwords (up to 16 chars).",
        "PassVQT shows lower uniqueness when trained on all occurrences (bias toward common passwords)."
      ],
      "future_work": [
        "Use PassGPT-assigned probabilities to improve current password strength estimators.",
        "Scale training to larger datasets and models to improve performance.",
        "Extend guided password generation and explore richer constraint satisfaction.",
        "Further analyze generalization to more diverse/unseen distributions."
      ],
      "motivation": "Investigate whether LLMs can effectively model human-generated passwords to improve password guessing and inform password strength estimation.",
      "potential_research_ideas": [
        "Conditioned/guided generation with explicit policy/regex/finite-automata constraints integrated into decoding (e.g., constrained beam search) for enterprise password policies.",
        "Train larger byte-level decoder-only LLMs (e.g., LLaMA/GPT-NeoX variants) on multi-leak corpora with domain-adaptive pretraining to improve generalization to unseen sites.",
        "Incorporate user/context features (e.g., language, locale, breach source) via conditional tokens to enable targeted yet privacy-safe distributions and ablation on cross-site generalization.",
        "Calibrate PassGPT probabilities (temperature scaling/Platt/Dirichlet) and evaluate correlation with cracking cost to directly inform risk scoring in strength estimators.",
        "Hybridize with normalizing flows or energy-based models for better tail modeling of long/rare passwords.",
        "Differentially private or memorization-aware training to mitigate leakage of rare passwords while retaining utility for strength estimation research.",
        "Reinforcement learning or constrained RLHF-style fine-tuning to maximize validity under complex policy constraints while maintaining diversity."
      ],
      "architectural_improvement_recommendations": [
        "Adopt byte-level BPE/Unigram tokenization instead of pure one-hot UTF-8 to capture subword patterns and improve efficiency.",
        "Scale model depth/width and train for more epochs with better regularization (dropout, weight decay) and learning rate schedules; evaluate larger context windows.",
        "Use constrained decoding (regex-guided, finite automata) and nucleus/temperature sampling to trade off diversity and policy satisfaction.",
        "Mixture-of-experts or language-specific adapters to capture cultural/password-pattern heterogeneity across leaks.",
        "Leverage curriculum learning from short to long passwords; auxiliary losses for character classes/patterns to improve long-password modeling.",
        "Apply uncertainty estimation and calibration techniques to better align probabilities with cracking difficulty.",
        "Explore VQ-VAE/VQ-Transformer variants with hierarchical codebooks for improved perplexity without sacrificing uniqueness."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/javirandor/passgpt",
      "frameworks": [
        "PyTorch",
        "HuggingFace Transformers"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Single consumer GPU; models trained for 1 epoch; GPT-2 style decoder with 12 attention heads, 8 layers, GeLU; AdamW optimizer with lr=5e-5 and linear decay."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Compute scaling required for larger leaks and longer training.",
        "Generalization to longer passwords reduces accuracy.",
        "Bias toward common passwords when training on all occurrences (affects novelty)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces PassGPT, an autoregressive transformer (GPT-2 based) for password generation achieving state-of-the-art results and strong generalization.",
      "Demonstrates guided password generation: character-level constrained sampling to meet arbitrary constraints (not supported by prior GAN approaches).",
      "Provides explicit password probability distribution, enabling entropy/probability analysis and informing password strength estimators (alignment with zxcvbn).",
      "Introduces PassVQT, a vector-quantized transformer architecture that increases generation perplexity and provides an alternative modeling path.",
      "Offers empirical comparison showing PassGPT recovers 41.86% of RockYou test (<10 chars) at 10^9 guesses vs 23.33% for improved PassGAN, and maintains higher uniqueness (~60%)."
    ]
  },
  {
    "arxiv_id": "2306.09318v1",
    "title": "Inroads into Autonomous Network Defence using Explained Reinforcement Learning",
    "authors": "Myles Foley; Mia Wang; Zoe M; Chris Hicks; Vasilios Mavroudis",
    "abstract": "Computer network defence is a complicated task that has necessitated a high degree of human involvement. However, with recent advancements in machine learning, fully autonomous network defence is becoming increasingly plausible. This paper introduces an end-to-end methodology for studying attack strategies, designing defence agents and explaining their operation. First, using state diagrams, we visualise adversarial behaviour to gain insight about potential points of intervention and inform the design of our defensive models. We opt to use a set of deep reinforcement learning agents trained on different parts of the task and organised in a shallow hierarchy. Our evaluation shows that the resulting design achieves a substantial performance improvement compared to prior work. Finally, to better investigate the decision-making process of our agents, we complete our analysis with a feature ablation and importance study.",
    "published_date": "2023-06-15",
    "pdf_link": "https://arxiv.org/pdf/2306.09318v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Autonomous/Active Cyber Defense",
      "specific_problem": "Designing explainable hierarchical deep RL agents for network defense in CybORG; online identification of attacker strategy and coordinated response via specialized subagents",
      "attack_types": [
        "network scanning",
        "port scanning",
        "exploitation of network services",
        "privilege escalation",
        "lateral movement",
        "service disruption/DoS on operational server"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Policy Gradient (PPO)",
        "specific": "Proximal Policy Optimization",
        "novel_contribution": "Applied in a hierarchical defense setting with specialized subagents tailored to distinct adversaries (Meander vs BLine) and explainability-driven design choices"
      },
      {
        "type": "primary",
        "category": "Hierarchical RL",
        "specific": "Controller with specialized subagents",
        "novel_contribution": "Shallow hierarchy where a controller selects between expert subagents trained for different attacker strategies"
      },
      {
        "type": "primary",
        "category": "Multi-armed Bandit",
        "specific": "Bandit Controller",
        "novel_contribution": "Contextualized bandit approach that instantiates a bandit per observed state window to classify the adversary from short sequences"
      },
      {
        "type": "primary",
        "category": "Heuristic/Rule-based",
        "specific": "Heuristic Controller",
        "novel_contribution": "Formalized early-step action-pattern heuristic to identify attacker type using first four timesteps"
      },
      {
        "type": "primary",
        "category": "Representation/Feature Engineering",
        "specific": "Action Knowledge (AK) and State Representation (SR) variants",
        "novel_contribution": "AK augments observation with a success-bit of previous action (53-bit); SR uses compact 27-float representation of activity/compromise plus success-bit to reduce variance"
      },
      {
        "type": "primary",
        "category": "Intrinsic Motivation",
        "specific": "Intrinsic Curiosity Module (ICM)",
        "novel_contribution": "Used for BLineAgent defense to reduce overfitting; ablated for MeanderAgent where curiosity did not help"
      },
      {
        "type": "primary",
        "category": "Explainability/Post-hoc",
        "specific": "Feature ablation and feature importance study",
        "novel_contribution": "Post-hoc analysis to identify influential observation elements and explain agent decisions"
      },
      {
        "type": "primary",
        "category": "Visualization/XRL",
        "specific": "Action-outcome transition graphs",
        "novel_contribution": "State-diagram visualizations to differentiate attacker behaviors and inform controller design"
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning (Deep RL)"
    ],
    "datasets": [
      {
        "name": "CybORG (CAGE II environment)",
        "type": "public",
        "domain": "network_simulation_environment",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "PPO with curiosity (CAGE I baseline from [9]) vs our SR/AK subagents (BLine defense)",
        "paper_reference": "[9] (CAGE I baseline)",
        "metric": "peak mean reward against BLineAgent",
        "their_result": "SR: -11.465 (peak); AK: -12.227 (peak)",
        "baseline_result": "-13.475 (peak)"
      },
      {
        "method_name": "PPO with curiosity (CAGE I baseline from [9]) vs our PPO (Meander defense)",
        "paper_reference": "[9] (CAGE I baseline)",
        "metric": "mean reward (training) against MeanderAgent",
        "their_result": "-24.91 ± 9.21",
        "baseline_result": "-123.91 ± 229.59"
      }
    ],
    "performance_metrics_used": [
      "episode reward",
      "mean reward",
      "max reward",
      "min reward",
      "standard deviation of reward",
      "adversary classification accuracy (controller)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can explainable RL (XRL) models and environment visualizations improve autonomous defensive capabilities and aid development?",
        "Can bandit- or heuristic-based controllers identify adversary type more accurately and improve hierarchical defense performance?",
        "Do curiosity signals (ICM) benefit defensive agents trained against optimal-path attackers (BLineAgent)?",
        "Which observation features most influence defensive decision-making in CybORG?"
      ],
      "gaps_identified": [
        "Limited consideration of explainability in autonomous network defense literature",
        "PPO has seen limited use in security settings",
        "Previously undocumented differences in built-in adversary models (Meander vs BLine) in CybORG"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Reduce human involvement and cost in network defense by leveraging DRL, while addressing the need to understand and explain autonomous defensive agents' decisions.",
      "potential_research_ideas": [
        "Extend to more diverse and adaptive adversary models (including unknown/novel strategies) and evaluate robustness",
        "Evaluate and adapt policies in CybORG’s AWS-backed emulator and real networks to study sim-to-real transfer",
        "Replace the bandit/heuristic controller with sequence models (LSTM/GRU/Transformer) for adversary classification under partial observability",
        "Incorporate contextual bandits or Bayesian bandits conditioned on richer state features for online adversary identification",
        "Adopt option-critic or hierarchical options frameworks to jointly learn controller and subpolicies end-to-end",
        "Use graph neural networks over dynamic network topology to inform action selection and generalize across network layouts",
        "Develop intrinsic explainability via interpretable policy classes (e.g., decision trees/rules) and compare to post-hoc methods",
        "Adversarial training or robust RL to handle adaptive attackers and stochastic outcomes",
        "Meta-RL or continual learning to adapt quickly across CAGE scenarios and changing environments",
        "Risk-sensitive or constrained RL to respect operational constraints (e.g., minimize disruptions like restores)"
      ],
      "architectural_improvement_recommendations": [
        "End-to-end joint training of controller and subagents (e.g., options framework) rather than decoupled training",
        "Use recurrent policies (PPO+LSTM/Transformer) for subagents to better handle partial observability over longer horizons",
        "Contextual bandit or sequence classifier (RNN/Transformer) for adversary identification instead of per-state bandits",
        "Graph-based state encoding (GNNs) of hosts and services to capture topology and information flow",
        "Curriculum learning across adversary difficulties and network configurations",
        "Reward shaping with penalties for unnecessary disruptive actions (e.g., restore) and incentives for early detection",
        "Ensemble of subagents with confidence-weighted blending rather than hard switching",
        "Systematic hyperparameter search and automated feature selection for SR/AK representations"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Simulated manufacturing plant network (CybORG); emulator on AWS exists but not reported used in evaluation",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Reality gap between simulation and real networks (partially mitigated by emulator)",
        "Partial observability and stochastic action outcomes",
        "Method evaluated against two predefined adversaries; generalization to adaptive/unknown attackers is untested",
        "Coordination and switching between subagents may be brittle if attacker behavior deviates from modeled patterns"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Methodologies for visualizing (explaining) attacker functionality in CybORG; highlight previously undocumented differences in adversary models and motivate new controller architectures with improved classification accuracy.",
      "New controller and specialized subagent models (hierarchical DRL with bandit/heuristic controllers; AK and SR subagents) with substantial performance improvements against two adversary classes in CybORG.",
      "Feature ablation and importance study to identify influential observation elements and explain model outputs."
    ]
  },
  {
    "arxiv_id": "2306.05589v1",
    "title": "Intrusion Detection Systems for Flying Ad-hoc Networks",
    "authors": "Jordan Quinn; Safdar Hussain Bouk",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are becoming more dependent on mission success than ever. Due to their increase in demand, addressing security vulnerabilities to both UAVs and the Flying Ad-hoc Networks (FANET) they form is more important than ever. As the network traffic is communicated through open airwaves, this network of UAVs relies on monitoring applications known as Intrusion Detection Systems (IDS) to detect and mitigate attacks. This paper will survey current IDS systems that include machine learning techniques when combating various vulnerabilities and attacks from bad actors. This paper will be concluded with research challenges and future research directions in finding an effective IDS system that can handle cyber-attacks while meeting performance requirements.",
    "published_date": "2023-06-08",
    "pdf_link": "https://arxiv.org/pdf/2306.05589v1",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "UAV/Drone Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Survey of ML-based intrusion detection systems for Flying Ad-hoc Networks (FANETs) and UAVs, with challenges and future directions",
      "attack_types": [
        "jamming",
        "spoofing",
        "GPS spoofing",
        "eavesdropping",
        "denial of service (DoS)",
        "routing attacks",
        "data forgery",
        "malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": "Deep Q-Learning (DQN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Deep CNN (UAV-IDS-ConvNet)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Unsupervised Learning",
        "specific": "Autoencoder-based IDS",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": "Q-Learning for power allocation vs. jamming/eavesdropping/spoofing",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "K-Nearest Neighbors",
        "specific": "K-NN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Semi-supervised",
        "specific": "Self-Taught Learning (STL)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Multiclass SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "One-Class SVM (OC-SVM)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "Recurrent Neural Networks (two-module framework)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Federated Learning",
        "specific": null,
        "novel_contribution": "Discussed as promising for IDS and privacy, but not yet applied to FANET in surveyed works"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Semi-supervised",
      "Reinforcement Learning",
      "Federated Learning"
    ],
    "datasets": [
      {
        "name": "UAV-IDS-2020",
        "type": "",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "CIC-IDS2018",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "OpenSky Network (Air Traffic Control data)",
        "type": "public",
        "domain": "aviation_control_data",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "detection rate",
      "false positive rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What ML-based IDS approaches have been proposed for UAVs/FANETs?",
        "Which attack types are addressed by these IDS approaches?",
        "What challenges and limitations remain for deploying effective IDS on resource-constrained UAVs/FANETs?"
      ],
      "gaps_identified": [
        "Shortage of high-quality, large-scale, representative datasets for UAV/FANET IDS; existing datasets may be incomplete or biased.",
        "Model selection is context-dependent; no consensus best model across data, attacks, and performance requirements.",
        "Limited transferability/portability of ML models across heterogeneous UAV hardware/software stacks.",
        "Data security risks (e.g., manipulation/poisoning) can render IDS ineffective; need mechanisms to verify data integrity.",
        "Federated learning has not yet been applied to FANET-specific IDS despite promise in other ad-hoc networks.",
        "Non-ML and signature-only IDS approaches struggle with unknown/zero-day attacks and yield higher false positives."
      ],
      "limitations": [
        "Encrypted traffic visibility challenges for anomaly detection and higher false positives are noted.",
        "Resource constraints on UAVs (power, CPU, memory) limit heavy cryptography and complex IDS.",
        "High mobility and dynamic topology complicate stable detection and model applicability.",
        "The paper is a short overview; no new empirical evaluation or code is provided."
      ],
      "future_work": [
        "Apply and evaluate federated learning-based IDS in FANET settings with privacy and secure aggregation.",
        "Develop comprehensive, public, labeled UAV/FANET IDS datasets covering jamming, spoofing (incl. GPS), DoS, routing attacks, and encrypted traffic scenarios.",
        "Design lightweight, energy-efficient IDS models tailored to UAV constraints (e.g., pruning/quantization).",
        "Establish robust data integrity verification and defenses against data poisoning/backdoors for IDS pipelines.",
        "Improve transferability via domain adaptation and model personalization across heterogeneous UAV platforms.",
        "Combine anomaly- and signature-based methods into hybrid ML-enhanced IDS to balance detection and false positives."
      ],
      "motivation": "Rising use of UAVs and FANETs increases exposure to wireless threats; survey ML-based IDS approaches, identify challenges, and outline future directions for effective, efficient, and secure detection.",
      "potential_research_ideas": [
        "First application and evaluation of federated learning IDS tailored to FANETs with secure aggregation and poisoning-robust aggregation (e.g., Krum/Trimmed Mean).",
        "A public benchmark suite for UAV/FANET IDS with standardized scenarios (jamming, spoofing/GPS, eavesdropping, DoS, routing attacks), including encrypted Wi-Fi traffic traces and synchronized sensor/telemetry.",
        "Poisoning- and backdoor-robust UAV IDS training with data integrity attestation (e.g., signatures, TEEs) and robust training objectives.",
        "Resource-aware AutoML for on-UAV IDS architecture search under power/latency constraints.",
        "Cross-UAV transfer learning and domain adaptation to handle hardware/software heterogeneity and mobility-induced distribution shift.",
        "Continual/online learning IDS for dynamic FANET environments with drift detection and safe model updates.",
        "Multimodal IDS fusing physical-layer RF features, GPS/IMU telemetry, and network traffic using sequence models.",
        "Graph-based IDS leveraging GNNs to model dynamic FANET topology and detect coordinated attacks.",
        "Simulation-to-reality transfer via domain randomization and high-fidelity UAV network simulators.",
        "Hybrid detection stacks combining one-class novelty detectors for sensors with supervised classifiers for network traffic."
      ],
      "architectural_improvement_recommendations": [
        "Edge–cloud split learning: lightweight on-UAV encoders with periodic aggregation on GCS; support intermittent connectivity.",
        "Model compression (quantization/pruning/knowledge distillation) to meet power and latency budgets on UAVs.",
        "Robust federated learning with secure aggregation, client-level anomaly scoring, and Byzantine-robust aggregation; support client personalization layers for heterogeneous UAVs.",
        "Hybrid IDS pipeline: anomaly detection (OC-SVM/autoencoder) front-end to flag novelties, followed by supervised classifier (CNN/XGBoost) for attribution; feedback to reduce false positives.",
        "Sequence models (RNN/Transformer) over time-series of telemetry and traffic for early detection of spoofing/jamming.",
        "Ensemble methods combining tree-based (RF/XGBoost) with neural models to balance accuracy, interpretability, and compute.",
        "Integrate physical-layer defenses (e.g., power allocation via RL) with higher-layer IDS decisions for cross-layer security.",
        "Data integrity pipeline with cryptographic signing of logs and sensor data; provenance tracking for training data.",
        "Automated hyperparameter tuning/AutoML under resource constraints; budget-aware NAS for microcontrollers/edge GPUs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Power limitations on UAVs restrict compute and heavy cryptography; attacks can drain batteries.",
        "Limited CPU/memory constrain IDS complexity and cryptographic options.",
        "High mobility and dynamic topology (30–460 km/h) complicate stable detection and routing; susceptible to jamming/interference.",
        "Wireless protocol diversity (802.11/802.15.4/Bluetooth/satellite/cellular) introduces heterogeneous bandwidth, management, and security challenges.",
        "Scarcity and bias of training data hamper model reliability and generalization.",
        "Model transferability across heterogeneous UAV platforms is difficult.",
        "Data security risks (poisoning/insertion/manipulation) can degrade IDS effectiveness."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Survey of recent ML-based IDS approaches for UAVs/FANETs and the attack types they address.",
      "Discussion of FANET/UAV components and security models relevant to IDS.",
      "Identification of research challenges and limitations (data scarcity/quality, model selection, transferability, data security).",
      "Outline of future research directions toward effective, efficient, and secure UAV/FANET IDS."
    ]
  },
  {
    "arxiv_id": "2306.07997v1",
    "title": "Machine Learning Approach on Multiclass Classification of Internet Firewall Log Files",
    "authors": "Md Habibur Rahman; Taminul Islam; Md Masum Rana; Rehnuma Tasnim; Tanzina Rahman Mona; Md. Mamun Sakib",
    "abstract": "Firewalls are critical components in securing communication networks by screening all incoming (and occasionally exiting) data packets. Filtering is carried out by comparing incoming data packets to a set of rules designed to prevent malicious code from entering the network. To regulate the flow of data packets entering and leaving a network, an Internet firewall keeps a track of all activity. While the primary function of log files is to aid in troubleshooting and diagnostics, the information they contain is also very relevant to system audits and forensics. Firewalls primary function is to prevent malicious data packets from being sent. In order to better defend against cyberattacks and understand when and how malicious actions are influencing the internet, it is necessary to examine log files. As a result, the firewall decides whether to 'allow,' 'deny,' 'drop,' or 'reset-both' the incoming and outgoing packets. In this research, we apply various categorization algorithms to make sense of data logged by a firewall device. Harmonic mean F1 score, recall, and sensitivity measurement data with a 99% accuracy score in the random forest technique are used to compare the classifier's performance. To be sure, the proposed characteristics did significantly contribute to enhancing the firewall classification rate, as seen by the high accuracy rates generated by the other methods.",
    "published_date": "2023-06-12",
    "pdf_link": "https://arxiv.org/pdf/2306.07997v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Firewall Log Analysis",
      "specific_problem": "Multiclass classification of firewall log actions (allow, deny, drop, reset-both) from Internet firewall log files",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble - Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "K-Nearest Neighbors",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Support Vector Machine",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "UCI firewall log dataset (65,478 firewall logs, 12 features; class 'Action' with allow, drop, deny, reset-both)",
        "type": "public",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "99% (Random Forest)",
        "baseline_result": "95% (SVM)"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "99% (Random Forest)",
        "baseline_result": "99% (KNN)"
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "99% (Random Forest)",
        "baseline_result": "98% (Logistic Regression)"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "F1-score (average reported)",
        "their_result": "0.99 (Random Forest)",
        "baseline_result": "0.95 (SVM)"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "F1-score (average reported)",
        "their_result": "0.99 (Random Forest)",
        "baseline_result": "0.98 (KNN)"
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "F1-score (average reported)",
        "their_result": "0.99 (Random Forest)",
        "baseline_result": "0.97 (Logistic Regression)"
      },
      {
        "method_name": "K-means + SOFM (Allagi et al.)",
        "paper_reference": "[17]",
        "metric": "accuracy",
        "their_result": "99% (Random Forest, this paper)",
        "baseline_result": "97.2% (reported by [17])"
      },
      {
        "method_name": "Spark-based security platform (Random Forest, JRip)",
        "paper_reference": "[18]",
        "metric": "accuracy",
        "their_result": "99% (Random Forest, this paper)",
        "baseline_result": "99.9% (reported by [18])"
      },
      {
        "method_name": "Multiclass SVM (RBF)",
        "paper_reference": "[19]",
        "metric": "accuracy",
        "their_result": "99% (Random Forest, this paper)",
        "baseline_result": "98% (reported by [19])"
      },
      {
        "method_name": "DT, SVM, ANN, PSO, ZeroR",
        "paper_reference": "[11]",
        "metric": "accuracy",
        "their_result": "99% (Random Forest, this paper)",
        "baseline_result": "99% (reported by [11])"
      },
      {
        "method_name": "NB, KNN, J48",
        "paper_reference": "[20]",
        "metric": "accuracy",
        "their_result": "99% (Random Forest, this paper)",
        "baseline_result": "99% (reported by [20])"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can supervised multiclass ML algorithms accurately classify firewall log actions (allow, deny, drop, reset-both) from Internet firewall logs?",
        "Which of SVM, KNN, Random Forest, and Logistic Regression performs best for firewall log action classification, and how do their precision/recall/F1 compare?"
      ],
      "gaps_identified": [
        "Manual firewall rule maintenance is time-consuming and error-prone; there is a need to automate log analysis and classification.",
        "Lower performance on the rare 'reset-both' class indicates class imbalance and data sparsity issues.",
        "Evolving cyber threats and changing environments imply potential concept drift that static models may not handle well."
      ],
      "limitations": [
        "Evaluation limited to a single public dataset from UCI; no validation on diverse real-world deployments.",
        "Results primarily from offline cross-validation; no real-time or production deployment testing.",
        "Incomplete methodological clarity (both a 70/30 split and 10-fold cross-validation are mentioned; hyperparameters not detailed).",
        "No code or model artifacts released for reproducibility.",
        "Poor recall for the 'reset-both' class due to dataset boundary and lower amount of data."
      ],
      "future_work": [
        "Overall, random forest is the most effective algorithm for classifying for the log file analysis and there is a room for improvement in the classification for 'reset both' class.",
        "Developing new strategies and techniques of classification is necessary due to evolving cyber threats."
      ],
      "motivation": "Automate and improve the classification of firewall log actions to aid troubleshooting, forensics, and security operations, reducing analyst workload and improving network protection.",
      "potential_research_ideas": [
        "Design cost-sensitive or focal-loss-based classifiers explicitly addressing rare firewall actions (e.g., 'reset-both').",
        "Apply modern gradient-boosted decision trees (XGBoost/LightGBM/CatBoost) and compare against Random Forest and KNN.",
        "Sequence- or session-level modeling (e.g., temporal features, LSTM/Transformer) to capture context across related log entries.",
        "Semi-supervised or self-training methods to leverage large unlabeled logs and limited labeled actions.",
        "Online/incremental learning to handle concept drift as traffic patterns and firewall rules evolve.",
        "Domain adaptation across different firewall vendors/formats to improve generalization.",
        "Integrate explainability (e.g., SHAP) to map features back to firewall rules for analyst trust and diagnostics.",
        "Calibrate predicted probabilities and apply threshold optimization for operational risk control.",
        "Combine rule-based filtering with learned models (hybrid system) for improved precision and recall.",
        "Evaluate and mitigate data leakage risks from preprocessing in cross-validation (proper pipeline handling)."
      ],
      "architectural_improvement_recommendations": [
        "Address class imbalance via SMOTE/ADASYN, class weighting, or focal loss and evaluate per-class gains, especially for 'reset-both'.",
        "Perform systematic hyperparameter optimization (grid/Bayesian search) and nested cross-validation for robust model selection.",
        "Engineer richer features (e.g., sessionization, temporal intervals, port/application/category embeddings) and evaluate feature importance.",
        "Stacking/ensembling (e.g., RF + calibrated LR meta-learner) to balance recall and precision across classes.",
        "Standardize preprocessing with pipelines to avoid leakage and ensure consistent CV (scaling and one-hot encoding within folds).",
        "Benchmark additional models (XGBoost/LightGBM/CatBoost, linear SVM, calibrated KNN) with calibration (Platt/Isotonic).",
        "Deploy model monitoring for drift detection and scheduled re-training on fresh logs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Weka 3.8.5",
        "Python 3.8",
        "Google Colab"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Class imbalance for rare actions (e.g., 'reset-both') impacting recall.",
        "Concept drift due to evolving traffic patterns and firewall rule changes.",
        "Heterogeneous log formats across vendors complicate model generalization.",
        "Need for low-latency inference for real-time log processing.",
        "Risk of false positives/negatives impacting security operations."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Applied and compared four supervised ML algorithms (Random Forest, KNN, SVM, Logistic Regression) for multiclass classification of firewall actions on a UCI firewall log dataset.",
      "Reported high performance: \"Random Forest (RF) and K-Nearest Neighbor (KNN) algorithms have the highest accuracy (99%), followed by SVM (95%) and Logistic Regression (98%).\"",
      "\"Comparing the f1 score, we can see that Random Forest has the highest average f1 score (0.99), followed by KNN (0.98), SVM (0.95), and Logistic Regression (0.97).\"",
      "Analyzed class-wise performance and highlighted difficulty with the rare 'reset-both' class: \"In all the algorithm 'reset both' had lower recall score which identify that this class was the most difficult one to classify correctly for all algorithm.\"",
      "Outlined a preprocessing pipeline: scaling, one-hot encoding, dataset randomization/shuffling, and cross-validation-based evaluation."
    ]
  },
  {
    "arxiv_id": "2306.06366v1",
    "title": "Zero-Day Threats Detection for Critical Infrastructures",
    "authors": "Mike Nkongolo; Mahmut Tokmak",
    "abstract": "Technological advancements in various industries, such as network intelligence, vehicle networks, e-commerce, the Internet of Things (IoT), ubiquitous computing, and cloud-based applications, have led to an exponential increase in the volume of information flowing through critical systems. As a result, protecting critical infrastructures from intrusions and security threats have become a paramount concern in the field of intrusion detection systems (IDS). To address this concern, this research paper focuses on the importance of defending critical infrastructures against intrusions and security threats. It proposes a computational framework that incorporates feature selection through fuzzification. The effectiveness and performance of the proposed framework is evaluated using the NSL-KDD and UGRansome datasets in combination with selected machine learning (ML) models. The findings of the study highlight the effectiveness of fuzzy logic and the use of ensemble learning to enhance the performance of ML models. The research identifies Random Forest (RF) and Extreme Gradient Boosting (XGB) as the top performing algorithms to detect zero-day attacks. The results obtained from the implemented computational framework outperform previous methods documented in the IDS literature, reaffirming the significance of safeguarding critical infrastructures from intrusions and security threats.",
    "published_date": "2023-06-10",
    "pdf_link": "https://arxiv.org/pdf/2306.06366v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Zero-day attack detection for critical infrastructures using fuzzy logic-based feature selection with supervised ML classifiers",
      "attack_types": [
        "zero-day attacks",
        "ransomware (Locky, CryptoLocker, SamSam, Globe)",
        "advanced persistent threats (APT)",
        "DoS",
        "Probe",
        "R2L",
        "U2R"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Feature Selection / Fuzzy Logic",
        "specific": "Fuzzy logic-based feature selection with triangular membership function; ExtraTrees used for selection criteria",
        "novel_contribution": "Computational framework that fuzzifies feature relevance and ranks features via fuzzy membership to produce multiple feature vectors (v1–v4; g1–g4) for binary and multi-class IDS"
      },
      {
        "type": "primary",
        "category": "Ensemble Tree",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Ensemble Tree",
        "specific": "Extra Trees",
        "novel_contribution": "Also used to guide fuzzy selection criteria according to text"
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "CART-style DT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Naive Bayes",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UGRansome",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Autoencoder-based DNN (Zhang et al. [8]) on NSL-KDD",
        "paper_reference": "[8]",
        "metric": "Accuracy / Precision / Recall / F1",
        "their_result": null,
        "baseline_result": "79.74% Acc, 82.22% Prec, 79.74% Rec, 76.47% F1"
      },
      {
        "method_name": "TSE-IDS (two-stage FS + bagging) on NSL-KDD (binary)",
        "paper_reference": "[9]",
        "metric": "Accuracy / Precision / Sensitivity",
        "their_result": null,
        "baseline_result": "85.797% Acc, 88.00% Prec, 86.80% Sensitivity"
      },
      {
        "method_name": "Filter-SVM on NSL-KDD",
        "paper_reference": "[10]",
        "metric": "Accuracy / Precision / Recall",
        "their_result": null,
        "baseline_result": "77.17% Acc, 66.34% Prec, 95.38% Rec"
      },
      {
        "method_name": "Wrapper-SVM on NSL-KDD",
        "paper_reference": "[10]",
        "metric": "Accuracy / Precision / Recall",
        "their_result": null,
        "baseline_result": "79.65% Acc, 68% Prec, 98.02% Rec"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "ROC-AUC",
      "Empirical error"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "NSL-KDD is a legacy dataset and does not include modern zero-day attack properties.",
        "UNSW-NB15 is not strongly correlated to realistic network behaviors for studying unknown malware.",
        "Some prior IDS work (e.g., TSE-IDS) was not tested with a multi-class configuration."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Safeguard critical infrastructures from intrusions, especially zero-day threats, by improving IDS via fuzzy logic-based feature selection and ensemble ML.",
      "potential_research_ideas": [
        "Extend the fuzzy FS framework to online/streaming settings to handle concept drift in critical infrastructure networks.",
        "Combine fuzzy FS with deep representation learning (e.g., autoencoders) to capture non-linear feature interactions for zero-day detection.",
        "Evaluate domain adaptation/transfer learning from synthetic/curated datasets (UGRansome) to real enterprise/ICS traffic.",
        "Integrate threat intelligence features (blacklists, campaign indicators) with learned features via multi-view learning.",
        "Develop an uncertainty-aware IDS that uses fuzzy FS outputs to calibrate prediction confidence and triage alerts.",
        "Explore weakly-supervised or self-supervised pretraining to reduce dependence on labeled data for emerging zero-day classes.",
        "Conduct cross-dataset generalization studies (train on UGRansome, test on other ransomware/zero-day corpora).",
        "Augment UGRansome with temporal/session-level features and evaluate sequential models (e.g., TCNs, Transformers) with fuzzy FS priors.",
        "Study robustness against data poisoning and evasion attacks specifically targeting the fuzzy FS ranking and tree ensembles.",
        "Design a cost-sensitive learning setup reflecting operational costs for false positives/negatives in critical infrastructure SOCs."
      ],
      "architectural_improvement_recommendations": [
        "Make fuzzy membership parameters (a,b,c) learnable and optimize jointly with classifier via bilevel optimization.",
        "Use hybrid FS: combine fuzzy membership rankings with model-based importances (e.g., SHAP, permutation importance, mutual information).",
        "Adopt stacking/ensembling of RF, XGBoost, and ET with calibrated probabilities (Platt or isotonic) to improve detection and thresholding.",
        "Apply rigorous hyperparameter optimization (Bayesian search) for tree ensembles and SVM to benchmark gains from fuzzy FS.",
        "Introduce class-imbalance handling (focal loss, class weights, resampling) tailored to rare zero-day classes.",
        "Evaluate k-fold cross-validation on fixed splits to reduce variance and report CIs for all metrics.",
        "Add feature stability analysis across folds to assess robustness of fuzzy-selected subsets.",
        "Incorporate incremental learning to update models as new zero-day signatures emerge without full retraining."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a computational framework that incorporates fuzzy logic-based feature selection using a triangular membership function.",
      "Constructs multiple feature vectors for both binary and multi-class classification and evaluates them on NSL-KDD and UGRansome.",
      "Empirically demonstrates that ensemble learning (especially RF and XGBoost) benefits from fuzzy FS and performs best for zero-day detection.",
      "Reports that the proposed framework outperforms previous IDS methods documented in the literature.",
      "Implements validation procedures and standard metrics (Accuracy, Precision, Recall, F1, ROC-AUC) to assess models."
    ]
  },
  {
    "arxiv_id": "2306.10923v1",
    "title": "Toward the Cure of Privacy Policy Reading Phobia: Automated Generation of Privacy Nutrition Labels From Privacy Policies",
    "authors": "Shidong Pan; Thong Hoang; Dawen Zhang; Zhenchang Xing; Xiwei Xu; Qinghua Lu; Mark Staples",
    "abstract": "Software applications have become an omnipresent part of modern society. The consequent privacy policies of these applications play a significant role in informing customers how their personal information is collected, stored, and used. However, customers rarely read and often fail to understand privacy policies because of the ``Privacy Policy Reading Phobia'' (PPRP). To tackle this emerging challenge, we propose the first framework that can automatically generate privacy nutrition labels from privacy policies. Based on our ground truth applications about the Data Safety Report from the Google Play app store, our framework achieves a 0.75 F1-score on generating first-party data collection practices and an average of 0.93 F1-score on general security practices. We also analyse the inconsistencies between ground truth and curated privacy nutrition labels on the market, and our framework can detect 90.1% under-claim issues. Our framework demonstrates decent generalizability across different privacy nutrition label formats, such as Google's Data Safety Report and Apple's App Privacy Details.",
    "published_date": "2023-06-19",
    "pdf_link": "https://arxiv.org/pdf/2306.10923v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Privacy and Data Protection",
      "subdomain": "Privacy Policy Analysis and Compliance",
      "specific_problem": "Automated generation of privacy nutrition labels from privacy policies and detection of inconsistencies (under-claims) in app store-provided labels",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM (Prompt-based QA)",
        "specific": "GPT-3",
        "novel_contribution": "Label generation module that translates privacy policy segments into platform-specific privacy nutrition labels via prompted Q&A, adaptable across formats (Google Data Safety Report and Apple App Privacy Details)"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Multi-label text classifier",
        "novel_contribution": "Used in the context classification module to map policy segments to high-level data practice categories; reuses architecture from prior work with a threshold of 0.5"
      },
      {
        "type": "primary",
        "category": "Text Segmentation and Embeddings",
        "specific": "fastText sentence embeddings + cosine similarity",
        "novel_contribution": "Policy segmentation into 1–4 sentence segments using sentence embeddings and similarity to group related content"
      },
      {
        "type": "baseline",
        "category": "LLM-only pipeline",
        "specific": "Fully LLM-based replacement of preprocessing and classification",
        "novel_contribution": "Ablation/alternative design: recursively uses an LLM to replace the first two modules; improves third-party sharing F1 by 13.1% with ~5× higher monetary cost"
      }
    ],
    "learning_paradigm": [
      "Supervised (multi-label CNN classifier)",
      "Zero-shot/Prompt-based inference (LLM)"
    ],
    "datasets": [
      {
        "name": "Google Play Data Safety Report Ground Truth Applications",
        "type": "proprietary",
        "domain": "privacy_policies",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Apple App Privacy Details (App Store labels)",
        "type": "public",
        "domain": "app_store_privacy_labels",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MAPS Privacy Policies Dataset",
        "type": "public",
        "domain": "privacy_policies",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a hybrid NLP + LLM framework automatically generate accurate privacy nutrition labels from privacy policies for Google Play’s Data Safety Report?",
        "What inconsistencies exist between app store–curated labels and ground truth, and can the framework detect under-claim issues?",
        "Does the framework generalize to Apple’s App Privacy Details format?",
        "What is the impact (accuracy vs. cost) of replacing preprocessing and classification with a fully LLM-based pipeline?"
      ],
      "gaps_identified": [
        "Users rarely read or understand privacy policies due to length, complexity, and technical/legal jargon (PPRP).",
        "Lack of standardized, officially promulgated privacy nutrition label formats across platforms.",
        "Absence of tools to automatically create privacy nutrition labels from existing privacy policies.",
        "Inconsistencies between curated labels on the market and ground truth practices (e.g., under-claims).",
        "LLM context-length limitations and tendency to over-positively answer yes/no under long prompts."
      ],
      "limitations": [
        "Errors attributed to omnibus data types, ambiguity caused by group-specific clauses, and under-performed context classification.",
        "Language handling limited to English in this study.",
        "LLM input length limitations necessitate preprocessing; direct end-to-end prompting is impractical.",
        "Fully LLM-based pipeline incurs approximately five times greater monetary cost.",
        "No publicly released ground-truth dataset to reproduce the exact evaluations."
      ],
      "future_work": [],
      "motivation": "Mitigate Privacy Policy Reading Phobia (PPRP) by providing concise, standardized privacy nutrition labels automatically generated from verbose policies, addressing the lack of tools and standardization while aiding compliance and user comprehension.",
      "potential_research_ideas": [
        "Develop a cross-lingual pipeline for multilingual privacy policies and labels using multilingual encoders and LLMs.",
        "Incorporate retrieval-augmented generation that grounds LLM answers in retrieved policy spans with evidence highlighting.",
        "Create a formal privacy ontology/knowledge graph aligning platform taxonomies to legal concepts (GDPR/CCPA) and use constrained decoding to enforce schema consistency.",
        "Automate detection of contradictions between policy text and declared labels via natural language inference tuned on privacy domains.",
        "Active learning to iteratively refine the multi-label classifier and prompts using human-in-the-loop adjudication of uncertain cases.",
        "Calibrate and quantify uncertainty (e.g., selective prediction/abstention) to reduce false positives in under-claim detection.",
        "Temporal monitoring to track label-policy drift across app versions, surfacing regressions or policy changes.",
        "Behavioral corroboration by linking static policy-derived labels with dynamic app telemetry (permissions, network flows) for end-to-end audits.",
        "Cost-efficient open-source LLM distillation to approximate GPT-3 performance with controllable cost/privacy.",
        "Standardized benchmark and metrics suite for privacy label generation across multiple platforms and jurisdictions."
      ],
      "architectural_improvement_recommendations": [
        "Replace CNN with transformer-based multi-label classifiers (e.g., LegalBERT/Longformer) for better context capture.",
        "Adopt hierarchical chunking and long-context models to reduce loss of context in segmentation and handle long policies.",
        "Use retrieval-augmented generation with evidence citations and constrained decoding to ensure outputs adhere to label schemas.",
        "Fine-tune domain-specific LLMs on annotated privacy policy–label pairs; use parameter-efficient tuning (LoRA/Adapters).",
        "Introduce rule-based post-processing/consistency checks across sections (e.g., retention must be present if collection occurs).",
        "Apply self-consistency or chain-of-thought prompting with verification to mitigate LLM yes-bias.",
        "Calibration and abstention mechanisms to defer uncertain cases for human review.",
        "Optimize cost via open-source LLMs with quantization and batching; hybrid routing based on difficulty.",
        "Train multilingual embeddings and classifiers to extend beyond English and reduce preprocessing language filters."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "OpenAI API (GPT-3)",
        "fastText",
        "Stanza",
        "Selenium",
        "BeautifulSoup"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "Uses GPT-3 API for label generation; fully LLM-based variant incurs approximately 5× higher monetary cost; CNN-based multi-label classifier is lightweight."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "LLM input length limitations for long privacy policies",
        "Increased monetary cost for fully LLM-based pipelines",
        "Ambiguity in policy text (omnibus data types, group-specific clauses)",
        "Cross-platform taxonomy differences and lack of standards",
        "Language constraints (English-only in current setup)"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First framework to automatically generate privacy nutrition labels from privacy policies using a hybrid NLP + LLM pipeline.",
      "Achieves 0.75 F1-score for first-party data collection, 0.63 F1-score for third-party sharing, and an average 0.93 F1-score for general security practices on Google’s Data Safety Report.",
      "Analyzes inconsistencies between curated labels and ground truth; detects 90.1% of under-claim issues and estimates ~12.6% under-claimed first-party collection practices.",
      "Demonstrates generalizability to Apple’s App Privacy Details with an average 0.70 F1-score across three data practice attributes.",
      "Proposes a fully LLM-based alternative that improves third-party sharing F1 by 13.1% at approximately five times the monetary cost."
    ]
  },
  {
    "arxiv_id": "2306.08566v1",
    "title": "Federated Learning-based Vehicle Trajectory Prediction against Cyberattacks",
    "authors": "Zhe Wang; Tingkai Yan",
    "abstract": "With the development of the Internet of Vehicles (IoV), vehicle wireless communication poses serious cybersecurity challenges. Faulty information, such as fake vehicle positions and speeds sent by surrounding vehicles, could cause vehicle collisions, traffic jams, and even casualties. Additionally, private vehicle data leakages, such as vehicle trajectory and user account information, may damage user property and security. Therefore, achieving a cyberattack-defense scheme in the IoV system with faulty data saturation is necessary. This paper proposes a Federated Learning-based Vehicle Trajectory Prediction Algorithm against Cyberattacks (FL-TP) to address the above problems. The FL-TP is intensively trained and tested using a publicly available Vehicular Reference Misbehavior (VeReMi) dataset with five types of cyberattacks: constant, constant offset, random, random offset, and eventual stop. The results show that the proposed FL-TP algorithm can improve cyberattack detection and trajectory prediction by up to 6.99% and 54.86%, respectively, under the maximum cyberattack permeability scenarios compared with benchmark methods.",
    "published_date": "2023-06-14",
    "pdf_link": "https://arxiv.org/pdf/2306.08566v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Vehicular Network Security",
      "subdomain": "V2X Misbehavior/Intrusion Detection",
      "specific_problem": "Federated multi-task vehicle trajectory prediction and cyberattack-type detection under falsified V2V messages",
      "attack_types": [
        "constant",
        "constant offset",
        "random",
        "random offset",
        "eventual stop"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": "Onboard multi-task LSTM that simultaneously predicts 5-step future trajectories and classifies received message attack type"
      },
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "Custom weighted aggregation (Model-robust Estimation, MrE)",
        "novel_contribution": "MrE assigns model aggregation weights based on effectiveness under different attack-type proportions, using an effectiveness gate γ and attack influence factor ξi"
      },
      {
        "type": "baseline",
        "category": "Federated Learning",
        "specific": "FedAvg",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "Centralized LSTM",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Federated",
      "Multi-task learning"
    ],
    "datasets": [
      {
        "name": "VeReMi (Vehicular Reference Misbehavior) dataset",
        "type": "public",
        "domain": "vehicular_network_messages",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "DARPA (IDS datasets, referenced)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ISCX (IDS dataset, referenced)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Centralized LSTM",
        "paper_reference": "[13]",
        "metric": "Cyberattack prediction accuracy (attack 75%, 20 vehicles)",
        "their_result": "0.979 ± 0.001 (FL-TP-20)",
        "baseline_result": "0.915 ± 0.007"
      },
      {
        "method_name": "Centralized LSTM",
        "paper_reference": "[13]",
        "metric": "Trajectory prediction error (avg Euclidean distance) (attack 75%, 20 vehicles)",
        "their_result": "21.447 ± 0.480 (FL-TP-20)",
        "baseline_result": "47.510 ± 1.541"
      },
      {
        "method_name": "FedAvg",
        "paper_reference": "[14]",
        "metric": "Cyberattack prediction accuracy (attack 75%, 20 vehicles)",
        "their_result": "0.979 ± 0.001 (FL-TP-20)",
        "baseline_result": "0.190 ± 0.0003"
      },
      {
        "method_name": "FedAvg",
        "paper_reference": "[14]",
        "metric": "Trajectory prediction error (avg Euclidean distance) (attack 75%, 20 vehicles)",
        "their_result": "21.447 ± 0.480 (FL-TP-20)",
        "baseline_result": "54.682 ± 1.289"
      }
    ],
    "performance_metrics_used": [
      "Prediction accuracy (cyberattack type classification)",
      "Prediction error (average Euclidean distance between predicted and actual trajectory)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a federated learning framework improve both vehicle trajectory prediction and cyberattack-type detection under varying attack penetration levels in IoV?",
        "How to aggregate client models effectively in FL when local data are contaminated by different cyberattack types and proportions?"
      ],
      "gaps_identified": [
        "“State-of-the-art vehicle trajectory prediction algorithms have yet to fully explore previous challenges, such as cyberattacks and user privacy.”",
        "“No adaptation or discussion of trajectory prediction algorithms has been implemented for cyberattacks of different degrees.”",
        "“To the best of our knowledge, there is no research investigating the trajectory prediction algorithm under cyberattack scenarios.”",
        "“There is no other research on the calculation of weights among all the different cyberattacks in the internet of vehicles.”"
      ],
      "limitations": [
        "It is difficult to generate proper aggregation weights for the MrE algorithm in the first several episodes; addressed by introducing an effectiveness judgment factor γ.",
        "Evaluated in simulation with the VeReMi dataset; authors plan larger-scale realistic simulations (no real-world deployment reported)."
      ],
      "future_work": [
        "“Carrying out extensive simulations using a large-scale realistic scenario to further assess the proposed algorithm’s performance.”"
      ],
      "motivation": "Mitigate safety risks from falsified V2V messages and protect driver privacy by using federated learning to enable vehicles to detect cyberattacks and accurately predict surrounding vehicle trajectories under different attack levels without sharing raw data.",
      "potential_research_ideas": [
        "Design and evaluate Byzantine-robust/poisoning-robust FL aggregation for IoV misbehavior detection (e.g., Krum, Trimmed Mean, coordinate-wise median) under adversarial clients.",
        "Replace or augment LSTM with attention-based sequence models (Transformer/Temporal Fusion Transformer) for improved long-horizon trajectory prediction under noisy/attacked inputs.",
        "Incorporate interaction-aware models (graph neural networks over vehicles) to capture multi-agent dynamics and misbehavior context.",
        "Develop uncertainty-aware prediction (e.g., probabilistic forecasts, conformal prediction) to quantify confidence under attack.",
        "Personalized FL for heterogeneous vehicles/roads (e.g., FedPer, pFedMe) to adapt to local conditions while sharing global knowledge.",
        "Extend attack taxonomy beyond five types (e.g., replay, Sybil, timing, message suppression) and study transfer/generalization across attacks.",
        "Multi-modal fusion (camera/radar/LiDAR with V2X messages) in FL to cross-validate and mitigate message falsification.",
        "Communication-efficient FL (quantization/sparsification) tailored to V2X bandwidth constraints and dynamic participation.",
        "Domain adaptation/simulation-to-reality transfer for deployment with real fleets and real V2X stacks."
      ],
      "architectural_improvement_recommendations": [
        "Use attention mechanisms or Transformer encoders on time series instead of or alongside LSTM to better handle long-term dependencies and noisy inputs.",
        "Adopt interaction-aware architectures (social pooling/graph attention) to model inter-vehicle influence explicitly in prediction and detection.",
        "Introduce robust FL aggregation (Krum, Trimmed Mean, FLTrust) and compare against MrE under adversarial client behaviors.",
        "Learn aggregation weights from a held-out validation meta-objective (e.g., meta-learning or performance-based weighting) rather than fixed γ and ξi schedules.",
        "Add uncertainty estimation (Monte Carlo dropout, deep ensembles) and use it for risk-aware planning and anomaly detection.",
        "Implement adaptive attack influence estimation ξi online with Bayesian updating instead of fixed Beta-function-based values.",
        "Employ personalized FL layers or adapters for clients with different traffic densities/attack profiles.",
        "Implement curriculum training by gradually increasing attack penetration to stabilize early training.",
        "Perform extensive ablations on γ and ξi, and sensitivity analysis to attack mix shifts."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/CoderTylor/FL-TP",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Onboard vehicle models with RSU/cloud aggregation in IoV (V2V/V2I)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Difficulty generating proper aggregation weights in early episodes; mitigated with effectiveness judgment factor γ=0.2",
        "Communication latency modeled via message propagation delay; real-world networking constraints not evaluated",
        "Model convergence degrades as attack penetration increases; stability in high-attack settings is challenging"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposed FL-TP: an FL framework with an LSTM network enabling vehicles to identify cyberattacks and predict surrounding vehicle trajectories under different cyberattack levels.",
      "Proposed a Model-robust Estimation (MrE) algorithm to compute aggregation weights and improve global FL aggregation effectiveness.",
      "Extensive experiments on the VeReMi dataset demonstrating improved cyberattack detection and trajectory prediction versus baselines across multiple attack penetration scenarios."
    ]
  },
  {
    "arxiv_id": "2306.05799v1",
    "title": "DETECTA: Investigación de metodologías no intrusivas apoyadas en tecnologías habilitadoras 4.0 para abordar un mantenimiento predictivo y ciberseguro en pymes industriales",
    "authors": "Alvaro García; Alejandro Echeverría; José Félix Ovejero",
    "abstract": "This work presents the results of the DETECTA project, which addresses industrial research activities for the generation of predictive knowledge aimed at detecting anomalies in machining-based manufacturing systems. It addresses different technological challenges to simultaneously improve the availability of machinery and the protection against cyberthreats of industrial systems, with the collaboration of knowledge centers and experts in industrial processes. Through the use of innovative technologies such as the digital twin and artificial intelligence, it implements process characterization methodologies and anomaly detection in a non-intrusive way without limiting the productivity of the industrial plant according to the maintenance and remote access needs. The research has been supported by a general evaluation of connected environments in small and medium-sized enterprises to identify if the benefits of digitization outweigh the risks that cannot be eliminated. The results obtained, through a process of supervision by process experts and machine learning, have made it possible to discriminate anomalies between purely technical events and events related to cyber incidents or cyber attacks.",
    "published_date": "2023-06-09",
    "pdf_link": "https://arxiv.org/pdf/2306.05799v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Industrial Control Systems Security",
      "subdomain": "Intrusion/Anomaly Detection in ICS",
      "specific_problem": "Non-intrusive anomaly detection in machining-based manufacturing to support predictive maintenance and discriminate technical faults from cyber incidents using digital twins and AI",
      "attack_types": [
        "Ransomware",
        "Malware",
        "Remote access abuse",
        "Industrial espionage",
        "Exploitation of unsegmented networks"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Anomaly Detection",
        "specific": null,
        "novel_contribution": "Non-intrusive, digital-twin-assisted anomaly detection on multi-sensor industrial data to separate technical events from cyber incidents under expert-in-the-loop supervision"
      },
      {
        "type": "primary",
        "category": "Semi-supervised learning",
        "specific": null,
        "novel_contribution": "Hybrid expert labeling plus semi-supervised modeling on real, labeled industrial datasets to learn process ‘patterns/footprints’ for early anomaly detection"
      },
      {
        "type": "primary",
        "category": "Simulation/Digital Twin",
        "specific": null,
        "novel_contribution": "Use of digital twin and black-box testing to generate and validate behavior patterns and cyber-attack scenarios non-intrusively without impacting production"
      }
    ],
    "learning_paradigm": [
      "Semi-supervised",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Machining cell multi-sensor dataset (current, vibration, temperature) from industrial milling machine",
        "type": "private",
        "domain": "industrial_sensor_timeseries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "FACYL Automotive cluster self-diagnosis survey (maintenance/digitalization)",
        "type": "private",
        "domain": "survey_responses",
        "link": "https://www.facyl.es/",
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "AEI Ciberseguridad y Tecnologías Avanzadas survey (cyber threats in industrial ecosystems)",
        "type": "private",
        "domain": "survey_responses",
        "link": "https://www.aeiciberseguridad.es/",
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can non-intrusive digital twin plus AI methods detect anomalies early in machining processes without limiting plant productivity?",
        "Can process expert supervision combined with machine learning discriminate anomalies between purely technical events and cyber incidents/attacks?",
        "Do the benefits of SME digitization outweigh the cybersecurity risks that cannot be eliminated in connected environments?",
        "How can heterogeneous processes involving people and machines be characterized to enable predictive maintenance and cybersecure operation?"
      ],
      "gaps_identified": [
        "Low adoption of predictive maintenance in SMEs: “todavía el mantenimiento preventivo es la estrategia utilizada en el 45% … relegadas [predictivo] a apenas el 10% de los casos”",
        "Legacy and heterogeneous proprietary industrial systems with closed interfaces hinder data access and integration (“acceso propietario e interfaces de comunicación heterogéneas … no abierta, con costes adicionales”)",
        "Increased cyber exposure due to OT/IT convergence and remote access; lack of network segmentation in many SMEs (“al menos un 35% … la red industrial y la red empresarial no están separadas”; “alrededor de un 30% … acceso directo … desde el exterior”)",
        "Need for non-intrusive monitoring/diagnostics that do not impact production to enable adoption in SMEs",
        "Rising ransomware and remote access threats against industrial control systems"
      ],
      "limitations": [
        "Validation performed in a controlled laboratory/digital twin setting rather than broad, long-term production deployments",
        "No detailed algorithmic specifications or quantitative evaluation metrics are reported",
        "Proprietary datasets; no public release, limiting reproducibility and comparability",
        "Generality across different machines/process types not yet demonstrated"
      ],
      "future_work": [
        "Field deployment in multiple SME plants to validate predictive indicators and cyber-incident discrimination in production environments",
        "Extending distributed data models across process and supply-chain points for broader coverage",
        "Expanding black-box cyber-attack scenario generation and resilience testing on the digital twin",
        "Operationalizing expert-in-the-loop workflows for continuous model refinement and governance"
      ],
      "motivation": "Improve machinery availability and cybersecurity protection in SMEs by using non-intrusive digital twin and AI to characterize processes and detect anomalies early, while assessing whether digitization benefits outweigh non-eliminable risks",
      "potential_research_ideas": [
        "Multi-modal fusion of physical sensor time series with OT network telemetry/ICS protocol logs to strengthen discrimination of technical vs cyber anomalies",
        "Self-supervised representation learning on unlabeled industrial sensor streams to reduce reliance on labeled data and expert time",
        "Domain adaptation/transfer learning to port models across different machines and processes with minimal recalibration",
        "Synthetic anomaly and cyber-attack scenario generation via the digital twin for data augmentation and stress testing",
        "Federated/edge learning across multiple SME sites to protect data locality while improving generalization",
        "Root-cause analysis models linking events, assets, and processes (knowledge graphs) for actionable diagnostics",
        "Online learning with drift detection for non-stationary industrial processes"
      ],
      "architectural_improvement_recommendations": [
        "Adopt multi-channel time-series models (e.g., temporal CNNs or Transformers) over synchronized current/vibration/temperature streams with cross-channel attention",
        "Integrate probabilistic uncertainty estimation (e.g., deep ensembles or Bayesian layers) to flag low-confidence anomalies for expert review",
        "Combine unsupervised change-point detection with semi-supervised classifiers to improve early warning and reduce false positives",
        "Embed physics- and process-aware constraints/rules into the ML pipeline to respect operational limits and improve interpretability",
        "Use explanation tools tailored to time series (e.g., attribution over time/frequency) to support expert-in-the-loop triage",
        "Build a two-branch architecture: physical process branch (sensors) + cyber branch (network/endpoint signals) with late fusion for cause separation"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Industrial machining cell (milling) in SME context; validated via lab digital twin using real sensor data",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Heterogeneous and proprietary industrial interfaces hindering data access/integration",
        "Legacy equipment not designed for connectivity or security and sometimes not updatable",
        "Lack of network segmentation and prevalence of direct external access to industrial networks",
        "Increased exposure to ransomware and remote access threats",
        "Limited in-house specialization in predictive maintenance and AI within SMEs",
        "Need for non-intrusive solutions that do not impact production"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a non-intrusive methodology that combines digital twin and AI for process characterization and anomaly detection in machining-based manufacturing",
      "Three-part solution: (i) non-intrusive full-information process characterization, (ii) early detection of technical anomalies, (iii) discrimination between technical causes and cyber incidents/attacks",
      "Builds a virtual interface/digital twin to visualize and parameterize multi-sensor indicators (current, vibration, temperature) and to host AI and black-box testing tools",
      "Conducts sector self-diagnoses in SMEs to assess maintenance maturity and cybersecurity posture, reporting key findings: “el mantenimiento preventivo es … 45% … [predictivo] apenas el 10%”; “al menos un 35% … la red industrial y la red empresarial no están separadas”; “alrededor de un 30% … acceso directo … desde el exterior”",
      "Validates learned patterns via expert-in-the-loop and digital twin testing, enabling discrimination “entre eventos puramente técnicos y eventos relacionados con ciberincidentes o ciberataques”",
      "Bridges predictive maintenance and cybersecurity within converged OT/IT SME environments using non-intrusive, black-box-compatible methods"
    ]
  },
  {
    "arxiv_id": "2306.02270v4",
    "title": "Crypto-Ransomware and Their Defenses: In-depth Behavioral Characterization, Discussion of Deployability, and New Insights",
    "authors": "Wenjia Song; Sanjula Karanam; Ya Xiao; Jingyuan Qi; Nathan Dautenhahn; Na Meng; Elena Ferrari;  Danfeng;  Yao",
    "abstract": "Crypto-ransomware has caused an unprecedented scope of impact in recent years with an evolving level of sophistication. An extensive range of studies have been on defending against ransomware and reviewing the efficacy of various protections. However, for practical defenses, deployability holds equal significance as detection accuracy. Therefore, in this study, we review 117 published ransomware defense works, categorize them by the level they are implemented at, and discuss the deployability. API-based solutions are easy to deploy and most existing works focus on machine learning-based classification. To provide more insights, we quantitively characterize the runtime behaviors of real-world ransomware samples. Based on our experimental findings, we present a possible future detection direction with our consistency analysis and API-contrast-based refinement. Moreover, we experimentally evaluate various commercial defenses and identify the security gaps. Our findings help the field understand the deployability of ransomware defenses and create more effective, practical solutions.",
    "published_date": "2023-06-04",
    "pdf_link": "https://arxiv.org/pdf/2306.02270v4",
    "paper_types": [
      "position",
      "empirical_analysis",
      "survey"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Ransomware Detection",
      "specific_problem": "Deployable detection and characterization of crypto-ransomware behaviors; evaluation of commercial defenses",
      "attack_types": [
        "Crypto-ransomware",
        "File-encrypting ransomware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Rule-based / Statistical pattern analysis",
        "specific": "Consistency analysis + API-contrast score refinement",
        "novel_contribution": "Proposes a deployable detection direction using consistency analysis of encryption-centric behaviors and an API usage contrast score to refine positives; feasibility test on execution traces"
      }
    ],
    "learning_paradigm": [],
    "datasets": [
      {
        "name": "54 real-world ransomware samples (35 families) for manual behavioral inspection",
        "type": "private",
        "domain": "malware_binaries; dynamic_behavior_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "API invocation dataset: occurrence frequency of 288 Windows APIs from 348 ransomware samples",
        "type": "private",
        "domain": "dynamic_behavior_traces (Windows API calls)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Benign software execution traces for comparison",
        "type": "private",
        "domain": "dynamic_behavior_traces (Windows API calls)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Antivirus evaluation set: 20 real ransomware samples (2015–2020)",
        "type": "private",
        "domain": "malware_binaries; endpoint_evaluation",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "VirusTotal scan set: 54 ransomware samples tested under 3 packaging settings",
        "type": "private",
        "domain": "malware_binaries; static_scan_artifacts",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Commercial decryptors (No More Ransom, 6 family-specific tools)",
        "paper_reference": null,
        "metric": "Success rate (decrypted vs. not)",
        "their_result": "\"The success rate of commercial decryptors is low (1 success out of 6), suffering from low generality across variants of ransomware.\"",
        "baseline_result": null
      },
      {
        "method_name": "Commercial antivirus (8 products incl. Bitdefender, Malwarebytes, Kaspersky, McAfee, Norton, 360 Total Security, plus two anonymized)",
        "paper_reference": null,
        "metric": "Qualitative detection behavior against real samples and simulators",
        "their_result": "\"Anti-virus software detects only generic malicious behaviors, being insensitive to core ransomware encryption.\" 360 Total Security performed poorly offline.",
        "baseline_result": null
      },
      {
        "method_name": "Commercial malware scanners on VirusTotal (>70 engines)",
        "paper_reference": null,
        "metric": "Detection of plain vs. password-protected (simple and complex) archives",
        "their_result": "\"Malware scanners use signature-based detection and miss unknown or obfuscated samples.\"",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Success rate (decryptors)",
      "Qualitative detection behavior",
      "Feasibility identification of malicious executions (consistency analysis)",
      "API contrast score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: What are the existing ransomware defenses? What are the more deployable approaches?",
        "RQ2: For highly deployable commercial defenses, what are the ransomware behaviors that trigger detection? What are the security gaps?",
        "RQ3: What are the quantitative ransomware API invocation behaviors? How do they systematically compare with benign software? How to quantify the unique ransomware API usage patterns for detection?"
      ],
      "gaps_identified": [
        "Limited focus on deployability of ransomware defenses despite high effectiveness reported in literature.",
        "File-system and kernel-level solutions (e.g., ShieldFS, UNVEIL) require kernel modifications; hard to deploy broadly.",
        "Existing API-based works largely rely on ML classification without in-depth ransomware-specific execution analyses.",
        "Commercial decryptors show low generality across variants (1/6 success).",
        "Antivirus tools tend to flag generic behaviors and are insensitive to core encryption behaviors.",
        "Signature-based malware scanners often fail on unknown or obfuscated (e.g., password-protected) samples.",
        "Need for behavioral, ransomware-specific detection and deployable API-level monitoring with manageable overhead."
      ],
      "limitations": [],
      "future_work": [
        "Pursue deployable API-based behavioral detection using consistency analysis focused on encryption and refine with API-contrast scoring.",
        "Explore selective API monitoring to reduce instrumentation overhead during deployment.",
        "Use quantitative API-usage profiling to strengthen ransomware-specific protection in commercial tools."
      ],
      "motivation": "Understand deployability of ransomware defenses, quantify ransomware-specific runtime/API behaviors, evaluate commercial defenses, and suggest a deployable detection path beyond raw ML classification.",
      "potential_research_ideas": [
        "Create and release a standardized, labeled dataset of Windows API call traces for ransomware and benignware with family/variant annotations.",
        "Develop a hybrid detector combining consistency analysis (crypto-centric signals) with sequence models (e.g., HMM/Transformer) on API streams.",
        "Adversarial robustness study: evaluate and harden API-contrast-based detection against API padding, call reordering, and living-off-the-land techniques.",
        "Cross-layer fusion: integrate API-contrast with lightweight kernel I/O entropy signals or hardware counters for stronger, evasion-resistant detection.",
        "Early-stage (pre-encryption) detection benchmarking with standardized scenarios and time-to-detect metrics.",
        "Online learning/continual adaptation to emerging ransomware families while controlling false positives.",
        "Cross-OS generalization: port methodology to Linux/macOS and evaluate portability of API-contrast features."
      ],
      "architectural_improvement_recommendations": [
        "Implement selective and adaptive API hooking guided by information gain to minimize overhead while preserving discriminative signals.",
        "Augment consistency analysis with streaming sequence encoders (Temporal CNN/Transformer) constrained by crypto-behavior priors.",
        "Incorporate per-process context (file types, extension changes, VSS deletion, registry edits) into a multi-view model with late fusion.",
        "Calibrate API-contrast with family-agnostic normalization to improve generality across ransomware variants.",
        "Deploy a two-stage pipeline: lightweight pre-filter (early-stage signals) followed by deeper analysis only on suspicious processes.",
        "Add provenance tracking to associate encryption actions with initiating processes to reduce false positives from benign encryptors."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Python 3.8",
        "Intel PIN (for API instrumentation)"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "Experiments conducted on a Windows 7 VM (2 CPUs, 4096 MB RAM); offline execution for real ransomware; network disconnected. Feasibility tests on 29 execution traces; API monitoring over 288 Windows APIs."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Windows endpoint VM (Windows 7) for experiments; evaluation of commercial tools; dynamic instrumentation environment",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Kernel-level approaches require OS/driver modifications and are hard to port.",
        "API instrumentation can introduce notable runtime overhead; selective monitoring suggested.",
        "Commercial tools show gaps: decryptors lack generality; AVs miss core encryption; scanners fail on obfuscated samples.",
        "System-version dependencies and manual configurations hinder low-level solutions.",
        "Evasion risk via API obfuscation or packing for API-based methods."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Reviewed 117 ransomware defense works and analyzed deployability by system level.",
      "Quantitatively characterized runtime behaviors and API usage of real-world ransomware (54 samples manual analysis; 348-sample API frequency dataset; comparison with benign software).",
      "Proposed a deployable detection direction using consistency analysis and API-contrast-based refinement; feasibility assessment on 29 execution traces (identified all malicious executions).",
      "Experimentally evaluated commercial defenses (6 decryptors, ~70 VirusTotal scanners, 8 antivirus) and identified security gaps (low decryptor generality; AV insensitivity to core encryption; scanners miss obfuscated samples)."
    ]
  },
  {
    "arxiv_id": "2306.09260v2",
    "title": "IsoEx: an explainable unsupervised approach to process event logs cyber investigation",
    "authors": "Pierre Lavieille; Ismail Alaoui Hassani Atlas",
    "abstract": "39 seconds. That is the timelapse between two consecutive cyber attacks as of 2023. Meaning that by the time you are done reading this abstract, about 1 or 2 additional cyber attacks would have occurred somewhere in the world. In this context of highly increased frequency of cyber threats, Security Operation Centers (SOC) and Computer Emergency Response Teams (CERT) can be overwhelmed. In order to relieve the cybersecurity teams in their investigative effort and help them focus on more added-value tasks, machine learning approaches and methods started to emerge. This paper introduces a novel method, IsoEx, for detecting anomalous and potentially problematic command lines during the investigation of contaminated devices. IsoEx is built around a set of features that leverages the log structure of the command line, as well as its parent/child relationship, to achieve a greater accuracy than traditional methods. To detect anomalies, IsoEx resorts to an unsupervised anomaly detection technique that is both highly sensitive and lightweight. A key contribution of the paper is its emphasis on interpretability, achieved through the features themselves and the application of eXplainable Artificial Intelligence (XAI) techniques and visualizations. This is critical to ensure the adoption of the method by SOC and CERT teams, as the paper argues that the current literature on machine learning for log investigation has not adequately addressed the issue of explainability. This method was proven efficient in a real-life environment as it was built to support a companyś SOC and CERT",
    "published_date": "2023-06-07",
    "pdf_link": "https://arxiv.org/pdf/2306.09260v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Endpoint Security",
      "subdomain": "Process Monitoring / EDR",
      "specific_problem": "Unsupervised anomaly detection of command-line process events to aid SOC/CERT investigations with explainable outputs",
      "attack_types": [
        "malware",
        "anomalous command lines",
        "command-line obfuscation",
        "novel/previously unseen attacks"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Anomaly Detection (unsupervised)",
        "specific": null,
        "novel_contribution": "Combines interpretable, domain-informed features (leveraging command-line structure and parent/child relationships) with a lightweight unsupervised anomaly detector; emphasis on explainability for analysts."
      },
      {
        "type": "primary",
        "category": "XAI / Interpretability",
        "specific": null,
        "novel_contribution": "Applies explainable AI techniques and visualizations tied to SOC/CERT concepts (parent-child process relations, obfuscation indicators) to justify anomaly scores for analyst-led operations."
      },
      {
        "type": "primary",
        "category": "Rule-based feature engineering",
        "specific": null,
        "novel_contribution": "Rule-based heuristics (e.g., IOC/signature checks, obfuscation indicators) transformed into quantitative and Boolean features to enhance interpretability and detection sensitivity."
      },
      {
        "type": "primary",
        "category": "NLP-inspired feature engineering",
        "specific": null,
        "novel_contribution": "Token/character frequency and structural features derived from command lines (e.g., counts, frequency-based thresholds) to capture suspicious patterns while remaining interpretable."
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Rule-based"
    ],
    "datasets": [
      {
        "name": "Microsoft Defender for Endpoint: Process creation events",
        "type": "proprietary",
        "domain": "process_events",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Microsoft Defender for Endpoint: DeviceImageLoadEvents (image load events)",
        "type": "proprietary",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can an unsupervised, lightweight anomaly detector over process event command lines effectively surface potentially malicious activity during incident investigations?",
        "How can explainability be incorporated so SOC/CERT analysts can understand and trust anomaly detections using familiar concepts (e.g., parent-child relations, obfuscation)?",
        "Do features derived from command-line structure and parent/child relationships improve detection compared to traditional methods?"
      ],
      "gaps_identified": [
        "Explainability is under-addressed in machine learning for log/process-event investigation; most prior XAI work focuses on IDS, malware classification, and phishing, not process-event anomaly detection.",
        "Supervised methods require large labeled datasets, can be costly, and may be less robust to novel attacks.",
        "Unsupervised anomaly detection methods, while sensitive to novel attacks, often suffer from higher false positive rates that hinder adoption."
      ],
      "limitations": [
        "Source code is not released due to security concerns.",
        "Specific feature details are intentionally kept ambiguous to avoid aiding adversaries.",
        "Evaluation relies on proprietary Microsoft Defender data; public replication data are not available.",
        "Unsupervised methods may yield higher false positives; mitigation relies on analyst-in-the-loop."
      ],
      "future_work": [
        "Iterative refinement using analyst feedback to reduce false positives and improve explanations.",
        "Adapting and validating the approach across different EDRs/raw logs with standardized preprocessing.",
        "More comprehensive quantitative evaluation and benchmarking against established baselines.",
        "Expanding explainability tooling and visualizations tailored to SOC/CERT workflows."
      ],
      "motivation": "Relieve overwhelmed SOC/CERT teams by rapidly surfacing anomalous and potentially malicious command lines from vast process event logs, with explanations that enable analyst trust and action.",
      "potential_research_ideas": [
        "Develop a public benchmark for process-event anomaly detection with explainability annotations to enable fair comparisons.",
        "Integrate active learning or analyst feedback loops (e.g., weak labels, pairwise constraints) to calibrate anomaly scores and reduce false positives.",
        "Explore graph-based models over process trees and image loads (parent–child DAGs) combined with interpretable subgraph motifs.",
        "Evaluate and ensemble multiple lightweight unsupervised detectors (e.g., Isolation Forest, One-Class SVM, LOF) with interpretable score fusion.",
        "Design adversarially robust features against command-line obfuscation (e.g., canonicalization, deobfuscation heuristics) and test with red-team generated perturbations.",
        "Add privacy-preserving aggregation/federated learning across endpoints to widen coverage without centralizing raw logs."
      ],
      "architectural_improvement_recommendations": [
        "Hybrid scoring pipeline: combine rule-based IOC/obfuscation flags with calibrated anomaly scores; use learnable weights validated via analyst feedback.",
        "Calibrate anomaly scores using conformal prediction or extreme value theory to control false positive rates.",
        "Adopt model-agnostic explanation methods (e.g., SHAP for tree-based detectors) and map feature attributions to SOC-relevant concepts (parent/child, obfuscation tokens).",
        "Introduce process-tree context windows (temporal and hierarchical) so anomaly decisions incorporate local lineage behavior and image-load sequences.",
        "Standardize a preprocessing schema for cross-EDR ingestion to improve portability and reproducibility."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Described as lightweight; no specific hardware or runtime details provided."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Enterprise endpoints monitored by Microsoft Defender; analyst-led SOC/CERT workflows",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Higher false positive rates typical of unsupervised anomaly detection require analyst triage.",
        "Data heterogeneity across EDRs/raw logs necessitates preprocessing and schema alignment.",
        "Security concerns limit code release and feature disclosure, complicating external validation."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces IsoEx, a novel explainable unsupervised approach to detect anomalous command lines in process event logs.",
      "Feature engineering leveraging command-line structure and parent/child process relationships, combining rule-based and ML-derived features.",
      "Emphasis on interpretability via XAI techniques and visualizations aligned with SOC/CERT concepts.",
      "Lightweight, unsupervised anomaly detection intended for analyst-led investigations.",
      "Demonstrated usefulness in a real-life environment supporting a company’s SOC and CERT."
    ]
  },
  {
    "arxiv_id": "2305.09594v1",
    "title": "HiNoVa: A Novel Open-Set Detection Method for Automating RF Device Authentication",
    "authors": "Luke Puppo; Weng-Keen Wong; Bechir Hamdaoui; Abdurrahman Elmaghbub",
    "abstract": "New capabilities in wireless network security have been enabled by deep learning, which leverages patterns in radio frequency (RF) data to identify and authenticate devices. Open-set detection is an area of deep learning that identifies samples captured from new devices during deployment that were not part of the training set. Past work in open-set detection has mostly been applied to independent and identically distributed data such as images. In contrast, RF signal data present a unique set of challenges as the data forms a time series with non-linear time dependencies among the samples. We introduce a novel open-set detection approach based on the patterns of the hidden state values within a Convolutional Neural Network (CNN) Long Short-Term Memory (LSTM) model. Our approach greatly improves the Area Under the Precision-Recall Curve on LoRa, Wireless-WiFi, and Wired-WiFi datasets, and hence, can be used successfully to monitor and control unauthorized network access of wireless devices.",
    "published_date": "2023-05-16",
    "pdf_link": "https://arxiv.org/pdf/2305.09594v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT/Wireless Security",
      "subdomain": "RF device fingerprinting and authentication",
      "specific_problem": "Open-set detection of unauthorized (unknown) RF transmitters among known authenticated devices",
      "attack_types": [
        "device cloning",
        "man-in-the-middle"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN + LSTM",
        "specific": "CNN feature extractor feeding LSTM; LogSoftmax classifier",
        "novel_contribution": "Hidden Node Value (LSTM internal state) fingerprinting: build per-device histograms over LSTM hidden states from correctly classified slices and use them for open-set detection"
      },
      {
        "type": "primary",
        "category": "Statistical correlation / ranking",
        "specific": "Kendall’s tau correlation over flattened hidden-state histograms",
        "novel_contribution": "Use maximal Kendall’s tau between test fingerprint and known device fingerprints; threshold 1 - max(tau) for open-set decision"
      },
      {
        "type": "baseline",
        "category": "Logit-based confidence",
        "specific": "MaxLogit",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Softmax-based confidence",
        "specific": "Maximum softmax probability",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Statistical correlation",
        "specific": "Pearson correlation (linear) between fingerprints",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Open-set detection"
    ],
    "datasets": [
      {
        "name": "LoRa",
        "type": "proprietary",
        "domain": "rf_iq_signals",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Wireless-WiFi",
        "type": "proprietary",
        "domain": "rf_iq_signals",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Wired-WiFi",
        "type": "proprietary",
        "domain": "rf_iq_signals",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "MaxLogit",
        "paper_reference": "[5], [6] in paper",
        "metric": "AUPRC",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Maximum softmax probability",
        "paper_reference": "[4], [10] in paper",
        "metric": "AUPRC",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Pearson correlation between hidden-state fingerprints",
        "paper_reference": null,
        "metric": "AUPRC",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "AUPRC (Area Under the Precision-Recall Curve)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can LSTM hidden state values be leveraged to form device-specific fingerprints that enable accurate open-set detection of unknown RF devices?",
        "Does a rank-based correlation measure (Kendall’s tau) between hidden-state histograms outperform linear correlation and logit/softmax-based confidence methods for RF open-set detection?",
        "How well does the proposed method perform across different RF protocols (LoRa, Wireless-WiFi, Wired-WiFi)?"
      ],
      "gaps_identified": [
        "Most open-set detection literature targets i.i.d. data (e.g., images), not RF time-series with non-linear temporal dependencies.",
        "Existing time-series open-set methods (e.g., DTW-based barycenters) can be computationally expensive (DTW O(T^2)).",
        "Softmax probabilities normalize logits and can discard magnitude information useful for open-set detection; MaxLogit is a stronger baseline but still not tailored to RF temporal patterns.",
        "Limited prior work applying open-set detection specifically to RF device fingerprinting."
      ],
      "limitations": [
        "Evaluation appears limited to a 15-device PyCom testbed and two protocols (LoRa and WiFi); broader generalization not demonstrated in text provided.",
        "Method depends on correctly classified slices to build fingerprints; behavior under high closed-set classification error not detailed.",
        "Threshold selection for (1 - max Kendall’s tau) not detailed in provided text."
      ],
      "future_work": [],
      "motivation": "Detect unauthorized/unknown IoT devices using RF fingerprinting in realistic open-set conditions where deployment may include devices not seen during training, with an efficient real-time method tailored to RF time-series.",
      "potential_research_ideas": [
        "Integrate self-supervised pretraining on raw IQ to improve hidden-state representations before fingerprinting.",
        "Explore Transformer-based temporal encoders (e.g., temporal attention) and compare hidden-state fingerprinting vs. LSTM.",
        "Model hidden-state distributions with probabilistic density models (e.g., Gaussian mixtures) and use likelihood ratios for open-set scoring.",
        "Domain adaptation across channel conditions (wireless vs wired, varying SNR, multipath) to enhance robustness.",
        "Outlier exposure during training with synthetic unknowns (e.g., generative augmentations) to calibrate open-set thresholds.",
        "Multi-layer/multi-time-step fingerprinting that aggregates hidden states across layers/time for richer signatures.",
        "Evaluate and harden against adversarial/spoofing attacks attempting to mimic hidden-state fingerprints."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment LSTM with Temporal Convolutional Networks or Transformers and assess fingerprint stability and separability.",
        "Use contrastive/metric learning (e.g., supervised contrastive loss) to structure hidden-state space for better within-device compactness and between-device separation before histogramming.",
        "Fuse multiple internal signals (forget gate, cell state, hidden state) and learn binning via differentiable histogram layers.",
        "Adopt adaptive thresholding calibrated per deployment using validation unknowns or Extreme Value Theory on scores.",
        "Compare Kendall’s tau with learned similarity metrics (e.g., shallow MLP or Mahalanobis distance with covariance estimated from training hidden-states)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Authors state detection can run in real-time on consumer-grade devices after training; no specific GPU/CPU details provided."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Lab RF testbed with 15 PyCom IoT transmitters and an Ettus USRP B210 receiver; indoor wireless and wired setups.",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces HiNoVa, a novel open-set detection method that builds per-device fingerprints from LSTM hidden node value histograms.",
      "Leverages Kendall’s tau rank correlation between hidden-state fingerprints for detecting unknown devices; uses thresholding on 1 - max(tau).",
      "RF-specific preprocessing via auto-correlation of IQ samples to emphasize cyclostationary features; CNN+LSTM architecture tailored to RF time-series.",
      "Demonstrates improved AUPRC for open-set detection on LoRa, Wireless-WiFi, and Wired-WiFi datasets collected from a 15-device testbed.",
      "Design emphasizes post-training efficiency suitable for real-time detection on consumer-grade devices."
    ]
  },
  {
    "arxiv_id": "2305.16615v1",
    "title": "AIBugHunter: A Practical Tool for Predicting, Classifying and Repairing Software Vulnerabilities",
    "authors": "Michael Fu; Chakkrit Tantithamthavorn; Trung Le; Yuki Kume; Van Nguyen; Dinh Phung; John Grundy",
    "abstract": "Many ML-based approaches have been proposed to automatically detect, localize, and repair software vulnerabilities. While ML-based methods are more effective than program analysis-based vulnerability analysis tools, few have been integrated into modern IDEs, hindering practical adoption. To bridge this critical gap, we propose AIBugHunter, a novel ML-based software vulnerability analysis tool for C/C++ languages that is integrated into Visual Studio Code. AIBugHunter helps software developers to achieve real-time vulnerability detection, explanation, and repairs during programming. In particular, AIBugHunter scans through developers' source code to (1) locate vulnerabilities, (2) identify vulnerability types, (3) estimate vulnerability severity, and (4) suggest vulnerability repairs. In this article, we propose a novel multi-objective optimization (MOO)-based vulnerability classification approach and a transformer-based estimation approach to help AIBugHunter accurately identify vulnerability types and estimate severity. Our empirical experiments on a large dataset consisting of 188K+ C/C++ functions confirm that our proposed approaches are more accurate than other state-of-the-art baseline methods for vulnerability classification and estimation. Furthermore, we conduct qualitative evaluations including a survey study and a user study to obtain software practitioners' perceptions of our AIBugHunter tool and assess the impact that AIBugHunter may have on developers' productivity in security aspects. Our survey study shows that our AIBugHunter is perceived as useful where 90% of the participants consider adopting our AIBugHunter. Last but not least, our user study shows that our AIBugHunter could possibly enhance developers' productivity in combating cybersecurity issues during software development.",
    "published_date": "2023-05-26",
    "pdf_link": "https://arxiv.org/pdf/2305.16615v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection and Repair",
      "specific_problem": "Real-time prediction, classification (CWE-ID/Type), severity estimation (CVSS), and repair of C/C++ software vulnerabilities within a VS Code IDE plugin",
      "attack_types": [
        "Buffer errors (CWE-119)",
        "Out-of-bounds write (CWE-787)",
        "Memory corruption",
        "Various CWE categories (CWE-ID and CWE-Type)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "CodeBERT",
        "novel_contribution": "Multi-objective, multi-task CWE classification with two special class tokens (for CWE-ID and CWE-Type) and two non-shared classification heads optimizing correlated tasks"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "CodeBERT",
        "novel_contribution": "Transformer-based regression model to estimate CVSS severity score for vulnerable functions"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Transformer encoder (LineVul)",
        "novel_contribution": "Used for line-level vulnerability localization via attention aggregation (integrated from prior work)"
      },
      {
        "type": "baseline",
        "category": "Encoder-Decoder Transformer",
        "specific": "T5 (VulRepair)",
        "novel_contribution": "Used for automated vulnerability repair patch generation (integrated from prior work)"
      },
      {
        "type": "baseline",
        "category": "Tokenizer",
        "specific": "Byte Pair Encoding (BPE)",
        "novel_contribution": "Subword tokenization to mitigate OOV in code tokens"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Multi-task Learning",
      "Transfer Learning (pretrained CodeBERT)"
    ],
    "datasets": [
      {
        "name": "AIBugHunter C/C++ vulnerability dataset (188K+ functions)",
        "type": "public",
        "domain": "source_code_functions",
        "link": "https://github.com/awsm-research/AIBugHunter",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Big-Vul",
        "type": "public",
        "domain": "source_code_functions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CVEFixes",
        "type": "public",
        "domain": "source_code_functions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CodeSearchNet (for tokenizer/vocabulary)",
        "type": "public",
        "domain": "source_code_corpus",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "Mean Squared Error (MSE)",
      "Mean Absolute Error (MAE)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "RQ1: How accurate is the proposed multi-objective approach at classifying CWE-ID for vulnerable C/C++ functions?",
        "RQ2: How accurate is the proposed multi-objective approach at classifying CWE-Type for vulnerable C/C++ functions?",
        "RQ3: How effective is the transformer-based approach at estimating CVSS severity scores (in terms of MSE/MAE)?",
        "RQ4: What are software practitioners’ perceptions of AIBugHunter and what impact does it have on developers’ productivity in security aspects?"
      ],
      "gaps_identified": [
        "Few ML-based vulnerability analysis methods are integrated into modern IDEs, hindering practical adoption.",
        "Program analysis tools rely on predefined patterns and struggle to detect diverse or evolving vulnerability types.",
        "Need for shift-left security with real-time, developer-centric tooling in IDEs."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Bridge the gap between accurate ML-based vulnerability analysis and practical developer adoption via IDE integration, providing real-time detection, explanation, severity estimation, and repair suggestions.",
      "potential_research_ideas": [
        "Extend to multi-language support (e.g., Java, Python, Rust) using multilingual code models and language adapters.",
        "Incorporate graph-based program representations (AST/CFG/DFG/CPG) and GNNs to enhance type and severity prediction.",
        "Active/online learning from developer feedback in-IDE to continually adapt models to project-specific codebases.",
        "Uncertainty estimation and calibration to communicate confidence to developers and guide triage/prioritization.",
        "Hybrid ML + static analysis fusion to combine precision of PA rules with ML generalization (e.g., co-training or features).",
        "Predict CVSS metric vectors (base metrics) as auxiliary tasks and derive score to improve severity generalization.",
        "Evaluate and harden against adversarial code perturbations and obfuscations to improve robustness.",
        "Human-in-the-loop repair ranking and constrained patch generation to ensure compilability and test-passing."
      ],
      "architectural_improvement_recommendations": [
        "Augment CodeBERT inputs with structural features (AST paths, dataflow edges) via multi-modal encoders or adapters.",
        "Use parameter-efficient fine-tuning (LoRA/adapters) for faster updates and on-device adaptation.",
        "Implement task uncertainty-weighted multi-task loss or dynamic weight averaging for MOO stability.",
        "Address class imbalance in CWE types with focal loss, re-weighting, or curriculum learning.",
        "Predict CVSS base metric components as multi-label classification jointly with CWE tasks.",
        "Introduce uncertainty calibration (temperature scaling) and confidence-based suppression in IDE warnings.",
        "Distill models for low-latency on-device inference; cache and incremental analysis to preserve real-time UX."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/awsm-research/AIBugHunter",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Visual Studio Code IDE extension (developer workstation)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "AIBugHunter: an ML-based security tool integrated into VS Code for real-time vulnerability localization, classification, severity estimation, and repair.",
      "Quantitative evaluation on a large dataset (188K+ C/C++ functions) showing high precision and recall.",
      "Survey study with 21 practitioners indicating usefulness and potential acceptance (90% would consider adopting).",
      "User study with 6 practitioners suggesting improved productivity for security tasks.",
      "A multi-objective optimization approach for CWE-ID and CWE-Type classification under a multi-task learning setup.",
      "A transformer-based approach to estimate vulnerability severity (CVSS score) for C/C++ vulnerable functions."
    ]
  },
  {
    "arxiv_id": "2305.12534v5",
    "title": "BertRLFuzzer: A BERT and Reinforcement Learning Based Fuzzer",
    "authors": "Piyush Jha; Joseph Scott; Jaya Sriram Ganeshna; Mudit Singh; Vijay Ganesh",
    "abstract": "We present a novel tool BertRLFuzzer, a BERT and Reinforcement Learning (RL) based fuzzer aimed at finding security vulnerabilities for Web applications. BertRLFuzzer works as follows: given a set of seed inputs, the fuzzer performs grammar-adhering and attack-provoking mutation operations on them to generate candidate attack vectors. The key insight of BertRLFuzzer is the use of RL with a BERT model as an agent to guide the fuzzer to efficiently learn grammar-adhering and attack-provoking mutation operators. In order to establish the efficacy of BertRLFuzzer we compare it against a total of 13 black box and white box fuzzers over a benchmark of 9 victim websites with over 16K LOC. We observed a significant improvement relative to the nearest competing tool in terms of time to first attack (54% less), new vulnerabilities found (17 new vulnerabilities), and attack rate (4.4% more attack vectors generated).",
    "published_date": "2023-05-21",
    "pdf_link": "https://arxiv.org/pdf/2305.12534v5",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Web Application Security",
      "subdomain": "Fuzzing and Vulnerability Discovery",
      "specific_problem": "Automatic grammar-adhering mutation-based fuzzing guided by BERT and reinforcement learning to discover injection vulnerabilities in web applications",
      "attack_types": [
        "SQL injection (SQLi)",
        "Cross-site scripting (XSS)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT",
        "novel_contribution": "Uses a BERT language model as the agent representation inside an RL-guided fuzzing loop to learn grammar-adhering, attack-provoking mutation operators."
      },
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": null,
        "novel_contribution": "RL feedback loop trains the BERT-based agent to efficiently search the space of attack vectors and learn mutation operators without labeled data."
      },
      {
        "type": "baseline",
        "category": "RNN/GRU + RL",
        "specific": "GRU-PPO",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Deep Q-Network",
        "specific": "DQN fuzzer; Multi-head DQN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Supervised Deep Learning",
        "specific": "DeepSQLi; DeepFuzz; DeepXSS; DeepFix (modified versions where noted)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Semi-supervised"
    ],
    "datasets": [
      {
        "name": "Benchmark of 9 victim web applications (up to 16K LOC)",
        "type": "proprietary",
        "domain": "web_applications",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Attack vector seed corpus (~7K injection attack vectors from public GitHub repositories)",
        "type": "public",
        "domain": "attack_payload_strings",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "DeepSQLi",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "DeepFuzz",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "DQN fuzzer",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "DeepXSS (modified)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "DeepFix (modified)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "GRU-PPO",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Multi-head DQN",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "BIOFuzz",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "SQLMap",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Baseline mutator (grammar-adhering)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Ardilla (white-box)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Random mutator",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Random fuzzer",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Nearest competing tool (unspecified)",
        "paper_reference": null,
        "metric": "Time to first attack",
        "their_result": "54% less than the nearest competing tool",
        "baseline_result": "Reference tool’s time (not specified)"
      },
      {
        "method_name": "Nearest competing tool (unspecified)",
        "paper_reference": null,
        "metric": "Time to find all vulnerabilities",
        "their_result": "40–60% less than the nearest competing tool",
        "baseline_result": "Reference tool’s time (not specified)"
      },
      {
        "method_name": "Nearest competing tool (unspecified)",
        "paper_reference": null,
        "metric": "Attack rate",
        "their_result": "4.4% more attack vectors generated than the nearest competing tool",
        "baseline_result": "Reference tool’s attack rate (not specified)"
      }
    ],
    "performance_metrics_used": [
      "time_to_first_attack",
      "time_to_find_all_vulnerabilities",
      "attack_rate",
      "number_of_new_vulnerabilities_found"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Fuzzers often require explicit, hand-crafted grammars, which is time-consuming and error-prone when retargeting to new applications.",
        "Supervised ML-based fuzzers require large labeled datasets of attack vectors.",
        "Existing mutation fuzzers (ML and non-ML) struggle to be grammar-adhering without manual grammar specification.",
        "Extending hand-written grammar-preserving fuzzers to new vulnerability classes or updated sanitizers requires repeated human effort.",
        "Sanitizers in web applications can be error-prone and give a false sense of security; finding their weaknesses is challenging."
      ],
      "limitations": [
        "Requires representative grammar-adhering seed inputs from the target vulnerability class; cannot generate attack patterns it has not seen (e.g., cannot discover UNION-based attacks if such seeds were not present).",
        "Benchmark details (names and availability of the 9 victim websites) are not specified, limiting external reproducibility.",
        "The exact RL algorithm and training hyperparameters are not explicitly detailed in the provided text."
      ],
      "future_work": [],
      "motivation": "Develop an automatic, extensible, and grammar-adhering web application fuzzer that can learn mutation operators without labeled data or explicit grammars and efficiently discover vulnerabilities across diverse applications.",
      "potential_research_ideas": [
        "Combine BERT-RL fuzzing with greybox feedback (e.g., code coverage, taint) to guide exploration for deeper vulnerabilities.",
        "Extend to additional vulnerability classes (e.g., command injection, path traversal, SSRF) by building curated seed corpora and evaluating transferability.",
        "Investigate curriculum RL or meta-RL to rapidly adapt the agent across applications and sanitizer variants.",
        "Incorporate constrained decoding or syntax-aware tokenization to further enforce grammar adherence in generated mutations.",
        "Use retrieval-augmented mutation (retrieve similar historical payloads/snippets) to inform the RL agent’s action proposals.",
        "Develop automatic seed set expansion via self-training: harvest successful payloads into the corpus and periodically re-tune the LM."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a hierarchical RL architecture where a high-level policy selects mutation families and a low-level policy edits token spans.",
        "Integrate encoder-decoder transformers with constrained decoding to enforce context-sensitive grammar while mutating.",
        "Augment the reward with multi-objective terms (evasion success, novelty, coverage, and request cost) using scalarization or Pareto RL.",
        "Leverage instrumentation (dynamic taint, sanitizer path tracing) to provide fine-grained rewards and reduce sparse-feedback issues.",
        "Use online continual learning or LoRA adapters for rapid per-application adaptation without full fine-tuning."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/bert-rl-fuzzer/fuzzer.git",
      "frameworks": [
        "PyTorch",
        "Hugging Face Transformers"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Likely requires a GPU for BERT pretraining/fine-tuning; exact hardware/training time not specified."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Web application testing environment over 9 victim websites (up to 16K LOC).",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Quality and representativeness of seed inputs strongly affect performance; unseen attack classes are not discovered.",
        "Setting up target applications and sanitizers for feedback can be non-trivial.",
        "Potential rate-limiting or side effects when interacting with live web applications."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces BertRLFuzzer, a novel BERT + reinforcement learning web application fuzzer that is automatic, extensible, and grammar-adhering.",
      "Demonstrates significant empirical gains vs. 13 black-box and white-box fuzzers across a benchmark of 9 web applications: “time to first attack (54% less), time to find all vulnerabilities (40–60% less), and attack rate (4.4% more)” and “17 new vulnerabilities.”",
      "Shows feasibility of using a BERT model as an RL agent to learn grammar-adhering, attack-provoking mutation operators without labeled data.",
      "Releases code for the proposed fuzzer."
    ]
  },
  {
    "arxiv_id": "2306.08060v1",
    "title": "Software Supply Chain Vulnerabilities Detection in Source Code: Performance Comparison between Traditional and Quantum Machine Learning Algorithms",
    "authors": "Mst Shapna Akter; Md Jobair Hossain Faruk; Nafisa Anjum; Mohammad Masum; Hossain Shahriar; Akond Rahman; Fan Wu; Alfredo Cuzzocrea",
    "abstract": "The software supply chain (SSC) attack has become one of the crucial issues that are being increased rapidly with the advancement of the software development domain. In general, SSC attacks execute during the software development processes lead to vulnerabilities in software products targeting downstream customers and even involved stakeholders. Machine Learning approaches are proven in detecting and preventing software security vulnerabilities. Besides, emerging quantum machine learning can be promising in addressing SSC attacks. Considering the distinction between traditional and quantum machine learning, performance could be varies based on the proportions of the experimenting dataset. In this paper, we conduct a comparative analysis between quantum neural networks (QNN) and conventional neural networks (NN) with a software supply chain attack dataset known as ClaMP. Our goal is to distinguish the performance between QNN and NN and to conduct the experiment, we develop two different models for QNN and NN by utilizing Pennylane for quantum and TensorFlow and Keras for traditional respectively. We evaluated the performance of both models with different proportions of the ClaMP dataset to identify the f1 score, recall, precision, and accuracy. We also measure the execution time to check the efficiency of both models. The demonstration result indicates that execution time for QNN is slower than NN with a higher percentage of datasets. Due to recent advancements in QNN, a large level of experiments shall be carried out to understand both models accurately in our future research.",
    "published_date": "2023-05-31",
    "pdf_link": "https://arxiv.org/pdf/2306.08060v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Classification",
      "specific_problem": "Binary (PE header) malware vs. benign classification to study feasibility for software supply chain vulnerability/attack detection",
      "attack_types": [
        "malware",
        "software_supply_chain_attack (claimed context)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Quantum Neural Network",
        "specific": "Variational quantum circuit with linear entanglement; TFQ-Keras parametrized quantum layer",
        "novel_contribution": "No new architecture; comparative evaluation of QNN vs. classical NN across varying dataset proportions"
      },
      {
        "type": "baseline",
        "category": "Feed-forward Neural Network",
        "specific": "TensorFlow/Keras NN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Dimensionality Reduction",
        "specific": "PCA (16 principal components)",
        "novel_contribution": "Applied due to qubit/simulator input-dimension limitations"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "ClaMP_raw",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ClaMP_Integrated",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Classical Neural Network (TensorFlow/Keras)",
        "paper_reference": null,
        "metric": "Accuracy at 60% of dataset",
        "their_result": "QNN accuracy = 0.40 (\"60 ... accuracy is 40\")",
        "baseline_result": "NN accuracy = 0.51 (Table 2: \"60 ... Accuracy 0.51\")"
      },
      {
        "method_name": "Classical Neural Network (TensorFlow/Keras)",
        "paper_reference": null,
        "metric": "Execution Time at 5% of dataset",
        "their_result": "QNN = 12min 24s (Table 1: \"5 ... 12min 24s\")",
        "baseline_result": "NN = 22.1s (Table 2: \"5 ... 22.1s\")"
      },
      {
        "method_name": "Classical Neural Network (TensorFlow/Keras)",
        "paper_reference": null,
        "metric": "Accuracy at 5% of dataset",
        "their_result": "QNN accuracy = 0.57 (Table 1: \"5 ... Accur acy 0.57\")",
        "baseline_result": "NN accuracy = 0.50 (Table 2: \"5 ... Accuracy 0.50\")"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "f1 score",
      "execution time"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How does a Quantum Neural Network (QNN) compare to a classical Neural Network (NN) on the ClaMP malware dataset across different dataset proportions?",
        "How do execution times differ between QNN and NN as dataset size increases?"
      ],
      "gaps_identified": [
        "“In the past years, none to very little research was conducted on the software supply chain vulnerabilities dataset using quantum machine learning perhaps due to the availability of quantum computing resources.”",
        "Limitations of current quantum simulators and qubit counts necessitate aggressive dimensionality reduction: “The present quantum simulator does not accept large dimensions as input… We selected the first 16 principal components, due to the limitation of qubit numbers in the existing simulator.”",
        "Insufficient SSC-specific labeled data and mitigation knowledge: “In Recognition and investigation into SSC attacks, there is an absence of sufficient information concerning mitigating or preventing these risks.”"
      ],
      "limitations": [
        "Experiments performed on quantum simulators with limited qubits; required PCA from 108 features to 16 components.",
        "No detailed architectural description or hyperparameters for the classical NN; results vary ('random') with dataset portions.",
        "QNN training/execution is slower than NN for larger dataset portions.",
        "Evaluation confined to a single malware dataset (ClaMP); despite SSC framing, dataset is PE header-based malware/benign classification rather than direct SSC source-code/dependency artifacts."
      ],
      "future_work": [
        "“Due to recent advancements in QNN, a large level of experiments shall be carried out to understand both models accurately in our future research.”",
        "Scale experiments to larger datasets and explore more extensive QNN configurations as hardware/software matures."
      ],
      "motivation": "Assess whether emerging quantum machine learning (QNN) can outperform or complement classical NN for detecting software security vulnerabilities (framed as SSC attacks) and understand performance/execution-time trade-offs across dataset sizes.",
      "potential_research_ideas": [
        "Build or curate a true software supply chain security dataset (source code, build scripts, dependency graphs, package metadata) and evaluate QNN/NN on SSC-specific tasks (e.g., detecting malicious dependencies, compromised build artifacts).",
        "Explore hybrid quantum-classical models (feature maps + classical heads) and quantum kernels (QSVM, quantum kernel regression) for PE header and SSC datasets.",
        "Investigate data re-uploading, richer encoding (amplitude/angle) and entanglement topologies to handle higher-dimensional inputs with fewer qubits.",
        "Evaluate cross-dataset generalization (ClaMP vs. EMBER/PE malware datasets) and domain adaptation for SSC artifacts.",
        "Adversarial robustness studies for malware/SSC detectors under evasion and poisoning attacks (both classical and quantum pipelines).",
        "Incorporate explainability (e.g., SHAP on classical side; influence functions or observable attribution on quantum side) to identify influential PE header fields or SSC features.",
        "End-to-end SSC pipeline detection using code property graphs or dependency graphs with GNNs, and assess quantum graph kernels or quantum-enhanced subroutines.",
        "Systematically benchmark against strong classical baselines (XGBoost, Random Forest, SVM, CNN for byte embeddings) with rigorous cross-validation and calibration."
      ],
      "architectural_improvement_recommendations": [
        "Adopt hybrid QNN architectures with data re-uploading layers and deeper entanglement while applying error mitigation on simulators/hardware.",
        "Use quantum feature maps tailored to the statistical structure of PE headers (e.g., polynomial or hardware-efficient ansätze) and perform feature selection prior to PCA to reduce information loss.",
        "Conduct hyperparameter optimization (optimizer choice, learning rate schedules, loss functions beyond hinge loss such as cross-entropy) for both QNN and NN.",
        "Implement stratified cross-validation and report averaged metrics with confidence intervals to mitigate randomness across dataset splits.",
        "Augment classical baselines with modern models (e.g., XGBoost, LightGBM, calibrated SVM) and deep byte-sequence models for more informative comparisons.",
        "Profile training vs. inference times separately and optimize QNN circuit depth/width for latency-constrained settings."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PennyLane",
        "TensorFlow",
        "Keras",
        "TensorFlow Quantum",
        "scikit-learn"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "Quantum simulator used; QNN runs per split ~9–12 minutes; NN runs per split ~15 seconds to ~1m23s for up to 60% of data. 100 training epochs for QNN; PCA to 16 components due to qubit limitations."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Quantum hardware/simulator limitations (qubit count and input dimension).",
        "Longer execution time for QNN compared to NN on larger datasets.",
        "Necessary dimensionality reduction may discard discriminative information."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Applied both quantum machine learning (QNN) and classical NN to the ClaMP malware dataset and evaluated across 20 dataset proportions (5% to 100%).",
      "Provided comparative analysis of precision, recall, F1, accuracy, and execution time between QNN and NN.",
      "Observed that QNN execution time is slower than NN for higher dataset percentages; accuracy varied irregularly across proportions for both models.",
      "Documented practical constraints of current quantum simulators necessitating PCA to 16 components due to qubit/input-dimension limits."
    ]
  },
  {
    "arxiv_id": "2306.00044v1",
    "title": "How to Construct Perfect and Worse-than-Coin-Flip Spoofing Countermeasures: A Word of Warning on Shortcut Learning",
    "authors": "Hye-jin Shim; Rosa González Hautamäki; Md Sahidullah; Tomi Kinnunen",
    "abstract": "Shortcut learning, or `Clever Hans effect` refers to situations where a learning agent (e.g., deep neural networks) learns spurious correlations present in data, resulting in biased models. We focus on finding shortcuts in deep learning based spoofing countermeasures (CMs) that predict whether a given utterance is spoofed or not. While prior work has addressed specific data artifacts, such as silence, no general normative framework has been explored for analyzing shortcut learning in CMs. In this study, we propose a generic approach to identifying shortcuts by introducing systematic interventions on the training and test sides, including the boundary cases of `near-perfect` and `worse than coin flip` (label flip). By using three different models, ranging from classic to state-of-the-art, we demonstrate the presence of shortcut learning in five simulated conditions. We analyze the results using a regression model to understand how biases affect the class-conditional score statistics.",
    "published_date": "2023-05-31",
    "pdf_link": "https://arxiv.org/pdf/2306.00044v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Biometric Security",
      "subdomain": "Presentation Attack Detection (PAD) / Anti-Spoofing",
      "specific_problem": "Audio anti-spoofing for automatic speaker verification (logical access)",
      "attack_types": [
        "Text-to-Speech (TTS)",
        "Voice Conversion (VC)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Framework/Methodology",
        "specific": "Systematic data intervention framework for shortcut learning analysis in binary classifiers",
        "novel_contribution": "Introduces controlled, asymmetric train/test interventions (including near-perfect and label-flip boundary cases) to reveal shortcut learning and quantify its effect."
      },
      {
        "type": "primary",
        "category": "Statistical Regression",
        "specific": "Linear Mixed Effects (LME) Modeling",
        "novel_contribution": "Models class-conditional score statistics with fixed and random effects to ‘go beyond the EER’ and quantify how interventions shift score distributions via parameters (µ, d, β*, σε)."
      },
      {
        "type": "baseline",
        "category": "Probabilistic Model",
        "specific": "Gaussian Mixture Model (GMM) with LFCC features",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Light Convolutional Neural Network (LCNN) with LFCC features",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph Neural Network / Attention",
        "specific": "AASIST (light variant, ~85K params) spectro-temporal graph attention network operating on raw waveform",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "ASVspoof 2019 Logical Access (LA)",
        "type": "public",
        "domain": "audio_anti_spoofing",
        "link": "https://www.asvspoof.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GMM (LFCC) on original config O",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "7.92"
      },
      {
        "method_name": "LCNN (LFCC) on original config O",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "1.39"
      },
      {
        "method_name": "AASIST-L on original config O",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "1.39"
      },
      {
        "method_name": "GMM under MP3 compression, config A",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "0.00"
      },
      {
        "method_name": "LCNN under MP3 compression, config A",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "0.01"
      },
      {
        "method_name": "AASIST-L under MP3 compression, config A",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "0.01"
      },
      {
        "method_name": "GMM under MP3 compression, config C (label flip)",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "99.99"
      },
      {
        "method_name": "LCNN under MP3 compression, config D (label flip)",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "99.93"
      },
      {
        "method_name": "Any CM under additive white noise, configs A/B",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "≈0.00–0.01 (all three CMs)"
      },
      {
        "method_name": "Any CM under additive white noise, configs C/D (label flip)",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "≈99.98–99.99 (all three CMs)"
      },
      {
        "method_name": "LCNN under non-speech zeroing, config D",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "35.67"
      },
      {
        "method_name": "AASIST-L under µ-law quantization, config C",
        "paper_reference": null,
        "metric": "EER (%)",
        "their_result": null,
        "baseline_result": "48.54"
      }
    ],
    "performance_metrics_used": [
      "Equal Error Rate (EER, %)",
      "Linear Mixed Effects model coefficients (µ, d, β*, residual variance σε)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can systematic, asymmetric train/test interventions reveal shortcut learning in audio anti-spoofing CMs?",
        "Do controlled interventions create boundary cases of near-perfect performance and worse-than-coin-flip (label-flip) behavior?",
        "How do such biases quantitatively affect class-conditional score distributions beyond EER?",
        "Which common audio perturbations (MP3 compression, additive white noise, loudness normalization, non-speech zeroing, µ-law) act as shortcuts?"
      ],
      "gaps_identified": [
        "Lack of a general normative framework to analyze shortcut learning in spoofing countermeasures; prior work focused on specific artifacts (e.g., silence).",
        "Potential biases in ASVspoof datasets (e.g., proportion of silence) impacting CM evaluations.",
        "Overreliance on scalar metrics like EER without analyzing class-conditional score shifts."
      ],
      "limitations": [
        "Interventions considered one type at a time; no mixtures or sequential combinations.",
        "Intervention probabilities restricted to extremes P(fj) ∈ {0,1}.",
        "Intervention parameter distributions simplified to uniform or Dirac.",
        "High residual variances in LME for some settings, indicating unexplained random effects.",
        "Evaluation limited to ASVspoof 2019 LA and three CM models (GMM, LCNN, AASIST-L)."
      ],
      "future_work": [
        "“The solutions to mitigate those biases and deep analysis of those correlations remain in our future work.”",
        "Extend the framework to more datasets and intervention combinations.",
        "Develop mitigation strategies to reduce shortcut reliance in CMs."
      ],
      "motivation": "Provide a generic, systematic framework to detect and quantify shortcut learning in audio anti-spoofing CMs, addressing biases not captured by previous artifact-specific studies and going beyond aggregate metrics like EER.",
      "potential_research_ideas": [
        "Design debiasing training schemes (e.g., adversarial or invariant risk minimization) that reduce reliance on intervention-induced shortcuts.",
        "Causal analysis of CM scores using do-calculus style interventions to separate causal from spurious features.",
        "Automatic discovery of shortcut-inducing transformations via neural architecture search or differentiable data augmentation.",
        "Cross-dataset, cross-protocol generalization studies (ASVspoof 2019 LA, 2021 LA/PA, in-the-wild data) under controlled interventions.",
        "Score-level debiasing: learn post-hoc correction models informed by LME parameters to recalibrate biased scores.",
        "Probing techniques to quantify shortcut reliance per layer (e.g., representation similarity metrics under interventions).",
        "Active data collection policies that balance suspected shortcut factors (e.g., silence proportion, compression levels).",
        "Robust feature engineering (e.g., loudness-invariant, codec-robust features) and augmentation schedules tuned to avoid shortcut leakage."
      ],
      "architectural_improvement_recommendations": [
        "Multi-branch CM architectures disentangling speech content from channel/codec/noise factors with adversarial factorization (gradient reversal on shortcut predictors).",
        "Incorporate domain generalization (e.g., CORAL, GroupDRO) to minimize distributional shifts corresponding to interventions.",
        "Regularize attention/GNN modules (AASIST) with penalties discouraging over-attention to non-speech or low-level artifacts.",
        "Curriculum and balanced augmentation strategies that symmetrize suspected shortcuts across classes during training.",
        "Integrate loudness and codec normalization layers to stabilize front-end representations.",
        "Estimate and monitor β* proxies during training (e.g., via online mixed-effects approximations) to detect emerging shortcut reliance."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": "https://github.com/asvspoof-challenge/2021",
      "frameworks": [
        "R (lme4)",
        "PyTorch"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "AASIST-L uses ~85K parameters; no explicit GPU or runtime details provided."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Shortcut learning can yield misleadingly low EER in biased conditions and catastrophic (>50% EER) behavior under label-flip conditions.",
        "Sensitivity to common signal processing (MP3 compression, noise) threatens robustness in real deployments.",
        "Dataset biases (e.g., silence proportion) can be inadvertently exploited by CMs."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a generic, systematic intervention framework to identify shortcut learning in binary classifiers, including near-perfect and worse-than-coin-flip boundary cases.",
      "Applies the framework to audio anti-spoofing using five interventions (MP3 compression, additive white noise, loudness normalization, non-speech zeroing, µ-law).",
      "Empirically demonstrates shortcut effects across three CMs (GMM, LCNN, AASIST-L) on ASVspoof 2019 LA with extreme EER outcomes (0% and ~100%).",
      "Introduces linear mixed effects modeling of detection scores to quantify how biases affect class-conditional score statistics, going beyond EER.",
      "Finds that MP3 compression and additive white noise are strong shortcuts; loudness normalization has smaller effects relative to others."
    ]
  },
  {
    "arxiv_id": "2305.18070v1",
    "title": "Forensic Video Steganalysis in Spatial Domain by Noise Residual Convolutional Neural Network",
    "authors": "Mart Keizer; Zeno Geradts; Meike Kombrink",
    "abstract": "This research evaluates a convolutional neural network (CNN) based approach to forensic video steganalysis. A video steganography dataset is created to train a CNN to conduct forensic steganalysis in the spatial domain. We use a noise residual convolutional neural network to detect embedded secrets since a steganographic embedding process will always result in the modification of pixel values in video frames. Experimental results show that the CNN-based approach can be an effective method for forensic video steganalysis and can reach a detection rate of 99.96%. Keywords: Forensic, Steganalysis, Deep Steganography, MSU StegoVideo, Convolutional Neural Networks",
    "published_date": "2023-05-29",
    "pdf_link": "https://arxiv.org/pdf/2305.18070v1",
    "paper_types": [
      "empirical_analysis",
      "new_dataset"
    ],
    "security_domain": {
      "primary": "Digital Forensics",
      "subdomain": "Steganalysis",
      "specific_problem": "Forensic video steganalysis in the spatial domain to detect and classify stego videos produced by Deep Video Steganography and MSU StegoVideo tools",
      "attack_types": [
        "Video steganography (deep learning-based)",
        "Video steganography (MSU StegoVideo tool)",
        "Data hiding/steganography"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Noise Residual CNN (NR-CNN)",
        "novel_contribution": "Applies NR-CNN to spatial-domain video steganalysis for multi-class classification (regular vs Deep Video Steganography vs MSU StegoVideo); no new architecture introduced."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "VLOG",
        "type": "public",
        "domain": "video_frames",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "10-sec VLOG splits (intermediate dataset)",
        "type": "private",
        "domain": "video_segments",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Stego-dataset (VLOG-derived with DVS and MSU stego videos plus regular videos)",
        "type": "synthetic",
        "domain": "video_frames",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "confusion_matrix"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Is a CNN-based approach effective for forensic video steganalysis in the spatial domain?",
        "Can the Noise Residual CNN (NR-CNN) detect and classify videos produced by Deep Video Steganography and MSU StegoVideo?",
        "Can NR-CNN serve as a general forensic video steganalysis network beyond intraprediction/motion-vector methods?"
      ],
      "gaps_identified": [
        "Video steganalysis research lags behind video steganography research.",
        "Generalization to unseen steganographic methods is unknown and untested.",
        "Potential content-specific failure modes (e.g., nearly black frames, CCTV footage with horizontal lines).",
        "Impact of embedding rate on detection is not fully characterized.",
        "MSU StegoVideo is closed-source, limiting detailed analysis."
      ],
      "limitations": [
        "Evaluated only on steganography methods present in training data (no unseen-method evaluation).",
        "Dataset limited to VLOG-derived content and two tools (DVS, MSU); dataset not released.",
        "Single-frame spatial analysis; no temporal modeling.",
        "Frames converted to grayscale 224x224, potentially losing color/channel information.",
        "Unknown robustness to compression, codecs, scaling, or camera pipelines.",
        "No comparisons against alternative steganalysis baselines."
      ],
      "future_work": [
        "Investigate whether NR-CNN can detect steganography methods not seen during training.",
        "Expand the dataset with additional tools/methods, including newly discovered tools, and retrain.",
        "Develop NR-CNN into a general forensic video steganalysis tool."
      ],
      "motivation": "Rising use of steganography in criminal contexts and a lack of corresponding forensic steganalysis tools for video necessitate effective detection methods.",
      "potential_research_ideas": [
        "Open-set and zero-shot video steganalysis that flags unseen steganography methods.",
        "Self-supervised pretraining on residuals and anomaly detection to model cover distributions and detect deviations.",
        "Temporal modeling via 3D CNNs or ConvLSTMs to leverage spatiotemporal inconsistencies introduced by embedding.",
        "Robustness evaluation and training across codecs, compression levels, scaling, and camera processing pipelines.",
        "Curriculum training to improve sensitivity to low bpp embedding rates; synthetic control of embedding strength.",
        "Explainable steganalysis: residual saliency maps and evidentiary artifacts for forensic reporting.",
        "Mixture-of-experts or specialized submodels for known hard cases (black frames, CCTV-like content).",
        "Domain adaptation methods for cross-dataset generalization (e.g., VLOG to surveillance or broadcast video).",
        "Benchmarking suite for video steganalysis with standardized tasks and metrics.",
        "Contrastive or metric-learning objectives on residual features to separate cover vs. stego manifolds."
      ],
      "architectural_improvement_recommendations": [
        "Incorporate temporal modules (3D CNN, ConvLSTM) to capture frame-to-frame residual consistency.",
        "Use multi-branch residual filtering with learnable SRM/high-pass banks at multiple scales, plus attention/SE blocks to focus on informative residuals.",
        "Adopt open-set classification (cosine classifiers, energy-based/OOD detection) to flag unknown tools.",
        "Ensemble detectors trained at different embedding rates and content types to improve robustness.",
        "Include color-space modeling (e.g., YCbCr residuals) alongside grayscale to exploit chroma artifacts.",
        "Hard negative mining on black/CCTV frames and artifacts with horizontal lines.",
        "Video-level aggregation (majority voting or learned pooling) instead of per-frame-only decisions."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/mjbkeizer/Video-Steganalysis-in-Spatial-Domain-by-Neural-Network",
      "frameworks": [
        "PyTorch"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Trained on 8,000 frames (batch size 20) for 150 epochs using AdaDelta (lr=0.4, rho=0.95, weight decay 5e-4, eps 1e-8). GPU not specified."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Unknown generalization to unseen steganography tools; may require frequent retraining.",
        "Sensitivity to specific content types (e.g., black frames, CCTV with horizontal lines).",
        "Handling diverse codecs, compression levels, resolutions, and camera pipelines in the wild.",
        "Frame-by-frame processing can be computationally intensive for large video corpora.",
        "Lack of public labeled benchmarks for video steganalysis."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Created a video steganography dataset by deriving 10-second clips from VLOG and generating DVS and MSU stego videos plus regular videos.",
      "Applied and trained NR-CNN to classify frames into regular, deep-stego, and MSU-stego categories in the spatial domain.",
      "Reported high detection performance: “the training set with 34,000 frames has an accuracy of 99.99% with 3 wrong predictions, and the test set with 33,620 frames has an accuracy of 99.96% with 13 wrong predictions.”",
      "Released complete source code for the pipeline and model training."
    ]
  },
  {
    "arxiv_id": "2305.07209v2",
    "title": "Gotcha! I Know What You are Doing on the FPGA Cloud: Fingerprinting Co-Located Cloud FPGA Accelerators via Measuring Communication Links",
    "authors": "Chongzhou Fang; Ning Miao; Han Wang; Jiacheng Zhou; Tyler Sheaves; John M. Emmert; Avesta Sasan; Houman Homayoun",
    "abstract": "In recent decades, due to the emerging requirements of computation acceleration, cloud FPGAs have become popular in public clouds. Major cloud service providers, e.g. AWS and Microsoft Azure have provided FPGA computing resources in their infrastructure and have enabled users to design and deploy their own accelerators on these FPGAs. Multi-tenancy FPGAs, where multiple users can share the same FPGA fabric with certain types of isolation to improve resource efficiency, have already been proved feasible. However, this also raises security concerns. Various types of side-channel attacks targeting multi-tenancy FPGAs have been proposed and validated. The awareness of security vulnerabilities in the cloud has motivated cloud providers to take action to enhance the security of their cloud environments.   In FPGA security research papers, researchers always perform attacks under the assumption that attackers successfully co-locate with victims and are aware of the existence of victims on the same FPGA board. However, the way to reach this point, i.e., how attackers secretly obtain information regarding accelerators on the same fabric, is constantly ignored despite the fact that it is non-trivial and important for attackers. In this paper, we present a novel fingerprinting attack to gain the types of co-located FPGA accelerators. We utilize a seemingly non-malicious benchmark accelerator to sniff the communication link and collect performance traces of the FPGA-host communication link. By analyzing these traces, we are able to achieve high classification accuracy for fingerprinting co-located accelerators, which proves that attackers can use our method to perform cloud FPGA accelerator fingerprinting with a high success rate. As far as we know, this is the first paper targeting multi-tenant FPGA accelerator fingerprinting with the communication side-channel.",
    "published_date": "2023-05-12",
    "pdf_link": "https://arxiv.org/pdf/2305.07209v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Side-Channel Attacks",
      "specific_problem": "Fingerprinting co-located FPGA accelerators on multi-tenant cloud FPGAs via PCIe communication side-channel measurements",
      "attack_types": [
        "side-channel",
        "fingerprinting",
        "PCIe contention",
        "co-location inference"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": "Use of classical ML over PCIe bandwidth traces to classify the type of co-located FPGA accelerators; random forest achieved the highest accuracy among tested classifiers"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "PCIe bandwidth/performance traces collected by authors (Intel DevCloud)",
        "type": "private",
        "domain": "communication_side_channel_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random Forest (closed-world classification)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "“reaching as high as around 90% by random forest”",
        "baseline_result": null
      },
      {
        "method_name": "Random Forest (open-world evaluation)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "“the success rate reaches around 80%”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can PCIe communication link measurements be used as a side-channel to fingerprint co-located FPGA accelerators?",
        "What classification accuracy can be achieved in closed-world and open-world settings?",
        "How does the level of PCIe contention affect fingerprinting success?"
      ],
      "gaps_identified": [
        "Existing FPGA cloud attacks assume attackers already know the victim’s accelerator type; the means of secretly obtaining this knowledge is largely ignored.",
        "Prior FPGA side-channel works focus on power or routing (long-wire) channels; communication side-channel for accelerator fingerprinting has not been studied for multi-tenant FPGA accelerator identification."
      ],
      "limitations": [
        "Assumes successful co-location in a multi-tenant FPGA environment.",
        "Assumes victims are continuously running and interact with the host via I/O, exposing distinct access patterns.",
        "Evaluation performed on Intel DevCloud; generalization to other providers/topologies and device families is not established.",
        "Attack requires offline collection of labeled traces for potential victim accelerators to train the classifier."
      ],
      "future_work": [
        "Discussion of potential defense approaches (outlined in Section 6, not detailed in the provided excerpt).",
        "Extending the approach and validation across different cloud FPGA platforms and communication topologies."
      ],
      "motivation": "Enable attackers to infer the type of co-located FPGA accelerators without prior knowledge, removing a key assumption in existing FPGA cloud side-channel/fault attacks and thereby exposing a practical vulnerability path.",
      "potential_research_ideas": [
        "Develop open-set and out-of-distribution detection methods tailored to PCIe side-channel traces to robustly identify unknown accelerators.",
        "Cross-platform transfer learning/domain adaptation to generalize fingerprinting across FPGA families (Intel/Xilinx) and cloud providers.",
        "Temporal/sequential modeling (e.g., HMMs or lightweight RNN/TCN variants) of bandwidth traces to capture richer I/O patterns beyond simple statistics.",
        "Adversarial trace generation and robustness testing to evaluate and harden both attack and defense strategies.",
        "Automated feature engineering for communication side-channel traces using signal processing and learned embeddings."
      ],
      "architectural_improvement_recommendations": [
        "Augment classifier with uncertainty calibration and thresholding for open-world detection.",
        "Incorporate multi-signal sensing (e.g., combining PCIe bandwidth with latency or queue depth proxies) for multi-view classification.",
        "Use ensemble methods combining random forest with gradient boosting or shallow neural networks to improve accuracy and stability under noise.",
        "Implement online/continual learning to adapt models to evolving workloads and cloud infrastructure changes."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "OpenCL",
        "Intel OneAPI"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Intel DevCloud multi-tenant FPGA environment (host–FPGA via PCIe, AFUs under OpenCL/OneAPI)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Achieving reliable co-location with victims on shared FPGA fabric.",
        "Variability of PCIe topology and contention across servers/providers impacting fingerprint stability.",
        "Need for labeled training data representing potential victim accelerators.",
        "Potential countermeasures or rate-limiting by cloud providers on PCIe access patterns."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a new fingerprinting attack on multi-tenant FPGA clouds leveraging PCIe communication side-channel measurements.",
      "Implements a proof-of-concept measurement accelerator and host program to stress PCIe and collect bandwidth traces.",
      "Evaluates four classification algorithms; reports closed-world accuracy “as high as around 90% by random forest” and open-world success “around 80%”.",
      "Analyzes the impact of contention level on fingerprinting success.",
      "Reveals a new vulnerability in communication links of heterogeneous computing systems and discusses insights toward defenses."
    ]
  },
  {
    "arxiv_id": "2306.00934v7",
    "title": "Interpreting GNN-based IDS Detections Using Provenance Graph Structural Features",
    "authors": "Kunal Mukherjee; Joshua Wiedemeier; Tianhao Wang; Muhyun Kim; Feng Chen; Murat Kantarcioglu; Kangkook Jee",
    "abstract": "Advanced cyber threats (e.g., Fileless Malware and Advanced Persistent Threat (APT)) have driven the adoption of provenance-based security solutions. These solutions employ Machine Learning (ML) models for behavioral modeling and critical security tasks such as malware and anomaly detection. However, the opacity of ML-based security models limits their broader adoption, as the lack of transparency in their decision-making processes restricts explainability and verifiability. We tailored our solution towards Graph Neural Network (GNN)-based security solutions since recent studies employ GNNs to comprehensively digest system provenance graphs for security-critical tasks.   To enhance the explainability of GNN-based security models, we introduce PROVEXPLAINER, a framework offering instance-level security-aware explanations using an interpretable surrogate model. PROVEXPLAINER's interpretable feature space consists of discriminant subgraph patterns and graph structural features, which can be directly mapped to the system provenance problem space, making the explanations human interpretable. We show how PROVEXPLAINER synergizes with current state-of-the-art (SOTA) GNN explainers to deliver domain and instance-specific explanations. We measure the explanation quality using the Fidelity+/Fidelity- metric as used by traditional GNN explanation literature, we incorporate the precision/recall metric, where we consider the accuracy of the explanation against the ground truth, and we designed a human actionability metric based on graph traversal distance. On real-world Fileless and APT datasets, PROVEXPLAINER achieves up to 29%/27%/25%/1.4x higher Fidelity+, precision, recall, and actionability (where higher values are better), and 12% lower Fidelity- (where lower values are better) when compared against SOTA GNN explainers.",
    "published_date": "2023-06-01",
    "pdf_link": "https://arxiv.org/pdf/2306.00934v7",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Endpoint/Host Security",
      "subdomain": "Intrusion Detection (Host-based IDS)",
      "specific_problem": "Post-hoc, instance-level explainability for GNN-based IDS decisions on system provenance graphs",
      "attack_types": [
        "Advanced Persistent Threat (APT)",
        "Fileless Malware",
        "Malware replication/propagation",
        "Data exfiltration",
        "Phishing-initiated compromise"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Surrogate Explainability (Decision Tree)",
        "specific": "Decision Tree surrogate to mimic GNN decisions",
        "novel_contribution": "Uses security-aware discriminant subgraph patterns and graph structural features as an interpretable feature space; provides local and global (structural) context explanations; introduces a human actionability metric."
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GraphSAGE",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GAT (Graph Attention Network)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN Explainer (white-box)",
        "specific": "GNNExplainer",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN Explainer (white-box)",
        "specific": "PGExplainer",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN Explainer (black-box)",
        "specific": "SubgraphX",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph Mining",
        "specific": "GERM (graph evolution miner) for subgraph pattern mining",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Post-hoc model-agnostic explainability"
    ],
    "datasets": [
      {
        "name": "In-house provenance dataset (86 mixed Windows/Linux hosts over 13 months)",
        "type": "proprietary",
        "domain": "system_provenance",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "DARPA Transparent Computing (TC) dataset (CDM schema)",
        "type": "public",
        "domain": "system_provenance",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "APT dataset from prior study [46]",
        "type": "public",
        "domain": "system_provenance",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Real-world malware samples (lists from [47])",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "VirusTotal database [30] (used for ground-truth documentation)",
        "type": "public",
        "domain": "threat_intel",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Cyber Threat Intelligence (CTI) feeds [50] (used for malware activity summaries)",
        "type": "public",
        "domain": "threat_intel",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [
      {
        "method_name": "GNNExplainer",
        "paper_reference": null,
        "metric": "Fidelity+, Fidelity-, precision, recall, human actionability",
        "their_result": "\"On real-world Fileless and APT datasets, PROVEXPLAINER achieves up to 29%/27%/25%/1.4x higher Fidelity+, precision, recall, and actionability, and 12% lower Fidelity-\" compared to SOTA explainers.",
        "baseline_result": "Lower Fidelity+, precision, recall, actionability; higher Fidelity- than PROVEXPLAINER (exact numbers not provided)."
      },
      {
        "method_name": "PGExplainer",
        "paper_reference": null,
        "metric": "Fidelity+, Fidelity-, precision, recall, human actionability",
        "their_result": "Same as above (relative improvements up to +29% Fidelity+, +27% precision, +25% recall, 1.4x actionability; -12% Fidelity-).",
        "baseline_result": "Underperforms PROVEXPLAINER across reported metrics (exact numbers not provided)."
      },
      {
        "method_name": "SubgraphX",
        "paper_reference": null,
        "metric": "Fidelity+, Fidelity-, precision, recall, human actionability",
        "their_result": "Same as above (relative improvements).",
        "baseline_result": "Underperforms PROVEXPLAINER across reported metrics (exact numbers not provided)."
      }
    ],
    "performance_metrics_used": [
      "Fidelity+",
      "Fidelity-",
      "Precision",
      "Recall",
      "Human actionability (graph traversal distance)",
      "Surrogate agreement with GNN (95%)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How can we provide instance-level, security-aware explanations for GNN-based IDS decisions on heterogeneous system provenance graphs?",
        "Can discriminant subgraph patterns and graph structural features yield faithful, precise, and actionable explanations aligned with ground truth TTPs and artifacts?",
        "How does the proposed surrogate-based framework compare to SOTA GNN explainers on fidelity, precision/recall, and human actionability across malware and APT scenarios?"
      ],
      "gaps_identified": [
        "Existing GNN explainers are domain-agnostic and lack validation in the security/provenance domain.",
        "Lack of ground truth-relevant, verifiable explanations mapped to system actions and artifacts (TTPs).",
        "High variance and reliability concerns in explanations from traditional GNN explainers.",
        "Difficulty capturing both local (subgraph) and global (structural/long-term) dependencies in provenance graphs.",
        "Opacity of GNN-based IDS limits adoption and trust among analysts."
      ],
      "limitations": [
        "Focuses on graph-level tasks; node- and edge-level explanation is out of scope.",
        "Considers only structural features; ignores textual/numeric node and edge attributes.",
        "Ground truth approximated from external documentation (vendor reports, prior studies), which may contain biases/errors.",
        "Adversarial robustness, poisoning, and manipulations are out of scope.",
        "Surrogate Decision Trees trade generalizability/expressiveness for interpretability; not intended for direct attack detection.",
        "Assumes integrity of on-device data collection; omits certain data types in schema (e.g., memory objects, registry, thread distinctions)."
      ],
      "future_work": [
        "Extend explanations to node- and edge-level tasks in provenance graphs.",
        "Incorporate robustness to adversarial manipulation and dataset poisoning into detection and explanation systems.",
        "Augment structural features with vetted attribute-based features while preserving interpretability.",
        "Integrate additional security-aware graph features and temporal reasoning for evolving provenance graphs.",
        "Broaden ground-truthing via improved curation and human-in-the-loop validation."
      ],
      "motivation": "Improve trust and verifiability of GNN-based IDS on system provenance by providing human-understandable, security-aware explanations that align with ground truth TTPs and operational workflows.",
      "potential_research_ideas": [
        "Develop adversarially robust provenance explainers that maintain fidelity/actionability under manipulation.",
        "Combine causal inference with provenance explanations to distinguish spurious from causal subgraph patterns.",
        "Create streaming/online PROVEXPLAINER for real-time EDR triage with bounded-latency explanations.",
        "Human-in-the-loop learning: use analyst feedback on explanations to refine subgraph pattern mining and surrogate splits.",
        "Cross-domain generalization: evaluate transfer of mined patterns between different OSes/environments and mitigate domain shift.",
        "Counterfactual explanations on provenance graphs to show minimal changes that flip GNN decisions.",
        "Uncertainty-aware explanations providing confidence bounds over identified patterns and metrics."
      ],
      "architectural_improvement_recommendations": [
        "Augment surrogate with rule lists or gradient-boosted trees while constraining depth to preserve interpretability.",
        "Incorporate temporal GNNs (e.g., TGNs) and temporal structural features to capture evolution in provenance.",
        "Use contrastive learning to learn more discriminative structural embeddings that enrich the explainer’s feature space.",
        "Hybrid white-box/black-box mode: leverage gradients/attention (when available) to weight mined patterns.",
        "Automate subgraph pattern mining with constraints (frequency, MDL, security priors) to reduce noise and improve fidelity.",
        "Integrate uncertainty estimation and calibration for surrogate predictions and explanation confidence."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "DGL",
        "Decision Tree surrogate"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Enterprise endpoints (86 mixed Windows/Linux hosts), DARPA TC environment, provenance-based EDR-like setting",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Ground-truth curation and validation across diverse attack scenarios.",
        "High-volume, heterogeneous provenance data collection and storage overhead.",
        "Bridging explanations to operational workflows and ensuring analyst actionability.",
        "Potential vulnerability to adversarial manipulation not addressed in current scope."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces PROVEXPLAINER, a GNN-structure-agnostic, surrogate-based explanation framework using discriminant subgraph patterns and graph structural features.",
      "Demonstrates instance-level, security-aware explanations aligned with system actions and artifacts (TTPs).",
      "Shows synergy and outperformance over SOTA GNN explainers (GNNExplainer, PGExplainer, SubgraphX) with up to +29% Fidelity+, +27% precision, +25% recall, 1.4x actionability, and -12% Fidelity-.",
      "Designs a human actionability metric based on graph traversal distance to ground-truth artifacts.",
      "Achieves 95% agreement between surrogate DTs and the GNN detection model.",
      "Curates and evaluates across real-world Fileless malware and APT datasets (in-house, DARPA TC, prior APT dataset) to validate generalizability."
    ]
  },
  {
    "arxiv_id": "2305.17246v2",
    "title": "NASimEmu: Network Attack Simulator & Emulator for Training Agents Generalizing to Novel Scenarios",
    "authors": "Jaromír Janisch; Tomáš Pevný; Viliam Lisý",
    "abstract": "Current frameworks for training offensive penetration testing agents with deep reinforcement learning struggle to produce agents that perform well in real-world scenarios, due to the reality gap in simulation-based frameworks and the lack of scalability in emulation-based frameworks. Additionally, existing frameworks often use an unrealistic metric that measures the agents' performance on the training data. NASimEmu, a new framework introduced in this paper, addresses these issues by providing both a simulator and an emulator with a shared interface. This approach allows agents to be trained in simulation and deployed in the emulator, thus verifying the realism of the used abstraction. Our framework promotes the development of general agents that can transfer to novel scenarios unseen during their training. For the simulation part, we adopt an existing simulator NASim and enhance its realism. The emulator is implemented with industry-level tools, such as Vagrant, VirtualBox, and Metasploit. Experiments demonstrate that a simulation-trained agent can be deployed in emulation, and we show how to use the framework to train a general agent that transfers into novel, structurally different scenarios. NASimEmu is available as open-source.",
    "published_date": "2023-05-26",
    "pdf_link": "https://arxiv.org/pdf/2305.17246v2",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Autonomous Penetration Testing",
      "specific_problem": "Training deep RL agents for penetration testing that generalize to novel, structurally different network scenarios and can be trained in simulation and deployed in emulation",
      "attack_types": [
        "network_scanning",
        "remote_service_exploitation",
        "privilege_escalation",
        "lateral_movement"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Policy Gradient RL",
        "specific": "PPO (Proximal Policy Optimization)",
        "novel_contribution": "A size-invariant observation-processing architecture for PPO tailored to varying network sizes and topologies; supports training across multiple scenarios and improved transfer to novel scenarios"
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "Fixed-size MLP over matrix-based observations",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Deep Reinforcement Learning"
    ],
    "datasets": [
      {
        "name": "NASimEmu Simulator Scenarios (static, random, dynamic)",
        "type": "public",
        "domain": "simulated_network_environment",
        "link": "https://github.com/jaromiru/NASimEmu",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "NASimEmu Emulator Cyber-Range (Vagrant/VirtualBox/Metasploit-based)",
        "type": "public",
        "domain": "emulated_network_environment",
        "link": "https://github.com/jaromiru/NASimEmu",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Metasploitable3 VM images (base OS templates used by emulator)",
        "type": "public",
        "domain": "virtual_machine_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Eight simple benchmark scenarios (for experiments)",
        "type": "synthetic",
        "domain": "simulated_network_environment",
        "link": "https://github.com/jaromiru/NASimEmu",
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "PPO + Fixed MLP (matrix-based observations)",
        "paper_reference": null,
        "metric": "Generalization to novel scenarios vs. training scenarios (episodic return/reward within 20-step cap)",
        "their_result": "“the commonly used MLP architecture fails [to transfer]” and “performs well in the training scenarios, [but] transfers poorly to novel scenarios that differ in topology and size.”",
        "baseline_result": null
      },
      {
        "method_name": "PPO + Size-invariant model (proposed)",
        "paper_reference": null,
        "metric": "Generalization to novel scenarios (episodic return/reward within 20-step cap); transfer from simulation to emulation",
        "their_result": "“initial evidence that it performs well both on the training and novel scenarios” and that “a simulation-trained agent can be successfully deployed in the emulator.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "episodic return (step penalty; positive reward for privileged access on sensitive hosts)",
      "number of sensitive hosts compromised within a 20-step episode limit",
      "generalization performance on novel scenarios not seen during training",
      "successful transfer/deployment from simulation to emulation (qualitative)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to create an agent that is invariant to possible variations in size, topology and configuration of real networks?",
        "When should the agent stop the penetration testing, given that the location and number of hosts with sensitive data is unknown?",
        "Can a simulation-trained agent be seamlessly deployed in an emulator while preserving effectiveness (closing the reality gap)?",
        "How do different model architectures influence generalization across multiple random scenarios?"
      ],
      "gaps_identified": [
        "Reality gap of simulation-based penetration testing frameworks prevents deployment of trained agents in real systems.",
        "Emulation-based frameworks are slow and not scalable for deep RL training.",
        "Unrealistic evaluation metric measuring performance on training data; frameworks often train and test on the same static network.",
        "Existing frameworks often do not support training/testing across multiple distinct scenarios simultaneously."
      ],
      "limitations": [
        "Service version differentiation not fully modeled/fingerprinted; cannot handle indistinguishable versions.",
        "Dynamic scenarios currently cannot generate correlated host configurations across subnets (independence assumption).",
        "Credentials discovery and reuse are not modeled.",
        "Exploits assumed to succeed whenever a corresponding service is present (no configuration/patch variability).",
        "Firewall abstraction is coarse (allow/deny all between subnets), not port/source specific.",
        "Only the attacker is modeled; no active defender (attacker–defender dynamics absent).",
        "Processes not implemented; ProcessScan does nothing.",
        "Termination condition left to the agent; experiments impose a fixed 20-step cap for practicality."
      ],
      "future_work": [
        "Model service versions more realistically and implement robust fingerprinting in emulation.",
        "Support correlated host configurations within dynamic scenarios.",
        "Introduce credential discovery/storage/use into the abstraction.",
        "Relax exploit determinism by modeling configuration/patch variability and stochastic outcomes.",
        "Implement port- and source-specific firewall rules.",
        "Add adversarial defender and honeypot dynamics beyond negative rewards.",
        "Implement processes and meaningful ProcessScan outputs.",
        "Develop principled termination/stopping policies for open-ended episodes."
      ],
      "motivation": "Provide a realism-first framework that enables efficient deep RL training in simulation with seamless deployment in emulation, promoting agents that generalize to novel networks and addressing unrealistic evaluation practices.",
      "potential_research_ideas": [
        "Design graph-based RL agents (GNNs) over the observation graph to encode subnet connectivity and permutation invariance.",
        "Learn an explicit stopping policy (termination head) under partial observability using POMDP methods.",
        "Meta-RL or domain randomization curricula to improve sim-to-emu and cross-topology generalization.",
        "Incorporate credential harvesting/use into the action space and evaluate planning with combinatorial credentials.",
        "Model port-level firewalls and study policy adaptation to variable ACLs and routing constraints.",
        "Introduce a defender agent for attacker–defender co-training and evaluate robustness.",
        "Sim2real transfer techniques (e.g., randomize service versions/latencies) to reduce reality gap further.",
        "Evaluate hierarchical RL (high-level tactics vs low-level actions) for long-horizon network pivoting.",
        "Leverage large language models for tool-use (Metasploit) combined with RL for decision making."
      ],
      "architectural_improvement_recommendations": [
        "Adopt permutation/size-invariant encoders with GNNs over hosts/subnets plus attention-based pooling.",
        "Use parameterized-action RL to handle action arguments instead of grounding all actions.",
        "Add memory (GRU/LSTM or transformer with recurrence) to remember scans and failed attempts.",
        "Introduce a learned termination head with uncertainty estimation for stopping under unknown sensitive host count.",
        "Hierarchical RL with options for scan → exploit → privilege escalation → lateral movement subtasks.",
        "Uncertainty-aware exploration (e.g., ensembles) to balance scanning vs exploitation.",
        "Off-policy RL (e.g., SAC) with prioritized replay from many simulated scenarios to improve sample efficiency."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/jaromiru/NASimEmu",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Simulation supports many parallel environments (e.g., 256); emulation requires Vagrant/VirtualBox VMs (RouterOS, Kali+Metasploit, Windows/Linux targets)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Virtualized cyber-range: Vagrant-managed VirtualBox network with RouterOS, attacker (Kali + Metasploit), Windows/Linux targets",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Emulation speed and scalability constraints for deep RL training",
        "Complex VM provisioning and service configuration",
        "Simplified firewall and exploit success models may limit real-world fidelity",
        "Lack of credential and defender modeling reduces realism"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces NASimEmu: a unified framework providing both simulator and emulator with a shared Gym interface, enabling training in simulation and deployment in emulation.",
      "Promotes and enables evaluation on novel scenarios by supporting multiple random scenario instances varying in topology, size, and configuration; discourages training-on-test metrics.",
      "Implements dynamic scenarios, observation persistence, permutation of IDs, multi-scenario training/testing, optional graph observations, and visualization.",
      "Demonstrates that a simulation-trained agent can be deployed in the emulator, verifying simulation realism.",
      "Shows that a commonly used MLP architecture transfers poorly to novel scenarios and provides a size-invariant model with initial evidence of better transfer."
    ]
  },
  {
    "arxiv_id": "2306.07601v1",
    "title": "Intrusion Detection: A Deep Learning Approach",
    "authors": "Ishaan Shivhare; Joy Purohit; Vinay Jogani; Samina Attari; Madhav Chandane",
    "abstract": "Network intrusions are a significant problem in all industries today. A critical part of the solution is being able to effectively detect intrusions. With recent advances in artificial intelligence, current research has begun adopting deep learning approaches for intrusion detection. Current approaches for multi-class intrusion detection include the use of a deep neural network. However, it fails to take into account spatial relationships between the data objects and long term dependencies present in the dataset. The paper proposes a novel architecture to combat intrusion detection that has a Convolutional Neural Network (CNN) module, along with a Long Short Term Memory(LSTM) module and with a Support Vector Machine (SVM) classification function. The analysis is followed by a comparison of both conventional machine learning techniques and deep learning methodologies, which highlights areas that could be further explored.",
    "published_date": "2023-06-13",
    "pdf_link": "https://arxiv.org/pdf/2306.07601v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Multi-class network intrusion detection on flow-based traffic using a CNN-LSTM feature extractor with an SVM classifier",
      "attack_types": [
        "Brute Force FTP",
        "Brute Force SSH",
        "DoS",
        "DDoS",
        "Heartbleed",
        "Web Attack",
        "Infiltration",
        "Botnet"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Hybrid (CNN+LSTM+SVM)",
        "specific": "CNN-LSTM feature extractor + SVM (RBF kernel) classifier",
        "novel_contribution": "Replaces the typical Softmax output layer with an SVM classifier on top of CNN-LSTM features for multi-class intrusion detection"
      },
      {
        "type": "primary",
        "category": "Dimensionality Reduction",
        "specific": "PCA (30 principal components)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "KNN",
        "specific": "k=5",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "CNN-only classifier (Softmax)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Hybrid (CNN+LSTM)",
        "specific": "CNN-LSTM (Softmax)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "DNN (5 Layers)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CICIDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "KNN (k=5)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "97.29%",
        "baseline_result": "90.10%"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "97.29%",
        "baseline_result": "88.48%"
      },
      {
        "method_name": "CNN",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "97.29%",
        "baseline_result": "91.65%"
      },
      {
        "method_name": "CNN-LSTM",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "97.29%",
        "baseline_result": "93.61%"
      },
      {
        "method_name": "DNN (5 Layers)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "97.29%",
        "baseline_result": "95.61%"
      }
    ],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can replacing the Softmax layer with an SVM classifier on top of CNN-LSTM features improve multi-class intrusion detection accuracy on CICIDS2017?",
        "Does combining CNN (spatial features) and LSTM (temporal dependencies) address shortcomings of prior DNN-based IDS models?"
      ],
      "gaps_identified": [
        "\"Current approaches for multi-class intrusion detection include the use of a deep neural network. However, it fails to take into account spatial relationships between the data objects and long term dependencies present in the dataset.\"",
        "Traditional machine learning approaches rely on manual feature extraction from network traffic.",
        "Use of Softmax as the final layer may be suboptimal compared to SVM for multi-class IDS in terms of performance and computational efficiency."
      ],
      "limitations": [
        "Only one kind of LSTM has been tested in this work."
      ],
      "future_work": [
        "Examine LSTM variations including Peephole, Multiplicative, and Weighted LSTM.",
        "Explore other neural network and feature selection techniques."
      ],
      "motivation": "Network intrusions are a growing problem; deep learning can automatically learn spatial and temporal features from traffic and potentially improve detection accuracy and scalability over traditional ML.",
      "potential_research_ideas": [
        "Evaluate alternative sequence models (BiLSTM, Temporal Convolutional Networks, Transformers) for temporal modeling in IDS.",
        "End-to-end differentiable SVM surrogate layers vs. traditional SVM classifier to enable joint training with CNN-LSTM.",
        "Systematic comparison of SVM kernels (linear, polynomial, RBF) and multi-class strategies (one-vs-rest, one-vs-one) atop deep features.",
        "Ablation study on PCA vs. learned dimensionality reduction (autoencoders, bottleneck layers) and their impact on accuracy/latency.",
        "Domain generalization and cross-dataset evaluation (e.g., CIC-IDS 2018/2019) to assess robustness and reduce overfitting to CICIDS2017.",
        "Online/streaming inference with concept drift detection and incremental model updates.",
        "Explainability of decisions (e.g., SHAP on deep features; saliency over flow fields) to support analyst triage.",
        "Adversarial robustness assessment and defenses (adversarial training, feature smoothing) for evasion-resilient IDS.",
        "Cost-sensitive and imbalance-aware training (focal loss, reweighting) to improve minority attack class detection.",
        "Calibration of outputs and threshold optimization for operational settings (false positive control)."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment LSTM with Transformer encoders and learnable positional encodings for sequence modeling of flows.",
        "Introduce attention over CNN-extracted features (CNN + BiLSTM + attention) before the classifier.",
        "Use residual 1D CNN blocks with batch normalization and dropout to stabilize training and improve feature richness.",
        "Jointly learn a low-dimensional bottleneck instead of PCA, or use variational/denoising autoencoders for dimensionality reduction.",
        "Compare SVM head with a well-regularized Softmax head (label smoothing, focal loss) and with metric-learning losses (ArcFace/Triplet).",
        "Hyperparameter tuning of SVM (C, gamma for RBF) and deep model (sequence length, hidden size) with cross-validation.",
        "Introduce class-imbalance handling (cost-sensitive SVM; weighted loss) and data-level augmentation (SMOTE for tabular flows).",
        "Pipeline for real-time deployment: batching, quantization, and model distillation to reduce latency and memory footprint."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a CNN-LSTM-SVM architecture for multi-class network intrusion detection, replacing the Softmax output with an SVM classifier.",
      "Leverages CNN for spatial feature extraction and LSTM (70 time steps) for temporal dependencies.",
      "Applies PCA to reduce 77 features to 30 principal components to lower computational complexity.",
      "Empirical comparison on CICIDS2017 shows higher accuracy (97.29%) than KNN, Random Forest, CNN, CNN-LSTM, and a 5-layer DNN."
    ]
  },
  {
    "arxiv_id": "2305.06108v1",
    "title": "A Deep Dive into NFT Rug Pulls",
    "authors": "Jintao Huang; Ningyu He; Kai Ma; Jiang Xiao; Haoyu Wang",
    "abstract": "NFT rug pull is one of the most prominent type of scam that the developers of a project abandon it and then run away with investors' funds. Although they have drawn attention from our community, to the best of our knowledge, the NFT rug pulls have not been systematically explored. To fill the void, this paper presents the first in-depth study of NFT rug pulls. Specifically, we first compile a list of 253 known NFT rug pulls as our initial ground truth, based on which we perform a pilot study, highlighting the key symptoms of NFT rug pulls. Then, we enforce a strict rule-based method to flag more rug pulled NFT projects in the wild, and have labelled 7,487 NFT rug pulls as our extended ground truth. Atop it, we have investigated the art of NFT rug pulls, with kinds of tricks including explicit ones that are embedded with backdoors, and implicit ones that manipulate the market. To release the expansion of the scam, we further design a prediction model to proactively identify the potential rug pull projects in an early stage ahead of the scam happens. We have implemented a prototype system deployed in the real-world setting for over 5 months. Our system has raised alarms for 7,821 NFT projects, by the time of this writing, which can work as a whistle blower that pinpoints rug pull scams timely, thus mitigating the impacts.",
    "published_date": "2023-05-10",
    "pdf_link": "https://arxiv.org/pdf/2305.06108v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique",
      "new_dataset"
    ],
    "security_domain": {
      "primary": "Blockchain/Web3 Security",
      "subdomain": "Fraud and Scam Detection",
      "specific_problem": "Detection and early warning of NFT rug pull scams on Ethereum",
      "attack_types": [
        "Rug pull",
        "Market manipulation",
        "Wash trading",
        "Counterfeit scam",
        "Middleman reselling",
        "Bonus creator fee manipulation",
        "Smart contract backdoors",
        "Hidden mint",
        "Unapproved transfer",
        "Hidden URI replacement",
        "Mint-fee withdraw"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Supervised classifier (unspecified)",
        "specific": null,
        "novel_contribution": "Early-warning prediction model using 73 features from on-chain events, market trades, and time-series signals to raise alarms prior to rug-pull execution"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Rule-based"
    ],
    "datasets": [
      {
        "name": "Initial ground truth of 253 NFT rug pulls",
        "type": "public",
        "domain": "blockchain_scams_labels",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Extended ground truth of 7,487 NFT rug pulls (rule-based labeled)",
        "type": "public",
        "domain": "blockchain_transactions_and_NFT_projects",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Ethereum NFT projects dataset (on-chain and off-chain data for 173K projects)",
        "type": "public",
        "domain": "blockchain_transactions_and_smart_contracts",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "OpenSea secondary market trade data",
        "type": "public",
        "domain": "NFT_market_trades",
        "link": "https://opensea.io",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Chainabuse reports used for seed labels",
        "type": "public",
        "domain": "threat_intelligence_reports",
        "link": "https://www.chainabuse.com",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Twitter reports by Rug Pull Finder",
        "type": "public",
        "domain": "social_media_reports",
        "link": "https://twitter.com/rugpullfinder",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Twitter reports by ZachXBT",
        "type": "public",
        "domain": "social_media_reports",
        "link": "https://twitter.com/zachxbt",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "early_detection_rate",
      "lead_time_hours",
      "prevalence_measurement (count flagged)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: What are the characteristics of NFT rug pulls? Can we summarize concrete patterns to depict them?",
        "RQ2: How prevalent are NFT rug pulls in the wild?",
        "RQ3: What are the tricks used in NFT rug pulls?",
        "RQ4: Can we raise early warning of NFT rug pulls in advance?"
      ],
      "gaps_identified": [
        "“the NFT rug pull scams have not been systematically investigated or measured.”",
        "General lack of understanding of patterns, prevalence, and tricks of NFT rug pulls.",
        "“no existing approaches can be used to detect, mitigate or prevent this kind of scam.”"
      ],
      "limitations": [
        "The rule-based detector yields a lower-bound of rug pulls (“using the most reliable method, although it is only the lower-bound.”).",
        "Verification of all real-time warnings is difficult (“Although it is hard to verify all of them…”).",
        "Focus on Ethereum NFT ecosystem; cross-chain generalization not demonstrated."
      ],
      "future_work": [
        "Release the dataset to the research community (stated intent).",
        "Potential extension to more chains and NFT marketplaces (implied).",
        "Refine and validate early-warning model with broader ground truth as labels mature (implied)."
      ],
      "motivation": "Rug pulls are a significant and rising NFT scam type with large financial impact; lack of systematic study, detection, and proactive mitigation.",
      "potential_research_ideas": [
        "Graph-based learning on contract- and address-level interaction graphs for rug-pull early detection and attribution.",
        "Cross-market, cross-chain rug-pull detection leveraging federated or transfer learning to generalize beyond Ethereum/OpenSea.",
        "Adversarial modeling of scammers’ evasion tactics (e.g., synthetic wash trading patterns) and robust training.",
        "Causal inference to disentangle market shocks from manipulation to reduce false positives in price/liveness signals.",
        "Explainable AI for actionable alerts that highlight specific suspicious features (e.g., abnormal mint-fee withdraw patterns) to aid investigators.",
        "Link analysis for scammer clustering and wallet attribution to detect repeat offenders and scam families."
      ],
      "architectural_improvement_recommendations": [
        "Augment the feature set with graph metrics (centrality, motif counts, temporal triads) from transaction and NFT transfer graphs.",
        "Use sequence models (temporal point processes or Transformer-based time-series models) for early-warning on event streams.",
        "Incorporate semi-supervised learning to leverage abundant unlabeled projects and handle label scarcity and delays.",
        "Implement concept-drift detection and online learning to adapt to evolving scam tactics.",
        "Calibrate outputs with conformal prediction to provide risk scores and uncertainty estimates for operations.",
        "Build an ensemble of rule-based detectors and ML models (stacking) to improve robustness and precision."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Real-time monitoring of Ethereum NFT transactions in production for over 5 months",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Difficulty verifying all raised warnings promptly",
        "Integration of heterogeneous data sources (on-chain, markets, social media)",
        "Potential adversarial adaptation by scammers to avoid rule-based flags"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Compiled and analyzed an initial ground truth of 253 NFT rug pulls; identified concrete symptoms (S1–S3) across profit, secondary market price/liquidity, and on-chain liveness.",
      "Designed a strict rule-based detector and labeled 7,487 rug-pulled NFT projects (30× larger than prior lists), establishing a large benchmark dataset.",
      "Investigated and automatically labeled eight tricks used in rug pulls (explicit backdoors and implicit market manipulation), observing “84% of existing rug pulls show such behaviors.”",
      "Proposed a real-time early-warning prediction model using 73 features from on-chain/off-chain/time-series data; reported: “Our model can raise alarms for 90% of NFT scam events within 96 hours ahead of rug pull happens.”",
      "Built and deployed a prototype system on Ethereum for over 5 months; “raised alarms for 7,821 NFT projects… most of them have been confirmed to be rug pulls in later times with additional evidences.”",
      "Commitment to release all datasets to the research community."
    ]
  },
  {
    "arxiv_id": "2306.02587v1",
    "title": "Jammer classification with Federated Learning",
    "authors": "Peng Wu; Helena Calatrava; Tales Imbiriba; Pau Closas",
    "abstract": "Jamming signals can jeopardize the operation of GNSS receivers until denying its operation. Given their ubiquity, jamming mitigation and localization techniques are of crucial importance, for which jammer classification is of help. Data-driven models have been proven useful in detecting these threats, while their training using crowdsourced data still poses challenges when it comes to private data sharing. This article investigates the use of federated learning to train jamming signal classifiers locally on each device, with model updates aggregated and averaged at the central server. This allows for privacy-preserving training procedures that do not require centralized data storage or access to client local data. The used framework FedAvg is assessed on a dataset consisting of spectrogram images of simulated interfered GNSS signal. Six different jammer types are effectively classified with comparable results to a fully centralized solution that requires vast amounts of data communication and involves privacy-preserving concerns.",
    "published_date": "2023-06-05",
    "pdf_link": "https://arxiv.org/pdf/2306.02587v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Wireless Security",
      "subdomain": "Jamming and Interference Mitigation",
      "specific_problem": "GNSS jammer type classification from spectrograms under privacy-preserving federated learning",
      "attack_types": [
        "Jamming",
        "RF interference"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "FedAvg",
        "novel_contribution": "Applies FedAvg to GNSS jammer classification and evaluates under IID and non-IID client distributions with varying numbers of clients"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "Shallow CNN for spectrogram image classification (one conv layer with 16 12x12 filters, pooling, FC + ReLU, softmax; SGD optimizer, lr=0.01) trained in a federated manner"
      },
      {
        "type": "baseline",
        "category": "Centralized Training",
        "specific": "Centralized CNN (same architecture)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Federated Learning",
        "specific": "FedProx, MOON",
        "novel_contribution": "Mentioned as alternatives; authors note similar performance in practice but only report FedAvg"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Federated"
    ],
    "datasets": [
      {
        "name": "GNSS jammer spectrogram dataset (Zenodo 3370934, from [7])",
        "type": "public",
        "domain": "rf_spectrograms (simulated interfered GNSS signals)",
        "link": "https://zenodo.org/record/3370934",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Centralized CNN (same architecture) trained on all data",
        "paper_reference": "[7] (dataset paper/benchmark) and [26] for CNN architecture mentioned",
        "metric": "Accuracy",
        "their_result": "Comparable to centralized; FL approaches the centralized benchmark under IID and degrades under non-IID",
        "baseline_result": "around 93.4% accuracy (centrally trained model)"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "confusion_matrix"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can federated learning train GNSS jamming signal classifiers without sharing raw data?",
        "How does federated learning perform for jammer classification under IID vs non-IID client data distributions and varying client counts?",
        "Is the performance of FL comparable to a fully centralized solution?"
      ],
      "gaps_identified": [
        "Crowdsourced centralized training raises privacy concerns due to sharing raw GNSS data",
        "Historically more work on jamming detection/mitigation/localization than on jammer type classification in GNSS",
        "Standard FL methods are challenged under non-IID client data, leading to degraded performance"
      ],
      "limitations": [
        "Experiments rely on simulated spectrogram images; no real-world interfered GNSS data used",
        "Wideband jammers excluded from classification",
        "Results reported only for FedAvg despite mentioning FedProx and MOON",
        "No analysis of communication cost, latency, or computational resource usage",
        "No evaluation of adversarial robustness or poisoning/Byzantine resilience",
        "Downsampled images (512x512 to 256x256), which may affect fidelity"
      ],
      "future_work": [],
      "motivation": "Enable privacy-preserving training of jammer classifiers using crowdsourced data without centralizing sensitive client data, while maintaining performance comparable to centralized training.",
      "potential_research_ideas": [
        "Evaluate and compare advanced FL algorithms (FedProx, MOON, SCAFFOLD, FedNova, FedOpt) specifically for non-IID jammer classification",
        "Personalized FL for clients observing different jammer types (e.g., pFedMe, Per-FedAvg, FedPer) to improve non-IID performance",
        "Collect and benchmark real-world GNSS interference datasets (including wideband and mixed sources) for federated training",
        "Robust FL against data/model poisoning and Byzantine clients in RF jammer classification (e.g., Krum, Bulyan, FLTrust)",
        "Incorporate communication-efficient FL (e.g., quantization, sparsification, Sketching) suited to bandwidth-limited receivers",
        "Domain adaptation and semi/self-supervised pretraining to bridge synthetic-to-real gap for spectrogram-based models",
        "Multi-modal fusion of time-domain and frequency-domain features (e.g., spectrogram + I/Q samples) within FL",
        "Differential privacy and secure aggregation tailored to RF spectrograms to quantify privacy-utility tradeoffs",
        "Automated data augmentation for RF spectrograms (e.g., frequency/time masking, random shifts) within federated pipelines"
      ],
      "architectural_improvement_recommendations": [
        "Replace shallow CNN with deeper yet efficient backbones (ResNet, MobileNet, EfficientNet) or Vision Transformers with patch sizes suited to spectrogram structure",
        "Use 2D convolutional kernels tuned to RF patterns (multi-scale receptive fields, dilated convolutions) and channel attention (SE/CBAM)",
        "Apply class-imbalance handling (focal loss, class-balanced loss, per-class reweighting) and client-level reweighting by class coverage",
        "Leverage contrastive/self-supervised objectives (SimCLR/MOCO variants) locally and globally to improve non-IID generalization",
        "Adopt personalized FL layers or adapters (frozen shared trunk with client-specific heads) for heterogeneous jammer availability",
        "Incorporate FedProx/MOON regularization terms and tune local epochs to reduce client drift",
        "Add DP-SGD noise and secure aggregation; evaluate impact on accuracy",
        "Implement gradient/weight compression (Top-k sparsification, quantization) to reduce communication overhead"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "400 federated communication rounds; experiments with 20/30/40 clients; local model: shallow CNN (one conv layer with 16 12x12 filters, pooling, FC + ReLU, softmax); optimizer SGD, learning rate 0.01; images downsampled to 256x256."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Non-IID client data degrades accuracy and slows convergence",
        "Higher number of clients reduces local data per client and requires more communication rounds",
        "Centralized training entails high data transfer and privacy concerns",
        "Lack of real-world labeled jammer data for training and evaluation"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Demonstrates the feasibility of federated learning (FedAvg) for GNSS jammer classification from spectrograms without sharing raw data",
      "Evaluates IID and non-IID client distributions and varying numbers of clients (20, 30, 40), analyzing convergence and accuracy",
      "Achieves accuracy comparable to a centralized CNN baseline (~93.4% benchmark) under IID settings and reports degradation under non-IID",
      "Details a lightweight CNN configuration and preprocessing pipeline for spectrogram inputs using a public dataset"
    ]
  },
  {
    "arxiv_id": "2305.15488v1",
    "title": "Foundational Models for Malware Embeddings Using Spatio-Temporal Parallel Convolutional Networks",
    "authors": "Dhruv Nandakumar; Devin Quinn; Elijah Soba; Eunyoung Kim; Christopher Redino; Chris Chan; Kevin Choi; Abdul Rahman; Edward Bowen",
    "abstract": "In today's interconnected digital landscape, the proliferation of malware poses a significant threat to the security and stability of computer networks and systems worldwide. As the complexity of malicious tactics, techniques, and procedures (TTPs) continuously grows to evade detection, so does the need for advanced methods capable of capturing and characterizing malware behavior. The current state of the art in malware classification and detection uses task specific objectives; however, this method fails to generalize to other downstream tasks involving the same malware class. In this paper, the authors introduce a novel method that combines convolutional neural networks, standard graph embedding techniques, and a metric learning objective to extract meaningful information from network flow data and create strong embeddings characterizing malware behavior. These embeddings enable the development of highly accurate, efficient, and generalizable machine learning models for tasks such as malware strain classification, zero day threat detection, and closest attack type attribution as demonstrated in this paper. A shift from task specific objectives to strong embeddings will not only allow rapid iteration of cyber-threat detection models, but also allow different modalities to be introduced in the development of these models.",
    "published_date": "2023-05-24",
    "pdf_link": "https://arxiv.org/pdf/2305.15488v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Network-based Malware Detection",
      "specific_problem": "Learning malware-behavior embeddings from network flow graphs for strain classification, zero-day threat detection, and closest attack type attribution",
      "attack_types": [
        "Remote Access Trojan (RAT)",
        "Downloader/Dropper",
        "Information Stealer/Keylogger",
        "Ransomware (as campaign outcome)",
        "Nanocore",
        "Azorult",
        "Ursnif",
        "Trickbot",
        "Lokibot",
        "Bazaloader",
        "Astaroth",
        "Matanbuchus",
        "Valak",
        "Qakbot",
        "Nymeria",
        "Xtremerat",
        "Netwire",
        "SquirrelWaffle",
        "Hancitor",
        "Gozi"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Spatio-Temporal Parallel Convolutional Network (ST-PCN)",
        "novel_contribution": "Parallel convolutional branches over adjacency (spatial) and FastRP-based temporal node-embedding matrices with concatenated embedding trained via metric-learning objective"
      },
      {
        "type": "primary",
        "category": "Graph Embedding",
        "specific": "FastRP (Very Sparse Random Projection)",
        "novel_contribution": "Use FastRP node embeddings combined with a novel edge-weighting scheme on connection graphs as input features; avoids network-wide normalization and manual graph feature engineering"
      },
      {
        "type": "primary",
        "category": "Metric Learning",
        "specific": "Additive Angular Margin (ArcFace)",
        "novel_contribution": "Optimizes malware-strain separability and intra-class compactness in the embedding space for transfer to multiple downstream tasks"
      },
      {
        "type": "baseline",
        "category": "Ensemble",
        "specific": "Random Forest",
        "novel_contribution": "Used as downstream classifier to evaluate quality of learned embeddings for malware classification"
      },
      {
        "type": "baseline",
        "category": "Instance-based",
        "specific": "K-Nearest Neighbors (distance-weighted, k=350)",
        "novel_contribution": "Used for zero-day threat detection (open-set proxy via thresholding complement of max class probability) and closest attack type attribution"
      },
      {
        "type": "baseline",
        "category": "Dimensionality Reduction",
        "specific": "UMAP",
        "novel_contribution": "Used for 3D visualization of embedding clusters (not part of training)"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Metric Learning",
      "Transfer Learning"
    ],
    "datasets": [
      {
        "name": "Gigas (internal malware cyber-range network flows)",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Malnet (flows derived from Malware-Traffic-Analysis PCAPs via CICFlowmeter)",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.malware-traffic-analysis.net/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "silhouette score",
      "completeness",
      "homogeneity",
      "Rand index",
      "AUC",
      "precision",
      "recall",
      "area under precision-recall curve (average precision)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can spatio-temporal embeddings learned from network flow connection graphs cluster malware strains and generalize across datasets?",
        "Do embeddings trained with a metric learning objective transfer to downstream tasks such as malware classification, zero-day threat detection, and closest attack type attribution without fine-tuning?",
        "Does combining FastRP node embeddings with adjacency matrices and a novel edge-weighting improve separability and downstream performance?"
      ],
      "gaps_identified": [
        "Task-specific malware classifiers fail to generalize to other downstream tasks involving the same malware class.",
        "Prior graph-based malware approaches rely on execution traces or static analysis rather than network flow telemetry.",
        "Normalization across heterogeneous networks is brittle for comparing network flow behavior; per-asset behavior embeddings mitigate this.",
        "Earlier network-flow-based anomaly/zero-day methods showed instability during training and weaker performance for specific malware types."
      ],
      "limitations": [
        "Assumes IP behavior at inference is similar to training for FastRP embeddings to be consistent.",
        "Lower performance on classes with limited samples (class imbalance in Malnet).",
        "Multiple tight sub-clusters for some strains suggest sensitivity to environmental factors (e.g., OS, context).",
        "Experiments require substantial memory and CPU resources (>=64 GB RAM, 32-core CPU); GPU usage not described.",
        "FastRP limited to second-degree neighborhoods in reported experiments; sensitivity to hyperparameters (alpha, beta, gamma, epsilon).",
        "No direct head-to-head quantitative baselines from prior art reported."
      ],
      "future_work": [
        "Shift from task-specific objectives to strong, reusable embeddings enabling rapid iteration and inclusion of different data modalities.",
        "Extend to additional downstream cyber-threat tasks and broader environments.",
        "Address class imbalance and evaluate across more diverse datasets."
      ],
      "motivation": "Create strong, reusable embeddings of malware behavior from network flow telemetry to improve generalization across tasks (classification, zero-day detection, attribution) and reduce reliance on task-specific models.",
      "potential_research_ideas": [
        "End-to-end learnable graph-temporal networks (e.g., combine GNNs with temporal CNN/Transformer) to replace fixed FastRP embeddings.",
        "Self-supervised or supervised-contrastive pretraining on large unlabeled flow graphs to reduce label dependence and improve zero-shot generalization.",
        "Domain adaptation and continual learning to handle network/environment drift (e.g., adversarial domain adaptation, test-time adaptation).",
        "Open-set recognition calibration and few-shot learning for novel malware strains with limited labeled examples.",
        "Adversarial robustness studies and defenses against traffic-manipulation/evasion attacks targeting flow features and graph structure.",
        "Multi-modal fusion (e.g., DNS/HTTP metadata, host logs, EDR telemetry) with cross-modal contrastive alignment.",
        "Explainability via subgraph/rule extraction and attention over flows/edges to provide analyst-understandable rationales.",
        "Federated or privacy-preserving training across organizations to leverage diverse data without sharing raw traffic.",
        "Streaming/online embedding updates and scalable approximate KNN for real-time deployment."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment FastRP with learnable GNN layers (GCN/GraphSAGE/GAT) trained jointly with the metric-learning head.",
        "Swap ArcFace loss with supervised contrastive loss or Proxy-NCA and apply hard example mining to improve class separation.",
        "Introduce temporal modules (Temporal Convolutional Networks or Transformers) over sequences of flow/node embeddings.",
        "Add attention mechanisms to weigh critical nodes/edges and enable explainability.",
        "Use class-imbalance-aware training (focal loss, reweighting) and mixup/cutmix in embedding space.",
        "Calibrate open-set thresholds using extreme value theory or energy-based scores for zero-day detection.",
        "Evaluate alternative graph embeddings (Node2Vec, LINE) and higher-order neighborhoods; perform ablations on edge-weight formula."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "At least 64 GB RAM and 32-core CPU for experiments; GPU not specified. Reported hyperparameters include alpha=1.15, beta=128, gamma=32, epsilon=32; FastRP uses up to second-degree neighbors with weights (1, 0.5, 0.5)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Domain shift across networks may break the assumption that IP behavior at inference matches training.",
        "Class imbalance and rarity of some malware strains can degrade performance.",
        "Graph construction and FastRP embedding computation add preprocessing overhead.",
        "Significant memory/CPU requirements may hinder real-time deployment without optimization."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A novel method of computing edge weights on connection graphs for graph-based feature learning from network flows.",
      "A technique that uses FastRP node embeddings and graph adjacency matrices with a metric learning objective to train an embedding model of malware behavior.",
      "A spatio-temporal parallel convolutional network (ST-PCN) that learns embeddings capturing both temporal sequence and spatial connectivity.",
      "Benchmarking the proposed embeddings on three downstream tasks: malware classification, zero-day threat detection, and closest attack-type attribution, showing strong performance on two datasets."
    ]
  },
  {
    "arxiv_id": "2305.19487v2",
    "title": "SPGNN-API: A Transferable Graph Neural Network for Attack Paths Identification and Autonomous Mitigation",
    "authors": "Houssem Jmal; Firas Ben Hmida; Nardine Basta; Muhammad Ikram; Mohamed Ali Kaafar; Andy Walker",
    "abstract": "Attack paths are the potential chain of malicious activities an attacker performs to compromise network assets and acquire privileges through exploiting network vulnerabilities. Attack path analysis helps organizations to identify new/unknown chains of attack vectors that reach critical assets within the network, as opposed to individual attack vectors in signature-based attack analysis. Timely identification of attack paths enables proactive mitigation of threats. Nevertheless, manual analysis of complex network configurations, vulnerabilities, and security events to identify attack paths is rarely feasible. This work proposes a novel transferable graph neural network-based model for shortest path identification. The proposed shortest path detection approach, integrated with a novel holistic and comprehensive model for identifying potential network vulnerabilities interactions, is then utilized to detect network attack paths. Our framework automates the risk assessment of attack paths indicating the propensity of the paths to enable the compromise of highly-critical assets (e.g., databases) given the network configuration, assets' criticality, and the severity of the vulnerabilities in-path to the asset. The proposed framework, named SPGNN-API, incorporates automated threat mitigation through a proactive timely tuning of the network firewall rules and zero-trust policies to break critical attack paths and bolster cyber defenses. Our evaluation process is twofold; evaluating the performance of the shortest path identification and assessing the attack path detection accuracy. Our results show that SPGNN-API largely outperforms the baseline model for shortest path identification with an average accuracy >= 95% and successfully detects 100% of the potentially compromised assets, outperforming the attack graph baseline by 47%.",
    "published_date": "2023-05-31",
    "pdf_link": "https://arxiv.org/pdf/2305.19487v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Attack Path Analysis and Mitigation",
      "specific_problem": "Automated identification of attack paths to highly-critical assets and autonomous mitigation via Zero-Trust policy tuning",
      "attack_types": [
        "multi-step vulnerability exploitation chains",
        "attack paths to critical assets"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Positional Graph Neural Network extension (distance/positional encoding based)",
        "novel_contribution": "Transferable GNN that computes shortest path distances using only nodes’ positional embeddings (distance encoding), independent of other node/edge features; enhanced by removing self-loops"
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "SPAGAN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Rule-based/Logic programming attack graph",
        "specific": "MulVAL",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Semi-supervised",
      "Transfer Learning"
    ],
    "datasets": [
      {
        "name": "Unnamed synthetic network dataset 1",
        "type": "synthetic",
        "domain": "enterprise_network_topology/zero-trust policies",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Unnamed synthetic network dataset 2",
        "type": "synthetic",
        "domain": "enterprise_network_topology/zero-trust policies",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Unnamed real-world enterprise network dataset 1 (middle-sized network)",
        "type": "proprietary",
        "domain": "enterprise_network_topology/zero-trust policies",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Unnamed real-world enterprise network dataset 2 (middle-sized network)",
        "type": "proprietary",
        "domain": "enterprise_network_topology/zero-trust policies",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Cora",
        "type": "public",
        "domain": "citation_network",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Citeseer",
        "type": "public",
        "domain": "citation_network",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SPAGAN",
        "paper_reference": "[10]",
        "metric": "Accuracy (shortest path identification)",
        "their_result": "“average accuracy ≥95%” for shortest path identification (SPGNN-API)",
        "baseline_result": null
      },
      {
        "method_name": "MulVAL",
        "paper_reference": "[7]",
        "metric": "Detection of potentially compromised assets (attack path identification)",
        "their_result": "“successfully detects 100% of the potentially compromised assets, outperforming the attack graph baseline by 47%”",
        "baseline_result": "Baseline detected 47% fewer potentially compromised assets (exact rate not specified)"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "percentage of potentially compromised assets detected",
      "relative improvement (%)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How to develop an automated and adaptive identification of attack paths given the dynamic nature of the network structure?",
        "How to comprehensively identify the potential interplay between vulnerabilities without being bound to a predefined set of rules or attack scenarios?",
        "How to efficiently characterize and rank the risks of attack paths, and autonomously triage and mitigate them without disrupting network functionalities?"
      ],
      "gaps_identified": [
        "Traditional attack graphs/trees require regeneration when the network structure changes and lack adaptiveness",
        "DL-based approaches need re-generated structure-based inputs and may require retraining when the network changes",
        "Existing approaches are restricted to predefined attacks or rule sets for vulnerability interactions",
        "GNNs often fail to capture positional information; nodes with similar local neighborhoods can have identical embeddings despite different global positions",
        "Vulnerability detection models often lack a risk evaluation process to prioritize threats",
        "Lack of integrated tools combining real-time network connectivity assessment and vulnerability scanning"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Rising complexity and volume of cyber attacks necessitate automated, adaptive attack path detection and proactive mitigation in dynamic enterprise networks using Zero-Trust policies and risk-aware analysis.",
      "potential_research_ideas": [
        "Extend from shortest-path-based risk to probabilistic, multi-criteria risk-aware path search that accounts for exploit likelihood, detection probability, and attacker costs",
        "Incorporate temporal/streaming graph modeling to capture evolving network configurations and vulnerability lifecycles",
        "Develop explainable path attribution methods to highlight which vulnerabilities and policies contribute most to risk",
        "Evaluate and harden against adversarial manipulations of graph structure/features (e.g., poisoned asset tags or misreported CVSS data)",
        "Integrate real-time telemetry (e.g., flow logs, EDR alerts) for online path risk updating and closed-loop mitigation",
        "Generalize to heterogeneous graphs (assets, policies, users, vulnerabilities) and hypergraphs to represent multi-asset interactions",
        "Benchmark on larger, public enterprise-like network graphs with released synthetic generators and seeds",
        "Formulate mitigation as a constrained optimization or RL problem balancing risk reduction and business continuity"
      ],
      "architectural_improvement_recommendations": [
        "Augment positional encodings with learnable spectral/Laplacian positional features and edge feature modeling (e.g., protocol/port/policy compliance flags)",
        "Adopt self-supervised/contrastive pretraining on large unlabeled network graphs to improve transfer to new environments",
        "Explore heterogeneous GNNs or attention-based architectures to better model different node/edge types (assets, policies, vulnerabilities)",
        "Incorporate uncertainty estimation (e.g., Monte Carlo dropout) to calibrate risk scores and mitigation confidence",
        "Use temporal GNNs for dynamic graph changes and incremental updates without full retraining",
        "Add a differentiable or RL-based policy selection layer to propose minimal-impact Zero-Trust rule changes"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Inference via learned GNN is O(1) per distance query vs classical shortest path O(VE); specific hardware not specified"
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Enterprise network with Zero-Trust micro-segmentation (distributed virtual firewalls)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Adapting to dynamic network structure without disrupting network functionalities",
        "Ensuring governance tag accuracy and compliance when tuning Zero-Trust policies",
        "Balancing proactive mitigation with business continuity"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Novel transferable GNN for shortest path calculation relying solely on nodes’ positional embeddings",
      "GNN-based approach for vulnerability assessment and attack path identification that adapts to dynamic enterprise networks without continuous retraining",
      "Empirical finding: removing self-loops improves positional GNN performance by ~5% on average (max 9%) across six datasets",
      "Comprehensive model learning propensity of vulnerabilities to contribute to compromising critical assets using CVSS base metrics without predefined signatures/rules",
      "Automated risk characterization of detected attack paths using network connectivity, asset configurations/criticality, and vulnerabilities’ CVSS metrics",
      "Autonomous mitigation by tuning Zero-Trust policies to break high-risk paths without disrupting functionality",
      "Outperforms SPAGAN for shortest paths (average accuracy >95%) and MulVAL for attack paths (detects 100% of potentially compromised assets; 47% better than baseline)"
    ]
  },
  {
    "arxiv_id": "2305.15191v1",
    "title": "IoT Threat Detection Testbed Using Generative Adversarial Networks",
    "authors": "Farooq Shaikh; Elias Bou-Harb; Aldin Vehabovic; Jorge Crichigno; Aysegul Yayimli; Nasir Ghani",
    "abstract": "The Internet of Things(IoT) paradigm provides persistent sensing and data collection capabilities and is becoming increasingly prevalent across many market sectors. However, most IoT devices emphasize usability and function over security, making them very vulnerable to malicious exploits. This concern is evidenced by the increased use of compromised IoT devices in large scale bot networks (botnets) to launch distributed denial of service(DDoS) attacks against high value targets. Unsecured IoT systems can also provide entry points to private networks, allowing adversaries relatively easy access to valuable resources and services. Indeed, these evolving IoT threat vectors (ranging from brute force attacks to remote code execution exploits) are posing key challenges. Moreover, many traditional security mechanisms are not amenable for deployment on smaller resource-constrained IoT platforms. As a result, researchers have been developing a range of methods for IoT security, with many strategies using advanced machine learning(ML) techniques. Along these lines, this paper presents a novel generative adversarial network(GAN) solution to detect threats from malicious IoT devices both inside and outside a network. This model is trained using both benign IoT traffic and global darknet data and further evaluated in a testbed with real IoT devices and malware threats.",
    "published_date": "2023-05-24",
    "pdf_link": "https://arxiv.org/pdf/2305.15191v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion/Anomaly Detection",
      "specific_problem": "Anomaly-based detection of malicious IoT device behavior using GANs trained on benign IoT testbed traffic and darknet data",
      "attack_types": [
        "DDoS (botnets: Mirai, Bashlite)",
        "Network scanning (Nmap, reconnaissance)",
        "Brute-force (default credentials)",
        "Command injection",
        "Remote code execution",
        "MITM (ARP poisoning)",
        "Nessus-based web/application scanning"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GAN",
        "specific": "GAN with encoder (E) and feature-matching discriminator loss (BiGAN/ALI-style formulation)",
        "novel_contribution": "Applies GAN-based anomaly detection to IoT by modeling both benign IoT traffic and malicious darknet traffic; trains on benign testbed traffic and CAIDA darknet data; evaluates on a live IoT malware testbed (Mirai, Bashlite)."
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "CAIDA darknet network telescope data",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "IoT Testbed Traffic (Benign)",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "IoT Testbed Traffic (Malware: Mirai, Bashlite)",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "“many of these studies do not consider prominent IoT malware families and/or utilize realistic attack datasets.”",
        "“the lack of realistic attack traffic is also problematic” when developing real-world operational intrusion and anomaly detection systems.",
        "High overheads of per-device autoencoders: “this approach has high overheads as separate autoencoders must be trained for every IoT device… does not account for external threats.”",
        "Traditional security mechanisms are “not amenable for deployment on smaller resource-constrained IoT platforms.”"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "IoT devices are widely deployed yet vulnerable, fueling large botnets (e.g., Mirai) and varied exploits; existing ML-based IoT IDS often lack realistic datasets and do not incorporate prominent malware families. The work proposes GAN-based anomaly detection leveraging benign IoT testbed traffic and real darknet data to detect threats inside and outside networks.",
      "potential_research_ideas": [
        "Domain adaptation/transfer learning between darknet-trained models and enterprise/home IoT network environments to improve generalization.",
        "Temporal modeling of IoT traffic (e.g., sequence GANs or hybrid GAN+RNN/Transformer) to capture time-dependent behavior changes during infection and scanning phases.",
        "Federated or on-device anomaly detection for privacy-preserving collaborative training across IoT deployments.",
        "Adversarial robustness studies against evasive botnets that attempt to mimic benign traffic; design robust training (e.g., adversarial training, outlier exposure).",
        "Explainability for anomaly scores (feature attribution) to aid operators in triage and response.",
        "Joint multi-source data fusion (e.g., network flows + device logs + firmware signals) for improved detection and attribution of attack stages.",
        "Early-stage scanning detection benchmarking with standardized, shareable IoT traffic corpora derived from diverse devices and malware families."
      ],
      "architectural_improvement_recommendations": [
        "Use conditional GANs to model specific attack families/stages (e.g., scanning vs. post-compromise) and enable multi-class anomaly characterization.",
        "Incorporate a reconstruction-based module (e.g., GANomaly/autoencoder branch) alongside the discriminator to produce complementary anomaly scores.",
        "Calibrate anomaly scores using extreme value theory or conformal prediction for threshold robustness across networks.",
        "Apply self-supervised pretraining on large-scale darknet traffic (contrastive learning) before GAN fine-tuning on local benign IoT traffic.",
        "Leverage graph-based representations (device-communication graphs) with graph-GANs for topology-aware anomaly detection.",
        "Integrate online/streaming learning to adapt to non-stationary IoT traffic distributions."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Laboratory IoT network testbed with physical devices (Netgear DGN2200 router, Yi 1080p camera, Samsung Smart IP camera); VMware ESXi VMs for C&C servers and binary distribution; pfsense virtual router/firewall; tools including Metasploit (Kali), Nessus, Nmap, Snort.",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Resource-constrained IoT devices limit traditional security mechanism deployment.",
        "Difficulty of patching/updating devices at scale and lack of vendor support.",
        "Obtaining realistic IoT malware traffic for training/validation.",
        "Evolving malware targeting bootloaders/firmware increases detection difficulty."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "One of the first known applications of GANs to IoT security for anomaly detection of malicious IoT devices inside and outside the network.",
      "Leverages real-world darknet (passive) measurements to validate the model.",
      "Builds and evaluates a live operational IoT testbed with devices commonly targeted by botnets and evaluates using Mirai and Bashlite malware families."
    ]
  },
  {
    "arxiv_id": "2305.10668v2",
    "title": "MetaGAD: Meta Representation Adaptation for Few-Shot Graph Anomaly Detection",
    "authors": "Xiongxiao Xu; Kaize Ding; Canyu Chen; Kai Shu",
    "abstract": "Graph anomaly detection has long been an important problem in various domains pertaining to information security such as financial fraud, social spam and network intrusion. The majority of existing methods are performed in an unsupervised manner, as labeled anomalies in a large scale are often too expensive to acquire. However, the identified anomalies may turn out to be uninteresting data instances due to the lack of prior knowledge. In real-world scenarios, it is often feasible to obtain limited labeled anomalies, which have great potential to advance graph anomaly detection. However, the work exploring limited labeled anomalies and a large amount of unlabeled nodes in graphs to detect anomalies is relatively limited. Therefore, in this paper, we study an important problem of few-shot graph anomaly detection. Nonetheless, it is challenging to fully leverage the information of few-shot anomalous nodes due to the irregularity of anomalies and the overfitting issue in the few-shot learning. To tackle the above challenges, we propose a novel meta-learning based framework, MetaGAD, that learns to adapt the knowledge from self-supervised learning to few-shot supervised learning for graph anomaly detection. In specific, we formulate the problem as a bi-level optimization, ensuring MetaGAD converging to minimizing the validation loss, thus enhancing the generalization capacity. The comprehensive experiments on six real-world datasets with synthetic anomalies and \"organic\" anomalies (available in the datasets) demonstrate the effectiveness of MetaGAD in detecting anomalies with few-shot anomalies. The code is available at https://github.com/XiongxiaoXu/MetaGAD.",
    "published_date": "2023-05-18",
    "pdf_link": "https://arxiv.org/pdf/2305.10668v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Security Analytics",
      "subdomain": "Anomaly Detection",
      "specific_problem": "Few-shot graph anomaly detection on a single homogeneous graph (node-level) using meta-learning with representation adaptation",
      "attack_types": [
        "financial fraud",
        "social spam",
        "network intrusion"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Meta-learning",
        "specific": "Bi-level optimization with validation-driven meta-objective (one-step SGD approximation)",
        "novel_contribution": "Representation Adaptation Network (RAN) optimized by validation loss to adapt self-supervised representations for few-shot supervised anomaly detection; bi-level optimization to mitigate overfitting."
      },
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Graph encoder from DOMINANT (GCN-based autoencoder) used as self-supervised encoder",
        "novel_contribution": "Use of a pretrained generative GNN encoder to provide raw node representations which are adapted via RAN."
      },
      {
        "type": "primary",
        "category": "Feed-forward Network",
        "specific": "Two-layer MLP as Representation Adaptation Network (RAN)",
        "novel_contribution": "Lightweight adapter to bridge self-supervised and supervised representations guided by validation loss."
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": "Anomaly detector (target model) over adapted representations",
        "novel_contribution": "Cost-sensitive training on few-shot positives vs many unlabeled nodes."
      },
      {
        "type": "primary",
        "category": "Optimization",
        "specific": "Finite difference approximation for mixed second-order term in meta-gradient",
        "novel_contribution": "Efficient approximation to enable practical bi-level updates."
      },
      {
        "type": "primary",
        "category": "Learning Strategy",
        "specific": "Cost-sensitive loss with positive-class weighting",
        "novel_contribution": "Balances extreme class imbalance in few-shot anomaly detection."
      }
    ],
    "learning_paradigm": [
      "Self-supervised (pretrained encoder)",
      "Supervised (few-shot)",
      "Meta-learning",
      "Semi-supervised",
      "Few-shot"
    ],
    "datasets": [
      {
        "name": "Cora (synthetic anomalies)",
        "type": "public",
        "domain": "citation_graph",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Citeseer (synthetic anomalies)",
        "type": "public",
        "domain": "citation_graph",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Amazon Photo (synthetic anomalies)",
        "type": "public",
        "domain": "social/e-commerce_photo_graph",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Wiki (organic anomalies)",
        "type": "public",
        "domain": "editor_page_graph",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Amazon Review (organic anomalies)",
        "type": "public",
        "domain": "ecommerce_review_graph",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "YelpChi (organic anomalies)",
        "type": "public",
        "domain": "social_review_graph",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: How effective is MetaGAD for detecting anomalies with few or even one labeled instance?",
        "RQ2: How does each key module of MetaGAD contribute to the detecting performance?",
        "RQ3: How does MetaGAD alleviate the commonly overfitting issue in the few-shot problem?",
        "RQ4: How does the performance of MetaGAD change under different imbalance levels in the data?",
        "RQ5: How robust is MetaGAD under different contamination levels in the unlabeled nodes?"
      ],
      "gaps_identified": [
        "Limited exploration of leveraging limited labeled anomalies together with many unlabeled nodes for graph anomaly detection.",
        "Representation gap between self-supervised and supervised learning for graph anomaly detection remains unaddressed.",
        "Few-shot settings suffer from severe overfitting with standard pretrain-finetune on deep GNNs.",
        "Unsupervised GAD may surface uninteresting anomalies due to lack of prior knowledge.",
        "Lack of principled approach to focus on the primary task of learning from few-shot anomalies while using unlabeled nodes."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Obtain and exploit limited labeled anomalies to improve graph anomaly detection while mitigating representation gaps between self-supervised and supervised paradigms and avoiding overfitting in few-shot settings.",
      "potential_research_ideas": [
        "Extend MetaGAD to heterogeneous and dynamic graphs (temporal anomalies) with time-aware RAN and detector.",
        "Jointly pretrain the graph encoder with contrastive objectives and meta-learned adapters end-to-end rather than using a fixed encoder.",
        "Integrate positive-unlabeled (PU) learning to avoid treating all unlabeled nodes as negatives and reduce label bias.",
        "Incorporate uncertainty estimation and active learning to select most informative nodes for labeling in the few-shot regime.",
        "Adversarially robust MetaGAD: train RAN and detector with adversarial perturbations on node features/graph structure.",
        "Develop edge-level and subgraph-level few-shot anomaly detectors using adapted representations.",
        "Design self-distillation or parameter-efficient adapters (e.g., LoRA-style) as RAN for scalable deployment on large graphs.",
        "Meta-learning with implicit differentiation or higher-order methods to stabilize and speed up bi-level optimization.",
        "Use differentiable ranking losses (AUC/average precision surrogates) tailored to anomaly detection.",
        "Combine graph Transformers as encoders with MetaGAD adaptation for larger-scale and long-range dependency modeling."
      ],
      "architectural_improvement_recommendations": [
        "Make the encoder trainable within the bi-level loop (end-to-end) with regularization to avoid overfitting.",
        "Replace the 2-layer RAN with attention/gating or hypernetwork-based adapters conditioned on node context.",
        "Adopt implicit differentiation (e.g., conjugate gradient/Neumann series) instead of finite differences for meta-gradient accuracy and efficiency.",
        "Use PU-learning losses and calibrated class weighting rather than labeling all unlabeled nodes as negatives.",
        "Optimize a differentiable AUC/ranking loss in the target model to better align with anomaly detection objectives.",
        "Add consistency regularization and data augmentation for graphs (edge/node feature perturbations) to improve generalization.",
        "Leverage parameter-efficient fine-tuning (adapters/LoRA) for the encoder to reduce compute and memory.",
        "Incorporate memory banks or prototype-based detectors over adapted embeddings for stability in ultra-few-shot (k<=1)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/XiongxiaoXu/MetaGAD",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Study of the crucial and practical problem of few-shot graph anomaly detection on a single graph.",
      "Proposal of MetaGAD: a meta-learning approach that adapts self-supervised representations to few-shot supervised anomaly detection via a bi-level optimization to enhance generalization and alleviate overfitting.",
      "Design of a Representation Adaptation Network (RAN) and an anomaly detector coupled through validation- and training-loss-driven updates.",
      "Extensive experiments on six real-world datasets with both synthetic and organic anomalies, demonstrating effectiveness."
    ]
  },
  {
    "arxiv_id": "2306.17187v1",
    "title": "An Intelligent Mechanism for Monitoring and Detecting Intrusions in IoT Devices",
    "authors": "Vitalina Holubenko; Paulo Silva; Carlos Bento",
    "abstract": "The current amount of IoT devices and their limitations has come to serve as a motivation for malicious entities to take advantage of such devices and use them for their own gain. To protect against cyberattacks in IoT devices, Machine Learning techniques can be applied to Intrusion Detection Systems. Moreover, privacy related issues associated with centralized approaches can be mitigated through Federated Learning. This work proposes a Host-based Intrusion Detection Systems that leverages Federated Learning and Multi-Layer Perceptron neural networks to detected cyberattacks on IoT devices with high accuracy and enhancing data privacy protection.",
    "published_date": "2023-06-23",
    "pdf_link": "https://arxiv.org/pdf/2306.17187v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Host-based intrusion detection on IoT devices using system call traces with federated learning",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "Federated Averaging (FA), Weighted Federated Averaging (WFA)",
        "novel_contribution": "Applies FL to HIDS on IoT endpoints to enhance privacy by keeping system call data on-device"
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": "Multi-Layer Perceptron",
        "novel_contribution": "Central and federated MLP-based classifier on TF-IDF features of system call sequences for HIDS"
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "KNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Engineering",
        "specific": "TF-IDF, vector space, trivial representations; PCA for feature selection",
        "novel_contribution": "Evaluates multiple feature representations for syscall traces; selects TF-IDF"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Federated Learning"
    ],
    "datasets": [
      {
        "name": "ADFA-LD",
        "type": "public",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Proof-of-concept HIDS system call dataset (local VMs)",
        "type": "private",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "“The current working system is able to achieve a F1-score of 96%.” (MLP-based system)",
        "baseline_result": "“Random Forest was the best performing classifier, obtaining a value of 98% for F1-score.”"
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": "Among best candidates with higher accuracy/recall/precision and lower FPR (no exact value reported)."
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": "Among best candidates with higher accuracy/recall/precision and lower FPR; low FPR/FNR “by a considerable margin, up to 0.05%.”"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": "Low FPR/FNR compared to other classifiers (no exact overall metric reported)."
      },
      {
        "method_name": "Federated Averaging (FA)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "Weighted Federated Averaging (WFA): “achieving around 96% of accuracy” and “slightly better performance than Federated Averaging (FA)” under non-iid.",
        "baseline_result": "FA: “achieving around 96% of accuracy” but slightly worse than WFA when data is not equally distributed."
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "FPR",
      "FNR",
      "TPR"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a host-based IDS for IoT devices leverage federated learning and MLPs to detect intrusions from system call traces while preserving data privacy?",
        "Which system call feature representation (trivial, vector space, TF-IDF) and sequence length yield the best detection performance on IoT HIDS?",
        "How does the performance of federated models (FA vs WFA) compare to centralized training for IoT HIDS under class balance and potential non-iid data distributions?"
      ],
      "gaps_identified": [
        "“little work has been done with HIDS for IoT”",
        "Centralized ML approaches pose privacy risks for user/device data aggregated on a server.",
        "Traditional IDS are not suitable for IoT due to limited resources, decentralization, and heterogeneity of devices, technologies, and protocols."
      ],
      "limitations": [
        "Training used balanced classes (50% benign / 50% attack), which differs from real-world where benign traffic dominates: “this balance of the data can lead to different problems.”",
        "Current system performs binary classification (normal vs attack) and does not differentiate attack types.",
        "Evaluation primarily on ADFA-LD and a small proof-of-concept local dataset; real IoT deployment not demonstrated."
      ],
      "future_work": [
        "“implementing other efficient machine learning algorithms, such as deep learning techniques, like CNN, RNN and LSTM”",
        "“multi class classification in order to differentiate the incoming attacks.”"
      ],
      "motivation": "Protect IoT devices from cyberattacks with IDS suited to resource-constrained, decentralized, and heterogeneous IoT environments, while mitigating privacy issues via federated learning.",
      "potential_research_ideas": [
        "Design lightweight sequence models (e.g., 1D CNNs, temporal CNNs, compact LSTMs, or tiny Transformers) over raw system call sequences with embedding layers, optimized for on-device inference.",
        "Explore non-IID and heterogeneous FL algorithms (FedProx, SCAFFOLD, FedAvgM, FedNova) and client personalization/clustered FL for diverse IoT device behaviors.",
        "Incorporate differential privacy and secure aggregation in FL to quantify privacy-utility trade-offs for syscall data.",
        "Develop poisoning/backdoor-robust FL with robust aggregation (Krum, Trimmed Mean, Median) and anomaly detection on client updates for HIDS.",
        "Address class imbalance with cost-sensitive learning, focal loss, calibrated thresholds, and anomaly/one-class learning for rare attacks.",
        "Continual/online learning with drift detection to adapt to evolving device behavior and new attack patterns.",
        "Multi-modal HIDS by fusing system calls with other host telemetry (process metadata, file ops) to improve robustness.",
        "Explainability for HIDS (n-gram attribution, prototype sequences) to assist analysts and reduce false positives.",
        "Model compression (quantization, pruning, distillation) to meet memory/compute constraints on IoT endpoints.",
        "Dynamic or adaptive windowing of syscall sequences and neural architectures that handle variable-length sequences."
      ],
      "architectural_improvement_recommendations": [
        "Replace TF-IDF+MLP with an embedding layer over syscall IDs followed by a lightweight 1D CNN or LSTM to capture temporal patterns beyond n-grams.",
        "Adopt FL algorithms tailored to non-IID settings (FedProx/SCAFFOLD) and momentum variants (FedAvgM) to stabilize convergence.",
        "Introduce class-weighted loss or focal loss and threshold calibration to handle real-world class imbalance.",
        "Add differential privacy noise and secure aggregation to the FL pipeline to strengthen privacy guarantees.",
        "Use hashing trick for n-gram features to reduce TF-IDF dimensionality, paired with PCA or feature selection to minimize memory.",
        "Implement early-stopping, quantization-aware training, and post-training quantization/pruning for on-device inference efficiency.",
        "Evaluate and tune variable sequence lengths with adaptive or attention-based pooling to generalize beyond fixed length 30."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Proposed for IoT endpoint devices (host-based)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Resource constraints on IoT devices (compute, memory, storage).",
        "Heterogeneity of devices, technologies, and protocols in IoT.",
        "Privacy risks in centralized learning; addressed via federated learning.",
        "Class imbalance in realistic settings (benign >> malicious)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a host-based IDS architecture for IoT leveraging federated learning and MLPs on system call traces.",
      "Evaluates multiple feature representations (trivial, vector space, TF-IDF) and selects TF-IDF, with PCA for feature selection.",
      "Identifies an optimal system call sequence length of 30 for best performance: “we concluded that 30 was the optimal length.”",
      "Compares centralized ML to federated settings (FA vs WFA); finds WFA slightly better than FA when data is not equally distributed, with “around 96%” accuracy.",
      "Reports centralized Random Forest baseline achieving “98%” F1-score on ADFA-LD with TF-IDF; current MLP-based system achieves “F1-score of 96%.”",
      "Constructs a proof-of-concept local HIDS dataset (system calls) for additional evaluation (not publicly released)."
    ]
  },
  {
    "arxiv_id": "2306.09247v1",
    "title": "ATLAS: Automatically Detecting Discrepancies Between Privacy Policies and Privacy Labels",
    "authors": "Akshath Jain; David Rodriguez; Jose M. del Alamo; Norman Sadeh",
    "abstract": "Privacy policies are long, complex documents that end-users seldom read. Privacy labels aim to ameliorate these issues by providing succinct summaries of salient data practices. In December 2020, Apple began requiring that app developers submit privacy labels describing their apps' data practices. Yet, research suggests that app developers often struggle to do so. In this paper, we automatically identify possible discrepancies between mobile app privacy policies and their privacy labels. Such discrepancies could be indicators of potential privacy compliance issues.   We introduce the Automated Privacy Label Analysis System (ATLAS). ATLAS includes three components: a pipeline to systematically retrieve iOS App Store listings and privacy policies; an ensemble-based classifier capable of predicting privacy labels from the text of privacy policies with 91.3% accuracy using state-of-the-art NLP techniques; and a discrepancy analysis mechanism that enables a large-scale privacy analysis of the iOS App Store.   Our system has enabled us to analyze 354,725 iOS apps. We find several interesting trends. For example, only 40.3% of apps in the App Store provide easily accessible privacy policies, and only 29.6% of apps provide both accessible privacy policies and privacy labels. Among apps that provide both, 88.0% have at least one possible discrepancy between the text of their privacy policy and their privacy label, which could be indicative of a potential compliance issue. We find that, on average, apps have 5.32 such potential compliance issues.   We hope that ATLAS will help app developers, researchers, regulators, and mobile app stores alike. For example, app developers could use our classifier to check for discrepancies between their privacy policies and privacy labels, and regulators could use our system to help review apps at scale for potential compliance issues.",
    "published_date": "2023-05-24",
    "pdf_link": "https://arxiv.org/pdf/2306.09247v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Privacy and Compliance",
      "subdomain": "Mobile App Privacy Compliance",
      "specific_problem": "Automatic detection of discrepancies between iOS App Store privacy labels and the text of mobile app privacy policies at scale",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": null,
        "novel_contribution": "Ensemble-based multi-label document classification to predict whether each of 32 iOS data types is collected per privacy policy; reported overall accuracy 91.3%."
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": null,
        "novel_contribution": "Applied state-of-the-art transformer-based long-document classifiers to privacy policy classification (policies up to thousands of tokens)."
      },
      {
        "type": "primary",
        "category": "Classical ML",
        "specific": "Logistic Regression",
        "novel_contribution": "Classifier to verify that an app-provided URL actually resolves to an English-language privacy policy; achieved 98.1% accuracy and F1 98.4%."
      },
      {
        "type": "primary",
        "category": "Feature Engineering",
        "specific": "TF-IDF",
        "novel_contribution": "TF-IDF embeddings of policies used for clustering-driven importance sampling to mitigate label noise."
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "DBSCAN",
        "novel_contribution": "Unsupervised clustering over reduced TF-IDF features to identify semantically similar policy clusters and re-label/weight via statistical tests."
      },
      {
        "type": "primary",
        "category": "Dimensionality Reduction",
        "specific": "LSA (TruncatedSVD)",
        "novel_contribution": "Projected high-dimensional TF-IDF vectors to 10 components before DBSCAN clustering for importance sampling."
      },
      {
        "type": "primary",
        "category": "Visualization",
        "specific": "t-SNE",
        "novel_contribution": "Used to visualize overlap and cluster structure between positive/negative samples for a given data type."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "United States iOS App Store app listings and privacy labels (2023 scrape)",
        "type": "public",
        "domain": "app_store_metadata",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ATLAS Privacy Policies Corpus (scraped from iOS App Store links)",
        "type": "proprietary",
        "domain": "privacy_policies",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Policy URL Classification Labeled Set (918 pages; 67.3% true privacy policies)",
        "type": "proprietary",
        "domain": "privacy_policies",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "F1",
      "precision",
      "recall",
      "two-proportion z-test (p < 0.05)",
      "discrepancy rate between labels and policies",
      "average number of potential compliance issues per app",
      "adoption/accessibility percentages (policy/label availability)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What is the state of privacy policy and privacy label adoption among iOS apps? Can app privacy policies be easily accessed?",
        "Is it possible to predict privacy labels from the text of privacy policies?",
        "Are privacy labels consistent with the text of privacy policies? What types and rates of discrepancies occur, and how do these correlate with app popularity?"
      ],
      "gaps_identified": [
        "Developers struggle to accurately create privacy labels, leading to noisy/mislabeled disclosures.",
        "Limited prior large-scale analyses of iOS privacy label compliance; earlier work often focused on Android, small samples, or static/dynamic analysis rather than policy–label consistency.",
        "Privacy policies are long and complex, making manual review infeasible at scale; need automated NLP methods.",
        "Many apps do not provide easily accessible privacy policies despite being required to link them."
      ],
      "limitations": [
        "The study only predicts which data types are collected and not how the data is used (“Linked to You” or “Used to Track” not modeled).",
        "Training labels come from developer-reported privacy labels, which can be noisy or inaccurate.",
        "Analysis focuses on apps with both accessible policies and labels (29.6% of sampled apps), potentially excluding a large portion of the store.",
        "Policy uniqueness determined by exact URL matching; duplicate content with different URLs may persist and vice versa.",
        "English-language focus for policy verification may exclude non-English policies.",
        "Static, point-in-time snapshot (Jan 29–31, 2023) and U.S. storefront only."
      ],
      "future_work": [],
      "motivation": "Provide scalable, automated tools to assess and improve the consistency of app privacy disclosures by identifying potential compliance issues between privacy policies and iOS privacy labels.",
      "potential_research_ideas": [
        "Extend classification to include data-use purposes, linkage (“Linked to You”) and tracking flags, enabling end-to-end label generation.",
        "Cross-validate predicted labels with dynamic and static code analysis to triangulate true practices and quantify false positives/negatives.",
        "Develop multilingual models to include non-English privacy policies across global App Stores.",
        "Create a benchmark dataset with human-verified policy–label alignments to reduce training/test noise and foster fair comparisons.",
        "Temporal drift analysis: track how discrepancies evolve across app updates and policy revisions.",
        "Causal analysis of factors associated with discrepancies (e.g., developer size, app category, SDK usage).",
        "Policy segmentation + span-level extraction to ground predictions in specific policy sentences for auditability."
      ],
      "architectural_improvement_recommendations": [
        "Adopt long-context transformer architectures (e.g., Longformer/BigBird) with hierarchical encoding of policy sections to capture full-document context.",
        "Incorporate noise-robust training (e.g., co-teaching, label smoothing, confident learning) instead of only sampling-based denoising.",
        "Use multi-task learning to jointly predict data collection, use purposes, linkage, and tracking flags, sharing representations.",
        "Add retrieval-augmented components to map Apple label taxonomy to policy-specific terminology via synonym/ontology expansion.",
        "Integrate calibration and uncertainty estimation to flag low-confidence predictions for human review.",
        "Provide rationale extraction/attribution (e.g., attention rollout, gradient-based saliency) to support explainability."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Distributed crawling with 1 driver node and 49 workers + 49 proxies (Phase 1) and 1 driver + 80 workers (Phase 2); headless Firefox; ~20k apps/hour; total 60-hour window. ML training/inference compute not specified."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Distributed web-scraping and analysis pipeline operating against the U.S. iOS App Store; headless browsers with proxy pool.",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Rate-limiting and proxy management (nightly proxy reboots, failures).",
        "Dynamic content loading and redirects requiring headless browser automation.",
        "High incidence of dead or extraneous links in App Store–provided policy URLs.",
        "Duplicate privacy policies across multiple apps.",
        "Label noise from developer-reported privacy labels."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A scalable, distributed pipeline to systematically scrape iOS App Store metadata, privacy policy URLs, and privacy labels, including a classifier to verify English-language privacy policies.",
      "An ensemble-based classifier that predicts privacy label data-type collection from privacy policy text for 32 data types, achieving 91.3% accuracy.",
      "A large-scale discrepancy analysis of 354,725 iOS apps: only 40.3% provide accessible policies; 62.5% provide privacy labels; 29.6% provide both; among those with both, 88.0% have at least one potential discrepancy; average of 5.32 potential compliance issues per app."
    ]
  },
  {
    "arxiv_id": "2305.10791v1",
    "title": "BrutePrint: Expose Smartphone Fingerprint Authentication to Brute-force Attack",
    "authors": "Yu Chen; Yiling He",
    "abstract": "Fingerprint authentication has been widely adopted on smartphones to complement traditional password authentication, making it a tempting target for attackers. The smartphone industry is fully aware of existing threats, and especially for the presentation attack studied by most prior works, the threats are nearly eliminated by liveness detection and attempt limit. In this paper, we study the seemingly impossible fingerprint brute-force attack on off-the-shelf smartphones and propose a generic attack framework. We implement BrutePrint to automate the attack, that acts as a middleman to bypass attempt limit and hijack fingerprint images. Specifically, the bypassing exploits two zero-day vulnerabilities in smartphone fingerprint authentication (SFA) framework, and the hijacking leverages the simplicity of SPI protocol. Moreover, we consider a practical cross-device attack scenario and tackle the liveness and matching problems with neural style transfer (NST). We also propose a method based on neural style transfer to generate valid brute-forcing inputs from arbitrary fingerprint images. A case study shows that we always bypasses liveness detection and attempt limit while 71% spoofs are accepted. We evaluate BrutePrint on 10 representative smartphones from top-5 vendors and 3 typical types of applications involving screen lock, payment, and privacy. As all of them are vulnerable to some extent, fingerprint brute-force attack is validated on on all devices except iPhone, where the shortest time to unlock the smartphone without prior knowledge about the victim is estimated at 40 minutes. Furthermore, we suggest software and hardware mitigation measures.",
    "published_date": "2023-05-18",
    "pdf_link": "https://arxiv.org/pdf/2305.10791v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "Biometric Authentication",
      "specific_problem": "Brute-force attacks against smartphone fingerprint authentication via attempt-limit bypass and fingerprint image hijacking",
      "attack_types": [
        "brute-force",
        "man-in-the-middle (SPI bus)",
        "side-channel inference (timing/behavioral)",
        "checksum/glitch injection",
        "presentation attack bypass"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GAN/NST (Neural Style Transfer)",
        "specific": "CycleGAN-style unpaired image-to-image translation",
        "novel_contribution": "Adapt NST to translate arbitrary fingerprint images into smartphone sensor-specific style to bypass liveness detection while retaining features for matching; includes DPI alignment, rectangular input handling via stride/padding changes, and sensor-specific raw format constraints"
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Open-source fingerprint databases (e.g., FVC)",
        "type": "public",
        "domain": "fingerprint_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Hijacked smartphone sensor raw fingerprint images (target domain via SPI MITM)",
        "type": "proprietary",
        "domain": "fingerprint_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "False Accept Rate (FAR)",
      "False Reject Rate (FRR)",
      "Spoof acceptance rate (e.g., \"71% spoofs are accepted\")",
      "Number of attempts beyond attempt limit",
      "Estimated time to unlock (e.g., \"40 minutes\" on iPhone, estimated)",
      "Success rate / probability model of brute-forcing"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Is smartphone fingerprint authentication secure enough against brute-force when liveness detection and attempt limits are in place?",
        "Can logical flaws in SFA frameworks be exploited to bypass attempt limits at scale (CAMF, MAL)?",
        "Can MITM on the SPI bus hijack fingerprint images for brute-forcing without device rooting?",
        "Can neural style transfer convert arbitrary fingerprint images into sensor-valid inputs that bypass liveness detection while preserving features for matching?"
      ],
      "gaps_identified": [
        "Reliance on liveness detection and attempt limits as primary defenses; no consideration of large-scale brute-force under FAR constraints",
        "Unencrypted and unauthenticated SPI communication between sensor and processor enabling MITM",
        "Logical defects in multi-sampling and error-cancel mechanisms (CAMF) allowing attempts without decrementing attempt counters",
        "Pseudo lockout that is ignored by Keyguard (MAL), enabling inference of matching results via side-channels even under lockout",
        "Prior disclosed SFA vulnerabilities were model/OS-specific; lack of cross-device, generic attack analysis"
      ],
      "limitations": [
        "Fingerprint image interception and replacement not achieved on iPhone; iOS/Touch ID behaves differently and is more constrained",
        "MAL exists only in screen lock context and may incur extra time cost",
        "Attack requires physical access, device disassembly, and model-specific FPC adapters",
        "Reverse engineering of raw image encoding/decoding is device-specific",
        "NST-based dictionary generation needs target domain samples for training and careful handling to avoid compensation/liveness rejection",
        "Success relies on the system FAR and number of enrolled fingerprints"
      ],
      "future_work": [
        "Software and hardware mitigation measures (as suggested by authors)"
      ],
      "motivation": "Demonstrate that seemingly impossible large-scale brute-force attacks against off-the-shelf smartphone fingerprint authentication are practical by bypassing attempt limits and hijacking fingerprint images, thereby challenging prevailing reliance on liveness detection and attempt limits.",
      "potential_research_ideas": [
        "Design PAD/liveness detection robust to NST-style-transferred inputs and domain-shift attacks specific to smartphone sensor pipelines",
        "Formal verification and redesign of SFA multi-sampling/error-cancel logic to prevent CAMF-like bypasses",
        "Authenticated, encrypted sensor-to-TEE links with challenge–response and per-frame nonces/MACs to eliminate SPI MITM and replay",
        "On-device anomaly detection of acquisition patterns (e.g., repeated M-th sample errors, abnormal sampling loops, SPI timing anomalies)",
        "Side-channel resistant SFA workflows (constant-time responses, uniform sample counts) to prevent MAL result inference",
        "Cross-sensor fingerprint style normalization and detection to flag injected/hijacked samples",
        "Hardware tamper detection on FPC/SPI paths (impedance, active shielding) integrated with SFA lockouts"
      ],
      "architectural_improvement_recommendations": [
        "Encrypt and mutually authenticate the SPI channel between sensor and TEE using per-session keys and per-frame nonces/MACs",
        "Eliminate error-cancel paths that do not decrement attempt counters; account per-sample or per-collection deterministically",
        "Unify lockout enforcement end-to-end (TEE and UI layers) and disallow any Keyguard exceptions in lockout",
        "Make matching pipelines constant-time or add fixed-time padding and fixed sample counts to remove side-channel leakage",
        "Integrity check the sensor chain with attestation of sensor firmware and bus path; add tamper sensors on FPC",
        "Strengthen PAD with multi-modal active liveness (e.g., blood perfusion, ultrasonic micro-motion) to resist material/textural spoofing and NST artifacts",
        "Rate limit and jitter defense on acquisition to disrupt precise MITM timing/injection"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Low-cost adversarial PCB (~$15) plus device-specific FPC adapters; physical access for several hours; ML training/inference requirements for NST not specified."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Off-the-shelf smartphones (Android, HarmonyOS, iOS Touch ID) across screen lock, payment, and privacy apps",
      "scalability_discussed": true,
      "inference_time": "Shortest time to unlock a smartphone without prior knowledge about the victim is estimated at 40 minutes (iPhone; estimate)",
      "deployment_challenges": [
        "Requires physical access and device disassembly to insert MITM PCB",
        "Model-specific flexible PCB (FPC) adapters needed",
        "Reverse engineering of sensor-specific raw image formats and checksums",
        "Attack not fully effective on iPhone (no image interception/replacement)",
        "MAL limited to screen lock and may incur extra time",
        "Reliance on availability of large fingerprint databases"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Discovery of two zero-day vulnerabilities in smartphone fingerprint authentication frameworks: Cancel-After-Match-Fail (CAMF) and Match-After-Lock (MAL), enabling attempt-limit bypass",
      "Hardware MITM attack on unprotected SPI links to hijack fingerprint images (interception and replacement) across multiple sensor types",
      "BrutePrint attack framework automating brute-force by combining attempt-limit bypass and fingerprint image hijacking",
      "Neural style transfer-based fingerprint dictionary generation to convert arbitrary fingerprint images into sensor-valid styles that bypass liveness detection and preserve matching features",
      "Empirical validation on 10 representative smartphones from top-5 vendors across screen lock, payment, and privacy applications; unlimited attempts on Android/HarmonyOS, 10 extra attempts on iOS; 71% spoof acceptance in case study; estimated 40 minutes to unlock iPhone",
      "Recommendations of software and hardware mitigations"
    ]
  },
  {
    "arxiv_id": "2305.01236v1",
    "title": "CNS-Net: Conservative Novelty Synthesizing Network for Malware Recognition in an Open-set Scenario",
    "authors": "Jingcai Guo; Song Guo; Shiheng Ma; Yuxia Sun; Yuanyuan Xu",
    "abstract": "We study the challenging task of malware recognition on both known and novel unknown malware families, called malware open-set recognition (MOSR). Previous works usually assume the malware families are known to the classifier in a close-set scenario, i.e., testing families are the subset or at most identical to training families. However, novel unknown malware families frequently emerge in real-world applications, and as such, require to recognize malware instances in an open-set scenario, i.e., some unknown families are also included in the test-set, which has been rarely and non-thoroughly investigated in the cyber-security domain. One practical solution for MOSR may consider jointly classifying known and detecting unknown malware families by a single classifier (e.g., neural network) from the variance of the predicted probability distribution on known families. However, conventional well-trained classifiers usually tend to obtain overly high recognition probabilities in the outputs, especially when the instance feature distributions are similar to each other, e.g., unknown v.s. known malware families, and thus dramatically degrades the recognition on novel unknown malware families. In this paper, we propose a novel model that can conservatively synthesize malware instances to mimic unknown malware families and support a more robust training of the classifier. Moreover, we also build a new large-scale malware dataset, named MAL-100, to fill the gap of lacking large open-set malware benchmark dataset. Experimental results on two widely used malware datasets and our MAL-100 demonstrate the effectiveness of our model compared with other representative methods.",
    "published_date": "2023-05-02",
    "pdf_link": "https://arxiv.org/pdf/2305.01236v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Family Classification",
      "specific_problem": "Open-set malware recognition (MOSR): classify known malware families and detect novel unknown families",
      "attack_types": [
        "malware (viruses, spyware, trojan horses, worms)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Generative Adversarial Network",
        "specific": "GAN",
        "novel_contribution": "Conservative novelty synthesizing network (CNS-Net) that generates marginal samples near known families to mimic unknown families, without strong assumptions about unknowns"
      },
      {
        "type": "primary",
        "category": "Feedforward Neural Network",
        "specific": null,
        "novel_contribution": "Single classifier trained with regularizers to lower and flatten predicted probabilities for unknowns while preserving/raising confidence for known classes"
      },
      {
        "type": "primary",
        "category": "Training Scheme",
        "specific": "Cooperative training (classification + synthesizing + rectification)",
        "novel_contribution": "Joint optimization where synthesized unknown-like samples regularize the classifier via two regularizers: global unknown probabilities flattening and batch-level specific known families exclusion"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Adversarial training"
    ],
    "datasets": [
      {
        "name": "MAL-100",
        "type": "synthetic",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "unspecified widely used malware dataset 1",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "unspecified widely used malware dataset 2",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to recognize both known malware families and detect novel unknown families in an open-set scenario (MOSR)?",
        "How to mitigate overly high recognition probabilities (overconfidence) on unknown malware families caused by feature similarity among families?",
        "Can synthesizing marginal unknown-like malware instances support more robust classifier training for MOSR?"
      ],
      "gaps_identified": [
        "Open-set malware recognition has been rarely and non-thoroughly investigated in cyber-security.",
        "Conventional classifiers tend to produce overly high probabilities for both known and unknown malware due to small inter-family variance.",
        "Lack of a large-scale open-set malware benchmark dataset; need for a dataset to evaluate MOSR (addressed by MAL-100)."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Construct an applicable MOSR system that can classify known malware families and detect novel unknown families, overcoming classifier overconfidence and addressing the lack of open-set benchmarks.",
      "potential_research_ideas": [
        "Incorporate self-supervised or contrastive pretraining on large unlabeled malware corpora to improve feature separability for open-set detection.",
        "Combine CNS-Net with EVT-based calibration (e.g., Extreme Value Machine) for threshold-free or better-calibrated unknown detection.",
        "Extend CNS-Net to multi-modal features (static + dynamic behavioral traces) to increase separability between known and unknown families.",
        "Develop continual/online learning mechanisms to incrementally integrate discovered unknown families into the known set with minimal forgetting.",
        "Explore uncertainty quantification (e.g., deep ensembles, evidential deep learning) alongside CNS synthesis to improve detection of unknowns.",
        "Investigate detection under distribution shift and poisoning/adversarially crafted malware that attempts to bypass open-set detectors."
      ],
      "architectural_improvement_recommendations": [
        "Use a stronger backbone (e.g., transformer-based feature extractor for binary sequences or API call graphs) prior to the classifier head.",
        "Integrate energy-based or logit-based open-set losses (e.g., OE, energy regularization) jointly with CNS regularizers.",
        "Adopt a conditional GAN that conditions on proximity to specific known classes to better target the marginal regions.",
        "Add embedding space separation via metric learning (e.g., ArcFace or center loss) to enhance known class compactness and known-unknown margin.",
        "Calibrate outputs with temperature scaling or post-hoc calibration to reduce overconfidence further.",
        "Introduce a detector head trained with a one-vs-rest or binary known-vs-unknown objective in parallel with the K-way classifier."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First formal investigation for malware recognition in the open-set scenario.",
      "A novel MOSR framework (CNS-Net) that conservatively synthesizes marginal malware instances to mimic unknown families and jointly improves classification and detection.",
      "A cooperative training scheme unifying classification, synthesizing, and rectification to facilitate training.",
      "A new large-scale malware benchmark dataset (MAL-100) with >50k instances from 100 families for open-set malware recognition."
    ]
  },
  {
    "arxiv_id": "2305.13287v1",
    "title": "Data-Centric Machine Learning Approach for Early Ransomware Detection and Attribution",
    "authors": "Aldin Vehabovic; Hadi Zanddizari; Nasir Ghani; Farooq Shaikh; Elias Bou-Harb; Morteza Safaei Pour; Jorge Crichigno",
    "abstract": "Researchers have proposed a wide range of ransomware detection and analysis schemes. However, most of these efforts have focused on older families targeting Windows 7/8 systems. Hence there is a critical need to develop efficient solutions to tackle the latest threats, many of which may have relatively fewer samples to analyze. This paper presents a machine learning(ML) framework for early ransomware detection and attribution. The solution pursues a data-centric approach which uses a minimalist ransomware dataset and implements static analysis using portable executable(PE) files. Results for several ML classifiers confirm strong performance in terms of accuracy and zero-day threat detection.",
    "published_date": "2023-05-22",
    "pdf_link": "https://arxiv.org/pdf/2305.13287v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Ransomware Detection and Attribution",
      "specific_problem": "Early ransomware detection and family attribution on Windows 10/11 using static PE-file features with minimalist datasets",
      "attack_types": [
        "ransomware",
        "zero-day ransomware (unseen family)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Gradient Boosting",
        "specific": "XGBoost",
        "novel_contribution": "Applied to compact PE-header feature vectors (5/7/10/15 features incl. computed TotalDLLCalls) for early ransomware detection and attribution on recent Windows 10/11 families using minimalist datasets."
      },
      {
        "type": "primary",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": "Evaluated on same minimalist PE feature vectors for detection/attribution and zero-day detection."
      },
      {
        "type": "baseline",
        "category": "Support Vector Machine",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feed-forward Neural Network",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Curated Windows 10/11 Ransomware PE Dataset (9 families + benign)",
        "type": "proprietary",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "MalwareBazaar",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://bazaar.abuse.ch/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Triage",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://tria.ge/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusShare",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://virusshare.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusTotal",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://www.virustotal.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VX Heaven (historical, inactive)",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Support Vector Machine",
        "paper_reference": null,
        "metric": "Multi-class accuracy (15-feature vector)",
        "their_result": "XGBoost: 94-96% (\"RF and XGBoost ... best accuracy (94-96% range)\")",
        "baseline_result": "SVM lower; improves with features but below RF/XGB; ransomware misclassification around 50% with small feature vectors"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Multi-class accuracy (15-feature vector)",
        "their_result": "XGBoost: 94-96%",
        "baseline_result": "RF comparable/best within 94-96% range"
      },
      {
        "method_name": "Feed-forward Neural Network",
        "paper_reference": null,
        "metric": "Multi-class accuracy (15-feature vector)",
        "their_result": "XGBoost: 94-96%",
        "baseline_result": "FNN ≈91% (\"the FNN scheme approaches these methods with 15 features, i.e., 91% accuracy\")"
      },
      {
        "method_name": "Support Vector Machine",
        "paper_reference": null,
        "metric": "Ransomware Detection Rate (RDR)",
        "their_result": "RF/XGBoost close to 95% RDR",
        "baseline_result": "SVM poor for small feature vectors; highly sensitive to feature size"
      },
      {
        "method_name": "Feed-forward Neural Network",
        "paper_reference": null,
        "metric": "Ransomware Detection Rate (RDR)",
        "their_result": "RF/XGBoost close to 95% RDR",
        "baseline_result": "FNN up to ~92% RDR with larger feature vectors"
      },
      {
        "method_name": "Support Vector Machine",
        "paper_reference": null,
        "metric": "Zero-day detection (family-wise accuracy)",
        "their_result": "See Table II for XGBoost (e.g., NetWalker 97.14%, DJVu/STOP 90.71%, WannaCry 14.29%)",
        "baseline_result": "SVM (e.g., NetWalker 95.00%, DJVu/STOP 82.86%, WannaCry 13.57%)"
      }
    ],
    "performance_metrics_used": [
      "multi-class accuracy",
      "ransomware detection rate (RDR)",
      "benign detection rate (BDR)",
      "confusion matrix",
      "zero-day detection accuracy (leave-one-family-out)",
      "runtime (PE-file generation and classification time)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can lightweight static PE-header features with a minimalist dataset provide accurate early detection and family attribution of recent Windows 10/11 ransomware?",
        "How do standard supervised classifiers (SVM, RF, XGBoost, FNN) perform on small PE-feature vectors for detection/attribution?",
        "What is the framework’s ability to flag zero-day ransomware (unseen families) as malicious?",
        "Are run-times amenable for practical early-stage (pre-infection) deployment?"
      ],
      "gaps_identified": [
        "Most prior works target older ransomware families on Windows 7/8; limited relevance to latest Windows 10/11 threats.",
        "Scarcity, duplication, and inconsistent labeling of recent ransomware samples across repositories hinder ML training.",
        "Many PE-based malware studies lacked dataset transparency and used decade-old samples.",
        "Dynamic/code-based analyses can be labor-intensive or require long observation windows; need earlier, faster detection."
      ],
      "limitations": [
        "Minimalist dataset; potential lack of diversity due to scarcity and duplication across sources.",
        "WannaCry evades all schemes in zero-day tests (14–20% detection).",
        "SVM and FNN highly sensitive to feature vector size; SVM poor with small feature sets.",
        "No public release of curated dataset mentioned."
      ],
      "future_work": [
        "Incorporate additional PE-file features or other static parameters to improve zero-day detection (especially WannaCry).",
        "Expand the curated dataset with more diverse, recent samples and benign applications.",
        "Integrate into network/host defenses for pre-infection scanning and conduct field evaluations."
      ],
      "motivation": "Address the pressing need to detect and attribute newly emerging Windows 10/11 ransomware using efficient, early, and data-centric ML approaches that work with limited samples.",
      "potential_research_ideas": [
        "Few-shot/open-set ransomware detection using metric learning or prototypes for unseen families.",
        "Self-supervised pretraining on large unlabeled PE corpora to learn robust representations, then fine-tune on minimalist ransomware labels.",
        "Hybrid static+lightweight dynamic features (e.g., brief API-call bursts) to improve zero-day generalization without heavy sandboxes.",
        "Graph-based modeling of import/function-call relationships (import graphs) for attribution and evasion robustness.",
        "Uncertainty-aware detection with selective abstention and human-in-the-loop triage for borderline cases.",
        "Automated feature engineering from PE sections (entropy, strings, resources) with feature selection to target WannaCry-like evasions.",
        "Cross-version generalization studies (Windows 10 vs 11) and temporal validation to assess dataset shift.",
        "Data-centric curation pipelines with de-duplication, label verification, and diversity metrics across families.",
        "Adversarially robust static detectors via feature smoothing or randomized ensembles against packing/obfuscation."
      ],
      "architectural_improvement_recommendations": [
        "Augment PE features: section-wise entropy/statistics, import frequencies, API n-grams, resource characteristics, string features, compiler/linker metadata.",
        "Use calibrated gradient boosting (XGBoost/LightGBM/CatBoost) with class-weighting and threshold tuning to minimize false negatives (maximize RDR).",
        "Add open-set recognition (e.g., OpenMax) or one-class anomaly detectors alongside multi-class attribution to flag novel families.",
        "Stacking/ensembles combining RF and XGBoost with a lightweight NN meta-learner; apply conformal prediction for calibrated confidence.",
        "Apply robust cross-validation and temporal splits; include feature importance (SHAP) for interpretability and feature pruning.",
        "Deploy feature hashing for high-cardinality import names and reduce overfitting on small datasets."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Keras",
        "TensorFlow",
        "Pandas",
        "scikit-learn"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Windows 11 server, Intel Core i9 3.60 GHz CPU, 64 GB RAM. Inference times: SVM/RF/XGBoost 2–8 ms per sample; FNN 47 ms. PE-file generation: ransomware 50–300 ms; benign avg 1.46 s. No GPU required for inference."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "SVM/RF/XGBoost: 2–8 ms per sample; FNN: 47 ms. PE-file generation adds 50–300 ms for ransomware and ~1.46 s for benign files.",
      "deployment_challenges": [
        "Scarcity/duplication of recent ransomware samples; inconsistent labeling across repositories.",
        "Need to minimize false negatives (ransomware misclassified as benign).",
        "WannaCry zero-day evasion (low detection rates).",
        "Static-only features may be vulnerable to packing/obfuscation; no evaluation provided."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Curated a new minimalist dataset of 9 recent Windows 10/11 ransomware families (Babuk/Babyk, BlackCat, Chaos, DJVu/STOP, Hive, LockBit, Netwalker, Sodinokibi/REvil, WannaCry) plus 2,000 benign apps.",
      "Designed lightweight static PE-based feature vectors (5/7/10/15 features), including a computed TotalDLLCalls feature.",
      "Comprehensive evaluation of SVM, RF, XGBoost, and FNN on detection, attribution, and zero-day scenarios.",
      "Reported strong accuracy with minimalist features: RF/XGBoost ~94–96% multi-class; FNN ~91% (15 features).",
      "High RDR/BDR with minimalist features: RF/XGBoost RDR close to 95%; BDR close to 99%.",
      "Zero-day tests: RF detected 8/9 families at ~80–99% (except WannaCry ~14.86%); XGBoost 6/9 at ~80–99% (WannaCry ~14.29%).",
      "Measured practical run-times suitable for pre-infection scanning (few ms inference; sub-second PE processing)."
    ]
  },
  {
    "arxiv_id": "2305.08226v1",
    "title": "NLP-based Cross-Layer 5G Vulnerabilities Detection via Fuzzing Generated Run-Time Profiling",
    "authors": "Zhuzhu Wang; Ying Wang",
    "abstract": "The effectiveness and efficiency of 5G software stack vulnerability and unintended behavior detection are essential for 5G assurance, especially for its applications in critical infrastructures. Scalability and automation are the main challenges in testing approaches and cybersecurity research. In this paper, we propose an innovative approach for automatically detecting vulnerabilities, unintended emergent behaviors, and performance degradation in 5G stacks via run-time profiling documents corresponding to fuzz testing in code repositories. Piloting on srsRAN, we map the run-time profiling via Logging Information (LogInfo) generated by fuzzing test to a high dimensional metric space first and then construct feature spaces based on their timestamp information. Lastly, we further leverage machine learning-based classification algorithms, including Logistic Regression, K-Nearest Neighbors, and Random Forest to categorize the impacts on performance and security attributes. The performance of the proposed approach has high accuracy, ranging from $ 93.4 \\% $ to $ 95.9 \\% $, in detecting the fuzzing impacts. In addition, the proof of concept could identify and prioritize real-time vulnerabilities on 5G infrastructures and critical applications in various verticals.",
    "published_date": "2023-05-14",
    "pdf_link": "https://arxiv.org/pdf/2305.08226v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Wireless/Cellular Security",
      "subdomain": "5G Protocol/Stack Security",
      "specific_problem": "Automatic detection of vulnerabilities, unintended behaviors, and performance degradation in 5G stacks from fuzzing-generated run-time log profiling",
      "attack_types": [
        "Fuzzing-induced anomalies",
        "RRC connection failure",
        "Denial of Service via increased latency/performance degradation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Sentence-BERT (BERT-based sentence embeddings)",
        "novel_contribution": "Use of sentence-BERT to embed semi-structured 5G run-time LogInfo and compute time-weighted/periodic center-distance features for vulnerability detection"
      },
      {
        "type": "primary",
        "category": "Dimensionality Reduction",
        "specific": "t-SNE",
        "novel_contribution": "Applied to sentence embeddings to obtain 2D coordinates used to compute per-second center distances as features"
      },
      {
        "type": "primary",
        "category": "Linear Model",
        "specific": "Logistic Regression",
        "novel_contribution": "Used as one of the classifiers for binary detection of fuzzing impacts"
      },
      {
        "type": "primary",
        "category": "Instance-based",
        "specific": "K-Nearest Neighbors",
        "novel_contribution": "Used as one of the classifiers for binary detection of fuzzing impacts"
      },
      {
        "type": "primary",
        "category": "Ensemble (Tree-based)",
        "specific": "Random Forest",
        "novel_contribution": "Used as one of the classifiers for binary detection of fuzzing impacts"
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "srsRAN RRC fuzzing run-time log profiling",
        "type": "private",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "ROC curve",
      "AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can semantic representations of 5G run-time logs (LogInfo) produced during fuzzing be used to automatically detect vulnerabilities and unintended behaviors?",
        "Can the approach provide early detection (before full connection outcome) of fuzzing impacts on connectivity and performance?",
        "Can classification models categorize fuzzing impacts on performance and security attributes from log-derived features?"
      ],
      "gaps_identified": [
        "Scalability limits of fuzzing due to exponential search space and computational complexity",
        "High human effort/expertise required for formal verification/modeling of 5G protocols",
        "Fragility of keyword-based log search for labeling/outcome detection due to format/keyword changes",
        "Lack of systematic frameworks to discover implementation-level vulnerabilities from real 5G logs"
      ],
      "limitations": [
        "Proof-of-concept evaluated only on srsRAN and primarily the RRC (and tunneled NAS) protocols",
        "Ground truth relies on keyword search for rrcConnectionSetupComplete, which is acknowledged as fragile",
        "No public dataset or code; limited details on dataset size and collection diversity",
        "Focuses on binary success/fail and coarse latency; no detailed mapping from fuzzing types to specific vulnerability classes yet",
        "No comparative evaluation against existing log-based or protocol fuzzing detection baselines"
      ],
      "future_work": [
        "Further analyze and model the relationship between fuzzing types and induced delay/performance degradation",
        "Extend beyond RRC to broader 5G stack components and cross-platform validation",
        "Refine categorization of vulnerability types and prioritize real-time vulnerabilities in diverse verticals"
      ],
      "motivation": "Enable scalable, automated detection of 5G software stack vulnerabilities and unintended behaviors without heavy reliance on manual formal modeling, by leveraging NLP of run-time logs from fuzzing.",
      "potential_research_ideas": [
        "Build a publicly available, labeled corpus of 5G stack logs under diverse fuzzing scenarios for benchmarking",
        "Develop end-to-end temporal deep models (e.g., sequence Transformers) operating on log events and timestamps to replace t-SNE + center-distance heuristics",
        "Multi-task learning to jointly predict connection outcome, latency distribution, and vulnerability category",
        "Online/streaming detection with early-warning objectives optimized for minimal time-to-detect",
        "Cross-layer graph modeling of 5G stack interactions with GNNs for richer anomaly/vulnerability inference",
        "Self-supervised/contrastive pretraining on large unlabeled 5G logs to improve robustness and generalization",
        "Integrate structured log parsing (e.g., Drain/LogPai) with semantic embeddings for hybrid feature sets",
        "Active learning and weak supervision to reduce labeling burden and adapt to new log formats/protocol updates"
      ],
      "architectural_improvement_recommendations": [
        "Replace t-SNE with trainable dimensionality reduction (e.g., supervised metric learning or autoencoders/UMAP) to scale and preserve class-relevant structure",
        "Model temporal dynamics explicitly using Transformer/LSTM over sequences of log events with time gaps (time-aware attention) instead of per-second center distance",
        "Use log template mining to normalize logs and aggregate event templates before embedding, reducing noise and format variance",
        "Incorporate cost-sensitive and early-exit classifiers optimizing early detection under latency constraints",
        "Adopt end-to-end differentiable pipelines from raw logs to predictions, enabling joint optimization and ablation of components",
        "Add uncertainty estimation and conformal prediction to support risk-aware prioritization of suspected vulnerabilities"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "scikit-learn"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "srsRAN-based 5G RAN/core emulation testbed with fuzzed RRC/NAS messages",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Access to comprehensive run-time logs across layers and standardized logging formats",
        "Variability in log levels and formats across vendors/platforms",
        "Labeling and ground-truth derivation without fragile keyword dependence",
        "Scalability of t-SNE and embedding computation on large-scale, real-time logs",
        "Integration with CI/CD and on-prem 5G edge environments for online monitoring"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Design and implementation of an NLP-based LogInfo vulnerability detection framework for 5G fuzz testing",
      "Use of sentence-BERT to embed log messages and computation of weighted periodic center-distance features over timestamps",
      "Demonstrated high detection accuracy “ranging from 93.4% to 95.9%” on srsRAN RRC fuzzing logs",
      "Early detection insight: main discriminative window between 10s and 17s; high accuracy achievable by 10s",
      "Proof-of-concept indicating potential to identify and prioritize real-time vulnerabilities and unintended behaviors across 5G stacks"
    ]
  },
  {
    "arxiv_id": "2306.03707v1",
    "title": "Effective Intrusion Detection in Highly Imbalanced IoT Networks with Lightweight S2CGAN-IDS",
    "authors": "Caihong Wang; Du Xu; Zonghang Li; Dusit Niyato",
    "abstract": "Since the advent of the Internet of Things (IoT), exchanging vast amounts of information has increased the number of security threats in networks. As a result, intrusion detection based on deep learning (DL) has been developed to achieve high throughput and high precision. Unlike general deep learning-based scenarios, IoT networks contain benign traffic far more than abnormal traffic, with some rare attacks. However, most existing studies have been focused on sacrificing the detection rate of the majority class in order to improve the detection rate of the minority class in class-imbalanced IoT networks. Although this way can reduce the false negative rate of minority classes, it both wastes resources and reduces the credibility of the intrusion detection systems. To address this issue, we propose a lightweight framework named S2CGAN-IDS. The proposed framework leverages the distribution characteristics of network traffic to expand the number of minority categories in both data space and feature space, resulting in a substantial increase in the detection rate of minority categories while simultaneously ensuring the detection precision of majority categories. To reduce the impact of sparsity on the experiments, the CICIDS2017 numeric dataset is utilized to demonstrate the effectiveness of the proposed method. The experimental results indicate that our proposed approach outperforms the superior method in both Precision and Recall, particularly with a 10.2% improvement in the F1-score.",
    "published_date": "2023-06-06",
    "pdf_link": "https://arxiv.org/pdf/2306.03707v1",
    "paper_types": [
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Class-imbalanced intrusion detection in IoT network traffic while maintaining majority-class precision",
      "attack_types": [
        "DoS/DDoS",
        "PortScan",
        "Brute Force (FTP-Patator, SSH-Patator)",
        "Web Attacks (XSS, SQL Injection, Brute Force)",
        "Bot",
        "Infiltration",
        "Heartbleed"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GAN",
        "specific": "Conditional GAN (CGAN) conditioned with Siamese Autoencoder features (SCGAN)",
        "novel_contribution": "Uses Siamese autoencoder-derived difference features to condition CGAN and accelerate convergence; applies discriminator-based filtering to remove low-quality synthetic samples; targeted to generate scarce-level classes."
      },
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": "Siamese Autoencoder Network (SAN)",
        "novel_contribution": "Combines Siamese networks and autoencoders to extract differential features that preserve class differences and speed up adversarial training."
      },
      {
        "type": "primary",
        "category": "Oversampling",
        "specific": "Synthetic k Neighbors (SKN)",
        "novel_contribution": "Feature-space oversampling method for extremely rare classes using KNN-based interpolation to synthesize new samples."
      },
      {
        "type": "primary",
        "category": "DNN",
        "specific": "Deep Neural Network classifier (details not specified)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Generative Adversarial Learning"
    ],
    "datasets": [
      {
        "name": "CICIDS2017 (numeric subset)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Precision",
      "Recall",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to improve the detection rate of minority classes in highly imbalanced IoT networks without sacrificing the precision of majority classes?",
        "Can combining data-space and feature-space augmentation targeted to category sparsity levels (scarce vs. rare) improve IDS performance?",
        "Does conditioning GANs with Siamese autoencoder-derived difference features accelerate convergence and improve synthetic data quality for scarce classes?"
      ],
      "gaps_identified": [
        "Most existing studies improve minority-class detection at the cost of decreasing precision for majority classes, which wastes resources and reduces IDS credibility.",
        "Purely data-space augmentation is ineffective for extremely rare classes with very few samples; purely feature-space augmentation may produce samples too similar to originals for scarce classes.",
        "IoT attack frequency distributions are highly imbalanced with step-wise sparsity patterns not adequately addressed by one-size-fits-all augmentation."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Enhance detection of rare and scarce attack categories in IoT networks while maintaining majority-class precision by leveraging traffic distribution characteristics and tailored augmentation.",
      "potential_research_ideas": [
        "Extend S2CGAN-IDS to streaming/online settings to handle non-stationarity and concept drift in IoT networks.",
        "Evaluate and adapt the framework across additional modern IoT/industrial datasets and real traffic to assess generalization.",
        "Replace or complement SCGAN with class-conditional diffusion models for tabular data to improve sample fidelity and mode coverage.",
        "Incorporate cost-sensitive learning or focal/curriculum losses in the classifier to complement data augmentation.",
        "Automate per-class augmentation policy selection (e.g., meta-learning which classes use data-space vs. feature-space synthesis and how much to generate).",
        "Combine the approach with open-set/novelty detection to handle unseen attacks in IoT environments.",
        "Investigate uncertainty estimation and calibration to maintain reliability when augmenting rare classes."
      ],
      "architectural_improvement_recommendations": [
        "Use stabilized GAN objectives (e.g., WGAN-GP, R1-regularized hinge loss) and spectral normalization to further improve SCGAN stability.",
        "Adopt tabular-focused conditional generators (e.g., CTGAN/TVAE) for categorical/continuous feature handling if present.",
        "Add contrastive representation learning in SAN to better separate classes and strengthen conditioning signals.",
        "Incorporate class-balanced or focal loss, hard example mining, and threshold calibration in the classifier to complement augmentation.",
        "Ensemble multiple lightweight classifiers to improve robustness without large computational overhead.",
        "Include a learned quality filter (e.g., density/one-class classifier) alongside discriminator-based filtering to remove out-of-distribution synthetic samples."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A lightweight S2CGAN-IDS framework addressing class imbalance by improving minority-class detection while maintaining majority-class precision.",
      "An innovative feature extraction method combining Siamese networks and autoencoders to preserve class differences and significantly accelerate GAN convergence.",
      "A novel SCGAN data augmentation technique for categories with similar distribution profiles, combining Siamese networks and autoencoders to accelerate convergence.",
      "A highly efficient feature-space data synthesis method, Synthetic k Neighbors (SKN), for extremely rare classes."
    ]
  },
  {
    "arxiv_id": "2306.07993v1",
    "title": "Trustworthy Artificial Intelligence Framework for Proactive Detection and Risk Explanation of Cyber Attacks in Smart Grid",
    "authors": "Md. Shirajum Munir; Sachin Shetty; Danda B. Rawat",
    "abstract": "The rapid growth of distributed energy resources (DERs), such as renewable energy sources, generators, consumers, and prosumers in the smart grid infrastructure, poses significant cybersecurity and trust challenges to the grid controller. Consequently, it is crucial to identify adversarial tactics and measure the strength of the attacker's DER. To enable a trustworthy smart grid controller, this work investigates a trustworthy artificial intelligence (AI) mechanism for proactive identification and explanation of the cyber risk caused by the control/status message of DERs. Thus, proposing and developing a trustworthy AI framework to facilitate the deployment of any AI algorithms for detecting potential cyber threats and analyzing root causes based on Shapley value interpretation while dynamically quantifying the risk of an attack based on Ward's minimum variance formula. The experiment with a state-of-the-art dataset establishes the proposed framework as a trustworthy AI by fulfilling the capabilities of reliability, fairness, explainability, transparency, reproducibility, and accountability.",
    "published_date": "2023-06-12",
    "pdf_link": "https://arxiv.org/pdf/2306.07993v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Critical Infrastructure Security",
      "subdomain": "Smart Grid / SCADA Security",
      "specific_problem": "Proactive detection and root-cause explanation of cyber attacks in DER control/status messages with dynamic risk quantification",
      "attack_types": [
        "port scanner",
        "address scan",
        "device identification",
        "aggressive mode",
        "exploit"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Framework",
        "specific": "Trustworthy AI pipeline combining supervised detection, SHAP explanations, and Ward’s variance-based risk clustering",
        "novel_contribution": "Designs a deployable framework that supports any AI model for detection, provides root-cause via Shapley value interpretation, and quantifies attack risk with Ward’s minimum variance"
      },
      {
        "type": "primary",
        "category": "Explainability",
        "specific": "SHAP (Shapley Additive Explanations)",
        "novel_contribution": "Uses Shapley value coefficients to attribute feature contributions for each decision to ensure transparency, fairness, accountability"
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "Agglomerative clustering with Ward linkage (Ward’s minimum variance)",
        "novel_contribution": "Quantifies dynamic risk severity when attack subtypes are not labeled by computing inter-cluster variance per Ward’s formula"
      },
      {
        "type": "baseline",
        "category": "Ensemble Trees",
        "specific": "Extra Trees Regressor",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble Trees",
        "specific": "Random Forest Regressor",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble Boosting",
        "specific": "Gradient Boosting Regressor",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble Boosting",
        "specific": "AdaBoost Regressor",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Model",
        "specific": "Linear Regression",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "SCADA WUSTL-IIOT-2018",
        "type": "public",
        "domain": "ics_scada_network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Extra Trees Regressor",
        "paper_reference": null,
        "metric": "MSE (testing)",
        "their_result": "0.0015 (minimum error rate achieved by Extra Tree model)",
        "baseline_result": null
      },
      {
        "method_name": "All tested models (Extra Trees, Random Forest, Gradient Boosting, AdaBoost, Linear Regression)",
        "paper_reference": null,
        "metric": "True Positive (TP) rate",
        "their_result": "1.0",
        "baseline_result": null
      },
      {
        "method_name": "All tested models (Extra Trees, Random Forest, Gradient Boosting, AdaBoost, Linear Regression)",
        "paper_reference": null,
        "metric": "False Positive (FP) rate",
        "their_result": "0.003",
        "baseline_result": null
      },
      {
        "method_name": "Random Forest Regressor",
        "paper_reference": null,
        "metric": "R^2 (training/testing)",
        "their_result": "High R^2 (coefficient of determination), exact values not reported",
        "baseline_result": null
      },
      {
        "method_name": "Gradient Boosting Regressor",
        "paper_reference": null,
        "metric": "R^2 (training/testing)",
        "their_result": "High R^2 (coefficient of determination), exact values not reported",
        "baseline_result": null
      },
      {
        "method_name": "AdaBoost Regressor",
        "paper_reference": null,
        "metric": "R^2 (training/testing)",
        "their_result": "High R^2 (coefficient of determination), exact values not reported",
        "baseline_result": null
      },
      {
        "method_name": "Linear Regression",
        "paper_reference": null,
        "metric": "R^2 (training/testing)",
        "their_result": "High R^2 (coefficient of determination), exact values not reported",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "True Negative (TN)",
      "False Positive (FP)",
      "False Negative (FN)",
      "True Positive (TP)",
      "R2",
      "Mean Squared Error (MSE)",
      "Mean Absolute Error (MAE)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to proactively detect the potential cyber threat in a smart grid environment, where millions of DERs are connected and controlled by the smart grid controller?",
        "In order to guarantee a secure power transaction, how can the root cause of a possible cyber attack be identified in a smart grid controller?",
        "When there are no apparent indicators to differentiate among types of attacks, how can the grid controller distinguish between the various attack types and measure the risk?"
      ],
      "gaps_identified": [
        "Prior works do not investigate root cause analysis of a particular cyber-attack nor quantify potential risk when there are no apparent indicators to differentiate among types of attacks.",
        "Existing approaches insufficiently address explainability, reliability, fairness, transparency, and accountability in cyber-attack detection for smart grids with heterogeneous DERs."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Enable trustworthy smart grid control by detecting potential cyber threats from DER messages, explaining root causes, and quantifying risk to support secure power transactions with reliability, fairness, transparency, reproducibility, and accountability.",
      "potential_research_ideas": [
        "Extend the framework to multi-modal CPS data (e.g., PMU/synchrophasor measurements, host logs) for richer context in detection and risk assessment.",
        "Develop multi-class and hierarchical classifiers to directly predict attack subtypes and severity levels, using semi-supervised learning when labels are sparse.",
        "Incorporate temporal sequence modeling (e.g., LSTM/Transformer/Temporal CNN) over message sessions to capture evolving attack behaviors.",
        "Integrate uncertainty quantification and calibration (e.g., Bayesian ensembles, MC Dropout) to provide confidence intervals alongside SHAP explanations.",
        "Study adversarial robustness of both detection and explanations; design defenses such as adversarial training and certified robustness for tree ensembles.",
        "Leverage graph-based learning (GNNs) over DER-communication topologies to model inter-DER dependencies in detection and risk propagation.",
        "Combine causal inference with SHAP (e.g., causal SHAP, counterfactual explanations) to improve faithfulness of root-cause analysis.",
        "Calibrate risk clustering with domain priors and cost-sensitive thresholds to align severity groups with operational risk tolerance.",
        "Online/continual learning to handle DER churn and concept drift while preserving explanation stability.",
        "Close the loop with automated mitigation policies (e.g., safe RL) guided by explanation-aware risk scores."
      ],
      "architectural_improvement_recommendations": [
        "Use TreeSHAP with calibrated probabilistic outputs (e.g., calibrated Gradient Boosting/Random Forest) instead of generic regression for clearer decision thresholds and uncertainty.",
        "Adopt sequence models (Temporal CNN/LSTM/Transformer) on time-windowed features to capture temporal dependencies in DER communications.",
        "Introduce ensembling and stacking (e.g., blending Extra Trees, Gradient Boosting, and calibrated linear models) with cross-validated model selection.",
        "Integrate drift detection and adaptive retraining; maintain an explanation stability constraint to avoid large SHAP fluctuations across retrains.",
        "Employ feature engineering and automated selection (e.g., BorutaSHAP) to refine the six raw features and explore higher-order interactions.",
        "Use SHAP interaction values and global summary plots to capture pairwise effects (e.g., SrcBytes × Sport) systematically.",
        "Accelerate explainability via approximation (e.g., sampling coalitions, model-specific TreeSHAP) and cache explanations for frequent DERs.",
        "Enhance clustering by evaluating different distance metrics and linkage criteria; validate cluster quality (silhouette, Davies–Bouldin) and map clusters to risk tiers.",
        "Add calibration and decision-theoretic thresholds to convert regression outputs to binary/multi-tier alarms with controllable FP/FN trade-offs.",
        "Harden pipeline security and data integrity with cryptographic provenance and anomaly-tolerant preprocessing to reduce explanation skew from poisoned inputs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Python",
        "scikit-learn",
        "SHAP"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Simulation with SCADA WUSTL-IIOT-2018 dataset; smart grid controller setting",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Operating at scale with millions of DERs and dynamic message patterns",
        "Lack of labeled indicators to differentiate attack subtypes necessitates unsupervised severity characterization",
        "Ensuring fairness, transparency, and accountability across heterogeneous DERs",
        "Computational complexity could be high with many features and DERs (O(2^{|D|}×|M| + |X|^2 log|X|))"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": true
    },
    "contributions": [
      "Designs a system model of a trustworthy smart grid controller and formulates a decision problem to detect potential cyber threats and analyze root causes via feature contributions.",
      "Proposes a trustworthy AI framework enabling deployment of AI algorithms for detection, Shapley value-based root-cause analysis, and dynamic risk quantification using Ward’s minimum variance.",
      "Implements the framework in Python and evaluates it on the SCADA WUSTL-IIOT-2018 dataset with ensemble ML models and SHAP.",
      "Demonstrates reliability (e.g., TP rate 1.0, FP rate 0.003; Extra Tree testing MSE ≈ 0.0015) and supports fairness, transparency, reproducibility, and explainability through feature attribution and risk clustering."
    ]
  },
  {
    "arxiv_id": "2306.04859v2",
    "title": "Island-based Random Dynamic Voltage Scaling vs ML-Enhanced Power Side-Channel Attacks",
    "authors": "Dake Chen; Christine Goins; Maxwell Waugaman; Georgios D. Dimou; Peter A. Beerel",
    "abstract": "In this paper, we describe and analyze an island-based random dynamic voltage scaling (iRDVS) approach to thwart power side-channel attacks. We first analyze the impact of the number of independent voltage islands on the resulting signal-to-noise ratio and trace misalignment. As part of our analysis of misalignment, we propose a novel unsupervised machine learning (ML) based attack that is effective on systems with three or fewer independent voltages. Our results show that iRDVS with four voltage islands, however, cannot be broken with 200k encryption traces, suggesting that iRDVS can be effective. We finish the talk by describing an iRDVS test chip in a 12nm FinFet process that incorporates three variants of an AES-256 accelerator, all originating from the same RTL. This included a synchronous core, an asynchronous core with no protection, and a core employing the iRDVS technique using asynchronous logic. Lab measurements from the chips indicated that both unprotected variants failed the test vector leakage assessment (TVLA) security metric test, while the iRDVS was proven secure in a variety of configurations.",
    "published_date": "2023-06-08",
    "pdf_link": "https://arxiv.org/pdf/2306.04859v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Side-Channel Analysis and Countermeasures",
      "specific_problem": "Power side-channel attack countermeasure using island-based random dynamic voltage scaling (iRDVS) and evaluation against ML-enhanced alignment/CPA attacks on AES",
      "attack_types": [
        "Correlation Power Analysis (CPA)",
        "Differential Power Analysis (DPA) (background)",
        "Elastic alignment (dynamic time warping) alignment attack",
        "K-means clustering-based alignment/attack"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "K-means",
        "novel_contribution": "Novelly applied unsupervised clustering of traces by voltage combinations to enable attacks on iRDVS; ranks subkeys per cluster and aggregates ranks across clusters"
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Northeastern University Sasebo-GII AES-128 power traces",
        "type": "public",
        "domain": "power_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Synthetic iRDVS traces (scaled/combined from NEU Sasebo-GII traces using Sakurai-Newton delay model)",
        "type": "synthetic",
        "domain": "power_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Elastic alignment (dynamic time warping + elastic averaging; fastdtw implementation)",
        "paper_reference": "Woudenberg et al. [21]; fastdtw [19]",
        "metric": "MTD, PGE",
        "their_result": "“MTD remains larger than 100k traces and the PGE increases from 49 to 148” after applying elastic alignment in a two-island setting with the attacked island fixed and the other randomized (two candidates).",
        "baseline_result": "Without elastic alignment, PGE was 49 (vs 148 after alignment); attack still unsuccessful (MTD > 100k)"
      },
      {
        "method_name": "Clustering attack (K-means) against iRDVS",
        "paper_reference": null,
        "metric": "MTD, PGE",
        "their_result": "“clustering-based attack is able to uncover keys in systems protected by one, two and three dynamic voltage islands but has limited benefit… with four or more islands.”",
        "baseline_result": "For iRDVS with four voltage islands: “cannot be broken with 200k encryption traces” (MTD > 200k)."
      }
    ],
    "performance_metrics_used": [
      "Minimum Traces to Disclosure (MTD)",
      "Partial Guessing Entropy (PGE)",
      "Test Vector Leakage Assessment (TVLA) t-score",
      "Correlation coefficient (Pearson)",
      "Signal-to-Noise Ratio (SNR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How does the number of independent voltage islands affect SNR and trace misalignment for side-channel resistance?",
        "Can unsupervised clustering of traces by voltage combinations enable effective attacks against iRDVS and up to what number of islands?",
        "What minimum number/configuration of independent voltages makes iRDVS robust (e.g., not breakable with 200k traces)?"
      ],
      "gaps_identified": [
        "Single-voltage DVS countermeasures are vulnerable once the random voltage is estimated and traces can be time/amplitude scaled.",
        "Existing elastic/time-warping alignment techniques degrade under multi-supply iRDVS due to increased inter-trace distance and added random noise.",
        "Limited exploration of multi-island random DVS (iRDVS) and its trade-offs vs number of islands in prior work."
      ],
      "limitations": [
        "Many evaluations use synthetic iRDVS traces generated from open-source AES traces; generalization to other implementations may vary.",
        "Clustering parameter K is chosen heuristically; optimal K selection remains open.",
        "Clustering-based attack shows limited benefit for four or more islands; upper bounds beyond 200k traces are not explored.",
        "Hardware measurements use TVLA for leakage; they do not demonstrate full key recovery on silicon.",
        "Assumes per-island on-chip DC/DC and TRNG entropy sources; practical overheads and design constraints are not fully quantified."
      ],
      "future_work": [
        "“Interesting future work includes using machine learning to guide the choice of K.”",
        "Explore optimal number and configuration of independent voltages and island partitioning under physical and logical constraints.",
        "Further hardware evaluation across more configurations and attack settings (e.g., >200k traces, different algorithms)."
      ],
      "motivation": "Power side-channel attacks threaten pervasive devices; single-island DVS can be defeated via voltage estimation and alignment. Multi-island random DVS (iRDVS) may thwart both amplitude and timing alignment while remaining practical.",
      "potential_research_ideas": [
        "Data-driven selection of the number of clusters K and automatic model selection (e.g., BIC/AIC with GMMs) for improved attack effectiveness or defense evaluation.",
        "Investigate advanced unsupervised or self-supervised representations (e.g., contrastive encodings) to cluster traces by voltage states more reliably and probe robustness thresholds.",
        "Design adaptive iRDVS controllers that modulate voltages based on real-time leakage metrics (online TVLA) to maintain security under varying workloads.",
        "Combine iRDVS with masking or current flattening to compose defenses and evaluate composability vs. performance overhead.",
        "Formal optimization of island partitioning (logic grouping) to minimize leakage correlation while respecting EDA/timing constraints.",
        "Study joint randomization of voltage and frequency/clocking (multi-dimensional desynchronization) and its effect on alignment attacks."
      ],
      "architectural_improvement_recommendations": [
        "Use ≥4 independent voltage islands for AES-like cores to exceed practical attack budgets (MTD > 200k) as indicated.",
        "Increase diversity and update rate of per-island voltage levels to further reduce alignment probability p and increase SNR in favor of defense.",
        "Implement asynchronous handshaking and balanced pipeline stage delays to avoid timing side channels when voltages vary.",
        "Share supplies across multiple islands judiciously to scale to larger circuits while maintaining minimal inter-island covariance.",
        "Integrate on-die TRNGs with verified entropy and ensure DC/DC converter response times support rapid randomization.",
        "Augment iRDVS with random frequency jittering or duty-cycle modulation to further frustrate alignment."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "fastdtw",
        "Python (custom scripts)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Silicon test chip (12nm FinFET) with three AES-256 accelerator variants (synchronous, asynchronous, asynchronous+iRDVS)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Design and integration of multiple on-chip DC/DC converters and per-island voltage domains",
        "Ensuring pipeline stage delays remain roughly equal to avoid timing side channels under random voltages",
        "Asynchronous channel design to handle variable stage delays",
        "Area/power overheads and physical partitioning constraints for many islands",
        "TRNG quality and accessibility considerations"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes island-based random dynamic voltage scaling (iRDVS) using multiple independent random voltages to thwart power side-channel attacks.",
      "Analytical SNR derivation and discussion showing how the number of independent voltages affects SNR and covariance among islands.",
      "Alignment analysis showing temporal desynchronization benefits from dynamic voltages and reduced alignment probability.",
      "Introduces a novel unsupervised K-means clustering-based attack to group traces by voltage combinations and aggregate subkey ranks.",
      "Simulation results indicating clustering can recover keys for 1–3 islands but iRDVS with four islands “cannot be broken with 200k encryption traces.”",
      "Hardware validation on a 12nm FinFET test chip with three AES-256 variants; TVLA indicates both unprotected variants leak while the iRDVS variant is secure across configurations."
    ]
  },
  {
    "arxiv_id": "2306.04920v1",
    "title": "Flow-based Network Intrusion Detection Based on BERT Masked Language Model",
    "authors": "Loc Gia Nguyen; Kohei Watabe",
    "abstract": "A Network Intrusion Detection System (NIDS) is an important tool that identifies potential threats to a network. Recently, different flow-based NIDS designs utilizing Machine Learning (ML) algorithms have been proposed as potential solutions to detect intrusions efficiently. However, conventional ML-based classifiers have not seen widespread adoption in the real-world due to their poor domain adaptation capability. In this research, our goal is to explore the possibility of improve the domain adaptation capability of NIDS. Our proposal employs Natural Language Processing (NLP) techniques and Bidirectional Encoder Representations from Transformers (BERT) framework. The proposed method achieved positive results when tested on data from different domains.",
    "published_date": "2023-06-08",
    "pdf_link": "https://arxiv.org/pdf/2306.04920v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Flow-based network intrusion detection with improved cross-domain (domain shift) adaptation using sequences of flows",
      "attack_types": [
        "dos",
        "portscan",
        "pingscan",
        "bruteforce",
        "scan"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT (Masked Language Model pretraining)",
        "novel_contribution": "Treat flows as words and sequences of flows as sentences; pretrain BERT with MLM on discretized flow-feature tokens and fine-tune for binary classification to leverage context across sequences for domain adaptation."
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": "Linear layer with softmax (2-class)",
        "novel_contribution": "Used as the classification head over BERT representations."
      },
      {
        "type": "baseline",
        "category": "Energy-based model",
        "specific": "Energy-based Flow Classifier (EFC) using Inverse Potts Model",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "KNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Naive Bayes",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised pretraining (MLM)",
      "Supervised",
      "Transfer Learning"
    ],
    "datasets": [
      {
        "name": "CIDDS-001 (large training split)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIDDS-001 (internal/OpenStack)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIDDS-001 (external server)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIDDS-002",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "EFC",
        "paper_reference": "Pontes et al., IEEE TNSM 2021",
        "metric": "Accuracy (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.941 (0.005)"
      },
      {
        "method_name": "EFC",
        "paper_reference": "Pontes et al., IEEE TNSM 2021",
        "metric": "F1 score (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.941 (0.004)"
      },
      {
        "method_name": "EFC",
        "paper_reference": "Pontes et al., IEEE TNSM 2021",
        "metric": "Accuracy (CIDDS-001 external)",
        "their_result": "0.895 (0.027)",
        "baseline_result": "0.747 (0.039)"
      },
      {
        "method_name": "EFC",
        "paper_reference": "Pontes et al., IEEE TNSM 2021",
        "metric": "F1 score (CIDDS-001 external)",
        "their_result": "0.904 (0.022)",
        "baseline_result": "0.796 (0.025)"
      },
      {
        "method_name": "EFC",
        "paper_reference": "Pontes et al., IEEE TNSM 2021",
        "metric": "Accuracy (CIDDS-002)",
        "their_result": "0.916 (0.045)",
        "baseline_result": "0.846 (0.046)"
      },
      {
        "method_name": "EFC",
        "paper_reference": "Pontes et al., IEEE TNSM 2021",
        "metric": "F1 score (CIDDS-002)",
        "their_result": "0.877 (0.072)",
        "baseline_result": "0.800 (0.070)"
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.996 (0.001)"
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.996 (0.001)"
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-001 external)",
        "their_result": "0.895 (0.027)",
        "baseline_result": "0.870 (0.028)"
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-001 external)",
        "their_result": "0.904 (0.022)",
        "baseline_result": "0.874 (0.024)"
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-002)",
        "their_result": "0.916 (0.045)",
        "baseline_result": "0.818 (0.061)"
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-002)",
        "their_result": "0.877 (0.072)",
        "baseline_result": "0.707 (0.106)"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.989 (0.002)"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.989 (0.003)"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-001 external)",
        "their_result": "0.895 (0.027)",
        "baseline_result": "0.839 (0.008)"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-001 external)",
        "their_result": "0.904 (0.022)",
        "baseline_result": "0.811 (0.011)"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-002)",
        "their_result": "0.916 (0.045)",
        "baseline_result": "0.818 (0.061)"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-002)",
        "their_result": "0.877 (0.072)",
        "baseline_result": "0.707 (0.106)"
      },
      {
        "method_name": "MLP (baseline)",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.992 (0.001)"
      },
      {
        "method_name": "MLP (baseline)",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.992 (0.001)"
      },
      {
        "method_name": "MLP (baseline)",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-001 external)",
        "their_result": "0.895 (0.027)",
        "baseline_result": "0.573 (0.009)"
      },
      {
        "method_name": "MLP (baseline)",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-001 external)",
        "their_result": "0.904 (0.022)",
        "baseline_result": "0.285 (0.023)"
      },
      {
        "method_name": "MLP (baseline)",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-002)",
        "their_result": "0.916 (0.045)",
        "baseline_result": "0.832 (0.059)"
      },
      {
        "method_name": "MLP (baseline)",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-002)",
        "their_result": "0.877 (0.072)",
        "baseline_result": "0.729 (0.108)"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.903 (0.002)"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.892 (0.002)"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-001 external)",
        "their_result": "0.895 (0.027)",
        "baseline_result": "0.500 (0.000)"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-001 external)",
        "their_result": "0.904 (0.022)",
        "baseline_result": "0.000 (0.000)"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-002)",
        "their_result": "0.916 (0.045)",
        "baseline_result": "0.499 (0.000)"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-002)",
        "their_result": "0.877 (0.072)",
        "baseline_result": "0.001 (0.000)"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.570 (0.015)"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-001 internal)",
        "their_result": "0.994 (0.002)",
        "baseline_result": "0.245 (0.047)"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-001 external)",
        "their_result": "0.895 (0.027)",
        "baseline_result": "0.738 (0.016)"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-001 external)",
        "their_result": "0.904 (0.022)",
        "baseline_result": "0.718 (0.021)"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "Accuracy (CIDDS-002)",
        "their_result": "0.916 (0.045)",
        "baseline_result": "0.513 (0.013)"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "F1 score (CIDDS-002)",
        "their_result": "0.877 (0.072)",
        "baseline_result": "0.090 (0.037)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1 score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can modeling sequences of flows (instead of single flows) with BERT improve NIDS domain adaptation across different deployment domains?",
        "Does preserving the natural distribution/order of flows within sequences materially impact performance?",
        "How does the proposed approach compare to EFC and common ML classifiers under domain shift (CIDDS-001 internal → CIDDS-001 external / CIDDS-002)?"
      ],
      "gaps_identified": [
        "Conventional ML-based flow classifiers adapt poorly to domain shift between training and deployment data.",
        "EFC, despite good adaptability, yields high false positives when malicious and benign feature distributions overlap.",
        "Using singular flows as input limits the ability to model contextual relationships across flows.",
        "Limited evaluation on recent datasets; more extensive testing is needed."
      ],
      "limitations": [
        "Evaluation limited to CIDDS-001/002; authors note the need for testing on more recent datasets.",
        "Performance is sensitive to alterations of sequence distribution (e.g., balanced subsets harmed performance).",
        "Current approach relies on labeled data for fine-tuning.",
        "Operational deployment aspects (throughput, latency, memory) are not evaluated."
      ],
      "future_work": [
        "Investigate impact of flow sequence sampling (e.g., only benign flows; grouping flows from the same hosts).",
        "Reduce reliance on labeled data by modeling benign flow sequences and detecting anomalous representations from BERT (unsupervised/anomaly detection).",
        "More extensive testing on recent datasets to further assess domain adaptation."
      ],
      "motivation": "Improve the domain adaptation capability of flow-based NIDS by leveraging contextual information across sequences of flows via BERT.",
      "potential_research_ideas": [
        "Pretrain with network-native objectives: next-flow prediction, contrastive learning between hosts/sessions, or masked multi-feature prediction with temporal masking.",
        "Domain-adaptive pretraining using adversarial domain adaptation or CORAL/MMD losses to explicitly align representations across domains.",
        "Continual learning for evolving traffic/attack patterns (regularization-based or replay buffers on benign sequences).",
        "Hierarchical sequence modeling (packet→flow→session→host) to capture multi-scale context.",
        "Incorporate temporal and positional encodings reflecting inter-arrival times and session boundaries.",
        "Self-labeling and pseudo-labeling pipelines using high-confidence benign sequences to reduce labeled data needs.",
        "Hybrid detection: combine supervised head with an unsupervised energy/anomaly score on BERT embeddings to lower false positives under shift.",
        "Calibrate outputs and thresholding per domain using small unlabeled adaptation sets; apply test-time adaptation."
      ],
      "architectural_improvement_recommendations": [
        "Augment BERT with time-aware/relative positional encodings and attention biases for temporal proximity.",
        "Multi-feature tokenization improvements: learn per-feature embeddings with feature-wise attention instead of simple concatenation.",
        "Sequence segmentation by host/session with sliding windows; add global pooling (CLS + attentive pooling) for robust per-flow context.",
        "Introduce domain-adversarial head (DANN) during fine-tuning to encourage domain-invariant representations.",
        "Use class-imbalance techniques (focal loss, cost-sensitive training) and mixup/cutmix in embedding space to improve robustness.",
        "Leverage larger pretrained transformer backbones (e.g., RoBERTa-style MLM without NSP) and longer context windows with efficient attention.",
        "Add uncertainty estimation (MC dropout or deep ensembles) to manage domain shift and threshold alerts."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Handling domain shift between training and deployment data.",
        "Maintaining natural sequence order/distribution in streaming settings for consistent performance.",
        "Current reliance on labeled data for fine-tuning; labeling costs in practice."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a flow-sequence-based NIDS using BERT masked language modeling to capture context across flows, addressing domain adaptation limitations of single-flow classifiers.",
      "Implements discretization of six flow features and encodes them into embeddings processed by BERT, followed by an MLP head for binary classification.",
      "Demonstrates improved cross-domain performance compared to EFC and several ML baselines on CIDDS-001/002, e.g., Accuracy/F1 on CIDDS-001 external: 0.895/0.904 vs EFC 0.747/0.796.",
      "Observes that altering sequence distribution (balanced subsets) degrades performance, indicating the model learns sequence distribution characteristics."
    ]
  },
  {
    "arxiv_id": "2305.18607v2",
    "title": "How Effective Are Neural Networks for Fixing Security Vulnerabilities",
    "authors": "Yi Wu; Nan Jiang; Hung Viet Pham; Thibaud Lutellier; Jordan Davis; Lin Tan; Petr Babkin; Sameena Shah",
    "abstract": "Security vulnerability repair is a difficult task that is in dire need of automation. Two groups of techniques have shown promise: (1) large code language models (LLMs) that have been pre-trained on source code for tasks such as code completion, and (2) automated program repair (APR) techniques that use deep learning (DL) models to automatically fix software bugs.   This paper is the first to study and compare Java vulnerability repair capabilities of LLMs and DL-based APR models. The contributions include that we (1) apply and evaluate five LLMs (Codex, CodeGen, CodeT5, PLBART and InCoder), four fine-tuned LLMs, and four DL-based APR techniques on two real-world Java vulnerability benchmarks (Vul4J and VJBench), (2) design code transformations to address the training and test data overlapping threat to Codex, (3) create a new Java vulnerability repair benchmark VJBench, and its transformed version VJBench-trans and (4) evaluate LLMs and APR techniques on the transformed vulnerabilities in VJBench-trans.   Our findings include that (1) existing LLMs and APR models fix very few Java vulnerabilities. Codex fixes 10.2 (20.4%), the most number of vulnerabilities. (2) Fine-tuning with general APR data improves LLMs' vulnerability-fixing capabilities. (3) Our new VJBench reveals that LLMs and APR models fail to fix many Common Weakness Enumeration (CWE) types, such as CWE-325 Missing cryptographic step and CWE-444 HTTP request smuggling. (4) Codex still fixes 8.3 transformed vulnerabilities, outperforming all the other LLMs and APR models on transformed vulnerabilities. The results call for innovations to enhance automated Java vulnerability repair such as creating larger vulnerability repair training data, tuning LLMs with such data, and applying code simplification transformation to facilitate vulnerability repair.",
    "published_date": "2023-05-29",
    "pdf_link": "https://arxiv.org/pdf/2305.18607v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "benchmark"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Management and Mitigation",
      "specific_problem": "Automated repair of Java security vulnerabilities using LLMs and deep learning-based automated program repair (APR)",
      "attack_types": [
        "CWE-20 Improper Input Validation",
        "CWE-22 Path Traversal",
        "CWE-74 Injection",
        "CWE-79 Cross-site Scripting",
        "CWE-172 Encoding Error",
        "CWE-200 Exposure of Sensitive Information",
        "CWE-325 Missing cryptographic step",
        "CWE-347 Improper Verification of Cryptographic Signature",
        "CWE-444 HTTP Request Smuggling",
        "CWE-611 XML External Entity Reference",
        "CWE-668 Exposure of Resource to Wrong Sphere",
        "CWE-1295 Debug messages revealing unnecessary information",
        "CWE-78 OS Command Injection",
        "CWE-502 Deserialization of Untrusted Data",
        "CWE-552 Files or Directories Accessible to External Parties",
        "CWE-285 Improper Authorization",
        "CWE-310 Cryptographic Issues",
        "CWE-754 Improper Check for Unusual or Exceptional Conditions",
        "CWE-400 Uncontrolled Resource Consumption",
        "CWE-184 Incomplete List of Disallowed Inputs",
        "CWE-863 Incorrect Authorization"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Transformer (decoder-only)",
        "specific": "Codex (GPT-3-based, davinci-002, 12B)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (encoder-decoder)",
        "specific": "CodeT5 (770M)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (decoder-only)",
        "specific": "CodeGen (6B)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (encoder-decoder)",
        "specific": "PLBART (400M)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (decoder-only, masked span pretraining)",
        "specific": "InCoder (6B)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Fine-tuned LLM (supervised on APR bug-fix pairs)",
        "specific": "Fine-tuned InCoder (APR data)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Fine-tuned LLM (supervised on APR bug-fix pairs)",
        "specific": "Fine-tuned CodeT5 (APR data)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Fine-tuned LLM (supervised on APR bug-fix pairs)",
        "specific": "Fine-tuned PLBART (APR data)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Fine-tuned LLM (supervised on APR bug-fix pairs)",
        "specific": "Fine-tuned CodeGen (APR data)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "DL-based APR (seq2seq/encoder-decoder)",
        "specific": "CURE",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "DL-based APR (seq2seq/encoder-decoder)",
        "specific": "Recoder",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "DL-based APR (learning-based APR)",
        "specific": "RewardRepair",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "DL-based APR",
        "specific": "KNOD",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised pretraining",
      "Supervised fine-tuning",
      "Supervised learning"
    ],
    "datasets": [
      {
        "name": "Vul4J",
        "type": "public",
        "domain": "source_code_vulnerabilities (Java)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VJBench",
        "type": "public",
        "domain": "source_code_vulnerabilities (Java)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "VJBench-trans",
        "type": "synthetic",
        "domain": "source_code_vulnerabilities (Java, transformed)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "General APR training data (143,666 Java bug-fix pairs from GitHub [76], used for fine-tuning)",
        "type": "public",
        "domain": "source_code_bug_fix_pairs (Java)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Codex (davinci-002)",
        "paper_reference": "[17]",
        "metric": "number of vulnerabilities fixed (out of 50) and fix rate",
        "their_result": "10.2 fixed (20.4%) on average",
        "baseline_result": null
      },
      {
        "method_name": "Codex (davinci-002)",
        "paper_reference": "[17]",
        "metric": "compilation rate",
        "their_result": "79.7%",
        "baseline_result": null
      },
      {
        "method_name": "Codex (davinci-002) on transformed set",
        "paper_reference": "[17]",
        "metric": "number of transformed vulnerabilities fixed (VJBench-trans)",
        "their_result": "8.7",
        "baseline_result": null
      },
      {
        "method_name": "Fine-tuned InCoder",
        "paper_reference": "[28],[38]",
        "metric": "number of vulnerabilities fixed (out of 50)",
        "their_result": "9",
        "baseline_result": null
      },
      {
        "method_name": "CodeT5",
        "paper_reference": "[73]",
        "metric": "compilation rate",
        "their_result": "6.4%",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "number_of_vulnerabilities_fixed",
      "fix_rate_percent",
      "compilation_rate",
      "passes_existing_test_suite (test-based correctness)",
      "CWE_coverage"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How effective are existing LLMs and DL-based APR techniques at fixing real-world Java security vulnerabilities?",
        "Does fine-tuning LLMs with general APR (non-security-specific) bug-fix data improve vulnerability fixing capability?",
        "How do LLMs compare to DL-based APR given differences in data scale and data format (pretraining on raw code vs supervised bug-fix pairs)?",
        "Can code transformations mitigate training–test overlap risks when evaluating black-box LLMs like Codex, and how do such transformations affect fix rates?"
      ],
      "gaps_identified": [
        "Lack of comprehensive Java vulnerability repair benchmarks; prior Vul4J has limited CWE coverage and few single-hunk cases for learning-based APR.",
        "Training–test data contamination risk for black-box LLMs trained on public GitHub code.",
        "Existing LLMs and APR models fix very few Java vulnerabilities overall.",
        "Many CWE types remain unfixed by all evaluated models (e.g., CWE-325, CWE-444, CWE-172, CWE-668, CWE-1295).",
        "Low compilation rates for many models indicate insufficient syntax-domain knowledge.",
        "Scarcity of large, high-quality vulnerability-specific training data for fine-tuning."
      ],
      "limitations": [
        "Evaluation constrained to single-hunk vulnerabilities due to APR tools’ capabilities; multi-hunk vulnerabilities largely excluded from quantitative evaluation.",
        "Codex training data is unreleased, causing unavoidable uncertainty about training–test overlap despite code transformations.",
        "Potential effect of code transformations on task difficulty; some transformations can make vulnerabilities easier or harder to fix.",
        "Model input length constraints required truncation around buggy lines for some models.",
        "Hardware limitations prevented evaluation of larger CodeGen (16B) models."
      ],
      "future_work": [
        "Create larger, high-quality vulnerability repair training datasets and fine-tune LLMs with such data.",
        "Apply code simplification transformations to facilitate vulnerability repair.",
        "Develop innovations to enhance automated Java vulnerability repair beyond current LLM and APR capabilities.",
        "Broaden support to more CWE types and multi-hunk, multi-file patches."
      ],
      "motivation": "Accelerate and improve the repair of Java security vulnerabilities by assessing the feasibility and limits of LLMs and DL-based APR compared to the long current time-to-fix in practice.",
      "potential_research_ideas": [
        "Construct a large-scale, curated Java vulnerability repair dataset with diverse CWE coverage and aligned bug–fix pairs for targeted fine-tuning.",
        "Design CWE-aware prompts and conditioning (e.g., include CWE ID, vulnerability description, and security patterns) to guide LLM patch generation.",
        "Integrate static analysis and symbolic checks into an LLM-in-the-loop repair framework for constraint-aware patch synthesis.",
        "Develop retrieval-augmented patching that retrieves similar historical patches and secure code snippets during decoding.",
        "Explore multi-hunk and multi-file repair with hierarchical or graph-based context modeling for large repositories.",
        "Use reinforcement learning from tests (compile–test feedback) or rejection sampling to improve syntactic validity and test-passing rates.",
        "Build contamination-resistant evaluation suites and automated transformation pipelines to regularly refresh benchmarks.",
        "Hybridize APR heuristics (edit patterns, templates) with LLM generation for reliability on common fix patterns.",
        "Investigate CWE-specific robustness testing via semantics-preserving transformations and evaluate brittleness to code style changes.",
        "Leverage constrained decoding (AST- or grammar-guided) and type-aware generation to reduce uncompilable patches."
      ],
      "architectural_improvement_recommendations": [
        "Adopt grammar/AST-constrained decoding and type-aware tokenization to reduce syntax errors and increase compilation rates.",
        "Incorporate retrieval-augmented generation with nearest-neighbor bug–fix pairs to inform patch proposals.",
        "Introduce CWE-aware control tokens or adapters during fine-tuning for vulnerability-type-specific specialization.",
        "Integrate compile-and-test feedback loops (toolformer-style) for iterative repair and validation during decoding.",
        "Use hierarchical context modeling to capture broader project context and support multi-hunk/multi-file repairs.",
        "Pretrain/fine-tune with contrastive objectives on vulnerable vs. fixed code to strengthen vulnerability pattern recognition.",
        "Combine LLM generation with APR edit pattern libraries and constraint solvers for safer, minimal patches."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Potential training–test overlap with black-box LLMs trained on public code.",
        "Low compilation rates for many models lead to unusable patches.",
        "Limited capability for multi-hunk/multi-file real-world fixes.",
        "Context length limits require truncation around buggy lines.",
        "Black-box API constraints (e.g., Codex) hinder full reproducibility and parameter control."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First comparative study of LLMs and DL-based APR techniques on Java vulnerability repair.",
      "Creation of VJBench (42 reproducible real-world Java vulnerabilities, 12 new CWE types) and VJBench-trans (150 transformed vulnerabilities).",
      "Design and application of code transformations (identifier renaming, code structure changes) to mitigate training–test overlap threats for LLMs.",
      "Comprehensive evaluation of five LLMs, four fine-tuned LLMs, and four APR techniques on Vul4J and VJBench, including transformed variants.",
      "Empirical findings: LLMs/APR fix few vulnerabilities overall; Codex achieves highest fix count and compilation rate; fine-tuning on general APR data improves LLM performance; many CWE types remain unfixed.",
      "Analysis of robustness under code transformations and implications for future research directions."
    ]
  },
  {
    "arxiv_id": "2305.09678v1",
    "title": "Anomaly Detection Dataset for Industrial Control Systems",
    "authors": "Alireza Dehlaghi-Ghadim; Mahshid Helali Moghadam; Ali Balador; Hans Hansson",
    "abstract": "Over the past few decades, Industrial Control Systems (ICSs) have been targeted by cyberattacks and are becoming increasingly vulnerable as more ICSs are connected to the internet. Using Machine Learning (ML) for Intrusion Detection Systems (IDS) is a promising approach for ICS cyber protection, but the lack of suitable datasets for evaluating ML algorithms is a challenge. Although there are a few commonly used datasets, they may not reflect realistic ICS network data, lack necessary features for effective anomaly detection, or be outdated. This paper presents the 'ICS-Flow' dataset, which offers network data and process state variables logs for supervised and unsupervised ML-based IDS assessment. The network data includes normal and anomalous network packets and flows captured from simulated ICS components and emulated networks. The anomalies were injected into the system through various attack techniques commonly used by hackers to modify network traffic and compromise ICSs. We also proposed open-source tools, `ICSFlowGenerator' for generating network flow parameters from Raw network packets. The final dataset comprises over 25,000,000 raw network packets, network flow records, and process variable logs. The paper describes the methodology used to collect and label the dataset and provides a detailed data analysis. Finally, we implement several ML models, including the decision tree, random forest, and artificial neural network to detect anomalies and attacks, demonstrating that our dataset can be used effectively for training intrusion detection ML models.",
    "published_date": "2023-05-11",
    "pdf_link": "https://arxiv.org/pdf/2305.09678v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Industrial Control Systems Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Anomaly and attack detection in ICS networks using ML; creation of a realistic evaluation dataset (ICS-Flow) with packets, flows, and process logs",
      "attack_types": [
        "Reconnaissance / Scan",
        "Denial of Service (DoS) / Distributed DoS (DDoS)",
        "Man-in-the-Middle (MitM) false data injection",
        "Replay"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble (Random Forest)",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Neural Network",
        "specific": "Artificial Neural Network (feedforward/MLP, unspecified)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "ICS-Flow",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.kaggle.com/datasets/alirezadehlaghi/icssim",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "DARPA 1998",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "KDD Cup '99",
        "type": "public",
        "domain": "network_traffic",
        "link": "http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": "http://www.unb.ca/cic/datasets/nsl.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Gas Pipeline and Water Tank ICS datasets (Morris et al.)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://research.unsw.edu.au/projects/unsw-nb15-dataset",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SWaT",
        "type": "public",
        "domain": "process_state_logs",
        "link": "https://itrust.sutd.edu.sg/itrust-labs_datasets/dataset_info/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/ids-2017.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Electra (railway ICS anomaly dataset)",
        "type": "public",
        "domain": "network_traffic",
        "link": "http://perception.inf.um.es/ICS-datasets/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "TON_IoT",
        "type": "public",
        "domain": "iot_telemetry",
        "link": "https://research.unsw.edu.au/projects/toniot-datasets",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Water Distribution Testbed (WDT)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Limited number of suitable datasets for ML-based anomaly detection in ICS; some based on unrealistic implementations.",
        "Only a small subset of datasets inject anomalies through cyberattacks relevant to intrusion detection.",
        "ICS testbeds often lack crucial details or implement components incorrectly, impacting anomaly detection accuracy.",
        "Some datasets are highly anonymized or outdated and may not reflect current market trends.",
        "Lack of labeled data; several ICS anomaly datasets are unlabeled, hindering supervised training.",
        "Network trace labeling often based on automatic generation of synthetic traces, removing details needed to distinguish malicious activity.",
        "Heterogeneity in logged data types (only process variables, only commands, or only packets), limiting dataset suitability.",
        "Difficult to transfer datasets across specialized IDS domains; customized datasets preferred.",
        "Existing ICS datasets often label individual packets; anomalies in ICS may span entire traffic patterns, necessitating flow-level perspective."
      ],
      "limitations": [
        "Use of automated HMIs may create uniform network traffic during regular operation; authors introduced randomization to mitigate."
      ],
      "future_work": [],
      "motivation": "Address the lack of realistic, well-labeled, and feature-rich ICS datasets for evaluating ML/DL-based intrusion and anomaly detection; provide a comprehensive dataset with packets, flows, process logs and realistic cyberattacks.",
      "potential_research_ideas": [
        "Develop multimodal IDS models that jointly learn from network flows and process state variables to improve detection and attribution.",
        "Explore unsupervised and self-supervised methods (e.g., contrastive, representation learning) for ICS anomaly detection using ICS-Flow.",
        "Temporal/sequence modeling of flows (e.g., TCNs, Transformers) to detect slow or stealthy attacks spanning multiple flows.",
        "Domain adaptation and transfer learning across ICS plants/testbeds to address dataset transferability challenges.",
        "Causal inference between network anomalies and process deviations for root-cause analysis in ICS incidents.",
        "Graph-based modeling of ICS components and communication (e.g., GNNs on ICS topology) to capture structural dependencies.",
        "Adversarial robustness studies for ML-based ICS IDS using ICS-Flow as seed data for attack simulation.",
        "Online/streaming detection with concept drift handling on flow features for real-time ICS monitoring.",
        "Automated attack taxonomy labeling at both packet and flow/session levels to support multi-granularity IDS training."
      ],
      "architectural_improvement_recommendations": [
        "Augment dataset with additional industrial protocols (e.g., DNP3, IEC 60870-5-104, S7, OPC UA) beyond Modbus-TCP.",
        "Include human-in-the-loop HMI behavior traces to better approximate operator actions and non-uniform traffic patterns.",
        "Provide standardized train/validation/test splits and cross-scenario splits (e.g., unseen attack types, unseen days) for benchmarking.",
        "Add richer timing features and sessionization (e.g., inter-arrival distributions, burst metrics) to the flow schema.",
        "Release code for baseline models with reproducible pipelines (feature extraction to evaluation) and hyperparameter configs.",
        "Incorporate more attack families (e.g., command injection variants, ARP spoofing, protocol fuzzing) and stealthier low-and-slow attacks.",
        "Provide synchronized high-resolution timestamps across packets, flows, and process logs to improve multimodal alignment."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "ICS control network (emulated testbed; switch-level packet capture)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Testing IDS on operational industrial systems is infeasible due to safety and availability risks.",
        "Scarcity of labeled ICS data for supervised training.",
        "High specialization of IDS and difficulty transferring datasets across domains.",
        "Existing datasets often anonymized or outdated, complicating deployment relevance."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces ICS-Flow: a publicly available dataset with over 25,000,000 raw packets, network flow records, and process variable logs for ICS IDS evaluation.",
      "Implements realistic cyberattacks (Reconnaissance/Scan, DDoS/DoS, MitM false data injection, Replay) on an emulated ICS bottle-filling factory.",
      "Proposes ICSFlowGenerator, an open-source tool to extract network flow features from raw packets.",
      "Provides multiple labeling strategies, including packet and flow-level labels aligned with attacks and anomalies.",
      "Includes a diverse set of 54 flow and general/TCP features, plus extended labeling features capturing ICS behavior.",
      "Releases a complete, non-anonymized dataset including flows, process state snapshots, attack logs, and ICS component logs.",
      "Demonstrates dataset utility by training and evaluating ML models (decision tree, random forest, artificial neural network) for anomaly/attack detection."
    ]
  },
  {
    "arxiv_id": "2305.09592v2",
    "title": "Trojan Playground: A Reinforcement Learning Framework for Hardware Trojan Insertion and Detection",
    "authors": "Amin Sarihi; Ahmad Patooghy; Peter Jamieson; Abdel-Hameed A. Badawy",
    "abstract": "Current Hardware Trojan (HT) detection techniques are mostly developed based on a limited set of HT benchmarks. Existing HT benchmark circuits are generated with multiple shortcomings, i.e., i) they are heavily biased by the designers' mindset when created, and ii) they are created through a one-dimensional lens, mainly the signal activity of nets. We introduce the first automated Reinforcement Learning (RL) HT insertion and detection framework to address these shortcomings. In the HT insertion phase, an RL agent explores the circuits and finds locations best for keeping inserted HTs hidden. On the defense side, we introduce a multi-criteria RL-based HT detector that generates test vectors to discover the existence of HTs. Using the proposed framework, one can explore the HT insertion and detection design spaces to break the limitations of human mindset and benchmark issues, ultimately leading toward the next generation of innovative detectors. We demonstrate the efficacy of our framework on ISCAS-85 benchmarks, provide the attack and detection success rates, and define a methodology for comparing our techniques.",
    "published_date": "2023-05-16",
    "pdf_link": "https://arxiv.org/pdf/2305.09592v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Hardware Trojan Insertion and Detection",
      "specific_problem": "Automated reinforcement learning-based hardware Trojan insertion and multi-criteria test-vector generation for detection on digital circuit netlists",
      "attack_types": [
        "Logic hardware Trojans (combinational trigger and XOR payload)",
        "Netlist-level HT insertion"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": null,
        "novel_contribution": "First automated RL framework that both inserts HTs (agent explores circuit graph, selects trigger/payload locations) and detects HTs via multi-criteria RL-based test-vector generation"
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": "Mentioned as prior ML detector using netlist features [8]; not used as their method"
      },
      {
        "type": "baseline",
        "category": "Graph Neural Network",
        "specific": null,
        "novel_contribution": "HW2VEC uses GNNs on design graphs [30]; cited as prior art"
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning"
    ],
    "datasets": [
      {
        "name": "ISCAS-85",
        "type": "public",
        "domain": "hardware_netlists",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Trust-Hub trust benchmarks",
        "type": "public",
        "domain": "hardware_netlists",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "TRIT benchmark set (Trust-Hub)",
        "type": "public",
        "domain": "hardware_netlists",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Trojan Playground HT-inserted ISCAS-85 benchmarks",
        "type": "synthetic",
        "domain": "hardware_netlists",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "MERO",
        "paper_reference": "[15]",
        "metric": "detection rate",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "TARMAC",
        "paper_reference": "[12]",
        "metric": "detection rate",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "TGRL",
        "paper_reference": "[2]",
        "metric": "detection rate",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "DETERRENT",
        "paper_reference": "[10]",
        "metric": "detection rate",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "HW2VEC",
        "paper_reference": "[30]",
        "metric": "detection rate",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "detection rate",
      "attack success rate",
      "confidence value metric"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can reinforcement learning automate hardware Trojan insertion to reduce human bias and expand the HT design space beyond rare-net signal activity heuristics?",
        "Can a multi-criteria RL-based detector generate effective test vectors to discover HTs inserted via diverse strategies?",
        "How should HT detectors be compared fairly across different insertion strategies (methodology based on a confidence value metric)?"
      ],
      "gaps_identified": [
        "Existing HT benchmarks are limited in size and variety, hampering the development of robust detectors and ML training.",
        "Benchmarks are biased by designers’ mindsets and often rely on one-dimensional criteria (primarily signal activity of nets).",
        "Almost no HT detectors are publicly available, increasing barriers for reproducibility and entry into the field."
      ],
      "limitations": [
        "Evaluation uses ISCAS-85 combinational benchmarks; generalization to large modern SoCs and sequential designs is not demonstrated in the provided text.",
        "Insertion assumes combinational HTs with ANDed triggers and an XOR payload as the payload model.",
        "Detection assumes availability of a golden model for output comparison.",
        "Trigger net selection relies on thresholds over SCOAP-derived parameters (HTS and OCR), which require tuning per design.",
        "Method description implies reliance on netlist-level access and Yosys JSON conversion; layout-level and side-channel HTs are not addressed in the described methods."
      ],
      "future_work": [],
      "motivation": "Break limitations of human-biased HT benchmarks and enable exploration of HT insertion and detection design spaces using RL to foster next-generation detectors.",
      "potential_research_ideas": [
        "Co-evolutionary multi-agent RL where an insertion agent and a detection agent train adversarially to improve robustness and stealth over time.",
        "Extend the framework to sequential circuits and stateful HTs (e.g., counters, finite-state triggers) and evaluate on larger industrial-scale designs.",
        "Integrate power/timing/area penalties and layout-aware constraints into the reward to explore stealthy yet physically feasible HTs.",
        "Leverage graph neural network encoders for state representations to better capture netlist structure and long-range dependencies.",
        "Hybrid RL + SAT/ATPG guidance to accelerate search for compatible trigger sets while maintaining diversity of HTs.",
        "Benchmark suite creation: systematically generate and release a large, labeled corpus of HT-inserted netlists with metadata to support ML-based detectors.",
        "Robustness studies: evaluate detectors under adversarially morphed Trojans (e.g., logical equivalents) and propose defenses.",
        "Transfer learning and curriculum strategies to scale training across families of circuits (e.g., from ISCAS to ITC’99, OpenCores)."
      ],
      "architectural_improvement_recommendations": [
        "Adopt modern policy-gradient algorithms (e.g., PPO/A2C) or off-policy methods (e.g., DQN/Dueling DQN) with prioritized replay to stabilize RL training.",
        "Use GNN-based policy/value networks operating on the circuit graph; include SCOAP and signal probability as node features.",
        "Formulate multi-objective rewards combining controllability/observability, stealth (low switching probability), minimal area/timing overhead, and detection evasion.",
        "Constrain action space via ATPG/SAT feasibility checks to prune incompatible trigger combinations and accelerate convergence.",
        "Implement curriculum learning (start with small nets, scale to larger circuits) and domain randomization of reward thresholds to reduce overfitting.",
        "Parallelize environment simulations (vectorized testbench runs) to improve sample efficiency; cache partial simulation results."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires a golden model for post-silicon comparison to flag malicious behavior.",
        "Assumes access to gate-level netlists and ability to run extensive simulations for RL reward estimation.",
        "Generalization from ISCAS-85 to modern complex designs and sequential logic is unproven in the provided text.",
        "Parameter/reward tuning (thresholds for rare-net selection) may be design-specific and non-trivial."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Developed a tunable RL-based HT insertion tool free of human bias, capable of automatic HT insertion and creating a large population of valid HTs for each design.",
      "Introduced a tunable RL-based multi-criteria HT detection tool that generates test vectors to discover HTs inserted via diverse strategies.",
      "Proposed a generic methodology to compare HT detectors fairly using a confidence value metric.",
      "Demonstrated efficacy on ISCAS-85 benchmarks with an average 90.54% detection rate across three detection reward formulations; provided attack and detection success rates."
    ]
  },
  {
    "arxiv_id": "2306.06228v1",
    "title": "AVScan2Vec: Feature Learning on Antivirus Scan Data for Production-Scale Malware Corpora",
    "authors": "Robert J. Joyce; Tirth Patel; Charles Nicholas; Edward Raff",
    "abstract": "When investigating a malicious file, searching for related files is a common task that malware analysts must perform. Given that production malware corpora may contain over a billion files and consume petabytes of storage, many feature extraction and similarity search approaches are computationally infeasible. Our work explores the potential of antivirus (AV) scan data as a scalable source of features for malware. This is possible because AV scan reports are widely available through services such as VirusTotal and are ~100x smaller than the average malware sample. The information within an AV scan report is abundant with information and can indicate a malicious file's family, behavior, target operating system, and many other characteristics. We introduce AVScan2Vec, a language model trained to comprehend the semantics of AV scan data. AVScan2Vec ingests AV scan data for a malicious file and outputs a meaningful vector representation. AVScan2Vec vectors are ~3 to 85x smaller than popular alternatives in use today, enabling faster vector comparisons and lower memory usage. By incorporating Dynamic Continuous Indexing, we show that nearest-neighbor queries on AVScan2Vec vectors can scale to even the largest malware production datasets. We also demonstrate that AVScan2Vec vectors are superior to other leading malware feature vector representations across nearly all classification, clustering, and nearest-neighbor lookup algorithms that we evaluated.",
    "published_date": "2023-06-09",
    "pdf_link": "https://arxiv.org/pdf/2306.06228v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Similarity and Classification",
      "specific_problem": "Scalable malware similarity search and representation learning from antivirus (AV) scan reports for classification, clustering, and nearest-neighbor retrieval",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "4-layer Transformer encoder (BERT-style)",
        "novel_contribution": "Custom BERT-style encoder over AV scan report sequences with position/segment embeddings per AV vendor; tailored to extremely large, open-vocabulary token space from AV labels"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "CharacterBERT-style token embeddings",
        "novel_contribution": "Character-level CNN + Highway layers for open-vocabulary AV label tokens with truncation at 20 chars to handle >40M unique tokens"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM decoder",
        "novel_contribution": "Used for Masked Label Prediction to autoregressively reconstruct held-out AV product labels from the encoder’s [CLS] representation"
      },
      {
        "type": "primary",
        "category": "Metric Learning",
        "specific": "Siamese network with Multiple Negatives Ranking (MNR) loss",
        "novel_contribution": "Fine-tunes [CLS] embeddings so reports from same malware family map to nearby vectors for similarity search"
      },
      {
        "type": "primary",
        "category": "Approximate Nearest Neighbor Indexing",
        "specific": "Dynamic Continuous Indexing (DCI)",
        "novel_contribution": "Demonstrates low-latency search at production scale using AVScan2Vec vectors"
      },
      {
        "type": "baseline",
        "category": "Feature Engineering",
        "specific": "BWMD (Burrows–Wheeler Transform-based vector on raw bytes)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Engineering",
        "specific": "EMBER feature set (PE metadata, imports, strings, entropy, etc.)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Engineering",
        "specific": "Saxe & Berlin features (byte entropy, imports, PE header metadata)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised",
      "Supervised",
      "Metric learning",
      "Contrastive learning"
    ],
    "datasets": [
      {
        "name": "AVScan2Vec Pretraining Corpus (≈30M AV scan reports)",
        "type": "proprietary",
        "domain": "av_scan_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "AVScan2Vec Fine-tuning Pairs (≈10M anchor-positive AV scan report pairs)",
        "type": "proprietary",
        "domain": "av_scan_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Large-scale NN Search Index (≈7M AVScan2Vec vectors)",
        "type": "proprietary",
        "domain": "av_scan_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "BWMD (Burrows–Wheeler-based vector on raw bytes)",
        "paper_reference": "Raff et al. [22]",
        "metric": "Vector dimensionality / storage",
        "their_result": "AVScan2Vec vectors are ≈85× smaller",
        "baseline_result": "BWMD uses a 65,536-dimensional vector (\"85× larger than AVScan2Vec’s\")"
      },
      {
        "method_name": "EMBER feature vector",
        "paper_reference": "Anderson and Roth [4]",
        "metric": "Vector dimensionality / storage",
        "their_result": "AVScan2Vec vectors are ≈3× smaller than popular alternatives",
        "baseline_result": null
      },
      {
        "method_name": "Saxe & Berlin features",
        "paper_reference": "Saxe and Berlin [23]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Homogeneity",
      "Completeness",
      "V-Measure",
      "Nearest-neighbor query latency",
      "Vector dimensionality/size"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can antivirus (AV) scan reports serve as scalable, high-quality features for malware representation learning?",
        "Can a language model learn semantics of AV labels to produce compact vectors that outperform existing malware feature representations for classification, clustering, and similarity search at production scale?",
        "Can nearest-neighbor queries over such vectors be executed with low latency on multi-million to billion-scale corpora?"
      ],
      "gaps_identified": [
        "Feature extractors based on disassembly and dynamic analysis do not scale to production corpora sizes.",
        "Many existing feature sets (e.g., EMBER) are PE-specific and do not generalize across file formats.",
        "Unscaled tabular features are less suitable for deep learning and pairwise distance computations.",
        "BWMD vectors are extremely high dimensional (65,536), leading to high storage and computational costs.",
        "Prior work has not leveraged AV scan reports as a source of ML features despite their availability and richness."
      ],
      "limitations": [
        "AV labels and reports can be noisy, inconsistent, and contain erroneous information due to vendor-specific formats and naming.",
        "Labels are truncated to the first five tokens, which may discard some information to control sequence length and memory.",
        "Model utility depends on the presence of AV detections; samples undetected or labeled benign contribute limited information."
      ],
      "future_work": [
        "Integrate AVScan2Vec into large-scale malware analysis pipelines for routine analyst workflows.",
        "Scale nearest-neighbor search with metric acceleration structures (e.g., DCI) to even larger datasets."
      ],
      "motivation": "Enable scalable, effective malware similarity and analysis by exploiting widely available, compact AV scan data instead of expensive, format-specific, or slow feature extraction methods.",
      "potential_research_ideas": [
        "Multimodal fusion: combine AVScan2Vec embeddings with lightweight static features (e.g., file size, simple byte histograms) or sandbox behavior summaries to improve robustness while maintaining scalability.",
        "Temporal modeling: incorporate time-aware training to capture family evolution and drift, enabling time-consistent retrieval and detection.",
        "Vendor-aware calibration: learn reliability weights per AV vendor and per token category to mitigate noise and inconsistent naming.",
        "Alias/ontology alignment: jointly learn or leverage a malware family/behavior ontology to align vendor-specific aliases via contrastive supervision.",
        "Hard-negative mining at scale: use cross-batch memory or mining from nearest neighbors to strengthen MNR fine-tuning.",
        "Compression/distillation: quantize or distill embeddings to smaller dimensions (e.g., 256) with minimal loss to further cut storage and speed up search.",
        "Robustness to label noise/poisoning: study and defend against adversarial manipulation of AV labels in training and inference.",
        "Indexing benchmarking: compare DCI with HNSW/IVF-PQ/ScaNN for billion-scale latency-accuracy trade-offs on AVScan2Vec vectors."
      ],
      "architectural_improvement_recommendations": [
        "Adopt long-sequence Transformers (e.g., Performer/Longformer) to handle longer per-report sequences without truncating labels.",
        "Introduce span masking and token shuffling objectives tailored to AV label structure to enrich pretraining.",
        "Use multi-task fine-tuning to predict family, behavior, and OS targets jointly alongside metric learning.",
        "Implement cross-vendor attention or vendor-specific adapters to better model inter-vendor relationships.",
        "Employ advanced contrastive losses (e.g., InfoNCE with temperature, circle loss) and cross-batch memory for more effective representation learning.",
        "Add vector regularization (e.g., unit norm, hyperspherical embeddings) to stabilize ANN indexing and similarity."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Embeddings can be computed on a single GPU; demonstrated ~16 ms nearest-neighbor search over ~7M vectors using Dynamic Continuous Indexing. Model uses 4-layer Transformer encoder (D=768, 8 heads) and character-CNN embeddings."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Large-scale malware analysis pipelines (e.g., enterprise malware corpora, VirusTotal-scale repositories)",
      "scalability_discussed": true,
      "inference_time": "≈16 ms per nearest-neighbor query over ~7M vectors (with DCI)",
      "deployment_challenges": [
        "Dependence on availability and quality of AV scan data; noise and inconsistency across vendors.",
        "Handling samples with abstentions or benign detections.",
        "Managing extremely large token vocabulary and evolving vendor label conventions.",
        "Index maintenance and memory footprint at billion-scale despite compact vectors."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces AVScan2Vec, a language model that embeds entire AV scan reports into compact vectors.",
      "Designs a preprocessing pipeline to normalize heterogeneous AV labels and handle abstentions/benign detections.",
      "Uses CharacterBERT-style character-CNN embeddings to support an open-set vocabulary of >40M tokens.",
      "Pretrains with Masked Token Prediction and Masked Label Prediction (with LSTM decoder) tailored to AV reports.",
      "Fine-tunes with a Siamese architecture and Multiple Negatives Ranking loss for similarity-preserving embeddings.",
      "Demonstrates vectors that are ≈3–85× smaller than popular alternatives (e.g., BWMD), enabling faster search and lower memory.",
      "Shows superior performance across classification (family/behavior), clustering (Homogeneity, Completeness, V-Measure), and nearest-neighbor retrieval.",
      "Demonstrates production-scale nearest-neighbor search using Dynamic Continuous Indexing with ≈16 ms latency over ~7M samples."
    ]
  },
  {
    "arxiv_id": "2305.18737v1",
    "title": "Phase Correction using Deep Learning for Satellite-to-Ground CV-QKD",
    "authors": "Nathan K. Long; Robert Malaney; Kenneth J. Grant",
    "abstract": "Coherent measurement of quantum signals used for continuous-variable (CV) quantum key distribution (QKD) across satellite-to-ground channels requires compensation of phase wavefront distortions caused by atmospheric turbulence. One compensation technique involves multiplexing classical reference pulses (RPs) and the quantum signal, with direct phase measurements on the RPs then used to modulate a real local oscillator (RLO) on the ground - a solution that also removes some known attacks on CV-QKD. However, this is a cumbersome task in practice - requiring substantial complexity in equipment requirements and deployment. As an alternative to this traditional practice, here we introduce a new method for estimating phase corrections for an RLO by using only intensity measurements from RPs as input to a convolutional neural network, mitigating completely the necessity to measure phase wavefronts directly. Conventional wisdom dictates such an approach would likely be fruitless. However, we show that the phase correction accuracy needed to provide for non-zero secure key rates through satellite-to-ground channels is achieved by our intensity-only measurements. Our work shows, for the first time, how artificial intelligence algorithms can replace phase-measuring equipment in the context of CV-QKD delivered from space, thereby delivering an alternate deployment paradigm for this global quantum-communication application.",
    "published_date": "2023-05-30",
    "pdf_link": "https://arxiv.org/pdf/2305.18737v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cryptography",
      "subdomain": "Quantum Key Distribution (QKD)",
      "specific_problem": "Satellite-to-ground CV-QKD coherent measurement: estimating RLO phase wavefront corrections from intensity-only reference pulses via deep learning to enable non-zero secure key rates",
      "attack_types": [
        "Eavesdropping (Holevo-bound-limited adversary)",
        "Transmitted Local Oscillator (TLO) manipulation/interception attacks",
        "Attacks on reference pulses (RPs)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN (encoder-decoder)",
        "specific": "SegNet-style architecture with VGG16-based encoder; deconvolutional decoder; regression output",
        "novel_contribution": "Maps intensity-only RP images to continuous RLO phase correction without direct phase wavefront measurement; removes pixel-wise classification and skip connections; linear regression output for phase map"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Regression"
    ],
    "datasets": [
      {
        "name": "Simulated satellite-to-ground RP propagation (Channel One)",
        "type": "synthetic",
        "domain": "simulated_optical_wavefronts",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Simulated satellite-to-ground RP propagation (Channel Two)",
        "type": "synthetic",
        "domain": "simulated_optical_wavefronts",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Simulated satellite-to-ground RP propagation (Channel Three)",
        "type": "synthetic",
        "domain": "simulated_optical_wavefronts",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "No phase correction (before correction)",
        "paper_reference": null,
        "metric": "Shared information I_AB (bits/pulse), Channel One",
        "their_result": "0.284",
        "baseline_result": "1.910e-5"
      },
      {
        "method_name": "Prevailing wavefront sensing + Zernike polynomials (conceptual reference)",
        "paper_reference": "[14], [16], [19] (as cited in paper)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Mean Squared Error (training loss)",
      "Coherent efficiency (gamma)",
      "Shared information I_AB (bits/pulse)",
      "Secret key rate R_sec (bits/pulse)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can simple intensity measurements of reference pulses transmitted through a satellite-to-ground channel provide accurate assessments of phase distortions sufficient to enable non-zero secure key rates for CV-QKD?"
      ],
      "gaps_identified": [
        "TLO-based coherent detection introduces security loopholes (LO can be intercepted/modified).",
        "RLO-based approaches require direct phase wavefront measurements of RPs, which are cumbersome in practice and increase equipment and deployment complexity.",
        "Wavefront sensor performance deteriorates under strong turbulence and requires computationally intensive phase reconstruction, limiting real-time practicality.",
        "Lack of methods to infer phase corrections from intensity-only measurements for satellite-to-ground CV-QKD (prior CNN work focused on single-photon OAM DV-QKD across horizontal channels)."
      ],
      "limitations": [
        "Results are based on simulations; no on-sky or hardware-in-the-loop experiments reported.",
        "Assumes satellite zenith angle 0°, limiting generality to best-pass geometry.",
        "Networks trained per-channel; generalization across broader channel parameter ranges not fully demonstrated.",
        "Estimated phase maps show segmented gradients and occasional false peaks, indicating residual model bias from MSE optimization.",
        "Positive key rates depend strongly on detector trust assumptions; untrusted detector scenarios require very high coherent efficiency (≈0.90).",
        "Assumes equivalence of wavefront distortion between RPs and quantum signals.",
        "Asymptotic key rates under collective attacks; finite-size effects not considered."
      ],
      "future_work": [],
      "motivation": "Replace complex phase-measuring hardware in satellite CV-QKD by learning phase corrections from intensity-only RPs to simplify deployment, mitigate certain attacks linked to transmitted LOs, and still achieve non-zero secure key rates.",
      "potential_research_ideas": [
        "Physics-informed learning: incorporate propagation constraints and phase retrieval priors (e.g., Fresnel/TIE constraints) into the loss to reduce false peaks and improve gradient smoothness.",
        "Domain generalization across atmospheric conditions and geometries (varying zenith angles, Cn^2 profiles, wind speeds) using curriculum learning or meta-learning.",
        "Temporal/sequential models (ConvLSTM/Transformers) that leverage RP sequences to capture turbulence dynamics for improved correction.",
        "Uncertainty-aware phase estimation (e.g., probabilistic regression or ensembles) to drive adaptive modulation and risk-aware key rate optimization.",
        "Joint optimization with adaptive optics (AO) loops, learning residual phase after low-order AO correction.",
        "Evaluate finite-size key rates and design online adaptation policies (e.g., RL) that adjust Vmod and detection strategy under fluctuating gamma.",
        "Robustness against RP attacks or spoofing via anomaly detection and adversarial training on intensity inputs.",
        "On-sky validation campaign with a ground station testbed to benchmark inference latency and real-time performance."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a U-Net or UNet++ variant with carefully designed skip connections plus regularization to preserve gradient smoothness while avoiding trivial intensity-phase shortcuts.",
        "Multi-scale feature extraction (atrous/dilated convolutions) and pyramid pooling to capture turbulence structures across spatial scales.",
        "Complex-valued networks or Fourier-domain branches to better model phase relationships; hybrid image-Fourier losses.",
        "Physics-constrained loss terms (e.g., Laplacian smoothness, Zernike regularization, Fresnel consistency) and multi-objective training with coherent efficiency directly in the loss.",
        "Sequence models (ConvLSTM/Temporal attention) ingesting multiple consecutive RP frames.",
        "Uncertainty modeling (heteroscedastic regression or MC Dropout) with calibration for downstream key rate decisions."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Satellite-to-ground CV-QKD ground station receiver",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Generalization to varying atmospheric conditions and satellite geometries (non-zero zenith angles).",
        "Real-time inference requirements and integration with ground station control loops.",
        "Ensuring RP intensity measurements remain secure against manipulation and spoofing.",
        "Detector trust assumptions significantly affect achievable key rates.",
        "Receiver aperture size and link budget constraints to maintain adequate transmissivity.",
        "Calibration drift and mismatch between simulated training distributions and real-world turbulence."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a deep learning method to estimate RLO phase corrections from intensity-only RP measurements for satellite-to-ground CV-QKD.",
      "Demonstrates, via simulation, mean coherent efficiency ≈0.53 after correction (Channel One) and corresponding I_AB increase from 1.910e-5 to 0.284 bits/pulse.",
      "Shows positive secret key rates after phase correction for several channels (e.g., 0.112 bits/pulse for Channel One).",
      "Analyzes sensitivity of key rates to detector trust assumptions and coherent efficiency.",
      "Implements a SegNet-style encoder-decoder CNN with VGG16-based encoder and MSE regression to phase without skip connections."
    ]
  },
  {
    "arxiv_id": "2306.13030v2",
    "title": "Online Self-Supervised Deep Learning for Intrusion Detection Systems",
    "authors": "Mert Nakıp; Erol Gelenbe",
    "abstract": "This paper proposes a novel Self-Supervised Intrusion Detection (SSID) framework, which enables a fully online Deep Learning (DL) based Intrusion Detection System (IDS) that requires no human intervention or prior off-line learning. The proposed framework analyzes and labels incoming traffic packets based only on the decisions of the IDS itself using an Auto-Associative Deep Random Neural Network, and on an online estimate of its statistically measured trustworthiness. The SSID framework enables IDS to adapt rapidly to time-varying characteristics of the network traffic, and eliminates the need for offline data collection. This approach avoids human errors in data labeling, and human labor and computational costs of model training and data collection. The approach is experimentally evaluated on public datasets and compared with well-known {machine learning and deep learning} models, showing that this SSID framework is very useful and advantageous as an accurate and online learning DL-based IDS for IoT systems.",
    "published_date": "2023-06-22",
    "pdf_link": "https://arxiv.org/pdf/2306.13030v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Botnet/DDoS malicious traffic detection and compromised IoT device identification with fully online self-supervised learning",
      "attack_types": [
        "Botnet",
        "DDoS"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Random Neural Network",
        "specific": "Auto-Associative Deep Random Neural Network (AADRNN)",
        "novel_contribution": "Used within a novel fully online self-supervised IDS (SSID) that auto-labels packets using its own decisions and an online trustworthiness estimate; no offline training data or generative/contrastive model needed."
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "Feedforward Multi-Layer Perceptron (evaluated within SSID per Section V mention)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised",
      "Online",
      "Anomaly-based"
    ],
    "datasets": [
      {
        "name": "Kitsune",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Bot-IoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "AADRNN-based IDS (offline learning)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "AADRNN-based IDS (incremental learning)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "AADRNN-based IDS (sequential learning)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "MLP within SSID (alternative architecture)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can an IDS perform fully online self-supervised learning with no human intervention or prior offline training/data collection?",
        "How to measure and use an online estimate of IDS trustworthiness to decide when to update model parameters?",
        "Can a self-supervised online framework adapt rapidly to time-varying network traffic while maintaining high detection accuracy and low resource use?"
      ],
      "gaps_identified": [
        "Existing self-supervised IDS methods often rely on offline labeled or unlabeled data and pseudo-labeling.",
        "Many approaches require additional generative/contrastive models for self-supervision.",
        "Online updates are typically scheduled at fixed/hand-tuned intervals, creating a trade-off between computational cost and adaptation speed.",
        "Dependence on human labeling and offline data collection introduces errors, labor, and cost."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Enable a fully online, self-supervised DL-based IDS that adapts to time-varying traffic without offline data collection, labeling, or human intervention, reducing errors and costs and suiting resource-constrained IoT environments.",
      "potential_research_ideas": [
        "Extend SSID to additional architectures (e.g., Transformers, GNNs, temporal CNNs) and compare adaptation/accuracy trade-offs across models.",
        "Incorporate formal concept drift detection to trigger updates and data selection policies within SSID.",
        "Develop federated or cross-node SSID to share trustworthiness signals or model updates while preserving privacy.",
        "Design adversarially robust SSID variants that estimate and resist poisoning/evasion during online self-labeling.",
        "Integrate uncertainty calibration and out-of-distribution detection to refine self-labeling and update decisions.",
        "Apply SSID to encrypted traffic using flow-level or side-channel features, evaluating effectiveness under limited observability.",
        "Theoretically analyze convergence and stability of online self-supervised updates under non-stationary traffic.",
        "Combine SSID with active learning triggers for selective minimal human validation to bound error propagation."
      ],
      "architectural_improvement_recommendations": [
        "Augment the trustworthiness estimator with Bayesian uncertainty or ensemble-based confidence to better gate updates.",
        "Introduce a lightweight drift detector (e.g., Page-Hinkley, ADWIN) to adaptively schedule updates and buffer selection.",
        "Use memory replay or reservoir sampling to prevent catastrophic forgetting during online updates.",
        "Add a small contrastive regularizer (without full generative model) to improve representation stability under drift.",
        "Implement multi-task heads for simultaneous traffic anomaly scoring and device-compromise identification.",
        "Quantize/prune the AADRNN or MLP variants for deployment on constrained IoT hardware.",
        "Incorporate calibration (e.g., temperature scaling) for the intrusion probability output."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Resource constraints on IoT devices and networks",
        "Time-varying traffic and concept drift",
        "Choosing update frequency to balance computational cost and adaptation",
        "Absence of labeled data and need for robust self-labeling"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": true
    },
    "contributions": [
      "Proposes SSID, a fully online self-supervised learning framework for IDS requiring no human intervention or offline learning/data collection.",
      "Introduces an online trustworthiness estimation to guide self-labeling and adaptive weight updates.",
      "Implements SSID with an Auto-Associative Deep Random Neural Network (AADRNN) anomaly-based IDS and evaluates on Kitsune and Bot-IoT datasets.",
      "Demonstrates that SSID-trained IDS achieves high performance compared to offline and quasi-online (incremental/sequential) learning of the same IDS, while avoiding offline datasets and external parameter optimization.",
      "Shows SSID can be used with different IDS architectures (e.g., AADRNN and MLP) and is suitable for IoT systems."
    ]
  },
  {
    "arxiv_id": "2306.07981v1",
    "title": "Feature Engineering-Based Detection of Buffer Overflow Vulnerability in Source Code Using Neural Networks",
    "authors": "Mst Shapna Akter; Hossain Shahriar; Juan Rodriguez Cardenas; Sheikh Iqbal Ahamed; Alfredo Cuzzocrea",
    "abstract": "One of the most significant challenges in the field of software code auditing is the presence of vulnerabilities in software source code. Every year, more and more software flaws are discovered, either internally in proprietary code or publicly disclosed. These flaws are highly likely to be exploited and can lead to system compromise, data leakage, or denial of service. To create a large-scale machine learning system for function level vulnerability identification, we utilized a sizable dataset of C and C++ open-source code containing millions of functions with potential buffer overflow exploits. We have developed an efficient and scalable vulnerability detection method based on neural network models that learn features extracted from the source codes. The source code is first converted into an intermediate representation to remove unnecessary components and shorten dependencies. We maintain the semantic and syntactic information using state of the art word embedding algorithms such as GloVe and fastText. The embedded vectors are subsequently fed into neural networks such as LSTM, BiLSTM, LSTM Autoencoder, word2vec, BERT, and GPT2 to classify the possible vulnerabilities. We maintain the semantic and syntactic information using state of the art word embedding algorithms such as GloVe and fastText. The embedded vectors are subsequently fed into neural networks such as LSTM, BiLSTM, LSTM Autoencoder, word2vec, BERT, and GPT2 to classify the possible vulnerabilities. Furthermore, we have proposed a neural network model that can overcome issues associated with traditional neural networks. We have used evaluation metrics such as F1 score, precision, recall, accuracy, and total execution time to measure the performance. We have conducted a comparative analysis between results derived from features containing a minimal text representation and semantic and syntactic information.",
    "published_date": "2023-06-01",
    "pdf_link": "https://arxiv.org/pdf/2306.07981v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection (Source Code Analysis)",
      "specific_problem": "Function-level buffer overflow (CWE-119) vulnerability detection in C/C++ source code",
      "attack_types": [
        "Buffer overflow (CWE-119)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Custom Neural Network",
        "specific": null,
        "novel_contribution": "Proposed neural network model that 'provides higher accuracy than LSTM, BiLSTM, LSTM-Autoencoder, word2vec and BERT models, and the same accuracy as the GPT-2 model with greater efficiency.'"
      },
      {
        "type": "primary",
        "category": "Word Embeddings",
        "specific": "Stacked GloVe + fastText",
        "novel_contribution": "Use of stacked pre-trained embeddings to preserve semantic and syntactic information for source code tokens"
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "Simple RNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN-LSTM",
        "specific": "LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN-LSTM",
        "specific": "BiLSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoencoder",
        "specific": "LSTM Autoencoder",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Word Embeddings",
        "specific": "word2vec",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "GPT-2",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "SATE IV Juliet Test Suite (C/C++)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Debian Linux distribution source code (C/C++)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Open-source GitHub repositories (C/C++)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Combined function-level dataset (C/C++), as referenced in Russell’s work [22], focused on CWE-119",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Paper’s split (train/val/test) of function-level samples",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Simple RNN",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "Proposed model higher accuracy",
        "baseline_result": "Lower accuracy than proposed"
      },
      {
        "method_name": "LSTM",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "Higher accuracy than LSTM",
        "baseline_result": "Lower accuracy"
      },
      {
        "method_name": "BiLSTM",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "Higher accuracy than BiLSTM",
        "baseline_result": "Lower accuracy"
      },
      {
        "method_name": "LSTM Autoencoder",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "Higher accuracy than LSTM-Autoencoder",
        "baseline_result": "Lower accuracy"
      },
      {
        "method_name": "word2vec-based model",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "Higher accuracy than word2vec",
        "baseline_result": "Lower accuracy"
      },
      {
        "method_name": "BERT",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "Higher accuracy than BERT",
        "baseline_result": "Lower accuracy"
      },
      {
        "method_name": "GPT-2",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "Same accuracy as GPT-2 with greater efficiency (lower execution time)",
        "baseline_result": "Same accuracy but less efficient"
      }
    ],
    "performance_metrics_used": [
      "F1 score",
      "Precision",
      "Recall",
      "Accuracy",
      "Total execution time"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does preserving semantic and syntactic information with GloVe and fastText embeddings improve neural network detection of buffer overflow vulnerabilities in source code?",
        "How do different neural architectures (RNN/LSTM/BiLSTM/LSTM-Autoencoder/word2vec/BERT/GPT-2) compare for function-level vulnerability classification?",
        "Can a proposed neural network achieve equal-or-better accuracy than strong baselines (including GPT-2) while being more efficient?"
      ],
      "gaps_identified": [
        "Static and dynamic code analysis approaches have high false positives or rely on test coverage and predefined rules.",
        "Prior ML approaches may suffer information loss in representation learning and rely heavily on dataset quality.",
        "Existing tools often identify only a small subset of potential problems based on pre-established rules."
      ],
      "limitations": [
        "Using semantic and syntactic features via word embeddings increases execution time due to added complexity.",
        "Focus is on CWE-119 (buffer overflow) in C/C++ (authors note method could generalize, but evaluations are on this class)."
      ],
      "future_work": [],
      "motivation": "Improve early detection of software vulnerabilities by building a scalable, function-level ML system that leverages semantic and syntactic code features to overcome limitations of traditional static/dynamic analysis.",
      "potential_research_ideas": [
        "Incorporate code structure with AST/CFG/CPG-based graph neural networks to reduce information loss and capture control/data flows.",
        "Leverage code-pretrained transformers (e.g., CodeBERT/GraphCodeBERT/CodeT5) and compare to generic BERT/GPT-2 on the same splits.",
        "Model inter-procedural vulnerabilities by constructing call graphs and performing message passing across function boundaries.",
        "Multi-CWE, multi-task learning to jointly detect various weakness types and share representations.",
        "Contrastive/self-supervised pretraining on large unlabeled code, followed by fine-tuning for CWE-119.",
        "Knowledge distillation or adapters to retain GPT-2-level accuracy with much smaller runtime footprint.",
        "Robustness to code transformations (identifier renaming, dead-code insertion) via adversarial training and data augmentation.",
        "Line-level or token-level vulnerability localization to improve developer actionability and explainability."
      ],
      "architectural_improvement_recommendations": [
        "Replace generic embeddings with code-aware contextual encoders (CodeBERT/GraphCodeBERT) and/or fuse with GNNs over AST/CFG/CPG.",
        "Adopt hierarchical models: token-to-statement encoders, then statement-to-function aggregators for long functions.",
        "Apply quantization/pruning and efficient transformers (e.g., Distil*, Longformer) to reduce execution time while maintaining accuracy.",
        "Introduce inter-procedural message passing using call graphs for cross-function flows.",
        "Calibrate outputs and add uncertainty estimation to reduce false positives in practice."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Keras"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Using semantic and syntactic embeddings (GloVe + fastText) increases total execution time."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Extraction of semantic and syntactic features using GloVe and fastText.",
      "Vulnerability detection using LSTM, BiLSTM, LSTM-Autoencoder, word2vec, BERT, and GPT-2 with minimal intermediate feature representations.",
      "Vulnerability detection using the same models with semantic and syntactic features.",
      "A proposed neural network that outperforms LSTM, BiLSTM, LSTM-Autoencoder, word2vec, and BERT, and matches GPT-2 accuracy with greater efficiency.",
      "Comparative analysis between minimal text representation features and semantic/syntactic feature representations."
    ]
  },
  {
    "arxiv_id": "2306.05358v1",
    "title": "Trustworthy Sensor Fusion against Inaudible Command Attacks in Advanced Driver-Assistance System",
    "authors": "Jiwei Guan; Lei Pan; Chen Wang; Shui Yu; Longxiang Gao; Xi Zheng",
    "abstract": "There are increasing concerns about malicious attacks on autonomous vehicles. In particular, inaudible voice command attacks pose a significant threat as voice commands become available in autonomous driving systems. How to empirically defend against these inaudible attacks remains an open question. Previous research investigates utilizing deep learning-based multimodal fusion for defense, without considering the model uncertainty in trustworthiness. As deep learning has been applied to increasingly sensitive tasks, uncertainty measurement is crucial in helping improve model robustness, especially in mission-critical scenarios. In this paper, we propose the Multimodal Fusion Framework (MFF) as an intelligent security system to defend against inaudible voice command attacks. MFF fuses heterogeneous audio-vision modalities using VGG family neural networks and achieves the detection accuracy of 92.25% in the comparative fusion method empirical study. Additionally, extensive experiments on audio-vision tasks reveal the model's uncertainty. Using Expected Calibration Errors, we measure calibration errors and Monte-Carlo Dropout to estimate the predictive distribution for the proposed models. Our findings show empirically to train robust multimodal models, improve standard accuracy and provide a further step toward interpretability. Finally, we discuss the pros and cons of our approach and its applicability for Advanced Driver Assistance Systems.",
    "published_date": "2023-05-30",
    "pdf_link": "https://arxiv.org/pdf/2306.05358v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Autonomous Vehicle Security",
      "specific_problem": "Defending Advanced Driver-Assistance Systems (ADAS) against inaudible (ultrasonic) voice command attacks via trustworthy multimodal sensor fusion",
      "attack_types": [
        "Inaudible voice command (ultrasonic) injection against MEMS microphones (e.g., DolphinAttack)",
        "Ultrasound-modulated command injection"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "VGG16 (dual-branch for left/right cameras)",
        "novel_contribution": "Parallel fused multimodal architecture that combines embeddings from two VGG16 vision branches with audio embeddings for semantic consistency checking in ADAS"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "VGGish (audio)",
        "novel_contribution": "Customized VGGish for Mel-spectrogram/MFCC features to produce audio semantic embeddings for fusion with vision"
      },
      {
        "type": "primary",
        "category": "Bayesian/Uncertainty Estimation",
        "specific": "Monte-Carlo Dropout",
        "novel_contribution": "Used at inference to estimate predictive distributions and quantify uncertainty in a multimodal defense setting"
      },
      {
        "type": "primary",
        "category": "Calibration",
        "specific": "Expected Calibration Error (ECE)",
        "novel_contribution": "Used to assess model trustworthiness and calibration of the multimodal fusion detector"
      },
      {
        "type": "baseline",
        "category": "Fusion Strategy",
        "specific": "Early fusion (feature concatenation of audio and dual-view vision embeddings)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Fusion Strategy",
        "specific": "Late fusion (decision-level ensembling of audio and vision classifiers)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Unimodal audio-only detector (VGGish)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Unimodal vision-only detector (dual VGG16 on left/right cameras)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Synthetic ADAS audio-vision fusion dataset (go/stop scenarios)",
        "type": "synthetic",
        "domain": "audio_vision_multimodal",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Traffic signs dataset [5]",
        "type": "public",
        "domain": "traffic_sign_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ASV Spoof 2015 Challenge dataset",
        "type": "public",
        "domain": "audio_speaker_verification",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Aurora-4",
        "type": "public",
        "domain": "speech_recognition",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Early fusion (feature concatenation)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Late fusion (decision-level ensembling)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Audio-only (VGGish)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Vision-only (dual VGG16)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Comparative fusion study (best variant of MFF)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "92.25%",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Expected Calibration Error (ECE)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can multimodal audio-vision fusion be used to detect inaudible voice command attacks in ADAS?",
        "How trustworthy and reliable are the fusion model’s predictions, as quantified by uncertainty and calibration metrics?"
      ],
      "gaps_identified": [
        "Little prior work detects inaudible attacks via cross-modal interactions in vehicles.",
        "Prior multimodal defenses overlook model uncertainty and trustworthiness.",
        "Existing defense methods (signal-processing-based) are not practical for real-time identification.",
        "It is difficult to collect enough inaudible command samples for ML training.",
        "No in-depth sensor fusion framework has been used for in-vehicle anti-inaudible voice command systems."
      ],
      "limitations": [
        "Experiments rely on a synthetic audio-vision dataset reflecting go/stop scenarios rather than extensive real-world inaudible command captures.",
        "Collecting real inaudible attack samples is challenging, impacting training realism."
      ],
      "future_work": [],
      "motivation": "Defend ADAS against stealthy inaudible (ultrasonic) voice command attacks by leveraging multimodal sensor fusion and providing trustworthy uncertainty-aware predictions.",
      "potential_research_ideas": [
        "Build and release a real-world ADAS audio-vision dataset containing true ultrasonic command injections recorded on moving vehicles with MEMS microphones.",
        "Integrate multi-microphone arrays with beamforming and direction-of-arrival estimation to spatially filter suspected ultrasonic sources before fusion.",
        "Adopt cross-modal Transformers for sequence-level audio-vision alignment (temporal modeling of commands and scene context).",
        "Evaluate and harden against broader physical attacks (e.g., laser light-to-sound microphone injection) within the same fusion framework.",
        "Use deep ensembles, evidential deep learning, or Laplace approximations for stronger uncertainty estimation, combined with temperature scaling or Dirichlet calibration.",
        "Perform adversarial and corruption robustness training on audio (ultrasound-modulated waveforms) and vision (weather/lighting) with realistic channel simulations.",
        "Leverage large-scale self-supervised audio-visual pretraining (e.g., AudioCLIP-like models) to improve generalization and reduce labeled data needs.",
        "Develop a physics-informed data synthesis pipeline modeling ultrasonic propagation, reflections, and vehicle cabin acoustics for realistic training data.",
        "Add OOD detection to reject out-of-distribution audio spectrograms or atypical visual scenes before decision making.",
        "Optimize for edge deployment (pruning/quantization, distillation) for real-time ADAS constraints."
      ],
      "architectural_improvement_recommendations": [
        "Replace VGG backbones with modern, lighter and stronger architectures (e.g., ResNet/EfficientNet for vision, PANNs or AST for audio).",
        "Adopt cross-modal attention or a Transformer-based fusion module with gating to learn fine-grained audio-vision alignment.",
        "Use deep ensembles in addition to MC Dropout for more reliable uncertainty estimates.",
        "Apply post-hoc calibration (temperature scaling, Dirichlet calibration) and conformal prediction for calibrated confidence and set-valued decisions.",
        "Model temporal context with 3D CNNs or temporal Transformers across audio and multi-view video to capture command-scene dynamics.",
        "Introduce explicit OOD detectors and uncertainty-aware thresholding to refuse execution under high uncertainty.",
        "Pretrain on large audio-visual corpora and fine-tune on ADAS-specific data to boost robustness and sample efficiency."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Advanced Driver-Assistance Systems with MEMS microphones and front left/right cameras on vehicles",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Collecting sufficient real inaudible (ultrasonic) command samples for training and evaluation.",
        "Ensuring reliable audio-vision semantic alignment in diverse driving scenarios.",
        "Meeting real-time constraints for decision making within ADAS.",
        "Monitoring and interpreting uncertainty for trust-aware execution (refuse/accept command)."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Propose a robust audio-vision fusion defense system (MFF) to detect inaudible voice command attacks in ADAS.",
      "Build a fusion detection model based on semantic consistency between vision and audio, with performance and ablation analyses (early vs late fusion).",
      "Provide model uncertainty quantification (ECE) and uncertainty estimation (Monte-Carlo Dropout) to assess trustworthiness."
    ]
  },
  {
    "arxiv_id": "2305.06430v1",
    "title": "HoneyIoT: Adaptive High-Interaction Honeypot for IoT Devices Through Reinforcement Learning",
    "authors": "Chongqi Guan; Heting Liu; Guohong Cao; Sencun Zhu; Thomas La Porta",
    "abstract": "As IoT devices are becoming widely deployed, there exist many threats to IoT-based systems due to their inherent vulnerabilities. One effective approach to improving IoT security is to deploy IoT honeypot systems, which can collect attack information and reveal the methods and strategies used by attackers. However, building high-interaction IoT honeypots is challenging due to the heterogeneity of IoT devices. Vulnerabilities in IoT devices typically depend on specific device types or firmware versions, which encourages attackers to perform pre-attack checks to gather device information before launching attacks. Moreover, conventional honeypots are easily detected because their replying logic differs from that of the IoT devices they try to mimic. To address these problems, we develop an adaptive high-interaction honeypot for IoT devices, called HoneyIoT. We first build a real device based attack trace collection system to learn how attackers interact with IoT devices. We then model the attack behavior through markov decision process and leverage reinforcement learning techniques to learn the best responses to engage attackers based on the attack trace. We also use differential analysis techniques to mutate response values in some fields to generate high-fidelity responses. HoneyIoT has been deployed on the public Internet. Experimental results show that HoneyIoT can effectively bypass the pre-attack checks and mislead the attackers into uploading malware. Furthermore, HoneyIoT is covert against widely used reconnaissance and honeypot detection tools.",
    "published_date": "2023-05-10",
    "pdf_link": "https://arxiv.org/pdf/2305.06430v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Deception and Honeypots",
      "specific_problem": "Adaptive high-interaction honeypot that selects high-fidelity responses to evade pre-attack checks and elicit exploitation/malware uploads on IoT devices",
      "attack_types": [
        "reconnaissance scanning and fingerprinting",
        "honeypot detection/bypass",
        "remote code execution exploitation",
        "malware upload/botnet recruitment"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": null,
        "novel_contribution": "Formulates attacker–honeypot interaction as an MDP with multi-discrete action space derived from real device responses; learns response selection policy from attack traces to maximize attacker engagement (vulnerability exploitation and malware upload)."
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning"
    ],
    "datasets": [
      {
        "name": "Real-device IoT attack trace (June 17–Sept 1, 2022)",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Collected malware samples from attacker C2s (via sandboxed crawler)",
        "type": "private",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accumulated reward (RL)",
      "occurrence of vulnerability exploitation events",
      "malware upload occurrence/rate",
      "evasion against reconnaissance and honeypot detection tools (e.g., Nmap, HoneyScore, HoneypotHunter)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What IoT device is the attacker targeting?",
        "When does the attacker send specific pre-attack checks?",
        "Which responses better lead to vulnerability exploitation or malware upload?"
      ],
      "gaps_identified": [
        "Heterogeneity of IoT devices makes fixed-logic honeypots easy to fingerprint and bypass.",
        "Conventional IoT honeypots provide limited interaction and have static reply logic detectable by scanners/detectors.",
        "Attack traces are too complex for purely heuristic or manual analysis; need learning-based modeling of attacker behavior.",
        "Attackers increasingly perform pre-attack checks tied to device/firmware type before exploitation."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve IoT security by building a deceptive, high-interaction honeypot that can bypass pre-attack checks and mislead attackers to reveal methods and upload malware, overcoming limitations of fixed-logic honeypots.",
      "potential_research_ideas": [
        "Extend HoneyIoT to additional IoT protocols and services (e.g., MQTT, CoAP, UPnP, RTSP variants) using automated protocol learning.",
        "Treat the interaction as a POMDP to explicitly handle partial observability and noisy attacker behavior.",
        "Hierarchical RL that models multi-stage attack phases (reconnaissance -> exploitation -> post-exploitation) for better long-horizon credit assignment.",
        "Meta-RL or transfer learning to rapidly adapt response policies to previously unseen device models/firmware.",
        "Pre-train policies via simulation using attacker behavior models or synthetic attack graphs, then fine-tune online.",
        "Integrate generative response synthesis constrained by protocol grammars to increase fidelity beyond replay/mutation.",
        "Incorporate active learning to prioritize uncertain interactions and collect targeted traces from real devices.",
        "Automated integration with firmware emulation (e.g., QEMU-based) to scale coverage without large fleets of physical devices."
      ],
      "architectural_improvement_recommendations": [
        "Use sequence models (e.g., transformer encoders) or graph neural networks over attack graphs to encode state histories instead of aggregated packet states.",
        "Reward shaping with intermediate signals for deeper engagement (e.g., time-to-exploitation, command diversity) and penalties for detector triggers.",
        "Constrained/safe RL to prevent responses that expose the backend devices or break protocol invariants.",
        "Adopt online/continual RL for non-stationary attacker behavior with drift detection and policy updates.",
        "Multi-agent formulation (attacker simulators vs. defender agent) for adversarial training and robustness to new detection tools.",
        "Policy ensembles per protocol/device type with a gating network for device-conditioned response selection."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Public Internet deployment with AWS-hosted frontend VM, backend server for forwarding/analysis, and multiple real IoT devices (cameras, routers, smart plugs).",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Requires forwarding and rewriting responses from heterogeneous real devices to match attacker requests.",
        "System may need to reboot devices to recover after attacks.",
        "Maintaining high-fidelity content mutation (e.g., time, sensor values) in real time."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "HoneyIoT: an adaptive high-interaction IoT honeypot using reinforcement learning.",
      "Model attacker–honeypot interactions as an MDP based on real attack traces; learn response selection to engage attackers.",
      "Differential analysis to identify and mutate response fields (e.g., date/time/sensor values) for high-fidelity replies.",
      "Public-Internet deployment showing evasion of reconnaissance/honeypot detection tools and successful deception leading to malware uploads."
    ]
  },
  {
    "arxiv_id": "2304.12682v1",
    "title": "Docmarking: Real-Time Screen-Cam Robust Document Image Watermarking",
    "authors": "Aleksey Yakushev; Yury Markin; Dmitry Obydenkov; Alexander Frolov; Stas Fomin; Manuk Akopyan; Alexander Kozachok; Arthur Gaynov",
    "abstract": "This paper focuses on investigation of confidential documents leaks in the form of screen photographs. Proposed approach does not try to prevent leak in the first place but rather aims to determine source of the leak. Method works by applying on the screen a unique identifying watermark as semi-transparent image that is almost imperceptible for human eyes. Watermark image is static and stays on the screen all the time thus watermark present on every captured photograph of the screen. The key components of the approach are three neural networks. The first network generates an image with embedded message in a way that this image is almost invisible when displayed on the screen. The other two neural networks are used to retrieve embedded message with high accuracy. Developed method was comprehensively tested on different screen and cameras. Test results showed high efficiency of the proposed approach.",
    "published_date": "2023-04-25",
    "pdf_link": "https://arxiv.org/pdf/2304.12682v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Data Security",
      "subdomain": "Insider Threat and Data Loss Prevention (DLP)",
      "specific_problem": "Screen-cam robust document image watermarking for leak attribution (blind extraction to identify source)",
      "attack_types": [
        "Insider data exfiltration via screen photography (screen-cam)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN (U-Net-like)",
        "specific": "U-Net with circular padding",
        "novel_contribution": "Encoder network generates a seamlessly tiling, smoothly varying grayscale watermark patch from an M-bit message; circular padding enforces cyclic smoothness for side-by-side tiling and imperceptibility."
      },
      {
        "type": "primary",
        "category": "CNN (U-Net-like)",
        "specific": "U-Net with circular padding (shift detector)",
        "novel_contribution": "Decoder Dc produces a peak map invariant to cyclic shifts to estimate periodic grid alignment (cyclic shift) before message decoding."
      },
      {
        "type": "primary",
        "category": "CNN Classifier",
        "specific": "EfficientNet-B2",
        "novel_contribution": "Used as multilabel decoder Dw to recover M-bit message from the aligned watermark patch."
      },
      {
        "type": "primary",
        "category": "Training/Augmentation Layer",
        "specific": null,
        "novel_contribution": "Differentiable distortion layer simulating screen-cam effects (random shift, scale, rotation, Gaussian noise and blur) for end-to-end joint training of encoder and decoders."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "In-the-wild screen-cam photographs collected on different screens and cameras",
        "type": "proprietary",
        "domain": "screen_photographs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Synthetic training pairs via distortion layer (DL) applied to generated watermark images",
        "type": "synthetic",
        "domain": "screen_photographs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a static, imperceptible, screen-wide watermark enable reliable, blind recovery of an identifying message from screen-cam photographs across varied screens and cameras?",
        "How to design and train neural networks to embed and robustly extract such a watermark under screen-cam distortions while keeping UI responsiveness and imperceptibility?"
      ],
      "gaps_identified": [
        "Existing screen-cam watermarking approaches often cause UI latency (line-spacing search), require high refresh rates, are conspicuous/visible, have low capacity, or work only under restricted shooting conditions and angles.",
        "Prior works insufficiently analyze effects like shooting angle, compression, and moiré for robust extraction."
      ],
      "limitations": [
        "Manual pre-processing required for extraction: perspective correction and cropping of non-screen areas by an analyst.",
        "Extraction relies on detecting document background regions; performance may degrade on low-contrast or non-uniform backgrounds.",
        "Limited message size demonstrated (M=50 bits).",
        "Training distortions cover modest ranges (±4% scale, ±2 degrees rotation); robustness under more severe transforms, heavy compression, and extensive edits is not detailed.",
        "Opacity-imperceptibility trade-off must be tuned; watermark may be perceivable at higher opacities.",
        "No public dataset or code; reproducibility depends on implementation specifics of networks and distortion pipeline."
      ],
      "future_work": [],
      "motivation": "Attribute the source of confidential document leaks occurring via screen photographs by embedding an imperceptible, persistent watermark across the whole display that can be blindly decoded post factum.",
      "potential_research_ideas": [
        "Automate perspective correction and screen detection using corner/edge detectors or learnable homography (e.g., using spatial transformer networks) to remove manual steps.",
        "Integrate stronger, physically grounded display–camera pipeline models (subpixel layouts, gamma, white balance, demosaicing, ISP, compression) and moiré synthesis into training for improved robustness.",
        "Incorporate error-correcting codes (e.g., Reed–Solomon/LDPC) and CRC for reliable message recovery under higher noise and edits.",
        "Content-adaptive embedding using visual saliency or text/background segmentation to optimize imperceptibility and robustness.",
        "Multi-scale or frequency-domain embeddings to improve resilience against blur and downscaling.",
        "Color-channel-aware embedding exploiting monitor subpixel structure and human contrast sensitivity functions.",
        "Adversarial removal resistance: train against watermark removal attacks (inpainting/denoising/compression) and develop tamper-evident signaling.",
        "Lightweight on-device/mobile decoder variants (e.g., MobileNet/Vision Transformers) for field triage.",
        "Dynamic or session-based keys with cryptographic binding to user/time/device metadata, plus secure key management.",
        "Federated or simulated-to-real training to generalize across diverse monitors/cameras without sharing sensitive data."
      ],
      "architectural_improvement_recommendations": [
        "Replace or complement EfficientNet-B2 with a spatial transformer front-end to learn alignment and remove the need for a separate Dc and manual rectification.",
        "Jointly optimize encoder–decoder with a differentiable display–camera/ISP pipeline; include JPEG/H.264 differentiable approximations during training.",
        "Add perceptual losses (e.g., LPIPS, CSF-weighted) and luminance masking to further reduce visual artifacts at a given robustness level.",
        "Introduce explicit ECC layer with differentiable decoding surrogate during training to directly minimize bit error rate post-coding.",
        "Adopt multi-scale encoder outputs (pyramid) and hybrid sinusoidal/cellular patterns to enhance robustness to blur and rescaling.",
        "Quantization-aware training and model pruning/distillation to deploy decoders on low-resource analyst devices.",
        "Augment with color-domain embedding and subpixel-aware convolutions to exploit LCD layouts.",
        "Use contrastive/self-supervised pretraining for Dw to improve feature robustness to unseen capture pipelines."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Employee/workstation OS overlay (always-on topmost semi-transparent window covering the screen)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Manual perspective correction and cropping by analyst during extraction.",
        "Variability across monitors/cameras and presence of moiré patterns.",
        "Opacity–imperceptibility trade-off; potential user perception at higher opacities.",
        "Dependence on sufficient background areas for reliable periodicity detection and averaging.",
        "Robustness under extreme angles, strong compression, or heavy edits not fully characterized."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a real-time, screen-wide, static and imperceptible document watermarking method for screen-cam leak attribution using three neural networks.",
      "Encoder (U-Net with circular padding) generates a smoothly varying, seamlessly tiling grayscale watermark patch from an M-bit message.",
      "Shift-invariant decoder Dc (U-Net with circular padding) estimates cyclic shift to align periodic watermark structure from arbitrary crops.",
      "EfficientNet-B2-based decoder Dw performs multilabel classification to recover embedded bits.",
      "End-to-end joint training with a distortion layer that simulates screen-cam transformations (shift, scale, rotation, Gaussian noise, blur).",
      "Practical embedding via an OS-level always-on-top semi-transparent overlay window enabling real-time usage without UI slowdown."
    ]
  },
  {
    "arxiv_id": "2305.13884v1",
    "title": "Multi-Granularity Detector for Vulnerability Fixes",
    "authors": "Truong Giang Nguyen; Thanh Le-Cong; Hong Jin Kang; Ratnadira Widyasari; Chengran Yang; Zhipeng Zhao; Bowen Xu; Jiayuan Zhou; Xin Xia; Ahmed E. Hassan; Xuan-Bach D. Le; David Lo",
    "abstract": "With the increasing reliance on Open Source Software, users are exposed to third-party library vulnerabilities. Software Composition Analysis (SCA) tools have been created to alert users of such vulnerabilities. SCA requires the identification of vulnerability-fixing commits. Prior works have proposed methods that can automatically identify such vulnerability-fixing commits. However, identifying such commits is highly challenging, as only a very small minority of commits are vulnerability fixing. Moreover, code changes can be noisy and difficult to analyze. We observe that noise can occur at different levels of detail, making it challenging to detect vulnerability fixes accurately.   To address these challenges and boost the effectiveness of prior works, we propose MiDas (Multi-Granularity Detector for Vulnerability Fixes). Unique from prior works, Midas constructs different neural networks for each level of code change granularity, corresponding to commit-level, file-level, hunk-level, and line-level, following their natural organization. It then utilizes an ensemble model that combines all base models to generate the final prediction. This design allows MiDas to better handle the noisy and highly imbalanced nature of vulnerability-fixing commit data. Additionally, to reduce the human effort required to inspect code changes, we have designed an effort-aware adjustment for Midas's outputs based on commit length. The evaluation results demonstrate that MiDas outperforms the current state-of-the-art baseline in terms of AUC by 4.9% and 13.7% on Java and Python-based datasets, respectively. Furthermore, in terms of two effort-aware metrics, EffortCost@L and Popt@L, MiDas also outperforms the state-of-the-art baseline, achieving improvements of up to 28.2% and 15.9% on Java, and 60% and 51.4% on Python, respectively.",
    "published_date": "2023-05-23",
    "pdf_link": "https://arxiv.org/pdf/2305.13884v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Management",
      "specific_problem": "Automatic identification of vulnerability-fixing commits from code changes",
      "attack_types": [
        "General software vulnerabilities (e.g., DoS, CSRF) via CVEs; method is vulnerability-agnostic"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "CodeBERT",
        "novel_contribution": "Fine-tuned separately at commit-, file-, hunk-, and line-level to generate embeddings per granularity for vulnerability-fix detection"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "Used as feature extractor on CodeBERT embeddings for certain granularities to capture local patterns in code changes"
      },
      {
        "type": "primary",
        "category": "LSTM",
        "specific": "Bidirectional LSTM",
        "novel_contribution": "Used as feature extractor on embedded sequences to model sequential structure of code change fragments"
      },
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": null,
        "novel_contribution": "Ensemble over base models at multiple granularities (commit, file, hunk, line) to reduce noise and handle class imbalance"
      },
      {
        "type": "primary",
        "category": "Post-processing",
        "specific": "Effort-aware adjustment",
        "novel_contribution": "Effort-aware adjustment based on commit length to improve human-effort-centric ranking metrics (EffortCost@L, Popt@L)"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "CodeBERT (file-level; VulFixMiner)",
        "novel_contribution": "State-of-the-art baseline representing code changes at file-level granularity (VulFixMiner)"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "MiDas Java dataset",
        "type": "public",
        "domain": "code_diffs/commits",
        "link": "https://github.com/soarsmu/midas",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "MiDas Python dataset",
        "type": "public",
        "domain": "code_diffs/commits",
        "link": "https://github.com/soarsmu/midas",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "VulFixMiner dataset (test set mentioned; 0.34% positive rate)",
        "type": "public",
        "domain": "code_diffs/commits",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Dataset of 1,282 vulnerability-fixing commits (prior work [26])",
        "type": "public",
        "domain": "code_diffs/commits",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "CodeSearchNet (for CodeBERT pretraining)",
        "type": "public",
        "domain": "source_code and natural_language (pairs and code-only)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "VulFixMiner (CodeBERT file-level)",
        "paper_reference": "[20]",
        "metric": "AUC (Java)",
        "their_result": "MiDas AUC higher by 4.9% than VulFixMiner",
        "baseline_result": null
      },
      {
        "method_name": "VulFixMiner (CodeBERT file-level)",
        "paper_reference": "[20]",
        "metric": "AUC (Python)",
        "their_result": "MiDas AUC higher by 13.7% than VulFixMiner",
        "baseline_result": null
      },
      {
        "method_name": "VulFixMiner (CodeBERT file-level)",
        "paper_reference": "[20]",
        "metric": "EffortCost@L (Java)",
        "their_result": "MiDas improves up to 28.2% over baseline",
        "baseline_result": null
      },
      {
        "method_name": "VulFixMiner (CodeBERT file-level)",
        "paper_reference": "[20]",
        "metric": "Popt@L (Java)",
        "their_result": "MiDas improves up to 15.9% over baseline",
        "baseline_result": null
      },
      {
        "method_name": "VulFixMiner (CodeBERT file-level)",
        "paper_reference": "[20]",
        "metric": "EffortCost@L (Python)",
        "their_result": "MiDas improves up to 60% over baseline",
        "baseline_result": null
      },
      {
        "method_name": "VulFixMiner (CodeBERT file-level)",
        "paper_reference": "[20]",
        "metric": "Popt@L (Python)",
        "their_result": "MiDas improves up to 51.4% over baseline",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "AUC",
      "EffortCost@L",
      "Popt@L"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can modeling code changes at multiple granularities (commit/file/hunk/line) and ensembling the predictions improve vulnerability-fixing commit detection?",
        "Does an effort-aware adjustment based on commit length reduce human inspection effort and improve EffortCost@L and Popt@L?"
      ],
      "gaps_identified": [
        "Noise in code changes occurs at different granularities (file, hunk, line) and degrades single-granularity classifiers.",
        "Commit datasets are highly imbalanced; vulnerability-fixing commits constitute a very small minority (e.g., 0.34% in a referenced test set).",
        "Natural language artifacts (commit messages, issue reports) are often sanitized due to coordinated disclosure, limiting their utility.",
        "Traditional static analyses struggle on partial code (diffs) and rely on handcrafted heuristics."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Reduce the gap between fix time and public disclosure by identifying vulnerability-fixing commits from code changes alone to support SCA tools and early warning systems.",
      "potential_research_ideas": [
        "Hierarchical transformer architecture trained end-to-end over line→hunk→file→commit with cross-level attention for better noise gating.",
        "Contrastive pretraining on commit diffs using CVE-linked positive pairs vs. non-security changes to improve representations under class imbalance.",
        "Joint learning to both classify commits and localize fix lines (sequence tagging) to aid triage and interpretability.",
        "Integrate static/dynamic security signals (taint flow, API misuse patterns) with learned embeddings via multimodal fusion.",
        "Active learning with uncertainty sampling and human-in-the-loop labeling to efficiently expand rare positive samples.",
        "Cost-sensitive or focal/CB (class-balanced) loss and calibrated probabilities to better handle extreme imbalance and decision thresholds.",
        "Leverage larger code models (CodeT5+, StarCoder2, CodeLlama) with parameter-efficient tuning (LoRA) for diffs.",
        "Temporal and repository-context features (release cadence, prior vuln history) combined with code signals for improved precision."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment CodeBERT with more recent code LMs (CodeT5+, UniXcoder, GraphCodeBERT) and evaluate per-granularity gains.",
        "Use a hierarchical attention network to aggregate line→hunk→file→commit, learning data-driven importance weights instead of post-hoc ensembling.",
        "Adopt stacking with a learned meta-learner (e.g., logistic regression/XGBoost) over base models rather than simple combination.",
        "Introduce focal loss or class-balanced loss during finetuning; perform threshold calibration (Platt/temperature scaling) for imbalanced settings.",
        "Incorporate long-sequence transformers (Longformer/BigBird) for very large diffs to reduce truncation.",
        "Add an auxiliary token-level tagging head to explicitly attend to security-relevant lines and provide explanations.",
        "Use lightweight adapters/LoRA for each granularity to reduce compute and enable domain adaptation (Java↔Python)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/soarsmu/midas",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Highly imbalanced datasets where vulnerability-fixing commits are rare",
        "Noisy and tangled commits with irrelevant changes across files/hunks/lines",
        "Limited availability of reliable labels due to coordinated disclosure practices"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "MiDas: multi-granularity deep learning model (commit/file/hunk/line) with an ensemble combining base models to detect vulnerability-fixing commits from code changes.",
      "Effort-aware adjustment of outputs based on commit length to reduce human inspection effort.",
      "Empirical gains over state-of-the-art: AUC +4.9% (Java) and +13.7% (Python); EffortCost@L and Popt@L improvements up to 60% and 51.4% (Python) and 28.2% and 15.9% (Java).",
      "Ablation studies showing benefits of multi-granularity (+up to 4.9% AUC, 8.5% CostEffort, 17.9% Popt) and effort-aware adjustment (+up to 21% CostEffort, 22% Popt).",
      "Released implementation and datasets at https://github.com/soarsmu/midas"
    ]
  },
  {
    "arxiv_id": "2305.01245v1",
    "title": "MDENet: Multi-modal Dual-embedding Networks for Malware Open-set Recognition",
    "authors": "Jingcai Guo; Yuanyuan Xu; Wenchao Xu; Yufeng Zhan; Yuxia Sun; Song Guo",
    "abstract": "Malware open-set recognition (MOSR) aims at jointly classifying malware samples from known families and detect the ones from novel unknown families, respectively. Existing works mostly rely on a well-trained classifier considering the predicted probabilities of each known family with a threshold-based detection to achieve the MOSR. However, our observation reveals that the feature distributions of malware samples are extremely similar to each other even between known and unknown families. Thus the obtained classifier may produce overly high probabilities of testing unknown samples toward known families and degrade the model performance. In this paper, we propose the Multi-modal Dual-Embedding Networks, dubbed MDENet, to take advantage of comprehensive malware features (i.e., malware images and malware sentences) from different modalities to enhance the diversity of malware feature space, which is more representative and discriminative for down-stream recognition. Last, to further guarantee the open-set recognition, we dually embed the fused multi-modal representation into one primary space and an associated sub-space, i.e., discriminative and exclusive spaces, with contrastive sampling and rho-bounded enclosing sphere regularizations, which resort to classification and detection, respectively. Moreover, we also enrich our previously proposed large-scaled malware dataset MAL-100 with multi-modal characteristics and contribute an improved version dubbed MAL-100+. Experimental results on the widely used malware dataset Mailing and the proposed MAL-100+ demonstrate the effectiveness of our method.",
    "published_date": "2023-05-02",
    "pdf_link": "https://arxiv.org/pdf/2305.01245v1",
    "paper_types": [
      "new_dataset",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Open-set Malware Recognition",
      "specific_problem": "Jointly classify malware from known families and detect samples from novel unknown families (MOSR)",
      "attack_types": [
        "malware families",
        "viruses",
        "worms",
        "trojan horses",
        "spyware",
        "unknown/novel malware families"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Multi-modal Architecture",
        "specific": "MDENet (Multi-modal Dual-Embedding Networks)",
        "novel_contribution": "Fuse numeric and textual malware features and dually embed into discriminative and exclusive spaces for classification and open-set detection"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Re-designed multi-scale CNN with integrated non-local means",
        "novel_contribution": "Numeric encoder integrates non-local means into a multi-scale CNN with local and global receptive modules to capture statistical and spatial correlations from malware images generated from numeric features"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT (or variants) textual encoder",
        "novel_contribution": "Organizes tokenized malware features into sentences and encodes them with a language model to obtain textual vectors"
      },
      {
        "type": "primary",
        "category": "Metric Learning",
        "specific": "Contrastive sampling + rho-bounded enclosing sphere regularizations",
        "novel_contribution": "Dual-embedding into discriminative (classification) and exclusive (open-set detection) spaces; modified distance-based detection"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Metric Learning"
    ],
    "datasets": [
      {
        "name": "MAL-100+",
        "type": "private",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Malimg (referred as Mailing in paper)",
        "type": "public",
        "domain": "malware_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can comprehensive multi-modal malware features (numeric images + textual sentences) enhance feature diversity to improve malware open-set recognition?",
        "Does dual-embedding into discriminative and exclusive spaces with contrastive sampling and rho-bounded enclosing sphere regularizations improve both family-level classification and unknown-family detection?",
        "Can a modified distance-based detection mechanism mitigate degradation seen in threshold/probability-based open-set detection for malware?"
      ],
      "gaps_identified": [
        "Feature distributions of malware samples are extremely similar even between known and unknown families, causing overly high predicted probabilities for unknowns with threshold-based methods and degraded performance",
        "Existing methods mostly use only numeric/static features and neglect comprehensive multi-modal malware features",
        "Lack of a large, multi-modal open-set malware dataset for MOSR",
        "Prior GAN-based novelty synthesis approaches can be resource-intensive in computing and data"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Enable robust malware open-set recognition that jointly classifies known families and detects novel unknown families by enriching malware feature space via multi-modal encoders and stabilizing open-set detection via dual-embedding with contrastive and sphere regularization; fill the dataset gap with a large multi-modal corpus.",
      "potential_research_ideas": [
        "Augment MDENet with dynamic-analysis features (e.g., sandboxed API traces) using sequence models to further boost modality diversity while retaining real-time feasibility via selective tracing",
        "Pretrain cross-modal malware encoders using self-supervised or contrastive objectives (e.g., CLIP-style numeric-text pairing) to improve generalization to unseen families",
        "Incorporate energy-based or calibrated confidence scoring (e.g., temperature scaling, energy scores) alongside the exclusive-space distance for more robust open-set thresholds",
        "Apply extreme value theory (EVT) calibration on the exclusive space distances to better model tails for unknown detection",
        "Prototype/center-based losses with class-wise margin optimization to tighten known-family clusters in the discriminative space",
        "Continuum/online open-world learning to incrementally add discovered families from unknowns with minimal forgetting",
        "Utilize graph neural networks over call graphs/import graphs in parallel with current modalities for structure-aware features",
        "Adopt parameter-efficient fine-tuning of the textual encoder (e.g., LoRA/adapters) to domain-adapt BERT on malware sentences at low cost",
        "Explore hierarchical open-set recognition (family → subfamily) using hierarchical prototypes and multi-level exclusivity constraints",
        "Leverage large language models to synthesize realistic malware sentences for hard negatives in contrastive sampling (with safety controls)"
      ],
      "architectural_improvement_recommendations": [
        "Replace simple fusion with cross-attention between numeric and textual streams to enable modality-aware interaction",
        "Introduce prototype learning with learnable class centers and center loss in the discriminative space; use Mahalanobis distance in exclusive space",
        "Use a hypersphere classifier (e.g., SVDD-style soft boundary) jointly optimized with contrastive loss for tighter known-class enclosures",
        "Add post-hoc calibration (temperature scaling, energy-based OOD) on the discriminative logits to complement distance-based detection",
        "Adopt multi-scale feature pyramids and attention pooling in the numeric encoder; refine non-local operations with efficient attention",
        "Apply adversarial/consistency regularization between modalities to reduce over-reliance on a single modality",
        "Use curriculum hard-negative mining in contrastive sampling to progressively challenge the exclusive space",
        "Parameter-efficient fine-tuning (LoRA/adapters) for the textual encoder to reduce compute while improving domain adaptation"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Dynamic analysis is time-consuming and unsuitable for real-time recognition, motivating reliance on static features",
        "High similarity between malware families causes probability-based thresholds to misclassify unknowns",
        "Constructing and maintaining multi-modal feature pipelines (numeric to images; tokenization to sentences) may add engineering overhead"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Formal and practical investigation of malware open-set recognition on large-scale multi-modal malware data",
      "A novel MOSR framework (MDENet) with multi-modal encoders (numeric and textual) and dual-embedding (discriminative and exclusive spaces) using contrastive sampling and rho-bounded enclosing sphere regularizations, plus a modified distance-based detection mechanism",
      "A new large-scale multi-modal malware dataset MAL-100+ (complementary to MAL-100), with numeric and tokenized textual features",
      "Experimental validation on Malimg and MAL-100+ demonstrating the effectiveness of MDENet"
    ]
  },
  {
    "arxiv_id": "2306.00694v1",
    "title": "UNGOML: Automated Classification of unsafe Usages in Go",
    "authors": "Anna-Katharina Wickert; Clemens Damke; Lars Baumgärtner; Eyke Hüllermeier; Mira Mezini",
    "abstract": "The Go programming language offers strong protection from memory corruption. As an escape hatch of these protections, it provides the unsafe package. Previous studies identified that this unsafe package is frequently used in real-world code for several purposes, e.g., serialization or casting types. Due to the variety of these reasons, it may be possible to refactor specific usages to avoid potential vulnerabilities. However, the classification of unsafe usages is challenging and requires the context of the call and the program's structure. In this paper, we present the first automated classifier for unsafe usages in Go, UNGOML, to identify what is done with the unsafe package and why it is used. For UNGOML, we built four custom deep learning classifiers trained on a manually labeled data set. We represent Go code as enriched control-flow graphs (CFGs) and solve the label prediction task with one single-vertex and three context-aware classifiers. All three context-aware classifiers achieve a top-1 accuracy of more than 86% for both dimensions, WHAT and WHY. Furthermore, in a set-valued conformal prediction setting, we achieve accuracies of more than 93% with mean label set sizes of 2 for both dimensions. Thus, UNGOML can be used to efficiently filter unsafe usages for use cases such as refactoring or a security audit. UNGOML: https://github.com/stg-tud/ungoml Artifact: https://dx.doi.org/10.6084/m9.figshare.22293052",
    "published_date": "2023-06-01",
    "pdf_link": "https://arxiv.org/pdf/2306.00694v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "API Misuse Detection",
      "specific_problem": "Automated classification of unsafe usages in Go (WHAT is done and WHY it is used) to support refactoring and security audits",
      "attack_types": [
        "memory corruption",
        "buffer overflows",
        "type safety violations",
        "pointer misuse"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Graph Isomorphism Network (GIN)",
        "novel_contribution": "Applied on enriched control-flow graphs (CFGs) of Go code to classify unsafe usages (WHAT/WHY)"
      },
      {
        "type": "primary",
        "category": "GNN",
        "specific": "2-WL-GNN (higher-order Weisfeiler-Lehman 2-GNN)",
        "novel_contribution": "Higher-order relational modeling over enriched CFGs for context-aware classification"
      },
      {
        "type": "primary",
        "category": "Set Network",
        "specific": "DeepSets",
        "novel_contribution": "Context-aware model using per-vertex embeddings pooled over neighborhoods; contrasts impact of ignoring explicit control-flow structure"
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "Single-vertex MLP",
        "novel_contribution": "Non-context model using only the local unsafe usage vertex features as a lower bound baseline"
      },
      {
        "type": "primary",
        "category": "Conformal Prediction",
        "specific": null,
        "novel_contribution": "First exploration of set-valued conformal prediction for software engineering tasks to provide reliable label sets with coverage guarantees"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "UNGOML labeled dataset of unsafe usages in Go",
        "type": "public",
        "domain": "source_code",
        "link": "https://dx.doi.org/10.6084/m9.figshare.22293052",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "GO-GEIGER unsafe usage study results (GitHub Go projects)",
        "type": "public",
        "domain": "source_code",
        "link": "https://github.com/Cortys/unsafe_go_study_results",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Single-vertex MLP",
        "paper_reference": null,
        "metric": "Top-1 accuracy (combined WHAT and WHY)",
        "their_result": "All three context-aware classifiers achieve a top-1 accuracy of more than 86% for both dimensions (WHAT and WHY); combined top-1 nearly 80%",
        "baseline_result": "74% top-1"
      }
    ],
    "performance_metrics_used": [
      "top-1 accuracy",
      "top-3 accuracy",
      "conformal prediction accuracy/coverage",
      "mean label set size"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can modern machine learning classifiers (e.g., GNNs/DeepSets) automatically classify the WHAT and WHY of unsafe usages in Go?",
        "How important is incorporating program context and structure (via enriched CFGs) for accurate classification?",
        "Can conformal set prediction provide reliable set-valued outputs that improve usability and accuracy for this task?"
      ],
      "gaps_identified": [
        "Automated rule-based static analyzers only support a small subset of well‑studied security‑critical unsafe usages; precise modeling of all patterns is challenging.",
        "Manual reasoning about WHAT and WHY of unsafe usages in large repositories is cumbersome and time-consuming.",
        "Lack of automated tools to classify unsafe usages by purpose; this is the first such classifier for Go.",
        "Prior studies did not cover the Go 1.17 additions to the unsafe package."
      ],
      "limitations": [
        "Focus on unsafe functions/types introduced before Go 1.17: “our discussions of the unsafe package focus on the functions and types introduced before Go 1.17.”",
        "Ambiguity in labeling: “sometimes even human annotators have difficulties agreeing on one specific label [3]”.",
        "Scope limited to the Go language and specifically the unsafe package; generalization to other languages/APIs not evaluated.",
        "Some contexts (type declarations/global variable definitions) lack control-flow structure in the graph, potentially limiting contextual signals."
      ],
      "future_work": [
        "Further explore and apply conformal set prediction in additional software engineering tasks.",
        "Extend coverage to the newer Go 1.17+ unsafe API functions (e.g., Add) and re-evaluate models.",
        "Use UNGOML to support and evaluate large-scale refactoring and security audits in real-world projects."
      ],
      "motivation": "Unsafe usages in Go can reintroduce memory-related security risks; auditing and refactoring require an efficient way to understand WHAT is done and WHY unsafe is used, which is difficult to encode with rules and labor-intensive to do manually.",
      "potential_research_ideas": [
        "Augment the classifier with vulnerability risk/severity prediction by combining learned representations with static data-flow/taint analyses to prioritize unsafe usages most likely to cause exploits.",
        "Generalize the approach to other languages’ unsafe or low-level escape hatches (e.g., Rust unsafe blocks, C/C++ casts) for cross-language unsafe usage classification.",
        "Human-in-the-loop active learning to resolve label ambiguities, leveraging conformal prediction to query uncertain cases and rapidly expand labeled data.",
        "Combine graph-based models with large language models (LLMs) over code (e.g., CodeBERT/CodeT5) via multi-modal fusion of token and graph features.",
        "Longitudinal analysis to study how unsafe usage patterns evolve post-introduction of Go generics and new unsafe APIs, informing refactoring strategies."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a Code Property Graph that fuses AST, CFG, and PDG (data/control dependencies) to enrich relational signals beyond the current CFG.",
        "Integrate precise data-flow and type inference features (e.g., points-to, escape analysis outcomes) as node/edge attributes for improved WHY inference.",
        "Pretrain with self-supervised graph contrastive learning on large Go codebases, then fine-tune for WHAT/WHY (improving data efficiency).",
        "Use multi-task learning with a shared backbone and task-specific heads for WHAT and WHY, possibly with hierarchical/conditional dependencies between them.",
        "Employ model ensembling and probabilistic calibration alongside conformal prediction to improve reliability and coverage-set compactness.",
        "Incorporate textual/contextual signals (identifiers, comments, import/package names) via joint token embeddings with graph encoders."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/stg-tud/ungoml",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Developer tooling for Go projects (code auditing/refactoring support)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Ambiguity in labels can require human oversight in edge cases.",
        "Building enriched CFGs and variable-use graphs at scale may be resource-intensive across very large repositories.",
        "Coverage gaps for newly added unsafe APIs (Go 1.17+) until models and representations are updated.",
        "Generalization to diverse coding styles and project structures may require continual re-training or domain adaptation."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Formalization of inferring programmer intentions when using unsafe (WHAT and WHY) as a classification problem.",
      "Comparison of relational and non-relational ML models (GNNs, DeepSets) to assess the impact of program structure on predictions.",
      "Discussion of important features needed to classify WHAT and WHY of unsafe usages and an enriched CFG representation.",
      "UNGOML: first classification tool that predicts how and why unsafe is used in Go projects to support refactoring and security audits.",
      "Initial evidence that conformal set prediction is valuable for software engineering classifiers, achieving >93% accuracy with mean label set size ≈2.",
      "Empirical results: context-aware models achieve top-1 accuracy >86% per dimension (WHAT/WHY), combined top-1 nearly 80%, and top-3 >91%; the single-vertex MLP achieves 74% top-1."
    ]
  },
  {
    "arxiv_id": "2306.01754v1",
    "title": "Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning?",
    "authors": "Aaron Chan; Anant Kharkar; Roshanak Zilouchian Moghaddam; Yevhen Mohylevskyy; Alec Helyar; Eslam Kamal; Mohamed Elkamhawy; Neel Sundaresan",
    "abstract": "Software vulnerabilities bear enterprises significant costs. Despite extensive efforts in research and development of software vulnerability detection methods, uncaught vulnerabilities continue to put software owners and users at risk. Many current vulnerability detection methods require that code snippets can compile and build before attempting detection. This, unfortunately, introduces a long latency between the time a vulnerability is injected to the time it is removed, which can substantially increases the cost of fixing a vulnerability. We recognize that the current advances in machine learning can be used to detect vulnerable code patterns on syntactically incomplete code snippets as the developer is writing the code at EditTime. In this paper we present a practical system that leverages deep learning on a large-scale data set of vulnerable code patterns to learn complex manifestations of more than 250 vulnerability types and detect vulnerable code patterns at EditTime. We discuss zero-shot, few-shot, and fine-tuning approaches on state of the art pre-trained Large Language Models (LLMs). We show that in comparison with state of the art vulnerability detection models our approach improves the state of the art by 10%. We also evaluate our approach to detect vulnerability in auto-generated code by code LLMs. Evaluation on a benchmark of high-risk code scenarios shows a reduction of up to 90% vulnerability reduction.",
    "published_date": "2023-05-23",
    "pdf_link": "https://arxiv.org/pdf/2306.01754v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection",
      "specific_problem": "Detecting software vulnerabilities in incomplete source code at edit time (IDE) across multiple languages",
      "attack_types": [
        "SQL Injection (CWE-89)",
        "Hardcoded Credentials (CWE-798)",
        "Code Injection (CWE-94)",
        "Path Injection (CWE-22)",
        "Clear Text Logging (CWE-312)",
        "Weak Cryptographic Algorithm (CWE-327)",
        "Incomplete URL Substring Sanitization (CWE-20)",
        "More than 250 vulnerability types (CWEs) across 7 languages"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "CodeBERT (RoBERTa-base)",
        "novel_contribution": "Fine-tuned with a classification head for binary vulnerability detection using a context + vulnerable block input format to support syntactically incomplete snippets at EditTime; oversampling of rare positives; BCE loss"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "code-davinci-002 (Codex)",
        "novel_contribution": "Fine-tuned as a classifier via next-token prediction with special classification tokens appended to the input sequence"
      },
      {
        "type": "baseline",
        "category": "Prompt-based LLM (Transformer)",
        "specific": "code-davinci-002 (Codex) zero-shot",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Prompt-based LLM (Transformer)",
        "specific": "text-davinci-003 (InstructGPT) zero-shot",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Prompt-based LLM (Transformer)",
        "specific": "code-davinci-002 (Codex) few-shot",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Prompt-based LLM (Transformer)",
        "specific": "text-davinci-003 (InstructGPT) few-shot",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Zero-shot",
      "Few-shot",
      "In-context Learning"
    ],
    "datasets": [
      {
        "name": "LGTM/CodeQL-labeled vulnerable code snippets (7 languages)",
        "type": "proprietary",
        "domain": "source_code",
        "link": "https://github.com/github/codeql",
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "GitHub PR Vulnerabilities dataset (for model variant evaluation)",
        "type": "proprietary",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Expanded high-risk code scenarios EditTime benchmark (based on Pearce et al.)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Pearce et al. high-risk code scenarios benchmark (original)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CodexZero (code-davinci-002 zero-shot)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "60.87%",
        "baseline_result": "19.90%"
      },
      {
        "method_name": "TextZero (text-davinci-003 zero-shot)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "60.87%",
        "baseline_result": "58.65%"
      },
      {
        "method_name": "CodexFew (code-davinci-002 few-shot, 8 examples)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "60.87%",
        "baseline_result": "37.70%"
      },
      {
        "method_name": "TextFew (text-davinci-003 few-shot, 6 examples)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "60.87%",
        "baseline_result": "59.29%"
      },
      {
        "method_name": "CodexVuln (fine-tuned code-davinci-002)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "60.87%",
        "baseline_result": "56.80%"
      }
    ],
    "performance_metrics_used": [
      "Precision",
      "Recall",
      "F1-score",
      "Vulnerability rate reduction",
      "Latency (milliseconds)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can transformer-based models detect vulnerable code patterns at EditTime on syntactically incomplete code?",
        "Among zero-shot, few-shot, and fine-tuning approaches on pre-trained LLMs, which achieves the best precision/recall trade-off for vulnerability detection?",
        "Can such models reduce vulnerabilities in auto-generated code from code LLMs?",
        "Can a practical, low-latency system be deployed in IDEs to prevent vulnerabilities earlier?"
      ],
      "gaps_identified": [
        "Most deep learning approaches require complete files, functions, or statements and cannot detect vulnerabilities at EditTime while code is incomplete.",
        "Rule-based static analysis and feature-based ML require manual expert effort to encode evolving vulnerability patterns.",
        "Dynamic analysis suffers from low code coverage.",
        "Code LLMs can produce vulnerable code completions in certain scenarios, necessitating mitigation."
      ],
      "limitations": [
        "Training data is vastly imbalanced with less than 10% vulnerable examples; oversampling was required.",
        "Fine-tuning code-davinci-002 was down-sized to 30,000 examples due to cost."
      ],
      "future_work": [],
      "motivation": "Reduce the latency between vulnerability injection and removal by detecting vulnerabilities as developers type, lowering remediation cost and risk.",
      "potential_research_ideas": [
        "Joint detection and localization: extend binary detection to line- or span-level vulnerability localization with CWE attribution.",
        "Multi-task learning across CWE types and languages to improve generalization, including multi-label classification for multiple co-occurring weaknesses.",
        "Incorporate program structure (AST/CFG/PDG) via graph-code transformers or hybrid GNN+Transformer architectures for better context on incomplete code.",
        "Active learning with developer-in-the-loop and CodeQL feedback to iteratively refine the model on hard negatives and novel patterns.",
        "Self-training/weak supervision by mining more CodeQL-flagged code and validated fixes from PRs to scale labels beyond current coverage.",
        "Explainable detection: generate natural-language rationales mapped to code regions to improve developer trust and adoption.",
        "Robustness testing against prompt/format variance and adversarial obfuscations of vulnerable patterns.",
        "Distill large models to efficient on-device classifiers for low-latency IDE deployment.",
        "Retrieval-augmented detection using CWE/CodeQL docs and similar historical fixes to inform decisions.",
        "Evaluate and adapt to new foundation code models (e.g., code-specific instruction-tuned LLMs) using parameter-efficient tuning (LoRA/PEFT)."
      ],
      "architectural_improvement_recommendations": [
        "Add a token/span classification head to support fine-grained vulnerability localization and CWE tagging.",
        "Adopt encoder-decoder or dual-encoder contrastive setups to compare vulnerable blocks against their fixed versions (contrastive learning).",
        "Use parameter-efficient tuning (LoRA/IA3/Adapters) on larger code LLMs to improve recall while controlling latency.",
        "Implement mixture-of-experts per language/CWE family with gating based on language and context.",
        "Leverage structured inputs (separate channels for context, vulnerable block, and AST edges) with cross-attention.",
        "Calibrate decision thresholds per-language using validation PR data to balance precision/recall in deployment.",
        "Curriculum training from complete to increasingly incomplete snippets to better handle EditTime syntax errors."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Fine-tuning code-davinci-002 was limited to 30,000 examples due to cost; DeepDevVuln (CodeBERT) operates with inference on the order of milliseconds in IDE."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "VSCode extension (IDE) for EditTime vulnerability detection",
      "scalability_discussed": true,
      "inference_time": "On the order of milliseconds",
      "deployment_challenges": [
        "Trade-offs between model size and precision/recall across zero-shot, few-shot, and fine-tuning approaches",
        "Handling syntactically incomplete code during EditTime",
        "Class imbalance across vulnerabilities and languages"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Production-quality vulnerability detection system that identifies vulnerabilities in incomplete code snippets at EditTime with millisecond latency.",
      "Comprehensive comparison of zero-shot, few-shot, and fine-tuning approaches on pre-trained LLMs (CodeBERT, code-davinci-002, text-davinci-003).",
      "Expanded the benchmark introduced by Pearce et al. and made it available to the community as a future EditTime benchmark.",
      "Collected more than 500K vulnerable code snippets across 7 languages using CodeQL to cover >250 vulnerability types.",
      "DeepDevVuln (fine-tuned CodeBERT) achieves precision 58.87% and recall 63.00% (F1 60.87%) on GitHub PR vulnerabilities dataset, while text-davinci-003 zero-shot attains recall 78.00% with precision 46.99%.",
      "On four established benchmark datasets, the approach 'improves recall up to 10% and precision up to 8%.'",
      "On a variant of Pearce et al.'s high-risk scenarios benchmark, 'Evaluation ... shows a reduction of up to 90% vulnerability reduction.'",
      "Real-world deployment in a VSCode extension shows '80% reduction in rate of vulnerability in code edited with the extension.'"
    ]
  },
  {
    "arxiv_id": "2304.14359v1",
    "title": "Measuring and Modeling the Free Content Web",
    "authors": "Abdulrahman Alabduljabbar; Runyu Ma; Ahmed Abusnaina; Rhongho Jang; Songqing Chen; DaeHun Nyang; and David Mohaisen",
    "abstract": "Free content websites that provide free books, music, games, movies, etc., have existed on the Internet for many years. While it is a common belief that such websites might be different from premium websites providing the same content types, an analysis that supports this belief is lacking in the literature. In particular, it is unclear if those websites are as safe as their premium counterparts. In this paper, we set out to investigate, by analysis and quantification, the similarities and differences between free content and premium websites, including their risk profiles. To conduct this analysis, we assembled a list of 834 free content websites offering books, games, movies, music, and software, and 728 premium websites offering content of the same type. We then contribute domain-, content-, and risk-level analysis, examining and contrasting the websites' domain names, creation times, SSL certificates, HTTP requests, page size, average load time, and content type. For risk analysis, we consider and examine the maliciousness of these websites at the website- and component-level. Among other interesting findings, we show that free content websites tend to be vastly distributed across the TLDs and exhibit more dynamics with an upward trend for newly registered domains. Moreover, the free content websites are 4.5 times more likely to utilize an expired certificate, 19 times more likely to be malicious at the website level, and 2.64 times more likely to be malicious at the component level. Encouraged by the clear differences between the two types of websites, we explore the automation and generalization of the risk modeling of the free content risky websites, showing that a simple machine learning-based technique can produce 86.81\\% accuracy in identifying them.",
    "published_date": "2023-04-26",
    "pdf_link": "https://arxiv.org/pdf/2304.14359v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Web Security",
      "subdomain": "Malicious Website Detection and Web Risk Measurement",
      "specific_problem": "Measuring and modeling the security risks of free-content websites compared to premium websites; automated identification of risky free-content sites using domain- and content-level features",
      "attack_types": [
        "malicious website (page-level) presence",
        "malicious component (file-level) presence",
        "malvertising and redirection-based risks",
        "data leakage via third-party ads",
        "exploitation via outdated/unpatched components",
        "use of invalid/expired SSL certificates",
        "PUP/malware distribution (contextualized in related work)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Classical ML (unspecified classifier)",
        "specific": null,
        "novel_contribution": "Risk modeling of free-content websites using easy-to-obtain domain- and content-level features; reports 86.81% accuracy for identifying risky websites"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Curated Free vs Premium Websites Dataset (Books, Games, Movies, Music, Software)",
        "type": "private",
        "domain": "web_content",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "VirusTotal API detections (URL/file scanning results)",
        "type": "public",
        "domain": "url_reputation",
        "link": "https://www.virustotal.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Sucuri API detections (website security scan results)",
        "type": "public",
        "domain": "web_security_scan",
        "link": "https://sucuri.net/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Detection rate (page-level maliciousness)",
      "Detection rate (file/component-level maliciousness)",
      "Relative risk ratio (times more likely)",
      "TLD distribution",
      "SSL certificate validity rates (unmatched/expired/invalid)",
      "HTTP request counts",
      "Page size (MB)",
      "Page load time (seconds)",
      "Content-type distribution (images, scripts, fonts, HTML, CSS, XHR, redirects)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Are free content websites different from premium websites delivering the same type of content?",
        "Do free content websites differ in their structure, content, and security properties from premium websites?",
        "Do free content websites come with a hidden cost to users, outweighing the perceived benefits (i.e., being free)?"
      ],
      "gaps_identified": [
        "Lack of prior analysis comparing free-content vs premium websites in terms of structure, content, and risk profiles.",
        "Validity/state of websites’ certificates and TLS configuration is underexplored in the literature.",
        "The interplay between advertisements on websites and associated maliciousness is crucial yet underexplored."
      ],
      "limitations": [],
      "future_work": [
        "Further exploration of premium websites detected as malicious: “the discovery of premium websites detected as malicious is quite interesting and calls for further exploration.”"
      ],
      "motivation": "Quantitatively assess and contrast domain-, content-, and risk-level characteristics of free content websites versus premium counterparts, and explore automated risk modeling.",
      "potential_research_ideas": [
        "Develop a comprehensive benchmark dataset of free vs premium websites with labeled page- and file-level ground truth over time (including ad/redirect chains).",
        "Study the causal link between advertising/redirect ecosystems and maliciousness on free-content sites using ad network telemetry and dynamic instrumentation.",
        "Temporal modeling of domain churn and cert refresh behaviors (e.g., sequence models) to predict imminent risk and blacklist evasion.",
        "Incorporate certificate transparency logs and passive DNS to forecast risky domain migrations across TLDs.",
        "Robust and explainable classifiers that highlight which domain/content features most contribute to risk to aid operators and end-user warnings.",
        "Cross-validation across geographies and categories to assess generalization and detection blind spots.",
        "Evaluate defenses that combine browser-side signals (e.g., redirect depth, script density) with server-side scans in real time."
      ],
      "architectural_improvement_recommendations": [
        "Augment features with dynamic behaviors: redirect chain depth, third-party domain graph metrics, script entropy/obfuscation scores.",
        "Use ensembles (e.g., gradient boosting + calibrated logistic regression) and probability calibration for risk scoring.",
        "Graph-based modeling of third-party resource relationships (GNNs over domain-resource graphs) to capture malvertising infrastructure.",
        "Leverage semi-supervised learning or PU-learning to handle label noise/coverage limits from VirusTotal/Sucuri.",
        "Incorporate time-based features (domain age, cert renewal cadence) and drift detection to maintain performance against evasion.",
        "Adopt explainability techniques (SHAP/LIME) to interpret predictions for operators and users."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PyWebCopy"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "High domain/TLD churn by free-content sites to evade blacklisting.",
        "Extensive use of redirection and scripts (malvertising) that can affect measurement consistency and risk.",
        "Prevalence of invalid/expired SSL certificates on free-content sites complicates trust and automated enforcement."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Free Content Websites Curation: 1,562 websites (834 free content, 728 premium) across books, games, movies, music, software; crawled with associated files and attributes.",
      "Domain-level Analysis: TLD distribution, creation dates, SSL certificate validity; free sites exhibit wider TLD spread and more domain dynamics; “free content websites are 4.5 times more likely to utilize an expired certificate.”",
      "Content-level Analysis: HTTP requests, page size, load time, and content types; premium sites have more/larger images; free sites use more scripts and redirection leading to comparable load times despite smaller sizes.",
      "Risk Analysis: Using VirusTotal and Sucuri, free sites are 19× more likely to be malicious at website/page level (38% vs 2%) and 2.64× at component/file level (45% vs 17%).",
      "Risk Modeling: A simple ML-based technique using domain and content features achieves “86.81% accuracy in identifying” risky free-content websites."
    ]
  },
  {
    "arxiv_id": "2305.09740v1",
    "title": "Four Factor Authentication with emerging cybersecurity for Mobile Transactions",
    "authors": "Sanyam Jain; Raju gautam; Shivani Sharma; Ravi Tomar",
    "abstract": "Cybersecurity is very essential for Mobile Transactions to complete seamlessly. Mobile Commerce (Mcom.) is the very basic transaction type, which is very commonly used (2 in 5 people uses mobile as transaction medium), To secure this there are various technologies used by this research. The four factors formally known as Multi-Factor-Authentication are: two of them are Traditional methods (User Login-password and One Time Password (aka OTP)) with addition of Geolocation and Facial Recognition. All the data is converted to a text file, which is hidden in an image (using Babushka algorithm). The end-point then decrypts the image using same algorithm.",
    "published_date": "2023-05-16",
    "pdf_link": "https://arxiv.org/pdf/2305.09740v1",
    "paper_types": [
      "position",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "Authentication and Access Control",
      "specific_problem": "Multi-factor authentication for mobile transactions combining password, SMS OTP, geolocation, and facial recognition with steganographic and cryptographic protection of authentication payloads",
      "attack_types": [
        "SIM swap/SMS interception",
        "Man-in-the-Middle (MITM) on SMS",
        "Phishing of credentials",
        "Brute force",
        "Rainbow table attacks",
        "Social engineering"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Haar Cascade (Viola-Jones) face detection/recognition via OpenCV",
        "specific": "OpenCV Haar Cascade (trained XML cascade)",
        "novel_contribution": "Use of OpenCV-based facial recognition as one factor within a 4-factor mobile transaction authentication pipeline; mentions training with positive/negative images to produce an XML cascade."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Face image dataset for training cascade (unnamed)",
        "type": "private",
        "domain": "face_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "transaction_time",
      "computational_complexity"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Conventional 2FA (password + SMS OTP) is vulnerable to SIM compromise and MITM interception of SMS.",
        "Passwords are susceptible to social engineering, brute force, and rainbow table attacks.",
        "Mobile-transaction security often relies solely on the mobile phone, creating single-point-of-failure risks.",
        "Lack of additional contextual/authentication factors such as geolocation and biometrics in many deployments."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Increase security of mobile transactions by extending 2FA with geolocation and facial recognition and protecting transmitted authentication data via steganography and cryptography.",
      "potential_research_ideas": [
        "Integrate liveness detection and presentation-attack detection (e.g., blink/3D depth, rPPG) to harden facial recognition against spoofing.",
        "Replace SMS OTP with phishing-resistant factors (FIDO2/WebAuthn, passkeys, or TOTP/push-based authenticator) to address SIM/MITM risks.",
        "Adopt deep learning face recognition (e.g., FaceNet/ArcFace/MobileFaceNet) with on-device templates for better accuracy and privacy.",
        "Introduce risk-based adaptive authentication that scores context (device fingerprinting, network signals, location anomaly) to trigger step-up factors.",
        "Evaluate and formalize the steganographic channel’s security; compare against standard secure transport with digital signatures (TLS + detached signature).",
        "Add geolocation integrity checks (sensor fusion, tamper/anti-spoof, anomaly detection) to mitigate GPS spoofing/VPN/relay attacks.",
        "End-to-end cryptographic binding of factors to the transaction (signing the payment intent) to prevent replay and relay attacks.",
        "Privacy-preserving biometrics (template protection, cancelable biometrics, secure enclaves/TEE) and regulatory compliance (GDPR).",
        "Comprehensive empirical evaluation with usability studies (latency/usability trade-offs) and attack simulations."
      ],
      "architectural_improvement_recommendations": [
        "Use on-device secure enclave/TEE for biometric capture/matching; store only protected templates (e.g., Bloom filter/cancelable biometrics).",
        "Swap SMS OTP with cryptographic hardware-backed authentication (FIDO2/WebAuthn) and bind authenticator to relying party origin.",
        "Replace/augment Haar cascades with lightweight CNN-based face verification models (MobileFaceNet) and add liveness detection.",
        "Bind geolocation and biometric factors cryptographically to the transaction payload (transaction hash) and sign with device keys.",
        "Use standard secure transport (TLS 1.3) with message authentication/signatures; if steganography is retained, add formal threat model and robustness evaluation.",
        "Implement risk-based scoring engine and policy framework to dynamically require additional factors.",
        "Log and audit all factor outcomes with secure telemetry; add anomaly detection over historical user behavior."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/samy280497/Matroschka",
      "frameworks": [
        "Python",
        "OpenCV",
        "PyQt4",
        "Pillow",
        "Twilio API",
        "Google Geolocation API",
        "Android"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "Not specified. Reported end-user transaction time ~30 seconds; bank server complexity stated as O(n)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Bank gateway/server-side program with mobile client (Android app) invoking geolocation and camera; merchant side decodes payload.",
      "scalability_discussed": true,
      "inference_time": "~30 seconds per complete transaction (as reported).",
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a four-factor authentication (username/password, SMS OTP, geolocation, facial recognition) for mobile transactions.",
      "Introduces a pipeline that converts collected factors to text and embeds them into an image using a Matryoschka/Babushka steganography approach with HMAC-SHA256 and XTEA for confidentiality/integrity.",
      "Implements facial recognition with OpenCV and a trained XML cascade; integrates Twilio for OTP and Google Geolocation API for location factor.",
      "Provides prototype commands and tooling (Python, Pillow, decode/encode scripts) and reports end-user transaction time (~30 seconds)."
    ]
  },
  {
    "arxiv_id": "2305.06947v3",
    "title": "Watch This Space: Securing Satellite Communication through Resilient Transmitter Fingerprinting",
    "authors": "Joshua Smailes; Sebastian Köhler; Simon Birnbach; Martin Strohmeier; Ivan Martinovic",
    "abstract": "Due to an increase in the availability of cheap off-the-shelf radio hardware, spoofing and replay attacks on satellite ground systems have become more accessible than ever. This is particularly a problem for legacy systems, many of which do not offer cryptographic security and cannot be patched to support novel security measures.   In this paper we explore radio transmitter fingerprinting in satellite systems. We introduce the SatIQ system, proposing novel techniques for authenticating transmissions using characteristics of transmitter hardware expressed as impairments on the downlinked signal. We look in particular at high sample rate fingerprinting, making fingerprints difficult to forge without similarly high sample rate transmitting hardware, thus raising the budget for attacks. We also examine the difficulty of this approach with high levels of atmospheric noise and multipath scattering, and analyze potential solutions to this problem.   We focus on the Iridium satellite constellation, for which we collected 1705202 messages at a sample rate of 25 MS/s. We use this data to train a fingerprinting model consisting of an autoencoder combined with a Siamese neural network, enabling the model to learn an efficient encoding of message headers that preserves identifying information.   We demonstrate the system's robustness under attack by replaying messages using a Software-Defined Radio, achieving an Equal Error Rate of 0.120, and ROC AUC of 0.946. Finally, we analyze its stability over time by introducing a time gap between training and testing data, and its extensibility by introducing new transmitters which have not been seen before. We conclude that our techniques are useful for building systems that are stable over time, can be used immediately with new transmitters without retraining, and provide robustness against spoofing and replay by raising the required budget for attacks.",
    "published_date": "2023-05-11",
    "pdf_link": "https://arxiv.org/pdf/2305.06947v3",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Satellite Security",
      "subdomain": "Physical-layer Authentication / Transmitter Fingerprinting",
      "specific_problem": "Authenticate downlinked satellite transmissions (Iridium) and detect spoofing/replay via hardware-induced RF impairments at high sample rates",
      "attack_types": [
        "spoofing",
        "replay",
        "wormhole",
        "timing attacks (e.g., GNSS replay)",
        "overshadowing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": null,
        "novel_contribution": "Learns an efficient encoding of high-sample-rate message headers preserving transmitter-identifying information for fingerprint extraction"
      },
      {
        "type": "primary",
        "category": "Siamese Network (Metric Learning)",
        "specific": null,
        "novel_contribution": "Compares pairs of encoded signals to produce a similarity/distance score enabling one-shot learning and operation with unseen transmitters without retraining"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "SatIQ Iridium high-sample-rate dataset (1,705,202 messages @ 25 MS/s)",
        "type": "public",
        "domain": "satellite_iq_samples",
        "link": "https://zenodo.org/record/8220494",
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Equal Error Rate (EER)",
      "ROC AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can high sample rate steady-state RF impairments of satellite downlinks be used to reliably authenticate transmitters and resist spoofing/replay?",
        "How robust is such fingerprinting under high atmospheric noise and multipath scattering?",
        "Can a Siamese metric-learning approach enable one-shot operation with new/unseen transmitters without retraining?",
        "How stable are learned fingerprints over time (training–testing time gap)?",
        "What attack budget is required to evade high-sample-rate fingerprinting (e.g., SDR-based replay vs. high-end arbitrary waveform generators)?"
      ],
      "gaps_identified": [
        "Legacy satellites often lack cryptographic authentication and cannot be patched; alternative non-cryptographic authentication is needed.",
        "Some satellites with crypto became insecure post-launch due to leaked keys or outdated cryptosystems; OTA patching may be impossible.",
        "Conventional cryptography does not protect against precise replay/timing attacks that do not alter message contents.",
        "Prior satellite fingerprinting (e.g., low sample rate, batch classification) is less suitable for per-message security and easier to forge at higher sample rates.",
        "High atmospheric noise and multipath in satellite links make many low-noise fingerprinting methods brittle; new methods must cope with noisy channels."
      ],
      "limitations": [
        "Vulnerability to very high-sample-rate forgery: \"It has been demonstrated in [31] that device fingerprinting ... an arbitrary waveform generator with a sufficiently high sample rate can be used to impersonate devices, fooling fingerprinting systems ... although our techniques are likely vulnerable to impersonation at a very high sample rate.\"",
        "Evaluation focuses on one constellation (Iridium); generalization to other satellite systems is not empirically established.",
        "High-rate capture/processing requirements may limit deployment on constrained ground stations without adequate RF front-ends and compute."
      ],
      "future_work": [],
      "motivation": "Provide non-cryptographic, deployment-ready authentication for satellite systems—especially legacy or compromised ones—by raising the adversary’s budget via high-sample-rate RF fingerprinting that is robust to replay and noise.",
      "potential_research_ideas": [
        "Extend SatIQ to other constellations (e.g., GNSS, weather sats) to assess cross-system generalization and required adaptations.",
        "Multi-receiver fusion: combine fingerprints across spatially distributed ground stations to improve robustness and detect wormholes (e.g., joint metric fusion or Bayesian aggregation).",
        "Adversarial robustness against high-end forgers: adversarial training with differentiable RF channel/impairment simulators to harden embeddings.",
        "Self-/contrastive pretraining on large unlabeled IQ corpora to improve data efficiency and stability under channel variability.",
        "Domain adaptation to changing channels (seasonal, atmospheric) via test-time adaptation or domain-adversarial training.",
        "Active physical-layer challenge-response for cooperative satellites by intentional micro-impairment watermarking to bind identity to hardware.",
        "Uncertainty estimation and calibrated thresholds for operational ROC/EER tuning under concept drift.",
        "Automated channel compensation layers (learned equalization, multipath suppression) to separate device impairments from propagation effects."
      ],
      "architectural_improvement_recommendations": [
        "Incorporate channel-invariant embedding learning (e.g., instance normalization on IQ, learnable equalizers, or adversarial domain confusion vs. SNR/multipath labels).",
        "Adopt contrastive losses (e.g., NT-Xent/InfoNCE) with hard negative mining to sharpen Siamese discrimination.",
        "Use 1D/2D CNNs or complex-valued neural layers tailored for IQ data within the autoencoder to better capture high-frequency impairments.",
        "Augment training with realistic channel models (Rayleigh/Rician fading, Doppler, AWGN, non-linear PA) and replay artifacts to improve robustness.",
        "Calibrate decision thresholds per-ground-station via ROC optimization and deploy score normalization (e.g., Z-norm/T-norm).",
        "Enable continual learning to add new transmitters without catastrophic forgetting (e.g., prototypical memory or episodic rehearsal)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/ssloxford/SatIQ",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Satellite ground station / enterprise ground system",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High atmospheric noise and multipath scattering in satellite links may obscure device-specific impairments.",
        "Requirement for high-sample-rate capture chains (RF front-end, ADC, storage) increases deployment cost/complexity.",
        "Potential for sophisticated attackers with very high-sample-rate arbitrary waveform generators to forge fingerprints.",
        "Per-station calibration and threshold tuning under varying SNR and Doppler."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces SatIQ, a high-sample-rate steady-state transmitter fingerprinting system for satellite downlinks using an autoencoder + Siamese neural network.",
      "Releases a large Iridium IQ dataset: \"We collected 1 705 202 messages at a sample rate of 25 MS/s.\" Publicly available on Zenodo.",
      "Demonstrates robustness to SDR-based replay: \"achieving an Equal Error Rate of 0.120, and ROC AUC of 0.946.\"",
      "Shows stability over time (train–test time gap) and extensibility to unseen transmitters (one-shot operation without retraining).",
      "Argues and analyzes how high sample rate raises attacker budget, making forgery harder compared to low-sample-rate methods.",
      "Provides code and model weights for reproducibility and adoption."
    ]
  },
  {
    "arxiv_id": "2306.06764v1",
    "title": "IoT-AD: A Framework To Detect Anomalies Among Interconnected IoT Devices",
    "authors": "Hasniuj Zahan; Md Washik Al Azad; Ihsan Ali; Spyridon Mastorakis",
    "abstract": "In an Internet of Things (IoT) environment (e.g., smart home), several IoT devices may be available that are interconnected with each other. In such interconnected environments, a faulty or compromised IoT device could impact the operation of other IoT devices. In other words, anomalous behavior exhibited by an IoT device could propagate to other devices in an IoT environment. In this paper, we argue that mitigating the propagation of the anomalous behavior exhibited by a device to other devices is equally important to detecting this behavior in the first place. In line with this observation, we present a framework, called IoT Anomaly Detector (IoT-AD), that can not only detect the anomalous behavior of IoT devices, but also limit and recover from anomalous behavior that might have affected other devices. We implemented a prototype of IoT-AD, which we evaluated based on open-source IoT device datasets as well as through real-world deployment on a small-scale IoT testbed we have built. We have further evaluated IoT-AD in comparison to prior relevant approaches. Our evaluation results show that IoT-AD can identify anomalous behavior of IoT devices in less than 2.12 milliseconds and with up to 98% of accuracy.",
    "published_date": "2023-06-11",
    "pdf_link": "https://arxiv.org/pdf/2306.06764v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Anomaly/Intrusion Detection",
      "specific_problem": "Detecting packet-level and device interaction anomalies in interconnected IoT environments and mitigating propagation via rollback to last known stable states",
      "attack_types": [
        "Device malfunction (software and hardware)",
        "Compromised IoT device",
        "Botnet-related compromise (Mirai example)",
        "Anomaly propagation across devices"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Signature-based / Rule-based",
        "specific": "Packet-level signature matching and device interaction validation rules",
        "novel_contribution": "Combines packet-level anomaly signatures with interaction validation and a rollback mechanism to revert affected devices to last stable states"
      }
    ],
    "learning_paradigm": [],
    "datasets": [
      {
        "name": "Open-source IoT device datasets (unspecified)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Small-scale IoT testbed traces (this paper)",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Homonit",
        "paper_reference": "[5]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "IoT-Praetor",
        "paper_reference": "[7]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "HAWatcher",
        "paper_reference": "[8]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "PingPong",
        "paper_reference": "[10]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Yamauchi et al. system (event-sequence-based anomaly detection and packet dropping)",
        "paper_reference": "[27]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "detection latency (milliseconds)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can we realize a framework that detects packet-level anomalies and anomalies related to the interactions among IoT devices?",
        "How can such a framework enable affected IoT devices to recover from propagated anomalies and revert to their last known stable state as if the detected anomalies had never occurred?"
      ],
      "gaps_identified": [
        "Prior work focused on detection but did not investigate mechanisms to mitigate effects of anomalies that propagate among IoT devices.",
        "Existing frameworks did not enable affected IoT devices to recover from propagated anomalies and revert to their last known stable state."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "In interconnected IoT environments, anomalies from one device can propagate to others; mitigating propagation and enabling recovery is as important as detection.",
      "potential_research_ideas": [
        "Develop a graph-based causal inference model to learn and predict cross-device interaction cascades and proactively block harmful propagation.",
        "Augment IoT-AD with online/continual learning to adapt packet-level signatures and interaction rules to evolving device firmware and behaviors.",
        "Create a standardized, open benchmark of interaction anomaly scenarios across heterogeneous IoT protocols with labeled propagation graphs.",
        "Incorporate probabilistic reasoning or Bayesian networks for uncertainty-aware rollback decisions when multiple devices are affected.",
        "Integrate privacy-preserving telemetry (e.g., sketching, differential privacy) to enable cloud-assisted model sharing without exposing raw traffic.",
        "Adversarial robustness evaluation of interaction validator against mimicry and traffic-shaping attacks; design robust features beyond simple packet headers.",
        "Extend rollback with safety policies and human-in-the-loop approvals for high-risk actuations (e.g., door locks, windows)."
      ],
      "architectural_improvement_recommendations": [
        "Model device interactions as a dynamic directed graph and apply temporal GNNs to detect anomalous subgraph patterns indicating propagation.",
        "Replace static packet-level signatures with hybrid models: lightweight sequence models (e.g., HMM/GRU) for packet header time-series combined with rule checks.",
        "Add confidence scoring and ensemble detectors (signature + statistical time-series + learned interaction constraints) to reduce false positives.",
        "Implement a policy engine using a declarative language (e.g., P4-like or Datalog rules) to specify acceptable interactions and rollback priorities.",
        "Introduce checkpointing/versioning of device states with transactional rollback to ensure atomic recovery across multiple devices.",
        "Edge-cloud split: run real-time detection at the controller, offload periodic retraining or rule synthesis to the cloud when privacy policies allow."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Reported as light-weight; detection in less than 2.12 ms per event/device anomaly. No hardware/GPU details provided."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Small-scale smart home IoT testbed with a controller (e.g., smart hub/router/edge device) mediating device interactions",
      "scalability_discussed": false,
      "inference_time": "“less than 2.12 milliseconds”",
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Design of IoT-AD to detect packet-level anomalies and interaction anomalies among IoT devices, maintain device states, and enable recovery from propagated anomalies.",
      "Prototype implementation evaluated on open-source datasets and a real-world testbed; comparison to prior approaches; results show identification of anomalies in less than 2.12 ms with up to 98% accuracy."
    ]
  },
  {
    "arxiv_id": "2305.09476v1",
    "title": "ANALYSE -- Learning to Attack Cyber-Physical Energy Systems With Intelligent Agents",
    "authors": "Thomas Wolgast; Nils Wenninghoff; Stephan Balduin; Eric Veith; Bastian Fraune; Torben Woltjen; Astrid Nieße",
    "abstract": "The ongoing penetration of energy systems with information and communications technology (ICT) and the introduction of new markets increase the potential for malicious or profit-driven attacks that endanger system stability. To ensure security-of-supply, it is necessary to analyze such attacks and their underlying vulnerabilities, to develop countermeasures and improve system design. We propose ANALYSE, a machine-learning-based software suite to let learning agents autonomously find attacks in cyber-physical energy systems, consisting of the power system, ICT, and energy markets. ANALYSE is a modular, configurable, and self-documenting framework designed to find yet unknown attack types and to reproduce many known attack strategies in cyber-physical energy systems from the scientific literature.",
    "published_date": "2023-04-21",
    "pdf_link": "https://arxiv.org/pdf/2305.09476v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Critical Infrastructure Security",
      "subdomain": "Industrial Control Systems (ICS) / Power Grid Security",
      "specific_problem": "Discovering and analyzing attack strategies and systemic vulnerabilities in cyber-physical energy systems (power grid + ICT + energy markets) using learning agents",
      "attack_types": [
        "false data injection (FDI)",
        "denial-of-service (DoS)",
        "market manipulation/market gaming",
        "voltage band violation",
        "blackout-inducing attacks",
        "data manipulation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": null,
        "novel_contribution": "Co-simulation RL environment spanning power grid, market, and ICT to let agents discover unknown attack strategies; modular, configurable, self-documenting training via palaestrAI + MIDAS + mosaik"
      },
      {
        "type": "primary",
        "category": "Deep Reinforcement Learning",
        "specific": null,
        "novel_contribution": "Framework supports DRL agents acting across multiple coupled simulators; designed to scale beyond simplified single-domain scenarios"
      },
      {
        "type": "baseline",
        "category": "Rule-based/Heuristic Agents",
        "specific": "Non-learning market participants (to create competition in the reactive power market)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Neuroevolution",
        "specific": null,
        "novel_contribution": "Supported by palaestrAI, though not emphasized in the illustrative example"
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Deep Reinforcement Learning",
      "Neuroevolution"
    ],
    "datasets": [
      {
        "name": "Publicly available load profiles",
        "type": "public",
        "domain": "power_system_time_series",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Public weather data (for PV model inputs)",
        "type": "public",
        "domain": "weather_time_series",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How much can profit on the energy market be increased when we apply false data injection at point xy in the system?",
        "How much of the ICT needs to be compromised by an attacker to create a blackout?"
      ],
      "gaps_identified": [
        "Most prior work models and evaluates CPES layers (physical, ICT, functional/market) separately, missing interdependencies.",
        "Over-simplified scenarios and too-limited action spaces restrict agents’ ability to find novel strategies, risking a false sense of security.",
        "OPF-based market simulators are computationally heavy for DRL training (thousands to millions of iterations), impeding scalable learning-based analysis.",
        "Unknown/zero-day-like attack vectors are most relevant yet underserved by existing methods focused on predictable or known strategies."
      ],
      "limitations": [
        "Currently focuses on a single learning attacker agent.",
        "Market model is non-OPF-based to reduce computation, potentially reducing economic realism.",
        "rettij does not simulate specific network technologies (e.g., cellular/WiFi) and instead uses a general MAC-layer abstraction.",
        "Paper presents a software artifact with an illustrative example; no quantitative benchmark or comparative evaluation is provided."
      ],
      "future_work": [
        "Enable multi-agent systems (multiple attackers) and add defender agents to analyze their interplay (adversarial resilience learning).",
        "Add more domains/simulators (e.g., gas system, balancing power market) to broaden CPES coverage.",
        "Reproduce existing single-domain studies within a unified multi-domain co-simulation and increase scenario complexity.",
        "Use the tool-suite to derive countermeasures and improve system design based on discovered vulnerabilities."
      ],
      "motivation": "Rising complexity and ICT penetration in energy systems increase attack surfaces and potential for catastrophic attacks; need tools that discover unknown attack vectors in realistic, interconnected CPES to inform defenses and design.",
      "potential_research_ideas": [
        "Develop defender agents and study attacker–defender dynamics using adversarial resilience learning across power, ICT, and market layers.",
        "Introduce partial observability and deception (e.g., stealthy FDI with detection-aware rewards) to explore advanced, realistic attack strategies.",
        "Integrate differentiable or surrogate OPF to enable learning in realistic market-clearing setups at DRL timescales.",
        "Automate scenario generation with design-of-experiments to systematically surface edge-case vulnerabilities across domain couplings.",
        "Extract and formalize discovered strategies into attack taxonomies and detection signatures for SIEM integration.",
        "Use interpretable/safe RL to produce attack policies amenable to operator understanding and red-teaming exercises.",
        "Meta-RL or transfer learning to generalize attack strategies across grids, topologies, and market rules.",
        "Stress-test resilience under varying ICT degradations (latency, loss) and correlate with physical impacts and market outcomes."
      ],
      "architectural_improvement_recommendations": [
        "Add native support for multi-agent RL with centralized training and decentralized execution (CTDE) to handle attacker/defender populations.",
        "Provide pluggable DRL backends (e.g., PyTorch/TensorFlow via Stable-Baselines3, Ray RLlib) for broader algorithm coverage (PPO, SAC, DDPG).",
        "Integrate a fast OPF surrogate (e.g., learned neural surrogate or reduced-order OPF) or differentiable optimization for reactive power markets.",
        "Extend rettij with optional emulation profiles for specific access technologies (e.g., 5G, WiFi) and realistic traffic generators.",
        "Add formal specification and verification hooks (temporal logic monitors) to detect safety/property violations during training.",
        "Provide built-in reward shaping templates and curriculum learning to guide exploration toward rare, high-impact events.",
        "Expose standardized observation/action schemas and scenario packs to facilitate benchmarking and reproducible comparisons."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/stbalduin/pyrate-analyse",
      "frameworks": [
        "Python",
        "palaestrAI",
        "arsenAI",
        "MIDAS",
        "mosaik",
        "pandapower",
        "rettij",
        "Docker",
        "Kubernetes",
        "Elasticsearch",
        "Kibana"
      ],
      "reproducibility_score": "high",
      "computational_requirements": "Runs on Unix systems (Linux/macOS). Requires a Kubernetes cluster with at least one node. No specific GPU requirements stated."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Research co-simulation on Kubernetes cluster; coupled simulators (power grid, ICT, market) with Elastic stack for logging.",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Co-simulation orchestration and synchronization overhead across multiple simulators.",
        "Computational burden of realistic market clearing (OPF) incompatible with DRL-scale iterations without surrogates.",
        "Need for realistic ICT emulation profiles beyond generic MAC abstraction.",
        "Complex configuration and reward design to avoid misleading conclusions.",
        "Cluster requirement (Kubernetes) and container orchestration complexity."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "“ANALYSE is the first open-source tool-suite that combines power grid, energy market, and ICT infrastructure into one coupled simulation to analyze them regarding vulnerabilities.”",
      "Modular, configurable, and self-documenting co-simulation framework enabling learning agents to access sensors and actuators across power, market, and ICT domains.",
      "Introduces palaestrAI + arsenAI for reproducible, large-scale RL experimentation with YAML run files and design-of-experiments.",
      "Provides MIDAS to assemble mosaik-based co-simulations into RL environments with defined actions, observations, and rewards.",
      "Implements a non-OPF reactive power market simulator suitable for DRL-scale training and basic non-learning competitor agents.",
      "Integrates rettij ICT simulator with agent-accessible sensors/actuators and Elastic stack logging for cross-domain event correlation.",
      "Illustrative example demonstrating multi-domain attack surface (market bids over ICT impacting power grid voltage control)."
    ]
  },
  {
    "arxiv_id": "2310.10778v1",
    "title": "Is there a Trojan! : Literature survey and critical evaluation of the latest ML based modern intrusion detection systems in IoT environments",
    "authors": "Vishal Karanam",
    "abstract": "IoT as a domain has grown so much in the last few years that it rivals that of the mobile network environments in terms of data volumes as well as cybersecurity threats. The confidentiality and privacy of data within IoT environments have become very important areas of security research within the last few years. More and more security experts are interested in designing robust IDS systems to protect IoT environments as a supplement to the more traditional security methods. Given that IoT devices are resource-constrained and have a heterogeneous protocol stack, most traditional intrusion detection approaches don't work well within these schematic boundaries. This has led security researchers to innovate at the intersection of Machine Learning and IDS to solve the shortcomings of non-learning based IDS systems in the IoT ecosystem.   Despite various ML algorithms already having high accuracy with IoT datasets, we can see a lack of sufficient production grade models. This survey paper details a comprehensive summary of the latest learning-based approaches used in IoT intrusion detection systems, and conducts a thorough critical review of these systems, potential pitfalls in ML pipelines, challenges from an ML perspective, and discusses future research scope and recommendations.",
    "published_date": "2023-06-14",
    "pdf_link": "https://arxiv.org/pdf/2310.10778v1",
    "paper_types": [
      "empirical_analysis",
      "survey"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Machine Learning-based intrusion detection systems for IoT environments with critical evaluation of techniques, datasets, and pitfalls",
      "attack_types": [
        "DDoS/DoS",
        "Spoofing",
        "Sinkhole",
        "RPL topology attacks",
        "Man-in-the-Middle",
        "Service scan",
        "Port scan (portsweep)",
        "IP sweep",
        "Nmap scanning",
        "R2L (Remote to Local)",
        "U2R (User to Root)",
        "Virus",
        "Worms",
        "Trojans",
        "Botnets (Mirai, Gafgyt, Bashlite, Okiru/Okiruk, Torii)",
        "Zero-day attacks"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "ANN/MLP",
        "specific": "3-layer MLP with unipolar sigmoid",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "C5.0",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "One-Class SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "SVM (binary/multiclass)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Mixture Model",
        "specific": "Beta Mixture Model (BMM)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Kernel Methods",
        "specific": "Correntropy-based model",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Selection",
        "specific": "Correlation-based attribute selection",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble/Hybrid",
        "specific": "Hybrid IDS combining C5.0 DT and One-Class SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree + Rules",
        "specific": "REP Tree, JRip, Forest PA (RDTIDS)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Selection",
        "specific": "CST-GR (lightweight feature selection)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": "RF",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Dimensionality Reduction",
        "specific": "PCA",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Clustering",
        "specific": "Fuzzy C-Means (semi-supervised)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoencoder",
        "specific": "Deep Autoencoder",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "VAE",
        "specific": "Conditional VAE (CVAE)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN+RNN (Hybrid)",
        "specific": "HCRNNIDS (hybrid convolutional recurrent network)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GAN",
        "specific": "BiGAN (Bidirectional GAN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoencoder (Adversarial)",
        "specific": "Adversarial Autoencoder (AAE)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "1D/2D/3D CNN with transfer learning",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Semi-supervised",
      "Deep Learning",
      "Hybrid"
    ],
    "datasets": [
      {
        "name": "ADFA",
        "type": "public",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IoTID20",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-IDS-2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "BoT-IoT (Bot-IoT)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IoT-BoT (IoT Botnet dataset)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "BoTNeTIoT-L01",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CSE-CIC-IDS2018",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IoT-23",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IoT Network Intrusion",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MQTT-IoT-IDS2020",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Hybrid IDS (C5.0 Decision Tree + One-Class SVM)",
        "paper_reference": "Khraisat et al.",
        "metric": "Accuracy (ADFA)",
        "their_result": "97.40%",
        "baseline_result": null
      },
      {
        "method_name": "ANN with 3-layer MLP (stochastic learning)",
        "paper_reference": "Hodo et al.",
        "metric": "Accuracy (simulated IoT network)",
        "their_result": "99.4%",
        "baseline_result": null
      },
      {
        "method_name": "Correlation-based feature selection + ANN",
        "paper_reference": "Thaseen et al.",
        "metric": "Accuracy (NSL-KDD, UNSW-NB15)",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "IoT-IDM (Logistic Regression + SVM with SDN)",
        "paper_reference": "Nobakht et al.",
        "metric": "Anomaly detection performance",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "IoTBoT-IDS (BMM + Correntropy)",
        "paper_reference": "Ashraf et al.",
        "metric": "Performance on 3 realistic IoT datasets",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "MidSiot (3-stage distributed IDS)",
        "paper_reference": "Nguyen, Ninh and Hung",
        "metric": "Accuracy (IoTID20, CIC-IDS-2017, BoT-IoT)",
        "their_result": "99.68%",
        "baseline_result": null
      },
      {
        "method_name": "RDTIDS (REP Tree, JRip, Forest PA)",
        "paper_reference": "Ferrag et al.",
        "metric": "Accuracy (CIC-IDS-2017, BoT-IoT)",
        "their_result": ">96%",
        "baseline_result": null
      },
      {
        "method_name": "CST-GR feature selection + J48/RF",
        "paper_reference": "Soe et al.",
        "metric": "TPR (accuracy proxy)",
        "their_result": "99.4% (with J48/RF)",
        "baseline_result": null
      },
      {
        "method_name": "Neural immune-inspired model",
        "paper_reference": "Aldhaheri et al.",
        "metric": "Accuracy (IoT-BoT dataset)",
        "their_result": "98.73%",
        "baseline_result": null
      },
      {
        "method_name": "CVAE for unsupervised anomaly detection",
        "paper_reference": "Lopez-Martin et al.",
        "metric": "Accuracy",
        "their_result": "≈99%",
        "baseline_result": null
      },
      {
        "method_name": "Deep Autoencoder (ReLU hidden layers)",
        "paper_reference": "Apostol et al.",
        "metric": "Accuracy; Precision (Bot-IoT)",
        "their_result": "Accuracy 99.7%; Precision 99%",
        "baseline_result": null
      },
      {
        "method_name": "HCRNNIDS (hybrid CNN+RNN)",
        "paper_reference": "Khan M.A.",
        "metric": "Accuracy (CSE-CIC-IDS2018, 10-fold CV)",
        "their_result": "up to 97.75%",
        "baseline_result": null
      },
      {
        "method_name": "AAE and BiGAN (generative deep learning)",
        "paper_reference": "Abdalgawad et al.",
        "metric": "F1-score (IoT-23); Zero-day F-score",
        "their_result": "F1 = 0.99; Zero-day F-score 0.85–1.0",
        "baseline_result": null
      },
      {
        "method_name": "1D/2D/3D CNN + transfer learning",
        "paper_reference": "Ullah and Mahmoud",
        "metric": "Detection rate (various IoT datasets)",
        "their_result": "1D: 99.74%; 2D: 99.42%; 3D: 99.03%",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall/TPR",
      "F1-score",
      "Detection rate",
      "False Negative Rate",
      "ROC-AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What are the latest learning-based approaches used in IoT intrusion detection systems?",
        "How do ML-based IDS for IoT perform on IoT-relevant datasets and what pitfalls exist in their ML pipelines?",
        "What challenges arise from an ML perspective for deploying IDS in IoT environments?",
        "What recommendations and future research directions can improve ML-based IoT IDS?"
      ],
      "gaps_identified": [
        "Lack of sufficient production-grade IoT IDS models despite high reported accuracies (>99%) on datasets",
        "Pitfalls in ML pipelines: training data selection, hyperparameter tuning, over/under-sampling, lack of rigid baselines/benchmarks",
        "Lack of standardization on learning approaches and datasets ideal for a generic state-of-the-art IoT IDS",
        "IoT constraints (resource limitations, heterogeneous stacks) limit applicability of traditional IDS and cloud-centric solutions",
        "Privacy and jurisdictional constraints hinder cloud-based data storage/processing for IDS",
        "Latency and cloud security/synchronization challenges for IoT IDS"
      ],
      "limitations": [
        "Survey nature: no unified experimental benchmark or implementation provided by the authors",
        "Relies on reported results across heterogeneous setups and datasets, making direct comparison difficult",
        "Older non-IoT datasets are still used in some works, limiting IoT relevance"
      ],
      "future_work": [
        "Evaluate ML-based IoT IDS models more robustly with up-to-date IoT-specific datasets",
        "Bridge the gap toward production-grade models suitable for real networks under constraints",
        "Standardize datasets, baselines, and evaluation protocols for IoT IDS",
        "Develop hybrid and distributed IDS architectures tailored to resource-constrained IoT"
      ],
      "motivation": "IoT environments face unique security challenges and constraints; while many ML models report high accuracy on datasets, there is a gap in production-grade deployments and standardized evaluation for IoT IDS.",
      "potential_research_ideas": [
        "Create a standardized, IoT-specific benchmarking suite with diverse protocols (e.g., MQTT, CoAP, 6LoWPAN, RPL) and realistic attack mixes, including zero-day scenarios and concept drift",
        "Develop lightweight, on-device (TinyML) IDS models with energy-aware design for microcontrollers and constrained gateways",
        "Design a continual/federated learning framework for IDS enabling privacy-preserving updates and zero-day adaptation across heterogeneous IoT fleets",
        "Investigate graph-based IDS using GNNs over device-communication graphs to capture cross-device attack patterns",
        "Build explainable IDS tailored to operators with feature-attribution and counterfactuals for network flows",
        "Systematically evaluate adversarial robustness of IoT IDS and propose defenses (adversarial training, certified defenses) for network-time-series data",
        "Uncertainty-aware IDS with calibration and abstention for human-in-the-loop triage",
        "Cross-layer IDS correlating host telemetry, SDN controller data, and network flows for improved detection and reduced false positives"
      ],
      "architectural_improvement_recommendations": [
        "Adopt self-supervised pretraining on large unlabeled IoT traffic (contrastive learning on flows/packets) to improve data efficiency",
        "Use transformer-based time-series models with efficient attention (Performer/Linear attention) for long sequences under resource constraints",
        "Incorporate protocol-aware parsers and embeddings (MQTT/CoAP/RPL features) with learned feature selection (e.g., integrate CST-GR as a differentiable module)",
        "Employ edge–cloud split architectures with compressed models (quantization, pruning, distillation) and streaming feature extraction at the edge",
        "Integrate drift detection and online adaptation (e.g., ADWIN, meta-learning for rapid fine-tuning) to maintain performance over time",
        "Add calibrated uncertainty estimation and threshold optimization for imbalanced attack distributions",
        "Standardize training pipelines with strong baselines and ablations: feature sets, sampling strategies, and cross-dataset validation"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Resource-constrained devices (low processing power, memory)",
        "Heterogeneous protocol stacks and hardware",
        "Need for low latency and real-time response",
        "High-volume data processing",
        "Privacy/jurisdiction constraints limiting cloud storage",
        "Cloud synchronization and security risks",
        "High cost of signature matching and database updates",
        "Network packet overload",
        "Susceptibility to DoS when using certain designs"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Classifying IoT IDS on the basis of learning methods and datasets used for evaluation",
      "Discussing the latest works which exclusively use IoT attack trace relevant datasets for evaluation",
      "Critical evaluation of the Machine Learning approaches for the latest works and pitfalls in ML pipelines",
      "Recommendations and further research directions for security researchers utilizing ML in IoT IDS"
    ]
  },
  {
    "arxiv_id": "2306.07249v2",
    "title": "Generalized Power Attacks against Crypto Hardware using Long-Range Deep Learning",
    "authors": "Elie Bursztein; Luca Invernizzi; Karel Král; Daniel Moghimi; Jean-Michel Picod; Marina Zhang",
    "abstract": "To make cryptographic processors more resilient against side-channel attacks, engineers have developed various countermeasures. However, the effectiveness of these countermeasures is often uncertain, as it depends on the complex interplay between software and hardware. Assessing a countermeasure's effectiveness using profiling techniques or machine learning so far requires significant expertise and effort to be adapted to new targets which makes those assessments expensive. We argue that including cost-effective automated attacks will help chip design teams to quickly evaluate their countermeasures during the development phase, paving the way to more secure chips.   In this paper, we lay the foundations toward such automated system by proposing GPAM, the first deep-learning system for power side-channel analysis that generalizes across multiple cryptographic algorithms, implementations, and side-channel countermeasures without the need for manual tuning or trace preprocessing. We demonstrate GPAM's capability by successfully attacking four hardened hardware-accelerated elliptic-curve digital-signature implementations. We showcase GPAM's ability to generalize across multiple algorithms by attacking a protected AES implementation and achieving comparable performance to state-of-the-art attacks, but without manual trace curation and within a limited budget. We release our data and models as an open-source contribution to allow the community to independently replicate our results and build on them.",
    "published_date": "2023-06-12",
    "pdf_link": "https://arxiv.org/pdf/2306.07249v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Side-Channel Analysis",
      "specific_problem": "Automated power side-channel key recovery across cryptographic algorithms (ECC, AES) and countermeasures using deep learning without manual trace preprocessing",
      "attack_types": [
        "power analysis",
        "profiling-based side-channel attack (white-box)",
        "black-box side-channel attack (demonstrated)",
        "lattice-assisted key recovery"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "GAU (Gated Attention Unit) encoder blocks",
        "novel_contribution": "Long-range deep model with temporal patchification + GAU-based Transformer encoder operating on raw power traces; designed to generalize across algorithms/implementations/countermeasures without manual preprocessing"
      },
      {
        "type": "primary",
        "category": "Patchification",
        "specific": "Temporal patchification",
        "novel_contribution": "Handles very long traces (\"up to 16 million samples and up to 1 million points on a public dataset\") efficiently"
      },
      {
        "type": "primary",
        "category": "Multi-task Learning",
        "specific": null,
        "novel_contribution": "Multi-task heads to attack masked implementations and improve convergence/generalization"
      },
      {
        "type": "primary",
        "category": "Activation Function",
        "specific": "Swish",
        "novel_contribution": "Chosen for robustness to countermeasures as suggested by prior work"
      },
      {
        "type": "baseline",
        "category": "Autoencoder + Attention",
        "specific": "Lu et al. 2021 (LZC+21)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Multi-scale CNN (WHJ+21)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Residual Network",
        "specific": "ZS20 alignment/processing",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoencoder",
        "specific": "Noise filtering/jitter handling (WP20)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Classical ML",
        "specific": "SVM, Template attacks",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Multi-task"
    ],
    "datasets": [
      {
        "name": "GPAM power traces datasets (ECC CM0–CM3 and AES)",
        "type": "public",
        "domain": "power_traces",
        "link": "https://github.com/google/scaaml/tree/main/papers/2024/GPAM",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "ASCADv1 (variable key)",
        "type": "public",
        "domain": "power_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CHES 2020 contest side-channel dataset",
        "type": "public",
        "domain": "power_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Lu et al. 2021 autoencoder+attention on raw long traces (LZC+21)",
        "paper_reference": "LZC+21",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "State-of-the-art AES DL SCA with manual trace preprocessing",
        "paper_reference": null,
        "metric": null,
        "their_result": "“achieving comparable performance to state-of-the-art attacks, but without manual trace curation and within a limited budget.”",
        "baseline_result": null
      },
      {
        "method_name": "Template attacks (profiling, CRR03)",
        "paper_reference": "CRR03",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Rank",
      "MaxRank",
      "MeanRank",
      "Confidence (margin between top-2 probabilities)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a single deep-learning architecture generalize across multiple cryptographic algorithms (ECC and AES), implementations, and countermeasures without manual tuning or trace preprocessing?",
        "Can automated, cost-effective profiling attacks be integrated into chip design workflows to quickly evaluate countermeasures?",
        "Can SCAAML-driven lattice attacks recover ECDSA private keys even when scalar blinding has high entropy (∥r∥ ≥ ∥n∥/2) and multi-share masking is used?",
        "How well can models trained on one device generalize to different physical chips and to black-box settings?"
      ],
      "gaps_identified": [
        "Lack of cross-algorithm generality in existing SCAAMLs",
        "Lack of cross-implementation generality; architectures tailored to specific targets",
        "High expertise requirements and manual trace preprocessing",
        "Difficulty processing raw long traces (100k+ samples) directly",
        "Limited portability across physical devices due to device-to-device variations"
      ],
      "limitations": [
        "Evaluated on research implementations, not production devices (Ethics note)",
        "Primary threat model is white-box; black-box only demonstrated in a subsection",
        "ECC evaluation targets recovery of the top 4 MSBs per signature and relies on combining predictions with lattice attacks to recover full keys",
        "Requires access to a clone device for training and a lab measurement setup",
        "Details like exact inference latency and full deployment constraints are not reported in the provided text"
      ],
      "future_work": [
        "Move toward standardization of fully automated side-channel leakage evaluations",
        "Extend to additional algorithms (e.g., RSA) and broader sets of countermeasures",
        "Improve cross-device portability and black-box performance",
        "Further reduce training/hyper-tuning cost and automate adaptation",
        "Incorporate additional side-channel modalities (e.g., EM) for multimodal analysis"
      ],
      "motivation": "Enable cost-effective, automated power side-channel attacks that generalize across algorithms and implementations to help chip design teams quickly evaluate countermeasures and build more secure chips.",
      "potential_research_ideas": [
        "Self-supervised pretraining on large unlabeled power traces to improve data efficiency and cross-device generalization",
        "Multimodal fusion of power and EM traces with shared Transformer backbones",
        "Uncertainty-aware key ranking and adaptive lattice attack strategies leveraging calibrated confidences",
        "Domain adaptation/meta-learning to handle device-to-device variability without retraining",
        "Online/streaming inference for extremely long traces via chunked attention",
        "Automated countermeasure characterization (e.g., predicting masking scheme/parameters) as auxiliary tasks",
        "Explainability tools to localize leakage points and guide hardware fixes"
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment GAU blocks with more efficient long-sequence attention (e.g., Performer/linear attention) for better scaling on 16M+ samples",
        "Hierarchical/segment-level Transformer with cross-segment attention for ultra-long traces",
        "Contrastive or multi-view learning across randomizations/masking shares to disentangle leakage",
        "Calibration layers and temperature scaling to improve confidence reliability for lattice integration",
        "Lightweight student model via knowledge distillation for faster inference in CI loops",
        "Incorporate device-invariant normalization/adversarial domain confusion for portability",
        "Sparse/structured pruning and mixed-precision to reduce memory/compute footprint"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/google/scaaml/tree/main/papers/2024/GPAM",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": "Automated hyper-tuning requires “a few hours of GPU time”. Model supports traces up to 16M samples; GPU strongly recommended."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Lab setting with oscilloscope-collected power traces on hardware crypto co-processors; training on a clone device and holdout evaluation on a second chip",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Access to clone hardware and measurement equipment",
        "Device-to-device variations affecting portability",
        "Handling extremely long, noisy traces without preprocessing",
        "Unknown real-time constraints and integration into production certification workflows"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduce GPAM, “the first deep-learning system for power side-channel analysis that generalizes across multiple cryptographic algorithms, implementations, and side-channel countermeasures without the need for manual tuning or trace preprocessing.”",
      "Demonstrate attacks on four hardened hardware-accelerated ECDSA implementations; recover top 4 MSBs of the scalar with “accuracy between 71.86% to 96.39%” and combine with lattice attacks to recover full keys",
      "Show GPAM generalizes to AES, achieving “comparable performance to state-of-the-art attacks, but without manual trace curation and within a limited budget”",
      "Demonstrate black-box capability in addition to the primary white-box setting",
      "Architectural contributions: temporal patchification + GAU Transformer encoder + multi-task learning; operates directly on raw traces",
      "Support for very long traces “up to 16 million samples and up to 1 million points on a public dataset”",
      "Open-source datasets and models under Apache 2.0 at https://github.com/google/scaaml/tree/main/papers/2024/GPAM to enable replication and extension",
      "Cost-effectiveness: adapting to new targets via automated hyper-tuning requires only “a few hours of GPU time.”"
    ]
  },
  {
    "arxiv_id": "2306.05375v1",
    "title": "Sequential Graph Neural Networks for Source Code Vulnerability Identification",
    "authors": "Ammar Ahmed; Anwar Said; Mudassir Shabbir; Xenofon Koutsoukos",
    "abstract": "Vulnerability identification constitutes a task of high importance for cyber security. It is quite helpful for locating and fixing vulnerable functions in large applications. However, this task is rather challenging owing to the absence of reliable and adequately managed datasets and learning models. Existing solutions typically rely on human expertise to annotate datasets or specify features, which is prone to error. In addition, the learning models have a high rate of false positives. To bridge this gap, in this paper, we present a properly curated C/C++ source code vulnerability dataset, denoted as CVEFunctionGraphEmbeddings (CVEFGE), to aid in developing models. CVEFGE is automatically crawled from the CVE database, which contains authentic and publicly disclosed source code vulnerabilities. We also propose a learning framework based on graph neural networks, denoted SEquential Graph Neural Network (SEGNN) for learning a large number of code semantic representations. SEGNN consists of a sequential learning module, graph convolution, pooling, and fully connected layers. Our evaluations on two datasets and four baseline methods in a graph classification setting demonstrate state-of-the-art results.",
    "published_date": "2023-05-23",
    "pdf_link": "https://arxiv.org/pdf/2306.05375v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Source Code Vulnerability Detection",
      "specific_problem": "Function-level C/C++ vulnerability identification using program graphs (CFG) and graph neural networks",
      "attack_types": [
        "Denial of Service (DoS)",
        "Buffer Overflow",
        "Information Disclosure",
        "Code Execution Overflow",
        "Null Pointer Dereference"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "SEGNN (Gated Graph Recurrent Network + Graph Attention + Pooling + FC)",
        "novel_contribution": "Sequential graph learning with Gated Graph Recurrent Networks to capture local/global program semantics, combined with attention and pooling for function-level graph classification."
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "GRU (within Gated Graph Recurrent Networks)",
        "novel_contribution": "Use of GRU-based message passing to model sequential information over CFG topology."
      },
      {
        "type": "primary",
        "category": "Embedding",
        "specific": "Word2Vec for source code tokens",
        "novel_contribution": "Concatenation of node-level (basic-block) embeddings with whole-function embeddings as initial node encodings for attributed CFGs."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised (embedding training)"
    ],
    "datasets": [
      {
        "name": "CVEFunctionGraphEmbeddings (CVEFGE)",
        "type": "private",
        "domain": "source_code (C/C++)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Big-Vul",
        "type": "public",
        "domain": "source_code (C/C++)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a sequential graph neural network (SEGNN) that combines GGRN, attention, and pooling improve function-level vulnerability identification compared to existing GNN baselines?",
        "Does a curated CVE-derived dataset with attributed CFGs (CVEFGE) enable better training and evaluation of ML models for vulnerability detection than existing datasets?",
        "How do word2vec-based node and function embeddings impact graph classification performance for vulnerability identification?"
      ],
      "gaps_identified": [
        "Absence of reliable and adequately managed labeled vulnerability datasets; reliance on human expert annotation or feature specification prone to error.",
        "Existing learning models exhibit high false positives and high false negatives due to poor intermediate code representations.",
        "Prior GNN frameworks either consider flat sequences or partial features and may not handle graphs of different sizes.",
        "Big-Vul lacks graph representations and has class imbalance with many rare CWE categories, making generalization difficult."
      ],
      "limitations": [
        "The new dataset (CVEFGE) is planned to be published; availability at the time of writing is not provided.",
        "Data collection restricts to CVE entries with publicly available repositories, potentially omitting vulnerabilities without accessible code.",
        "Focus is on C/C++ and CFG representations; other program representations (e.g., AST/PDG) are not integrated into the main proposed framework."
      ],
      "future_work": [],
      "motivation": "Address the lack of reliable, curated datasets and the high false positive/negative rates of existing ML methods by creating a CVE-grounded dataset and proposing a sequential GNN framework that captures rich program semantics.",
      "potential_research_ideas": [
        "Integrate multi-graph program representations (CFG, AST, PDG/DFG) in a heterogeneous or multiplex GNN to capture complementary syntactic/semantic cues.",
        "Pretrain graph encoders on large unlabeled code corpora using contrastive/self-supervised objectives (e.g., graph masking, path prediction) before fine-tuning on vulnerability labels.",
        "Replace or augment word2vec with contextual code embeddings (e.g., CodeBERT/GraphCodeBERT) aligned to graph nodes/blocks for richer semantics.",
        "Develop cross-project and cross-repository generalization studies with domain adaptation to reduce dataset-specific overfitting and false positives.",
        "Incorporate value-flow and taint analysis features into node/edge attributes to better capture vulnerability patterns (e.g., buffer sizes, pointer aliasing).",
        "Add calibration and uncertainty estimation to reduce false positives in practical settings; explore cost-sensitive learning for imbalanced vulnerability types.",
        "Create a public benchmark with standardized splits, graph artifacts, and evaluation protocols to facilitate reproducible comparisons."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a heterogeneous GNN that jointly reasons over CFG, AST, and PDG with relation-specific attention (R-GAT/R-GCN) and meta-path aggregations.",
        "Introduce hierarchical pooling (e.g., DiffPool, ASAP, SAGPool) to better summarize large functions and variable graph sizes.",
        "Use contrastive multi-view training aligning token-level, block-level, and function-level representations to improve robustness.",
        "Augment initial node features with static analysis summaries (e.g., variable types, bounds, callsite contexts) and learned positional/topological encodings.",
        "Leverage pretrained code LMs (CodeBERT/UniXcoder) to initialize node/graph embeddings, followed by lightweight GNN layers.",
        "Incorporate label smoothing, focal loss, and class-balanced re-weighting to handle skew across CWE types."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Curation of CVEFunctionGraphEmbeddings (CVEFGE), a C/C++ vulnerability dataset with CVE metadata, CFGs, and learned embeddings, automatically crawled from the CVE database.",
      "Proposed SEquential Graph Neural Network (SEGNN) combining sequential graph learning (GGRN), attention, pooling, and fully connected layers for vulnerability identification.",
      "Empirical comparison across two datasets showing learning models perform “up to 20% better” on the curated dataset.",
      "On both datasets, comparison against four baselines demonstrating state-of-the-art results."
    ]
  },
  {
    "arxiv_id": "2306.05816v3",
    "title": "Detecting Phishing Sites Using ChatGPT",
    "authors": "Takashi Koide; Naoki Fukushi; Hiroki Nakano; Daiki Chiba",
    "abstract": "The emergence of Large Language Models (LLMs), including ChatGPT, is having a significant impact on a wide range of fields. While LLMs have been extensively researched for tasks such as code generation and text synthesis, their application in detecting malicious web content, particularly phishing sites, has been largely unexplored. To combat the rising tide of cyber attacks due to the misuse of LLMs, it is important to automate detection by leveraging the advanced capabilities of LLMs.   In this paper, we propose a novel system called ChatPhishDetector that utilizes LLMs to detect phishing sites. Our system involves leveraging a web crawler to gather information from websites, generating prompts for LLMs based on the crawled data, and then retrieving the detection results from the responses generated by the LLMs. The system enables us to detect multilingual phishing sites with high accuracy by identifying impersonated brands and social engineering techniques in the context of the entire website, without the need to train machine learning models. To evaluate the performance of our system, we conducted experiments on our own dataset and compared it with baseline systems and several LLMs. The experimental results using GPT-4V demonstrated outstanding performance, with a precision of 98.7% and a recall of 99.6%, outperforming the detection results of other LLMs and existing systems. These findings highlight the potential of LLMs for protecting users from online fraudulent activities and have important implications for enhancing cybersecurity measures.",
    "published_date": "2023-06-09",
    "pdf_link": "https://arxiv.org/pdf/2306.05816v3",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Web Security",
      "subdomain": "Phishing Detection",
      "specific_problem": "Detecting phishing websites by analyzing full-page content (HTML, URL, screenshots) with LLMs without model training",
      "attack_types": [
        "phishing",
        "social engineering",
        "brand impersonation",
        "technical support scams",
        "fake malware infection warnings",
        "fake rewards/gift card scams",
        "account problem scams",
        "postal/package delivery scams"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer LLM (prompt-based)",
        "specific": "GPT-4V (vision), GPT-4 (text)",
        "novel_contribution": "ChatPhishDetector: a CoT-prompted LLM pipeline that crawls pages, simplifies browser-rendered HTML, integrates OCR text or screenshot (vision mode), and outputs JSON with phishing decision, brands, suspicious domain, and risk score"
      },
      {
        "type": "baseline",
        "category": "Transformer LLM (prompt-based)",
        "specific": "GPT-3.5-turbo",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Open-weight LLM",
        "specific": "Llama 2 (4k context)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Multimodal VLM",
        "specific": "GPT-4V",
        "novel_contribution": "Vision mode directly consumes screenshots to identify logos/visual SE cues without OCR"
      }
    ],
    "learning_paradigm": [
      "Zero-shot prompting",
      "Chain-of-Thought (in-context reasoning)",
      "Multimodal inference"
    ],
    "datasets": [
      {
        "name": "ChatPhishDetector dataset (2,000 websites: 1,000 phishing + 1,000 non-phishing)",
        "type": "proprietary",
        "domain": "web_pages (browser-rendered HTML, URLs, screenshots)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "OpenPhish",
        "type": "public",
        "domain": "phishing_URL_feed",
        "link": "https://openphish.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PhishTank",
        "type": "public",
        "domain": "phishing_URL_feed",
        "link": "https://phishtank.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CrowdCanary (Twitter-derived phishing URL source)",
        "type": "public",
        "domain": "social_media_URLs (phishing reports)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Tranco Top Sites list",
        "type": "public",
        "domain": "domain_rankings (benign seed URLs)",
        "link": "https://tranco-list.eu/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Legitimate brand websites (153 brands; home/login pages)",
        "type": "proprietary",
        "domain": "web_pages (benign)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GPT-4 (text-only)",
        "paper_reference": null,
        "metric": "precision/recall",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "GPT-3.5-turbo",
        "paper_reference": null,
        "metric": "precision/recall",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Llama 2 (4k context)",
        "paper_reference": null,
        "metric": "precision/recall",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Existing phishing detection systems (unspecified)",
        "paper_reference": null,
        "metric": "precision/recall",
        "their_result": "Precision 98.7%, Recall 99.6% (GPT-4V)",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can LLMs accurately detect phishing websites by reasoning over full-page content (HTML, URL, and visual cues) without training custom ML models?",
        "Do multimodal LLMs (GPT-4V) outperform text-only LLMs for phishing detection, particularly on multilingual and visually-driven attacks?",
        "Can LLMs identify impersonated brands and social engineering techniques and reason about domain legitimacy in context?"
      ],
      "gaps_identified": [
        "LLMs largely unexplored for detecting malicious web content, particularly phishing websites.",
        "Existing approaches require brand-specific learning/resources (e.g., logo collections, squatting rules) and frequent logic updates.",
        "Prior methods struggle to analyze nuanced, page-wide social engineering contexts beyond keyword matching or narrow ML models.",
        "Large real-world pages exceed common LLM token limits, hindering end-to-end content analysis without careful preprocessing."
      ],
      "limitations": [
        "HTML and OCR text are shortened to fit within 4k token limits; this may remove useful content.",
        "OCR-extracted text may be inaccurate (explicitly acknowledged in prompt limitations).",
        "Dataset excludes pages with incomplete rendering/image loading; may bias towards fully renderable sites.",
        "Only two browser profiles (Chrome/Windows and Safari/iPhone) were emulated during crawling.",
        "Decision extraction rules label as phishing if either phishing=true or suspicious_domain=true; thresholding may affect precision/recall."
      ],
      "future_work": [],
      "motivation": "Rising cyber attacks (including misuse of LLMs) and lack of automated, context-aware detection for multilingual phishing; desire to leverage LLMs’ reasoning to detect brand impersonation and social engineering without training bespoke models.",
      "potential_research_ideas": [
        "Release and expand a multilingual, labeled phishing/non-phishing benchmark with full artifacts (HTML, screenshots, OCR, network traces) to standardize LLM-based evaluations.",
        "Evaluate and harden against adversarial content and prompt injection originating from malicious pages (e.g., HTML/JS designed to jailbreak or mislead the LLM).",
        "Integrate retrieval-augmented verification with authoritative brand/domain knowledge bases (WHOIS, CT logs, PSL, DMARC, brand registries) to improve domain legitimacy checks.",
        "Leverage long-context or windowed-chunk reasoning to avoid aggressive HTML/OCR truncation (e.g., gpt-4.1/long-context models, hierarchical summarization).",
        "Train a lightweight verifier or ensemble (LLM + URL/SSL features + DOM heuristics) to reduce false positives in edge cases.",
        "Use layout-aware VLMs (e.g., layout/form understanding) to robustly parse login flows and visual warnings.",
        "Automate dynamic interaction (form fills, button clicks) in a sandbox to elicit gated content and re-run analysis.",
        "Develop multilingual SE tactic taxonomies and detectors to support structured extraction beyond brand and domain checks.",
        "Study temporal robustness (evolving templates, domain churn) with continuous evaluation pipelines."
      ],
      "architectural_improvement_recommendations": [
        "Adopt retrieval-augmented generation: on detection, fetch WHOIS/CT/PSL/brand KB entries and provide to the LLM for grounded decisions.",
        "Upgrade to long-context models or implement hierarchical chunking with intermediate summaries and tool-use to cover full HTML/JS content.",
        "Replace OCR with end-to-end VLMs fine-tuned for web UI understanding, or combine OCR with layout models (e.g., LayoutLM-like) for better text-visual alignment.",
        "Introduce prompt-injection defenses and content sanitization (e.g., HTML tag stripping, neutral system prompts) to mitigate adversarial page content targeting the LLM.",
        "Add a calibration/verifier head: a small supervised model on LLM rationales/outputs to flag low-confidence or inconsistent decisions.",
        "Incorporate network- and certificate-level features (TLS issuer, age, ASN, hosting metadata) into the prompt or as side-channel features for an ensemble decision.",
        "Implement multi-agent analysis: separate agents for domain reputation, visual similarity, SE tactic extraction, and a final arbiter for robust consensus."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "OpenAI API (GPT-4/GPT-4V)",
        "Azure Cognitive Services (OCR)",
        "Chrome DevTools Protocol"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "LLM token/context limits require aggressive HTML/OCR simplification.",
        "OCR inaccuracies can degrade text-based analysis in normal mode.",
        "Dynamic/obfuscated JavaScript necessitates browser-rendered HTML collection; some pages fail to render and were excluded."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposed ChatPhishDetector, an LLM-driven system that crawls websites and uses CoT prompting (normal and vision modes) to classify phishing vs. non-phishing without training ML models.",
      "Experimental comparison across several LLMs and existing systems; GPT-4V achieved precision 98.7% and recall 99.6%, outperforming others.",
      "Analysis of LLM outputs showing GPT-4/GPT-4V can assess suspicious domains, identify SE techniques in content, and weigh multiple factors for comprehensive detection."
    ]
  },
  {
    "arxiv_id": "2304.13905v1",
    "title": "LSTM based IoT Device Identification",
    "authors": "Kahraman Kostas",
    "abstract": "While the use of the Internet of Things is becoming more and more popular, many security vulnerabilities are emerging with the large number of devices being introduced to the market. In this environment, IoT device identification methods provide a preventive security measure as an important factor in identifying these devices and detecting the vulnerabilities they suffer from. In this study, we present a method that identifies devices in the Aalto dataset using Long short-term memory (LSTM)",
    "published_date": "2023-04-27",
    "pdf_link": "https://arxiv.org/pdf/2304.13905v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Device Fingerprinting / Identification",
      "specific_problem": "Identifying IoT devices from network traffic flows using sequential models",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Vanilla LSTM",
        "novel_contribution": "Applies LSTM to sequences of per-session IoT network features (12x25 matrices) for device identification"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Stacked LSTM",
        "novel_contribution": "Evaluates deeper LSTM stacks for the same IoT device identification task"
      },
      {
        "type": "primary",
        "category": "CNN-RNN Hybrid",
        "specific": "CNN-LSTM",
        "novel_contribution": "Combines a CNN layer with LSTM to process pseudo-image inputs derived from sequential network features"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Encoder-Decoder LSTM",
        "novel_contribution": "Tests an encoder-decoder LSTM architecture for sequence-to-label prediction of device identity"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Aalto dataset",
        "type": "",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [
      {
        "method_name": "CNN-LSTM",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "0.769 (Vanilla LSTM)",
        "baseline_result": "0.763"
      },
      {
        "method_name": "Encoder-Decoder LSTM",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "0.769 (Vanilla LSTM)",
        "baseline_result": "0.750"
      },
      {
        "method_name": "Stacked LSTM",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "0.769 (Vanilla LSTM)",
        "baseline_result": "0.740"
      }
    ],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can LSTM-based sequence models accurately identify IoT devices from network traffic feature sequences in the Aalto dataset?"
      ],
      "gaps_identified": [
        "Sequential modeling (RNN/LSTM/GRU) is underutilized for IoT device identification despite network behavior being inherently sequential."
      ],
      "limitations": [
        "Only the first 12 packets of each session were used, with zero-padding for sessions shorter than 12, potentially limiting utilization of longer-range behaviors.",
        "Evaluation limited to a single dataset (Aalto) comprising 27 devices and 540 sessions (20 per device), which may restrict generalizability.",
        "Only accuracy is reported; no per-class metrics or confusion analyses are provided.",
        "No comparison against non-RNN baselines (e.g., classical ML or Transformer-based models)."
      ],
      "future_work": [],
      "motivation": "Provide a preventive security measure by identifying IoT devices (and thus their vulnerabilities) using LSTM-based sequence modeling on network traffic.",
      "potential_research_ideas": [
        "Evaluate GRU, BiLSTM, and Transformer/Temporal Convolutional Networks for device identification on the same data.",
        "Incorporate attention mechanisms over packet sequences or features to capture salient behaviors and improve interpretability.",
        "Cross-dataset and cross-network generalization studies (domain adaptation) to assess robustness to environment changes.",
        "Few-shot/continual learning for onboarding new device types with minimal labeled data.",
        "Augment with flow-level and timing features beyond the first 12 packets; study variable-length sequence models without truncation.",
        "Contrastive/self-supervised pretraining on unlabeled traffic to improve downstream identification.",
        "Robustness evaluation under adversarial traffic perturbations and encrypted payload prevalence."
      ],
      "architectural_improvement_recommendations": [
        "Use BiLSTM layers and attention pooling to better capture bidirectional temporal dependencies.",
        "Adopt Transformer encoders with positional encodings tailored to inter-arrival times and protocol events.",
        "Replace fixed-length truncation with masking and packed sequences to handle variable-length sessions.",
        "Multi-branch architecture separating header, timing, and directional features with late fusion before classification.",
        "Hyperparameter optimization (layer width/depth, dropout, learning rate schedulers) and regularization (label smoothing, mixup for sequences)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/kahramankostas/LSTM-based-IoT-Device-Identification",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes and evaluates four LSTM-based architectures (Vanilla, Stacked, CNN-LSTM, Encoder-Decoder) for IoT device identification from network traffic.",
      "Constructs sequential inputs by converting each session to a 12x25 feature matrix using IoTDevIDv1 features and first 12 packets with zero-padding if needed.",
      "Reports average accuracy over 50 runs for each architecture (Vanilla LSTM: 0.769; CNN-LSTM: 0.763; ED-LSTM: 0.750; Stacked LSTM: 0.740).",
      "Provides statistical significance testing across architectures (ANOVA and Mann–Whitney U tests).",
      "Releases implementation script via GitHub."
    ]
  },
  {
    "arxiv_id": "2305.19214v1",
    "title": "Design and implementation of intelligent packet filtering in IoT microcontroller-based devices",
    "authors": "Gustavo de Carvalho Bertoli; Gabriel Victor C. Fernandes; Pedro H. Borges Monici; César H. de Araujo Guibo; Lourenço Alves Pereira; Aldri Santos",
    "abstract": "Internet of Things (IoT) devices are increasingly pervasive and essential components in enabling new applications and services. However, their widespread use also exposes them to exploitable vulnerabilities and flaws that can lead to significant losses. In this context, ensuring robust cybersecurity measures is essential to protect IoT devices from malicious attacks. However, the current solutions that provide flexible policy specifications and higher security levels for IoT devices are scarce. To address this gap, we introduce T800, a low-resource packet filter that utilizes machine learning (ML) algorithms to classify packets in IoT devices. We present a detailed performance benchmarking framework and demonstrate T800's effectiveness on the ESP32 system-on-chip microcontroller and ESP-IDF framework. Our evaluation shows that T800 is an efficient solution that increases device computational capacity by excluding unsolicited malicious traffic from the processing pipeline. Additionally, T800 is adaptable to different systems and provides a well-documented performance evaluation strategy for security ML-based mechanisms on ESP32-based IoT systems. Our research contributes to improving the cybersecurity of resource-constrained IoT devices and provides a scalable, efficient solution that can be used to enhance the security of IoT systems.",
    "published_date": "2023-05-30",
    "pdf_link": "https://arxiv.org/pdf/2305.19214v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Intelligent stateless packet filtering on microcontroller-based IoT devices (ESP32) to block malicious ingress traffic (e.g., port scans) at the TCP/IP stack (lwIP) entry point",
      "attack_types": [
        "Port scanning",
        "Lateral movement scanning",
        "Internet-wide scanning",
        "Unsolicited/malicious ingress traffic",
        "Botnet-related probing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": "Depth-12 Decision Tree (DT-12)",
        "novel_contribution": "On-device deployment as a packet-filtering policy integrated into lwIP on ESP32 via TensorFlow Lite Micro; low-overhead stateless classification from TCP/IP headers"
      },
      {
        "type": "primary",
        "category": "Neural Network (MLP)",
        "specific": "MLP with two hidden layers (16 neurons each), sigmoid hidden activations, softmax output; TFLite-Micro quantized",
        "novel_contribution": "Feasible inference of a small MLP on ESP32 using TensorFlow Lite Micro and esp-nn optimizations for packet filtering"
      },
      {
        "type": "primary",
        "category": "Linear Model",
        "specific": "Logistic Regression",
        "novel_contribution": "Lightweight linear model deployed on microcontroller as a replaceable filtering policy"
      },
      {
        "type": "primary",
        "category": "SVM",
        "specific": "Linear SVM",
        "novel_contribution": "Linear-kernel SVM realized on-device via TensorFlow/TFLite conversion as a plug-in policy"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Port scanning traffic dataset (this work)",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Standard ESP32 networking stack without T800 (no ML filtering)",
        "paper_reference": null,
        "metric": "CPU usage, memory usage, network throughput, power consumption (energy efficiency)",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "CPU utilization",
      "Memory usage",
      "Network throughput",
      "Power consumption",
      "Energy efficiency",
      "Computational overhead"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can machine-learning-based packet filtering be executed efficiently on resource-constrained microcontroller-based IoT devices (ESP32) with low overhead?",
        "Does early dropping of unsolicited/malicious ingress traffic increase computational capacity and energy efficiency on IoT edge nodes?",
        "Can a modular, updatable ML policy mechanism be integrated at the lwIP entry point to support zero-trust-inspired filtering on-device?"
      ],
      "gaps_identified": [
        "Scarcity of ML-based security mechanisms evaluated on microcontroller-based IoT systems (edge nodes), as opposed to gateways or SBCs",
        "Lack of flexible policy specification and update mechanisms to handle time-varying attacks and concept drift",
        "Limited lifetime of attack characterizations (weeks) requiring policy updates",
        "Few works report comprehensive runtime performance, especially power consumption, on constrained devices",
        "Limited generality and lack of on-device (kernel/stack-level) integration in prior IoT IDS solutions"
      ],
      "limitations": [
        "Current implementation is limited to stateless packet filtering; stateful or anomaly-based capabilities are described as possible but not implemented",
        "Covers only ingress traffic at the lwIP entry point",
        "Uses features from TCP/IP headers; payload- or flow-augmented features are not explored in this implementation",
        "Evaluation focuses on the ESP32 platform; portability to other microcontrollers is discussed but not empirically validated in this text",
        "Models are trained offline; periodic updates are needed to address concept drift"
      ],
      "future_work": [
        "Implement stateful packet filtering and anomaly detection models on microcontrollers",
        "Extend and validate T800 on other stacks and MCU platforms beyond ESP32/ESP-IDF/lwIP",
        "Broaden evaluations to more attack types and operational scenarios",
        "Refine and automate the policy update mechanism to respond to evolving threats",
        "Explore additional feature sets and model architectures optimized for MCU inference"
      ],
      "motivation": "IoT devices are widely deployed yet vulnerable; there is a lack of flexible, updatable ML-based security mechanisms for microcontroller-based nodes. Dropping malicious traffic early can save scarce CPU, memory, and power resources while enabling zero-trust policies at the edge.",
      "potential_research_ideas": [
        "Design and evaluate stateful and flow-based packet filtering on MCUs using lightweight feature caching and compact models",
        "Online or federated policy updates for MCU fleets to address concept drift without over-the-air full firmware updates",
        "Hierarchical cascade filters combining cheap allow/deny heuristics with ML models to reduce inference cost",
        "Explore ultra-compact architectures (e.g., Bonsai trees, micro-MLPs, LUT-based models) with quantization/pruning tailored to ESP32/ESP32-Sx",
        "Encrypted traffic handling via header-only and side-channel/timing features for robust filtering when payloads are unavailable",
        "Adversarially robust training for packet classifiers to resist evasion (e.g., modified header fields)",
        "Energy-aware policy selection that dynamically chooses models based on current power budget and workload",
        "Cross-device collaborative detection (edge-to-edge signaling) to share indicators while preserving MCU constraints"
      ],
      "architectural_improvement_recommendations": [
        "Adopt quantization-aware training and structured pruning to minimize model size and latency on TensorFlow Lite Micro",
        "Implement a two-stage pipeline: whitelist/cheap rules first, then ML inference only on suspicious packets",
        "Introduce secure, OTA policy update channels with integrity verification and rollback for runtime pluggable classifiers",
        "Add optional lightweight state (e.g., per-flow counters) to enable semi-stateful features within tight RAM budgets",
        "Compile decision trees to optimized C code paths (branchless or predicated) for further latency reduction",
        "Instrumentation for fine-grained latency measurements (per-packet inference time) and dynamic throttling",
        "Abstract the lwIP hook to support additional stacks/RTOSes (e.g., Zephyr, NuttX) for portability",
        "Implement telemetry of filter outcomes and resource impact for continuous tuning and A/B testing"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "TensorFlow",
        "TensorFlow Lite Micro",
        "esp-nn",
        "ESP-IDF",
        "lwIP",
        "FreeRTOS"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "ESP32-class microcontroller (~320 kB RAM) running FreeRTOS/ESP-IDF; inference via TensorFlow Lite Micro using esp-nn optimizations; no GPU/accelerator required; runs as a dedicated FreeRTOS task"
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "ESP32-based IoT edge device (ESP-IDF, lwIP, FreeRTOS)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Handling concept drift and frequent policy updates on constrained devices",
        "Tight RAM/CPU/power budgets limiting model complexity and feature extraction",
        "Ensuring generalization across diverse IoT traffic patterns and devices",
        "Secure integration and maintenance of filtering hooks within lwIP/RTOS",
        "Balancing false positives with resource savings and service availability"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Design and implementation of T800, an intelligent packet filter with pluggable ML policies (DT, LR, SVM, MLP) integrated into lwIP on ESP32 (ESP-IDF/FreeRTOS) using TensorFlow Lite Micro",
      "A runtime-update mechanism allowing dynamic selection/replacement of working mode and classification functions",
      "“To the best of our knowledge, this is the first work evaluating the technical feasibility of machine learning-based detection on microcontroller-based systems.”",
      "Performance benchmarking framework and comprehensive runtime evaluation on ESP32 covering CPU, memory, network, and power consumption (energy efficiency)",
      "Demonstration that early dropping of unsolicited malicious traffic increases device computational capacity by reducing protocol stack processing load",
      "Design adaptable to other low-resource platforms and TCP/IP stacks; enables zero-trust-aligned policies on IoT edge nodes"
    ]
  },
  {
    "arxiv_id": "2305.05309v1",
    "title": "PSP Framework: A novel risk assessment method in compliance with ISO/SAE-21434",
    "authors": "Franco Oberti; Ernesto Sanchez; Alessandro Savino; Filippo Parisi; Stefano Di Carlo",
    "abstract": "As more cars connect to the internet and other devices, the automotive market has become a lucrative target for cyberattacks. This has made the industry more vulnerable to security threats. As a result, car manufacturers and governments are working together to reduce risks and prevent cyberattacks in the automotive sector. However, existing attack feasibility models derived from the information technology field may not always provide accurate assessments of the potential risks faced by Vehicle Electronic Control Units in different operating conditions and domains. This paper introduces the PUNCH Softronix and Politecnico di Torino (PSP) framework to address this issue. This framework is designed to provide accurate assessments compatible with the attack feasibility models defined by the automotive product security standards. The PSP framework utilizes social sentiment analysis to evaluate the real threat risk levels.",
    "published_date": "2023-05-09",
    "pdf_link": "https://arxiv.org/pdf/2305.05309v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Automotive Security",
      "subdomain": "Risk Assessment and Threat Modeling",
      "specific_problem": "Dynamic ISO/SAE-21434-compliant attack feasibility assessment using social sentiment and financial indicators, with emphasis on insider/local/physical attacks (e.g., ECU reprogramming in powertrain)",
      "attack_types": [
        "Insider",
        "Outsider",
        "Local",
        "Physical",
        "Adjacent",
        "Network",
        "Denial of Service (DoS) on CAN bus",
        "MATE (Man-At-The-End)",
        "ECU reprogramming via OBD",
        "Vehicle theft"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "NLP",
        "specific": null,
        "novel_contribution": "Use of social sentiment and popularity signals from Twitter to compute a Social Attraction Index (SAI) that dynamically adjusts ISO/SAE-21434 attack feasibility weights for insider threats."
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": null,
        "novel_contribution": "Text mining and clustering of online product/service descriptions and prices to estimate Purchase Price per Insider Attack (PPIA) for the financial feasibility model."
      },
      {
        "type": "primary",
        "category": "Keyword mining/expansion",
        "specific": null,
        "novel_contribution": "Auto-learning strategy to discover and expand attack-related keywords/hashtags for future runs."
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Heuristic"
    ],
    "datasets": [
      {
        "name": "Twitter posts via Twitter API",
        "type": "public",
        "domain": "social_media_text",
        "link": "https://developer.twitter.com/en/docs/twitter-api",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Upstream global automotive cybersecurity reports",
        "type": "public",
        "domain": "cybersecurity_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Vehicle sales and market share reports (for PAE)",
        "type": "public",
        "domain": "market_statistics",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Online prices of tuning devices/services (for PPIA)",
        "type": "public",
        "domain": "web_scraped_listings",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "ISO/SAE-21434 attack vector-based feasibility model (G.9 table)",
        "paper_reference": "ISO/SAE-21434:2021",
        "metric": "Attack feasibility rating categories",
        "their_result": "PSP reweights insider threats (e.g., ECM reprogramming) to elevate local/physical vectors based on SAI/time window.",
        "baseline_result": "\"the result was a very high score for a remote attack and a low score for a physical attack\" for powertrain scenarios."
      },
      {
        "method_name": "ISO/SAE-21434 attack potential-based model",
        "paper_reference": "ISO/SAE-21434:2021",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "ISO/SAE-21434 CVSS-based model",
        "paper_reference": "ISO/SAE-21434:2021",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Attack feasibility rating (Very Low, Low, Medium, High)",
      "Social Attraction Index (SAI)",
      "Market Value (MV) = PAE × PPIA",
      "Potential Attackers Estimation (PAE)",
      "Purchase Price per Insider Attack (PPIA)",
      "Break-even Point (BEP)",
      "Cybersecurity Assurance Level (CAL)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can static attack feasibility models in ISO/SAE-21434 misestimate risks for certain automotive domains (e.g., powertrain with physical/local attack surfaces)?",
        "Can social sentiment and popularity signals from social media be used to dynamically tune attack vector weights while remaining compliant with ISO/SAE-21434?",
        "How does time window selection affect the perceived feasibility of insider attacks?",
        "Can a financial feasibility perspective (market size, pricing, and BEP) improve assessment of insider attack likelihood and prioritization?"
      ],
      "gaps_identified": [
        "Static, fixed-weight ISO/SAE-21434 models may misrepresent feasibility for heterogeneous automotive domains, especially powertrain and physical attacks.",
        "Physical attacks are undervalued in CAL determination (physical limited to CAL2).",
        "Automotive insider/MATE-style attacks are difficult to assess with IT-derived TARA models.",
        "Lack of flexibility to tune attack feasibility to domain-, region-, and time-specific realities.",
        "Limited application of NLP/social sentiment in road vehicle cybersecurity risk assessment."
      ],
      "limitations": [
        "\"preliminary results obtained through a proof of concept implementation\"",
        "\"the social sentiment analysis time window plays a crucial role in the PSP framework’s analysis\"",
        "Manual seeding of hashtags/keywords at first interaction; reliance on Twitter data and public reports.",
        "No quantitative end-to-end validation against ground-truth incident outcomes provided.",
        "Outsider threats keep standard ISO weights; reweighting is focused on insider scenarios."
      ],
      "future_work": [],
      "motivation": "Address inaccuracies and limitations of static ISO/SAE-21434 TARA models by introducing a dynamic, data-informed framework that better reflects real-world insider attack feasibility and market drivers.",
      "potential_research_ideas": [
        "Cross-platform sentiment and topic fusion (Twitter, Reddit, forums, Telegram, YouTube) to mitigate single-source bias and manipulation.",
        "Develop a domain-adapted transformer model for automotive threat topic detection, stance, and intent classification tied to specific ECUs and attack vectors.",
        "Construct a labeled benchmark of insider attack instances (by domain/vector/time/region) to quantitatively validate reweighting and calibrate SAI-to-weight mappings.",
        "Integrate PSP with in-vehicle telemetry/IDS alerts to correlate social signals with observed attacks for causal or predictive studies.",
        "Model adversarial manipulation of social signals and design robustness defenses (bot detection, campaign anomaly detection).",
        "Use multilingual NLP and geolocation-aware models to capture regional attack trends and regulation effects.",
        "Learn continuous-time hazard models linking SAI and financial indices to incident likelihood and CAL recommendations.",
        "Create a knowledge graph linking ECUs, attack vectors, tools, vendors, prices, and regulations to support explainable TARA updates."
      ],
      "architectural_improvement_recommendations": [
        "Replace heuristic sentiment/popularity scoring with transformer-based classifiers (e.g., domain-tuned BERT/RoBERTa) for topic/intent/sentiment and entity extraction.",
        "Active learning and weak supervision (Snorkel-style) for keyword/hashtag expansion and labeling of attack-related posts.",
        "Temporal modeling (state-space models or TCNs) for trend sensitivity and time-window selection; include change-point detection for trend inversions.",
        "Robustness layer for bot/campaign detection (graph-based bot detection, anomaly detection on interaction networks).",
        "Structured price extraction with IE pipelines (NER + relation extraction) from web sources; probabilistic models for PPIA uncertainty.",
        "Calibrate SAI-to-weight mapping via Bayesian modeling with priors informed by domain experts and validated against incident data."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Product security assessment workflows for automotive OEMs/suppliers (TARA/ISO-21434 compliance)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Access and rate-limit constraints of social media APIs; ToS compliance.",
        "Bias and manipulability of social media signals; bot/campaign interference.",
        "Time-window sensitivity and regional/language coverage.",
        "Mapping SAI and financial metrics to ISO weight changes with auditor-acceptable justification.",
        "Data governance and repeatability for certification; archival of data snapshots.",
        "Integration with existing TARA tooling and processes across suppliers."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces PSP framework, a dynamic, ISO/SAE-21434-compliant approach to reweight attack feasibility using NLP-derived Social Attraction Index for insider threats.",
      "Differentiates insider vs outsider threats, keeping outsider weights standard while tuning insider vectors via social signals.",
      "Implements auto-learning keyword expansion to capture emerging attack hashtags/topics.",
      "Demonstrates ECM reprogramming case where PSP elevates local/physical vectors relative to static ISO table; shows sensitivity to time-window selection.",
      "Proposes a financial feasibility model (MV, PAE, PPIA, BEP) to assess profitability-driven insider attacks and prioritize accordingly."
    ]
  },
  {
    "arxiv_id": "2304.07470v1",
    "title": "Few-shot Weakly-supervised Cybersecurity Anomaly Detection",
    "authors": "Rahul Kale; Vrizlynn L. L. Thing",
    "abstract": "With increased reliance on Internet based technologies, cyberattacks compromising users' sensitive data are becoming more prevalent. The scale and frequency of these attacks are escalating rapidly, affecting systems and devices connected to the Internet. The traditional defense mechanisms may not be sufficiently equipped to handle the complex and ever-changing new threats. The significant breakthroughs in the machine learning methods including deep learning, had attracted interests from the cybersecurity research community for further enhancements in the existing anomaly detection methods. Unfortunately, collecting labelled anomaly data for all new evolving and sophisticated attacks is not practical. Training and tuning the machine learning model for anomaly detection using only a handful of labelled data samples is a pragmatic approach. Therefore, few-shot weakly supervised anomaly detection is an encouraging research direction. In this paper, we propose an enhancement to an existing few-shot weakly-supervised deep learning anomaly detection framework. This framework incorporates data augmentation, representation learning and ordinal regression. We then evaluated and showed the performance of our implemented framework on three benchmark datasets: NSL-KDD, CIC-IDS2018, and TON_IoT.",
    "published_date": "2023-04-15",
    "pdf_link": "https://arxiv.org/pdf/2304.07470v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Few-shot weakly-supervised anomaly-based intrusion detection with scarce labeled anomalies",
      "attack_types": [
        "DoS",
        "DDoS",
        "Probe",
        "R2L",
        "U2R"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Siamese/Triplet Network",
        "specific": null,
        "novel_contribution": "Triplet-based data augmentation with three shared-weight streams to generate combined anomaly scores for few-shot weakly-supervised detection; extends prior two-sample framework [23]"
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": null,
        "novel_contribution": "Three identical shared-weight MLP subnetworks learn compressed representations of each sample before combining"
      },
      {
        "type": "primary",
        "category": "Ordinal Regression",
        "specific": null,
        "novel_contribution": "Uses absolute prediction error loss on ordinal labels C1>C2>C3>C4 to align anomaly scores with the number of anomalies in augmented triplets"
      },
      {
        "type": "baseline",
        "category": "Siamese/Pair Network",
        "specific": null,
        "novel_contribution": "Two-sample weakly-supervised ordinal regression framework from [23] used as the conceptual baseline"
      }
    ],
    "learning_paradigm": [
      "Weakly-supervised",
      "Few-shot"
    ],
    "datasets": [
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-IDS2018",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "TON_IoT (Windows 10 subset)",
        "type": "public",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Two-sample weakly-supervised ordinal regression framework",
        "paper_reference": "[23]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Collecting labeled anomaly data for all evolving attacks is impractical and expensive",
        "Supervised and semi-supervised methods depend on labels and struggle with novel threats",
        "Unsupervised methods cannot leverage the availability of a few labeled anomaly samples"
      ],
      "limitations": [
        "Framework assumes anomaly samples are not statistically dominant in the dataset",
        "Relies on extremely few labeled anomaly samples compared to unlabeled samples",
        "Ordinal label spacing fixed using m=4 based on prior work; may not be optimal across datasets",
        "Inference requires multiple random pairings (e.g., 30 runs) per test sample, adding overhead"
      ],
      "future_work": [],
      "motivation": "Enable practical anomaly-based intrusion detection when only a handful of labeled anomalies exist, by leveraging few-shot weakly-supervised learning with data augmentation, representation learning, and ordinal regression.",
      "potential_research_ideas": [
        "Integrate self-supervised contrastive pretraining on unlabeled traffic/logs to improve representations before the triplet scoring network",
        "Extend the framework with temporal models (e.g., TCNs or Transformers) to capture sequence dynamics in flows or logs",
        "Calibrate ordinal scores and incorporate uncertainty estimation to better set thresholds under distribution shift",
        "Meta-learning across multiple networks/environments to quickly adapt to new domains with very few labels",
        "Incorporate explainability modules (e.g., feature attributions over combined representations) to highlight factors driving anomaly scores",
        "Study robustness to label noise and class-overlap in the few labeled anomalies, with noise-robust ordinal objectives",
        "Reduce inference cost by learning reference prototypes for A and U sets instead of repeated random sampling"
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment the shared-weight MLPs with Transformer encoders or temporal CNNs for sequential features",
        "Use supervised contrastive loss jointly with ordinal regression to better separate normal vs anomaly representations",
        "Learn class-specific or prototype embeddings for anomaly references to avoid repeated random sampling at test time",
        "Adopt dynamic or learned ordinal label spacing rather than a fixed m=4 to adapt across datasets",
        "Add uncertainty-aware scoring (e.g., MC dropout or deep ensembles) to provide calibrated anomaly probabilities",
        "Introduce feature selection or attention over triplet components to reduce noise from uninformative features"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Scarcity of labeled anomaly data",
        "Rapidly evolving and diverse attack types",
        "Class imbalance with anomalies as minority",
        "Inference involves repeated sampling of references per test sample"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Enhanced few-shot weakly-supervised anomaly detection framework with three stages: data augmentation, representation learning, and ordinal regression",
      "Triplet-based augmentation scheme creating ordinal classes C1>C2>C3>C4 tied to the number of anomalies in each augmented sample",
      "Three-stream shared-weight MLP scoring network that combines compressed representations to produce anomaly scores",
      "Training with absolute prediction error loss on ordinal labels; evaluation on NSL-KDD, CIC-IDS2018, and TON_IoT datasets"
    ]
  },
  {
    "arxiv_id": "2304.02870v1",
    "title": "Protecting User Privacy in Online Settings via Supervised Learning",
    "authors": "Alexandru Rusescu; Brooke Lampe; Weizhi Meng",
    "abstract": "Companies that have an online presence-in particular, companies that are exclusively digital-often subscribe to this business model: collect data from the user base, then expose the data to advertisement agencies in order to turn a profit. Such companies routinely market a service as \"free\", while obfuscating the fact that they tend to \"charge\" users in the currency of personal information rather than money. However, online companies also gather user data for more principled purposes, such as improving the user experience and aggregating statistics. The problem is the sale of user data to third parties. In this work, we design an intelligent approach to online privacy protection that leverages supervised learning. By detecting and blocking data collection that might infringe on a user's privacy, we can restore a degree of digital privacy to the user. In our evaluation, we collect a dataset of network requests and measure the performance of several classifiers that adhere to the supervised learning paradigm. The results of our evaluation demonstrate the feasibility and potential of our approach.",
    "published_date": "2023-04-06",
    "pdf_link": "https://arxiv.org/pdf/2304.02870v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Privacy and Data Protection",
      "subdomain": "Online Tracking Protection",
      "specific_problem": "Detecting and blocking privacy-invasive web (HTTP) requests that exfiltrate user data to third parties",
      "attack_types": [
        "web tracking",
        "third-party advertising trackers",
        "privacy-invasive data collection",
        "data exfiltration via HTTP requests"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": "Applied to classify HTTP requests as benign vs. privacy-invasive for online tracking protection; integrated into a blocking tool with an API."
      },
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": "Applied to classify HTTP requests as benign vs. privacy-invasive for online tracking protection; integrated into a blocking tool with an API."
      },
      {
        "type": "primary",
        "category": "Support Vector Machine",
        "specific": null,
        "novel_contribution": "Applied to classify HTTP requests as benign vs. privacy-invasive for online tracking protection; integrated into a blocking tool with an API."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Binary classification"
    ],
    "datasets": [
      {
        "name": "Manually collected HTTP network requests from multiple websites (invasive vs. benign)",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Support Vector Machine (SVM)",
        "paper_reference": null,
        "metric": "Precision, Recall, Confusion Matrix",
        "their_result": "Precision 0.7; Recall 1.0; \"predicted all values to be true, but actually was wrong on 30% of the cases.\"",
        "baseline_result": null
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": "Precision, Recall, F1, Confusion Matrix",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "Precision, Recall, F1, Confusion Matrix",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall",
      "F1-score",
      "confusion matrix"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Safeguarding a user’s privacy online remains an open challenge despite existing PETs.",
        "Existing solutions (e.g., ad/tracker blocklists, containerization) may not capture all privacy-invasive requests tied to site context.",
        "Need for intelligent detection to distinguish necessary site functionality from privacy-invasive collection."
      ],
      "limitations": [
        "Small dataset: \"The data set consists of 90 unique requests...\" with 60 train / 30 test.",
        "Manual data collection and labeling; risk of mislabeling leading to false positives/negatives and degraded user experience.",
        "Scope limited to JSON-formatted payloads in the initial implementation.",
        "Removed URL feature and one-hot encoded request type (GET/POST), potentially limiting feature richness.",
        "Reported that SVM predicted all positives with 30% wrong, indicating class imbalance or thresholding issues."
      ],
      "future_work": [],
      "motivation": "Restore digital privacy by detecting and blocking online requests that collect user data for advertisers while preserving website usability.",
      "potential_research_ideas": [
        "Scale up and release a comprehensive, diverse benchmark dataset of labeled web requests (including non-JSON payloads) for privacy-invasive tracking detection.",
        "Develop feature sets combining URL/domain features, request headers, timing, referer chains, and content context to improve generalization across sites.",
        "Explore semi-supervised or weakly supervised learning leveraging public tracker lists and heuristic labels to reduce manual labeling effort.",
        "Design browser/extension-based real-time classifiers with on-device inference and incremental/online learning to adapt to new trackers.",
        "Investigate adversarial robustness against tracker evasion (e.g., obfuscation, domain rotation, encryption) and propose defenses.",
        "Incorporate explainability to show which request attributes trigger blocking, enabling user trust and policy tuning.",
        "Evaluate privacy-preserving training (e.g., federated learning across users/browsers) to avoid centralizing sensitive browsing data.",
        "Integrate graph-based models (GNNs) on request-dependency graphs (request chains, third-party domains) for better context-aware tracking detection.",
        "Formulate multi-task learning to jointly classify invasiveness and categorize tracker purpose (ads, analytics, fingerprinting).",
        "Perform longitudinal studies measuring real-world impact on usability and privacy leakage reduction across diverse websites."
      ],
      "architectural_improvement_recommendations": [
        "Augment features beyond JSON payload fields: include domain reputation, third-party status, cookie/Storage access, referer/origin, URL patterns, headers, content-type, and request timing.",
        "Adopt calibrated probabilistic outputs with threshold tuning and cost-sensitive learning to balance false positives (usability) vs. false negatives (privacy).",
        "Use ensemble methods (e.g., gradient boosting, random forests, XGBoost) and compare against linear models and SVMs.",
        "Implement cross-validation and stratification to mitigate small-sample variance; apply regularization and feature selection.",
        "Handle class imbalance via reweighting or resampling (SMOTE/undersampling) if present.",
        "Support non-JSON payloads by adding parsers and learning from raw bytes with shallow text models or character n-grams.",
        "Integrate an inline feedback loop where users can report misclassifications to enable continuous learning.",
        "Deploy as a browser extension or network middleware with caching and preclassification for frequent domains to reduce latency.",
        "Add an explainability layer (e.g., SHAP/LIME) to highlight influential features per decision.",
        "Introduce robust evaluation with holdout sites (cross-site generalization) and adversarial test scenarios (obfuscation, domain churn)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Flask"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "Small dataset (60 train / 30 test); all three algorithms trained quickly; no specific hardware requirements reported."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Risk of false positives disrupting website usability; authors manually verified by refreshing sites after blocking.",
        "Limited to JSON payloads; many tracking requests may use other formats or obfuscation.",
        "Manual labeling is labor-intensive and error-prone.",
        "Generalization across diverse sites and evolving trackers is challenging.",
        "Payload inspection may be constrained by encryption and browser/network integration details."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Developed a tool leveraging supervised machine learning to detect and block privacy-invasive online requests.",
      "Detailed an API implementation (web API using Flask) that receives request data and returns a binary decision (invasive vs. non-invasive).",
      "Collected a dataset of network requests from multiple websites and evaluated Logistic Regression, Decision Tree, and SVM classifiers, demonstrating feasibility."
    ]
  },
  {
    "arxiv_id": "2304.08224v2",
    "title": "Uncharted Territory: Energy Attacks in the Battery-less Internet of Things",
    "authors": "Luca Mottola; Arslan Hameed; Thiemo Voigt",
    "abstract": "We study how ambient energy harvesting may be used as an attack vector in the battery-less Internet of Things (IoT). Battery-less IoT devices rely on ambient energy harvesting and are employed in a multitude of applications, including safety-critical ones such as biomedical implants. Due to scarce energy intakes and limited energy buffers, their executions become intermittent, alternating periods of active operation with periods of recharging energy buffers. Through an independent exploratory study and a follow-up systematic analysis, we demonstrate that by exerting limited control on ambient energy one can create situations of livelock, denial of service, and priority inversion, without physical device access. We call these situations energy attacks. Using concepts of approximate intermittent computing and machine learning, we design a technique that can detect energy attacks with 92%+ accuracy, that is, up to 37% better than the baselines, and with up to one fifth of their energy overhead. Crucially, by design, our technique does not cause any additional energy failure compared to the regular intermittent processing. We conclude with directions to inspire defense techniques and a discussion on the feasibility of energy attacks.",
    "published_date": "2023-04-17",
    "pdf_link": "https://arxiv.org/pdf/2304.08224v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Battery-less/energy-harvesting IoT",
      "specific_problem": "Energy attacks via manipulation of ambient energy against intermittently powered IoT devices; on-device detection of such attacks",
      "attack_types": [
        "Livelock",
        "Denial of Service",
        "Priority Inversion",
        "Ambient energy manipulation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Anomaly Detection",
        "specific": null,
        "novel_contribution": "On-device ML-based detection of energy attacks leveraging approximate intermittent computing; by design does not cause additional energy failures compared to regular intermittent processing"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Anomaly detection"
    ],
    "datasets": [
      {
        "name": "Real-world energy traces for battery-less IoT (500K+ data points)",
        "type": "private",
        "domain": "energy_harvesting_time_series",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Baseline 1 (unspecified by paper)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "“92%+ accuracy”",
        "baseline_result": "“up to 37% better than the baselines” (exact baseline accuracy not specified)"
      },
      {
        "method_name": "Baseline 2 (unspecified by paper)",
        "paper_reference": null,
        "metric": "Energy overhead",
        "their_result": "“up to one fifth of their energy overhead”",
        "baseline_result": "Baselines incur up to 5× the energy overhead of the proposed technique (exact values not specified)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Energy overhead",
      "Robustness to previously unseen attacks (qualitative)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can limited control over ambient energy be used as an attack vector in battery-less IoT to induce livelock, denial of service, or priority inversion without physical access?",
        "How to detect such energy attacks accurately and with low latency directly on intermittently powered IoT devices with minimal energy overhead?",
        "What vulnerabilities in existing intermittent computing designs (e.g., static activation thresholds) enable these attacks?"
      ],
      "gaps_identified": [
        "Security for intermittent computing is largely unexplored compared to functionality and forward progress.",
        "Existing intermittent systems often use statically set activation thresholds (Von) that do not guarantee progress when ambient energy is blocked during active periods.",
        "Prior security work focuses mainly on securing persistent state/checkpoints, not on energy-provisioning-based attacks or their detection."
      ],
      "limitations": [],
      "future_work": [
        "Design of attack-specific countermeasures and generic software/hardware defenses.",
        "Adaptive energy management to mitigate energy attacks.",
        "Supporting multiple energy sources to reduce susceptibility to manipulation."
      ],
      "motivation": "Battery-less IoT devices are increasingly used, including in safety-critical applications, but intermittent operation due to scarce/variable energy creates new security vulnerabilities exploitable by manipulating ambient energy. There is a need to understand these attacks and detect them on-device with minimal energy impact.",
      "potential_research_ideas": [
        "Formalize a threat model and verification framework for energy attack resilience across hardware, energy buffers, and software stacks.",
        "Collaborative, network-level detection that fuses multi-node energy/traffic observations to localize and attribute energy attacks.",
        "Combine dynamic Von/Voff adaptation with learning-based predictors for safe energy checkpoints under adversarial energy.",
        "Integrate multi-source energy mixing and scheduling policies that are provably attack-resilient (e.g., game-theoretic controllers).",
        "Temporal sequence models tailored to MCU constraints (e.g., tiny RNN/TCN variants) for improved on-device detection under bursty patterns.",
        "Lightweight active probing (micro-calibration tasks) to estimate instantaneous energy inflow and detect adversarial suppression.",
        "Hardware-assisted sensing (e.g., on-chip energy monitors) to provide better features for detection without large overhead.",
        "Automatic synthesis of defensive task graphs that remain correct under intermittent execution with adversarial energy pauses."
      ],
      "architectural_improvement_recommendations": [
        "Replace static Von with adaptive, context-aware activation thresholds based on online energy inflow estimates.",
        "Augment intermittent runtimes with energy-aware schedulers that prioritize state persistence under suspected attack.",
        "Introduce multi-capacitor orchestration that prevents starvation/priority inversion by bounding inter-task buffer backlogs.",
        "Add lightweight, on-chip energy telemetry (voltage/current sampling) to expose richer features for detection.",
        "Use multi-source energy fusion (e.g., solar + RF) and rapid source switching to limit single-source manipulation.",
        "Implement secure radio control channels to reduce the attacker’s ability to time energy interference via packet sniffing.",
        "Employ intermittent-safe approximate computing modes during detection to cap energy draw deterministically."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "On-device inference on TI MSP430FR5969 MCU at 1 MHz; designed to avoid additional energy failures and minimize energy overhead. No GPU/accelerator required."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Battery-less IoT nodes powered by solar or RF (Powercast), with intermittent execution on MSP430-class MCUs",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Severe energy constraints and intermittent execution limit detector complexity.",
        "Need for low-latency, on-device detection to avoid radio overhead.",
        "Variable and application-dependent energy patterns complicate robust detection.",
        "Attackers may leverage packet sniffing to time energy manipulation."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Defines and systematizes energy attacks in battery-less IoT, showing livelock, denial of service, and priority inversion without physical access.",
      "Provides attack model and evidence of vulnerabilities (e.g., static activation thresholds) via exploratory and systematic studies.",
      "Designs an on-device ML-based detection technique leveraging approximate intermittent computing with “92%+ accuracy,” up to “37% better than the baselines,” and “up to one fifth of their energy overhead,” without inducing additional energy failures.",
      "Outlines defense directions including adaptive energy management and leveraging multiple energy sources."
    ]
  },
  {
    "arxiv_id": "2305.00550v1",
    "title": "SoK: Pragmatic Assessment of Machine Learning for Network Intrusion Detection",
    "authors": "Giovanni Apruzzese; Pavel Laskov; Johannes Schneider",
    "abstract": "Machine Learning (ML) has become a valuable asset to solve many real-world tasks. For Network Intrusion Detection (NID), however, scientific advances in ML are still seen with skepticism by practitioners. This disconnection is due to the intrinsically limited scope of research papers, many of which primarily aim to demonstrate new methods ``outperforming'' prior work -- oftentimes overlooking the practical implications for deploying the proposed solutions in real systems. Unfortunately, the value of ML for NID depends on a plethora of factors, such as hardware, that are often neglected in scientific literature.   This paper aims to reduce the practitioners' skepticism towards ML for NID by \"changing\" the evaluation methodology adopted in research. After elucidating which \"factors\" influence the operational deployment of ML in NID, we propose the notion of \"pragmatic assessment\", which enable practitioners to gauge the real value of ML methods for NID. Then, we show that the state-of-research hardly allows one to estimate the value of ML for NID. As a constructive step forward, we carry out a pragmatic assessment. We re-assess existing ML methods for NID, focusing on the classification of malicious network traffic, and consider: hundreds of configuration settings; diverse adversarial scenarios; and four hardware platforms. Our large and reproducible evaluations enable estimating the quality of ML for NID. We also validate our claims through a user-study with security practitioners.",
    "published_date": "2023-04-30",
    "pdf_link": "https://arxiv.org/pdf/2305.00550v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "survey",
      "benchmark"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Classification of malicious network traffic for Network Intrusion Detection (NID) with emphasis on pragmatic, deployment-oriented evaluation",
      "attack_types": [
        "intrusions (general)",
        "unknown/zero-day attacks (generalization to unseen attacks)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Evaluation methodology",
        "specific": null,
        "novel_contribution": "Introduces and formalizes a pragmatic assessment methodology and guidelines to evaluate ML for NID, including consideration of hardware platforms, configuration space, adversarial scenarios, and lifecycle costs"
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Neural Network",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Support Vector Machine",
        "specific": "One-Class SVM",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "KDD99 (KDD Cup 1999)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS2017 (CICIDS17)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Drebin (Android malware)",
        "type": "public",
        "domain": "android_apps",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ImageNet",
        "type": "public",
        "domain": "images (non-security reference benchmark)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIFAR (CIFAR-10/100)",
        "type": "public",
        "domain": "images (non-security reference benchmark)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "F1-score",
      "Accuracy",
      "False Positive Rate (FPR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ (§3): What are the factors taken into account by practitioners when developing ML-NIDS?",
        "RQ (§4): What should research on ML in NID do to allow practitioners to estimate the real value of the corresponding results?",
        "RQ (§5): Does the state-of-the-art allow us to estimate the real value of ML methods for NID?",
        "RQ (§6): Can pragmatic assessments be done in research?"
      ],
      "gaps_identified": [
        "State-of-research hardly allows one to estimate the value of ML for NID",
        "Lack of an ‘universal’ dataset for NID due to immense variability of networks",
        "Research evaluations focus primarily on the ML model component and overlook system, lifecycle, and hardware aspects",
        "Over-reliance on single metrics (e.g., F1-score) can conceal impractical false positive rates",
        "Popular datasets have issues (e.g., CICIDS17 is flawed; poor generalization to unknown attacks)",
        "Uncertainty transfer across networks: models do not reliably transfer between different network environments",
        "Practical costs (data collection/labeling, maintenance, hardware) often neglected in literature",
        "Quote (contradictory findings on CICIDS17): “0.96 for NN, 0.95 for DT” vs “DT reaching 0.99 F1-score, against the 0.96 of the NN.”"
      ],
      "limitations": [
        "Authors accept that lack of a universal dataset for NID cannot be solved today",
        "The pragmatic assessment focuses on network traffic classification (not the entire breadth of NID tasks)",
        "Adversarial behavior and network evolution are unpredictable and cannot be fully addressed during model development"
      ],
      "future_work": [
        "Adopt and extend the proposed pragmatic assessment guidelines in future ML-NID research",
        "Use the released code and study as a benchmark baseline for future studies",
        "Facilitate integration of ML research results into real NIDS via deployment-aware evaluations"
      ],
      "motivation": "Reduce practitioners’ skepticism by changing research evaluation methodology to include pragmatic aspects (hardware, lifecycle costs, adversarial scenarios) so practitioners can gauge the real value of ML for NID.",
      "potential_research_ideas": [
        "Design a standardized, community-maintained pragmatic benchmark suite for ML-NID covering multiple networks, adversarial scenarios, and hardware profiles",
        "Develop domain adaptation and transfer learning methods tailored to network uniqueness to improve cross-network generalization",
        "Create continual/online learning pipelines with drift detection for evolving networks and attacker-induced drifts",
        "Build adversarially robust NID models with realistic attacker models at the traffic-feature level (including cost-aware evasion)",
        "Investigate active learning and labeling budget optimization strategies for NID with minimal human annotation costs",
        "Explore federated or privacy-preserving collaborative learning across organizations to mitigate data scarcity and uniqueness",
        "Develop hardware-aware model selection/NAS for NID that optimizes latency/FPR/throughput on target appliances",
        "Advance uncertainty estimation and calibration techniques for NID to better control FPR at operational thresholds"
      ],
      "architectural_improvement_recommendations": [
        "Integrate hardware-aware training and model selection into the ML-NIDS pipeline (optimize for target CPU/edge/accelerator)",
        "Implement continual learning with modular re-assessment triggers (data drift detectors + retraining schedulers)",
        "Adopt cost-sensitive and FPR-constrained training objectives aligned with operational budgets",
        "Use ensemble pipelines combining unsupervised anomaly detectors (e.g., one-class SVM) with supervised classifiers to balance coverage and precision",
        "Add robust evaluation harness: cross-dataset validation, cross-network splits, and adversarial test sets with protocol-preserving constraints",
        "Include calibrated scoring and thresholding to meet strict FPR targets; report prediction intervals/uncertainty"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": "Experiments conducted across four different hardware platforms (details in the code repository)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Uniqueness of each network (per-network training/testing)",
        "Perpetual network evolution (concept drift)",
        "Adversaries intent on evasion (adversarial drift)",
        "Labeling cost and errors",
        "Maintenance cost across the lifecycle",
        "Hardware constraints and deployment environment diversity"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Elucidates practitioner-relevant factors for deploying ML in NID (business perspective, lifecycle, costs, hardware)",
      "Formalizes the notion of pragmatic assessment and provides guidelines for conducting it",
      "Systematically reviews ML-NIDS papers (top security venues since 2017) against pragmatic assessment criteria and reports practitioner viewpoints",
      "Performs the first large pragmatic assessment of ML for NID (traffic classification) across hundreds of configurations, diverse adversarial scenarios, and four hardware platforms with statistically validated results",
      "Releases code to ensure reproducibility and to serve as a benchmark",
      "Validates claims through a user study with security practitioners"
    ]
  },
  {
    "arxiv_id": "2305.09482v1",
    "title": "Your Identity is Your Behavior -- Continuous User Authentication based on Machine Learning and Touch Dynamics",
    "authors": "Brendan Pelto; Mounika Vanamala; Rushit Dave",
    "abstract": "The aim of this research paper is to look into the use of continuous authentication with mobile touch dynamics, using three different algorithms: Neural Network, Extreme Gradient Boosting, and Support Vector Machine. Mobile devices are constantly increasing in popularity in the world, today smartphone subscriptions have surpassed 6 billion. Mobile touch dynamics refer to the distinct patterns of how a user interacts with their mobile device, this includes factors such as touch pressure, swipe speed, and touch duration. Continuous authentication refers to the process of continuously verifying a user's identity while they are using a device, rather than just at the initial login. This research used a dataset of touch dynamics collected from 40 subjects using the LG V30+. The participants played four mobile games, PUBG, Diep.io, Slither, and Minecraft, for 10 minutes each game. The three algorithms were trained and tested on the extracted dataset, and their performance was evaluated based on metrics such as accuracy, precision, false negative rate, and false positive rate. The results of the research showed that all three algorithms were able to effectively classify users based on their individual touch dynamics, with accuracy ranging from 80% to 95%. The Neural Network algorithm performed the best, achieving the highest accuracy and precision scores, followed closely by XGBoost and SVC. The data shows that continuous authentication using mobile touch dynamics has the potential to be a useful method for enhancing security and reducing the risk of unauthorized access to personal devices. This research also notes the importance of choosing the correct algorithm for a given dataset and use case, as different algorithms may have varying levels of performance depending on the specific task.",
    "published_date": "2023-04-24",
    "pdf_link": "https://arxiv.org/pdf/2305.09482v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Authentication and Access Control",
      "subdomain": "Continuous Authentication",
      "specific_problem": "Mobile continuous user authentication using behavioral biometrics from multi-finger touch dynamics",
      "attack_types": [
        "unauthorized access",
        "impostor login"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Neural Network",
        "specific": null,
        "novel_contribution": "Applied as per-user binary classifier on a new multi-finger mobile touch dynamics dataset; showed best average performance among evaluated models"
      },
      {
        "type": "baseline",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "SVC",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Touch Dynamics Multi-Finger Mobile Games Dataset (40 users, LG V30+)",
        "type": "public",
        "domain": "touch_dynamics",
        "link": "https://github.com/Brprb08/Touch-Dynamics-Research",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Touchalytics",
        "type": "unknown",
        "domain": "touch_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "DeRidder et al. (2022) multi-finger touch dynamics dataset (25 users, Minecraft and Slither, 10 minutes each)",
        "type": "unknown",
        "domain": "touch_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Siddiqui et al. (2021) mouse dynamics dataset (10 users, Minecraft)",
        "type": "unknown",
        "domain": "mouse_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Siddiqui et al. (2022) Applications to Mouse Dynamics dataset (40 users)",
        "type": "unknown",
        "domain": "mouse_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Ackerson et al. (2021) keyboard and mouse dynamics dataset (744 users)",
        "type": "unknown",
        "domain": "keyboard_mouse_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Accuracy (average across 40 users)",
        "their_result": "Neural Network: 90.04%",
        "baseline_result": "XGBoost: 86.61%"
      },
      {
        "method_name": "SVC",
        "paper_reference": null,
        "metric": "Accuracy (average across 40 users)",
        "their_result": "Neural Network: 90.04%",
        "baseline_result": "SVC: 78.65%"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "F1 score",
      "false positive rate (FPR)",
      "false negative rate (FNR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can multi-finger (two-finger) touch dynamics support effective continuous authentication on mobile devices?",
        "How do different machine learning classifiers (Neural Network, XGBoost, SVC) perform for per-user binary authentication on multi-finger touch data?",
        "Does multi-finger gesture-based touch dynamics improve classification performance compared to single-finger approaches reported in prior work?"
      ],
      "gaps_identified": [
        "A gap in multi-finger touch dynamics datasets suitable for continuous authentication research.",
        "Limited comparative evaluation of multiple ML models on multi-finger mobile touch dynamics.",
        "Lack of approaches to detect imposters without prior enrollment data for a user."
      ],
      "limitations": [
        "Requires continuous two-finger input; many users commonly operate mobile devices with a single finger.",
        "Approach requires prior user data (enrollment) for accurate authentication.",
        "May be unusable for users who cannot provide two-finger touch interactions."
      ],
      "future_work": [
        "Create methods for detecting imposters without prior user data (open-set or zero-/few-shot impostor detection).",
        "Explore additional machine learning classifiers for multi-finger authentication and compare performance."
      ],
      "motivation": "Enhance mobile device security by enabling continuous authentication based on distinctive behavioral biometrics from touch dynamics, addressing risks of unauthorized access beyond one-time login methods.",
      "potential_research_ideas": [
        "Open-set continuous authentication using anomaly detection or one-/few-shot learning to identify imposters without prior enrollment.",
        "Sequence modeling of raw multi-finger trajectories with temporal deep models (e.g., LSTM/GRU/Temporal CNN/Transformers) instead of aggregated statistics.",
        "Multi-stream architectures that process each finger’s trajectory separately with cross-finger attention or late fusion.",
        "Self-supervised or contrastive pretraining on unlabeled touch sequences to learn robust user embeddings with minimal enrollment.",
        "Domain adaptation and personalization across devices and apps (games, typing, browsing) to handle distribution shifts.",
        "Sensor fusion with additional smartphone sensors (gyroscope/accelerometer/orientation/pressure) for richer behavioral signals.",
        "Robustness to mimicry and adversarial attempts via adversarial training and impostor simulation.",
        "Privacy-preserving on-device training or federated learning to keep behavioral biometrics local."
      ],
      "architectural_improvement_recommendations": [
        "Replace hand-crafted aggregate features with end-to-end temporal models (e.g., BiLSTM/Temporal CNN/Transformer) on variable-length sequences.",
        "Design a two-branch (one per finger) network with shared weights and cross-attention, followed by metric learning loss (triplet/ArcFace) for user embeddings.",
        "Adopt open-set recognition (e.g., one-class SVM/OC-NN or energy-based scoring) to handle unseen imposters without prior data.",
        "Calibrate decision thresholds per user with cost-sensitive optimization to explicitly minimize FPR while maintaining low FNR.",
        "Use data augmentation for trajectories (time warping, jittering, speed scaling) to improve generalization.",
        "Implement on-device inference with model compression (quantization/pruning) to meet latency and battery constraints."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Requires continuous two-finger interaction, which may not match common single-finger usage patterns.",
        "Needs prior user enrollment data to authenticate correctly.",
        "Potential device and app heterogeneity may affect generalization and model calibration."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a new multi-finger touch dynamics dataset of 40 users playing four mobile games on LG V30+ (publicly released).",
      "Implements and compares three per-user binary classifiers (Neural Network, XGBoost, SVC) for continuous authentication.",
      "Demonstrates effective user classification with average accuracies ~78.65% (SVC), 86.61% (XGBoost), and 90.04% (Neural Network).",
      "Reports detailed biometric metrics (F1, FPR, FNR) and highlights the trade-offs relevant to continuous authentication.",
      "Positions multi-finger gesture-based touch dynamics relative to prior single-finger approaches and literature."
    ]
  },
  {
    "arxiv_id": "2305.00605v2",
    "title": "Classification and Online Clustering of Zero-Day Malware",
    "authors": "Olha Jurečková; Martin Jureček; Mark Stamp; Fabio Di Troia; Róbert Lórencz",
    "abstract": "A large amount of new malware is constantly being generated, which must not only be distinguished from benign samples, but also classified into malware families. For this purpose, investigating how existing malware families are developed and examining emerging families need to be explored. This paper focuses on the online processing of incoming malicious samples to assign them to existing families or, in the case of samples from new families, to cluster them. We experimented with seven prevalent malware families from the EMBER dataset, four in the training set and three additional new families in the test set. Based on the classification score of the multilayer perceptron, we determined which samples would be classified and which would be clustered into new malware families. We classified 97.21% of streaming data with a balanced accuracy of 95.33%. Then, we clustered the remaining data using a self-organizing map, achieving a purity from 47.61% for four clusters to 77.68% for ten clusters. These results indicate that our approach has the potential to be applied to the classification and clustering of zero-day malware into malware families.",
    "published_date": "2023-05-01",
    "pdf_link": "https://arxiv.org/pdf/2305.00605v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Family Classification",
      "specific_problem": "Online assignment of incoming PE malware to known families and clustering of previously unseen (zero-day) families from static features",
      "attack_types": [
        "zero-day malware",
        "malware families (PE)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Feedforward Neural Network",
        "specific": "Multilayer Perceptron (MLP)",
        "novel_contribution": "Confidence/score-based gating of streaming samples to decide known-family classification vs deferring to clustering"
      },
      {
        "type": "primary",
        "category": "SOM",
        "specific": "Self-Organizing Map",
        "novel_contribution": "Online clustering of deferred (suspected novel-family) samples; evaluated purity across different cluster counts"
      },
      {
        "type": "baseline",
        "category": "K-means",
        "specific": "Online k-means (MacQueen sequential k-means, OKM)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Sequential Clustering",
        "specific": "Basic Sequential Algorithmic Scheme (BSAS)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Online"
    ],
    "datasets": [
      {
        "name": "EMBER",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://github.com/elastic/ember",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "balanced_accuracy",
      "purity",
      "coverage (percent of streaming samples classified)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Signature-based detection cannot detect zero-day malware; need ML-based methods that handle emerging families online",
        "Most prior work focuses on offline classification or clustering; limited exploration of online processing to both classify known families and cluster novel families from streaming data"
      ],
      "limitations": [
        "Evaluation limited to static-analysis features from EMBER",
        "Experiments consider seven families (four seen in training, three novel in test), which may limit generality",
        "Clustering purity for novel families remains moderate (reported 47.61% with 4 clusters to 77.68% with 10 clusters)"
      ],
      "future_work": [],
      "motivation": "Continuously increasing malware volume necessitates automated, online methods that can assign samples to known families and discover/clustering emerging (zero-day) families.",
      "potential_research_ideas": [
        "Open-set recognition for malware family classification to formally model unknown detection before clustering",
        "Uncertainty calibration (e.g., temperature scaling, conformal prediction) to set principled thresholds for deferring samples to clustering",
        "Self-supervised representation learning on PE static features to improve both classification and clustering quality",
        "Multi-view fusion of static and dynamic analysis features for better novel-family separability",
        "Incremental metric learning or contrastive learning to maintain family-aware embeddings over streams",
        "Online drift detection to adapt thresholds and clustering as family distributions shift",
        "Active learning loop that queries analysts for labels on cluster exemplars to rapidly bootstrap new family models",
        "Evaluate additional online clustering algorithms (e.g., BIRCH, HDBSCAN*, DenStream) for improved purity and automatic cluster-number selection",
        "Leverage AVClass-style normalization to unify family labels and reduce noise for training and evaluation"
      ],
      "architectural_improvement_recommendations": [
        "Replace raw MLP scores with calibrated confidence or conformal p-values to decide classify-vs-cluster gating",
        "Adopt a shared embedding backbone (e.g., MLP with triplet/contrastive loss) so both classifier and SOM/clusterer operate in a metric-optimized space",
        "Use an online clustering method that does not require predefining cluster count and is robust to noise (e.g., HDBSCAN, BIRCH) for novel families",
        "Introduce a replay/memory buffer and incremental fine-tuning to convert newly formed clusters into supervised classes over time",
        "Add feature drift monitoring and adaptive thresholding to maintain stable coverage and balanced accuracy",
        "Combine static features with lightweight dynamic signals (e.g., import-based behavior surrogates) to improve separability of unknowns"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "An online pipeline that classifies streaming malware into known families using an MLP and defers low-confidence samples for clustering to identify emerging families",
      "Evaluation on EMBER-derived malware families: “We classified 97.21% of streaming data with a balanced accuracy of 95.33%.”",
      "Clustering of deferred samples using a self-organizing map: “achieving a purity from 47.61% for four clusters to 77.68% for ten clusters.”",
      "Demonstration that the approach can process samples one-by-one in real time to handle zero-day malware families"
    ]
  },
  {
    "arxiv_id": "2304.13941v1",
    "title": "Detecting inner-LAN anomalies using hierarchical forecasting",
    "authors": "Sevvandi Kandanaarachchi; Mahdi Abolghasemi; Hideya Ochiai; Asha Rao",
    "abstract": "Increasing activity and the number of devices online are leading to increasing and more diverse cyber attacks. This continuously evolving attack activity makes signature-based detection methods ineffective. Once malware has infiltrated into a LAN, bypassing an external gateway or entering via an unsecured mobile device, it can potentially infect all nodes in the LAN as well as carry out nefarious activities such as stealing valuable data, leading to financial damage and loss of reputation. Such infiltration could be viewed as an insider attack, increasing the need for LAN monitoring and security. In this paper we aim to detect such inner-LAN activity by studying the variations in Address Resolution Protocol (ARP) calls within the LAN. We find anomalous nodes by modelling inner-LAN traffic using hierarchical forecasting methods. We substantially reduce the false positives ever present in anomaly detection, by using an extreme value theory based method. We use a dataset from a real inner-LAN monitoring project, containing over 10M ARP calls from 362 nodes. Furthermore, the small number of false positives generated using our methods, is a potential solution to the \"alert fatigue\" commonly reported by security experts.",
    "published_date": "2023-04-27",
    "pdf_link": "https://arxiv.org/pdf/2304.13941v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion/Anomaly Detection",
      "specific_problem": "Inner-LAN anomaly detection using ARP behavior forecasting and EVT-based thresholding",
      "attack_types": [
        "insider threats",
        "lateral movement",
        "internal scanning/reconnaissance",
        "malware propagation within LAN"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Hierarchical Time Series Forecasting",
        "specific": null,
        "novel_contribution": "First application of hierarchical forecasting to model inner-LAN ARP behavior across nodes and levels for anomaly detection; uses cross-sectional hierarchy of LAN nodes and reconciliation methods to produce coherent per-node forecasts."
      },
      {
        "type": "primary",
        "category": "Forecast Reconciliation",
        "specific": "Bottom-Up (BU), Top-Down (TD; historical proportions), MinT (minimum trace)",
        "novel_contribution": "Leverages reconciliation to inject network-wide constraints into per-node forecasts and improve accuracy for anomaly detection contexts."
      },
      {
        "type": "primary",
        "category": "Extreme Value Theory (EVT)",
        "specific": null,
        "novel_contribution": "EVT-based anomaly scoring on forecast residuals to handle heavy tails and reduce false positives; parameters derived in a data-driven manner."
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Time-series forecasting"
    ],
    "datasets": [
      {
        "name": "LAN Security Monitoring Project inner-LAN ARP dataset",
        "type": "public",
        "domain": "network_traffic (ARP calls)",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "false positive rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can inner-LAN anomalies be detected by modeling ARP call behavior per node using hierarchical time-series forecasting?",
        "Does reconciling forecasts across the LAN hierarchy improve per-node anomaly detection versus modeling nodes in isolation?",
        "Can EVT-based thresholding on forecast residuals substantially reduce false positives to mitigate alert fatigue?"
      ],
      "gaps_identified": [
        "Conventional NADS focus on gateway traffic and miss inner-LAN/insider activities.",
        "High false positive rates in anomaly detection cause alert fatigue.",
        "Rare anomalies slip through typical systems; need methods tailored to heavy-tailed traffic.",
        "Prior forecasting-based security work seldom leverages hierarchical forecasting or cross-node information.",
        "Encrypted C2 and non-blacklisted infrastructure limit signature-based and gateway-centric detection."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve inner-LAN security by forecasting normal ARP behavior across nodes and detecting deviations with low false positives to address insider/lateral movement that bypasses gateway monitors.",
      "potential_research_ideas": [
        "Extend from ARP-only to multimodal inner-LAN sensing (ARP+TCP/UDP/DNS/NetFlow) with multi-view hierarchical forecasting.",
        "Incorporate explicit LAN topology using graph-based temporal models (e.g., GNNs with temporal forecasting) for cross-node influence modeling.",
        "Develop online/streaming hierarchical forecasters with concept drift detection and adaptive EVT thresholds per node.",
        "Combine this approach with honeypot signals (e.g., Honeyboost) for joint detection and causal attribution.",
        "Evaluate robustness against adversarial evasion that mimics seasonal patterns; design adversarially robust forecasters/thresholds.",
        "Introduce probabilistic hierarchical forecasting (e.g., distributional forecasts) and calibrate EVT using forecast uncertainty.",
        "Benchmark against deep temporal models (e.g., N-BEATS, TFT, TCN) adapted for hierarchical reconciliation.",
        "Synthetic attack injection framework on the released dataset to quantify detection sensitivity across attack types/intensities."
      ],
      "architectural_improvement_recommendations": [
        "Adopt probabilistic hierarchical forecasting and propagate predictive intervals into EVT to set calibrated, node-specific thresholds.",
        "Integrate a graph-temporal layer that conditions forecasts on neighborhood activity and switch-level aggregates.",
        "Implement adaptive, per-node EVT with automated threshold selection (e.g., POT with stability diagnostics) updated online.",
        "Fuse ARP with selected TCP/UDP features via hierarchical multi-task learning where each node-task shares global seasonal components.",
        "Add change-point detection on residuals to trigger model re-calibration during abrupt behavior shifts.",
        "Leverage reconciliation variants (e.g., structural MinT with shrinkage covariance) to better handle noisy aggregates."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Enterprise/organizational LAN with diverse endpoints including IoT devices (cameras, printers, storage)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Integrating an internal monitoring device/sensor in LAN segments.",
        "Managing and tuning thresholds to avoid alert fatigue while maintaining sensitivity.",
        "Handling highly seasonal and heterogeneous per-node traffic patterns.",
        "Potential ARP-related vulnerabilities (spoofing/poisoning) influencing signals.",
        "Data governance and storage at scale (10M+ ARP calls) within enterprise constraints."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces hierarchical forecasting for inner-LAN anomaly detection using ARP data, leveraging cross-node information.",
      "Applies EVT-based anomaly detection on forecast residuals to substantially reduce false positives.",
      "Demonstrates feasibility on a real inner-LAN dataset with over 10M ARP calls from 362 nodes, and makes the dataset available.",
      "Positions inner-LAN monitoring as a complement to gateway NADS to detect insider/lateral activities and mitigate alert fatigue."
    ]
  },
  {
    "arxiv_id": "2304.14540v7",
    "title": "Efficient IAM Greybox Penetration Testing",
    "authors": "Yang Hu; Wenxi Wang; Sarfraz Khurshid; Mohit Tiwari",
    "abstract": "Identity and Access Management (IAM) is an access control service in cloud platforms. To securely manage cloud resources, customers need to configure IAM to specify the access control rules for their cloud organizations. However, misconfigured IAM can lead to privilege escalation (PE) attacks, causing significant economic loss. Third-party cloud security services detect such issues using whitebox penetration testing, which requires full access to IAM configurations. However, since these configurations often contain sensitive data, customers must manually anonymize them to protect their privacy. To address the dual challenges of anonymization and data privacy, we introduce TAC, the first greybox penetration testing approach for third-party services to efficiently detect IAM PEs. Instead of requiring customers to blindly anonymize their entire IAM configuration, TAC intelligently interacts with customers by querying only a small fraction of information in the IAM configuration that is necessary for PE detection. To achieve this, TAC integrates two key innovations: (1) a comprehensive IAM modeling approach to detect a wide range of IAM PEs using partial information collected from query responses, and (2) a query optimization mechanism leveraging Reinforcement Learning (RL) and Graph Neural Networks (GNNs) to minimize customer inputs. Additionally, to address the scarcity of real-world IAM PE datasets, we introduce IAMVulGen, a synthesizer that generates a large number of diverse IAM PEs that mimic real-world scenarios. Experimental results on both synthetic and real-world benchmarks show that TAC, as a greybox approach, achieves competitively low and, in some cases, significantly lower false negative rates than state-ofthe-art whitebox approaches, while utilizing a limited number of queries.",
    "published_date": "2023-04-27",
    "pdf_link": "https://arxiv.org/pdf/2304.14540v7",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cloud Security",
      "subdomain": "Identity and Access Management (IAM)",
      "specific_problem": "Greybox penetration testing for detecting IAM privilege escalation due to misconfigurations with minimal information disclosure",
      "attack_types": [
        "Privilege Escalation",
        "Transitive Privilege Escalation (multi-step)",
        "Misconfiguration Exploitation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": null,
        "novel_contribution": "RL-based pretraining to learn a query policy that minimizes the number of customer queries needed to detect IAM privilege escalations under a query budget"
      },
      {
        "type": "primary",
        "category": "GNN",
        "specific": null,
        "novel_contribution": "Graph Neural Network-based query model over a Permission Flow Graph representation to guide query selection"
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Deep Learning"
    ],
    "datasets": [
      {
        "name": "IAMVulGen synthetic IAM PE tasks",
        "type": "synthetic",
        "domain": "iam_configurations",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "IAM Vulnerable (31 IAM PE tasks)",
        "type": "public",
        "domain": "iam_configurations",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Two real-world IAM PE tasks from a security startup",
        "type": "proprietary",
        "domain": "iam_configurations",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "500 held-out synthetic IAM PE tasks generated by IAMVulGen (for evaluation)",
        "type": "synthetic",
        "domain": "iam_configurations",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Pacu",
        "paper_reference": null,
        "metric": "False Negative Rate; PEs detected",
        "their_result": "“TAC, as a greybox approach, achieves competitively low and, in some cases, significantly lower false negative rates than state-of-the-art whitebox approaches, while utilizing a limited number of queries.”",
        "baseline_result": null
      },
      {
        "method_name": "Cloudsplaining",
        "paper_reference": null,
        "metric": "False Negative Rate; PEs detected",
        "their_result": "On IAM Vulnerable, “TAC is able to detect 23 PEs (under a query budget of 10), and all 31 PEs (with a query budget of 20), which substantially outperforms all three whitebox baselines.”",
        "baseline_result": null
      },
      {
        "method_name": "PMapper",
        "paper_reference": null,
        "metric": "False Negative Rate; PEs detected",
        "their_result": "On synthesized IAMVulGen tasks, “TAC’s whitebox variant successfully detected all PEs, and significantly outperforms all three state-of-the-art whitebox baselines.”",
        "baseline_result": null
      },
      {
        "method_name": "TAC whitebox variant (ablation)",
        "paper_reference": null,
        "metric": "PEs detected",
        "their_result": "“TAC’s whitebox variant successfully detected all PEs” on the synthesized IAMVulGen task set.",
        "baseline_result": null
      },
      {
        "method_name": "Four greybox TAC variants (different pretraining/query models; ablations)",
        "paper_reference": null,
        "metric": "PEs detected within query budget; average number of queries",
        "their_result": "“Given a query budget of 100, TAC identifies 32% to 68% more PEs with 13% to 23% fewer queries on average than all its four greybox variants.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "False Negative Rate (FNR)",
      "Number of queries",
      "Query budget",
      "PEs detected / detection rate"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can IAM privilege escalations be detected with partial, privacy-preserving access to configurations via interactive querying?",
        "How to model IAM to detect a broad class of single-step and multi-step privilege escalations using partial information?",
        "How to optimize query selection to minimize customer input under a query budget?"
      ],
      "gaps_identified": [
        "All existing third-party IAM PE detectors require whitebox access to full IAM configurations, creating privacy risks and manual anonymization burden.",
        "Scarcity of publicly available IAM PE datasets (only 31 tasks in IAM Vulnerable).",
        "Lack of greybox or blackbox penetration testing tools for IAM PEs."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Reduce privacy exposure and manual anonymization while maintaining or improving IAM PE detection effectiveness by moving from whitebox to interactive greybox penetration testing with minimal queries.",
      "potential_research_ideas": [
        "Extend TAC’s modeling and query policy to multi-cloud IAM (AWS, Azure, GCP) and cross-account scenarios.",
        "Incorporate privacy guarantees (e.g., differential privacy or formal privacy budgets) into query policies for quantifiable privacy-utility trade-offs.",
        "Robust query optimization under uncertain or noisy customer responses using uncertainty-aware or Bayesian RL.",
        "Meta-learning or continual learning to rapidly adapt query policies to new organizations or evolving IAM schemas.",
        "Joint symbolic–neuro approach: combine formal PE reachability search with learned query heuristics (e.g., MCTS+GNN).",
        "Human-in-the-loop optimization to prioritize queries based on operator-specified sensitivity labels or cost models.",
        "Benchmarking and standardization: create larger public IAM PE corpora and generators with community-driven templates."
      ],
      "architectural_improvement_recommendations": [
        "Adopt heterogeneous or relation-aware GNNs (e.g., R-GCN or attention-based GNNs) to capture typed entities/relations in IAM graphs.",
        "Use curriculum learning and self-play to progressively learn multi-step/transitive PE strategies.",
        "Formulate the task as a POMDP with explicit belief-state tracking and plan with model-based RL or MCTS.",
        "Pretrain the GNN on large unlabeled IAM graphs with graph contrastive learning before RL fine-tuning.",
        "Constrain RL with symbolic safety and reachability properties to prune invalid actions and accelerate learning."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Third-party cloud security service interacting with enterprise cloud IAM configurations",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Protecting sensitive IAM configuration data while enabling effective detection",
        "Operator burden to answer queries within a budget",
        "Generalizing across diverse organizational IAM schemas and policies"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces TAC, the first interactive greybox penetration testing tool for IAM PE detection that minimizes disclosed information via query optimization.",
      "Develops a comprehensive IAM modeling approach using Permission Flow Graphs for detecting a broader class of single-step and multi-step PEs.",
      "Proposes a GNN- and RL-based query optimization mechanism to reduce the number of customer queries.",
      "Introduces IAMVulGen, a synthesizer generating diverse IAM PE tasks based on 72 entity types and 219 permission flow templates.",
      "Empirical evaluation on synthetic, public, and real-world tasks demonstrating competitive or better detection with fewer queries compared to whitebox tools."
    ]
  },
  {
    "arxiv_id": "2305.09674v3",
    "title": "Quantum Machine Learning for Malware Classification",
    "authors": "Grégoire Barrué; Tony Quertier",
    "abstract": "In a context of malicious software detection, machine learning (ML) is widely used to generalize to new malware. However, it has been demonstrated that ML models can be fooled or may have generalization problems on malware that has never been seen. We investigate the possible benefits of quantum algorithms for classification tasks. We implement two models of Quantum Machine Learning algorithms, and we compare them to classical models for the classification of a dataset composed of malicious and benign executable files. We try to optimize our algorithms based on methods found in the literature, and analyze our results in an exploratory way, to identify the most interesting directions to explore for the future.",
    "published_date": "2023-05-09",
    "pdf_link": "https://arxiv.org/pdf/2305.09674v3",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Classification",
      "specific_problem": "Binary (benign vs malicious) classification of Windows PE executables",
      "attack_types": [
        "malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Quantum SVM (kernel methods)",
        "specific": "QSVM with ZZFeatureMap",
        "novel_contribution": "Exploratory evaluation on malware PE-derived datasets; studies PCA/qubit count and feature-map choices."
      },
      {
        "type": "primary",
        "category": "Quantum SVM (kernel methods)",
        "specific": "QSVM with PauliFeatureMap",
        "novel_contribution": "Exploratory comparison against other quantum feature maps and classical SVMs."
      },
      {
        "type": "primary",
        "category": "Quantum SVM (kernel methods)",
        "specific": "QSVM with ZZphiFeatureMap",
        "novel_contribution": "Tests alternative data-mapping function (sin-based) within ZZFeatureMap."
      },
      {
        "type": "primary",
        "category": "Quantum SVM (kernel methods)",
        "specific": "QSVM with ZFeatureMap (no entanglement)",
        "novel_contribution": "Uses non-entangling map as control to assess entanglement benefit."
      },
      {
        "type": "primary",
        "category": "Quantum Neural Network (Variational)",
        "specific": "Variational QNN (RY layers + entanglement to ancilla qubits; parameter-shift training) adapted from [8]",
        "novel_contribution": "Implements two-class QNN with ancilla readout and studies depth, qubit count, learning rate, and epochs."
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Linear kernel",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Polynomial kernel",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "RBF kernel",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Sigmoid kernel",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Neural Network",
        "specific": "Classical feedforward NN (matched layers/epochs to QNN; batch size = 1)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "BODMAS",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PEMachineLearning",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Ordered Importance Features (OIF) (derived from EMBER features + import maliciousness score)",
        "type": "private",
        "domain": "feature_vectors",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Grayscale Images (64x64) (derived from PE binaries)",
        "type": "private",
        "domain": "images",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SVM (RBF kernel)",
        "paper_reference": null,
        "metric": "Accuracy (Images dataset, PCA=7; 1000 train / 200 test)",
        "their_result": "0.825 (QSVM ZZFeature)",
        "baseline_result": "0.80"
      },
      {
        "method_name": "SVM (Linear kernel)",
        "paper_reference": null,
        "metric": "Accuracy (Images dataset, PCA=7; 1000 train / 200 test)",
        "their_result": "0.825 (QSVM ZZFeature)",
        "baseline_result": "0.79"
      },
      {
        "method_name": "SVM (RBF kernel)",
        "paper_reference": null,
        "metric": "Accuracy (Images dataset; 16000 train / 4000 test)",
        "their_result": "0.81075 (QSVM ZZFeature)",
        "baseline_result": "0.81"
      },
      {
        "method_name": "SVM (Linear kernel)",
        "paper_reference": null,
        "metric": "Accuracy (IBM real hardware; 100 train / 20 test)",
        "their_result": "0.80 (QSVM PauliFeature)",
        "baseline_result": "0.85"
      },
      {
        "method_name": "Classical Neural Network",
        "paper_reference": null,
        "metric": "Accuracy (Images dataset; 4 data qubits ≈ PCA=4; 5 layers; 10 epochs)",
        "their_result": "0.64 (QNN)",
        "baseline_result": "0.54"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Do quantum machine learning models (QSVM, QNN) provide benefits for malware (benign vs malicious PE) classification compared to classical models?",
        "How do quantum feature maps, circuit depth, and number of qubits (PCA dimension) affect classification performance?",
        "Are quantum models advantageous in small-data regimes common in cybersecurity?",
        "What optimization choices from literature (e.g., parameter-shift, feature-map design) help improve QML performance on malware data?"
      ],
      "gaps_identified": [
        "Classical ML for malware can be fooled and may not generalize to unseen malware; exploring alternatives like QML could help.",
        "Limited labeled data in many cybersecurity scenarios motivates techniques that extract more information from small datasets.",
        "Current quantum simulators (e.g., Qiskit) lack parallelization for their circuits, leading to long runtimes, limiting experiment scale.",
        "Limited access to real quantum hardware and small number of available logical qubits constrain practical evaluation."
      ],
      "limitations": [
        "Experiments often restricted to small training/testing subsets due to compute/queue constraints and parameter-shift cost.",
        "Only two datasets and two preprocessing pipelines were explored; results may not generalize.",
        "QNN accuracy generally lagged QSVM and classical SVMs; deep circuits require many parameters and long training time.",
        "IBM hardware tests used very small sample sizes (100 train / 20 test), so differences correspond to only a few labels.",
        "Simulator performance (no circuit parallelization) and limited qubits prevented testing larger feature counts/datasets."
      ],
      "future_work": [
        "Adopt shot-frugal/backprop alternatives (e.g., techniques from [11],[19]) to improve QNN training efficiency beyond parameter-shift.",
        "Explore symmetry-aware/structure-exploiting circuits and feature maps tailored to PE static features.",
        "Scale evaluations with improved simulators/parallelization and more qubits; revisit larger feature sets.",
        "Expand to multi-class malware family classification and more diverse datasets.",
        "Systematically study entanglement benefit vs non-entangling encodings and data re-uploading strategies.",
        "Test robustness to adversarial malware modifications/evasion and OOD generalization.",
        "Investigate hybrid quantum-classical kernels and learned quantum kernels for SVMs.",
        "Deploy hardware-efficient ansätze with error mitigation when using real devices."
      ],
      "motivation": "Investigate whether quantum algorithms can improve malware classification, particularly under small data and generalization challenges where classical ML can be fooled.",
      "potential_research_ideas": [
        "Design learned quantum kernels (optimize feature-map parameters) and compare kernel-target alignment against classical kernels.",
        "Develop shot-frugal gradient estimators (e.g., SPSA/zeroth-order) for QNNs and benchmark vs parameter-shift on malware data.",
        "Combine quantum feature maps with classical linear models beyond SVMs (e.g., logistic regression) to test margin effects.",
        "Explore data re-uploading and amplitude encoding for richer embeddings of EMBER-derived features within limited qubits.",
        "Conduct adversarial-evasion studies to compare robustness of QML vs classical malware detectors.",
        "Leverage transfer learning: pretrain QNNs/QSVM feature maps on large generic PE corpora, then fine-tune on specific malware tasks.",
        "Incorporate hardware-aware ansätze and error-mitigation techniques to improve on-device results beyond toy subsets.",
        "Hybrid pipeline: quantum feature extraction + classical gradient boosting; measure gains on small labeled sets."
      ],
      "architectural_improvement_recommendations": [
        "Use hardware-efficient, shallow entangling layers with data re-uploading to boost expressivity without prohibitive parameter-shift cost.",
        "Replace parameter-shift with SPSA/NES or backprop-through-simulator methods from [11],[19] for faster QNN training.",
        "Optimize/learn parameters in the quantum feature maps (e.g., ZZFeatureMap with tunable coefficients) to align kernels to data.",
        "Adopt batch-based stochastic training on simulators with parallelized circuit executions to mitigate runtime.",
        "Experiment with error mitigation and readout error calibration on IBM hardware; use dynamical decoupling to improve fidelity.",
        "Apply feature selection tailored to quantum circuits (mutual-information or kernel-target alignment) to choose qubit-encoded features.",
        "Explore hybrid classical-quantum ensembles (stacked generalization) combining QSVM and classical SVM/NN outputs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Qiskit"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "QNN training via parameter-shift requires 3 circuit evaluations per parameter; training times reported (e.g., 4 qubits: ~9m44s–51m24s for 1–3 layers; 7 qubits: ~17m–1h23m). QSVM simulations are slow due to lack of simulator parallelization; limited IBM hardware access introduced queues."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Limited logical qubits on current hardware constrain feature counts (PCA dimension).",
        "Quantum simulator not parallelized, leading to long runtimes.",
        "Parameter-shift training cost scales with number of parameters; deep QNNs impractical.",
        "Queueing/limited access on IBM devices restricted on-hardware experiments.",
        "Encoding high-dimensional PE features into few qubits may lose information (PCA trade-offs)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Implements and compares QSVM variants (ZZFeatureMap, PauliFeatureMap, ZZphiFeatureMap, ZFeatureMap) and a QNN for malware PE classification.",
      "Shows QSVMs can match or slightly outperform classical SVMs on certain small-data/PCA settings (e.g., +2.5% accuracy at PCA=7 on Images dataset with 1000/200 split).",
      "Analyzes impact of PCA dimension (qubit count), feature-map choice, and circuit depth on performance and F1-score.",
      "Demonstrates feasibility of small-sample runs on real IBM hardware with results comparable to classical baselines.",
      "Provides exploratory insights that QNNs under current training (parameter-shift) and depths often underperform QSVMs/classical baselines on this task."
    ]
  },
  {
    "arxiv_id": "2306.01143v1",
    "title": "Federated Graph Learning for Low Probability of Detection in Wireless Ad-Hoc Networks",
    "authors": "Sivaram Krishnan; Jihong Park; Subhash Sagar; Gregory Sherman; Benjamin Campbell; Jinho Choi",
    "abstract": "Low probability of detection (LPD) has recently emerged as a means to enhance the privacy and security of wireless networks. Unlike existing wireless security techniques, LPD measures aim to conceal the entire existence of wireless communication instead of safeguarding the information transmitted from users. Motivated by LPD communication, in this paper, we study a privacy-preserving and distributed framework based on graph neural networks to minimise the detectability of a wireless ad-hoc network as a whole and predict an optimal communication region for each node in the wireless network, allowing them to communicate while remaining undetected from external actors. We also demonstrate the effectiveness of the proposed method in terms of two performance measures, i.e., mean absolute error and median absolute error.",
    "published_date": "2023-06-01",
    "pdf_link": "https://arxiv.org/pdf/2306.01143v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Wireless Network Security",
      "subdomain": "Covert Communications / Low Probability of Detection (LPD)",
      "specific_problem": "Minimize detectability of a wireless ad-hoc network by predicting per-node communication regions (coverage radii/transmit power) to minimize total communication area under connectivity constraints",
      "attack_types": [
        "RF signal detection by external Electronic Support Measures (ESM) devices"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Hybrid GCN + GAT for node-level regression",
        "novel_contribution": "Applies a hybrid of graph convolution and attention to predict optimal communication region per node for LPD; attention compensates for sparse node features in wireless topology graphs"
      },
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": null,
        "novel_contribution": "Federated training of GNNs across multiple workers to address limited, non-co-located topology data while preserving privacy and reducing background data exchange"
      },
      {
        "type": "primary",
        "category": "Model Pruning / Compression",
        "specific": "Magnitude-based pruning with sparsity threshold",
        "novel_contribution": "Prunes global model to reduce communication and memory footprint for deployment on storage-constrained IoT devices while maintaining accuracy up to ~30% sparsity"
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GCN (two graph convolution layers + fully connected layer)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Federated"
    ],
    "datasets": [
      {
        "name": "Synthetic wireless ad-hoc topology graphs (200 graphs, 5 nodes each)",
        "type": "synthetic",
        "domain": "wireless_topology_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "MLP",
        "paper_reference": null,
        "metric": "MAE and MedAE",
        "their_result": "GCN MAE=2.9; MedAE=2.4",
        "baseline_result": "MAE=6.12; MedAE=5.8"
      },
      {
        "method_name": "CNN",
        "paper_reference": null,
        "metric": "MAE and MedAE",
        "their_result": "GCN MAE=2.9; MedAE=2.4",
        "baseline_result": "MAE=5.8; MedAE=4.12"
      },
      {
        "method_name": "Standalone (single worker, 180 graphs) vs FL-25 (6 workers, 25 graphs each)",
        "paper_reference": null,
        "metric": "MedAE",
        "their_result": "FL-25 achieves ~20% reduction in MedAE on unseen graphs vs standalone",
        "baseline_result": "Standalone MedAE not reported numerically"
      },
      {
        "method_name": "GCN vs Hybrid GCN+GAT",
        "paper_reference": null,
        "metric": "MAE and MedAE",
        "their_result": "Hybrid GCN+GAT outperforms GCN (exact values not reported; shown qualitatively in Fig. 3b)",
        "baseline_result": "GCN MAE=2.9; MedAE=2.4"
      }
    ],
    "performance_metrics_used": [
      "Mean Absolute Error (MAE)",
      "Median Absolute Error (MedAE)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a GNN predict per-node communication regions from node locations to minimize the overall communication area under LPD constraints in ad-hoc networks?",
        "Can federated learning improve model performance under limited, non-co-located graph samples for LPD?",
        "How does model pruning impact prediction error and communication efficiency in federated GNNs for LPD?"
      ],
      "gaps_identified": [
        "Most LPD works focus on single point-to-point links; limited research considers multi-node wireless ad-hoc networks",
        "Existing ad-hoc LPD approaches rely on iterative algorithms that are computationally expensive and often lack closed-form analysis",
        "Training GCNs with limited node features can fail to converge; attention mechanisms are needed",
        "Training data for topology graphs is unlikely to be co-located, creating communication overhead if centralized"
      ],
      "limitations": [
        "Evaluation uses a small synthetic dataset (200 graphs, 5 nodes each)",
        "External actor location/model not included in the graphs",
        "Assumes 2D area of operation; does not consider 3D or mobility/dynamics",
        "Simplified physical layer assumptions (ignores small-scale fading; assumes small payload and adequate SNR)",
        "No code or dataset link provided",
        "Performance under pruning degrades notably beyond ~30% sparsity",
        "Results for the proposed hybrid GCN+GAT are presented qualitatively without explicit MAE/MedAE numbers"
      ],
      "future_work": [
        "Extend to realistic and dynamic scenarios in a 3D area of operation"
      ],
      "motivation": "Enable privacy-preserving, undetectable communication in wireless ad-hoc networks by minimizing detectability of transmissions while guaranteeing connectivity, avoiding expensive iterative algorithms and centralized data sharing.",
      "potential_research_ideas": [
        "Model explicit adversary/ESM detectors in the training objective to jointly optimize covertness against learned detection models",
        "Multi-objective optimization balancing detectability, connectivity, throughput, and latency with Pareto-front analysis",
        "Incorporate mobility: online/continual federated graph learning for time-varying topologies",
        "Integrate realistic channel models (shadowing, small-scale fading) and uncertainty-aware training",
        "Scale to larger graphs with variable node counts using hierarchical or graph transformer architectures",
        "Self-supervised pretraining on unlabeled topology graphs to reduce label dependence",
        "Robustness to federated poisoning/backdoor attacks on graph models used for LPD",
        "Personalized FL for heterogeneous node capabilities and local environments",
        "Explore differentiable combinatorial layers approximating MAST/MST within the GNN"
      ],
      "architectural_improvement_recommendations": [
        "Adopt graph transformers with distance/positional encodings to better capture long-range dependencies",
        "Use edge features (e.g., pairwise distances, path loss) and learnable edge attention biases",
        "Add uncertainty estimation (e.g., MC dropout) to drive risk-aware communication region selection",
        "Apply curriculum learning from simple to complex topologies",
        "Use sparsity-aware training and structured pruning; follow-up with post-pruning fine-tuning",
        "Employ secure aggregation and differential privacy in FL to strengthen privacy guarantees",
        "Consider asynchronous or hierarchical FL to improve scalability and reduce straggler effects",
        "Knowledge distillation to small on-device models for efficient deployment"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Wireless ad-hoc networks; target deployment on storage-constrained IoT devices",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Limited and non-co-located training data; centralized training incurs high communication overhead",
        "Model parameter communication costs in FL (mitigated via pruning)",
        "Unknown adversary/ESM location and behavior not modeled",
        "Resource constraints on edge/IoT devices require compact models",
        "Accuracy degradation beyond ~30% sparsity threshold"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Propose a GNN-based framework that predicts optimal per-node communication regions to minimize detectability (LPD) in ad-hoc networks",
      "Introduce a federated learning setup to train GNNs across workers without sharing raw topology data",
      "Apply magnitude-based pruning to the global model to reduce communication and enable deployment on constrained devices",
      "Demonstrate improved accuracy over MLP and CNN, and better performance with FL under limited samples; identify pruning sparsity regime (~≤30%) with stable error"
    ]
  },
  {
    "arxiv_id": "2306.02715v3",
    "title": "Federated Deep Learning for Intrusion Detection in IoT Networks",
    "authors": "Othmane Belarbi; Theodoros Spyridopoulos; Eirini Anthi; Ioannis Mavromatis; Pietro Carnelli; Aftab Khan",
    "abstract": "The vast increase of Internet of Things (IoT) technologies and the ever-evolving attack vectors have increased cyber-security risks dramatically. A common approach to implementing AI-based Intrusion Detection systems (IDSs) in distributed IoT systems is in a centralised manner. However, this approach may violate data privacy and prohibit IDS scalability. Therefore, intrusion detection solutions in IoT ecosystems need to move towards a decentralised direction. Federated Learning (FL) has attracted significant interest in recent years due to its ability to perform collaborative learning while preserving data confidentiality and locality. Nevertheless, most FL-based IDS for IoT systems are designed under unrealistic data distribution conditions. To that end, we design an experiment representative of the real world and evaluate the performance of an FL-based IDS. For our experiments, we rely on TON-IoT, a realistic IoT network traffic dataset, associating each IP address with a single FL client. Additionally, we explore pre-training and investigate various aggregation methods to mitigate the impact of data heterogeneity. Lastly, we benchmark our approach against a centralised solution. The comparison shows that the heterogeneous nature of the data has a considerable negative impact on the model's performance when trained in a distributed manner. However, in the case of a pre-trained initial global FL model, we demonstrate a performance improvement of over 20% (F1-score) compared to a randomly initiated global model.",
    "published_date": "2023-06-05",
    "pdf_link": "https://arxiv.org/pdf/2306.02715v3",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Federated intrusion detection for IoT network traffic under realistic non-IID client distributions",
      "attack_types": [
        "Scanning",
        "DDoS",
        "DoS",
        "XSS",
        "Password attacks",
        "Backdoor",
        "Injection",
        "Ransomware",
        "Man-in-the-Middle (MITM)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Deep Belief Network (DBN)",
        "specific": null,
        "novel_contribution": "Applied as a federated IDS model on TON-IoT with realistic non-IID client partitioning; evaluated with pre-training vs random initialization and multiple FL aggregation methods."
      },
      {
        "type": "primary",
        "category": "Multilayer Perceptron / Feedforward DNN",
        "specific": "DNN (128:128:64 ReLU)",
        "novel_contribution": "Used as a federated IDS model baseline against DBN; evaluated with pre-training vs random initialization and multiple FL aggregation methods."
      },
      {
        "type": "primary",
        "category": "Energy-based model",
        "specific": "Restricted Boltzmann Machines (RBMs) within DBN",
        "novel_contribution": "Layer-wise unsupervised pre-training with contrastive divergence prior to supervised fine-tuning for IDS."
      },
      {
        "type": "baseline",
        "category": "Federated Aggregation/Optimizer",
        "specific": "FedAvg",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Federated Aggregation/Optimizer",
        "specific": "FedProx",
        "novel_contribution": "Evaluated for robustness to non-IID; reported to increase detection performance over FedAvg."
      },
      {
        "type": "baseline",
        "category": "Federated Aggregation/Optimizer",
        "specific": "FedYogi",
        "novel_contribution": "Evaluated for heterogeneous settings; reported to perform closely to FedProx and better than FedAvg."
      },
      {
        "type": "primary",
        "category": "Transfer Learning",
        "specific": "Pre-training of initial global model",
        "novel_contribution": "Shows that starting FL from a pre-trained model improves F1 by over 20% vs random initialization in non-IID IoT IDS."
      }
    ],
    "learning_paradigm": [
      "Federated Learning",
      "Supervised",
      "Unsupervised pre-training"
    ],
    "datasets": [
      {
        "name": "TON-IoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MedBIoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "BoT-IoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "KDDCup'99",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Modbus dataset",
        "type": "public",
        "domain": "ics_network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "N-BaIoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Bot-IoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Centralised IDS (DNN/DBN)",
        "paper_reference": null,
        "metric": "F1-score (weighted), Precision (weighted), Recall (weighted)",
        "their_result": "Federated approaches under non-IID perform worse; centralised IDS \"performs significantly better than the FL approaches.\"",
        "baseline_result": "Centralised learning achieves higher performance; exact numbers not provided."
      },
      {
        "method_name": "Randomly initialised federated model",
        "paper_reference": null,
        "metric": "F1-score (weighted)",
        "their_result": "\"performance improvement of over 20% (F1-score)\" when starting from a pre-trained global model compared to random init.",
        "baseline_result": "Lower F1-score than pre-trained FL; exact values not provided."
      },
      {
        "method_name": "FedAvg vs FedProx vs FedYogi (aggregation)",
        "paper_reference": null,
        "metric": "F1-score (weighted), Precision (weighted), Recall (weighted)",
        "their_result": "\"FedProx increases the detection performance, followed closely by FedYogi\" in non-IID settings.",
        "baseline_result": "FedAvg underperforms compared to FedProx and FedYogi in non-IID settings; exact numbers not provided."
      }
    ],
    "performance_metrics_used": [
      "F1-score (weighted)",
      "Precision (weighted)",
      "Recall (weighted)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How does a federated IDS perform on realistic non-IID IoT network traffic when clients are defined by destination IPs?",
        "Does initializing FL with a pre-trained global model improve detection performance versus random initialization under non-IID data?",
        "Which federated aggregation method (FedAvg, FedProx, FedYogi) is more robust under non-IID client distributions?",
        "How do DBN-based and DNN-based IDSs compare under centralized vs federated training on TON-IoT?"
      ],
      "gaps_identified": [
        "Most FL-based IDS for IoT are designed under unrealistic data distribution conditions.",
        "Common IDS datasets are not designed for FL and/or do not reflect IoT-specific traffic.",
        "Non-IID client data induces performance degradation and convergence issues in FL.",
        "Lack of reproducible studies of FL-based IDS under realistic non-IID settings prevents fair comparison with prior work."
      ],
      "limitations": [
        "Results could not be compared against prior FL-based IDS works due to lack of comparable, reproducible non-IID methodologies.",
        "Evaluation is limited to one IoT dataset (TON-IoT) and ten clients (top destination IPs) to avoid tiny client datasets.",
        "Centralized IDS performs significantly better than FL approaches in this setup.",
        "Experiments were CPU-only (8-core, 16GB RAM), which may limit exploration of larger models or longer training."
      ],
      "future_work": [],
      "motivation": "Enable privacy-preserving and scalable intrusion detection for heterogeneous IoT ecosystems while addressing the challenge of non-IID client data in federated learning.",
      "potential_research_ideas": [
        "Personalized FL for IDS (e.g., pFedMe, FedPer, FedRep) to mitigate client heterogeneity while preserving a global backbone.",
        "Client clustering or hierarchical FL based on traffic profiles or IP subnets to reduce non-IID effects.",
        "Self-supervised or contrastive pre-training on large unlabeled IoT traffic corpora to initialize robust FL models.",
        "Domain adaptation across multiple IoT datasets (TON-IoT, Bot-IoT, N-BaIoT) for cross-domain generalization.",
        "Adaptive aggregation with client-level distribution shift estimation (label/feature shift-aware weighting, SCAFFOLD-style control variates).",
        "Robust aggregation against noisy or low-quality clients (e.g., Trimmed Mean, Median, Krum) and its effect on IDS metrics.",
        "Class-imbalance mitigation via class-balanced or focal losses, re-weighting, or federated re-sampling without leaking label stats.",
        "Communication-efficient FL for IDS (update sparsification, quantization, periodic averaging) with performance-communication trade-offs.",
        "Knowledge distillation from a centralized teacher to federated students to close the performance gap while preserving privacy.",
        "Concept drift detection and continual FL to handle evolving IoT attack patterns."
      ],
      "architectural_improvement_recommendations": [
        "Incorporate temporal models (1D-CNN+TCN or Transformer encoders) to capture flow/sequence dynamics beyond tabular features.",
        "Graph Neural Networks to model device-to-device or IP-level communication graphs for relational intrusion patterns.",
        "Use federated optimizers like FedAdam/FedOpt or SCAFFOLD to reduce client-drift; evaluate server-side momentum/Adam.",
        "Apply class-imbalance techniques (focal loss, class-balanced loss) and calibration (temperature scaling) for better minority attack detection.",
        "Federated feature standardization (per-feature scaling with secure aggregation of stats) to reduce preprocessing-induced drift.",
        "Leverage multi-dataset pre-training and selective fine-tuning (frozen lower layers) to stabilize FL under non-IID.",
        "Client selection policies based on dataset quality/coverage; adaptive participation to stabilize training.",
        "Evaluate secure aggregation and differential privacy to quantify privacy-utility trade-offs for IDS."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PyTorch",
        "Flower"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Experiments on 8-core CPU with 16GB RAM (macOS). 10 clients, 50 FL rounds, 2 local epochs per round; no GPU reported."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Non-IID client data significantly degrades FL performance relative to centralized training.",
        "Severe class imbalance across clients and globally complicates reliable detection.",
        "Independent local preprocessing can introduce distributional discrepancies across clients.",
        "Trade-off between privacy/locality and detection performance (centralized outperforms FL in this study)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Realistic FL-based IDS evaluation on TON-IoT by partitioning flows per destination IP to induce strong non-IID client distributions.",
      "Implementation and comparison of DBN-based and DNN-based IDS in centralized and federated settings.",
      "Systematic study of pre-training for FL IDS, showing over 20% F1 improvement vs random initialization under non-IID.",
      "Evaluation of aggregation methods (FedAvg, FedProx, FedYogi) in non-IID settings; FedProx performed best, followed by FedYogi."
    ]
  },
  {
    "arxiv_id": "2305.02396v2",
    "title": "Can Feature Engineering Help Quantum Machine Learning for Malware Detection?",
    "authors": "Ran Liu; Maksim Eren; Charles Nicholas",
    "abstract": "With the increasing number and sophistication of malware attacks, malware detection systems based on machine learning (ML) grow in importance. At the same time, many popular ML models used in malware classification are supervised solutions. These supervised classifiers often do not generalize well to novel malware. Therefore, they need to be re-trained frequently to detect new malware specimens, which can be time-consuming. Our work addresses this problem in a hybrid framework of theoretical Quantum ML, combined with feature selection strategies to reduce the data size and malware classifier training time. The preliminary results show that VQC with XGBoost selected features can get a 78.91% test accuracy on the simulator. The average accuracy for the model trained using the features selected with XGBoost was 74% (+- 11.35%) on the IBM 5 qubits machines.",
    "published_date": "2023-05-03",
    "pdf_link": "https://arxiv.org/pdf/2305.02396v2",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Android Malware Detection",
      "specific_problem": "Binary classification of Android apps (benign vs malware) using quantum machine learning with classical feature selection and resampling",
      "attack_types": [
        "Android malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Quantum Variational Circuit Classifier",
        "specific": "Variational Quantum Classifier (VQC; Havlíček et al., 2019 quantum-enhanced feature spaces)",
        "novel_contribution": "Applies VQC to Android malware detection with XGBoost-selected features; evaluates on IBM 5-qubit hardware and simulator; explores oversampling/undersampling to work within qubit limits"
      },
      {
        "type": "primary",
        "category": "Quantum SVM",
        "specific": "Quantum kernel estimation SVM (QSVM; Havlíček et al., 2019)",
        "novel_contribution": "Evaluated on IBM 5-qubit hardware with feature-selected inputs and data resampling; reports accuracy with 95% CI"
      },
      {
        "type": "baseline",
        "category": "Feature Selection",
        "specific": "XGBoost feature importance",
        "novel_contribution": "Used to select top-20 features from 215 to fit limited qubit capacity and reduce training time"
      },
      {
        "type": "baseline",
        "category": "Feature Selection",
        "specific": "Decision Tree feature importance",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Data Resampling - Oversampling",
        "specific": "SMOTE",
        "novel_contribution": "Applied to improve quantum classifier performance under small-sample constraints"
      },
      {
        "type": "baseline",
        "category": "Data Resampling - Oversampling",
        "specific": "ADASYN",
        "novel_contribution": "Applied to improve quantum classifier performance under small-sample constraints"
      },
      {
        "type": "baseline",
        "category": "Data Resampling - Undersampling",
        "specific": "K-means-based undersampling",
        "novel_contribution": "Removes samples via clustering to fit within hardware limits"
      },
      {
        "type": "baseline",
        "category": "Data Resampling - Undersampling",
        "specific": "Neighborhood agreement-based removal (e.g., edited-nearest-neighbors style)",
        "novel_contribution": "Removes samples that do not agree with their neighborhood to mitigate noise"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Drebin",
        "type": "public",
        "domain": "mobile_malware",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "QSVM (hardware, 5-qubit) vs VQC",
        "paper_reference": "Havlíček et al., Nature 2019",
        "metric": "accuracy",
        "their_result": "VQC achieved 80% success",
        "baseline_result": "QSVM got 56% accuracy"
      },
      {
        "method_name": "VQC with DT-selected features (simulator) vs VQC with XGBoost-selected features",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "78.91% (VQC with XGBoost-selected top-20 features, 10,000 samples, 50% test split)",
        "baseline_result": "62.41% (VQC with Decision Tree-selected features)"
      },
      {
        "method_name": "SMOTE oversampling vs no resampling (hardware small-sample setting)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "80.15%",
        "baseline_result": "74%"
      },
      {
        "method_name": "ADASYN oversampling vs no resampling (hardware small-sample setting)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "78.06%",
        "baseline_result": "74%"
      },
      {
        "method_name": "K-means undersampling vs no resampling (hardware small-sample setting)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "78.62%",
        "baseline_result": "74%"
      },
      {
        "method_name": "Neighborhood-based undersampling vs no resampling (hardware small-sample setting)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "77.26%",
        "baseline_result": "74%"
      },
      {
        "method_name": "Combined over- and under-sampling vs no resampling (hardware small-sample setting)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "83.78%",
        "baseline_result": "74%"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "95% confidence interval"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can classical feature engineering (feature selection) enable effective quantum machine learning for malware detection under limited qubit resources?",
        "Do oversampling and undersampling strategies improve quantum classifier performance on small hardware-constrained datasets?",
        "How do VQC and QSVM perform for Android malware detection on simulator vs near-term quantum hardware?"
      ],
      "gaps_identified": [
        "Supervised malware classifiers often do not generalize well to novel malware and require frequent retraining.",
        "Current quantum hardware has very limited qubit capacity and noise, constraining practical ML applications.",
        "Quantum annealing and some quantum approaches show partial noise robustness and limited applicability on large datasets.",
        "Mapping high-dimensional classical features to quantum states is challenging when features far exceed available qubits."
      ],
      "limitations": [
        "Experiments on real hardware are limited to IBM 5-qubit machines with only 20 samples per run and 50% test split.",
        "Results are preliminary with substantial variance (e.g., 74% ± 11.35% on hardware).",
        "Conflicting or variable results across QSVM and VQC on hardware due to noise and tiny sample sizes.",
        "No comparison against strong classical malware detection baselines on the same feature subsets.",
        "No public code or detailed hyperparameter settings reported."
      ],
      "future_work": [
        "Explore the practical use of quantum machines for malware detection as hardware improves and qubit counts increase."
      ],
      "motivation": "Reduce data dimensionality and training time for malware classifiers by combining theoretical quantum ML advantages with classical feature selection to address poor generalization and frequent retraining needs.",
      "potential_research_ideas": [
        "Evaluate quantum classifiers on larger qubit devices with error mitigation to assess scalability beyond 20 samples.",
        "Systematically compare QML against strong classical baselines (e.g., XGBoost, LightGBM, RF, SVM) on the same selected features.",
        "Investigate quantum kernel alignment/selection and multiple feature maps tailored to malware feature distributions.",
        "Develop quantum-friendly representation learning (e.g., classical autoencoders/PCA to 6–20 dims) before quantum encoding.",
        "Study semi-supervised or anomaly-detection quantum approaches for novel malware detection under label scarcity.",
        "Assess robustness to label noise and adversarial perturbations of features in quantum pipelines.",
        "Automate feature selection jointly with hardware-efficient ansatz search (AutoML for hybrid QML).",
        "Fuse static and dynamic Android features with hybrid classical-quantum ensembles and stacking."
      ],
      "architectural_improvement_recommendations": [
        "Use hardware-efficient ansatz with shallow depth and optimized entanglement patterns to reduce decoherence.",
        "Experiment with alternative encodings (angle, amplitude, basis, re-uploading) and feature maps beyond Havlíček’s.",
        "Apply error mitigation (measurement error mitigation, zero-noise extrapolation) and dynamical decoupling on hardware.",
        "Perform classical dimensionality reduction (PCA/autoencoder) before XGBoost-based selection to preserve informative variance.",
        "Tune optimizer/hyperparameters for VQC (e.g., COBYLA, SPSA) and use Bayesian optimization for circuit parameters.",
        "Increase shots and perform cross-validation with stratification; report full variance and CIs.",
        "Calibrate transpilation to hardware topology (e.g., map to qubit pairs with best fidelity) and constrain circuit depth.",
        "Adopt combined resampling pipelines with validation to avoid overfitting (SMOTE+ENN/KMeans) and evaluate on held-out sets."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Qiskit",
        "XGBoost"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "IBM 5-qubit quantum processors; experiments repeated 10 times with 20 samples per run; additional runs on Qiskit simulator"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Very limited number of qubits on available hardware",
        "Quantum noise and decoherence affecting accuracy",
        "High-dimensional feature mapping constrained by qubit counts",
        "Small effective training sets on hardware (20 samples/run)",
        "Potential dataset imbalance and noise from oversampling",
        "Queueing and access constraints to quantum devices"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a hybrid approach combining classical feature selection (XGBoost/Decision Tree) with quantum classifiers (VQC, QSVM) for Android malware detection.",
      "Reports simulator and hardware results: 78.91% test accuracy on simulator with VQC and XGBoost-selected features; average 74% (±11.35% 95% CI) on IBM 5-qubit hardware.",
      "Explores data resampling (SMOTE, ADASYN, K-means undersampling, neighborhood-based undersampling) to improve performance under hardware constraints, with combined resampling up to 83.78% accuracy.",
      "Demonstrates feasibility and limitations of QML for malware detection on near-term quantum devices."
    ]
  },
  {
    "arxiv_id": "2306.00284v1",
    "title": "Case Study-Based Approach of Quantum Machine Learning in Cybersecurity: Quantum Support Vector Machine for Malware Classification and Protection",
    "authors": "Mst Shapna Akter; Hossain Shahriar; Sheikh Iqbal Ahamed; Kishor Datta Gupta; Muhammad Rahman; Atef Mohamed; Mohammad Rahman; Akond Rahman; Fan Wu",
    "abstract": "Quantum machine learning (QML) is an emerging field of research that leverages quantum computing to improve the classical machine learning approach to solve complex real world problems. QML has the potential to address cybersecurity related challenges. Considering the novelty and complex architecture of QML, resources are not yet explicitly available that can pave cybersecurity learners to instill efficient knowledge of this emerging technology. In this research, we design and develop QML-based ten learning modules covering various cybersecurity topics by adopting student centering case-study based learning approach. We apply one subtopic of QML on a cybersecurity topic comprised of pre-lab, lab, and post-lab activities towards providing learners with hands-on QML experiences in solving real-world security problems. In order to engage and motivate students in a learning environment that encourages all students to learn, pre-lab offers a brief introduction to both the QML subtopic and cybersecurity problem. In this paper, we utilize quantum support vector machine (QSVM) for malware classification and protection where we use open source Pennylane QML framework on the drebin215 dataset. We demonstrate our QSVM model and achieve an accuracy of 95% in malware classification and protection. We will develop all the modules and introduce them to the cybersecurity community in the coming days.",
    "published_date": "2023-06-01",
    "pdf_link": "https://arxiv.org/pdf/2306.00284v1",
    "paper_types": [
      "position",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection",
      "specific_problem": "Android malware classification using quantum support vector machine (QSVM) on Drebin-derived features",
      "attack_types": [
        "malware",
        "ransomware",
        "trojan",
        "worm",
        "spyware",
        "adware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "SVM/Kernel Method",
        "specific": "Quantum Support Vector Machine (QSVM) via PennyLane quantum kernel/circuit",
        "novel_contribution": "Case-study based, hands-on QSVM learning module for malware classification; demonstrated QSVM achieving 95% accuracy on drebin215 dataset within an educational labware framework"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "drebin215",
        "type": "public",
        "domain": "android_app_static_features",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "f1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Lack of explicit, hands-on pedagogical resources for QML applied to cybersecurity",
        "Scarcity of knowledgeable instructors and difficulties configuring end-to-end labs for QML security use-cases",
        "Limited availability of open-source, portable, easy-to-adopt QML labware for cybersecurity topics, especially malware protection"
      ],
      "limitations": [
        "Only one module (QSVM for malware classification) is demonstrated; the remaining modules are planned",
        "Model evaluation reported primarily as accuracy (95%) without comparisons to classical baselines",
        "Preliminary learning assessment with a small cohort (n=16) undergraduate students"
      ],
      "future_work": [
        "We will develop all the modules and introduce them to the cybersecurity community in the coming days.",
        "Encourage students to optimize detection accuracy with new ideas, testing, and experiments in post-lab activities"
      ],
      "motivation": "Considering the novelty and complex architecture of QML, resources are not yet explicitly available that can pave cybersecurity learners to instill efficient knowledge of this emerging technology.",
      "potential_research_ideas": [
        "Systematic benchmark comparing QSVM to strong classical baselines (e.g., linear/RBF SVM, Random Forest, XGBoost, deep learning) across multiple malware datasets",
        "Investigate quantum feature maps and kernels tailored to static Android features; perform ablations across encodings",
        "Assess robustness of QSVM to adversarial examples and obfuscation techniques common in Android malware",
        "Evaluate hybrid quantum-classical pipelines (quantum kernels + classical classifiers; or classical feature selection + QSVM)",
        "Port and test on diverse malware datasets (e.g., EMBER, Androzoo subsets) for generalization",
        "Evaluate performance on real quantum hardware versus simulators under noise models",
        "Incorporate explainability (e.g., feature importance via kernel attribution) for actionable insights in malware analysis"
      ],
      "architectural_improvement_recommendations": [
        "Add classical baselines and hyperparameter tuning for fair comparisons (e.g., grid search over C, kernel parameters)",
        "Use cross-validation and stratified splits; report full metrics (precision, recall, F1, ROC-AUC, confusion matrix)",
        "Explore multiple quantum feature maps and kernel alignment methods; select via validation",
        "Implement dimensionality reduction or feature selection (e.g., mutual information, PCA) before QSVM",
        "Calibrate thresholds and address class imbalance with reweighting or sampling if present",
        "Automate the labware with reproducible seeds, environment files, and dataset versioning"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PennyLane",
        "Google Colab"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Scarcity of knowledgeable instructors for QML in cybersecurity",
        "Complex setup and configuration of QML labs",
        "Collection of required resources and materials for hands-on labs",
        "Learner dedication needed to complete all steps"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Design and development of a case study-based, portable, open-source QML labware structure (pre-lab, lab, post-lab) for cybersecurity topics",
      "A suite of ten planned QML-cybersecurity learning modules; this paper presents the QSVM-for-malware-classification module",
      "Implementation of QSVM with PennyLane on the drebin215 dataset for malware classification",
      "Reported result: \"We demonstrate our QSVM model and achieve an accuracy of 95% in malware classification and protection.\"",
      "Preliminary student learning assessment (pre/post surveys) indicating positive learning outcomes"
    ]
  },
  {
    "arxiv_id": "2306.06109v1",
    "title": "Learning to Quantize Vulnerability Patterns and Match to Locate Statement-Level Vulnerabilities",
    "authors": "Michael Fu; Trung Le; Van Nguyen; Chakkrit Tantithamthavorn; Dinh Phung",
    "abstract": "Deep learning (DL) models have become increasingly popular in identifying software vulnerabilities. Prior studies found that vulnerabilities across different vulnerable programs may exhibit similar vulnerable scopes, implicitly forming discernible vulnerability patterns that can be learned by DL models through supervised training. However, vulnerable scopes still manifest in various spatial locations and formats within a program, posing challenges for models to accurately identify vulnerable statements. Despite this challenge, state-of-the-art vulnerability detection approaches fail to exploit the vulnerability patterns that arise in vulnerable programs. To take full advantage of vulnerability patterns and unleash the ability of DL models, we propose a novel vulnerability-matching approach in this paper, drawing inspiration from program analysis tools that locate vulnerabilities based on pre-defined patterns. Specifically, a vulnerability codebook is learned, which consists of quantized vectors representing various vulnerability patterns. During inference, the codebook is iterated to match all learned patterns and predict the presence of potential vulnerabilities within a given program. Our approach was extensively evaluated on a real-world dataset comprising more than 188,000 C/C++ functions. The evaluation results show that our approach achieves an F1-score of 94% (6% higher than the previous best) and 82% (19% higher than the previous best) for function and statement-level vulnerability identification, respectively. These substantial enhancements highlight the effectiveness of our approach to identifying vulnerabilities. The training code and pre-trained models are available at https://github.com/optimatch/optimatch.",
    "published_date": "2023-05-26",
    "pdf_link": "https://arxiv.org/pdf/2306.06109v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection",
      "specific_problem": "Function-level and statement-level vulnerability identification in C/C++ source code via learned vulnerability pattern matching",
      "attack_types": [
        "buffer overflow",
        "out-of-bounds write (e.g., CWE-787)",
        "common security flaws (generic)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Vector Quantization / Codebook Learning",
        "specific": "Learned vulnerability codebook (centroids/codewords)",
        "novel_contribution": "Quantizes vulnerable scopes into a trainable codebook of centroids representing vulnerability patterns, enabling explicit pattern matching at inference"
      },
      {
        "type": "primary",
        "category": "Optimal Transport",
        "specific": "Wasserstein distance minimization",
        "novel_contribution": "Uses OT/Wasserstein distance to cluster vulnerable scopes into centroids and to align scopes with codebook during training"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Bidirectional/stacked RNNs for statement embedding and vulnerable-scope summarization",
        "novel_contribution": "Statement Embedding layer (SEMB) aggregates token embeddings within each statement via a learnable RNN instead of max/mean pooling; an RNN (RNN_vul) summarizes vulnerable statements into a scope vector"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "12-layer Transformer encoders",
        "novel_contribution": "Concatenates statement embeddings with either vulnerable-scope summary or matched centroid to perform joint function- and statement-level predictions"
      },
      {
        "type": "primary",
        "category": "Attention",
        "specific": "Cross-attention between vulnerable-scope vector and codebook",
        "novel_contribution": "CrossAtt(vi, C) used for selecting best-matching centroid and supporting explicit vulnerability pattern matching"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "CodeBERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "CodeGPT",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Unnamed real-world C/C++ vulnerability dataset (>188k functions)",
        "type": "public",
        "domain": "source_code_c_cpp_functions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Previous best (function-level on same dataset)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "94%",
        "baseline_result": null
      },
      {
        "method_name": "Previous best (statement-level on same dataset)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "82%",
        "baseline_result": null
      },
      {
        "method_name": "CodeBERT",
        "paper_reference": null,
        "metric": "Statement-level prediction performance (e.g., F1)",
        "their_result": "“33% enhancement” with SEMB vs token embeddings (Table 1, as stated)",
        "baseline_result": null
      },
      {
        "method_name": "CodeGPT",
        "paper_reference": null,
        "metric": "Statement-level prediction performance (e.g., F1)",
        "their_result": "“32% enhancement” with SEMB vs token embeddings (Table 1, as stated)",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "F1-score"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "“vulnerable scopes still manifest in various spatial locations and formats within a program, posing challenges for models to accurately identify vulnerable statements.”",
        "“state-of-the-art vulnerability detection approaches fail to exploit the vulnerability patterns that arise in vulnerable programs.”",
        "Token-length limitations of pre-trained code LMs lead to truncation and information loss on long functions (512-token context windows).",
        "RNN-based prior work struggles with long-term dependencies; function-level predictions lack granularity for root-cause localization."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Leverage repeated vulnerability patterns across programs by explicitly learning and matching a codebook of vulnerable scopes to improve both function- and statement-level vulnerability detection.",
      "potential_research_ideas": [
        "Extend the vulnerability codebook approach to multi-language settings (e.g., Java, Python, Rust) and cross-language transfer of vulnerability patterns.",
        "Map learned centroids to human-interpretable CWE categories and generate natural-language rationales for statement-level findings.",
        "Incorporate program structure (AST/CFG/DFG/PDG) into the codebook learning via graph encoders or graph-aware centroids.",
        "Self-supervised pretraining for SEMB and RNN_vul (e.g., contrastive learning over vulnerable vs benign statements/scopes) before supervised fine-tuning.",
        "Online/continual codebook updates to capture newly emerging vulnerability patterns from streaming repositories.",
        "Soft-assignment matching using differentiable relaxations (e.g., Gumbel-Softmax) to replace hard argmax and gradient copying for end-to-end learning.",
        "Hierarchical codebooks (coarse-to-fine centroids) to support scalable matching and fine-grained localization.",
        "Integrate flow- and slice-based context (taint analysis) to improve statement-level precision in complex data/control-flow scenarios.",
        "Combine with LLMs as rerankers or explanation generators conditioned on matched centroids for triage assistance.",
        "Evaluate robustness to code obfuscation, refactoring, and stylistic variance; augment training with such transformations."
      ],
      "architectural_improvement_recommendations": [
        "Replace hard centroid selection (argmax) and gradient-copy trick with differentiable soft assignment (e.g., Gumbel-Softmax or Sinkhorn-Knopp) to enable smoother end-to-end training.",
        "Adopt hybrid encoders: fuse statement-level transformers with graph neural networks to encode structural flows (AST/CFG/DFG/PDG) before codebook matching.",
        "Introduce hierarchical vector quantization (e.g., VQ-VAE style) for multi-level pattern abstraction and faster nearest-centroid search.",
        "Use approximate nearest neighbor search (e.g., FAISS) for scalable centroid matching at inference.",
        "Pretrain SEMB with contrastive objectives (e.g., InfoNCE) across statements/scopes and fine-tune for detection.",
        "Learn centroid-to-CWE classifiers to attach interpretable labels to codewords and support explainable alerts.",
        "Incorporate uncertainty estimation (MC dropout or deep ensembles) to better calibrate statement-level scores.",
        "Optimize long-sequence handling with sparse attention or memory-augmented transformers for functions exceeding current n×r limits."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/optimatch/optimatch",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Handling very long functions and diverse spatial locations of vulnerable statements",
        "Generalizing to varied coding styles and formats across repositories"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces OPTIMATCH: a vulnerability-matching DL framework using optimal transport and vector quantization for function- and statement-level detection.",
      "Proposes a statement embedding approach (SEMB) using RNNs to overcome token-length limitations and better preserve salient token features.",
      "Learns a trainable vulnerability codebook of centroids (codewords) representing recurring vulnerable scopes; performs explicit matching during inference.",
      "Demonstrates large empirical gains: “F1-score of 94% (6% higher than the previous best)” at function level and “82% (19% higher than the previous best)” at statement level on a >188K C/C++ functions real-world dataset.",
      "Releases training code and pre-trained models."
    ]
  },
  {
    "arxiv_id": "2304.02260v1",
    "title": "Feature Engineering Using File Layout for Malware Detection",
    "authors": "Jeongwoo Kim; Eun-Sun Cho; Joon-Young Paik",
    "abstract": "Malware detection on binary executables provides a high availability to even binaries which are not disassembled or decompiled. However, a binary-level approach could cause ambiguity problems. In this paper, we propose a new feature engineering technique that use minimal knowledge about the internal layout on a binary. The proposed feature avoids the ambiguity problems by integrating the information about the layout with structural entropy. The experimental results show that our feature improves accuracy and F1-score by 3.3% and 0.07, respectively, on a CNN based malware detector with realistic benign and malicious samples.",
    "published_date": "2023-04-05",
    "pdf_link": "https://arxiv.org/pdf/2304.02260v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection",
      "specific_problem": "Static detection of Windows PE malware using binary-level CNN with structural-entropy features augmented by PE section layout information",
      "attack_types": [
        "Malware (Windows PE)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D CNN (three convolution + pooling layers, three fully connected layers, ReLU, BatchNorm1D)",
        "novel_contribution": "New input feature: per-chunk structural entropy concatenated with a one-hot encoding of PE section type (13-section schema), producing an m x 14 input tensor."
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "1D CNN with structural entropy stream only (no section information)",
        "novel_contribution": "Baseline feature uses only entropy streams of fixed-size chunks."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Benign (Windows System32 .exe/.dll)",
        "type": "proprietary",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Malware (VirusShare)",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://virusshare.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Entropy streams (w/o information on sections)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "99.1%",
        "baseline_result": "95.8%"
      },
      {
        "method_name": "Entropy streams (w/o information on sections)",
        "paper_reference": null,
        "metric": "Macro-averaged F1-score",
        "their_result": "0.99",
        "baseline_result": "0.94"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Macro-averaged F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can minimal PE layout information (section table) combined with structural entropy reduce ambiguity in binary-level CNN-based malware detection?",
        "How much does adding section one-hot indicators to entropy streams improve detection accuracy and macro-F1 on realistic PE datasets?"
      ],
      "gaps_identified": [
        "Binary-level CNN detectors suffer from ambiguity because similar byte/entropy patterns can have different semantics across sections.",
        "Structural entropy alone cannot disambiguate code vs. metadata/resources since similar entropy patterns may indicate different functionalities."
      ],
      "limitations": [
        "Undeclared sections grouped as 'Undefined' are not further analyzed; current approach may miss nuances of packed/crypter/protector-modified binaries."
      ],
      "future_work": [
        "\"We plan to further analyze the Undefined section in order to detect malware which exploit various packers, crypters, and protectors.\""
      ],
      "motivation": "Resolve ambiguity in binary-level malware detection by injecting minimal semantic layout (PE section) information into structural-entropy features.",
      "potential_research_ideas": [
        "Learned embeddings for section types (instead of one-hot) jointly trained with the CNN.",
        "Multi-scale entropy features (vary chunk sizes) with feature pyramids to capture both local and coarse-grained patterns.",
        "Hybrid static feature fusion: combine raw-byte CNN/transformer signals with entropy+section features.",
        "Contrastive/self-supervised pretraining on PE chunks leveraging section labels to improve generalization.",
        "Out-of-distribution and packed-malware detection by modeling the 'Undefined' section distribution.",
        "Cross-format generalization (ELF/Mach-O) by abstracting layout metadata into a unified section/segment schema.",
        "Explainability studies mapping salient sections/chunks (entropy + section) to aid triage."
      ],
      "architectural_improvement_recommendations": [
        "Replace one-hot section vectors with learnable section embeddings plus positional encodings for chunk indices.",
        "Adopt 1D transformer or CNN-Transformer hybrids to capture long-range dependencies across distant sections.",
        "Use multi-branch CNN where each branch specializes per-section streams, followed by attention-based fusion.",
        "Incorporate channel-wise attention (SE/CBAM) to reweight entropy vs section channels dynamically.",
        "Train with curriculum or data augmentation (e.g., synthetic code transposition, section reordering) to improve robustness.",
        "Model variable-length inputs with masking instead of truncation/padding to fixed 3600 chunks; use packed sequences."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a new feature engineering technique that concatenates per-chunk structural entropy with PE section one-hot indicators (13-section taxonomy).",
      "Demonstrates a CNN-based malware detector consuming the engineered m x 14 feature with three 1D conv+pool layers and three FC layers.",
      "Shows performance gains over entropy-only features on realistic PE datasets: \"Our feature improved the accuracy by 3.3% and the macro-averaged F1-score by 0.05, compared with the entropy stream, as shown in Table 2.\"; Table 2 reports 99.1% accuracy and 0.99 macro-F1 vs. 95.8% and 0.94.",
      "Uses large benign/malicious sets (Benign: 4,870; Malware: 16,712), chunk size 4096 bytes, and fixed input length 3,600 chunks via padding/truncation.",
      "Argues minimal PE layout knowledge effectively mitigates ambiguity of structural entropy patterns across different sections."
    ]
  },
  {
    "arxiv_id": "2305.04102v1",
    "title": "Leveraging Semantic Relationships to Prioritise Indicators of Compromise in Additive Manufacturing Systems",
    "authors": "Mahender Kumar; Gregory Epiphaniou; Carsten Maple",
    "abstract": "Additive manufacturing (AM) offers numerous benefits, such as manufacturing complex and customised designs quickly and cost-effectively, reducing material waste, and enabling on-demand production. However, several security challenges are associated with AM, making it increasingly attractive to attackers ranging from individual hackers to organised criminal gangs and nation-state actors. This paper addresses the cyber risk in AM to attackers by proposing a novel semantic-based threat prioritisation system for identifying, extracting and ranking indicators of compromise (IOC). The system leverages the heterogeneous information networks (HINs) that automatically extract high-level IOCs from multi-source threat text and identifies semantic relations among the IOCs. It models IOCs with a HIN comprising different meta-paths and meta-graphs to depict semantic relations among diverse IOCs. We introduce a domain-specific recogniser that identifies IOCs in three domains: organisation-specific, regional source-specific, and regional target-specific. A threat assessment uses similarity measures based on meta-paths and meta-graphs to assess semantic relations among IOCs. It prioritises IOCs by measuring their severity based on the frequency of attacks, IOC lifetime, and exploited vulnerabilities in each domain.",
    "published_date": "2023-05-06",
    "pdf_link": "https://arxiv.org/pdf/2305.04102v1",
    "paper_types": [
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cyber-Physical Systems Security",
      "subdomain": "Threat Intelligence for Industrial/Manufacturing Systems",
      "specific_problem": "Semantic extraction, modeling, and prioritization of Indicators of Compromise (IOCs) for Additive Manufacturing using Heterogeneous Information Networks",
      "attack_types": [
        "Advanced Persistent Threats (APTs)",
        "Ransomware",
        "Remote Code Execution",
        "Industrial Control System malware (e.g., Stuxnet)",
        "Sabotage of AM/ICS processes"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Graph-based (Heterogeneous Information Network)",
        "specific": "Meta-path and meta-graph similarity over HIN",
        "novel_contribution": "Models AM-specific IOCs and their semantic relations via HIN with meta-paths/meta-graphs; ranks IOCs using severity signals (frequency, lifetime, exploited vulnerabilities) across organization, regional-source, and regional-target domains"
      },
      {
        "type": "primary",
        "category": "NLP - Information Extraction / NER",
        "specific": "Domain-specific IOC recognizer with dependency parsing",
        "novel_contribution": "Introduces a domain-specific recognizer to identify IOCs in three domains (organization-specific, regional source-specific, regional target-specific) and integrates them into HIN"
      },
      {
        "type": "baseline",
        "category": "Word Embeddings",
        "specific": "word2vec, skip-gram, CBOW (mentioned as possible embedding models for node sequences)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [],
    "datasets": [
      {
        "name": "Unstructured multi-source CTI text (forums, blogs, security news, bulletins)",
        "type": "proprietary",
        "domain": "threat_intelligence_text",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "IBM X-Force Threat Intelligence feed",
        "type": "public",
        "domain": "threat_intelligence",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Facebook ThreatExchange",
        "type": "public",
        "domain": "threat_intelligence",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "OpenCTI",
        "type": "public",
        "domain": "threat_intelligence",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MISP (Malware Information Sharing Platform)",
        "type": "public",
        "domain": "threat_intelligence",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PhishTank",
        "type": "public",
        "domain": "threat_intelligence_urls",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IOCFinder",
        "type": "public",
        "domain": "threat_intelligence_iocs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CleanMX",
        "type": "public",
        "domain": "threat_intelligence_urls_ips",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "TIMiner",
        "paper_reference": "Zhao et al. [14]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "HINCTI",
        "paper_reference": "Gao et al. [15]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "HINTI",
        "paper_reference": "Zhao et al. [16]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "iACE",
        "paper_reference": "Liao et al. [17]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "THREATRAPTOR",
        "paper_reference": "Gao et al. [18]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Automated entity and relation extraction from text reports",
        "paper_reference": "Wang et al. [19]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Attack frequency (used in IOC severity)",
      "IOC lifetime (used in IOC severity)",
      "Number of exploited vulnerabilities per domain (used in IOC severity)",
      "Meta-path-based similarity",
      "Meta-graph-based similarity"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can high-level IOCs be automatically extracted from multi-source threat text and linked to organization, regional-source, and regional-target domains?",
        "How can semantic relations among heterogeneous IOCs be modeled using HINs (meta-paths and meta-graphs)?",
        "How can similarity measures over HIN (meta-path/meta-graph) be used to assess interdependent relationships among IOCs?",
        "How should IOC severity be prioritized using attack frequency, IOC lifetime, and exploited vulnerabilities within each domain?"
      ],
      "gaps_identified": [
        "Structured threat feeds have limited scope, delayed information, high cost, inflexibility, and false positives.",
        "Unstructured reports may not be well-organized, making it hard to identify relationships between pieces of information; they may contain errors, inaccuracies, and missing information.",
        "Existing methods often consider IOCs but avoid modeling the relationships among IOCs, limiting understanding of the comprehensive threat landscape."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Address cyber risk in Additive Manufacturing by overcoming limitations of existing IOC extraction tools through semantic modeling of IOC relationships and domain-aware prioritization.",
      "potential_research_ideas": [
        "Construct and release an AM-focused CTI corpus with gold annotations for IOCs and relations to enable quantitative evaluation.",
        "Evaluate and compare HIN-based prioritization against learning-to-rank baselines using measured incident response outcomes.",
        "Extend to cross-lingual CTI extraction and regional normalization for non-English threat reports.",
        "Integrate continuous/streaming CTI ingestion with temporal HIN updates and concept drift handling.",
        "Study human-in-the-loop feedback (from SOC analysts) to refine IOC ranking via active learning.",
        "Assess transferability to other CPS domains (power grid, automotive manufacturing) and quantify domain adaptation needs.",
        "Benchmark robustness of the recognizer to noisy/adversarially crafted CTI text."
      ],
      "architectural_improvement_recommendations": [
        "Replace hand-crafted similarity with learned HIN models (e.g., HAN, metapath2vec, MAGNN, HGT) and attention over meta-paths/meta-graphs.",
        "Adopt transformer-based NER and relation extraction (e.g., RoBERTa/BERT fine-tuning) with distant/weak supervision to reduce manual rules.",
        "Incorporate temporal HIN/temporal knowledge graph embeddings (e.g., TGAT, TComplEx) to model IOC lifecycles and attack evolution.",
        "Use entity resolution and canonicalization (e.g., to CVE/CWE/CPE) and link prediction (TransE/ComplEx/RotatE) to fill missing relations.",
        "Apply learning-to-rank objectives (pairwise/listwise) combining severity signals with learned relevance from historical incidents.",
        "Calibrate severity scoring with Bayesian uncertainty estimates to inform analyst triage."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Unstructured CTI may be noisy, error-prone, and incomplete, complicating automated extraction.",
        "Difficulty in identifying and maintaining relationships among heterogeneous IOCs across sources.",
        "Structured feeds can contain false positives and may be delayed or limited in scope."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a domain-specific recognizer to automatically extract IOCs and associate them with organization, regional-source, and regional-target domains.",
      "Models IOCs using a Heterogeneous Information Network with meta-paths and meta-graphs to capture semantic relations among diverse IOCs.",
      "Performs threat assessment using meta-path and meta-graph based similarity to evaluate interdependent IOC relations.",
      "Prioritizes IOCs by measuring severity via attack frequency, IOC lifetime, and exploited vulnerabilities within each domain."
    ]
  },
  {
    "arxiv_id": "2304.10737v2",
    "title": "Schooling to Exploit Foolish Contracts",
    "authors": "Tamer Abdelaziz; Aquinas Hobor",
    "abstract": "We introduce SCooLS, our Smart Contract Learning (Semi-supervised) engine. SCooLS uses neural networks to analyze Ethereum contract bytecode and identifies specific vulnerable functions. SCooLS incorporates two key elements: semi-supervised learning and graph neural networks (GNNs). Semi-supervised learning produces more accurate models than unsupervised learning, while not requiring the large oracle-labeled training set that supervised learning requires. GNNs enable direct analysis of smart contract bytecode without any manual feature engineering, predefined patterns, or expert rules. SCooLS is the first application of semi-supervised learning to smart contract vulnerability analysis, as well as the first deep learning-based vulnerability analyzer to identify specific vulnerable functions. SCooLS's performance is better than existing tools, with an accuracy level of 98.4%, an F1 score of 90.5%, and an exceptionally low false positive rate of only 0.8%. Furthermore, SCooLS is fast, analyzing a typical function in 0.05 seconds. We leverage SCooLS's ability to identify specific vulnerable functions to build an exploit generator, which was successful in stealing Ether from 76.9% of the true positives.",
    "published_date": "2023-04-21",
    "pdf_link": "https://arxiv.org/pdf/2304.10737v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Security",
      "specific_problem": "Function-level detection of reentrancy (SWC-107) vulnerabilities from EVM bytecode",
      "attack_types": [
        "Reentrancy (SWC-107)",
        "Ether theft via exploit generation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": null,
        "novel_contribution": "Applies graph neural networks to control-flow graphs of EVM bytecode for function-level vulnerability classification without manual feature engineering."
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Universal Sentence Encoder",
        "novel_contribution": "Encodes basic-block opcode sequences into 512-dimensional vectors used as node features for the GNN."
      },
      {
        "type": "primary",
        "category": "Semi-supervised Self-training",
        "specific": "Committee-based pseudo-labeling with confidence thresholds",
        "novel_contribution": "First application of semi-supervised learning to smart contract vulnerability analysis; iterative self-training on a large unlabeled corpus with a 120-model committee, high-confidence filtering (discard 0.1<x<0.9), and supermajority voting (≥ two-thirds)."
      },
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": "Committee of 120 GNN models",
        "novel_contribution": "Uses five state-of-the-art graph convolution methods across hyperparameters to create 120 models and a voting committee for robust labeling and inference."
      }
    ],
    "learning_paradigm": [
      "Semi-supervised",
      "Supervised (initial step)",
      "Self-training",
      "Ensemble"
    ],
    "datasets": [
      {
        "name": "ReentrancyBook",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "ReentrancyStudyBook",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "ReentrancyTestBook",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "BigBook",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": "https://console.cloud.google.com/bigquery?sq=814627022739:e4a5075f5a7141078f0e170ced82ffa0",
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "F1-score",
      "False Positive Rate",
      "Inference time per function",
      "Exploit success rate"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can semi-supervised learning with GNNs on EVM bytecode CFGs accurately detect reentrancy vulnerabilities at the function level without manual features or rules?",
        "Can function-level predictions be leveraged to automatically generate successful reentrancy exploits?"
      ],
      "gaps_identified": [
        "Scarcity and subjectivity of high-confidence labeled data for smart contract vulnerabilities.",
        "Most existing analysis tools rely on expert-crafted rules and manual feature engineering.",
        "Source code is often unavailable; bytecode analysis is crucial.",
        "Prior ML approaches have not targeted function-level vulnerability identification nor used semi-supervised learning in this domain.",
        "Flagging vulnerabilities without demonstrating exploitability limits practical impact."
      ],
      "limitations": [
        "Focuses on a single vulnerability type (reentrancy-eth, SWC-107).",
        "Small labeled dataset (22 vulnerable vs 480 non-vulnerable functions) despite careful curation.",
        "Exploit generator requires ABI and uses simple templates; does not track recursion depth or EVM call depth limits.",
        "Potential for misuse; responsible disclosure on blockchains is challenging.",
        "Details of the five GNN variants and some hyperparameters are referenced but not fully enumerated in the text provided."
      ],
      "future_work": [
        "Extend SCooLS to additional vulnerability classes beyond reentrancy.",
        "Release SCooLS (without exploit generator) and later the exploit generator per the stated timeline.",
        "Enhance the exploit generator to track recursion depth and avoid hitting the EVM 1,024-call depth limit."
      ],
      "motivation": "Reduce dependence on expert-crafted rules and large labeled datasets by using semi-supervised learning and GNNs to analyze EVM bytecode directly and identify specific vulnerable functions, enabling practical exploitation validation.",
      "potential_research_ideas": [
        "Generalize to multi-vulnerability, multi-label detection across the SWC taxonomy with shared representations.",
        "Pretrain EVM-specific code embeddings (contrastive or masked opcode modeling) to replace or augment the Universal Sentence Encoder.",
        "Incorporate inter-procedural graphs (call graphs) and data-flow edges for richer graph representations.",
        "Active learning to prioritize manual labeling of most informative functions from BigBook.",
        "Calibration and abstention mechanisms to further reduce false positives while retaining high recall.",
        "Assess robustness to compiler optimizations and bytecode obfuscations; develop invariance-enhancing training.",
        "Domain adaptation to other EVM-compatible chains (BSC, Polygon) and cross-chain generalization.",
        "Integrate dynamic execution traces into a hybrid static-dynamic graph model for improved exploitability predictions."
      ],
      "architectural_improvement_recommendations": [
        "Replace generic sentence encoder with an opcode- and operand-aware tokenizer and transformer pretrained on EVM bytecode (or train a small BPE-based model).",
        "Use heterogeneous GNNs with typed edges (control-flow, call, storage access) and edge features (gas, call value).",
        "Adopt hierarchical graph pooling/readout to better aggregate basic-block to function-level representations.",
        "Introduce uncertainty-aware ensembling and temperature scaling for better confidence estimates and voting.",
        "Leverage label propagation or graph consistency regularization during semi-supervised training.",
        "Augment with program slicing to focus on call-value-transfer slices that are relevant to reentrancy."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://bit.ly/SCooLS-Tool",
      "frameworks": [
        "TensorFlow 2.12.0",
        "TensorFlow Hub 0.13.0",
        "Spektral",
        "evm-cfg-builder",
        "Ganache"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Trained/evaluated on a 12-core Intel i7-8700 (3.2 GHz) with 32 GB RAM, Ubuntu 20.04.6; inference ~0.05 s per function; no GPU specified."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Offline analysis of Ethereum mainnet bytecode; exploit validation in local Ganache blockchain environment.",
      "scalability_discussed": true,
      "inference_time": "0.05 seconds per function",
      "deployment_challenges": [
        "Responsible disclosure on pseudonymous blockchains is difficult; risk of misuse.",
        "Exploit generator requires ABI availability.",
        "Extending to other vulnerabilities requires incremental dataset curation and labeling.",
        "Operating solely on bytecode may miss source-level context."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces SCooLS, the first semi-supervised learning approach for smart contract vulnerability analysis.",
      "First deep learning-based analyzer to identify specific vulnerable functions (function-level classification).",
      "Publishes two datasets: ReentrancyBook (22 vulnerable, 480 non-vulnerable functions) and BigBook (553,665 unlabeled functions).",
      "Designs a committee of 120 GNN models over five graph convolution methods with voting and high-confidence filtering.",
      "Achieves 98.4% accuracy, 90.5% F1, and 0.8% false positive rate; 0.05 s per-function inference.",
      "Builds an exploit generator that successfully steals Ether from 76.9% of true positives (with ABI available).",
      "Plans staged release of SCooLS and the exploit generator; provides a download link."
    ]
  },
  {
    "arxiv_id": "2304.11072v1",
    "title": "An Unbiased Transformer Source Code Learning with Semantic Vulnerability Graph",
    "authors": "Nafis Tanveer Islam; Gonzalo De La Torre Parra; Dylan Manuel; Elias Bou-Harb; Peyman Najafirad",
    "abstract": "Over the years, open-source software systems have become prey to threat actors. Even as open-source communities act quickly to patch the breach, code vulnerability screening should be an integral part of agile software development from the beginning. Unfortunately, current vulnerability screening techniques are ineffective at identifying novel vulnerabilities or providing developers with code vulnerability and classification. Furthermore, the datasets used for vulnerability learning often exhibit distribution shifts from the real-world testing distribution due to novel attack strategies deployed by adversaries and as a result, the machine learning model's performance may be hindered or biased. To address these issues, we propose a joint interpolated multitasked unbiased vulnerability classifier comprising a transformer \"RoBERTa\" and graph convolution neural network (GCN). We present a training process utilizing a semantic vulnerability graph (SVG) representation from source code, created by integrating edges from a sequential flow, control flow, and data flow, as well as a novel flow dubbed Poacher Flow (PF). Poacher flow edges reduce the gap between dynamic and static program analysis and handle complex long-range dependencies. Moreover, our approach reduces biases of classifiers regarding unbalanced datasets by integrating Focal Loss objective function along with SVG. Remarkably, experimental results show that our classifier outperforms state-of-the-art results on vulnerability detection with fewer false negatives and false positives. After testing our model across multiple datasets, it shows an improvement of at least 2.41% and 18.75% in the best-case scenario. Evaluations using N-day program samples demonstrate that our proposed approach achieves a 93% accuracy and was able to detect 4, zero-day vulnerabilities from popular GitHub repositories.",
    "published_date": "2023-04-17",
    "pdf_link": "https://arxiv.org/pdf/2304.11072v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection",
      "specific_problem": "Static source code vulnerability detection and multi-class CWE categorization at function level",
      "attack_types": [
        "Out-of-bounds write (CWE-787)",
        "Buffer overflow",
        "Divide-by-zero",
        "Use-after-free / out-of-scope variable usage",
        "Remote code execution",
        "Information leakage"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "RoBERTa",
        "novel_contribution": "Jointly trained with a GCN in a multitask setting on a Semantic Vulnerability Graph for vulnerability detection and CWE description prediction."
      },
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Graph Convolutional Network (GCN)",
        "novel_contribution": "Operates over a novel Semantic Vulnerability Graph (SVG) that integrates sequential, control, data, and new Poacher Flow edges to capture long-range and runtime-related semantics."
      },
      {
        "type": "primary",
        "category": "Graph Construction",
        "specific": "Semantic Vulnerability Graph (SVG) with Poacher Flow edges",
        "novel_contribution": "Introduces Poacher Flow edges that associate edges with specific potential vulnerabilities to bridge static and dynamic analysis and model long-range dependencies."
      },
      {
        "type": "primary",
        "category": "Training Paradigm",
        "specific": "Multitask learning",
        "novel_contribution": "Jointly optimizes vulnerability presence detection and vulnerability description/CWE category prediction."
      },
      {
        "type": "primary",
        "category": "Loss Function",
        "specific": "Focal Loss",
        "novel_contribution": "Used to mitigate class imbalance and reduce classifier bias when training on imbalanced datasets."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Multitask"
    ],
    "datasets": [
      {
        "name": "Vulnerability Finder (VulF)",
        "type": "public",
        "domain": "source_code",
        "link": "https://github.com/pial08/SemVulDet",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "ReVEAL",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "FFMpeg+Qemu",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "D2A",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MVD",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "false positive rate",
      "false negative rate"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "RQ1: Based on our proposed SVG representation, can the classifier learn to identify and provide CWE Numbers of vulnerabilities in real-world source code?",
        "RQ2: Can our classifier learn vulnerabilities in a biased setting?",
        "RQ3: Is our classifier generalized enough to detect vulnerabilities in N-day and zero-day program samples?"
      ],
      "gaps_identified": [
        "Training data imbalance and model bias hinder performance on real-world software vulnerabilities.",
        "Distribution shifts between training datasets and real-world testing distributions are underrepresented and degrade model performance.",
        "AST/CPG cannot capture certain runtime-exposed vulnerabilities (e.g., divide-by-zero, use-after-free) that are syntactically correct.",
        "Existing graphs (AST/CPG) and sequence models struggle with long-range dependencies across distant code statements.",
        "Many detectors provide only binary vulnerable/non-vulnerable outputs, lacking vulnerability category explanations.",
        "Transformer models have limited context and struggle with very long functions, missing long-range interactions."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve static vulnerability detection to handle distribution shift, class imbalance, runtime-related semantics, and long-range dependencies while providing actionable CWE-level descriptions.",
      "potential_research_ideas": [
        "Extend SVG and Poacher Flow to additional programming languages (e.g., Java, Python, Rust) and cross-language transfer learning.",
        "Integrate selective dynamic analysis traces (e.g., lightweight fuzzing summaries) with SVG via multi-view or co-training to further bridge runtime semantics.",
        "Apply domain adaptation or test-time adaptation to explicitly handle distribution shifts between curated datasets and in-the-wild repositories.",
        "Use graph transformers or attention-based GNNs (GAT, GraphGPS) over SVG to better exploit heterogeneous edge types and long-range relations.",
        "Pretrain on large unlabeled code corpora with contrastive objectives aligning token sequences and SVG structures (graph-text contrastive pretraining).",
        "Incorporate program slicing and hierarchical graph pooling for scalable project-level analysis (function → file → project).",
        "Active learning to prioritize uncertain code regions and efficiently label rare/vulnerable patterns, reducing annotation costs.",
        "Adopt calibrated uncertainty estimation and abstention to minimize false positives in CI/CD pipelines."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment GCN with graph attention or transformer-based GNN to capture heterogeneous edge importance and long-range dependencies more directly.",
        "Introduce hierarchical modeling: token → statement → function graph pooling to scale to long functions and whole files/projects.",
        "Use hybrid long-context encoders (e.g., Longformer/RoPE-based transformers) for token embeddings before graph stages.",
        "Add edge-type embeddings and relation-specific convolution or R-GCN to better model different flows (sequential/control/data/poacher).",
        "Leverage curriculum or focal+class-balanced loss and reweighting schedules for extreme imbalance and rare CWEs.",
        "Incorporate uncertainty calibration (e.g., temperature scaling) and cost-sensitive decision thresholds to control FNs/FPs in deployment."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/pial08/SemVulDet",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Distribution shift between curated datasets and real-world repositories",
        "Imbalanced vulnerability prevalence causing classifier bias",
        "Capturing long-range dependencies in long functions"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": true
    },
    "contributions": [
      "Introduces Poacher Flow edges and a Semantic Vulnerability Graph (SVG) unifying sequential, control, data, and poacher flows for richer static analysis.",
      "Proposes a joint interpolated multitask model (RoBERTa-PFGCN) combining a transformer and GCN with Focal Loss to mitigate imbalance bias.",
      "Creates the Vulnerability Finder (VulF) dataset with vulnerability descriptions for 40 CWE categories.",
      "Reports outperforming state-of-the-art on multiple datasets with fewer false negatives and false positives; “it shows an improvement of at least 2.41% and 18.75% in the best-case scenario.”",
      "Generalization to real programs: “achieves a 93% accuracy and was able to detect 4, zero-day vulnerabilities from popular GitHub repositories.”",
      "Provides CWE-level descriptions/explanations as part of the multitask output to aid developers in remediation."
    ]
  },
  {
    "arxiv_id": "2304.07704v1",
    "title": "A Survey of Access Control Misconfiguration Detection Techniques",
    "authors": "Bingyu Shen",
    "abstract": "Access control mechanisms have been adopted in many real-world systems to control resource sharing for the principals in the system. An error in the access control policy (misconfiguration) can easily cause severe data leakage and system exploitation. Researchers have developed several methodologies to detect the access control misconfigurations through data mining, testing, and verification for various applications. This survey will study the line of works to detect access control misconfigurations and discuss some future research directions.",
    "published_date": "2023-04-16",
    "pdf_link": "https://arxiv.org/pdf/2304.07704v1",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Identity and Access Management",
      "subdomain": "Access Control Policy Analysis",
      "specific_problem": "Detecting access control misconfigurations (errors) in policies and configurations before they cause security failures, using data mining, verification, and testing approaches",
      "attack_types": [
        "Unauthorized access",
        "Data leakage due to over-privilege",
        "Insider misuse"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Association Rule Mining",
        "specific": "Apriori",
        "novel_contribution": "Used to mine rules from access logs or configuration key-value pairs to identify anomalous access decisions or configuration correlations (e.g., Bauer et al., EnCore)"
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "C4.5",
        "novel_contribution": "Used to detect inconsistencies in access control policies via attribute-based splits and information gain (Shaikh et al.)"
      },
      {
        "type": "baseline",
        "category": "Clustering",
        "specific": null,
        "novel_contribution": "Object clustering on access control matrices to detect outliers and uniformity deviations (Bazz)"
      },
      {
        "type": "baseline",
        "category": "Anomaly Detection",
        "specific": null,
        "novel_contribution": "Detect anomalous permissions and access patterns relative to inferred normal profiles (Bazz)"
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Access history logs (Bauer et al.)",
        "type": "private",
        "domain": "access_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Subject dataset (user–resource access matrix) [Bazz]",
        "type": "private",
        "domain": "access_control_matrix",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Reference dataset (user–group membership matrix) [Bazz]",
        "type": "private",
        "domain": "identity_group_membership",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Application configuration files and system environment (EnCore)",
        "type": "private",
        "domain": "configuration_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "support",
      "confidence",
      "information gain",
      "false positive rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "“The detection techniques will answer a fundamental question: whether the configuration result meet the intended security goals.”",
        "How do data mining, verification, and testing approaches detect access control misconfigurations, and what are their trade-offs in human effort, comprehensiveness, and accuracy?",
        "What unique challenges distinguish access control misconfigurations from performance or availability misconfigurations?"
      ],
      "gaps_identified": [
        "Access control misconfigurations often do not impact performance or functionality, so they remain unnoticed until breaches occur; prior misconfiguration detection methods for performance/availability do not transfer directly.",
        "Heterogeneity of access control models (ACL, DAC, MAC, RBAC, ABAC) and configuration formats complicates cross-system validation and tooling.",
        "Verification approaches require formal specifications and deep domain knowledge, imposing high human effort and limiting practicality.",
        "Testing approaches hinge on comprehensive test generation; missing tests lead to undetected errors, and manual test design is onerous.",
        "Data mining approaches assume mostly-correct logs/configs and introduce false positives/negatives; they may not track dynamic policy changes.",
        "XACML’s complexity, centralized PEP requirement, and limited ecosystem support reduce real-world adoption; many works focus narrowly on XACML.",
        "Association rule mining requires manual threshold tuning (support, confidence); low thresholds increase coverage but degrade accuracy.",
        "Some mining frameworks (e.g., EnCore) need user-authored rule templates and operate on simple key-value correlations, missing complex rule interactions (e.g., anyOf, first-applicable).",
        "Bazz and similar matrix-based methods require administrators to prepare subject/reference datasets; results may include false positives that burden admins.",
        "Existing approaches often lack mechanisms to trace detected anomalies back to root-cause configuration faults across multi-component systems."
      ],
      "limitations": [
        "Data mining: threshold sensitivity, assumption of static policies, inability to capture complex rule interactions, false positives/negatives.",
        "Verification: high human effort for specifications and model fidelity; practicality issues across heterogeneous systems.",
        "Testing: dependence on coverage of generated test cases; manual test design is infeasible for comprehensive coverage.",
        "EnCore: relies on administrator-written rule templates; limited expressiveness for enumerations and inter-rule logic; focuses on key-value correlations.",
        "Bauer et al.: only addresses accessibility (false denials), assumes static configurations, requires parameter tuning, limited root-cause traceability.",
        "Bazz: demands admin-prepared matrices (subject/reference); potential for false positives; requires client monitoring stubs.",
        "XACML focus: many techniques tailored to XACML despite limited industry adoption and scalability concerns."
      ],
      "future_work": [],
      "motivation": "Access control misconfigurations are common and can cause severe data leakage and system compromise; proactive detection of configuration errors before deployment is needed to ensure configurations meet intended security goals.",
      "potential_research_ideas": [
        "A cross-model intermediate representation (IR) for access control policies to enable unified analysis across ACL/DAC/MAC/RBAC/ABAC and diverse config formats.",
        "Online and incremental learning for policy mining to handle concept drift and frequent access rights changes without retraining from scratch.",
        "Human-in-the-loop active learning for rule mining to reduce false positives while minimizing administrator burden.",
        "Hybrid analysis that jointly mines access logs and parses configuration/policy files to improve anomaly attribution and root-cause diagnosis.",
        "Automated generation of access-control test cases using constraint solving and grammar-based fuzzing guided by coverage over policy IR.",
        "Learning rule interaction models (e.g., combining algorithms, precedence) via differentiable or symbolic reasoning to capture complex policy semantics.",
        "Template induction for configuration correlation rules from data (e.g., LLM-assisted extraction) to reduce reliance on hand-written templates.",
        "Causal analysis frameworks linking observed unauthorized access to specific misconfigurations across distributed components and services.",
        "Benchmarking suite and synthetic data generators for access control misconfiguration detection across models and stacks.",
        "Explainable detectors that produce minimal, actionable policy patches (e.g., role assignment changes, rule edits) with safety guarantees."
      ],
      "architectural_improvement_recommendations": [
        "Introduce an intermediate policy representation with explicit semantics (targets, combining algorithms) and translators from common policy/config languages.",
        "Augment association rule mining with online updating, drift detection, and Bayesian calibration of support/confidence thresholds.",
        "Combine decision-tree inconsistency detection with SMT-based validation to confirm contradictions under precise attribute domains.",
        "Integrate rule-interaction modeling (e.g., learned precedence graphs) into mining frameworks like EnCore to handle anyOf/first-applicable semantics.",
        "Use multi-view learning that fuses user–group graphs, access matrices, and configuration KV pairs via graph neural networks or factorization models for anomaly scoring.",
        "Leverage constrained test generation (symbolic/concolic execution of PEP/PDP code) to cover edge-case policy paths and conditions automatically.",
        "Add administrator feedback loops with uncertainty estimation to prioritize high-confidence, high-impact misconfiguration alerts.",
        "Provide automated patch synthesis that proposes minimal policy/config edits and simulates impact before application."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Heterogeneous access control models and policy/config formats across systems",
        "High human effort for specifying formal properties or preparing datasets",
        "Centralized authorization (e.g., XACML PEP) scalability concerns in cloud/distributed settings",
        "Dynamic access rights and policy drift over time",
        "False positives that burden administrators and slow remediation"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Surveys and classifies access control misconfiguration detection approaches into data mining, verification, and testing.",
      "Analyzes unique challenges of access control misconfigurations compared to performance/availability misconfigurations.",
      "Provides background on access control models and XACML, including adoption considerations and complexities.",
      "Summarizes representative techniques (e.g., association rule mining, decision trees, matrix/clustering) and discusses their limitations.",
      "Identifies trade-offs among human effort, comprehensiveness, and accuracy, and outlines future research opportunities."
    ]
  },
  {
    "arxiv_id": "2306.07974v1",
    "title": "Chainlet Orbits: Topological Address Embedding for the Bitcoin Blockchain",
    "authors": "Poupak Azad; Baris Coskunuzer; Murat Kantarcioglu; Cuneyt Gurcan Akcora",
    "abstract": "The rise of cryptocurrencies like Bitcoin, which enable transactions with a degree of pseudonymity, has led to a surge in various illicit activities, including ransomware payments and transactions on darknet markets. These illegal activities often utilize Bitcoin as the preferred payment method. However, current tools for detecting illicit behavior either rely on a few heuristics and laborious data collection processes or employ computationally inefficient graph neural network (GNN) models that are challenging to interpret.   To overcome the computational and interpretability limitations of existing techniques, we introduce an effective solution called Chainlet Orbits. This approach embeds Bitcoin addresses by leveraging their topological characteristics in transactions. By employing our innovative address embedding, we investigate e-crime in Bitcoin networks by focusing on distinctive substructures that arise from illicit behavior.   The results of our node classification experiments demonstrate superior performance compared to state-of-the-art methods, including both topological and GNN-based approaches. Moreover, our approach enables the use of interpretable and explainable machine learning models in as little as 15 minutes for most days on the Bitcoin transaction network.",
    "published_date": "2023-05-18",
    "pdf_link": "https://arxiv.org/pdf/2306.07974v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain/Cryptocurrency Security",
      "subdomain": "Illicit Activity Detection / Transaction Monitoring",
      "specific_problem": "Classifying/identifying illicit Bitcoin addresses using topological address embeddings (ransomware and darknet market related activity)",
      "attack_types": [
        "ransomware payments",
        "darknet market transactions"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Topological/motif-based graph embedding",
        "specific": "Chainlet Orbits (2-chainlet-based orbit counts via graph automorphisms)",
        "novel_contribution": "Defines mathematically grounded, interpretable, topological-equivalence (orbit) embeddings of Bitcoin addresses using group actions on 2-chainlets; enables efficient, scalable, explainable node classification on full Bitcoin UTXO graphs."
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GCN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "DGCNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GIN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GraphSAGE",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Topological/engineered features + classical ML",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Bitcoin blockchain (full transaction graph; daily 24h windows)",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Darknet Market Archives",
        "type": "public",
        "domain": "blockchain_transactions / darknet market sales metadata",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Montreal ransomware dataset (Bitcoin)",
        "type": "public",
        "domain": "blockchain_transactions / ransomware labels",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Princeton ransomware dataset (Bitcoin)",
        "type": "public",
        "domain": "blockchain_transactions / ransomware labels",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Padua ransomware dataset (Bitcoin)",
        "type": "public",
        "domain": "blockchain_transactions / ransomware labels",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Elliptic dataset",
        "type": "public",
        "domain": "blockchain_transactions (transaction-level temporal graph)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GCN",
        "paper_reference": "Kipf & Welling (2017)",
        "metric": "AUC",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "DGCNN",
        "paper_reference": "Zhang et al. (2018)",
        "metric": "AUC",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "GIN",
        "paper_reference": "Xu et al. (2019)",
        "metric": "AUC",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "GraphSAGE",
        "paper_reference": "Hamilton et al. (2017)",
        "metric": "AUC",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Topological/feature-engineering baselines",
        "paper_reference": null,
        "metric": "AUC",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "AUC"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Existing tools rely on a few heuristics and laborious data collection processes.",
        "GNN-based models are computationally inefficient on very large blockchain graphs and are challenging to interpret.",
        "Public benchmark datasets like Elliptic omit address nodes, limiting applicability of address-centric methods.",
        "Prior studies often use proprietary, undisclosed features, hindering transparency and reproducibility."
      ],
      "limitations": [
        "Focus on k=2 chainlets; k>2 deemed less useful for controllable behavior, so global patterns beyond immediate spend/receive are not modeled.",
        "To control orbit count, input addresses of the first transaction in 2-chainlets are excluded, reducing space to 48 orbits (design trade-off).",
        "Orbit approach cannot be applied to datasets that lack address nodes (e.g., Elliptic)."
      ],
      "future_work": [],
      "motivation": "Provide an interpretable, computationally efficient alternative to GNNs for illicit activity detection on Bitcoin by leveraging topological address roles (orbits) that capture distinctive illicit substructures.",
      "potential_research_ideas": [
        "Extend Chainlet Orbits with temporal/orbit dynamics (e.g., sequence models over daily orbit trajectories) for early detection of emerging ransomware campaigns.",
        "Sampled 3-chainlet or hierarchical motif-orbit embeddings to capture broader structural context while controlling complexity.",
        "Combine orbit features with lightweight message passing (hybrid Orbit+GNN) to improve accuracy while retaining interpretability via orbit attributions.",
        "Unsupervised/contrastive pretraining on orbit distributions for anomaly detection without labels; later fine-tune for specific e-crime types.",
        "Adversarial robustness study: simulate obfuscation strategies (peel chains, fan-in/out, mixers) to assess and harden orbit stability.",
        "Cross-chain generalization and transfer (e.g., Litecoin, Bitcoin Cash) with domain adaptation on orbit distributions.",
        "Human-in-the-loop tooling: interactive search/query over orbits with provenance and explanations for compliance investigations."
      ],
      "architectural_improvement_recommendations": [
        "Augment orbit vectors with weighted monetary/time features (amount quantiles, inter-block times) and learnable normalization to enhance discriminative power.",
        "Learn embeddings via contrastive objectives on orbit histograms across time windows (e.g., InfoNCE) before supervised classification.",
        "Introduce hierarchical motif pooling: 2-chainlet orbits -> sampled 3-chainlet summaries -> global sketch to capture multi-scale behavior.",
        "Integrate class-specific orbit attribution (e.g., Shapley on orbit features) and sparse feature selection to strengthen explainability.",
        "Implement streaming/online orbit computation with incremental updates and reservoir sampling for real-time detection.",
        "Explore hybrid Orbit + shallow GNN (1-2 hops) with orbit features as node attributes to balance scalability and context."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/chainletRepo/chainlet",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Reported runtime: enables interpretable and explainable ML models in as little as 15 minutes for most days on the Bitcoin transaction network."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "\"as little as 15 minutes for most days on the Bitcoin transaction network\"",
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces Chainlet Orbits: a topological-equivalence address embedding based on group actions on UTXO 2-chainlets.",
      "Demonstrates e-crime address discovery by identifying orbits associated with illicit behaviors (e.g., ransomware).",
      "Extensive empirical evaluation on the Bitcoin transaction network showing orbit-based models outperform topological and GNN-based methods.",
      "Enables interpretable and explainable ML, along with search and similarity queries over UTXO graphs; claims first to provide search and query capabilities over UTXO graphs.",
      "Provides an efficient orbit discovery method that scales to very large directed heterogeneous graphs."
    ]
  },
  {
    "arxiv_id": "2304.13249v1",
    "title": "A Security Verification Framework of Cryptographic Protocols Using Machine Learning",
    "authors": "Kentaro Ohno; Misato Nakabayashi",
    "abstract": "We propose a security verification framework for cryptographic protocols using machine learning. In recent years, as cryptographic protocols have become more complex, research on automatic verification techniques has been focused on. The main technique is formal verification. However, the formal verification has two problems: it requires a large amount of computational time and does not guarantee decidability. We propose a method that allows security verification with computational time on the order of linear with respect to the size of the protocol using machine learning. In training machine learning models for security verification of cryptographic protocols, a sufficient amount of data, i.e., a set of protocol data with security labels, is difficult to collect from academic papers and other sources. To overcome this issue, we propose a way to create arbitrarily large datasets by automatically generating random protocols and assigning security labels to them using formal verification tools. Furthermore, to exploit structural features of protocols, we construct a neural network that processes a protocol along its series and tree structures. We evaluate the proposed method by applying it to verification of practical cryptographic protocols.",
    "published_date": "2023-04-26",
    "pdf_link": "https://arxiv.org/pdf/2304.13249v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cryptographic Protocol Analysis",
      "subdomain": "Formal/Symbolic Verification",
      "specific_problem": "Automatic security verification of cryptographic protocols (evaluated on session key confidentiality for key exchange protocols)",
      "attack_types": [
        "Dolev–Yao active adversary",
        "Session key confidentiality compromise",
        "Impersonation/authentication errors (discussed as targets, evaluation focused on confidentiality)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": "Processes the series (sequence) structure of protocol message flows; combined with a tree encoder for hierarchical message syntax."
      },
      {
        "type": "primary",
        "category": "Tree-LSTM",
        "specific": "Child-Sum Tree-LSTM",
        "novel_contribution": "Encodes the abstract syntax tree of each protocol message to preserve hierarchical structure (order of crypto operations like enc/sign/hash), avoiding information loss in prior fixed-length vectorizations."
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": null,
        "novel_contribution": "Classification head over learned representations to predict security label."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Auto-generated cryptographic protocol dataset (this paper)",
        "type": "synthetic",
        "domain": "cryptographic_protocols",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Practical cryptographic protocols evaluation set",
        "type": "public",
        "domain": "cryptographic_protocols",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "TLM protocol vectorization + classical ML (e.g., SVM) [Ma et al.]",
        "paper_reference": "Ma et al. [37]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Improved TLM + multi-label classification [Zahednejad et al.]",
        "paper_reference": "Zahednejad et al. [45]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can machine learning provide a practically fast and decidable verifier for cryptographic protocols with high accuracy?",
        "How can we build arbitrarily large labeled datasets for protocol security verification without manual collection?",
        "How should we model the hierarchical (tree) and sequential (series) structures of protocols to improve verification accuracy?"
      ],
      "gaps_identified": [
        "Formal verification is computationally expensive and may be undecidable; verification may not terminate.",
        "Lack of sufficient labeled datasets for protocol verification; prior ML works used only 500–1000 examples.",
        "Previous ML approaches lose hierarchical structural information due to fixed-length vectorization with many-to-one mappings, hurting accuracy."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Construct a verifier for cryptographic protocols that is practically fast, decidable, and accurate by leveraging ML; overcome data scarcity and structural encoding challenges.",
      "potential_research_ideas": [
        "Domain adaptation and transfer learning from synthetic, tool-labeled protocols to diverse real-world protocols (e.g., TLS, 5G, messaging protocols).",
        "Active learning with formal verification tools in-the-loop to query uncertain cases and refine the model.",
        "Neuro-symbolic verification: integrate differentiable encoders with lightweight symbolic checks or constraints to reduce false positives/negatives.",
        "Multi-task learning predicting multiple security properties (confidentiality, authentication, replay resistance) jointly.",
        "Uncertainty estimation and calibration for risk-aware use in security-critical settings.",
        "Contrastive or self-supervised pretraining on large unlabeled protocol corpora followed by supervised fine-tuning with tool labels.",
        "Counterfactual and adversarial training by generating near-miss protocol variants to improve sensitivity to small structural changes.",
        "Program/graph-based encoders (AST + data-flow/term-rewriting graphs) to better capture variable bindings and cryptographic algebra."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment Tree-LSTM with graph neural networks over protocol ASTs and message/term graphs to capture long-range dependencies and variable bindings.",
        "Hierarchical Transformer with tree positional encodings to jointly model intra-message trees and inter-message sequences.",
        "Pointer/network components to explicitly model references to keys, nonces, and identities across messages.",
        "Incorporate symbolic features from formal tools (e.g., attack traces, reachability hints) as auxiliary inputs.",
        "Calibration layers (e.g., temperature scaling) and abstention/triage mechanisms for uncertain predictions.",
        "Multi-label output heads to support simultaneous verification of multiple properties."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Inference time scales linearly with protocol size; no specific hardware/training-time details given."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Automated dataset generation: random cryptographic protocol generator with security labels assigned by formal verification tools, allowing arbitrarily large datasets.",
      "Neural network model that jointly processes sequence and tree structures of protocols to preserve hierarchical message information.",
      "Feasibility study verifying key exchange protocol confidentiality on practical protocols with 79.5% accuracy.",
      "Linear-time verification with respect to protocol size, providing practical speed and decidability characteristics."
    ]
  },
  {
    "arxiv_id": "2304.13935v1",
    "title": "Bitcoin Double-Spending Attack Detection using Graph Neural Network",
    "authors": "Changhoon Kang; Jongsoo Woo; James Won-Ki Hong",
    "abstract": "Bitcoin transactions include unspent transaction outputs (UTXOs) as their inputs and generate one or more newly owned UTXOs at specified addresses. Each UTXO can only be used as an input in a transaction once, and using it in two or more different transactions is referred to as a double-spending attack. Ultimately, due to the characteristics of the Bitcoin protocol, double-spending is impossible. However, problems may arise when a transaction is considered final even though its finality has not been fully guaranteed in order to achieve fast payment. In this paper, we propose an approach to detecting Bitcoin double-spending attacks using a graph neural network (GNN). This model predicts whether all nodes in the network contain a given payment transaction in their own memory pool (mempool) using information only obtained from some observer nodes in the network. Our experiment shows that the proposed model can detect double-spending with an accuracy of at least 0.95 when more than about 1% of the entire nodes in the network are observer nodes.",
    "published_date": "2023-04-27",
    "pdf_link": "https://arxiv.org/pdf/2304.13935v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Cryptocurrency Transaction Security",
      "specific_problem": "Detection of Bitcoin double-spending during fast (zero-confirmation) payments by predicting network-wide propagation of a payment transaction from partial mempool observations",
      "attack_types": [
        "Double-spending"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Graph Neural Network",
        "specific": "GCN",
        "novel_contribution": "Formulates double-spending detection as graph-level classification of transaction propagation using partial observer nodes; engineered node features using counts of neighbor labels and two-hop label combinations; two-layer GNN with mean pooling over node embeddings."
      },
      {
        "type": "primary",
        "category": "Graph Neural Network",
        "specific": "GraphSAGE",
        "novel_contribution": "Same task/architecture variant evaluated as alternative GNN layer for message passing."
      },
      {
        "type": "primary",
        "category": "Graph Neural Network",
        "specific": "GAT",
        "novel_contribution": "Same task/architecture variant evaluated as alternative GNN layer for message passing."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Virtual Bitcoin network propagation simulation datasets (14,000-node Barabasi-Albert graphs; observer counts 10/50/100/150/200/250; 1,000 graphs per case; train/test split 700/300; 5-fold CV on train)",
        "type": "synthetic",
        "domain": "blockchain_p2p_network_mempool_propagation",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "BITNODES reachable Bitcoin nodes (used to set network size reference)",
        "type": "public",
        "domain": "blockchain_network_metadata",
        "link": "https://bitnodes.io/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "Cross-validation accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a GNN, using mempool information from a small fraction of observer nodes, predict whether all nodes have received a payment transaction (txpay) and thereby detect double-spending attempts?",
        "What fraction of observer nodes is required to accurately detect double-spending in a 14,000-node Bitcoin-like P2P network?"
      ],
      "gaps_identified": [
        "Many fast-payment protections require protocol changes that are difficult to deploy on Bitcoin.",
        "Solutions like the Lightning Network are complex for ordinary merchants to operate.",
        "Existing commercial risk scoring (e.g., GAP600) lacks publicly disclosed methodologies.",
        "Merchants cannot easily manage peer connections to ensure arbitrary sampling that thwarts double-spending."
      ],
      "limitations": [
        "Experiments use virtual Bitcoin network topologies (Barabasi-Albert) rather than the actual, dynamic Bitcoin P2P topology.",
        "Training failed when the number of observer nodes was 10, 50, or 100 out of 14,000 (i.e., less than about 1% coverage).",
        "No evaluation on real-world mempool data or live Bitcoin network measurements.",
        "No comparison against non-GNN baselines or existing detection heuristics."
      ],
      "future_work": [],
      "motivation": "Enable fast Bitcoin payments without protocol changes by detecting double-spending attempts using only partial network observations accessible to merchants or monitoring services.",
      "potential_research_ideas": [
        "Collect and evaluate on real Bitcoin P2P topology and mempool snapshots; assess generalization from simulated to real networks.",
        "Model temporal propagation explicitly using dynamic/temporal GNNs (e.g., TGN/TGAT) with message timestamps and edge directions.",
        "Optimize observer node placement via sensor selection/active learning to minimize required coverage while maintaining accuracy.",
        "Self-supervised or semi-supervised pretraining on unlabeled network traffic to reduce observer fraction needed for reliable detection.",
        "Calibrated risk scoring (e.g., conformal prediction) to provide merchants with actionable confidence measures for zero-conf acceptance.",
        "Adversarial robustness evaluation where attackers manipulate propagation patterns; develop defenses robust to Sybil/evasion.",
        "Privacy-preserving aggregation (federated learning or differential privacy) for mempool features across independent observers.",
        "Incremental/streaming inference to support real-time detection on evolving network states.",
        "Benchmark against classical diffusion/epidemic models or probabilistic propagation models as baselines.",
        "Integrate cost-sensitive learning reflecting merchant risk/benefit trade-offs for fast payment approvals."
      ],
      "architectural_improvement_recommendations": [
        "Include edge features (direction, latency) and temporal ordering; use temporal GNN architectures.",
        "Replace mean graph pooling with attention-based global pooling or Set2Set for better aggregation.",
        "Predict continuous coverage (fraction of nodes that have txpay) as an auxiliary task to improve calibration.",
        "Use uncertainty-aware losses and probability calibration to inform acceptance thresholds.",
        "Hyperparameter optimization and regularization tuning; explore deeper GNNs with residual/skip connections and batch norm.",
        "Leverage heterogeneous node roles (observer vs non-observer) via feature gating or relational GNNs.",
        "Scale training with mini-batch graph sampling (e.g., GraphSAINT/Cluster-GCN) for larger-than-14k graphs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Obtaining real-time mempool data from a sufficient (>~1%) and well-placed set of observer nodes.",
        "Synchronizing observations and timestamps across distributed observers.",
        "Potential mismatch between simulated and real network topologies and dynamics.",
        "Operational overhead of maintaining observer nodes and network connectivity.",
        "Privacy and policy constraints when aggregating mempool data from multiple parties.",
        "Susceptibility to adversarial manipulation of propagation (e.g., Sybil or targeted peer selection)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a GNN-based method to detect Bitcoin double-spending by predicting whether all nodes in the network have received a given payment transaction using partial observer data.",
      "Designs node features based on counts of neighbor labels and two-hop label combinations to capture local propagation context.",
      "Demonstrates high detection performance in simulations: \"accuracy of at least 0.95\" when monitoring \"more than about 1%\" (≥150/14,000) observer nodes; recall of 1.0 across evaluated high-observer scenarios.",
      "Empirically evaluates multiple GNN layer choices (GCN, GraphSAGE, GAT) and reports precision/recall/F1 across observer coverage levels.",
      "Identifies a practical threshold: training failed with fewer than ~1% observer nodes (10–100/14,000), highlighting coverage requirements for reliable detection."
    ]
  },
  {
    "arxiv_id": "2304.13103v1",
    "title": "HyMo: Vulnerability Detection in Smart Contracts using a Novel Multi-Modal Hybrid Model",
    "authors": "Mohammad Khodadadi; Jafar Tahmoresnezhad",
    "abstract": "With blockchain technology rapidly progress, the smart contracts have become a common tool in a number of industries including finance, healthcare, insurance and gaming. The number of smart contracts has multiplied, and at the same time, the security of smart contracts has drawn considerable attention due to the monetary losses brought on by smart contract vulnerabilities. Existing analysis techniques are capable of identifying a large number of smart contract security flaws, but they rely too much on rigid criteria established by specialists, where the detection process takes much longer as the complexity of the smart contract rises. In this paper, we propose HyMo as a multi-modal hybrid deep learning model, which intelligently considers various input representations to consider multimodality and FastText word embedding technique, which represents each word as an n-gram of characters with BiGRU deep learning technique, as a sequence processing model that consists of two GRUs to achieve higher accuracy in smart contract vulnerability detection. The model gathers features using various deep learning models to identify the smart contract vulnerabilities. Through a series of studies on the currently publicly accessible dataset such as ScrawlD, we show that our hybrid HyMo model has excellent smart contract vulnerability detection performance. Therefore, HyMo performs better detection of smart contract vulnerabilities against other approaches.",
    "published_date": "2023-04-25",
    "pdf_link": "https://arxiv.org/pdf/2304.13103v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Security",
      "specific_problem": "Smart contract vulnerability detection (arithmetic vulnerabilities in Ethereum smart contracts)",
      "attack_types": [
        "Integer overflow",
        "Integer underflow",
        "Division by zero",
        "Modulo by zero"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN/GRU",
        "specific": "BiGRU",
        "novel_contribution": "Two-branch, multi-modal hybrid model with parallel BiGRUs over cleaned source code and compiled opcode, followed by feature fusion (concatenation) for classification."
      },
      {
        "type": "primary",
        "category": "Word Embedding",
        "specific": "FastText",
        "novel_contribution": "Character n-gram embeddings applied to both modalities (cleaned source code and opcode) before BiGRU feature extraction."
      },
      {
        "type": "baseline",
        "category": "Word Embedding",
        "specific": "Word2Vec",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "ScrawlD",
        "type": "public",
        "domain": "smart_contract_source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SmartBugs Dataset-Wild",
        "type": "public",
        "domain": "smart_contract_source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ERC-20 smart contract dataset",
        "type": "public",
        "domain": "smart_contract_source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a multi-modal hybrid deep learning model that fuses representations from cleaned Solidity source code and compiled EVM opcode using FastText + BiGRU improve smart contract vulnerability detection?",
        "How well does the proposed approach detect arithmetic vulnerabilities (integer over/underflow, division/modulo by zero) in real-world Ethereum smart contracts?"
      ],
      "gaps_identified": [
        "Existing analysis techniques rely on rigid expert-defined rules; detection time increases as contract complexity rises.",
        "Prior deep learning approaches often use a single, linear network structure, which can increase complexity and risk overfitting and long training times.",
        "Some methods target only specific vulnerabilities (e.g., reentrancy) or require complex graph construction pipelines.",
        "Opcode slicing approaches can cause partial feature loss by not fully distinguishing valuable from useless operands.",
        "BLSTM-ATT does not consider the relationship between the word embedding technique and the deep learning model."
      ],
      "limitations": [
        "Evaluation focuses on arithmetic vulnerabilities, despite claiming generality to all vulnerability types.",
        "Results are reported on a combined dataset (ScrawlD + SmartBugs Wild); broader generalization to other datasets or vulnerability categories is not demonstrated in the provided text."
      ],
      "future_work": [
        "Extend and validate the model on additional vulnerability types beyond arithmetic issues.",
        "Broaden empirical evaluation with more metrics and explicit, quantitative comparisons to established tools and deep learning baselines.",
        "Investigate scalability and deployment considerations (e.g., inference speed, integration with development toolchains)."
      ],
      "motivation": "Improve smart contract vulnerability detection accuracy and robustness by leveraging multimodal inputs (cleaned source and opcode) and a hybrid architecture (FastText + BiGRU) to overcome limitations of rule-based tools and single-branch DL models.",
      "potential_research_ideas": [
        "Integrate code property graphs or control/data flow graphs with the multimodal sequence inputs and use a graph neural network branch for richer semantics.",
        "Adopt transformer-based code models (e.g., CodeBERT/GraphCodeBERT) for source modality and compare/ensemble with RNNs.",
        "Design a contrastive multimodal pretraining objective to align source code and opcode representations before supervised fine-tuning.",
        "Move from binary to multi-label, multi-vulnerability detection and calibrate uncertainty for risk-aware triage.",
        "Incorporate static analysis-derived features (e.g., symbolic constraints) as an additional modality to improve precision on edge cases.",
        "Evaluate adversarial robustness to code obfuscations/semantics-preserving transformations relevant to smart contracts.",
        "Create a standardized benchmark suite combining real-world and synthetic contracts with verified ground truth across vulnerability types."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment BiGRU encoders with lightweight transformers and apply cross-attention between source and opcode streams before fusion.",
        "Use learnable gating or attention-based feature fusion instead of simple concatenation to weight modalities adaptively.",
        "Pretrain FastText or subword embeddings on a large corpus of Solidity/EVM code; compare with contextual embeddings.",
        "Introduce multi-task heads for simultaneous prediction of vulnerability presence and type/category.",
        "Apply curriculum learning or hard negative mining focused on near-miss non-vulnerable examples to improve boundary cases."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "TensorFlow",
        "Keras"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes HyMo, a multi-modal hybrid deep learning model combining two input representations (cleaned source code and compiled opcode) with FastText embeddings and BiGRU encoders.",
      "Demonstrates feature fusion from parallel deep learning branches to improve smart contract vulnerability detection.",
      "Uses real-world smart contracts in the dataset (combination of ScrawlD and SmartBugs Dataset-Wild).",
      "Evaluates multiple hybrid structures and reports: \"we achieve 79.71% accuracy given that our dataset contains real-world smart contracts.\"",
      "Claims improved accuracy over single neural networks and hybrid models without multimodal inputs, and better detection than other approaches."
    ]
  },
  {
    "arxiv_id": "2304.13253v1",
    "title": "Analyzing In-browser Cryptojacking",
    "authors": "Muhammad Saad; David Mohaisen",
    "abstract": "Cryptojacking is the permissionless use of a target device to covertly mine cryptocurrencies. With cryptojacking, attackers use malicious JavaScript codes to force web browsers into solving proof-of-work puzzles, thus making money by exploiting the resources of the website visitors. To understand and counter such attacks, we systematically analyze the static, dynamic, and economic aspects of in-browser cryptojacking. For static analysis, we perform content, currency, and code-based categorization of cryptojacking samples to 1) measure their distribution across websites, 2) highlight their platform affinities, and 3) study their code complexities. We apply machine learning techniques to distinguish cryptojacking scripts from benign and malicious JavaScript samples with 100\\% accuracy. For dynamic analysis, we analyze the effect of cryptojacking on critical system resources, such as CPU and battery usage. We also perform web browser fingerprinting to analyze the information exchange between the victim node and the dropzone cryptojacking server. We also build an analytical model to empirically evaluate the feasibility of cryptojacking as an alternative to online advertisement. Our results show a sizeable negative profit and loss gap, indicating that the model is economically infeasible. Finally, leveraging insights from our analyses, we build countermeasures for in-browser cryptojacking that improve the existing remedies.",
    "published_date": "2023-04-26",
    "pdf_link": "https://arxiv.org/pdf/2304.13253v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Web Security",
      "subdomain": "Web-based Malware and Abuse",
      "specific_problem": "Detection and characterization of in-browser cryptojacking JavaScript and its system/economic impacts; design of countermeasures",
      "attack_types": [
        "in-browser cryptojacking",
        "unauthorized cryptocurrency mining",
        "JavaScript-based mining",
        "Monero mining",
        "resource hijacking"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Linear Model",
        "specific": "Logistic Regression",
        "novel_contribution": "Applied to static code-based and website-level features to classify cryptojacking scripts vs benign/malicious JavaScript"
      },
      {
        "type": "primary",
        "category": "Linear Discriminant Analysis",
        "specific": "LDA",
        "novel_contribution": "Used within a supervised learning setup for cryptojacking code detection"
      },
      {
        "type": "primary",
        "category": "Instance-based",
        "specific": "k-Nearest Neighbors",
        "novel_contribution": "Used as one of several supervised learners for detection"
      },
      {
        "type": "primary",
        "category": "SVM",
        "specific": "Support Vector Machine",
        "novel_contribution": "Applied to distinguish cryptojacking JavaScript from benign and other malicious scripts"
      },
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": "Random Forest",
        "novel_contribution": "Part of the supervised learning suite achieving reported 100% accuracy on the task"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Pixalate cryptojacking websites list (Nov 2017)",
        "type": "public",
        "domain": "web_urls",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Netlab 360 cryptojacking websites list (Feb 24, 2018)",
        "type": "public",
        "domain": "web_urls",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Combined cryptojacking websites dataset (5,703 sites)",
        "type": "public",
        "domain": "web_urls",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Active subset of cryptojacking websites (620 sites)",
        "type": "public",
        "domain": "web_urls",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Benign and other malicious JavaScript samples (non-cryptojacking)",
        "type": "private",
        "domain": "javascript_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Alexa site metrics",
        "type": "public",
        "domain": "web_analytics",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SimilarWeb traffic metrics",
        "type": "public",
        "domain": "web_analytics",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "WebShrinker URL categorization",
        "type": "public",
        "domain": "web_analytics",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "CPU usage",
      "battery usage",
      "memory footprint",
      "economic profit/loss"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What is the distribution of cryptojacking across websites and content categories?",
        "Which platforms/cryptocurrencies are used for in-browser cryptojacking and what are their affinities?",
        "Can static code-based features and supervised learning reliably distinguish cryptojacking scripts from benign and other malicious JavaScript?",
        "What are the dynamic impacts of cryptojacking on system resources such as CPU, battery, and memory?",
        "What information is exchanged between victim browsers and cryptojacking servers (via WebSocket fingerprinting)?",
        "Is cryptojacking economically feasible as an alternative to online advertising?",
        "What countermeasures can effectively mitigate in-browser cryptojacking beyond existing remedies?"
      ],
      "gaps_identified": [
        "Existing antivirus and traditional binary-focused defenses are ineffective against browser-based cryptojacking scripts shielded within browser processes.",
        "Limited understanding of the economic feasibility of cryptojacking as an ad replacement.",
        "Need for accurate detection at the website/script level using features specific to cryptojacking behavior.",
        "Existing countermeasures are limited; improvements are needed."
      ],
      "limitations": [
        "Primary focus on Monero-based in-browser cryptojacking due to prevalence and resource usage.",
        "Some listed websites became inactive and were excluded from analysis."
      ],
      "future_work": [
        "Explore and strengthen countermeasures for in-browser cryptojacking."
      ],
      "motivation": "Understand and counter in-browser cryptojacking by analyzing its ecosystem (static, dynamic, and economic aspects), achieving accurate detection, measuring user impact, and proposing improved defenses.",
      "potential_research_ideas": [
        "Develop robust detection against obfuscated and evolving cryptojacking scripts, including WebAssembly-based miners and dynamic code loading.",
        "Leverage network-level features (e.g., WebSocket traffic patterns and timing) combined with static script features for early, script-agnostic detection.",
        "Create a standardized, regularly updated public benchmark of cryptojacking scripts and benign/malicious JavaScript with detailed labels to enable fair comparisons.",
        "Investigate client-side, privacy-preserving on-device detection to protect users without leaking browsing data.",
        "Model adversarial responses (evasion) and build adversarially robust detectors for cryptojacking.",
        "Re-evaluate the economic model under different cryptocurrency markets and PoW algorithms, including throttling behaviors and consent mechanisms."
      ],
      "architectural_improvement_recommendations": [
        "Combine static code complexity/AST features with dynamic runtime and network telemetry in a multi-view classifier.",
        "Use representation learning on JavaScript ASTs (e.g., graph neural networks or transformers) to capture nuanced mining patterns beyond hand-crafted features.",
        "Incorporate WebSocket sequence modeling (e.g., HMM/transformers) to detect cryptojacking communication templates.",
        "Add adversarial training and obfuscation-augmented data to improve robustness.",
        "Implement lightweight, browser-side enforcement (extensions or CSP-integrated modules) that throttle or block suspicious mining behavior in real time."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Web browsers on Windows/Linux laptops and an Android phone (Selenium-automated) visiting real cryptojacking websites",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Potential script obfuscation and rapid evolution of cryptojacking code",
        "User-consent and ethics considerations complicate blanket blocking",
        "Cross-browser and cross-platform behavioral differences",
        "Encrypted/WebSocket communications reduce visibility for network defenses"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "In-depth analysis and characterization of >5,700 websites with in-browser cryptojacking scripts.",
      "Static analysis including content-, currency-, and code-based categorization; complexity analysis of scripts.",
      "Supervised ML-based detection of cryptojacking JavaScript achieving “100% accuracy” for distinguishing cryptojacking from benign/malicious JavaScript and website-level detection of 620 cryptojacking sites.",
      "Dynamic analysis measuring CPU usage, battery drainage, and memory footprints; WebSocket inspection/fingerprinting of cryptojacking communication.",
      "Analytical economic model showing cryptojacking is economically infeasible as an alternative to online advertising (negative profit/loss gap).",
      "Countermeasures proposed to improve upon existing remedies for in-browser cryptojacking.",
      "Extended analysis over prior version: more systematic background, supervised learning with multiple classifiers at website level, and memory footprint analysis; update showing 620 sites still active."
    ]
  },
  {
    "arxiv_id": "2304.00485v2",
    "title": "Graph Mining for Cybersecurity: A Survey",
    "authors": "Bo Yan; Cheng Yang; Chuan Shi; Yong Fang; Qi Li; Yanfang Ye; Junping Du",
    "abstract": "The explosive growth of cyber attacks nowadays, such as malware, spam, and intrusions, caused severe consequences on society. Securing cyberspace has become an utmost concern for organizations and governments. Traditional Machine Learning (ML) based methods are extensively used in detecting cyber threats, but they hardly model the correlations between real-world cyber entities. In recent years, with the proliferation of graph mining techniques, many researchers investigated these techniques for capturing correlations between cyber entities and achieving high performance. It is imperative to summarize existing graph-based cybersecurity solutions to provide a guide for future studies. Therefore, as a key contribution of this paper, we provide a comprehensive review of graph mining for cybersecurity, including an overview of cybersecurity tasks, the typical graph mining techniques, and the general process of applying them to cybersecurity, as well as various solutions for different cybersecurity tasks. For each task, we probe into relevant methods and highlight the graph types, graph approaches, and task levels in their modeling. Furthermore, we collect open datasets and toolkits for graph-based cybersecurity. Finally, we outlook the potential directions of this field for future research.",
    "published_date": "2023-04-02",
    "pdf_link": "https://arxiv.org/pdf/2304.00485v2",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Cross-domain Security",
      "subdomain": "Graph-based Cybersecurity",
      "specific_problem": "Survey of graph mining techniques, graph types, and processes applied across cybersecurity tasks",
      "attack_types": [
        "malware",
        "spam",
        "intrusions",
        "botnet",
        "fake news/rumors",
        "review spam",
        "fake accounts (Sybils)",
        "malicious domains (phishing, fast-flux/domain-flux)",
        "financial fraud (money laundering, cash-out, loan default, insurance fraud)",
        "underground market illicit trade",
        "system vulnerabilities (e.g., SQL injection)",
        "blockchain/smart contract security"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Graph Neural Networks",
        "novel_contribution": "Survey and taxonomy of how GNNs are applied to cybersecurity tasks"
      },
      {
        "type": "primary",
        "category": "Graph Embedding",
        "specific": "Graph embedding; representation learning on graphs",
        "novel_contribution": "Survey of graph embedding techniques (e.g., node/edge/structure embeddings) used in cybersecurity"
      },
      {
        "type": "primary",
        "category": "Graph Algorithms",
        "specific": "Graph mining methods",
        "novel_contribution": "Overview of general graph mining techniques and their use in cybersecurity (e.g., capturing correlations, structural patterns)"
      },
      {
        "type": "primary",
        "category": "Heterogeneous Graph Methods",
        "specific": "Meta-path based methods on HINs",
        "novel_contribution": "Discussion of meta-path based graph mining for modeling heterogeneous cyber-entity interactions (e.g., fraud detection)"
      }
    ],
    "learning_paradigm": [],
    "datasets": [
      {
        "name": "CVE (Common Vulnerabilities and Exposures)",
        "type": "public",
        "domain": "vulnerability_records",
        "link": "https://cve.mitre.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What cybersecurity tasks have been modeled using graph mining techniques?",
        "What are the typical graph types, graph approaches, and task levels used across these tasks?",
        "What is the general process for applying graph mining to cybersecurity problems?",
        "What open datasets and toolkits exist for graph-based cybersecurity?",
        "What promising directions exist for future research in graph-based cybersecurity?"
      ],
      "gaps_identified": [
        "Lack of a comprehensive survey specifically on graph-based cybersecurity applications prior to this work.",
        "Traditional ML methods hardly model correlations between real-world cyber entities, limiting performance on some tasks.",
        "Adversarial behaviors (e.g., fast-flux, domain-flux) pose challenges for tasks like malicious domain detection.",
        "Cyber attacks evolve rapidly, requiring methods that can capture and adapt to complex structural/temporal correlations."
      ],
      "limitations": [],
      "future_work": [
        "The paper provides an outlook on potential directions of this field for future research (details in Section 7)."
      ],
      "motivation": "Explosive growth of cyber attacks and the increasing use of graph mining in cybersecurity create an imperative to summarize existing graph-based solutions, techniques, datasets, and provide guidance for future studies.",
      "potential_research_ideas": [
        "Create standardized, multi-domain benchmark suites for graph-based cybersecurity with shared schemas and evaluation protocols.",
        "Develop temporal and dynamic GNNs tailored to evolving cyber graphs (e.g., DNS dynamics, API-call sequences over time).",
        "Design adversarially robust graph learning methods and attack/defense evaluations specific to cyber graphs (evasion/poisoning).",
        "Investigate privacy-preserving graph learning for sensitive cyber data (federated or secure multiparty graph learning).",
        "Cross-domain transfer and pretraining for cyber graphs to reduce label requirements (graph foundation models for security).",
        "Explainability methods for GNNs in cybersecurity to surface actionable indicators (APIs, domains, accounts) for analysts.",
        "Unified modeling of heterogeneous cyber entities with HINs and knowledge graphs for threat intelligence integration.",
        "Few-shot and active learning on graphs for emerging threats (new malware families, novel fraud patterns).",
        "Scalable graph processing pipelines for high-throughput network/security telemetry in real time.",
        "Causal and counterfactual reasoning over cyber graphs to distinguish correlation from causation in threat patterns."
      ],
      "architectural_improvement_recommendations": [
        "Adopt heterogeneous GNNs with meta-path attention to capture multi-entity interactions (e.g., user–device–IP–domain).",
        "Incorporate temporal GNNs or dynamic graph embeddings to handle evolving behaviors and concepts.",
        "Use contrastive/self-supervised pretraining on large unlabeled cyber graphs to improve downstream performance.",
        "Integrate rule-based constraints or knowledge graphs with neural models for compliance and better generalization.",
        "Employ robust training (adversarial augmentation, certified defenses) to mitigate graph perturbation attacks.",
        "Add explanation modules (e.g., GNNExplainer, PGExplainer) for analyst-friendly rationales.",
        "Leverage hierarchical pooling and subgraph-level models to detect community- or campaign-level threats.",
        "Build streaming graph ingestion with mini-batch training/inference (neighbor sampling) for real-time detection."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comprehensive review of graph mining for cybersecurity across tasks and domains.",
      "Overview and taxonomy of cybersecurity tasks addressed by graph-based methods.",
      "Summary of typical graph mining techniques and a general process for applying them to cybersecurity.",
      "For each task, highlights of graph types, graph approaches, and task levels used in modeling.",
      "Collection of open datasets and toolkits for graph-based cybersecurity.",
      "Outlook on potential directions for future research in graph-based cybersecurity."
    ]
  },
  {
    "arxiv_id": "2306.05698v1",
    "title": "JABBERWOCK: A Tool for WebAssembly Dataset Generation and Its Application to Malicious Website Detection",
    "authors": "Chika Komiya; Naoto Yanai; Kyosuke Yamashita; Shingo Okamura",
    "abstract": "Machine learning is often used for malicious website detection, but an approach incorporating WebAssembly as a feature has not been explored due to a limited number of samples, to the best of our knowledge. In this paper, we propose JABBERWOCK (JAvascript-Based Binary EncodeR by WebAssembly Optimization paCKer), a tool to generate WebAssembly datasets in a pseudo fashion via JavaScript. Loosely speaking, JABBERWOCK automatically gathers JavaScript code in the real world, convert them into WebAssembly, and then outputs vectors of the WebAssembly as samples for malicious website detection. We also conduct experimental evaluations of JABBERWOCK in terms of the processing time for dataset generation, comparison of the generated samples with actual WebAssembly samples gathered from the Internet, and an application for malicious website detection. Regarding the processing time, we show that JABBERWOCK can construct a dataset in 4.5 seconds per sample for any number of samples. Next, comparing 10,000 samples output by JABBERWOCK with 168 gathered WebAssembly samples, we believe that the generated samples by JABBERWOCK are similar to those in the real world. We then show that JABBERWOCK can provide malicious website detection with 99\\% F1-score because JABBERWOCK makes a gap between benign and malicious samples as the reason for the above high score. We also confirm that JABBERWOCK can be combined with an existing malicious website detection tool to improve F1-scores. JABBERWOCK is publicly available via GitHub (https://github.com/c-chocolate/Jabberwock).",
    "published_date": "2023-06-09",
    "pdf_link": "https://arxiv.org/pdf/2306.05698v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Web Security",
      "subdomain": "Malicious Website Detection",
      "specific_problem": "Using WebAssembly-derived features for malicious website detection and generating pseudo WebAssembly datasets from JavaScript",
      "attack_types": [
        "phishing",
        "cryptojacking"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Document Embedding",
        "specific": "Doc2Vec (PV-DM, PV-DBOW)",
        "novel_contribution": "Vectorizes WebAssembly Text (WAT) produced from JavaScript via Wobfuscator, enabling WebAssembly-based features for website detection; introduces evaluation via difference of cosine similarities between J2W- and OWA-based models"
      },
      {
        "type": "primary",
        "category": "SVM",
        "specific": "RBF, Polynomial, Linear kernels",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Ensemble - Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Naive Bayes",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "LightGBM",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "J2W pseudo WebAssembly dataset (generated by JABBERWOCK) - 10,000 samples",
        "type": "synthetic",
        "domain": "webassembly_text",
        "link": "https://github.com/c-chocolate/Jabberwock",
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "OWA real-world WebAssembly samples - 168 samples",
        "type": "public",
        "domain": "webassembly_binaries",
        "link": "https://publicwww.com",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Benign URL list (Tranco)",
        "type": "public",
        "domain": "urls",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Malicious URL lists (URLhaus, Malware Domain List, CyberCrime Tracker, PhishTank)",
        "type": "public",
        "domain": "urls",
        "link": "https://urlhaus.abuse.ch",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PublicWWW URL list (source for 10,000 JS and 168 WebAssembly samples)",
        "type": "public",
        "domain": "web_contents",
        "link": "https://publicwww.com",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "MADMAX (browser-based ML malicious website detection tool)",
        "paper_reference": "[3]",
        "metric": "F1-score",
        "their_result": "“We also confirm that JABBERWOCK can be combined with an existing malicious website detection tool to improve F1-scores.”",
        "baseline_result": null
      },
      {
        "method_name": "MADDONA (latest extension of MADMAX)",
        "paper_reference": "[4]",
        "metric": "F1-score",
        "their_result": "“its resultant performance outperforms MADDONA.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "Processing time per sample",
      "Cosine similarity difference (between J2W- and OWA-based models)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Is malicious website detection based on WebAssembly possible?",
        "Can pseudo WebAssembly datasets generated from JavaScript approximate real-world WebAssembly distributions sufficiently for ML use?"
      ],
      "gaps_identified": [
        "“there is no publicly available dataset of WebAssembly.”",
        "The number of websites with WebAssembly is currently limited.",
        "Prior works do not contain correctly labeled WebAssembly samples from live websites for ML-based detection.",
        "WebAssembly as a feature for malicious website detection has not been explored."
      ],
      "limitations": [
        "JABBERWOCK extracts only a single JavaScript file per page to suppress data bias, which may omit relevant scripts.",
        "The OWA real-world WebAssembly set is small (168 samples).",
        "In the unlabeled OWA corpus, malicious proportion is low (“less than 10% malicious WebAssembly samples”), complicating labeled evaluation.",
        "Generated datasets are pseudo (converted from JavaScript via Wobfuscator), which may not capture all characteristics of native WebAssembly found in the wild."
      ],
      "future_work": [
        "“We leave it as an open problem to design a browser-based application with WebAssembly.”"
      ],
      "motivation": "Enable the use of WebAssembly as a feature for malicious website detection despite the lack of labeled WebAssembly datasets and the limited prevalence of WebAssembly on current websites.",
      "potential_research_ideas": [
        "Pretrain large-code embeddings on massive WAT/wasm corpora (e.g., code transformers) and fine-tune for website classification.",
        "Domain adaptation/contrastive learning to align pseudo J2W embeddings with real OWA embeddings for improved generalization.",
        "Fuse WebAssembly features with other modalities (URL, HTML, DNS, TLS, network telemetry) for multi-view detection.",
        "Dynamic analysis: incorporate runtime WebAssembly behavior (imports, memory ops, syscalls) and side-channel features.",
        "Adversarial robustness: study obfuscation/evasion tactics in JavaScript-to-WASM conversion and robustify embeddings.",
        "Automatic labeling via weak supervision/snorkel-style rules using multiple threat feeds and behavioral heuristics.",
        "Deploy as a browser extension or gateway filter with on-the-fly WAT extraction and incremental learning."
      ],
      "architectural_improvement_recommendations": [
        "Replace Doc2Vec with modern sequence/graph encoders for code (e.g., Transformer encoders over opcode/token sequences; code-specific models like CodeBERT/GraphCodeBERT).",
        "Model control-flow/data-flow graphs of WAT/wasm with GNNs to capture structural malicious patterns.",
        "Use contrastive/self-supervised objectives (SimCLR/InfoNCE) on WAT snippets to learn robust embeddings before supervised fine-tuning.",
        "Calibrate classifiers and use cost-sensitive learning to handle class imbalance and reduce FPs.",
        "Scale vector size and tune Doc2Vec hyperparameters systematically; evaluate contextualized embeddings vs static.",
        "Augment training via diverse JS-to-WASM pipelines beyond Wobfuscator to reduce generator bias."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/c-chocolate/Jabberwock",
      "frameworks": [
        "Python",
        "requests (2.27.1)",
        "gensim (Doc2Vec)",
        "scikit-learn",
        "xgboost",
        "lightgbm",
        "Node.js/npm (wasm2wat)",
        "Wobfuscator"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Implemented in Python 3.7.10 on AWS EC2 Ubuntu t3a.xlarge; dataset generation time ≈ 4.5 seconds per sample; vectorization time increases with vector size; PV-DBOW slower than PV-DM."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Limited prevalence of WebAssembly on current websites reduces labeled data availability.",
        "Labeling challenges and imbalance (few malicious WebAssembly samples in the wild).",
        "Reliance on JavaScript-to-WASM conversion (Wobfuscator) may introduce distribution shift vs native WebAssembly.",
        "Potential integration complexity for real-time browser/gateway deployment and on-the-fly vectorization."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes JABBERWOCK, a publicly available tool to generate WebAssembly datasets from JavaScript code for malicious website detection.",
      "Processing performance: “JABBERWOCK can construct a dataset in 4.5 seconds per sample for any number of samples.”",
      "Similarity to real world: “comparing 10,000 samples output by JABBERWOCK with 168 gathered WebAssembly samples, we believe that the generated samples by JABBERWOCK are similar to those in the real world.”",
      "Detection effectiveness: “Malicious websites can be detected with 99% F1-score because JABBERWOCK makes a gap between benign and malicious samples.”",
      "Demonstrates improvement when combined with existing tool: “JABBERWOCK can be combined with an existing malicious website detection tool to improve F1-scores,” and it outperforms MADDONA.",
      "Introduces an evaluation approach based on the difference between cosine similarities of J2W- and OWA-based models."
    ]
  },
  {
    "arxiv_id": "2306.02473v1",
    "title": "Anomaly Detection Techniques in Smart Grid Systems: A Review",
    "authors": "Shampa Banik; Sohag Kumar Saha; Trapa Banik; S M Mostaq Hossain",
    "abstract": "Smart grid data can be evaluated for anomaly detection in numerous fields, including cyber-security, fault detection, electricity theft, etc. The strange anomalous behaviors may have been caused by various reasons, including peculiar consumption patterns of the consumers, malfunctioning grid infrastructures, outages, external cyber-attacks, or energy fraud. Recently, anomaly detection of the smart grid has attracted a large amount of interest from researchers, and it is widely applied in a number of high-impact fields. One of the most significant challenges within the smart grid is the implementation of efficient anomaly detection for multiple forms of aberrant behaviors. In this paper, we provide a scoping review of research from the recent advancements in anomaly detection in the context of smart grids. We categorize our study from numerous aspects for deep understanding and inspection of the research challenges so far. Finally, after analyzing the gap in the reviewed paper, the direction for future research on anomaly detection in smart-grid systems has been provided briefly.",
    "published_date": "2023-06-04",
    "pdf_link": "https://arxiv.org/pdf/2306.02473v1",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Critical Infrastructure Security",
      "subdomain": "Smart Grid Security",
      "specific_problem": "Anomaly detection in smart grid/AMI using smart meter, ICS/SCADA, and network data (cyber-attacks, faults, electricity theft, outages, unusual consumption)",
      "attack_types": [
        "False Data Injection (FDI)",
        "Electricity theft",
        "Denial of Service (DoS)",
        "Cyber-physical attacks on DER communication",
        "Protocol-based threats (Modbus/TCP, DNP3)"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Deep Learning",
        "specific": "Stacked Autoencoder; Seq2Seq LSTM Autoencoder",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GAN",
        "specific": "Recurrent GAN (R-GAN); Wasserstein GAN (WGAN); Metropolis-Hastings GAN (MH-GAN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Spectral Residual CNN (SR-CNN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM (including MODLSTM)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transfer Learning",
        "specific": "CDAN (Cluster-based Deep Adaptation Network)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Classical ML",
        "specific": "Isolation Forest; PCA for feature selection",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Density-based",
        "specific": "Distance-matrix abnormality (compared with k-means, GMM, DBSCAN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoencoder+GAN",
        "specific": "MENSA IDS (Autoencoder-GAN for anomaly detection and cyber threat classification)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph Neural Network",
        "specific": "GCN for time-series edge-cloud anomaly detection",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "DNN",
        "specific": "Stacked Sparse Autoencoder + Softmax classifier",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Forecasting model",
        "specific": "Prophet (Generalized Additive Regression Model)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Rule-based + DNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Privacy-preserving ML",
        "specific": "LUT-based Fully Homomorphic Encryption (FHE) + Private Information Retrieval (PIR) for anomaly detection",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Digital Twin",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble",
        "specific": "Ensemble of prediction-based models + majority voting",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Time-series models",
        "specific": "ARIMA; Fourier Transform for feature engineering",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Big Data Architecture",
        "specific": "Lambda architecture; Apache Flink-based speed layer",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Semi-supervised",
      "Transfer learning",
      "Federated"
    ],
    "datasets": [
      {
        "name": "Smart meter (SM) data (residential/commercial)",
        "type": "private",
        "domain": "smart_meter_readings",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "DER communication testbed data (ML-ADS for stealthy attacks)",
        "type": "private",
        "domain": "ics_der_network",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Raspberry Pi-based smart meter experiment (FHE+PIR privacy-preserving anomaly detection)",
        "type": "private",
        "domain": "smart_meter_readings",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "ISAAC ICS SCADA testbed data with IREST sensor",
        "type": "private",
        "domain": "ics_scada",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "IEEE 39-bus power system simulated measurements",
        "type": "synthetic",
        "domain": "power_system_measurements",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IEEE 118-bus power system simulated measurements",
        "type": "synthetic",
        "domain": "power_system_measurements",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IEEE 2848-bus power system simulated measurements",
        "type": "synthetic",
        "domain": "power_system_measurements",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "MODBUS/TCP and DNP3 network traffic traces (for MENSA IDS)",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Residential building power consumption time-series (Janetzko et al.)",
        "type": "private",
        "domain": "building_energy",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Smart meter analytics performance benchmark and synthetic data generation (Golab et al.)",
        "type": "synthetic",
        "domain": "smart_meter_readings",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "True Positive Rate (TPR)",
      "False Positive Rate (FPR)",
      "Detection latency",
      "Execution time"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What are the recent advancements in anomaly detection techniques for smart grids?",
        "How can anomaly detection research in smart grids be categorized by detection level, anomaly type, and computing methodology?",
        "What are the open challenges and research gaps, and what directions should future research take for smart-grid anomaly detection?"
      ],
      "gaps_identified": [
        "“there has not been enough published research work done on the application of these crucial SM data for outage/anomaly identification in SG technology.”",
        "Lack of system-wide ML-based event correlation for cyber situation awareness (noted in [22]).",
        "Comparative evaluations across anomaly detection algorithms are missing in some big-data platforms to better cluster customers based on SM traces (noted in [2]/Table 1).",
        "Privacy and distribution constraints, and heavy data requirements hinder some hybrid frameworks (Table 1: “require an extensive amount of data samples, don’t function distributively, and are hard to keep private”).",
        "Shortage of malicious/anomalous labeled datasets for training (Table 1: “malicious datasets are not readily available”)."
      ],
      "limitations": [],
      "future_work": [
        "Propose and investigate a generative model leveraging smart meter data at both lateral and consumer levels for multi-level anomaly detection.",
        "Use SM data to predict load patterns and design corresponding defense models.",
        "Further study digital twin-based monitoring for anomaly detection and cybersecurity in smart grids."
      ],
      "motivation": "Efficiently detecting multiple forms of anomalous behaviors in smart grids (cyber-security, faults, electricity theft, outages) is challenging; the paper aims to provide a scoping review, categorize approaches, analyze strengths/limitations, identify gaps, and outline future research directions.",
      "potential_research_ideas": [
        "Create a public benchmark dataset for smart meter-based anomaly and outage detection with standardized tasks and metrics across cyber, theft, and fault scenarios.",
        "Develop privacy-preserving federated semi-supervised learning for SM anomaly detection using FHE/PIR at meters and secure aggregation at the edge.",
        "Design system-wide event correlation methods that fuse DER communications, SCADA measurements, and SM data for holistic cyber situation awareness.",
        "Self-supervised representation learning for multi-seasonal energy time series to reduce labeled data needs and handle concept drift.",
        "Edge-cloud collaborative GNNs that transform streaming time series to graphs for low-latency anomaly detection with bandwidth-aware model partitioning.",
        "Generative data augmentation pipelines (GANs + physics-informed constraints) to synthesize rare attack/fault conditions for training and evaluation."
      ],
      "architectural_improvement_recommendations": [
        "Adopt multi-task architectures that jointly detect anomalies and classify cause (cyber vs. fault vs. theft) with shared encoders for SM, network, and SCADA modalities.",
        "Incorporate drift detection and online adaptation (e.g., adaptive normalization, continual learning) to handle seasonal and behavioral changes in consumption.",
        "Use uncertainty-aware inference (Bayesian layers, conformal prediction) to flag low-confidence detections for human review.",
        "Integrate explainability modules (e.g., SHAP for time-series, counterfactuals) to attribute anomalies to features, devices, or time segments.",
        "Implement hierarchical edge-cloud deployment: lightweight anomaly filters on meters/gateways, with deep models in fog/cloud; use model compression/quantization for TinyML on devices.",
        "Leverage hybrid privacy mechanisms: combine FHE/PIR for critical queries with DP-noised summaries for model training."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High data volume/velocity from smart meters and IoT sensors",
        "Privacy constraints on smart meter data sharing",
        "Label scarcity and class imbalance for anomalies",
        "Need for edge-cloud distribution to meet latency and bandwidth constraints",
        "Heterogeneity of industrial protocols (Modbus, DNP3) and DER devices",
        "Concept drift and strong seasonality/trends in consumption patterns"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Scoping review of recent anomaly detection techniques in smart grids.",
      "Categorization by detection level (cyber-attacks, faults, theft, CPS), anomaly types (power supply rate, customer behavior, load balancing, outages), and computing platforms (machine learning, cloud, hybrid, edge).",
      "Critical analysis summarizing main concepts, strengths, and limitations of pertinent literature (Table 1).",
      "Identification of research gaps in smart grid anomaly detection.",
      "Recommendation of a generative-model-based approach leveraging smart meter data for multi-level anomaly detection and load pattern prediction."
    ]
  },
  {
    "arxiv_id": "2304.03958v1",
    "title": "KeyDetect --Detection of anomalies and user based on Keystroke Dynamics",
    "authors": "Soumyatattwa Kar; Abhishek Bamotra; Bhavya Duvvuri; Radhika Mohanan",
    "abstract": "Cyber attacks has always been of a great concern. Websites and services with poor security layers are the most vulnerable to such cyber attacks. The attackers can easily access sensitive data like credit card details and social security number from such vulnerable services. Currently to stop cyber attacks, various different methods are opted from using two-step verification methods like One-Time Password and push notification services to using high-end bio-metric devices like finger print reader and iris scanner are used as security layers. These current security measures carry a lot of cons and the worst is that user always need to carry the authentication device on them to access their data. To overcome this, we are proposing a technique of using keystroke dynamics (typing pattern) of a user to authenticate the genuine user. In the method, we are taking a data set of 51 users typing a password in 8 sessions done on alternate days to record mood fluctuations of the user. Developed and implemented anomaly-detection algorithm based on distance metrics and machine learning algorithms like Artificial Neural networks (ANN) and convolutional neural network (CNN) to classify the users. In ANN, we implemented multi-class classification using 1-D convolution as the data was correlated and multi-class classification with negative class which was used to classify anomaly based on all users put together. We were able to achieve an accuracy of 95.05% using ANN with Negative Class. From the results achieved, we can say that the model works perfectly and can be bought into the market as a security layer and a good alternative to two-step verification using external devices. This technique will enable users to have two-step security layer without worrying about carry an authentication device.",
    "published_date": "2023-04-08",
    "pdf_link": "https://arxiv.org/pdf/2304.03958v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Identity and Access Management",
      "subdomain": "Behavioral Biometrics",
      "specific_problem": "User authentication and impostor detection using keystroke dynamics",
      "attack_types": [
        "unauthorized_access",
        "account_takeover",
        "impostor_login"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D CNN + Fully Connected head",
        "novel_contribution": "Multi-class classifier over 51 users using two 1D conv layers (16 and 32 channels, kernel size 3) followed by FC layers (992, 128) to capture spatial correlation in timing features; achieved 94.6% accuracy."
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D CNN with Negative Class training",
        "novel_contribution": "Introduces a 'Negative Class' composed of samples from unseen users (20 of 51) alongside 31 known user classes to detect anomalous/unseen users; achieved 95.05% accuracy overall; negative class recall 80.9%, precision 67.22%, F1 0.733."
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": "Fully Connected ANN",
        "novel_contribution": "Two hidden layers (80, 60 nodes) with learning-rate scheduler; achieved 92.2% accuracy."
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": "Used as a baseline multiclass classifier; 93.66% accuracy."
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Multiclass SVM",
        "novel_contribution": "Used as a baseline; achieved 75.6% accuracy."
      },
      {
        "type": "baseline",
        "category": "One-class SVM",
        "specific": null,
        "novel_contribution": "Used as an anomaly detector; hyperparameter nu optimized; no aggregate performance numbers reported."
      },
      {
        "type": "baseline",
        "category": "Distance-based anomaly detection",
        "specific": "Euclidean distance to mean",
        "novel_contribution": "Anomaly detection baseline; Average EER 0.265; Average ZFR 0.753."
      },
      {
        "type": "baseline",
        "category": "Distance-based anomaly detection",
        "specific": "Manhattan distance to mean",
        "novel_contribution": "Anomaly detection baseline; Average EER 0.206; Average ZFR 0.711."
      },
      {
        "type": "baseline",
        "category": "Distance-based anomaly detection",
        "specific": "Manhattan (Scaled)",
        "novel_contribution": "Anomaly detection baseline using average absolute deviation scaling; Average EER 0.141; Average ZFR 0.540."
      },
      {
        "type": "baseline",
        "category": "Distance-based anomaly detection",
        "specific": "Mahalanobis distance",
        "novel_contribution": "Anomaly detection baseline; Average EER 0.193; Average ZFR 0.645."
      },
      {
        "type": "baseline",
        "category": "Distance-based anomaly detection",
        "specific": "Mahalanobis (Normed)",
        "novel_contribution": "Anomaly detection baseline normalized by input norms; Average EER 0.166; Average ZFR 0.666."
      },
      {
        "type": "baseline",
        "category": "Statistical anomaly detection",
        "specific": "Z-score thresholding",
        "novel_contribution": "Anomaly detection baseline; Average EER 0.135 (best among distance/statistical baselines); Average ZFR 0.535."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "One-class",
      "Distance-based anomaly detection"
    ],
    "datasets": [
      {
        "name": "Killourhy & Maxion 2009 Keystroke Dynamics Dataset",
        "type": "public",
        "domain": "keystroke_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "ANN (1-D Conv.)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "95.05% (ANN with Negative Class)",
        "baseline_result": "94.6%"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "95.05% (ANN with Negative Class)",
        "baseline_result": "93.66%"
      },
      {
        "method_name": "ANN (Fully Connected)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "95.05% (ANN with Negative Class)",
        "baseline_result": "92.2%"
      },
      {
        "method_name": "SVM (multiclass)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "95.05% (ANN with Negative Class)",
        "baseline_result": "75.6%"
      },
      {
        "method_name": "Muliono et al. (2018) keystroke classification",
        "paper_reference": "Y. Muliono, H. Ham, D. Darmawan, Procedia Computer Science, 2018",
        "metric": "Accuracy",
        "their_result": "95.05% (ANN with Negative Class)",
        "baseline_result": "92.6%"
      },
      {
        "method_name": "Z-Score (anomaly detection)",
        "paper_reference": null,
        "metric": "Average EER",
        "their_result": null,
        "baseline_result": "0.135 (S.D. 0.065)"
      },
      {
        "method_name": "Manhattan (Scaled) (anomaly detection)",
        "paper_reference": null,
        "metric": "Average EER",
        "their_result": null,
        "baseline_result": "0.141 (S.D. 0.068)"
      },
      {
        "method_name": "Mahalanobis (anomaly detection)",
        "paper_reference": null,
        "metric": "Average EER",
        "their_result": null,
        "baseline_result": "0.193 (S.D. 0.101)"
      },
      {
        "method_name": "Mahalanobis (Normed) (anomaly detection)",
        "paper_reference": null,
        "metric": "Average EER",
        "their_result": null,
        "baseline_result": "0.166 (S.D. 0.092)"
      },
      {
        "method_name": "Manhattan (anomaly detection)",
        "paper_reference": null,
        "metric": "Average EER",
        "their_result": null,
        "baseline_result": "0.206 (S.D. 0.077)"
      },
      {
        "method_name": "Euclidean (anomaly detection)",
        "paper_reference": null,
        "metric": "Average EER",
        "their_result": null,
        "baseline_result": "0.265 (S.D. 0.079)"
      },
      {
        "method_name": "Z-Score (anomaly detection)",
        "paper_reference": null,
        "metric": "Average ZFR",
        "their_result": null,
        "baseline_result": "0.535 (S.D. 0.275)"
      },
      {
        "method_name": "Manhattan (Scaled) (anomaly detection)",
        "paper_reference": null,
        "metric": "Average ZFR",
        "their_result": null,
        "baseline_result": "0.540 (S.D. 0.271)"
      },
      {
        "method_name": "Mahalanobis (anomaly detection)",
        "paper_reference": null,
        "metric": "Average ZFR",
        "their_result": null,
        "baseline_result": "0.645 (S.D. 0.299)"
      },
      {
        "method_name": "Mahalanobis (Normed) (anomaly detection)",
        "paper_reference": null,
        "metric": "Average ZFR",
        "their_result": null,
        "baseline_result": "0.666 (S.D. 0.301)"
      },
      {
        "method_name": "Manhattan (anomaly detection)",
        "paper_reference": null,
        "metric": "Average ZFR",
        "their_result": null,
        "baseline_result": "0.711 (S.D. 0.224)"
      },
      {
        "method_name": "Euclidean (anomaly detection)",
        "paper_reference": null,
        "metric": "Average ZFR",
        "their_result": null,
        "baseline_result": "0.753 (S.D. 0.212)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "Equal Error Rate (EER)",
      "Zero-miss False-Alarm Rate (ZFR)",
      "ROC curve"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can keystroke dynamics be used to authenticate a genuine user and detect impostors?",
        "Do keystroke timing features exhibit spatial correlation that 1D convolutions can exploit?",
        "Can a negative-class training strategy enable detection of unseen (anomalous) users?"
      ],
      "gaps_identified": [
        "Distance-metric anomaly detectors showed relatively high EER/ZFR on this dataset.",
        "Prior reported result cited as 92.6% accuracy served as a benchmark to improve upon.",
        "Existing approaches often evaluated on fixed passwords; generalization beyond a single password is underexplored."
      ],
      "limitations": [
        "Data collected and evaluated on a single fixed password typed by 51 users.",
        "Accuracy decreased when increasing CNN depth/channels (sensitivity to model complexity).",
        "No deployment or real-world evaluation; results limited to a controlled benchmark dataset."
      ],
      "future_work": [
        "Extend to commonly occurring English words ('flag words') for online monitoring and verification.",
        "Implement continuous monitoring on smartphones, desktops, laptops as an extra security layer.",
        "Add emotion detection based on keystrokes tactile sensing using highly sensitive soft-bodied tactile sensors."
      ],
      "motivation": "Provide a two-step security layer without requiring users to carry external authentication devices by leveraging keystroke dynamics for user authentication and anomaly detection.",
      "potential_research_ideas": [
        "Free-text and multi-password keystroke authentication to improve generalization beyond a single fixed string.",
        "Sequence modeling (LSTM/GRU/Transformer) or temporal CNNs tailored to keystroke timing sequences.",
        "Metric learning/Siamese or prototypical networks for per-user verification and impostor detection.",
        "Self-supervised or contrastive pretraining on keystroke data to reduce labeled data needs and improve robustness.",
        "Domain adaptation across keyboards/devices (mechanical vs. laptop) and typing contexts.",
        "Adversarial robustness studies against mimicry attacks and informed impostors.",
        "Federated learning for privacy-preserving training across user devices.",
        "Calibration of anomaly thresholds and open-set recognition methods for unseen users."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment 1D CNN with temporal models (BiLSTM/Temporal Convolutional Networks/Transformers) to capture longer-range dependencies.",
        "Use Siamese/Triplet networks with contrastive/triplet loss to directly learn user-discriminative embeddings.",
        "Incorporate per-user adaptive thresholds and open-set classifiers (e.g., OpenMax) for anomaly detection.",
        "Apply regularization and model selection (e.g., dropout, weight decay, early stopping) to avoid overfitting when increasing capacity.",
        "Explore feature normalization and learned positional encodings reflecting key order in the password.",
        "Multi-task training to jointly predict user ID and auxiliary attributes (e.g., session/day) to improve invariance."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Proposed for smartphones and desktop/laptop keyboards; not deployed.",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Current evaluation limited to a single fixed password; generalization to free-text or varied passwords not addressed."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Implements and evaluates multiple anomaly-detection distance metrics and ML classifiers for keystroke-based authentication on the Killourhy & Maxion dataset.",
      "Proposes and validates a Negative Class training strategy to detect unseen users, achieving 95.05% accuracy with reported negative-class precision/recall/F1.",
      "Demonstrates that 1D convolution over keystroke timing features improves accuracy over fully connected ANN (94.6% vs. 92.2%), indicating spatial correlation in features.",
      "Provides comparative results including EER and ZFR for standard anomaly detectors, showing their limitations on this dataset."
    ]
  },
  {
    "arxiv_id": "2304.12749v2",
    "title": "Blockchain Large Language Models",
    "authors": "Yu Gai; Liyi Zhou; Kaihua Qin; Dawn Song; Arthur Gervais",
    "abstract": "This paper presents a dynamic, real-time approach to detecting anomalous blockchain transactions. The proposed tool, BlockGPT, generates tracing representations of blockchain activity and trains from scratch a large language model to act as a real-time Intrusion Detection System. Unlike traditional methods, BlockGPT is designed to offer an unrestricted search space and does not rely on predefined rules or patterns, enabling it to detect a broader range of anomalies. We demonstrate the effectiveness of BlockGPT through its use as an anomaly detection tool for Ethereum transactions. In our experiments, it effectively identifies abnormal transactions among a dataset of 68M transactions and has a batched throughput of 2284 transactions per second on average. Our results show that, BlockGPT identifies abnormal transactions by ranking 49 out of 124 attacks among the top-3 most abnormal transactions interacting with their victim contracts. This work makes contributions to the field of blockchain transaction analysis by introducing a custom data encoding compatible with the transformer architecture, a domain-specific tokenization technique, and a tree encoding method specifically crafted for the Ethereum Virtual Machine (EVM) trace representation.",
    "published_date": "2023-04-25",
    "pdf_link": "https://arxiv.org/pdf/2304.12749v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Intrusion Detection / Anomaly Detection for Smart Contracts",
      "specific_problem": "Real-time anomaly detection and ranking of anomalous Ethereum transactions using execution traces (EVM) as a defense-oriented IDS",
      "attack_types": [
        "Flash loan attacks",
        "Reentrancy",
        "Price oracle manipulation",
        "Governance attack via flash-loan-enabled vote takeover"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": null,
        "novel_contribution": "Custom data encoding for EVM trace trees, domain-specific tokenization, and a custom tree positional encoding; trained from scratch with causal language modeling on transaction traces to score anomaly via log-likelihood"
      },
      {
        "type": "baseline",
        "category": "Representation Learning",
        "specific": "doc2vec",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Heuristic",
        "specific": "Trace length heuristic",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Ethereum 68M Tx trace dataset (124 attacked contracts, 2018-04-19 to 2022-06-21)",
        "type": "public",
        "domain": "blockchain_transaction_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "doc2vec",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Trace length heuristic",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "percentage ranking alarm threshold",
      "absolute ranking alarm threshold",
      "F1-score",
      "F10-score",
      "CID score",
      "False Positive Rate (FPR)",
      "Throughput (transactions per second)",
      "Latency per transaction"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a transformer language model trained in an unsupervised/self-supervised manner on EVM execution traces detect anomalous blockchain transactions in real time without predefined rules or profit heuristics?",
        "What anomaly ranking accuracy and false positive rates can be achieved across large-scale Ethereum datasets?",
        "Can such a system operate at real-time throughput suitable for IDS/IPS use on blockchain nodes?"
      ],
      "gaps_identified": [
        "State-of-the-art works rely on predefined rules/patterns or reward-based heuristics, constraining the search space and potentially missing unseen anomalies.",
        "Real-time blockchain IDS is challenging due to manual engineering effort and limited generality of pattern-based approaches.",
        "Existing methods may not capture the full spectrum of anomalous behaviors in DeFi’s composable transactions."
      ],
      "limitations": [
        "Potential for false positives; performance depends on alarm thresholds.",
        "Hidden adversaries using private propagation (FaaS) cannot be observed pre-confirmation; detection becomes retrospective.",
        "Coverage is partial: “ranking 49 out of 124 attacks among the top-3 most abnormal transactions interacting with their victim contracts.”",
        "Evaluation limited to Ethereum and the set of 124 known attacked contracts/timeframe provided.",
        "Operational defenses (e.g., pause mechanisms) are required to act on alerts; not all contracts have them."
      ],
      "future_work": [],
      "motivation": "Significant financial losses in DeFi and the limitations of rule/pattern-based or profit-focused detection motivate a generic, dynamic, and scalable real-time anomaly detection system for blockchain transactions.",
      "potential_research_ideas": [
        "Cross-chain generalization: extend training to multi-chain EVM and non-EVM ecosystems; study transfer learning across chains and DApps.",
        "Hybrid training: combine self-supervised LM pretraining on traces with supervised fine-tuning on labeled attacks to improve precision/recall.",
        "Mempool-aware detection: incorporate pending-transaction and ordering features (where available) to better handle observable adversaries.",
        "Continual/online learning to adapt to evolving DeFi behaviors and concept drift while controlling catastrophic forgetting.",
        "Explainable anomaly scoring: learn token/segment-level attributions on trace trees to highlight suspicious substructures.",
        "Defense-in-the-loop: integrate with automated on-chain mitigation (pauses, circuit breakers) with calibrated risk thresholds and economic impact modeling.",
        "Robustness to evasion: evaluate and harden against adversarial manipulation of traces (e.g., padding, benign-looking call patterns).",
        "Retrieval-augmented scoring: condition the LM on historical contract-specific context or code semantics for better disambiguation."
      ],
      "architectural_improvement_recommendations": [
        "Adopt hierarchical or tree-transformers explicitly modeling call-tree structure (e.g., Tree/Hierarchical Positional Encodings, pooling by call scopes).",
        "Explore decoder-only causal LMs versus encoder-only masked objectives; compare with permutation-based objectives (XLNet-style) for anomaly scoring.",
        "Introduce graph neural networks over inter-contract call graphs and state access graphs, fused with token-level LM features.",
        "Use mixture-of-experts or contract/domain adapters (LoRA/IA3) to specialize to protocol families while retaining shared backbone.",
        "Employ contrastive learning between normal vs. rare/novel traces (InfoNCE) and energy-based anomaly scoring.",
        "Calibrate anomaly scores (e.g., temperature scaling, EVT modeling) to stabilize thresholds across protocols and traffic regimes.",
        "Leverage retrieval augmentation from historical traces and on-chain metadata (ABI, verified source) for contextualized scoring.",
        "Implement efficient inference (FlashAttention, KV cache, pruning) to increase TPS and reduce per-tx latency."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Reported performance: “an average batched throughput of 2,284±289 transactions per second” and “on average 0.16±0.3 seconds to rank a single transaction.” Training from scratch a large language model on 68M transaction traces; specific hardware details not provided."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Ethereum archive node; can run on sequencer/validator or ordinary node depending on visibility (P2P vs. private propagation).",
      "scalability_discussed": true,
      "inference_time": "0.16±0.3 seconds per transaction (average); batched throughput 2,284±289 tx/s",
      "deployment_challenges": [
        "Hidden adversaries using private relay (FaaS) limit pre-confirmation detection; system acts retrospectively.",
        "Managing false positives and threshold calibration across varying protocol volumes.",
        "Need for robust node connectivity and timely access to traces (archive node).",
        "Operational integration with mitigation controls (e.g., emergency pause) and governance policies.",
        "Concept drift as DeFi behaviors evolve; requirement for periodic retraining or continual learning."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First application of unsupervised/self-supervised learning for anomaly detection in smart contract transaction execution traces.",
      "A large language model trained from scratch for Ethereum transaction anomaly detection with custom EVM-compatible data encoding, domain-specific tokenization, and a tree encoding tailored to EVM trace representation.",
      "Demonstrated effectiveness on a dataset of 68M transactions from 124 attacked contracts over 1,523 days; evaluated with percentage and absolute ranking alarm thresholds, F1, F10, and CID scores.",
      "Benchmarking against doc2vec and trace length heuristics, showing superior effectiveness of BlockGPT.",
      "Real-time capability: “a batched throughput of 2,284±289 transactions per second,” and “0.16±0.3 seconds to rank a single transaction.”",
      "Detection outcome: “ranking 49 out of 124 attacks among the top-3 most abnormal transactions interacting with their victim contracts.”",
      "Case studies demonstrating detection of different malicious activities (e.g., flash loan attack) and discussion of observable vs. hidden adversaries for deployment."
    ]
  },
  {
    "arxiv_id": "2304.11084v1",
    "title": "Training Automated Defense Strategies Using Graph-based Cyber Attack Simulations",
    "authors": "Jakob Nyberg; Pontus Johnson",
    "abstract": "We implemented and evaluated an automated cyber defense agent. The agent takes security alerts as input and uses reinforcement learning to learn a policy for executing predefined defensive measures. The defender policies were trained in an environment intended to simulate a cyber attack. In the simulation, an attacking agent attempts to capture targets in the environment, while the defender attempts to protect them by enabling defenses. The environment was modeled using attack graphs based on the Meta Attack Language language. We assumed that defensive measures have downtime costs, meaning that the defender agent was penalized for using them. We also assumed that the environment was equipped with an imperfect intrusion detection system that occasionally produces erroneous alerts based on the environment state. To evaluate the setup, we trained the defensive agent with different volumes of intrusion detection system noise. We also trained agents with different attacker strategies and graph sizes. In experiments, the defensive agent using policies trained with reinforcement learning outperformed agents using heuristic policies. Experiments also demonstrated that the policies could generalize across different attacker strategies. However, the performance of the learned policies decreased as the attack graphs increased in size.",
    "published_date": "2023-04-17",
    "pdf_link": "https://arxiv.org/pdf/2304.11084v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cyber Defense",
      "subdomain": "Automated Intrusion Response",
      "specific_problem": "Learning a defender policy to enable defensive measures based on IDS alerts over attack-graph-modeled environments with operational downtime costs",
      "attack_types": [
        "multi-step attack graph traversal",
        "generic cyber intrusion steps (AND/OR preconditions)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning (Policy Gradient)",
        "specific": "Proximal Policy Optimization (PPO)",
        "novel_contribution": "Application of PPO to learn automated defense policies operating on attack graphs with noisy IDS observations and downtime costs"
      },
      {
        "type": "primary",
        "category": "Feedforward Neural Network (MLP)",
        "specific": "Fully-connected network with tanh activations (2 hidden layers, 128 units each)",
        "novel_contribution": "Policy network mapping concatenated attack/defense step states to defense actions (+ do-nothing) under cost-sensitive reward"
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning"
    ],
    "datasets": [
      {
        "name": "Handcrafted attack graph for IDS FPR/FNR sweep (Figure 1a)",
        "type": "synthetic",
        "domain": "attack_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Handcrafted attack graph for attacker policy comparison (Figure 1b)",
        "type": "synthetic",
        "domain": "attack_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Semi-random attack graphs of sizes 20, 40, 60, 80 steps (graph size study)",
        "type": "synthetic",
        "domain": "attack_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random defender policy",
        "paper_reference": null,
        "metric": "average percentage of flags captured; average reward",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Tripwire (rule-based conditional) defender policy",
        "paper_reference": null,
        "metric": "average percentage of flags captured; average reward",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "average percentage of flags captured by attacker",
      "average (cumulative) defender reward"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How well can a defender agent operate with imperfect IDS information (varying false positive/false negative rates)?",
        "Do RL-trained defender policies generalize across different attacker strategies?",
        "How does increasing attack graph size affect learned defender policy performance?"
      ],
      "gaps_identified": [
        "Need for scalable training methods as attack graphs grow large",
        "Limited understanding of robustness to IDS observation noise in automated defense policies",
        "Sim-to-real transfer not addressed; reliance on simulation for policy learning",
        "Attacker behaviors modeled as heuristics; lack of learning/adaptive attacker in training"
      ],
      "limitations": [
        "Performance of learned policies decreases as attack graphs increase in size",
        "Evaluation limited to simulated, manually crafted/semi-random attack graphs",
        "Assumes availability of an IDS capable of tracking attack step states (detection problem eschewed)",
        "Attacker modeled via heuristic policies only (no adaptive/learning adversary)",
        "No real-world deployment or transfer evaluation"
      ],
      "future_work": [
        "Use reinforcement learning for the attacker agent (self-play/adversarial training)",
        "Pursue sim-to-real transfer of the learned defense policies to real systems"
      ],
      "motivation": "Automate parts of cyber defense decision-making to complement human operators by learning policies to enable defenses in response to alerts, while accounting for operational downtime costs, trained efficiently via simulation on attack graphs.",
      "potential_research_ideas": [
        "Adversarial self-play: co-train learning attacker and defender agents to improve robustness and generalization",
        "Formulate as a POMDP and use belief-state or recurrent policies to better handle noisy/partial IDS observations",
        "Domain randomization over graph structures, costs, and IDS noise to improve sim-to-real transfer",
        "Curriculum learning that gradually increases graph size/complexity to mitigate performance degradation",
        "Risk-aware or constrained RL optimizing defense effectiveness under explicit downtime/SLA constraints",
        "Meta-learning or few-shot adaptation to new environments/graphs",
        "Offline/pretraining from historical SOC logs combined with online fine-tuning in simulation",
        "Exploration of explainable RL or causal policy representations for operator trust",
        "Evaluate and optimize policies using real-world attack datasets or red-team exercises mapped to attack graphs"
      ],
      "architectural_improvement_recommendations": [
        "Replace MLP policy with a Graph Neural Network (e.g., GCN/GAT) operating on attack-graph structure with action masking",
        "Add recurrence (LSTM/GRU) or transformer-based memory to handle partial observability and temporal alert patterns",
        "Use hierarchical/option-based RL to decompose defense decisions (e.g., flag-level or subgraph-level options)",
        "Ensemble PPO agents or mixture-of-experts to improve robustness across attacker strategies and graph distributions",
        "Robust RL techniques (e.g., adversarial training, distributional RL) to handle IDS noise and attacker variability",
        "Constrained RL (Lagrangian methods) to explicitly manage downtime cost budgets",
        "Centralized critic with multi-agent RL if modeling attacker/defender jointly",
        "Hyperparameter tuning and action masking to stabilize PPO on large discrete action spaces"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Ray RLlib",
        "Python"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Google Cloud VM with NVIDIA V100 GPU, 12 CPU cores, 30 GB RAM; PPO training for 500 iterations; ~20 minutes per policy to train and evaluate; 500 evaluation episodes per policy"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Sim-to-real transfer gap from attack-graph simulation to operational networks",
        "Dependence on accurate, up-to-date attack graphs of the environment",
        "Handling high IDS false positive/false negative rates in operation",
        "Policy performance degrades as graph size increases",
        "Operational downtime cost modeling and alignment with business constraints",
        "Compute/training time requirements for policy updates"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Implements an automated cyber defense agent that learns to enable predefined defensive measures from IDS alerts via reinforcement learning",
      "Introduces an attack-graph-based simulation environment inspired by Meta Attack Language to train defender policies with downtime costs and IDS noise",
      "Empirically compares RL-based defender against heuristic baselines across varying IDS false positive/negative rates",
      "Demonstrates partial generalization of learned defender policies across different attacker strategies",
      "Analyzes impact of attack graph size on learned policy performance, observing degradation with larger graphs"
    ]
  },
  {
    "arxiv_id": "2304.10726v2",
    "title": "Smart Learning to Find Dumb Contracts (Extended Version)",
    "authors": "Tamer Abdelaziz; Aquinas Hobor",
    "abstract": "We introduce the Deep Learning Vulnerability Analyzer (DLVA) for Ethereum smart contracts based on neural networks. We train DLVA to judge bytecode even though the supervising oracle can only judge source. DLVA's training algorithm is general: we extend a source code analysis to bytecode without any manual feature engineering, predefined patterns, or expert rules. DLVA's training algorithm is also robust: it overcame a 1.25% error rate mislabeled contracts, and--the student surpassing the teacher--found vulnerable contracts that Slither mislabeled. DLVA is much faster than other smart contract vulnerability detectors: DLVA checks contracts for 29 vulnerabilities in 0.2 seconds, a 10-1,000x speedup. DLVA has three key components. First, Smart Contract to Vector (SC2V) uses neural networks to map smart contract bytecode to a high-dimensional floating-point vector. We benchmark SC2V against 4 state-of-the-art graph neural networks and show that it improves model differentiation by 2.2%. Second, Sibling Detector (SD) classifies contracts when a target contract's vector is Euclidian-close to a labeled contract's vector in a training set; although only able to judge 55.7% of the contracts in our test set, it has a Slither-predictive accuracy of 97.4% with a false positive rate of only 0.1%. Third, Core Classifier (CC) uses neural networks to infer vulnerable contracts regardless of vector distance. We benchmark DLVA's CC with 10 ML techniques and show that the CC improves accuracy by 11.3%. Overall, DLVA predicts Slither's labels with an overall accuracy of 92.7% and associated false positive rate of 7.2%. Lastly, we benchmark DLVA against nine well-known smart contract analysis tools. Despite using much less analysis time, DLVA completed every query, leading the pack with an average accuracy of 99.7%, pleasingly balancing high true positive rates with low false positive rates.",
    "published_date": "2023-04-21",
    "pdf_link": "https://arxiv.org/pdf/2304.10726v2",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Security",
      "specific_problem": "Vulnerability detection on Ethereum smart contracts from bytecode using deep learning",
      "attack_types": [
        "shadowing-state (SWC-119)",
        "suicidal (SWC-106)",
        "uninitialized-state (SWC-109)",
        "arbitrary-send",
        "controlled-array-length",
        "controlled-delegatecall (SWC-112)",
        "reentrancy-eth (SWC-107)",
        "unchecked-transfer",
        "erc20-interface",
        "incorrect-equality (SWC-132)",
        "locked-ether",
        "mapping-deletion",
        "shadowing-abstract",
        "tautology",
        "write-after-write",
        "constant-function-asm",
        "constant-function-state",
        "divide-before-multiply",
        "reentrancy-no-eth (SWC-107)",
        "tx-origin",
        "unchecked-lowlevel",
        "unchecked-send",
        "uninitialized-local (SWC-109)",
        "unused-return (SWC-104)",
        "incorrect-modifier",
        "shadowing-builtin",
        "shadowing-local",
        "variable-scope",
        "void-cst"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Sentence Encoder",
        "specific": "Universal Sentence Encoder (DAN variant)",
        "novel_contribution": "Used unsupervised to embed EVM basic blocks (opcode sentences) into 512-d vectors as N2V without manual features"
      },
      {
        "type": "primary",
        "category": "GNN + CNN",
        "specific": null,
        "novel_contribution": "Smart Contract to Vector (SC2V) summarizes CFGs into contract-level vectors using USE node embeddings and a combination of graph neural and convolutional layers; improves model differentiation"
      },
      {
        "type": "primary",
        "category": "Nearest Neighbor / Distance-based",
        "specific": "Euclidean nearest-neighbor heuristic",
        "novel_contribution": "Sibling Detector (SD) classifies a contract when its SC2V vector is Euclidean-close to a labeled training contract; very low FPR on covered subset"
      },
      {
        "type": "primary",
        "category": "Feedforward Neural Network",
        "specific": null,
        "novel_contribution": "Core Classifier (CC) multi-label classifier over 29 vulnerabilities operating on SC2V vectors; improves accuracy vs 10 ML baselines"
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "Four state-of-the-art GNNs (unspecified)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Classical ML",
        "specific": "Ten off-the-shelf ML techniques (unspecified)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Google BigQuery Ethereum smart contract dataset",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "EthereumSC",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "EthereumSC large",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "EthereumSC small",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Elysium benchmark",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Reentrancy benchmark",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SolidiFI benchmark",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Four SOTA GNNs (average)",
        "paper_reference": null,
        "metric": "Model differentiation",
        "their_result": "“We benchmark SC2V against 4 state-of-the-art graph neural networks and show that it improves model differentiation by an average of 2.2%.”",
        "baseline_result": null
      },
      {
        "method_name": "Best GNN baseline",
        "paper_reference": null,
        "metric": "Model differentiation",
        "their_result": "“1.2% better than the best.”",
        "baseline_result": null
      },
      {
        "method_name": "Sibling Detector (coverage subset)",
        "paper_reference": null,
        "metric": "Accuracy and FPR (to Slither) on 55.7% of test set",
        "their_result": "“it has an average Slither-predictive accuracy of 97.4% with a false positive rate of only 0.1%.”",
        "baseline_result": null
      },
      {
        "method_name": "Ten off-the-shelf ML techniques (average)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "“the CC improves average accuracy by 11.3%.”",
        "baseline_result": null
      },
      {
        "method_name": "Best ML baseline",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "“beats the best by 8.4%.”",
        "baseline_result": null
      },
      {
        "method_name": "DLVA (overall; small contracts variant also reported)",
        "paper_reference": null,
        "metric": "Accuracy and FPR (to Slither)",
        "their_result": "“DLVA predicts Slither’s labels with an overall accuracy of 92.7% and associated false positive rate of 7.2%.”; “On small contracts, DLVA has an average accuracy (to Slither) of 97.6% with a FPR of 2.3%.”",
        "baseline_result": null
      },
      {
        "method_name": "Nine well-known smart contract analysis tools (aggregate)",
        "paper_reference": null,
        "metric": "Accuracy, TPR, FPR, Completion rate, Analysis time",
        "their_result": "“leading the pack with an average accuracy of 99.7%, ... True Positive Rate ... 98.7% ... False Positive Rate ... 0.6% ... average Completion Rate ... 100.0% ... average analysis time per contract ... 0.2 seconds.”",
        "baseline_result": null
      },
      {
        "method_name": "Slither",
        "paper_reference": "Slither [25]",
        "metric": "TPR vs DLVA",
        "their_result": "“DLVA beats Slither on every statistic except for TPR (where it lags by 0.7%).”",
        "baseline_result": "Slither’s TPR higher by 0.7% than DLVA"
      },
      {
        "method_name": "SoliAudit",
        "paper_reference": null,
        "metric": "Benchmark inclusion (end-to-end tools)",
        "their_result": "DLVA completed every query and led in average accuracy; uses much less analysis time.",
        "baseline_result": null
      },
      {
        "method_name": "ConFuzzius",
        "paper_reference": null,
        "metric": "Benchmark inclusion (end-to-end tools)",
        "their_result": "DLVA completed every query and led in average accuracy; uses much less analysis time.",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "true positive rate (TPR)",
      "false positive rate (FPR)",
      "completion rate",
      "analysis time per contract",
      "coverage (percentage of contracts SD can judge)",
      "model differentiation"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a deep learning system trained on source-level labels (Slither) be made to accurately judge vulnerabilities directly from bytecode?",
        "Can learned vector embeddings of smart contract CFGs (SC2V) enable fast and accurate vulnerability detection without manual rules?",
        "Can a distance-based Sibling Detector reliably classify a large subset of contracts with very low false positives?",
        "Can a neural Core Classifier outperform off-the-shelf ML methods on the harder cases?",
        "Can such a system significantly outperform existing static analyzers in accuracy, completion rate, and speed?"
      ],
      "gaps_identified": [
        "Most previous vulnerability analyzers require or benefit from source code, but ~2/3 of Ethereum contracts lack source availability.",
        "Traditional formal methods-based tools are slow for large contracts, hindering scalability.",
        "Label noise and mislabels exist in static-analysis-derived training data (e.g., Slither), complicating supervised learning.",
        "Imbalanced datasets where vulnerable contracts are scarce make accuracy alone misleading."
      ],
      "limitations": [
        "Sibling Detector can only judge 55.7% of the test contracts (limited coverage).",
        "Core Classifier on the harder 44.3% subset attains 80.0% accuracy with a relatively high FPR of 21.4%.",
        "Relies on Slither for supervision and thus limited to the 29 vulnerabilities Slither reports and to the subset of contracts with available source for labeling.",
        "EtherSolve failed to create CFGs for 0.1% of labeled contracts.",
        "Used the DAN variant of USE instead of Transformer due to computational resource constraints."
      ],
      "future_work": [],
      "motivation": "Enable fast, accurate, source-agnostic detection of smart contract vulnerabilities at scale by learning directly from bytecode, overcoming source unavailability and the performance limitations of existing tools.",
      "potential_research_ideas": [
        "Train a Transformer-based sentence encoder (USE-Transformer or domain-specific transformer) tailored to EVM opcode sequences for improved node embeddings.",
        "Contrastive or metric learning to explicitly optimize the SC2V vector space for nearest-neighbor classification and robustness.",
        "Active learning or noise-robust training to mitigate label noise from static analyzers (e.g., Slither) and reduce FPR in the hard subset.",
        "Joint multi-task learning that predicts multiple vulnerability types with shared representations and uncertainty estimation.",
        "Cross-chain generalization: adapt DLVA to other EVM-compatible chains and to non-EVM smart contract platforms.",
        "Integrate lightweight dynamic traces or symbolic features with SC2V embeddings for hybrid analysis.",
        "Explainability overlays (e.g., attention over basic blocks/CFG subgraphs) to localize suspected vulnerable regions.",
        "Adversarial robustness studies against bytecode-level obfuscations or semantics-preserving transformations."
      ],
      "architectural_improvement_recommendations": [
        "Replace DAN with a Transformer encoder or train a domain-specific opcode transformer to improve N2V quality.",
        "Add graph attention or hierarchical pooling to SC2V to better capture long-range control-flow dependencies.",
        "Introduce metric learning (e.g., triplet loss) to optimize SC2V embeddings for Euclidean distance, strengthening SD coverage and reliability.",
        "Calibrate CC outputs with temperature scaling or focal loss to handle class imbalance and reduce FPR on the hard subset.",
        "Use approximate nearest neighbor indexing (e.g., FAISS) for scalable SD over very large training corpora.",
        "Employ label-noise robust losses or semi-supervised self-training with high-confidence pseudo-labels on unlabeled bytecode."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://bit.ly/DLVA-Tool",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Slither labeling 13.6 days on 1 core/16GB; model load 1–2 minutes (~2s per model); inference ~0.2s per contract; Transformer-based USE not used due to resource limits."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Offline analysis of Ethereum smart contract bytecode",
      "scalability_discussed": true,
      "inference_time": "≈0.2 seconds per contract",
      "deployment_challenges": [
        "Requires labeled datasets for training; only 32.6% of contracts had source available for Slither labeling.",
        "Imbalanced datasets make evaluation tricky; need to consider TPR and FPR, not just accuracy.",
        "Label noise and mislabels from the supervising analyzer (estimated mislabels and FP in certain vulnerabilities).",
        "CFG extraction failures for a small fraction of contracts (0.1%).",
        "Initial model load time (1–2 minutes) before fast per-contract inference."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces DLVA, a bytecode-based deep learning vulnerability analyzer for Ethereum smart contracts.",
      "Smart Contract to Vector (SC2V) that maps CFGs to high-dimensional vectors using neural networks; “2.2% better than the average competitor and 1.2% better than the best.”",
      "Sibling Detector (SD) using Euclidean proximity in embedding space; “97.4% accuracy” and “0.1% FPR” on “55.7%” of test contracts.",
      "Core Classifier (CC) neural model; “improves average accuracy by 11.3%” vs 10 ML baselines and “8.4%” vs the best baseline.",
      "Combined system achieves “overall accuracy of 92.7% and associated false positive rate of 7.2%” (to Slither’s labels).",
      "Small-contract variant achieving “97.6%” accuracy and “2.3%” FPR (to Slither).",
      "Benchmarks against nine well-known tools across Elysium, Reentrancy, and SolidiFI benchmarks; “average accuracy of 99.7%,” “TPR 98.7%,” “FPR 0.6%,” “Completion Rate 100%,” and ~0.2s analysis time.",
      "Demonstrates training a bytecode analyzer from a source-only oracle (Slither), effectively extending source analysis to bytecode without manual features.",
      "Public release of DLVA tool and datasets (EthereumSC small/large) with instructions for batch and single-contract analysis."
    ]
  },
  {
    "arxiv_id": "2304.06727v2",
    "title": "Contingency Analyses with Warm Starter using Probabilistic Graphical Model",
    "authors": "Shimiao Li; Amritanshu Pandey; Larry Pileggi",
    "abstract": "Cyberthreats are an increasingly common risk to the power grid and can thwart secure grid operations. We propose to extend contingency analysis to include cyberthreat evaluations. However, unlike the traditional N-1 or N-2 contingencies, cyberthreats (e.g., MadIoT) require simulating hard-to-solve N-k (with k >> 2) contingencies in a practical amount of time. Purely physics-based power flow solvers, while being accurate, are slow and may not solve N-k contingencies in a timely manner, whereas the emerging data-driven alternatives are fast but not sufficiently generalizable, interpretable, and scalable. To address these challenges, we propose a novel conditional Gaussian Random Field-based data-driven method that performs fast and accurate evaluation of cyberthreats. It achieves speedup of contingency analysis by warm-starting simulations, i.e., improving starting points, for the physical solvers. To improve the physical interpretability and generalizability, the proposed method incorporates domain knowledge by considering the graphical nature of the grid topology. To improve scalability, the method applies physics-informed regularization that reduces model complexity. Experiments validate that simulating MadIoT-induced attacks with our warm starter becomes approximately 5x faster on a realistic 2000-bus system.",
    "published_date": "2023-04-10",
    "pdf_link": "https://arxiv.org/pdf/2304.06727v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cyber-Physical Systems Security",
      "subdomain": "Power Grid Security",
      "specific_problem": "Fast N-k contingency analysis for cyber-induced load manipulation (MadIoT) by warm-starting physical power flow solvers",
      "attack_types": [
        "MadIoT/BlackIoT",
        "IoT-based load manipulation",
        "N-k multi-point contingency",
        "Data/command integrity manipulation of distributed loads"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Probabilistic Graphical Model",
        "specific": "Conditional Gaussian Random Field (pairwise Markov Random Field)",
        "novel_contribution": "Conditional GRF whose node/edge Gaussian potentials are parameterized by neural networks; physics-informed regularization and parameter sharing; used as a warm starter for physical power flow solvers"
      },
      {
        "type": "primary",
        "category": "Neural Network",
        "specific": null,
        "novel_contribution": "Local neural networks map from contingency and grid features to parameters of Gaussian potentials in the GRF"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Simulated MadIoT contingencies on a realistic 2000-bus system",
        "type": "synthetic",
        "domain": "power_grid_simulation",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Traditional initialization methods for contingency simulation (no learned warm start)",
        "paper_reference": null,
        "metric": "Speedup of contingency analysis / convergence time",
        "their_result": "“approximately 5x faster on a realistic 2000-bus system”",
        "baseline_result": "1x (reference runtime without warm start)"
      }
    ],
    "performance_metrics_used": [
      "Speedup factor (convergence time)",
      "Convergence iterations (implied)",
      "Post-contingency voltage prediction accuracy (implied)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can contingency analysis be extended to efficiently evaluate cyberthreat-driven N-k events (k >> 1) within real-time CA windows?",
        "Can a data-driven warm starter accelerate physical power flow solvers while remaining generalizable to topology changes and physically interpretable?",
        "How to leverage grid topology and physics-informed regularization to improve scalability without sacrificing accuracy?"
      ],
      "gaps_identified": [
        "Purely physics-based solvers are slow for large sets of hard N-k contingencies within 5–30 minute CA windows.",
        "Emerging data-driven alternatives lack sufficient generalizability, interpretability, and scalability for grid operations.",
        "Many physics-informed ML approaches struggle with topology changes, physical interpretability, and handling nonlinear constraints at scale."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Cyberthreats such as MadIoT can induce widespread N-k contingencies that current EMS CA cannot solve fast enough; need a fast, accurate, generalizable, and interpretable warm starter to accelerate physical simulations.",
      "potential_research_ideas": [
        "Extend the warm starter to transient stability and dynamic simulations for time-domain cyber events.",
        "Incorporate uncertainty quantification (e.g., Bayesian GRF) to provide calibrated confidence on warm starts under out-of-distribution contingencies.",
        "Develop online/continual learning to adapt the GRF parameters to evolving grids and IoT penetration levels without full retraining.",
        "Integrate an OOD detector for contingency patterns to selectively fall back to robust but slower solvers.",
        "Generalize to other cyberattack types (e.g., coordinated DER manipulation, breaker toggling) and mixed cyber–physical incident sets."
      ],
      "architectural_improvement_recommendations": [
        "Combine the conditional GRF with graph message passing to better capture longer-range dependencies while retaining probabilistic structure.",
        "Introduce a global context node or low-rank global factors in the GRF to handle system-wide coupling (useful for OPF-like tasks).",
        "Adopt Bayesian/neural density estimators to output uncertainty over potential parameters, enabling risk-aware warm starts.",
        "Use meta-learning or few-shot adaptation to rapidly specialize the warm starter to new topologies or operating points.",
        "Multi-task training to jointly predict voltages and currents/line flows, improving physical consistency of warm starts."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/ohCindy/GridWarm.git",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Energy Management System (EMS) Contingency Analysis module in control centers",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Meeting real-time CA windows (5–30 minutes) for large N-k contingency sets",
        "Integration with existing power flow solvers and EMS pipelines"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a conditional Gaussian Random Field-based data-driven warm starter for contingency analysis under cyberthreats.",
      "Warm-starts physical power flow solvers to accelerate convergence for hard N-k contingencies.",
      "Incorporates grid topology via a graphical model for improved generalizability.",
      "Introduces physics-informed regularization (e.g., parameter sharing) to improve scalability and trainability.",
      "Demonstrates approximately 5x speedup on a realistic 2000-bus system for MadIoT-induced attacks.",
      "Releases code for reproducibility."
    ]
  },
  {
    "arxiv_id": "2305.08993v2",
    "title": "Survey of Malware Analysis through Control Flow Graph using Machine Learning",
    "authors": "Shaswata Mitra; Stephen A. Torri; Sudip Mittal",
    "abstract": "Malware is a significant threat to the security of computer systems and networks which requires sophisticated techniques to analyze the behavior and functionality for detection. Traditional signature-based malware detection methods have become ineffective in detecting new and unknown malware due to their rapid evolution. One of the most promising techniques that can overcome the limitations of signature-based detection is to use control flow graphs (CFGs). CFGs leverage the structural information of a program to represent the possible paths of execution as a graph, where nodes represent instructions and edges represent control flow dependencies. Machine learning (ML) algorithms are being used to extract these features from CFGs and classify them as malicious or benign. In this survey, we aim to review some state-of-the-art methods for malware detection through CFGs using ML, focusing on the different ways of extracting, representing, and classifying. Specifically, we present a comprehensive overview of different types of CFG features that have been used as well as different ML algorithms that have been applied to CFG-based malware detection. We provide an in-depth analysis of the challenges and limitations of these approaches, as well as suggest potential solutions to address some open problems and promising future directions for research in this field.",
    "published_date": "2023-05-15",
    "pdf_link": "https://arxiv.org/pdf/2305.08993v2",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection and Classification",
      "specific_problem": "Survey of control flow graph (CFG)-based malware detection using machine learning, including feature extraction, representation, and classification across platforms",
      "attack_types": [
        "polymorphic/metamorphic malware",
        "dynamically executed content (DEC)",
        "packed malware",
        "adversarial examples (AEs)",
        "code obfuscation (e.g., XOR, semantic NOPs, junk code)",
        "Android malware",
        "IoT/industrial malware",
        "Windows malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "CNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "DGCNN (Deep Graph Convolutional Neural Network)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble",
        "specific": null,
        "novel_contribution": "Combining API usage, frequency, and sequence models for Android detection (as surveyed)"
      },
      {
        "type": "baseline",
        "category": "Autoencoder",
        "specific": null,
        "novel_contribution": "Used for adversarial example detection in CFG-based pipelines (as surveyed)"
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GIN-JK (Graph Isomorphism Network with Jumping Knowledge)",
        "novel_contribution": "Used with attributed CFGs for malware classification (as surveyed)"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT (MLM + Next Block Prediction) for instruction embedding",
        "novel_contribution": "Pretraining to create node embeddings for ACFG prior to GNN (as surveyed)"
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "KNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "ANN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "AdaBoost",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "XGBoost",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Extraction",
        "specific": "Random walk + n-gram on CFG",
        "novel_contribution": "Used to capture behavior sequences prior to AE detection or classification (as surveyed)"
      },
      {
        "type": "baseline",
        "category": "Dimensionality Reduction",
        "specific": "PCA",
        "novel_contribution": "Used for feature validation and dimensionality reduction (as surveyed)"
      },
      {
        "type": "baseline",
        "category": "Graph Signature/Kernel",
        "specific": "NetLSD (Laplacian heat/wave kernel signatures)",
        "novel_contribution": "Compact CFG spectral signatures for classical ML models (as surveyed)"
      },
      {
        "type": "baseline",
        "category": "Explainability",
        "specific": "GNNExplainer, SubgraphX, PGExplainer",
        "novel_contribution": "Compared against a DL approach that identifies most contributing CFG subgraphs (as surveyed)"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Self-supervised (pretraining)",
      "Deep Learning"
    ],
    "datasets": [
      {
        "name": "Android Malware Genome Project",
        "type": "public",
        "domain": "android_apks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Marvin",
        "type": "public",
        "domain": "android_apks",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Drebin",
        "type": "public",
        "domain": "android_apks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusShare",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ContagioDump",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "AndroZoo",
        "type": "public",
        "domain": "android_apks",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "Android Malware Dataset [12,13]",
        "type": "public",
        "domain": "android_apks",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "VXHeaven",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MALICIA",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MSKCFG",
        "type": "public",
        "domain": "control_flow_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "YANCFG",
        "type": "public",
        "domain": "control_flow_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Microsoft Malware Classification Challenge (BIG2015)",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CyberIOCs",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "F1-score",
      "Detection rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Q1: How can control flow graphs (CFG) be used to identify malware derivatives?",
        "Q2: What are the existing machine learning (ML) approaches to analyze malware using CFG?",
        "Q3: What are the drawbacks of existing ML approaches in processing CFG to classify malware?"
      ],
      "gaps_identified": [
        "Signature-based detection is ineffective for new/unknown malware; need CFG-based and ML-based methods.",
        "Vulnerability of CFG-based string/grammar features to junk code and obfuscation.",
        "Insufficient consideration of malware anti-detection techniques (e.g., obfuscation, packing) in many studies; need more experiments targeting these.",
        "Function call graph quality could be improved for better representation.",
        "Some Android CFG-API methods cannot detect malware families; lack of root-cause behavior analysis.",
        "High computational cost of CFG generation and CNN/GNN training; long training times.",
        "Models require validation with latest/real-world malware samples to ensure robustness.",
        "Adversarial example detectors can be bypassed by CFG alterations; susceptibility to incomplete CFGs from obfuscation.",
        "Limited explainability in GNN-based classifiers; need identification of contributing subgraphs.",
        "Survey itself is not a full systematic literature review; scope limited to popular approaches in last 10 years."
      ],
      "limitations": [
        "Not a full-fledged systematic literature review; focuses on popular ML frameworks and recent works.",
        "No new empirical experiments; relies on reported results from prior studies."
      ],
      "future_work": [
        "Develop improved ML approaches robust to code obfuscation and junk code.",
        "Conduct more experiments targeting malware anti-detection (packing, obfuscation, adversarial perturbations).",
        "Improve function/call graph extraction quality and representations.",
        "Evaluate on latest malware samples and diverse datasets for robustness.",
        "Integrate explainability to highlight important CFG subgraphs for analysts.",
        "Explore cloud-deployable, efficient graph learning models for real-time use."
      ],
      "motivation": "Traditional signature-based malware detection fails against rapidly evolving malware; CFG-based representations combined with ML can capture structural/behavioral properties for improved detection. The survey aims to overview techniques, challenges, and future directions for CFG+ML malware analysis.",
      "potential_research_ideas": [
        "Create a standardized, multi-platform CFG benchmark suite with shared extraction pipelines, obfuscation/packing variants, and documented train/test splits.",
        "Design adversarially robust graph-learning pipelines for CFGs using graph augmentations and adversarial training specific to code transformations.",
        "Develop hybrid static-dynamic ACFGs that fuse CFG, DFG, and call graphs with runtime traces to mitigate incomplete CFG due to obfuscation/packing.",
        "Self-supervised pretraining on large corpora of binaries/bytecode to learn transferable instruction and graph embeddings for downstream malware detection.",
        "Lightweight, real-time graph models (e.g., graph transformers with sparse attention, hierarchical pooling) for endpoint/IoT deployment.",
        "Explainable GNNs for malware that output salient subgraphs and semantic rationales aligned with analyst workflows.",
        "Federated or privacy-preserving collaborative training across organizations to continuously update models without sharing raw binaries."
      ],
      "architectural_improvement_recommendations": [
        "Adopt hierarchical graph networks (block→function→program) with pooling to capture multi-scale CFG structure.",
        "Use transformer-based instruction encoders (e.g., code-specific BERT variants) and fuse with GNNs via attributed CFGs.",
        "Incorporate contrastive/self-supervised objectives (graph-graph, view-view) to improve robustness to obfuscation/packing.",
        "Augment CFGs with semantic node/edge attributes (API categories, calling conventions, CFG dominator info) and interprocedural context.",
        "Integrate adversarial training with code-preserving graph perturbations to harden models against AEs.",
        "Implement dynamic-static fusion (lazy binding, sandboxed unpacking) with confidence-aware selection of local CFGs.",
        "Add post-hoc and intrinsic explainability modules (e.g., differentiable subgraph selectors) to identify malicious substructures."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Cloud (some surveyed work suggests cloud-deployable classification)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High computational cost for CFG extraction and CNN/GNN training",
        "Long training times for graph models",
        "Susceptibility to code obfuscation causing incomplete CFGs",
        "Potential bypass of AE detectors via CFG alterations",
        "Packed malware alters runtime CFG; requires sandboxing/unpacking",
        "Need for continuous updates with latest malware samples"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comprehensive overview of CFG-based malware analysis techniques using ML across Android, IoT/industrial, adversarial, and Windows contexts",
      "Categorization of CFG feature types, representations, and ML algorithms used",
      "In-depth analysis of challenges and limitations, including obfuscation, packing, and adversarial robustness",
      "Compilation of datasets and evaluation practices used in the literature",
      "Identification of open problems and promising future research directions",
      "Summarized tables of approaches, contributions, and limitations; defined research questions and inclusion criteria"
    ]
  },
  {
    "arxiv_id": "2304.12115v1",
    "title": "SQLi Detection with ML: A data-source perspective",
    "authors": "Balazs Pejo; Nikolett Kapui",
    "abstract": "Almost 50 years after the invention of SQL, injection attacks are still top-tier vulnerabilities of today's ICT systems. Consequently, SQLi detection is still an active area of research, where the most recent works incorporate machine learning techniques into the proposed solutions. In this work, we highlight the shortcomings of the previous ML-based results focusing on four aspects: the evaluation methods, the optimization of the model parameters, the distribution of utilized datasets, and the feature selection. Since no single work explored all of these aspects satisfactorily, we fill this gap and provide an in-depth and comprehensive empirical analysis. Moreover, we cross-validate the trained models by using data from other distributions. This aspect of ML models (trained for SQLi detection) was never studied. Yet, the sensitivity of the model's performance to this is crucial for any real-life deployment. Finally, we validate our findings on a real-world industrial SQLi dataset.",
    "published_date": "2023-04-24",
    "pdf_link": "https://arxiv.org/pdf/2304.12115v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Web Application Security",
      "subdomain": "Injection Attack Detection",
      "specific_problem": "Machine-learning-based SQL Injection (SQLi) payload detection and cross-distribution evaluation",
      "attack_types": [
        "SQL Injection",
        "In-band SQLi (error-based, union-based)",
        "Out-of-band SQLi",
        "Blind SQLi (content-based, time-based)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Preprocessing",
        "specific": "TF-IDF Vectorizer (Bag-of-Words)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Preprocessing",
        "specific": "Skip-gram embeddings (Word2Vec)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Preprocessing",
        "specific": "Keyword weighting",
        "novel_contribution": "Authors tune keyword weights; conclude it is ~10% inferior to TF-IDF and Skip-gram in their experiments"
      },
      {
        "type": "primary",
        "category": "Linear Model",
        "specific": "Logistic Regression",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "SVM",
        "specific": "Support Vector Machine (linear/poly/RBF kernels)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": "Gradient Boosting (scikit-learn)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Neural Network",
        "specific": "Feedforward MLP",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "United",
        "type": "public",
        "domain": "sql_payloads",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "OWASP (component of United)",
        "type": "public",
        "domain": "sql_payloads",
        "link": "https://www.github.com/ChrisAHolland/ML-SQL-Injection-Detector/tree/master/data",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "BurpSuite (component of United)",
        "type": "public",
        "domain": "sql_payloads",
        "link": "https://www.github.com/ChrisAHolland/ML-SQL-Injection-Detector/tree/master/data",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "FuzzDB (component of United)",
        "type": "public",
        "domain": "sql_payloads",
        "link": "https://www.github.com/ChrisAHolland/ML-SQL-Injection-Detector/tree/master/data",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SQLi1",
        "type": "public",
        "domain": "sql_payloads",
        "link": "https://www.kaggle.com/datasets/syedsaqlainhussain/sql-injection-dataset",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SQLi2",
        "type": "public",
        "domain": "sql_payloads",
        "link": "https://www.kaggle.com/datasets/syedsaqlainhussain/sql-injection-dataset",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Company (industrial SIEM SQLi dataset)",
        "type": "private",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "Confusion matrix",
      "ROC curve",
      "AUC",
      "False Positive Rate (FPR)",
      "True Positive Rate (TPR)",
      "False Negative Rate (FNR)",
      "Training time",
      "Model size",
      "Prediction speed (inference latency)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How do evaluation methods, hyper-parameter optimization, dataset distribution, and feature selection impact ML-based SQLi detection performance?",
        "How do models trained on one data distribution generalize to other distributions in SQLi detection?",
        "Which models and preprocessing choices provide better trade-offs at low false positive rates (as seen in ROC curves) for SOC/SIEM use cases?",
        "What are the computational and latency characteristics (training time, model size, prediction speed) of commonly used ML models for SQLi detection?"
      ],
      "gaps_identified": [
        "Many prior works use small datasets or a single data source, limiting generalization.",
        "Lack of cross-distribution (non-IID) validation of trained models for SQLi detection.",
        "Insufficient feature richness in several studies; not following best practices from NLP.",
        "Limited or no hyper-parameter optimization; cherry-picking single models.",
        "Over-reliance on accuracy without reporting ROC/operating-point trade-offs (precision/recall, FPR/FNR)."
      ],
      "limitations": [
        "Public datasets come from only two sources; the private dataset is from a single client/time window.",
        "The study evaluates five model families and three preprocessing methods; other modern architectures (e.g., transformers) are not included.",
        "Small size and extreme class imbalance in the United dataset; authors note ROC/AUC is impacted (only a single negative sample in its test set).",
        "Experiments are two-fold only; limited repeats.",
        "Code planned to be shared only after acceptance, reducing immediate reproducibility."
      ],
      "future_work": [],
      "motivation": "Provide an in-depth empirical analysis of ML-based SQLi detection covering evaluation metrics, hyper-parameter optimization, dataset distribution diversity, and feature selection; and, for the first time in SQLi ML literature, cross-validate trained models on distinct data distributions to assess real-life deployment sensitivity, also validating on a real-world industrial dataset.",
      "potential_research_ideas": [
        "Domain adaptation and transfer learning methods (e.g., CORAL, adversarial domain-invariant training) to improve cross-distribution SQLi detection.",
        "Self-supervised or contrastive pretraining on large unlabeled SQL/log corpora to improve feature learning with limited labeled SQLi data.",
        "Data augmentation for SQL payloads using grammar-based mutation or LLM-guided generation to address class imbalance and improve robustness.",
        "Open-set and out-of-distribution detection to flag novel SQLi variants unseen during training.",
        "Cost-sensitive and calibrated detection tailored to SOC workflows to guarantee low FPR at target operating points.",
        "Federated learning for multi-organization training without data sharing, with privacy auditing."
      ],
      "architectural_improvement_recommendations": [
        "Adopt character-level CNNs or transformer encoders over tokenized/character sequences of SQL payloads for richer representations than TF-IDF/Skip-gram.",
        "Use domain-adversarial neural networks to learn distribution-invariant features across multiple sources.",
        "Apply focal loss or class-balanced loss to handle class imbalance (e.g., in highly skewed datasets like United).",
        "Ensemble heterogeneous models (RF/GB/NN) with calibrated probability outputs and threshold optimization at deployment-time ROC operating points.",
        "Calibrate outputs (Platt scaling/Isotonic regression) to provide well-calibrated risk scores for SIEM integration.",
        "Automate hyper-parameter optimization (e.g., Bayesian optimization) and include early stopping and cross-validation for stability."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "scikit-learn"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Experiments on Ubuntu 20.04.4 LTS with 16 CPUs (3.10 GHz) and 98 GB RAM. Example training times: SVM up to ~44 s; Gradient Boosting up to ~590 s; Random Forest a few seconds. Per-sample prediction latency ranges ~0.002–3.077 ms. Model sizes range from ~0.002 MB to ~72 MB depending on model and dataset."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "SIEM within an international SOC operator (enterprise environment)",
      "scalability_discussed": true,
      "inference_time": "Reported per-sample prediction speed ~0.002–3.077 ms depending on model and dataset",
      "deployment_challenges": [
        "Sensitivity to distribution shift between training and deployment data sources.",
        "Requirement to select and operate at specific ROC operating points (low FPR) for SOC usability.",
        "Class imbalance in real data leading to potential performance degradation.",
        "Feature extraction choice (TF-IDF vs embeddings) impacts latency, model size, and generalization.",
        "Obtaining diverse labeled datasets across organizations."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comprehensive empirical analysis of ML-based SQLi detection focusing on evaluation metrics, hyper-parameter optimization, dataset distribution, and feature selection.",
      "First cross-distribution validation of SQLi ML models, training on one source and testing on others to assess robustness.",
      "Validation on a real-world industrial SIEM SQLi dataset.",
      "Systematic comparison of preprocessing (TF-IDF, Skip-gram, Keyword weights) and models (LR, SVM, RF, GB, NN) with grid-search hyper-parameter tuning.",
      "ROC/AUC analysis demonstrating that the highest accuracy model may be suboptimal at low FPR or under distribution shift.",
      "Timing measurements: training time, model size, and inference speed for best-performing settings.",
      "Empirical finding that keyword-weight-based preprocessing underperforms TF-IDF and Skip-gram by about 10%."
    ]
  },
  {
    "arxiv_id": "2305.05952v1",
    "title": "Unraveling the MEV Enigma: ABI-Free Detection Model using Graph Neural Networks",
    "authors": "Seongwan Park; Woojin Jeong; Yunyoung Lee; Bumho Son; Huisu Jang; Jaewook Lee",
    "abstract": "The detection of Maximal Extractable Value (MEV) in blockchain is crucial for enhancing blockchain security, as it enables the evaluation of potential consensus layer risks, the effectiveness of anti-centralization solutions, and the assessment of user exploitation. However, existing MEV detection methods face limitations due to their low recall rate, reliance on pre-registered Application Binary Interfaces (ABIs) and the need for continuous monitoring of new DeFi services.   In this paper, we propose ArbiNet, a novel GNN-based detection model that offers a low-overhead and accurate solution for MEV detection without requiring knowledge of smart contract code or ABIs. We collected an extensive MEV dataset, surpassing currently available public datasets, to train ArbiNet. Our implemented model and open dataset enhance the understanding of the MEV landscape, serving as a foundation for MEV quantification and improved blockchain security.",
    "published_date": "2023-05-10",
    "pdf_link": "https://arxiv.org/pdf/2305.05952v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "DeFi/MEV Detection",
      "specific_problem": "ABI-free detection of MEV transactions (arbitrage and sandwich) from Ethereum token transfer graphs using GNNs",
      "attack_types": [
        "Arbitrage",
        "Sandwich attack"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "ArbiNet",
        "novel_contribution": "ABI-free arbitrage detection model operating on ERC-20 token transfer graphs; avoids smart contract/event decoding and ABIs"
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GCN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GraphSAGE",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GAT",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Authors' MEV dataset (ArbiNet training/evaluation set)",
        "type": "public",
        "domain": "blockchain_transaction_graph",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Heuristic MEV detection using swap-event loops across DEXs",
        "paper_reference": "[34] (first heuristic-based MEV quantification; loops on swap events)",
        "metric": "F1",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Graph-based arbitrage detection using token transfer cycles validated by swap events",
        "paper_reference": "[32]",
        "metric": "F1",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Open-source heuristic MEV detectors (swap-event based; includes liquidations)",
        "paper_reference": "[45]",
        "metric": "F1",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Open-source MEV detection codebase",
        "paper_reference": "[17]",
        "metric": "F1",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "F1",
      "Recall",
      "Precision"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can MEV (especially arbitrage and sandwich) be accurately detected without relying on smart contract ABIs or event decoding?",
        "How to overcome dependency on centralized ABI services and reduce maintenance burden while improving recall?",
        "What are the dominant forms/patterns of MEV transactions and how can they be systematically categorized for labeling and learning?"
      ],
      "gaps_identified": [
        "Existing methods have low recall and are overly conservative, underestimating MEV.",
        "Strong dependency on pre-registered ABIs and centralized services (e.g., Etherscan) to decode events/functions.",
        "High maintenance burden to track new DeFi services, events, and pool addresses.",
        "Novel strategies (e.g., index tokens, burn/mint patterns, non-DEX exchanges) evade prior heuristics; many token exchanges are not accompanied by events."
      ],
      "limitations": [
        "Focuses evaluation on arbitrage and sandwiches; liquidations are not addressed further.",
        "Initial taxonomy/labeling of MEV forms leverages knowledge of events/ABIs for ground-truth construction; although the final detector is ABI-free."
      ],
      "future_work": [],
      "motivation": "Quantify and detect MEV to assess consensus-layer risks, measure anti-centralization solutions, and detect user exploitation, while removing ABI dependency and improving recall.",
      "potential_research_ideas": [
        "Extend ABI-free detection to additional MEV types (e.g., liquidations, time-bandit attacks, CEX-DEX arbitrage, cross-chain MEV).",
        "Cross-domain MEV detection for multi-chain ecosystems using unified, heterogeneous graph representations.",
        "Online/streaming MEV detection with temporal GNNs to capture block/slot ordering dynamics.",
        "Adversarially robust MEV detection to handle strategic evasion by sophisticated builders/searchers.",
        "Self-supervised pretraining on unlabeled transaction graphs to reduce labeling needs and improve generalization to novel strategies."
      ],
      "architectural_improvement_recommendations": [
        "Adopt heterogeneous/multi-relational GNNs with typed nodes/edges (addresses, pools, tokens; transfer, call, approval) to capture richer semantics.",
        "Incorporate temporal/positional encodings (block number, intra-block ordering) and use temporal GNNs or TGAT-type architectures.",
        "Leverage motif/subgraph mining (e.g., swap/star/cycle motifs) with neural subgraph matching for better pattern sensitivity.",
        "Use attention-based readouts and contrastive/self-supervised objectives (graph-level and subgraph-level) prior to supervised finetuning.",
        "Integrate lightweight rule filters with the GNN (neuro-symbolic pipeline) to reduce false positives and inference cost."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Offline analysis of Ethereum on-chain transactions (token transfer logs/graphs)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires access to reliable token transfer logs at scale (potentially archive data for historical labeling/evaluation).",
        "Evolving DeFi mechanics and token standards may introduce unseen patterns requiring continual validation.",
        "Handling non-ERC20 assets or non-standard token behaviors may reduce coverage without additional features."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Identify and analyze limitations of existing MEV detection algorithms (dependency on ABIs, maintenance overhead, low recall).",
      "Thorough taxonomy and classification of MEV transactions: two sandwich categories and five arbitrage categories, revealing novel strategies.",
      "Release a publicly available, extensive MEV dataset surpassing existing public data; used to train and evaluate ArbiNet.",
      "Propose ArbiNet, a low-overhead GNN-based arbitrage detector that operates without smart contract/event/ABI knowledge.",
      "Simple ABI-free sandwich detection algorithm.",
      "Demonstrate significantly better detection performance (F1) compared to public data sources."
    ]
  },
  {
    "arxiv_id": "2305.05285v2",
    "title": "The Day-After-Tomorrow: On the Performance of Radio Fingerprinting over Time",
    "authors": "Saeif Alhazbi; Savio Sciancalepore; Gabriele Oligeri",
    "abstract": "The performance of Radio Frequency (RF) Fingerprinting (RFF) techniques is negatively impacted when the training data is not temporally close to the testing data. This can limit the practical implementation of physical-layer authentication solutions. To circumvent this problem, current solutions involve collecting training and testing datasets at close time intervals -- this being detrimental to the real-life deployment of any physical-layer authentication solution. We refer to this issue as the Day-After-Tomorrow (DAT) effect, being widely attributed to the temporal variability of the wireless channel, which masks the physical-layer features of the transmitter, thus impairing the fingerprinting process.   In this work, we investigate the DAT effect shedding light on its root causes. Our results refute previous knowledge by demonstrating that the DAT effect is not solely caused by the variability of the wireless channel. Instead, we prove that it is also due to the power cycling of the radios, i.e., the turning off and on of the radios between the collection of training and testing data. We show that state-of-the-art RFF solutions double their performance when the devices under test are not power cycled, i.e., the accuracy increases from about 0.5 to about 1 in a controlled scenario. Finally, we show how to mitigate the DAT effect in real-world scenarios, through pre-processing of the I-Q samples. Our experimental results show a significant improvement in accuracy, from approximately 0.45 to 0.85. Additionally, we reduce the variance of the results, making the overall performance more reliable.",
    "published_date": "2023-05-09",
    "pdf_link": "https://arxiv.org/pdf/2305.05285v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Physical-Layer Security",
      "subdomain": "Device Authentication",
      "specific_problem": "Robustness of Radio Frequency Fingerprinting (RFF) over time (Day-After-Tomorrow effect) and mitigation for practical physical-layer authentication",
      "attack_types": [
        "Device impersonation",
        "Spoofing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "ResNet-50 (ImageNet-pretrained, adapted)",
        "novel_contribution": "Refined pre-processing by converting I-Q samples to images before feeding ResNet-50, yielding higher accuracy and reduced variance in real-world scenarios"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet-50 on raw I-Q samples (interleaved N×1 or N×2 inputs)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "HBKU–TU/e RFF dataset (wired BPSK, 900 MHz, USRP X310)",
        "type": "proprietary",
        "domain": "radio_iq_samples",
        "link": null,
        "is_new_contribution": true,
        "availability": "available_on_request"
      },
      {
        "name": "HBKU–TU/e RFF dataset (wireless indoor nLoS 10 m, BPSK, 900 MHz, USRP X310)",
        "type": "proprietary",
        "domain": "radio_iq_samples",
        "link": null,
        "is_new_contribution": true,
        "availability": "available_on_request"
      }
    ],
    "baselines": [
      {
        "method_name": "ResNet-50 on raw I-Q samples (with power cycling) vs. no power cycling (controlled scenario)",
        "paper_reference": "as in [3], [14] (ResNet-50-based RFF)",
        "metric": "accuracy",
        "their_result": "\"accuracy increases from about 0.5 to about 1\" when devices are not power cycled (controlled setup)",
        "baseline_result": "\"about 0.5\" with power cycling (controlled setup)"
      },
      {
        "method_name": "ResNet-50 with image-based pre-processing (proposed) vs. raw I-Q (wireless real-world)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "\"approximately 0.85\" with proposed pre-processing",
        "baseline_result": "\"approximately 0.45\" with raw I-Q"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "variance"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What are the root causes of the Day-After-Tomorrow (DAT) effect in RF fingerprinting?",
        "To what extent does radio power cycling contribute to degraded RFF performance compared to channel variability?",
        "Can pre-processing of I-Q samples mitigate the DAT effect in real-world deployments?"
      ],
      "gaps_identified": [
        "Prior literature largely attributes DAT solely to channel variability, overlooking radio power cycling effects.",
        "Lack of reporting about power cycling procedures in prior work hampers reproducibility and accurate causal analysis.",
        "Observed dataset shift across days leads to poor generalization and unstable accuracy.",
        "RFF performance is jointly affected by transmitter signal, channel, and receiver hardware, complicating deployment."
      ],
      "limitations": [
        "Small-scale setup: 6 transmitters and 1 receiver (USRP X310).",
        "Single modulation (BPSK) at 900 MHz with a specific SDR hardware chain (GNURadio v3.8).",
        "Wireless measurements limited to indoor nLoS at ~10 m; no mobility scenarios reported.",
        "Evaluation focuses on ResNet-50; broader architectural comparisons are not provided.",
        "Datasets are not publicly released; only available on request."
      ],
      "future_work": [],
      "motivation": "Enable practical physical-layer authentication by understanding and mitigating the DAT effect that causes severe performance drops when training and testing occur on different days.",
      "potential_research_ideas": [
        "Develop calibration routines to remove power-cycle-induced offsets (e.g., per-boot RF front-end calibration signatures) to stabilize fingerprints across sessions.",
        "Design domain-adaptive or continual learning RFF that adapts to temporal drift and power-cycle shifts without full retraining.",
        "Self-supervised or contrastive representation learning on I-Q to disentangle device-specific features from channel/boot-state factors.",
        "Meta-learning across channels, days, and receivers to quickly adapt to new conditions with few samples.",
        "Generative augmentation models that simulate power-cycle and channel variations to robustify training.",
        "Receiver-invariant feature learning using adversarial domain adaptation (receiver as domain) to improve cross-receiver robustness.",
        "Siamese/Prototypical metric-learning for open-set and few-shot device authentication tolerant to day-to-day shifts.",
        "Integrate physics-informed layers (e.g., CFO/DC-offset/phase-noise estimators) into the network to normalize front-end impairments."
      ],
      "architectural_improvement_recommendations": [
        "Standardize input normalization: amplitude/phase normalization, DC-offset removal, CFO/phase tracking prior to CNN.",
        "Adopt contrastive or supervised contrastive loss to enforce day-invariant embeddings per device.",
        "Use adversarial domain adaptation to minimize distributions across days/power cycles (domain discriminator on day/session labels).",
        "Employ hybrid models combining DSP features (e.g., cyclostationary statistics) with CNN embeddings.",
        "Evaluate lighter CNN backbones or 1D/2D CNN hybrids for raw I-Q and spectrogram/image inputs to improve efficiency.",
        "Augment training with explicit power-cycle/session augmentation and channel simulation.",
        "Consider Siamese networks for verification-style authentication to enhance robustness to temporal shifts."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "MATLAB",
        "GNU Radio"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Indoor wireless (10 m, non-line-of-sight) and controlled wired coax link; SDR-based lab setup",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Temporal variability across days (DAT effect)",
        "Power cycling causes shifts in learned fingerprints",
        "Channel impairments obscure device-specific features",
        "Dependency on receiver hardware characteristics",
        "Need for frequent retraining or tightly timed data collection to maintain accuracy",
        "High variance of results across days without mitigation"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Identify and experimentally validate that radio power cycling is a significant root cause of the DAT effect beyond wireless channel variability.",
      "Reproduce the DAT effect and confirm via a wired link (excluding channel effects) that power cycling degrades performance.",
      "Demonstrate that avoiding power cycling can roughly double accuracy in controlled settings (\"about 0.5\" to \"about 1\").",
      "Propose an I-Q pre-processing (I-Q to images) that boosts accuracy in real-world wireless scenarios from \"approximately 0.45\" to \"approximately 0.85\" and reduces result variance.",
      "Provide a multi-day measurement campaign with SDR USRP X310s over wired and wireless links; datasets available on request."
    ]
  },
  {
    "arxiv_id": "2304.01244v1",
    "title": "Unified Emulation-Simulation Training Environment for Autonomous Cyber Agents",
    "authors": "Li Li; Jean-Pierre S. El Rami; Adrian Taylor; James Hailing Rao; Thomas Kunz",
    "abstract": "Autonomous cyber agents may be developed by applying reinforcement and deep reinforcement learning (RL/DRL), where agents are trained in a representative environment. The training environment must simulate with high-fidelity the network Cyber Operations (CyOp) that the agent aims to explore. Given the complexity of net-work CyOps, a good simulator is difficult to achieve. This work presents a systematic solution to automatically generate a high-fidelity simulator in the Cyber Gym for Intelligent Learning (CyGIL). Through representation learning and continuous learning, CyGIL provides a unified CyOp training environment where an emulated CyGIL-E automatically generates a simulated CyGIL-S. The simulator generation is integrated with the agent training process to further reduce the required agent training time. The agent trained in CyGIL-S is transferrable directly to CyGIL-E showing full transferability to the emulated \"real\" network. Experimental results are presented to demonstrate the CyGIL training performance. Enabling offline RL, the CyGIL solution presents a promising direction towards sim-to-real for leveraging RL agents in real-world cyber networks.",
    "published_date": "2023-04-03",
    "pdf_link": "https://arxiv.org/pdf/2304.01244v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Autonomous Cyber Operations (Red/Blue Team) Training",
      "specific_problem": "Unified emulation–simulation environment for training RL cyber agents with sim-to-real transfer",
      "attack_types": [
        "Network discovery",
        "Command and Control (C2) establishment",
        "Credential access",
        "Privilege escalation",
        "Defense evasion",
        "Lateral movement",
        "Information collection",
        "Data exfiltration"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": "Unified emulation–simulation RL training (CyGIL-E ↔ CyGIL-S) with MDP/FSM modeling",
        "novel_contribution": "Unsupervised auto-generation of simulator transition model P(o,o'|a) from emulation data; cross-training/continuous learning loop that alternates between emulation (CyGIL-E) and simulation (CyGIL-S) to reduce data collection and training time; representation learning to move to promising regions of the state space."
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": "DQN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": "PPO",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": "Rainbow C51 (C51)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Deep Reinforcement Learning",
      "Offline RL (enabled via data-driven simulator generation)"
    ],
    "datasets": [
      {
        "name": "CyGIL-E interaction dataset D (random plays, 10 days)",
        "type": "private",
        "domain": "cyber_ops_transitions (action–observation–next-observation tuples)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "CyGIL-E interaction dataset D (DQN training session)",
        "type": "private",
        "domain": "cyber_ops_transitions (action–observation–next-observation tuples)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "CyGIL-E interaction dataset D (PPO training session)",
        "type": "private",
        "domain": "cyber_ops_transitions (action–observation–next-observation tuples)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CyGIL-E–only training (real/emulated network)",
        "paper_reference": null,
        "metric": "Time to reach optimal policy",
        "their_result": "\"DQN in CyGIL-S: 17.31 minutes\"; \"PPO in CyGIL-S: 25.92 minutes\"; \"C51 in CyGIL-S: 5.76 minutes\"",
        "baseline_result": "\"CyGIL-E: 7–20 days depending on algorithm\""
      },
      {
        "method_name": "Cross-training loop vs. initial CyGIL-E stage",
        "paper_reference": null,
        "metric": "Average training reward and best episode length",
        "their_result": "SEG-3 PPO in CyGIL-S: \"26.5, 10\"; SEG-5 PPO in CyGIL-E: \"26.5, 10\"; SEG-3 C51 in CyGIL-S: \"92, 8\"",
        "baseline_result": "SEG-1 DQN in CyGIL-E after 35.5h: \"-0.9, 24\" (from initial -912, 80)"
      }
    ],
    "performance_metrics_used": [
      "Average training reward",
      "Average evaluation reward",
      "Episode length (steps per episode)",
      "Time to reach optimal policy",
      "Accumulated return",
      "Unknown transition counts/histogram in simulator"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can we automatically generate a high-fidelity simulator (CyGIL-S) from an emulated/real cyber network (CyGIL-E) to train RL agents that transfer to the real network?",
        "Can a unified emulation–simulation cross-training loop reduce data collection and overall training time while preserving transferability?",
        "How should we handle unknown transitions in the simulator arising from sparse/expensive data collection in real/emulated networks?"
      ],
      "gaps_identified": [
        "Existing CyOp simulators rely on abstracted actions and simplified states, making trained agents non-transferable to real networks.",
        "Building high-fidelity simulators for complex cyber networks is difficult and time-consuming.",
        "Collecting sufficient real-system data to populate accurate transition models is expensive and slow.",
        "Data-driven simulators face unknown transitions due to sparse coverage of large state spaces."
      ],
      "limitations": [
        "To generate a sufficient CyGIL-S that reaches optimal policy, the data collection time can approximate the time for training directly in CyGIL-E (still long).",
        "Unknown transitions in CyGIL-S persist due to sparse data; current fallback often treats actions as non-executable (penalized), which biases exploration.",
        "Evaluation is performed on an emulated SDN/VM-based lab network; no deployment evidence in large, production enterprise networks.",
        "Focus and examples are primarily for a red agent; blue agent treatment and multi-agent interactions are not fully elaborated.",
        "Transferability is demonstrated to the emulated 'real' network; true on-prem production validation is not shown."
      ],
      "future_work": [
        "Further reduce real/emulated data collection time while maintaining simulator fidelity.",
        "Improve handling of unknown transitions (e.g., better imputation/estimation or model-based components).",
        "Extend unified training to blue agents and richer multi-agent settings with concurrent actions.",
        "Scale to larger, heterogeneous enterprise networks and diverse toolchains beyond CALDERA.",
        "Investigate stronger offline RL methods leveraging logs from real operations."
      ],
      "motivation": "Enable practical sim-to-real RL training for cyber operations by unifying a realistic emulation environment with an auto-generated simulator to reduce training cost and time while preserving action/state fidelity.",
      "potential_research_ideas": [
        "Develop a generative dynamics model (e.g., ensemble world models) to estimate unknown transitions and quantify uncertainty, reducing reliance on extensive emulation data.",
        "Graph-based state representation (GNNs) that encode hosts, services, credentials, and connectivity; learn transition operators over graphs for better generalization.",
        "Causality-aware modeling of action effects to improve counterfactual reasoning and sim-to-real robustness.",
        "Apply conservative/offline RL (e.g., CQL, IQL) over CyGIL-E logs to reduce unsafe exploration needs in emulation.",
        "Curriculum/domain-randomization over network topology, services, and defenses to improve transfer to varied real environments.",
        "Hierarchical/option-based RL to capture multi-stage TTPs (e.g., privilege escalation → lateral movement) and reduce exploration complexity.",
        "Active data collection policies that prioritize informative transitions in CyGIL-E to minimize collection time.",
        "Uncertainty-aware planning (e.g., Thompson sampling, UCB) in CyGIL-S to navigate regions with unknown transitions safely.",
        "Leverage human red-team traces for imitation or hybrid RL to bootstrap policies and simulators.",
        "Parameterized action RL to more faithfully model tool invocation with arguments and preconditions."
      ],
      "architectural_improvement_recommendations": [
        "Replace FSM-only simulator with a probabilistic neural dynamics model (ensemble) to predict next observations and rewards, with epistemic uncertainty.",
        "Adopt graph neural networks for state encoding and action-conditioned transition modeling over network graphs.",
        "Incorporate model-based RL (Dyna-style) to interleave real/emulated rollouts with learned model rollouts and prioritized sweeping.",
        "Use hierarchical RL with learned options/subpolicies corresponding to ATT&CK tactic groups.",
        "Handle partial observability using recurrent policies (RNN/Transformer) and belief-state estimation.",
        "Introduce conservative/offline RL objectives during CyGIL-S training to mitigate distribution shift from sparse emulation data.",
        "Implement prioritized and diversity-aware sampling of (a,o,o') transitions to reduce overfitting to frequent states.",
        "Formalize unknown-transition handling via pessimistic backups or uncertainty penalties rather than defaulting to non-executable outcomes."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "OpenAI Gym interface (environment API)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Emulation on laptops: one Windows laptop Intel Core i9, 64GB RAM (network emulation with Mininet/ONOS); second laptop Intel Core i7, 64GB RAM (agent training). CyGIL-E training to optimal policy: 7–20 days depending on algorithm. CyGIL-S training times: DQN ~17.31 min, PPO ~25.92 min, C51 ~5.76 min. CyGIL-S generation from data takes seconds."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Emulated enterprise-like network: Mininet switches + ONOS SDN controller; larger networks via VMware vSphere; CALDERA red-team tool for realistic actions.",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Slow action execution and environment reset time in emulation/real networks elongate training.",
        "Collecting sufficient high-fidelity data from real/emulated networks is time-consuming and costly.",
        "Unknown transitions due to sparse coverage can degrade simulator fidelity and training stability.",
        "Integration with operational tools (e.g., CALDERA) and environment orchestration (Mininet/ONOS/vSphere) adds engineering overhead."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A unified cyber-operations RL environment (CyGIL) that supports efficient agent training with high fidelity across emulation (CyGIL-E) and simulation (CyGIL-S).",
      "Unsupervised auto-generation of the simulator (CyGIL-S) from real/emulated network data via observation-level transition modeling.",
      "A unified DRL cross-training framework that integrates simulator generation with training to reduce data collection and training time, with demonstrated transfer from CyGIL-S to CyGIL-E."
    ]
  },
  {
    "arxiv_id": "2306.03733v1",
    "title": "A Novel Approach To User Agent String Parsing For Vulnerability Analysis Using Mutli-Headed Attention",
    "authors": "Dhruv Nandakumar; Sathvik Murli; Ankur Khosla; Kevin Choi; Abdul Rahman; Drew Walsh; Scott Riede; Eric Dull; Edward Bowen",
    "abstract": "The increasing reliance on the internet has led to the proliferation of a diverse set of web-browsers and operating systems (OSs) capable of browsing the web. User agent strings (UASs) are a component of web browsing that are transmitted with every Hypertext Transfer Protocol (HTTP) request. They contain information about the client device and software, which is used by web servers for various purposes such as content negotiation and security. However, due to the proliferation of various browsers and devices, parsing UASs is a non-trivial task due to a lack of standardization of UAS formats. Current rules-based approaches are often brittle and can fail when encountering such non-standard formats. In this work, a novel methodology for parsing UASs using Multi-Headed Attention Based transformers is proposed. The proposed methodology exhibits strong performance in parsing a variety of UASs with differing formats. Furthermore, a framework to utilize parsed UASs to estimate the vulnerability scores for large sections of publicly visible IT networks or regions is also discussed. The methodology present here can also be easily extended or deployed for real-time parsing of logs in enterprise settings.",
    "published_date": "2023-06-06",
    "pdf_link": "https://arxiv.org/pdf/2306.03733v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Web Security",
      "subdomain": "Log Analysis and Fingerprinting",
      "specific_problem": "Automatic parsing of HTTP User-Agent strings to extract OS and browser names and versions, then mapping to CVEs/CVSS via CPE to estimate vulnerability exposure across networks/CIDR ranges",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Single-layer Transformer encoder with 2 attention heads and sinusoidal positional encoding",
        "novel_contribution": "Applies multi-headed attention transformer to robustly parse non-standard UAS formats; frames version extraction as position tagging over UAS tokens"
      },
      {
        "type": "primary",
        "category": "Word Embeddings",
        "specific": "FastText (CBOW) trained on UAS corpus",
        "novel_contribution": "Domain-specific FastText embeddings to capture character n-gram substrings (e.g., Mac vs Macintosh) for UAS tokens"
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": null,
        "novel_contribution": "Task-specific dense heads: classification heads for OS/software names and PoS-style indexing heads for version positions with SeLU activations and dropout"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "WhatIsMyBrowser.com User-Agent Strings",
        "type": "public",
        "domain": "log_files",
        "link": "https://www.whatismybrowser.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "National Vulnerability Database (NVD)",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://nvd.nist.gov/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Common Platform Enumeration (CPE) Dictionary",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://nvd.nist.gov/products/cpe",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "f1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can transformer-based NLP robustly parse heterogeneous, non-standard User-Agent strings to accurately extract OS and software (browser) names and versions?",
        "Can the parsed UAS fields be correlated with known CVEs/CVSS (via CPE) to estimate vulnerability exposure at network/CIDR or regional scales?"
      ],
      "gaps_identified": [
        "Lack of a universal standard for UAS formats leads to brittleness of rules-based parsers",
        "Prior work often analyzes entire HTTP requests or aggregates UASs for malicious traffic detection rather than extracting structured fields from individual UASs",
        "Rules-based approaches struggle with unexpected or non-standard UAS formats"
      ],
      "limitations": [
        "Scope limited to four fields: OS name/version and software (browser) name/version",
        "Classification restricted to 7 classes (top-6 plus N/A) for both OS and software in training",
        "Performance degrades for Linux due to overlap with less frequent UNIX-based OS strings",
        "UAS length truncated to 50 tokens after preprocessing",
        "Ground truth relies on labels provided by WhatIsMyBrowser.com",
        "No head-to-head comparison with existing rules-based or learned parsers",
        "No evaluation on spoofed/fake or adversarially crafted UASs",
        "No runtime or resource usage reporting; no real-world deployment results provided"
      ],
      "future_work": [
        "Extend parsing beyond four fields to other UAS components",
        "Deploy for real-time parsing of enterprise logs",
        "Use parsed UASs for ongoing vulnerability monitoring and trend analysis at network or regional levels"
      ],
      "motivation": "Overcome brittleness of rules-based UAS parsers amid heterogeneous, non-standard formats and leverage parsed UAS information to quantify vulnerability exposure via CVEs/CVSS.",
      "potential_research_ideas": [
        "Joint multi-task model that simultaneously extracts names and versions (sequence labeling + classification) with shared transformer backbone",
        "Character-level or subword-level tokenization (BPE/unigram) with domain-adaptive pretraining (MLM) on large UAS corpora to improve robustness to typos and variants",
        "Adversarial robustness evaluation and training against spoofed or manipulated UASs",
        "Confidence calibration and abstention for uncertain extractions to reduce false CPE mappings",
        "Automated disambiguation and canonicalization from parsed tokens to CPEs using learned entity linking",
        "Incremental/continual learning to capture emerging browsers/OS versions without full retraining",
        "Integrate other HTTP headers or network context to improve parsing and vulnerability inference",
        "Benchmarking against state-of-the-art rules-based libraries and sequence models on a shared test set"
      ],
      "architectural_improvement_recommendations": [
        "Add more transformer layers and heads with residual connections, layer norm, and pre-norm configuration",
        "Use subword tokenization and initialize with domain-adapted transformer (pretrained via MLM on UAS corpus)",
        "Replace position classification head with a CRF or pointer network for more accurate version span extraction",
        "Apply class-weighting or focal loss to mitigate class imbalance (e.g., Linux/UNIX overlaps)",
        "Introduce character-CNN or convolutional sublayers to better capture local patterns and obfuscations",
        "Knowledge distillation and quantization for low-latency, real-time deployment",
        "Calibrate outputs (temperature scaling) and provide confidence scores for downstream CPE mapping"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "FastText"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Proposed for enterprise real-time log parsing and public-internet CIDR monitoring",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Non-standard and evolving UAS formats",
        "Ambiguity/overlap among UNIX-like OS indicators affecting classification",
        "Potential for spoofed or manipulated UASs",
        "Mapping parsed fields to precise CPEs may be ambiguous or incomplete",
        "Keeping NVD/CPE data current for accurate vulnerability scoring"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a transformer-based approach with domain-specific FastText embeddings to parse UASs and extract OS and software names and versions",
      "Proposes a framework to correlate parsed UAS fields with NVD CVEs via CPE and compute CVSS-based vulnerability scores per UAS, aggregating by CIDR/geography",
      "Demonstrates strong performance on name classification (accuracy/precision/recall/F1) and version indexing (≈99.4–99.5% accuracy)",
      "Provides visualization concept for vulnerability distribution and trend analysis across networks and regions"
    ]
  },
  {
    "arxiv_id": "2305.02763v1",
    "title": "VendorLink: An NLP approach for Identifying & Linking Vendor Migrants & Potential Aliases on Darknet Markets",
    "authors": "Vageesh Saxena; Nils Rethmeier; Gijs Van Dijck; Gerasimos Spanakis",
    "abstract": "The anonymity on the Darknet allows vendors to stay undetected by using multiple vendor aliases or frequently migrating between markets. Consequently, illegal markets and their connections are challenging to uncover on the Darknet. To identify relationships between illegal markets and their vendors, we propose VendorLink, an NLP-based approach that examines writing patterns to verify, identify, and link unique vendor accounts across text advertisements (ads) on seven public Darknet markets. In contrast to existing literature, VendorLink utilizes the strength of supervised pre-training to perform closed-set vendor verification, open-set vendor identification, and low-resource market adaption tasks. Through VendorLink, we uncover (i) 15 migrants and 71 potential aliases in the Alphabay-Dreams-Silk dataset, (ii) 17 migrants and 3 potential aliases in the Valhalla-Berlusconi dataset, and (iii) 75 migrants and 10 potential aliases in the Traderoute-Agora dataset. Altogether, our approach can help Law Enforcement Agencies (LEA) make more informed decisions by verifying and identifying migrating vendors and their potential aliases on existing and Low-Resource (LR) emerging Darknet markets.",
    "published_date": "2023-05-04",
    "pdf_link": "https://arxiv.org/pdf/2305.02763v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cyber Threat Intelligence",
      "subdomain": "Dark Web Monitoring",
      "specific_problem": "Linking and verifying darknet marketplace vendor identities across markets (migrants) and detecting potential aliases from text advertisements",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT-base-cased sequence classifier",
        "novel_contribution": "Supervised pre-training on darknet ad text for closed-set vendor verification and to learn style representations specific to darknet language"
      },
      {
        "type": "primary",
        "category": "Representation Learning",
        "specific": "Style representation extraction using CKA-guided layer selection",
        "novel_contribution": "Uses Centered Kernel Alignment to locate layers most changed by darknet-domain training and extract semantically meaningful style embeddings for open-set identification"
      },
      {
        "type": "primary",
        "category": "Similarity Learning",
        "specific": "Cosine similarity with normalized similarity (sim_norm)",
        "novel_contribution": "Introduces a normalization by self-similarity to compare vendors across diverse categories without manual category labels"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Bi-GRU (two-layer) classifier initialized with BERT-derived style embeddings",
        "novel_contribution": "Knowledge transfer to a lightweight BiGRU for low-resource market adaptation enabling closed-set verification on emerging markets"
      },
      {
        "type": "baseline",
        "category": "Bag-of-Words + Linear/NN",
        "specific": "TF-IDF features with Multilayer Perceptron",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Naive Bayes",
        "specific": "Multinomial Naive Bayes",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Models",
        "specific": "Logistic Regression",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Support Vector Machine",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Character-level CNN over n-grams",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "BiGRU with FastText embeddings",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "DistilBERT-base-cased sequence classifier",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "RoBERTa-base sequence classifier",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT-uncased sequence classifier",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "DarkBERT (language model + classifier trained on darknet ads)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer with Adapters",
        "specific": "Adapter-BERT (frozen backbone with adapter layers)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Transfer Learning",
      "Zero-shot",
      "Open-set identification"
    ],
    "datasets": [
      {
        "name": "Alphabay",
        "type": "public",
        "domain": "darknet_market_ads",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Dreams",
        "type": "public",
        "domain": "darknet_market_ads",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Silk Road-1",
        "type": "public",
        "domain": "darknet_market_ads",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Valhalla",
        "type": "public",
        "domain": "darknet_market_ads",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Berlusconi",
        "type": "public",
        "domain": "darknet_market_ads",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Traderoute",
        "type": "public",
        "domain": "darknet_market_ads",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Agora",
        "type": "public",
        "domain": "darknet_market_ads",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Alphabay-Dreams-Silk (combined)",
        "type": "public",
        "domain": "darknet_market_ads",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Valhalla-Berlusconi (combined low-resource)",
        "type": "public",
        "domain": "darknet_market_ads",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Traderoute-Agora (combined high-resource)",
        "type": "public",
        "domain": "darknet_market_ads",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Multinomial Naive Bayes (TF-IDF) on Dreams",
        "paper_reference": null,
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.8978 / 0.8978 / 0.9002",
        "baseline_result": "0.0183 / 0.0144 / 0.0059"
      },
      {
        "method_name": "Random Forest (TF-IDF) on Dreams",
        "paper_reference": null,
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.8978 / 0.8978 / 0.9002",
        "baseline_result": "0.0102 / 0.1093 / 0.0449"
      },
      {
        "method_name": "Logistic Regression (TF-IDF) on Dreams",
        "paper_reference": null,
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.8978 / 0.8978 / 0.9002",
        "baseline_result": "0.0045 / 0.0090 / 0.0037"
      },
      {
        "method_name": "SVM (TF-IDF) on Dreams",
        "paper_reference": null,
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.8978 / 0.8978 / 0.9002",
        "baseline_result": "0.2480 / 0.3974 / 0.3703"
      },
      {
        "method_name": "MLP (TF-IDF) on Dreams",
        "paper_reference": null,
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.8978 / 0.8978 / 0.9002",
        "baseline_result": "0.6614 / 0.6603 / 0.6594"
      },
      {
        "method_name": "Character-CNN on Dreams",
        "paper_reference": "Shrestha et al., 2017 (cited)",
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.8978 / 0.8978 / 0.9002",
        "baseline_result": "0.7266 / 0.7256 / 0.7248"
      },
      {
        "method_name": "BiGRU-FastText on Dreams",
        "paper_reference": "Gupta et al., 2019 (cited)",
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.8978 / 0.8978 / 0.9002",
        "baseline_result": "0.7374 / 0.7415 / 0.7360"
      },
      {
        "method_name": "DistilBERT-base-cased on Dreams",
        "paper_reference": "Sanh et al., 2019 (cited)",
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.8978 / 0.8978 / 0.9002",
        "baseline_result": "0.8886 / 0.8885 / 0.8889"
      },
      {
        "method_name": "RoBERTa-base on Dreams",
        "paper_reference": "Liu et al., 2019 (cited)",
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.8978 / 0.8978 / 0.9002",
        "baseline_result": "0.8776 / 0.8797 / 0.8736"
      },
      {
        "method_name": "BERT-uncased on Alphabay-Dreams-Silk",
        "paper_reference": "Devlin et al., 2019 (cited)",
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.9046 / 0.9066 / 0.9013",
        "baseline_result": "0.8947 / 0.8939 / 0.8768"
      },
      {
        "method_name": "DarkBERT-classifier on Alphabay-Dreams-Silk",
        "paper_reference": null,
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.9046 / 0.9066 / 0.9013",
        "baseline_result": "0.9000 / 0.9090 / 0.9073"
      },
      {
        "method_name": "Adapter-BERT on Alphabay-Dreams-Silk",
        "paper_reference": "Houlsby et al., 2019 (adapters cited)",
        "metric": "Accuracy/Micro-F1/Macro-F1",
        "their_result": "BERT-cased: 0.9046 / 0.9066 / 0.9013",
        "baseline_result": "0.8398 / 0.8330 / 0.8188"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Micro-F1",
      "Macro-F1"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can vendor accounts that migrate between darknet markets be verified (closed-set) using writing style from ad text?",
        "Can potential vendor aliases and unknown vendors be identified in an open-set scenario using style representations?",
        "Can knowledge learned from high-resource markets be transferred to low-resource/emerging markets for vendor verification with limited compute?"
      ],
      "gaps_identified": [
        "Significant language differences between darknet and surface web reduce effectiveness of models pretrained on surface web data.",
        "Existing vendor verification work focuses on closed-set classification and struggles with open-set identification in real-world settings with unknown vendors.",
        "High computational and storage requirements hinder LEAs from training heavyweight models for continually emerging markets.",
        "Reproducibility challenges due to seized/shut-down markets and lack of access to prior datasets.",
        "Manual feature extraction from ads is costly; need end-to-end text approaches."
      ],
      "limitations": [
        "Does not classify vendors with fewer than 20 ads; such vendors are grouped into an 'others' class.",
        "Open-set identification relies on cosine similarity of learned embeddings without explicit content-control; potential entanglement of style with content acknowledged.",
        "Focuses on English-dominant ads; multilingual aspects not addressed.",
        "Evaluation limited to publicly available historical datasets; no live deployment evaluation.",
        "Preprocessing minimal; potential noise retained which may affect generalization."
      ],
      "future_work": [
        "Experiment with content control in a contrastive setup to disentangle style from content for authorship verification.",
        "Extend low-resource adaptation and evaluate against zero-shot and transformer baselines on additional emerging markets.",
        "Investigate more efficient adaptation mechanisms for LEAs with constrained compute."
      ],
      "motivation": "Assist law enforcement by automatically linking migrating vendors and potential aliases across darknet markets to uncover market connections while reducing manual effort.",
      "potential_research_ideas": [
        "Contrastive, content-controlled style encoders to improve robustness of style representations independent of product content.",
        "Multilingual and code-mixed vendor verification to cover non-English ads on darknet markets.",
        "Joint multimodal vendor linking by fusing text with image style (photography) features from listings.",
        "Graph-based cross-market entity resolution combining style similarity with metadata (timestamps, prices, shipping regions) in a probabilistic framework.",
        "Active learning pipeline for LEAs to validate high-confidence links and iteratively refine the model.",
        "Open-set recognition with calibrated thresholds and distance-based confidence (e.g., energy-based OOD detection) to flag unknown vendors.",
        "Unsupervised or semi-supervised domain adaptation to new markets without labels via self-training or adversarial alignment.",
        "Category-aware or topic-conditioned normalization to mitigate content bias while avoiding manual labeling (weak supervision).",
        "Temporal modeling to account for style drift of vendors over time and after market seizures."
      ],
      "architectural_improvement_recommendations": [
        "Replace cosine with metric learning (e.g., ArcFace/Triplet loss) fine-tuning on style embeddings for better inter/intra-vendor separation.",
        "Introduce multi-task training: closed-set classification plus contrastive loss between ads of same/different vendors.",
        "Use parameter-efficient fine-tuning (LoRA/adapters) on darknet corpora for rapid market adaptation with limited compute.",
        "Calibrate open-set thresholds using extreme value theory or deep ensembles for more reliable alias detection.",
        "Incorporate lightweight topic/style disentanglement (adversarial removal of product-category signals) to reduce content leakage.",
        "Leverage sentence-transformer fine-tuning on vendor-pair similarity labels to improve open-set retrieval quality."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/maastrichtlawtech/VendorLink.git",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High computational and storage requirements for training large transformer models in LEA environments.",
        "Rapid emergence of new markets and vendors requires continual adaptation and open-set handling.",
        "Class imbalance across vendors (many vendors with few ads) complicates training and evaluation.",
        "Data access challenges due to market seizures and takedowns affecting reproducibility."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces VendorLink: an NLP approach to verify, identify, and link darknet market vendors across markets using writing style.",
      "Closed-set vendor verification via supervised pre-training of a BERT-cased classifier on darknet ads (domain adaptation).",
      "Open-set vendor identification using style representations extracted from trained classifier and normalized cosine similarity.",
      "Low-resource market adaptation by transferring style representations to a lightweight Bi-GRU classifier (transfer-BiGRU).",
      "Establishes extensive architectural and methodological baselines (TF-IDF + classical ML, CNN/RNN, multiple transformers).",
      "Reports discovered links: “15 migrants and 71 potential aliases” (Alphabay-Dreams-Silk), “17 migrants and 3 potential aliases” (Valhalla-Berlusconi), “75 migrants and 10 potential aliases” (Traderoute-Agora).",
      "Releases code for reproducibility and bases experiments on publicly available datasets.",
      "Proposes CKA-based analysis to select layers for style representation extraction."
    ]
  },
  {
    "arxiv_id": "2303.17740v1",
    "title": "A CI-based Auditing Framework for Data Collection Practices",
    "authors": "Athina Markopoulou; Rahmadi Trimananda; Hao Cui",
    "abstract": "Apps and devices (mobile devices, web browsers, IoT, VR, voice assistants, etc.) routinely collect user data, and send them to first- and third-party servers through the network. Recently, there is a lot of interest in (1) auditing the actual data collection practices of those systems; and also in (2) checking the consistency of those practices against the statements made in the corresponding privacy policies. In this paper, we argue that the contextual integrity (CI) tuple can be the basic building block for defining and implementing such an auditing framework. We elaborate on the special case where the tuple is partially extracted from the network traffic generated by the end-device of interest, and partially from the corresponding privacy policies using natural language processing (NLP) techniques. Along the way, we discuss related bodies of work and representative examples that fit into that framework. More generally, we believe that CI can be the building block not only for auditing at the edge, but also for specifying privacy policies and system APIs. We also discuss limitations and directions for future work.",
    "published_date": "2023-03-30",
    "pdf_link": "https://arxiv.org/pdf/2303.17740v1",
    "paper_types": [
      "position"
    ],
    "security_domain": {
      "primary": "Privacy Engineering",
      "subdomain": "Policy Compliance Auditing",
      "specific_problem": "Auditing data collection and sharing practices on end-user devices and checking consistency with privacy policy disclosures using the Contextual Integrity (CI) tuple.",
      "attack_types": [
        "Tracking/Advertising (ATS)",
        "Third-party data sharing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Knowledge representation",
        "specific": "Contextual Integrity (CI) tuple",
        "novel_contribution": "Proposes CI tuple as the central, unifying data structure for specifying and auditing data collection practices and policy consistency."
      },
      {
        "type": "primary",
        "category": "NLP / Information Extraction",
        "specific": "PolicyLint, Polisis (referenced tools)",
        "novel_contribution": "Use NLP-extracted entities (sender, recipient, data type, purpose) from privacy policies to populate CI parameters and support flow-to-policy consistency checks."
      },
      {
        "type": "primary",
        "category": "Ontology-based matching / Rule-based reasoning",
        "specific": null,
        "novel_contribution": "Employ ontologies and synonym lists to match data types and entities between observed flows and disclosed policy statements; advocates for hierarchical CI-tuples."
      },
      {
        "type": "baseline",
        "category": "NLP / Consistency Analysis",
        "specific": "PoliCheck",
        "novel_contribution": "Referenced as state-of-the-art method to compare network-derived flows with policy statements and classify disclosures (clear, vague, omitted, ambiguous, incorrect)."
      },
      {
        "type": "baseline",
        "category": "Classification / Purpose inference",
        "specific": "MobiPurpose, PurPliance",
        "novel_contribution": "Referenced methods to infer and validate purposes from policies and traffic to augment CI tuples."
      },
      {
        "type": "baseline",
        "category": "Network Traffic Analysis",
        "specific": "On-device VPN/proxy, domain/entity resolution using blocklists/whois",
        "novel_contribution": "Referenced as the means to extract sender, recipient, and partial data type from encrypted/unencrypted traffic."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Rule-based",
      "Knowledge-based",
      "Heuristic"
    ],
    "datasets": [
      {
        "name": "Oculus VR apps - network traffic traces (case study referenced from [23])",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Oculus VR apps - privacy policies (case study referenced from [23])",
        "type": "private",
        "domain": "policy_documents",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Mobile apps - network traffic traces (prior studies)",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Smart TV platforms/apps - network traffic traces (prior studies)",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "IoT devices - network traffic traces (prior studies)",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "VR headsets - network traffic traces (prior studies)",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Smart speakers - network traffic traces (prior studies)",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Alexa skills - privacy policies (applied by prior tools)",
        "type": "private",
        "domain": "policy_documents",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Q1: How to model and summarize hierarchical CI parameters across many flows/statements (\"hierarchical\" CI-tuple vs. flat/bloated)?",
        "Q2: How to combine CI parameters extracted from heterogeneous sources (traffic, dynamic analysis, policy NLP, permissions) into a single consistent tuple and handle inconsistencies?",
        "Q3: How to move from reactive auditing to proactive use of CI for specifying privacy policies and system APIs?"
      ],
      "gaps_identified": [
        "Significant gap between actual data collection practices and formulation/enforcement of privacy laws; difficulty mapping legal requirements to implementable/auditable specifications.",
        "Existing auditing methods extract CI-like parameters ad hoc, lacking a unifying data structure and pipeline.",
        "Encrypted traffic hinders accurate extraction of data types; decrypted payloads often contain opaque key-value pairs that are hard to interpret.",
        "Reliance on ontologies/synonym lists is necessary but currently limited; need robust, domain-specific hierarchies (e.g., VR).",
        "Privacy policies can be \"bloated\" lists and often vague or inconsistent; purpose and consent are hard to extract reliably.",
        "Complex app ecosystems (third-party SDKs, platforms) make compliance verification difficult."
      ],
      "limitations": [
        "Only subsets of CI (especially transmission principles like purpose/consent) can be reliably automated today.",
        "Network encryption and opaque payload semantics limit precise data-type inference from traffic.",
        "Flow-to-policy matching depends on the quality and coverage of ontologies and entity resolution (first vs third party, ATS).",
        "The presented work is a position/framework paper without new empirical evaluation; relies on prior tools and case studies.",
        "Subject parameter often implicit/omitted when auditing at the edge."
      ],
      "future_work": [
        "Develop a formal, hierarchical CI-tuple representation backed by ontologies to enable precise summarization and matching.",
        "Design principled methods to merge CI evidence from multiple sources and encode/resolve inconsistencies.",
        "Use CI to structure privacy policies and system APIs for proactive, verifiable disclosures and enforcement.",
        "Automate broader transmission principle extraction (purpose, notice-and-consent) and validation against destinations (e.g., ATS).",
        "Build end-to-end CI-driven auditing pipelines that scale across platforms (mobile, IoT, VR, smart TV)."
      ],
      "motivation": "Provide a unifying, interpretable and automatable framework (CI tuple) to bridge the gap between system data collection practices and privacy law disclosures, enabling auditing of actual behaviors and their consistency with privacy policies.",
      "potential_research_ideas": [
        "Define a graph-based hierarchical CI representation with ontology alignment across domains (mobile, VR, IoT) and study matching/merging algorithms with uncertainty handling.",
        "Develop encrypted-traffic CI inference using side-channel features (SNI, sequence patterns, metadata) plus active watermarking to infer data types without decrypting payloads.",
        "Create a CI-aware large-scale entity resolution service mapping domains/IPs to organizations, roles (first/third party, ATS), and purposes with confidence scores.",
        "Design CI-aligned policy languages/templates and compiler toolchains that emit machine-readable disclosures and enforcement hooks for SDKs/APIs.",
        "Integrate UI/UX instrumentation to automatically detect presence/quality of notice-and-consent and link it to CI tuples for compliance checks.",
        "Construct continuous compliance monitoring (\"CI CI/CD\") that runs automated tests for each app release and flags policy/behavior drift.",
        "Cross-jurisdiction mapping: link CI tuples to legal obligations (GDPR/CCPA articles) to generate actionable compliance reports and DPIA support."
      ],
      "architectural_improvement_recommendations": [
        "Implement an end-to-end CI pipeline: automated app exercising, on-device VPN/proxy capture, domain/entity resolution, ontology-driven data-type inference, policy NLP (IE of sender/recipient/data-type/purpose), and flow-to-policy matcher.",
        "Standardize and publish domain-specific ontologies (e.g., VR motion/biometric data) with versioning; use them to drive hierarchical CI tuples and vague/clear matching rules.",
        "Augment traffic analysis with permission/dynamic taint signals and SDK fingerprinting to strengthen sender/data-type attribution.",
        "Add active testing (synthetic unique markers in inputs) to validate data-type exfiltration paths and improve mapping of opaque key-value payloads.",
        "Maintain a knowledge base of ATS and third-party SDK endpoints with purposes and confidence levels to auto-annotate recipients.",
        "Encode inconsistency outcomes directly as transmission principle attributes within CI tuples to preserve provenance and conflict reasoning."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "End-user devices (mobile, browsers, smart TVs, VR, IoT) via on-device VPN/proxy vantage points for traffic capture; privacy policy analysis via NLP pipelines.",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "TLS encryption and opaque payload semantics hinder precise data-type extraction.",
        "Accurate mapping of destinations to organizations and roles (first vs third party, ATS) is non-trivial.",
        "Purpose inference and consent detection from policies/UX are noisy and often vague.",
        "Ecosystem complexity and third-party SDK behavior outside app developer control.",
        "Dependence on comprehensive ontologies and synonym lists for robust matching across domains."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Argues that the Contextual Integrity (CI) tuple is the central, interpretable data structure for auditing data collection and sharing practices at the edge.",
      "Shows how parts of the CI tuple can be extracted from network traffic (sender, recipient, partial data type) and from privacy policies using NLP (sender, recipient, data type, purpose).",
      "Positions existing tools (PolicyLint, PoliCheck, Polisis, MobiPurpose, PurPliance) within a CI-based auditing pipeline; presents a VR app case study ontology example.",
      "Identifies open problems: hierarchical CI parameters, merging multi-source evidence, and proactive CI use for policy/API specification.",
      "Proposes that CI underpin not only auditing but also the structure of privacy policies and system APIs for enforceable, machine-readable disclosures."
    ]
  },
  {
    "arxiv_id": "2306.06782v1",
    "title": "Augmenting Greybox Fuzzing with Generative AI",
    "authors": "Jie Hu; Qian Zhang; Heng Yin",
    "abstract": "Real-world programs expecting structured inputs often has a format-parsing stage gating the deeper program space. Neither a mutation-based approach nor a generative approach can provide a solution that is effective and scalable. Large language models (LLM) pre-trained with an enormous amount of natural language corpus have proved to be effective for understanding the implicit format syntax and generating format-conforming inputs. In this paper, propose ChatFuzz, a greybox fuzzer augmented by generative AI. More specifically, we pick a seed in the fuzzer's seed pool and prompt ChatGPT generative models to variations, which are more likely to be format-conforming and thus of high quality. We conduct extensive experiments to explore the best practice for harvesting the power of generative LLM models. The experiment results show that our approach improves the edge coverage by 12.77\\% over the SOTA greybox fuzzer (AFL++) on 12 target programs from three well-tested benchmarks. As for vulnerability detection, \\sys is able to perform similar to or better than AFL++ for programs with explicit syntax rules but not for programs with non-trivial syntax.",
    "published_date": "2023-06-11",
    "pdf_link": "https://arxiv.org/pdf/2306.06782v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Software Testing and Analysis",
      "specific_problem": "Greybox fuzzing of programs with structured inputs; improving generation of format-conforming inputs to pass parsing stages and explore deeper program states",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "GPT-3.5-turbo (ChatGPT chat model)",
        "novel_contribution": "ChatFuzz: integrates a chat-driven LLM \"chat mutator\" into a greybox fuzzer to generate format-conforming mutations; systematic exploration of LLM hyperparameters (model choice, prompt design, max_tokens, n, temperature) for fuzzing efficacy"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "text-curie-001 (OpenAI completion model)",
        "novel_contribution": "Evaluated as an alternative LLM endpoint for the chat mutator; latency and quality trade-off characterization"
      }
    ],
    "learning_paradigm": [
      "Zero-shot prompting",
      "Heuristic/Evolutionary (greybox fuzzing with coverage feedback)"
    ],
    "datasets": [
      {
        "name": "jq (program under test; JSON inputs)",
        "type": "public",
        "domain": "text_based_program_inputs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "php (program under test; PHP inputs)",
        "type": "public",
        "domain": "text_based_program_inputs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "mujs (program under test; JavaScript inputs)",
        "type": "public",
        "domain": "text_based_program_inputs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "xml (program under test; XML inputs; e.g., libxml2)",
        "type": "public",
        "domain": "text_based_program_inputs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "12 target programs from three well-tested benchmarks (unspecified)",
        "type": "public",
        "domain": "text_based_program_inputs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "AFL++ (state-of-the-art greybox fuzzer)",
        "paper_reference": null,
        "metric": "Edge coverage",
        "their_result": "“improves the edge coverage by 12.77% over the SOTA greybox fuzzer (AFL++) on 12 target programs from three well-tested benchmarks.”",
        "baseline_result": "Absolute baseline coverage values not provided"
      },
      {
        "method_name": "AFL++ (vulnerability detection)",
        "paper_reference": null,
        "metric": "Vulnerability detection (qualitative)",
        "their_result": "“CHATFUZZ is able to perform similar to or better than AFL++ for programs with explicit syntax rules but not for programs with non-trivial syntax.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "edge coverage",
      "seed unique ratio",
      "seed valid ratio (syntactic validity)",
      "model latency per query",
      "average latency per output",
      "vulnerability detection (qualitative comparison)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "“Real-world programs expecting structured inputs often has a format-parsing stage gating the deeper program space.”",
        "Mutation-based fuzzers often generate syntactically invalid inputs, leading to poor exploration past parsers (e.g., AFL++ valid XML ratio 0.82% in 2h for libxml2).",
        "Generative/grammar-based approaches demand manual grammars and lack runtime feedback; learning-based generators may not leverage execution feedback for exploration."
      ],
      "limitations": [
        "“CHATFUZZ is able to perform similar to or better than AFL++ for programs with explicit syntax rules but not for programs with non-trivial syntax.”",
        "Effectiveness is sensitive to LLM hyperparameters (model choice, prompt, max_tokens, n, temperature) and query latency/cost constraints.",
        "Current evaluation limited to text-based formats; applicability to binary or highly context-sensitive grammars is unproven.",
        "Reliance on external LLM API introduces latency, cost, context-length limits, and potential privacy concerns (not addressed)."
      ],
      "future_work": [
        "“We will open-source CHATFUZZ along with datasets at https://www.github.com/xxxx upon acceptance of this work.”"
      ],
      "motivation": "Improve greybox fuzzing for programs with structured inputs by generating format-conforming testcases that pass parsing stages and enable deeper state exploration; leverage LLMs that can infer and preserve input structure from few examples.",
      "potential_research_ideas": [
        "Integrate grammar induction or parser-informed constrained decoding with LLM prompting to better handle non-trivial/recursive grammars.",
        "On-premise/open-source LLM fine-tuned on code and specification corpora for domain formats (JSON/XML/JS/PHP) to reduce latency/cost and improve control.",
        "Adaptive prompt optimization (e.g., bandits or Bayesian optimization) that tunes temperature, n, and prompt templates online based on coverage feedback.",
        "Hybrid generator that ensembles LLM outputs with grammar-based or AST-level mutators and program-aware repair (e.g., parser-based auto-fix).",
        "Extend to binary protocols and file formats using tokenization schemes and structure recovery (e.g., token dictionaries + structural hints).",
        "Coverage-guided LLM decoding where branch/edge feedback steers token sampling (e.g., reward model for decoding choices).",
        "Automated seed curation using LLMs to cluster and diversify seed pools with structural/semantic cues to avoid duplicate mutations."
      ],
      "architectural_improvement_recommendations": [
        "Add constrained decoding or schema validation in the generation loop (e.g., JSON/XML schema, PHP/JS parsers) to filter/repair outputs online.",
        "Introduce an online controller to dynamically adjust n, temperature, and max_tokens based on recent coverage gains and latency budget.",
        "Use multi-stage prompting: first infer structure/grammar sketch from seeds, then generate constrained instances; cache and reuse inferred structure.",
        "Incorporate program feedback beyond edge coverage (e.g., value profiling, taint hints) to bias prompts toward mutating semantically influential regions.",
        "Replace external API with a local smaller LLM plus retrieval-augmented prompting over seed corpora for lower latency and reproducibility."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "AFL++",
        "OpenAI API"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "No training; relies on OpenAI GPT endpoints. Hyperparameters selected include max_tokens=256 (chosen to keep latency <~5s/query), n=20 completions per query, and tuned temperature. Latency per output decreases as n increases, but per-query latency increases."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Standalone greybox fuzzer environment targeting real-world open-source programs (text-based inputs)",
      "scalability_discussed": true,
      "inference_time": "Configured to keep model latency lower than ~5s per query with max_tokens=256; average latency per output decreases with larger n (e.g., n=20).",
      "deployment_challenges": [
        "LLM API latency and cost constraints",
        "Context length limits affecting number/length of completions",
        "Dependency on closed-source external service availability",
        "Parsing and validating LLM outputs to ensure syntactic correctness",
        "Potential data/privacy concerns sending seeds to cloud API",
        "Effectiveness degrades on non-trivial syntax formats"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Identify format-conforming input generation as a major limitation for both mutation-based and generative fuzzing approaches.",
      "Propose ChatFuzz, integrating a generative LLM chat mutator into a greybox fuzzer, with detailed hyperparameter exploration (model, prompts, max_tokens, n, temperature).",
      "Demonstrate empirical improvement: “improves the edge coverage by 12.77% over the SOTA greybox fuzzer (AFL++) on 12 target programs from three well-tested benchmarks.” and analyze cases where vulnerability detection is similar/better (explicit syntax) vs. worse (non-trivial syntax)."
    ]
  },
  {
    "arxiv_id": "2303.14836v1",
    "title": "Illuminati: Towards Explaining Graph Neural Networks for Cybersecurity Analysis",
    "authors": "Haoyu He; Yuede Ji; H. Howie Huang",
    "abstract": "Graph neural networks (GNNs) have been utilized to create multi-layer graph models for a number of cybersecurity applications from fraud detection to software vulnerability analysis. Unfortunately, like traditional neural networks, GNNs also suffer from a lack of transparency, that is, it is challenging to interpret the model predictions. Prior works focused on specific factor explanations for a GNN model. In this work, we have designed and implemented Illuminati, a comprehensive and accurate explanation framework for cybersecurity applications using GNN models. Given a graph and a pre-trained GNN model, Illuminati is able to identify the important nodes, edges, and attributes that are contributing to the prediction while requiring no prior knowledge of GNN models. We evaluate Illuminati in two cybersecurity applications, i.e., code vulnerability detection and smart contract vulnerability detection. The experiments show that Illuminati achieves more accurate explanation results than state-of-the-art methods, specifically, 87.6% of subgraphs identified by Illuminati are able to retain their original prediction, an improvement of 10.3% over others at 77.3%. Furthermore, the explanation of Illuminati can be easily understood by the domain experts, suggesting the significant usefulness for the development of cybersecurity applications.",
    "published_date": "2023-03-26",
    "pdf_link": "https://arxiv.org/pdf/2303.14836v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection",
      "specific_problem": "Explaining GNN decisions for code and smart contract vulnerability detection (identify important nodes, edges, and attributes driving predictions)",
      "attack_types": [
        "double free (CWE-415)",
        "use-after-free",
        "NULL pointer dereference",
        "smart contract reentrancy",
        "smart contract infinite loop"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN Explanation (mask-based)",
        "specific": "Illuminati",
        "novel_contribution": "Jointly learns and explains importance of edges, nodes, and per-node attributes via learnable masks and mutual-information-based objective; derives node importance by aggregating edge and attribute importance; model-agnostic to pre-trained GNN and requires no prior knowledge."
      },
      {
        "type": "baseline",
        "category": "GNN Explanation (mask-based)",
        "specific": "GNNExplainer",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN Explanation (parametric, edge-centric)",
        "specific": "PGExplainer",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN Explanation (mask-based)",
        "specific": "GraphMask",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN Explanation (probabilistic graphical model, node-centric)",
        "specific": "PGM-Explainer",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN Explanation (subgraph search/Shapley-based)",
        "specific": "SubgraphX",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised (downstream GNN training for vulnerability detection)",
      "Post-hoc model-agnostic explanation (mask optimization on a fixed pre-trained GNN)"
    ],
    "datasets": [
      {
        "name": "CWE vulnerability dataset (C/C++ code; e.g., CWE415_test)",
        "type": "public",
        "domain": "source_code_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Smart contract vulnerability dataset (reentrancy, infinite loop)",
        "type": "public",
        "domain": "smart_contracts",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GNNExplainer",
        "paper_reference": "Ying et al., NeurIPS 2019",
        "metric": "Prediction retention rate (% of explained subgraphs that retain original prediction)",
        "their_result": "87.6%",
        "baseline_result": null
      },
      {
        "method_name": "PGExplainer",
        "paper_reference": "Luo et al., NeurIPS 2020",
        "metric": "Prediction retention rate",
        "their_result": "87.6%",
        "baseline_result": null
      },
      {
        "method_name": "GraphMask",
        "paper_reference": "Schlichtkrull et al., 2020",
        "metric": "Prediction retention rate",
        "their_result": "87.6%",
        "baseline_result": null
      },
      {
        "method_name": "PGM-Explainer",
        "paper_reference": "Vu and Thai, NeurIPS 2020",
        "metric": "Prediction retention rate",
        "their_result": "87.6%",
        "baseline_result": null
      },
      {
        "method_name": "SubgraphX",
        "paper_reference": "Yuan et al., NeurIPS 2021",
        "metric": "Prediction retention rate",
        "their_result": "87.6%",
        "baseline_result": null
      },
      {
        "method_name": "Average of state-of-the-art baselines (Others)",
        "paper_reference": null,
        "metric": "Prediction retention rate",
        "their_result": "87.6%",
        "baseline_result": "77.3% (\"an improvement of 10.3% over others at 77.3%\")"
      }
    ],
    "performance_metrics_used": [
      "Prediction retention rate (percentage of explained subgraphs that retain original prediction)",
      "Prediction probability change between original graph and explained subgraph"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How to provide comprehensive explanations for GNNs in cybersecurity that cover nodes, edges, and attributes?",
        "How to achieve accurate explanations that retain original predictions with high probability?",
        "How to design explanations that require no prior knowledge of the pre-trained GNN model?"
      ],
      "gaps_identified": [
        "Prior GNN explainers focus on specific factors only (node-centric or edge-centric) rather than comprehensive explanations.",
        "Edge-centric methods can miss truly important nodes; node-centric methods ignore edges critical for investigation.",
        "Existing methods rarely provide per-node attribute importance; attributes are often treated globally.",
        "Many explanation approaches are not easily usable without knowledge of the model internals."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Address threat alert fatigue by providing interpretable, actionable explanations for GNN-based cybersecurity alarms; reduce manual investigation burden and increase trust in GNN predictions.",
      "potential_research_ideas": [
        "Extend Illuminati to dynamic/temporal graphs (e.g., evolving program execution or transaction graphs) with time-aware mask learning.",
        "Combine Illuminati with counterfactual explanation to generate minimal changes that flip predictions for vulnerability root-cause analysis.",
        "Incorporate causal inference to disentangle spurious correlations from causal substructures in code and smart contracts.",
        "Design human-in-the-loop explanation refinement where analysts provide feedback to iteratively adjust masks and improve fidelity.",
        "Develop adversarially robust explainers that maintain explanation stability under adversarial perturbations to graphs/attributes.",
        "Global explanation summarization across many samples to extract common vulnerability motifs/patterns for rule induction."
      ],
      "architectural_improvement_recommendations": [
        "Use discrete reparameterization (e.g., Gumbel-Softmax/Concrete) with sparsity and connectivity constraints to yield crisper subgraphs.",
        "Learn separate direction-aware masks for directed edges and explore learned asymmetric aggregation functions instead of fixed averaging.",
        "Jointly optimize node, edge, and attribute masks with multi-task losses (fidelity, sparsity, connectivity, plausibility) and add regularizers for subgraph compactness.",
        "Calibrate explanation confidence by Bayesian treatment of masks (posterior over importance) to quantify uncertainty.",
        "Integrate training-time explainability (self-explaining GNN layers or attention alignment) to reduce post-hoc discrepancies.",
        "Add constraints grounded in domain knowledge (e.g., data/control-flow validity) to avoid implausible subgraphs during mask optimization."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces Illuminati, the first GNN explanation method specialized for cybersecurity that jointly explains nodes, edges, and per-node attributes without prior model knowledge.",
      "Provides extensive evaluation on two cybersecurity applications (code and smart contract vulnerability detection) and shows higher explanation accuracy.",
      "Achieves \"87.6% of subgraphs identified by Illuminati are able to retain their original prediction, an improvement of 10.3% over others at 77.3%\".",
      "Presents case studies demonstrating how explanations help analysts interpret correct and incorrect predictions and troubleshoot models."
    ]
  },
  {
    "arxiv_id": "2304.06728v1",
    "title": "Late Breaking Results: Scalable and Efficient Hyperdimensional Computing for Network Intrusion Detection",
    "authors": "Junyao Wang; Hanning Chen; Mariam Issa; Sitao Huang; Mohsen Imani",
    "abstract": "Cybersecurity has emerged as a critical challenge for the industry. With the large complexity of the security landscape, sophisticated and costly deep learning models often fail to provide timely detection of cyber threats on edge devices. Brain-inspired hyperdimensional computing (HDC) has been introduced as a promising solution to address this issue. However, existing HDC approaches use static encoders and require very high dimensionality and hundreds of training iterations to achieve reasonable accuracy. This results in a serious loss of learning efficiency and causes huge latency for detecting attacks. In this paper, we propose CyberHD, an innovative HDC learning framework that identifies and regenerates insignificant dimensions to capture complicated patterns of cyber threats with remarkably lower dimensionality. Additionally, the holographic distribution of patterns in high dimensional space provides CyberHD with notably high robustness against hardware errors.",
    "published_date": "2023-04-11",
    "pdf_link": "https://arxiv.org/pdf/2304.06728v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Network intrusion detection using efficient hyperdimensional computing on resource-constrained/edge platforms",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Hyperdimensional Computing",
        "specific": "CyberHD",
        "novel_contribution": "Dynamic HDC framework for NIDS that identifies low-variance (insignificant) dimensions across class hypervectors, drops them based on a regeneration rate, and regenerates them with new base vectors (Gaussian) in an RBF-inspired encoder; optimized and parallelized training via matrix operations; achieves comparable accuracy with much lower physical dimensionality and improved efficiency and hardware robustness."
      },
      {
        "type": "baseline",
        "category": "Hyperdimensional Computing",
        "specific": "Baseline HDC (static encoder, no regeneration)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "Feed-forward DNN (SOTA DNNs as referenced)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-IDS-2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-IDS-2018",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "DNN (MLP)",
        "paper_reference": "[8]",
        "metric": "Accuracy",
        "their_result": "CyberHD provides comparable accuracy to SOTA DNNs.",
        "baseline_result": null
      },
      {
        "method_name": "DNN (MLP)",
        "paper_reference": "[8]",
        "metric": "Training time",
        "their_result": "CyberHD delivers on average 2.47x faster training than SOTA DNN.",
        "baseline_result": null
      },
      {
        "method_name": "SVM",
        "paper_reference": "[9]",
        "metric": "Accuracy",
        "their_result": "On average 1.63% higher accuracy than SVMs.",
        "baseline_result": null
      },
      {
        "method_name": "Baseline HDC (static, no regeneration) at D=0.5k",
        "paper_reference": "[1]",
        "metric": "Accuracy",
        "their_result": "On average 4.28% higher accuracy than baselineHD (D=0.5k).",
        "baseline_result": null
      },
      {
        "method_name": "Baseline HDC (static) at effective D'=4k",
        "paper_reference": "[1]",
        "metric": "Accuracy vs dimensionality",
        "their_result": "Comparable accuracy to baselineHD at D'=4k while using 8.0x lower physical dimensionality (D=0.5k).",
        "baseline_result": null
      },
      {
        "method_name": "Baseline HDC (static) at effective D'=4k",
        "paper_reference": "[1]",
        "metric": "Training time",
        "their_result": "On average 1.85x faster training than baselineHD (D'=4k).",
        "baseline_result": null
      },
      {
        "method_name": "Baseline HDC (static) at effective D'=4k",
        "paper_reference": "[1]",
        "metric": "Inference latency",
        "their_result": "On average 15.29x faster inference than baselineHD (D'=4k).",
        "baseline_result": null
      },
      {
        "method_name": "DNN (MLP)",
        "paper_reference": "[8]",
        "metric": "Robustness to random hardware bit flips",
        "their_result": "With 1-bit hypervectors, CyberHD shows on average 12.90x higher robustness than DNN.",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Training time",
      "Inference latency",
      "Energy efficiency (normalized vs 1-bit CPU)",
      "Power consumption (FPGA)",
      "Robustness to random hardware bit flips"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Existing HDC approaches use static encoders that cannot distinguish the importance of each dimension, requiring very high dimensionality and many training iterations to achieve reasonable accuracy.",
        "High dimensionality and static encoders cause inefficiency and latency, limiting scalability for large network intrusion detection workloads."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Enable real-time, robust, and efficient intrusion detection on resource-constrained/edge devices by improving HDC’s learning efficiency and reducing required dimensionality while maintaining accuracy and robustness.",
      "potential_research_ideas": [
        "Online/streaming CyberHD for NIDS with concept drift handling and continual regeneration in non-stationary traffic.",
        "Learned/optimizable encoders: make base vectors or RBF parameters trainable (e.g., gradient-based or evolutionary search) instead of purely random Gaussian regeneration.",
        "Adaptive regeneration-rate scheduling (per-class or per-feature) driven by validation performance or bandit/RL to balance accuracy and efficiency.",
        "Hybrid systems combining CyberHD with lightweight deep models (e.g., small MLP or temporal CNN) for sequence/flow-level context aggregation.",
        "Adversarial robustness study against evasion/poisoning attacks tailored to HDC encoders and regeneration process; design defenses leveraging holographic properties.",
        "Deploy on SmartNIC/DPUs or IoT gateways; co-design data-plane feature extraction with CyberHD accelerator for line-rate NIDS.",
        "Privacy-preserving CyberHD (e.g., secure enclaves or homomorphic-friendly binary operations) for sensitive network data.",
        "AutoML to jointly tune dimensionality, bitwidth, and regeneration policy under hardware/latency constraints."
      ],
      "architectural_improvement_recommendations": [
        "Replace variance-only criterion with information-theoretic or discriminative criteria (e.g., Fisher score, mutual information) to select/drop/regenerate dimensions.",
        "Make the RBF-inspired encoder parameters (centers, widths) trainable and optimized jointly with class hypervectors.",
        "Use mixture-of-experts or subspace specialization where different hypervector subspaces specialize to different attack families.",
        "Introduce multi-resolution or hierarchical hypervectors to capture both coarse and fine-grained patterns.",
        "Incorporate feature selection or learned projections prior to HDC encoding to reduce redundancy and improve separability.",
        "Implement adaptive precision (bitwidth scaling per stage) to maximize robustness and efficiency on hardware.",
        "GPU/ASIC accelerator and memory-optimized dataflows to further scale throughput; exploit sparsity if present in hypervectors."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Evaluated on Intel Core i9-12900 CPU and Xilinx Alveo U50 FPGA; CyberHD FPGA accelerator <20 W at 200 MHz; cross-bitwidth experiments (1–32 bits) and varying effective dimensionality."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Prototype accelerator on Xilinx Alveo U50 FPGA; edge deployment targeted",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "CyberHD: a dynamic HDC framework that identifies low-variance (insignificant) dimensions across classes, drops them, and regenerates them with new Gaussian base vectors in an RBF-inspired encoder to enhance discrimination at lower dimensionality.",
      "Optimized and parallelized HDC training via matrix operations, improving efficiency and scalability.",
      "Applied dynamic HDC to cybersecurity NIDS domain (first application of this dynamic HDC approach to cyber security, as claimed).",
      "Achieves comparable accuracy to SOTA DNNs while providing, on average, 1.63% higher accuracy than SVMs and 4.28% higher than baseline HDC at the same physical dimensionality (D=0.5k).",
      "Provides comparable accuracy to baseline HDC at effective D'=4k using 8.0x lower physical dimensionality, and improves efficiency (2.47x faster training vs DNN; 1.85x faster training and 15.29x faster inference vs baseline HDC at D'=4k).",
      "Demonstrates strong robustness to hardware bit flips, with 1-bit hypervectors yielding on average 12.90x higher robustness than DNN; evaluates cross-platform energy efficiency on CPU and FPGA with bitwidth and dimensionality trade-offs."
    ]
  },
  {
    "arxiv_id": "2303.18138v2",
    "title": "BERT4ETH: A Pre-trained Transformer for Ethereum Fraud Detection",
    "authors": "Sihao Hu; Zhen Zhang; Bingqiao Luo; Shengliang Lu; Bingsheng He; Ling Liu",
    "abstract": "As various forms of fraud proliferate on Ethereum, it is imperative to safeguard against these malicious activities to protect susceptible users from being victimized. While current studies solely rely on graph-based fraud detection approaches, it is argued that they may not be well-suited for dealing with highly repetitive, skew-distributed and heterogeneous Ethereum transactions. To address these challenges, we propose BERT4ETH, a universal pre-trained Transformer encoder that serves as an account representation extractor for detecting various fraud behaviors on Ethereum. BERT4ETH features the superior modeling capability of Transformer to capture the dynamic sequential patterns inherent in Ethereum transactions, and addresses the challenges of pre-training a BERT model for Ethereum with three practical and effective strategies, namely repetitiveness reduction, skew alleviation and heterogeneity modeling. Our empirical evaluation demonstrates that BERT4ETH outperforms state-of-the-art methods with significant enhancements in terms of the phishing account detection and de-anonymization tasks. The code for BERT4ETH is available at: https://github.com/git-disl/BERT4ETH.",
    "published_date": "2023-03-29",
    "pdf_link": "https://arxiv.org/pdf/2303.18138v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Fraud Detection",
      "specific_problem": "Ethereum phishing account detection and account de-anonymization via account representation learning",
      "attack_types": [
        "Phishing scams",
        "Money laundering (coin mixing)",
        "Pump-and-dump",
        "Ponzi schemes",
        "ICO scams",
        "Bot arbitrage"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT-style Transformer encoder",
        "novel_contribution": "Pre-trained universal account representation extractor for Ethereum transactions with Masked Address Prediction (MAP) objective"
      },
      {
        "type": "primary",
        "category": "Self-supervised learning",
        "specific": "Masked Address Prediction with contrastive loss",
        "novel_contribution": "Predict masked addresses using contrastive loss over sampled negatives instead of full softmax due to massive address vocabulary"
      },
      {
        "type": "primary",
        "category": "Contrastive Learning",
        "specific": "Frequency-aware negative sampling and intra-batch negative sharing",
        "novel_contribution": "Alleviates skewed address frequency (power-law) by emphasizing high-frequency addresses as negatives and sharing negatives across batch to achieve very high negative-to-positive ratios"
      },
      {
        "type": "primary",
        "category": "Regularization",
        "specific": "High masking ratio and high dropout during pre-training",
        "novel_contribution": "High masking ratio (≈80%) or high dropout ratio (≈80%) to mitigate label leakage from repetitive transactions"
      },
      {
        "type": "primary",
        "category": "Sequence modeling",
        "specific": "Heterogeneity modeling",
        "novel_contribution": "Feature embeddings for address, account type, in/out type, amount (binned), count (binned), timestamp, position; separation into in/out subsequences; log encoder for ERC-20 token transfer traces"
      },
      {
        "type": "baseline",
        "category": "Graph embedding",
        "specific": "Trans2Vec",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph embedding",
        "specific": "Diff2Vec",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph embedding",
        "specific": "Role2Vec",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GCN/GAT-based (e.g., TTAGNN, HGATE)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient boosting",
        "specific": "LightGBM (as classifier on learned embeddings in prior work)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised pre-training",
      "Supervised fine-tuning",
      "Contrastive learning"
    ],
    "datasets": [
      {
        "name": "BERT4ETH Ethereum transaction corpus (pre-training)",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": "https://github.com/git-disl/BERT4ETH",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Phishing account detection dataset (Ethereum)",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": "https://github.com/git-disl/BERT4ETH",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "ENS de-anonymization dataset",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": "https://github.com/git-disl/BERT4ETH",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Tornado (0.1 ETH) de-anonymization dataset",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": "https://github.com/git-disl/BERT4ETH",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Raw Ethereum data via Ethereum-ETL (transactions.csv, trace.csv)",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": "https://ethereum-etl.readthedocs.io/en/latest/schema",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Trans2Vec",
        "paper_reference": "Phishing detection prior work [31] (as cited in paper)",
        "metric": "F1",
        "their_result": "“achieving a F1 improvement of 21.61 absolute percentage (AP) for phishing detection”",
        "baseline_result": null
      },
      {
        "method_name": "Diff2Vec",
        "paper_reference": "Considered SOTA for de-anonymization [25] (as cited in paper)",
        "metric": "Hit Ratio@1",
        "their_result": "“Hit Ratio@1 improvement of 13.54 … on the ENS … dataset”",
        "baseline_result": null
      },
      {
        "method_name": "Role2Vec",
        "paper_reference": "Considered SOTA for de-anonymization [1] (as cited in paper)",
        "metric": "Hit Ratio@1",
        "their_result": "“Hit Ratio@1 improvement of … 21.57 AP … on the Tornado (0.1ETH) dataset”",
        "baseline_result": null
      },
      {
        "method_name": "HGATE",
        "paper_reference": "Zhou et al. [34] (phishing detection)",
        "metric": "F1",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "TTAGNN (with GAT + LSTM fusion)",
        "paper_reference": "Li et al. [20]",
        "metric": "F1",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "F1",
      "Hit Ratio@1"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a pre-trained Transformer encoder capture dynamic sequential patterns in Ethereum transactions better than graph-based methods for fraud detection?",
        "How to address high repetitiveness, skewed address frequency, and heterogeneity in Ethereum when pre-training a BERT-like model?",
        "Can a universal pre-trained model support multiple downstream fraud tasks (e.g., phishing detection, de-anonymization) with minimal adaptation?"
      ],
      "gaps_identified": [
        "Graph methods collapse multi-edges and fail to capture sequential patterns inherent in transactions.",
        "GNNs on skew-distributed Ethereum graphs suffer from noise as hops increase; limiting hops restricts capacity.",
        "Existing works are task-specific end-to-end and lack a universal pre-trained representation for various fraud tasks."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Graph-based Ethereum fraud detection struggles with highly repetitive, skew-distributed, and heterogeneous transactions; a pre-trained Transformer could universally encode account behaviors.",
      "potential_research_ideas": [
        "Extend BERT4ETH to cross-chain fraud detection with shared or federated pre-training across multiple blockchains.",
        "Incorporate internal transactions and full execution traces (call graphs) via program-analysis-informed embeddings.",
        "Online/streaming pre-training to adapt to evolving fraud patterns and concept drift.",
        "Adversarial pre-training to harden against evasion strategies (e.g., synthetic repetitive/noise patterns).",
        "Unified multi-task fine-tuning jointly optimizing phishing detection, bot detection, and de-anonymization.",
        "Leverage retrieval-augmented or memory-based modules to handle extremely popular addresses without representation collapse.",
        "Calibrated uncertainty estimation for triage and human-in-the-loop investigation.",
        "Privacy-conscious de-anonymization risk assessment leveraging the learned representations."
      ],
      "architectural_improvement_recommendations": [
        "Use span masking or motif-based masking (mask groups of transactions) to learn higher-order behavioral patterns.",
        "Adopt time-aware positional encodings (e.g., continuous-time encodings) to better capture irregular transaction intervals.",
        "Hybrid GNN-Transformer: propagate representations over a pruned/multi-edge graph and sequence-encode local transaction windows.",
        "Long-sequence Transformers (e.g., Performer/Longformer) to handle very long account histories efficiently.",
        "Temperature-scaled contrastive loss with adaptive sampling to further counter popularity bias.",
        "Sampled softmax or adaptive softmax over address vocabulary as an alternative to contrastive loss for scalability.",
        "Richer heterogeneity modeling via typed attention for transaction types, token standards (ERC-20/721), and account categories.",
        "Curriculum masking/dropout schedules to balance label-leakage mitigation and context sufficiency during pre-training."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/git-disl/BERT4ETH",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Massive address vocabulary precludes full softmax; requires negative sampling and contrastive objectives.",
        "Highly skewed popularity of addresses risks representation collapse without frequency-aware sampling.",
        "High transaction repetitiveness causes label leakage in masked prediction unless masked/dropout ratios are adjusted."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A universal pre-trained Transformer (BERT4ETH) for Ethereum fraud detection that encodes account transaction sequences.",
      "Three strategies for effective pre-training on Ethereum: repetitiveness reduction (de-duplication; high masking/dropout), skew alleviation (frequency-aware negatives; intra-batch sharing), and heterogeneity modeling (feature embeddings; in/out separation; ERC-20 log encoder).",
      "State-of-the-art results on phishing account detection and de-anonymization with large absolute improvements, and release of code and dataset."
    ]
  },
  {
    "arxiv_id": "2306.07972v1",
    "title": "Leveraging Machine Learning for Multichain DeFi Fraud Detection",
    "authors": "Georgios Palaiokrassas; Sandro Scherrers; Iason Ofeidis; Leandros Tassiulas",
    "abstract": "Since the inception of permissionless blockchains with Bitcoin in 2008, it became apparent that their most well-suited use case is related to making the financial system and its advantages available to everyone seamlessly without depending on any trusted intermediaries. Smart contracts across chains provide an ecosystem of decentralized finance (DeFi), where users can interact with lending pools, Automated Market Maker (AMM) exchanges, stablecoins, derivatives, etc. with a cumulative locked value which had exceeded 160B USD. While DeFi comes with high rewards, it also carries plenty of risks. Many financial crimes have occurred over the years making the early detection of malicious activity an issue of high priority. The proposed framework introduces an effective method for extracting a set of features from different chains, including the largest one, Ethereum and it is evaluated over an extensive dataset we gathered with the transactions of the most widely used DeFi protocols (23 in total, including Aave, Compound, Curve, Lido, and Yearn) based on a novel dataset in collaboration with Covalent. Different Machine Learning methods were employed, such as XGBoost and a Neural Network for identifying fraud accounts detection interacting with DeFi and we demonstrate that the introduction of novel DeFi-related features, significantly improves the evaluation results, where Accuracy, Precision, Recall, F1-score and F2-score where utilized.",
    "published_date": "2023-05-17",
    "pdf_link": "https://arxiv.org/pdf/2306.07972v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain/Cryptocurrency Security",
      "subdomain": "DeFi Fraud Detection",
      "specific_problem": "Supervised detection of malicious Ethereum/DeFi addresses using DeFi-interaction features across multiple chains and protocols",
      "attack_types": [
        "phishing",
        "hack",
        "heist",
        "scam",
        "Ponzi scheme",
        "fake ICO",
        "impersonation",
        "scam lotteries",
        "mirroring websites"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost",
        "novel_contribution": "Applied with a novel, large set of 414 DeFi-specific engineered features; identified as a top performer for malicious DeFi address detection"
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": "Feed-forward ANN (5 layers)",
        "novel_contribution": "Simple ANN (Dense[40]-Dropout[0.3]-Dense[10]-Dense[5]-Dense[1]) trained on 414 DeFi features; competitive with XGBoost"
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": "Baseline classical model; showed high precision but low recall for malicious class"
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "RBF kernel",
        "novel_contribution": "Baseline classical model; showed lower precision but higher recall for malicious class relative to RF"
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": "Baseline linear model; performed worst overall"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "DeFi Transactions Dataset (23 protocols, 12 chains)",
        "type": "proprietary",
        "domain": "defi_events",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Covalent decoded DeFi events",
        "type": "proprietary",
        "domain": "defi_events",
        "link": "https://www.covalenthq.com/",
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Compiled labeled malicious Ethereum addresses ( >10,000 total; 81 that interacted with DeFi)",
        "type": "proprietary",
        "domain": "labeled_addresses",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Google BigQuery Public Ethereum Dataset",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": "https://console.cloud.google.com/marketplace/product/ethereum/crypto-ethereum-blockchain",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CryptoScamDB",
        "type": "public",
        "domain": "labeled_addresses",
        "link": "https://cryptoscamdb.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Etherscan labels",
        "type": "public",
        "domain": "labeled_addresses",
        "link": "https://etherscan.io/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Hall et al. labeled dataset (5212 addresses) [26]",
        "type": "public",
        "domain": "labeled_addresses",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Tether Blacklisted Addresses",
        "type": "public",
        "domain": "labeled_addresses",
        "link": "https://cointelegraph.com/news/tether-blacklists-39-ethereum-addresses-worth-over-46-million",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MyEtherWallet blacklist",
        "type": "public",
        "domain": "labeled_addresses",
        "link": "https://github.com/MyEtherWallet/ethereum-lists/blob/master/src/addresses/addresses-darklist.json",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Farrugia et al. public dataset (2179 Ethereum accounts) [17]",
        "type": "public",
        "domain": "labeled_addresses",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "XBlock Ethereum Datasets",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": "http://xblock.pro/tx/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Al-E'mari et al. Labeled Transactions-based Dataset of Ethereum Network",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": "https://github.com/salam-ammari/Labeled-Transactions-based-Dataset-of-Ethereum-Network",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "ANN (vs. XGBoost)",
        "paper_reference": null,
        "metric": "Precision (malicious class)",
        "their_result": "0.80 (for NN)",
        "baseline_result": "0.93 (for XGB) — quote: “XGBoost and a Neural Network are the best classifiers… with a Precision of 0.80-0.93 (for NN vs. XGB respectively)”"
      },
      {
        "method_name": "ANN (vs. XGBoost)",
        "paper_reference": null,
        "metric": "Recall (malicious class)",
        "their_result": "0.74 (for NN)",
        "baseline_result": "0.85 (for XGB) — quote: “…Recall of 0.74-0.85 (for NN vs. XGB respectively)”"
      },
      {
        "method_name": "ANN (vs. XGBoost)",
        "paper_reference": null,
        "metric": "F1-score (malicious class)",
        "their_result": "0.76 (for NN)",
        "baseline_result": "0.85 (for XGB) — quote: “…F1-Score of 0.76-0.85 (for NN vs. XGB respectively)”"
      },
      {
        "method_name": "Transactional features only (vs. DeFi-related features included)",
        "paper_reference": null,
        "metric": "F1-score (malicious class)",
        "their_result": "0.85 (with DeFi-related features; best model)",
        "baseline_result": "0.08 (transactional non-DeFi features only) — quote: “the same models for only transactional non-DeFi related features yields an F1-Score of 0.08”"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Qualitative (Precision/Recall tradeoff)",
        "their_result": "High precision, low recall (malicious class)",
        "baseline_result": null
      },
      {
        "method_name": "SVM (RBF)",
        "paper_reference": null,
        "metric": "Qualitative (Precision/Recall tradeoff)",
        "their_result": "Lower precision, higher recall than RF (malicious class)",
        "baseline_result": null
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "Overall performance",
        "their_result": "Worst overall among tested models",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "F2-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can engineered DeFi-interaction features improve supervised detection of malicious addresses compared to transactional features alone?",
        "Which supervised ML models (XGBoost, ANN, SVM, RF, LR) perform best for DeFi fraud detection under severe class imbalance?",
        "Does oversampling (SMOTE) help mitigate class imbalance in DeFi malicious address detection?",
        "Are multichain and per-protocol interaction statistics predictive for early detection of malicious wallets?"
      ],
      "gaps_identified": [
        "Prior works largely rely on generic transactional features and do not incorporate DeFi protocol-interaction features.",
        "Lack of a labeled dataset specifically linking malicious addresses to DeFi interactions; only 81/10,000+ known-malicious addresses interacted with major DeFi protocols.",
        "Severe class imbalance in blockchain/DeFi fraud datasets.",
        "Limited coverage of multichain, multi-protocol behaviors in existing studies."
      ],
      "limitations": [
        "Very small positive class: only 81 malicious addresses that interacted with DeFi protocols.",
        "Imbalanced dataset requiring oversampling (SMOTE) during training.",
        "Dependence on publicly available labels from third-party sources; authors do not perform labeling/verification.",
        "Datasets (including Covalent-derived data and compiled labels) are not released, hindering reproducibility.",
        "Focus on major protocols and a defined time window; potential generalization issues to other protocols/time periods."
      ],
      "future_work": [
        "Explore more machine learning algorithms and specifically Deep Learning algorithms.",
        "Integrate additional preprocessing techniques in the ML pipeline.",
        "Consider additional oversampling and undersampling methods."
      ],
      "motivation": "Early detection of malicious activity in rapidly growing DeFi ecosystems with high financial risk by leveraging ML on multichain DeFi-interaction features.",
      "potential_research_ideas": [
        "Graph-based modeling (GNNs) over address–contract–protocol bipartite/multilayer graphs to capture structural DeFi interactions for fraud detection.",
        "Temporal/sequence models (RNN/Transformer/Temporal GNN) for early-warning detection using block-time-ordered DeFi events.",
        "Semi-supervised learning and label propagation across transaction graphs to expand scarce DeFi-malicious labels.",
        "Unsupervised/weakly supervised anomaly detection for zero-day DeFi fraud patterns across chains.",
        "Cross-chain entity resolution to link addresses across L1/L2s and bridges for holistic risk scoring.",
        "Contrastive/self-supervised representation learning of wallet behaviors to reduce label dependence.",
        "Active learning with investigators to prioritize uncertain addresses for manual review to grow labeled sets.",
        "Domain adaptation/continual learning to handle concept drift as DeFi protocols upgrade and new chains emerge."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment SMOTE with class-weighted losses, focal loss, or balanced bagging to reduce overfitting risk on synthetic samples.",
        "Hyperparameter optimization (e.g., Bayesian search) and calibrated probability outputs (Platt/Isotonic) for decision-threshold tuning under imbalance.",
        "Ensemble models combining XGBoost and calibrated neural networks to exploit complementary precision/recall tradeoffs.",
        "Adopt SHAP-based feature attribution for interpretability and feature selection/stability analysis of DeFi features.",
        "Temporal cross-validation (rolling-origin) and out-of-time validation to assess generalization and drift.",
        "Evaluate with PR-AUC in addition to F-scores for imbalanced settings; report per-class metrics with CIs.",
        "Build a graph feature pipeline (e.g., node2vec/GraphSAGE embeddings) to augment tabular DeFi features.",
        "Deploy streaming feature computation and online learning for near-real-time detection."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "scikit-learn",
        "TensorFlow"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "Ethereum full archive node (Intel i7-11700 8-core 4.8GHz, 32GB RAM, 10TB SSD) for data; models trained with 5-fold CV; ANN trained for 30 epochs, batch size 128."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Severe class imbalance and scarcity of DeFi-malicious labeled addresses.",
        "Evolving DeFi protocols and multichain heterogeneity complicate stable feature engineering."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Collected DeFi transactions across 23 protocols and 12 chains, creating a large multichain DeFi dataset (54M+ transactions for ~550k addresses).",
      "Compiled public labeled malicious address sources (>10,000 addresses) and identified those interacting with DeFi (81 addresses), forming the first labeled dataset for Ethereum DeFi malicious accounts detection.",
      "Introduced 414 DeFi-related engineered features (plus 9 transactional features) capturing events, fees, per-protocol, per-chain, temporal aggregations, and token interactions.",
      "Developed and evaluated a supervised ML framework (XGBoost, ANN, SVM, Random Forest, Logistic Regression) with 5-fold CV and SMOTE for imbalance.",
      "Demonstrated significant performance gains from DeFi features; best models achieved Precision 0.80–0.93, Recall 0.74–0.85, F1 0.76–0.85 for the malicious class, whereas transactional-only features yielded F1 ≈ 0.08."
    ]
  },
  {
    "arxiv_id": "2304.07989v3",
    "title": "IMCDCF: An Incremental Malware Detection Approach Using Hidden Markov Models",
    "authors": "Ran Liu; Charles Nicholas",
    "abstract": "The popularity of dynamic malware analysis has grown significantly, as it enables analysts to observe the behavior of executing samples, thereby enhancing malware detection and classification decisions. With the continuous increase in new malware variants, there is an urgent need for an automated malware analysis engine capable of accurately identifying malware samples. In this paper, we provide a brief overview of malware detection and classification methodologies. Moreover, we introduce a novel framework tailored for the dynamic analysis environment, called the Incremental Malware Detection and Classification Framework (IMDCF). IMDCF offers a comprehensive solution for general-purpose malware detection and classification, achieving an accuracy rate of 96.49% while maintaining a simple architecture.",
    "published_date": "2023-04-17",
    "pdf_link": "https://arxiv.org/pdf/2304.07989v3",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Dynamic/Behavior-based Malware Detection",
      "specific_problem": "Incremental malware detection and family classification from dynamic opcode sequences using HMMs",
      "attack_types": [
        "Windows malware (Zeroaccess)",
        "Windows malware (Zbot)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Hidden Markov Model",
        "specific": "Discrete-emission HMM on opcode symbols",
        "novel_contribution": "Per-family ensembles of HMMs trained on disjoint subsets; incremental scoring of sliding sequences with threshold-based novelty detection"
      },
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": "Majority vote over family HMMs; mean score aggregation within family",
        "novel_contribution": "Multiple HMMs per family each trained on ≤30% of features/files; mean of HMM scores per family; longer sequence construction with majority vote to break ties"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Online/Incremental",
      "Generative modeling",
      "Open-set/novelty detection"
    ],
    "datasets": [
      {
        "name": "Zeroaccess malware opcode sequences",
        "type": "private",
        "domain": "dynamic_execution_traces (opcodes)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Zbot malware opcode sequences",
        "type": "private",
        "domain": "dynamic_execution_traces (opcodes)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Benign software opcode sequences",
        "type": "private",
        "domain": "dynamic_execution_traces (opcodes)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Log Likelihood per Opcode (LLPO)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can an HMM-based framework incrementally detect and classify malware from dynamic behavior while the sample is still executing?",
        "Can novelty (previously unseen families) be detected via thresholding HMM log-likelihoods and extending sequences to disambiguate families?",
        "How does observation sequence length impact classification accuracy?"
      ],
      "gaps_identified": [
        "“there is a growing need for an automated malware analysis engine that can accurately detect malware samples.”",
        "Lack of methods tailored to incremental, during-execution classification in dynamic analysis settings."
      ],
      "limitations": [
        "Evaluation limited to two malware families (Zeroaccess: 1,308 files; Zbot: 2,136 files) and one benign set.",
        "No quantitative comparison against other malware detection/classification methods.",
        "Dataset and code are not released; important implementation details (e.g., number of HMM states, exact thresholds) are unspecified.",
        "Features reduced to 26 most frequent opcodes plus a catch-all symbol ‘T’, potentially losing information.",
        "Claim of detection with a single opcode is made without detailed substantiation."
      ],
      "future_work": [
        "“We are excited about the possibility of detecting malware using short sequences and plan to apply this model to other tasks.”"
      ],
      "motivation": "Rising volume and variation of malware and the popularity of dynamic analysis motivate an automated, accurate, incrementally operating detection and classification engine.",
      "potential_research_ideas": [
        "Extend to more malware families and evaluate open-set recognition performance with calibrated thresholds and ROC/PR analysis.",
        "Incorporate additional dynamic features (system/API calls, call arguments, registry/file/network events) and multimodal fusion with opcode sequences.",
        "Replace or augment discrete HMMs with GMM-HMM, HSMM, or neural sequence models (e.g., RNNs/Transformers) for improved modeling of long-range behavior.",
        "Online/continual learning for HMM parameters to handle concept drift and emerging families without full retraining.",
        "Open-set Bayesian calibration of likelihoods and likelihood-ratio tests for robust novelty detection.",
        "Adversarial robustness study against behavior obfuscation (e.g., no-op padding, API shims) and defenses (sequence sanitization, randomization).",
        "Interpretable HMMs with state semantics and post-hoc explanations mapping states/observations to behavior categories.",
        "Semi-supervised clustering of novel families and active learning loop with analysts.",
        "Benchmarking against standard dynamic malware datasets and strong discriminative baselines (SVM/RF over n-grams, HMM vs. LSTM/Transformer)."
      ],
      "architectural_improvement_recommendations": [
        "Adopt GMM-HMM or HSMM to capture duration and multi-modal emissions; tune number of states via BIC/AIC.",
        "Use hybrid models: HMM embeddings plus discriminative classifier, or HMMs initialized/regularized by neural encoders.",
        "Calibrate per-family thresholds using validation sets; use log-likelihood ratios between best/second-best families instead of raw thresholds.",
        "Leverage ensemble diversity explicitly (bagging on files and features) and weighted voting based on validation performance.",
        "Integrate system-call sequences and arguments; perform late fusion with opcode HMM scores.",
        "Implement online EM for incremental updates; add drift detection to trigger model refresh.",
        "Report standardized metrics (ROC-AUC, F1, detection latency vs. accuracy) and measure computational/inference latency."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Windows sandbox; dynamic analysis environment",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces IMDCF, an incremental malware detection and classification framework for dynamic analysis using HMMs.",
      "Claims high accuracy: “IMDCF provides a end-to-end solution for general-purpose malware detection and classification with 96.49% accuracy and simple architecture.”",
      "Demonstrates malware detection accuracy of “0.9091” and per-family classification accuracy of “0.8384” on Zeroaccess/Zbot vs. benign.",
      "Shows that accuracy increases with observation sequence length and that the framework can operate incrementally during execution.",
      "Simple architecture employing per-family ensembles of HMMs and threshold-based novelty detection."
    ]
  },
  {
    "arxiv_id": "2304.04398v1",
    "title": "Ransomware Detection and Classification Strategies",
    "authors": "Aldin Vehabovic; Nasir Ghani; Elias Bou-Harb; Jorge Crichigno; Aysegul Yayimli",
    "abstract": "Ransomware uses encryption methods to make data inaccessible to legitimate users. To date a wide range of ransomware families have been developed and deployed, causing immense damage to governments, corporations, and private users. As these cyberthreats multiply, researchers have proposed a range of ransomware detection and classification schemes. Most of these methods use advanced machine learning techniques to process and analyze real-world ransomware binaries and action sequences. Hence this paper presents a survey of this critical space and classifies existing solutions into several categories, i.e., including network-based, host-based, forensic characterization, and authorship attribution. Key facilities and tools for ransomware analysis are also presented along with open challenges.",
    "published_date": "2023-04-10",
    "pdf_link": "https://arxiv.org/pdf/2304.04398v1",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Ransomware Detection and Classification",
      "specific_problem": "Survey and taxonomy of ransomware detection and classification strategies (network-based, host-based, forensic characterization, authorship attribution) with tools and open challenges",
      "attack_types": [
        "ransomware",
        "locker ransomware",
        "cryptographic ransomware",
        "double-extortion ransomware",
        "worm-like propagation"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Ensemble - Random Forest",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "Random Tree / Decision Trees",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Bayesian Network",
        "specific": "Bayes network",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Support Vector Machine",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Neural Network - CNN",
        "specific": "CNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "Bi-LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Attention RNN",
        "specific": "Attention-based Bi-LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "k-NN",
        "specific": "k-Nearest Neighbors",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "Multi-layer Perceptron",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Naive Bayes",
        "specific": "Naive Bayes",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Anomaly Detection",
        "specific": "Unsupervised LSTM encoding on hardware performance counter time series",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "VirusTotal",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://www.virustotal.com",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusShare",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://virusshare.com",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UNVEIL malware dataset (148,223 samples)",
        "type": "proprietary",
        "domain": "log_files, file_operations, system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Locky ransomware network traffic testbed traces",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "SMB/REDFISH ransomware network traces",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Rapid ransomware detection dataset (4 strains, 220 samples each)",
        "type": "proprietary",
        "domain": "host_activity, network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "DeepRan 63-day Windows host network logs (2 users, 17 families)",
        "type": "proprietary",
        "domain": "network_traffic, log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Pre-attack API call dataset (117 ransomware across 30 families + 98 benign)",
        "type": "proprietary",
        "domain": "API_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "File I/O ransomware dataset (504 samples from 12 families; evaluated with 9,432 samples)",
        "type": "proprietary",
        "domain": "file_operations, I/O_requests",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "detection rate",
      "accuracy",
      "true positive rate (TPR)",
      "false negative rate (FNR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Many ransomware detection methods are labor intensive, requiring sandbox runs, reverse engineering, or host-based countermeasures",
        "Early-state ('paranoia') behaviors vary and some families do not exhibit detectable pre-execution checks, causing higher false negatives for such detectors",
        "Lack of standardized public benchmarks and comprehensive, labeled datasets across families and environments",
        "Stealthy and intermittent C&C communications and partial-file encryption reduce detectability by network/host defenses",
        "Limited cross-layer (network + host) fused detection frameworks in practice"
      ],
      "limitations": [
        "Survey focuses on Windows-based ransomware",
        "Survey scope centers on detection and classification; recovery/decryption methods are not reviewed"
      ],
      "future_work": [],
      "motivation": "Provide a comprehensive survey and taxonomy of ransomware detection and classification approaches, review analysis tools, and outline open challenges to inform future research and defenses.",
      "potential_research_ideas": [
        "Design a unified, cross-layer ransomware detector that fuses network flows, API calls, file I/O, and HPC time series for robust early-stage detection",
        "Develop self-supervised pretraining on large unlabeled malware telemetry (network and host logs) to improve zero-day ransomware detection",
        "Construct and release a standardized, multi-organization benchmark for ransomware with realistic benign workloads and detailed family labels",
        "Investigate authorship attribution for ransomware using multimodal code stylometry (binaries, strings, API sequences) to aid threat intelligence",
        "Explore privacy-preserving federated learning for enterprise ransomware detection without sharing raw logs",
        "Evaluate and harden ransomware detectors against adversarial and evasive behaviors (partial encryption, C&C obfuscation)",
        "Extend detection to non-Windows ecosystems (Linux servers, macOS, mobile/IoT) with tailored behavioral features"
      ],
      "architectural_improvement_recommendations": [
        "Adopt multimodal Transformer architectures that jointly model sequences of API calls, file I/O, and network conversations with cross-attention",
        "Use graph neural networks over process-file-registry interaction graphs to capture complex ransomware behaviors",
        "Apply contrastive and masked-modeling objectives for pretraining on unlabeled telemetry and fine-tune for detection/classification",
        "Incorporate online/streaming anomaly detection with concept drift handling for evolving ransomware tactics",
        "Leverage few-shot/meta-learning to rapidly adapt to emerging ransomware families with scarce labeled samples",
        "Integrate SDN controllers with learned detectors for closed-loop mitigation (rate limiting, quarantine) with minimal collateral damage",
        "Add interpretable attribution (e.g., SHAP over event sequences) to support analyst triage and response"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Stealthy and intermittent C&C communications hinder network-only detection",
        "Partial and selective file encryption reduces obvious host-side signatures",
        "Pre-attack 'paranoia' checks and anti-analysis behavior evade sandbox-based detection",
        "High CPU/disk usage can be transient and confounded with benign intensive workloads"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comprehensive survey of ransomware detection and classification approaches",
      "Taxonomy of solutions: network-based, host-based, forensic characterization, authorship attribution",
      "Overview of ransomware kill chain and ecosystem",
      "Review of key facilities and tools for ransomware analysis",
      "Discussion of open challenges",
      "Focus on Windows-based ransomware families"
    ]
  },
  {
    "arxiv_id": "2304.14746v1",
    "title": "FlowTransformer: A Transformer Framework for Flow-based Network Intrusion Detection Systems",
    "authors": "Liam Daly Manocchio; Siamak Layeghy; Wai Weng Lo; Gayan K. Kulatilleke; Mohanad Sarhan; Marius Portmann",
    "abstract": "This paper presents the FlowTransformer framework, a novel approach for implementing transformer-based Network Intrusion Detection Systems (NIDSs). FlowTransformer leverages the strengths of transformer models in identifying the long-term behaviour and characteristics of networks, which are often overlooked by most existing NIDSs. By capturing these complex patterns in network traffic, FlowTransformer offers a flexible and efficient tool for researchers and practitioners in the cybersecurity community who are seeking to implement NIDSs using transformer-based models. FlowTransformer allows the direct substitution of various transformer components, including the input encoding, transformer, classification head, and the evaluation of these across any flow-based network dataset. To demonstrate the effectiveness and efficiency of the FlowTransformer framework, we utilise it to provide an extensive evaluation of various common transformer architectures, such as GPT 2.0 and BERT, on three commonly used public NIDS benchmark datasets. We provide results for accuracy, model size and speed. A key finding of our evaluation is that the choice of classification head has the most significant impact on the model performance. Surprisingly, Global Average Pooling, which is commonly used in text classification, performs very poorly in the context of NIDS. In addition, we show that model size can be reduced by over 50\\%, and inference and training times improved, with no loss of accuracy, by making specific choices of input encoding and classification head instead of other commonly used alternatives.",
    "published_date": "2023-04-28",
    "pdf_link": "https://arxiv.org/pdf/2304.14746v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Flow-based network intrusion detection using transformer architectures on sequences of flows (NetFlow/IPFIX) with interchangeable input encodings and classification heads",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT (encoder-only)",
        "novel_contribution": "Evaluated within the FlowTransformer framework for NIDS; analysis of how classification head choices impact performance, model size, and speed"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "GPT-2 (decoder-only)",
        "novel_contribution": "Evaluated within the FlowTransformer framework for NIDS; compared across datasets and heads for accuracy/model size/speed"
      },
      {
        "type": "primary",
        "category": "Embedding/Encoding",
        "specific": "Lookup-based embedding layer for categorical features",
        "novel_contribution": "Provided as an interchangeable input encoding option for flow/tabular fields within FlowTransformer"
      },
      {
        "type": "primary",
        "category": "Embedding/Encoding",
        "specific": "Fully-connected (dense) embedding layer for categorical features",
        "novel_contribution": "Provided as an interchangeable input encoding option; part of the demonstrated design choices impacting accuracy/speed/model size"
      },
      {
        "type": "baseline",
        "category": "Embedding/Encoding",
        "specific": "One-hot encoding (frequency-limited) concatenated with numerical features",
        "novel_contribution": "Discussed/implemented as an alternative input encoding for tabular flow fields"
      },
      {
        "type": "primary",
        "category": "Pooling/Head",
        "specific": "Global Average Pooling (GAP) classification head",
        "novel_contribution": "Systematically evaluated; finding: performs very poorly for NIDS compared to alternatives"
      },
      {
        "type": "primary",
        "category": "Pooling/Head",
        "specific": "Attention-based/learned pooling head",
        "novel_contribution": "Evaluated as an alternative to GAP; identified as more suitable for NIDS in the framework’s findings"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CICD-DoS2019",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "KDD (e.g., KDD'99)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS-2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Global Average Pooling classification head",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "\"Global Average Pooling ... performs very poorly in the context of NIDS.\"",
        "baseline_result": null
      },
      {
        "method_name": "BERT vs GPT-2 architectures (transformer family choice)",
        "paper_reference": null,
        "metric": "Accuracy / Model size / Inference & training time",
        "their_result": "Evaluated within FlowTransformer across three public datasets; trade-offs analyzed",
        "baseline_result": null
      },
      {
        "method_name": "Specific input encoding + classification head (recommended) vs commonly used alternatives",
        "paper_reference": null,
        "metric": "Accuracy / Model size / Inference & training time",
        "their_result": "\"Model size can be reduced by over 50%, and inference and training times improved, with no loss of accuracy\"",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Model size (parameters)",
      "Inference time",
      "Training time",
      "Speed"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What transformer components (input encoding, transformer architecture, classification head) yield the best trade-off between accuracy, model size, and speed for flow-based NIDS?",
        "Does the classification head choice dominate performance for NIDS tasks?",
        "Are commonly used text classification heads (e.g., Global Average Pooling) appropriate for NIDS?",
        "Can model size and inference/training time be reduced without accuracy loss by careful component choices?"
      ],
      "gaps_identified": [
        "Current ML-based NIDS research often overlooks sequential data, focusing on individual flow records in isolation.",
        "Lack of extensive and systematic evaluation of transformer models and parameters in the context of NIDS.",
        "No established architectures for handling flow-based network traffic with transformers (e.g., input encodings and classification heads remain largely unevaluated in NIDS).",
        "Dimensionality and representation challenges for categorical and numerical fields in tabular flow data."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Enable systematic, flexible, and efficient implementation and evaluation of transformer-based NIDSs that can capture long-term behavior and complex patterns in network traffic, addressing the lack of comprehensive evaluation of component choices.",
      "potential_research_ideas": [
        "Pretrain transformers on large unlabeled flow corpora (self-supervised pretraining) and fine-tune for NIDS tasks.",
        "Semi-supervised or few-shot transformer-based NIDS to reduce labeled data requirements.",
        "Design and evaluate time-aware/relative positional encodings tailored to flow timing and burstiness.",
        "Hierarchical models combining packet-level and flow-level transformers.",
        "Cross-domain/domain-adaptive transformers for NIDS to improve generalization across networks.",
        "Robustness studies against adversarial manipulations in flow features and sequence ordering.",
        "Explainability methods for transformer-based NIDS (e.g., attention attribution over flows and fields).",
        "Resource-efficient inference via pruning, quantization, and distillation targeting high-throughput deployments.",
        "Curating standardized flow-sequence benchmarks with consistent preprocessing pipelines."
      ],
      "architectural_improvement_recommendations": [
        "Replace GAP with learned pooling (e.g., attention pooling or CLS-token summarization) for NIDS classification heads.",
        "Adopt relative/time-aware positional encodings to capture inter-flow timing patterns.",
        "Use tabular-specific encoders (e.g., per-field embeddings + numerical encoders) with feature-wise gating.",
        "Incorporate efficient attention variants (linear/performer/longformer) to handle long flow sequences.",
        "Apply knowledge distillation from larger transformers to compact student models for deployment.",
        "Leverage mixture-of-experts or adapter layers to handle heterogeneous network segments/domains."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/liamdm/FlowTransformer",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Selecting suitable input encodings and classification heads for high-throughput flow sequences",
        "Handling high-cardinality categorical fields (e.g., ports) without excessive dimensionality",
        "Avoiding classification head parameter blow-up with increasing sequence length",
        "Scaling to large volumes of flow data while maintaining accuracy and latency constraints"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes FlowTransformer, a modular framework for transformer-based NIDS with interchangeable input encodings, transformer backbones, and classification heads.",
      "Public implementation provided for researchers to evaluate transformers on any flow-based network dataset.",
      "Extensive evaluation of common transformer architectures (e.g., GPT-2 and BERT) on three public NIDS datasets with results for accuracy, model size, and speed.",
      "Key empirical finding: classification head choice has the most significant impact on model performance; Global Average Pooling performs poorly for NIDS.",
      "Demonstrates over 50% reduction in model size and improved inference/training time with no loss of accuracy by appropriate choice of input encoding and classification head.",
      "Provides a recommended overall transformer architecture as a strong starting point for future transformer-based NIDS research."
    ]
  },
  {
    "arxiv_id": "2304.14451v1",
    "title": "Machine Learning for Detection and Mitigation of Web Vulnerabilities and Web Attacks",
    "authors": "Mahnoor Shahid",
    "abstract": "Detection and mitigation of critical web vulnerabilities and attacks like cross-site scripting (XSS), and cross-site request forgery (CSRF) have been a great concern in the field of web security. Such web attacks are evolving and becoming more challenging to detect. Several ideas from different perspectives have been put forth that can be used to improve the performance of detecting these web vulnerabilities and preventing the attacks from happening. Machine learning techniques have lately been used by researchers to defend against XSS and CSRF, and given the positive findings, it can be concluded that it is a promising research direction. The objective of this paper is to briefly report on the research works that have been published in this direction of applying classical and advanced machine learning to identify and prevent XSS and CSRF. The purpose of providing this survey is to address different machine learning approaches that have been implemented, understand the key takeaway of every research, discuss their positive impact and the downsides that persists, so that it can help the researchers to determine the best direction to develop new approaches for their own research and to encourage researchers to focus towards the intersection between web security and machine learning.",
    "published_date": "2023-04-27",
    "pdf_link": "https://arxiv.org/pdf/2304.14451v1",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Web Security",
      "subdomain": "Web Application Vulnerability and Attack Detection",
      "specific_problem": "Detection and mitigation of Cross-Site Scripting (XSS) and Cross-Site Request Forgery (CSRF) using machine learning",
      "attack_types": [
        "XSS",
        "CSRF"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "KNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Naive Bayes",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "ADTree",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Boosting",
        "specific": "AdaBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Neural Network",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Rule-based",
        "specific": "RIPPER/JRIP",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble",
        "specific": "Stacking",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble",
        "specific": "Cascading (two-stage classifier)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble",
        "specific": "Bagging",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Embedding",
        "specific": "Word2Vec (feature representation)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "XSSed (malicious XSS webpages)",
        "type": "public",
        "domain": "web_pages",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "DMOZ (benign webpages)",
        "type": "public",
        "domain": "web_pages",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ClueWeb09 (benign webpages)",
        "type": "public",
        "domain": "web_pages",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Weibo.com webpages simulating XSS worms",
        "type": "public",
        "domain": "web_pages",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Likarish et al. (2009) JavaScript code dataset",
        "type": "private",
        "domain": "javascript_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Komiya et al. (2011) user input/web code dataset (SQLi and XSS)",
        "type": "private",
        "domain": "user_inputs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Khan et al. (2017) webpages/JavaScript samples",
        "type": "private",
        "domain": "web_pages",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Meerani et al. (2018) multi-source balanced scripts dataset",
        "type": "private",
        "domain": "http_requests",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Meerani et al. (2019) text vs script dataset (phase 1)",
        "type": "private",
        "domain": "text_and_scripts",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Meerani et al. (2019) script classification dataset (phase 2)",
        "type": "private",
        "domain": "javascript_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Kascheev et al. (2020) 240k JavaScript samples (40k malicious, 200k benign)",
        "type": "private",
        "domain": "javascript_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Wang et al. (2014) OSN-focused dataset (DMOZ + XSSed + Weibo)",
        "type": "private",
        "domain": "web_pages",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "K. Gupta et al. (2015) 1000 PHP source files from open-source projects",
        "type": "private",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "AdaBoost (vs ADTree) on OSN XSS vulnerability detection (Wang et al., 2014)",
        "paper_reference": "Wang R. et al. 2014",
        "metric": "F1",
        "their_result": "0.939 (AdaBoost)",
        "baseline_result": "0.936 (ADTree)"
      },
      {
        "method_name": "Decision Tree (vs SVM, Logistic Regression, Naive Bayes) on JavaScript/XSS (Kascheev et al., 2020)",
        "paper_reference": "Kascheev et al. 2020",
        "metric": "Accuracy",
        "their_result": "98.81% (Decision Tree)",
        "baseline_result": "SVM=71.37%; Logistic Regression=83.03%; Naive Bayes=65.27%"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "F1",
      "F2",
      "false alarm rate",
      "detection rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What classical and advanced machine learning approaches have been used to detect and mitigate XSS and CSRF?",
        "What are the key takeaways, positive impacts, and downsides of each approach?",
        "How can machine learning be applied to automate CSRF detection and classify sensitive requests?"
      ],
      "gaps_identified": [
        "Severe class imbalance and scarcity of malicious samples in several datasets (e.g., 60,000 benign vs 62 malicious in Likarish et al.).",
        "Reliance on single-source malicious data (e.g., many works depend solely on XSSed) raising representativeness concerns.",
        "Ambiguity in defining obfuscation/maliciousness and labeling practices in some studies.",
        "Limited discussion of computational complexity and scalability in real-world deployments.",
        "Traditional feature engineering may not generalize to novel/obfuscated payloads; difficulty with plain text vs script discrimination.",
        "Misclassification due to base64 and other obfuscation/encoding techniques.",
        "High variance across classifiers indicates feature-generation limitations (e.g., large gaps in accuracy among models).",
        "CSRF detection automation is less mature; limited ML-based studies and emphasis compared to XSS."
      ],
      "limitations": [],
      "future_work": [
        "Encourage further research at the intersection of web security and machine learning for XSS and CSRF.",
        "Develop improved approaches building on surveyed positives while addressing noted downsides (e.g., dataset quality, generalization)."
      ],
      "motivation": "XSS and CSRF are top critical web vulnerabilities with evolving attack patterns; machine learning has shown promise for detection and prevention. The paper surveys ML approaches to guide researchers toward effective directions.",
      "potential_research_ideas": [
        "Deep learning for raw HTTP/query payloads and JavaScript (e.g., byte-/char-level Transformers) to reduce manual feature engineering and improve robustness to obfuscation.",
        "Graph-based analysis of DOM/HTML/JS ASTs with GNNs to capture structural patterns of XSS and sanitization context.",
        "Self-supervised pretraining on large-scale web code and HTTP corpora to improve low-shot generalization to novel XSS payloads.",
        "Adversarial training and attack-generation frameworks for robust XSS/CSRF detectors against encoding and obfuscation tricks (e.g., base64, nested encodings).",
        "Cross-site, cross-language datasets with better balance and diversity; standardized benchmarks for XSS/CSRF detection.",
        "Runtime browser-side defenses with ML (WASM-based) that combine content inspection with contextual signals (origin, CSP, referrer, cookie/samesite) for CSRF.",
        "Hybrid static-dynamic analysis combining taint tracking with ML classifiers for end-to-end vulnerability triage in web apps."
      ],
      "architectural_improvement_recommendations": [
        "Use byte/character-level tokenization and subword models to handle obfuscated and encoded payloads; add deobfuscation/normalization preprocessing.",
        "Adopt multi-task learning to jointly predict 'script vs text' and 'malicious vs benign' to reduce cascading errors.",
        "Incorporate contextual features (CSP headers, cookie flags, referrer policies) alongside content features for CSRF-sensitive request classification.",
        "Employ cost-sensitive learning, focal loss, and data augmentation to mitigate class imbalance; leverage hard-negative mining.",
        "Leverage ensemble diversity explicitly (heterogeneous architectures) and calibrate outputs to reduce false positives.",
        "Model program structure via AST-based embeddings and code-language models; integrate Word2Vec replacements with modern embeddings (e.g., code transformers)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Maintaining low runtime overhead for browser- or gateway-side inspection.",
        "High false positives due to benign packed/encoded JavaScript and base64-heavy content.",
        "Dataset bias and limited representativeness from single-source malicious data.",
        "Generalization to novel, obfuscated, or context-dependent attacks.",
        "Handling plain-text inputs vs scripts in user-provided fields.",
        "Managing class imbalance and label quality at scale."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Concise and systematic literature review of machine learning and deep learning methods for detecting and mitigating XSS.",
      "Brief overview of existing works on automating CSRF detection and the use of machine learning for classifying sensitive requests."
    ]
  },
  {
    "arxiv_id": "2304.01908v1",
    "title": "Leveraging Deep Learning Approaches for Deepfake Detection: A Review",
    "authors": "Aniruddha Tiwari; Rushit Dave; Mounika Vanamala",
    "abstract": "Conspicuous progression in the field of machine learning and deep learning have led the jump of highly realistic fake media, these media oftentimes referred as deepfakes. Deepfakes are fabricated media which are generated by sophisticated AI that are at times very difficult to set apart from the real media. So far, this media can be uploaded to the various social media platforms, hence advertising it to the world got easy, calling for an efficacious countermeasure. Thus, one of the optimistic counter steps against deepfake would be deepfake detection. To undertake this threat, researchers in the past have created models to detect deepfakes based on ML/DL techniques like Convolutional Neural Networks. This paper aims to explore different methodologies with an intention to achieve a cost-effective model with a higher accuracy with different types of the datasets, which is to address the generalizability of the dataset.",
    "published_date": "2023-04-04",
    "pdf_link": "https://arxiv.org/pdf/2304.01908v1",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Digital Forensics",
      "subdomain": "Multimedia Forensics",
      "specific_problem": "Deepfake detection in facial images/videos with cross-dataset generalization",
      "attack_types": [
        "face swap",
        "lip-sync",
        "head puppetry",
        "GAN-generated deepfakes",
        "Autoencoder-generated deepfakes"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "XceptionNet",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet-50",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet-18",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "InceptionV3",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "InceptionResNetV2",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "DenseNet169",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "VGG16 (hybrid with CNN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Custom CNN",
        "specific": "MesoNet (Meso-4, MesoInception-4)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN+RNN",
        "specific": "LRCN (Long-term Recurrent Convolutional Network)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Optical Flow",
        "specific": "Optical flow features fused with CNN+RNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Attention Mechanism",
        "specific": "Attention fused with ResNet/Xception; Swish activation",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "DNN",
        "specific": "General DNN classifier (frame-level + video-level)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Classical ML",
        "specific": "SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Image Enhancement",
        "specific": "DFDNet (for enhancement in creation pipeline)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GAN",
        "specific": "Recycle-GAN (used for iterative improvement in pipeline)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Rule-based/Heuristic",
        "specific": "DeepVision (eye-blink based integrity verification using EAR and detectors)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Super-Resolution",
        "specific": "Super-resolution preprocessor with ResNet-50 classifier",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Celeb-DF",
        "type": "public",
        "domain": "face_videos",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "FaceForensics++",
        "type": "public",
        "domain": "face_videos",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "FFIW10K",
        "type": "public",
        "domain": "face_videos",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Deepfake Detection Challenge (DFDC)",
        "type": "public",
        "domain": "face_videos",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "WildDeepfake",
        "type": "public",
        "domain": "face_videos",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UADFV",
        "type": "public",
        "domain": "face_videos",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Eye Blinking Prediction Dataset (Kaggle)",
        "type": "public",
        "domain": "face_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "DenseNet169 + face-warping indicators (with Gaussian/Exponential/Rayleigh blur) [7]",
        "paper_reference": "[7]",
        "metric": "Accuracy",
        "their_result": "60% (Celeb-DF)",
        "baseline_result": null
      },
      {
        "method_name": "DeepVision (eye-blink-based integrity verification)",
        "paper_reference": "[11]",
        "metric": "Accuracy",
        "their_result": "87.5% (Eye Blinking Prediction Dataset, Kaggle)",
        "baseline_result": null
      },
      {
        "method_name": "MesoNet (Meso-4 and MesoInception-4)",
        "paper_reference": "[27][31]",
        "metric": "Accuracy",
        "their_result": "98% (deepfake dataset), 95% (FaceForensics++)",
        "baseline_result": null
      },
      {
        "method_name": "MesoNet (compressed frames focus)",
        "paper_reference": "[27]",
        "metric": "Confidence interval",
        "their_result": "80% CI reported",
        "baseline_result": null
      },
      {
        "method_name": "Hybrid CNN + VGG16 (DFP)",
        "paper_reference": "[32]",
        "metric": "Accuracy, Precision",
        "their_result": "94% accuracy and precision",
        "baseline_result": null
      },
      {
        "method_name": "ResNet-50 + super-resolution (head pose + SR)",
        "paper_reference": "[33]",
        "metric": "Accuracy",
        "their_result": "94.4% (UADFV)",
        "baseline_result": null
      },
      {
        "method_name": "CNN + RNN with optical-flow temporal features",
        "paper_reference": "[37]",
        "metric": "Accuracy",
        "their_result": "92% (FaceForensics++)",
        "baseline_result": null
      },
      {
        "method_name": "ResNet50 vs InceptionV3 vs XceptionNet as feature extractors on compressed videos",
        "paper_reference": "[24]",
        "metric": null,
        "their_result": "XceptionNet chosen as best-performing under c=23 and c=40",
        "baseline_result": null
      },
      {
        "method_name": "Attention mechanism fused with XceptionNet/ResNet-18/ResNet-50 (Swish activation)",
        "paper_reference": "[29]",
        "metric": null,
        "their_result": "Significant improvements reported on FaceForensics++ (no exact numbers given)",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Confidence interval"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can we efficiently build a deepfake detection model while keeping the transferability over various datasets and higher accuracy intact?"
      ],
      "gaps_identified": [
        "CNN-based detectors often perform well only in intra-dataset settings; performance drops significantly when tested on new datasets (poor cross-dataset generalization).",
        "Existing models are dependent on specific deepfake generation methods (GANs vs Autoencoders); accuracy degrades when evaluated on a different generation method.",
        "High-quality deepfakes reduce the efficacy of artifact-based and temporal-feature-based detectors.",
        "Difficulty detecting when the facial structure is straight toward the camera; limited sensitivity to color/resolution/head-pose changes.",
        "Region-specific detectors (e.g., eye-blink based) fail when manipulation occurs elsewhere (e.g., lips) and lack handling for fast blinking.",
        "Limited number of studies focus on human behavioral/physiological cues relative to visual/temporal artifacts.",
        "Robust detection on compressed videos remains challenging; need models applicable to different compression levels.",
        "Cost-efficiency of training/deployment is underexplored.",
        "Most evaluations emphasize intra-dataset rather than cross-dataset transferability."
      ],
      "limitations": [
        "Existing models show high accuracy only for the same deepfake generation method they are trained on (GAN vs Autoencoder mismatch hurts accuracy).",
        "For high-quality deepfakes, artifact/temporal methods show lower accuracy and may not work effectively.",
        "Models tend not to detect fake media if the facial structure is straight and head pose issues persist.",
        "Eye-blink-based approaches focus only on the eye region and cannot detect manipulations in other regions; lack guidance for fast eye blinking.",
        "Overall generalization across datasets and manipulation types is limited."
      ],
      "future_work": [
        "Develop a new model that efficiently and securely detects fake media using ML/DL while incorporating new features.",
        "Generalize detection for both image and video datasets created via GANs or Autoencoders (method-agnostic detection).",
        "Account for cost of building models to achieve cost-effective detection.",
        "Detect discrepancies across the entire face rather than focusing on specific regions (eyes, lips).",
        "Conduct deeper studies to improve generalization and robustness."
      ],
      "motivation": "Deepfakes pose growing societal threats through misinformation and fraud; there is a need for efficient, accurate, and cost-effective detection methods that generalize across datasets and manipulation techniques.",
      "potential_research_ideas": [
        "Domain generalization and cross-dataset training using self-supervised and contrastive pretraining on large-scale real and synthetic face-video corpora to learn manipulation-agnostic features.",
        "Multimodal deepfake detection combining visual, audio, and physiological cues (e.g., rPPG/heart-rate, blink/lip dynamics) to improve robustness against high-quality fakes.",
        "Frequency- and phase-based analysis (e.g., FFT/DCT and local phase) fused with spatial-temporal features to capture subtle synthesis artifacts robust to compression.",
        "Unified detector that jointly predicts manipulation presence, region localization, and generation method as auxiliary tasks to improve representation learning.",
        "Test-time adaptation/meta-learning to handle unseen datasets via unsupervised entropy minimization or pseudo-label refinement without labels.",
        "Generator-ensemble adversarial training where detectors are trained against diverse GAN/autoencoder pipelines and random codec/compression augmentations.",
        "Lightweight mobile-ready detectors via knowledge distillation and neural architecture search maintaining cross-dataset robustness.",
        "Benchmark and protocol design emphasizing cross-dataset and cross-method transfer (train-test on disjoint datasets/methods) with standardized compression settings."
      ],
      "architectural_improvement_recommendations": [
        "Adopt video transformers (e.g., spatiotemporal transformer/tubelet attention) with dual-stream inputs: RGB frames and frequency/phase maps.",
        "Two-branch architecture: local patch-level artifact detector with attention over facial regions + global temporal consistency branch using optical flow or motion tokens.",
        "Contrastive learning between real/fake patches and across augmentations (codec, resolution, color space) to enforce invariances.",
        "Randomized codec/compression, frame-rate, and resolution augmentations during training to improve compression robustness.",
        "Adversarial training against a zoo of generators (StyleGAN variants, autoencoders, face-reenactment) and post-processing (super-resolution, denoisers).",
        "Uncertainty estimation and calibration (e.g., temperature scaling) to flag low-confidence cases in deployment.",
        "Knowledge distillation from a heavy spatiotemporal teacher to an efficient student for edge deployment."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Generalization gap across datasets and manipulation methods (GAN vs Autoencoder).",
        "Performance degradation on high-quality and compressed videos.",
        "Sensitivity to pose/front-facing shots and limited artifact visibility.",
        "Region-specific methods (e.g., eye-only) missing other manipulations (e.g., lip-sync).",
        "Cost-efficiency concerns for training and deployment at scale."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comprehensive review of ML/DL-based deepfake detection techniques (CNN, RNN/LSTM, hybrid models, attention mechanisms).",
      "Survey and discussion of major public deepfake datasets (FaceForensics++, Celeb-DF, FFIW10K, DFDC, WildDeepfake, UADFV) and their characteristics.",
      "Analytical discussion highlighting dataset dependence and poor cross-dataset generalization of existing detectors.",
      "Compilation of reported results from prior work, including accuracy figures and settings (e.g., compression levels).",
      "Formulation of a research question emphasizing efficiency and transferability across datasets.",
      "Identification of limitations and articulation of directions for future work (whole-face analysis, method-agnostic generalization, cost considerations)."
    ]
  },
  {
    "arxiv_id": "2304.11130v1",
    "title": "Automated Mapping of CVE Vulnerability Records to MITRE CWE Weaknesses",
    "authors": "Ashraf Haddad; Najwa Aaraj; Preslav Nakov; Septimiu Fabian Mare",
    "abstract": "In recent years, a proliferation of cyber-security threats and diversity has been on the rise culminating in an increase in their reporting and analysis. To counter that, many non-profit organizations have emerged in this domain, such as MITRE and OSWAP, which have been actively tracking vulnerabilities, and publishing defense recommendations in standardized formats. As producing data in such formats manually is very time-consuming, there have been some proposals to automate the process. Unfortunately, a major obstacle to adopting supervised machine learning for this problem has been the lack of publicly available specialized datasets. Here, we aim to bridge this gap. In particular, we focus on mapping CVE records into MITRE CWE Weaknesses, and we release to the research community a manually annotated dataset of 4,012 records for this task. With a human-in-the-loop framework in mind, we approach the problem as a ranking task and aim to incorporate reinforced learning to make use of the human feedback in future work. Our experimental results using fine-tuned deep learning models, namely Sentence-BERT and rankT5, show sizable performance gains over BM25, BERT, and RoBERTa, which demonstrates the need for an architecture capable of good semantic understanding for this task.",
    "published_date": "2023-04-13",
    "pdf_link": "https://arxiv.org/pdf/2304.11130v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cyber Threat Intelligence",
      "subdomain": "Vulnerability Analysis and Standardization",
      "specific_problem": "Automated mapping of CVE vulnerability records to MITRE CWE weaknesses (Top 25) framed as a ranking task",
      "attack_types": [
        "Out-of-bounds Write",
        "Cross-site Scripting (XSS)",
        "SQL Injection",
        "Improper Input Validation",
        "Out-of-bounds Read",
        "OS Command Injection",
        "Use After Free",
        "Path Traversal",
        "Cross-Site Request Forgery (CSRF)",
        "Unrestricted File Upload of Dangerous Type",
        "NULL Pointer Dereference",
        "Deserialization of Untrusted Data",
        "Integer Overflow/Wraparound",
        "Improper Authentication",
        "Hard-coded Credentials",
        "Missing Authorization",
        "Command Injection"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Sentence-BERT (SBERT)",
        "novel_contribution": "Fine-tuned for CVE-to-CWE ranking as semantic similarity matching"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "rankT5",
        "novel_contribution": "Applied as a sequence-to-sequence ranking model for retrieving the most appropriate CWE"
      },
      {
        "type": "baseline",
        "category": "IR",
        "specific": "BM25",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "RoBERTa",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "T5 (Seq2Seq generation)",
        "novel_contribution": "Used both as a generative Seq2Seq model and as a ranker baseline"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Learning-to-Rank"
    ],
    "datasets": [
      {
        "name": "CVE-to-CWE Top 25 Annotated Dataset (4,012 records)",
        "type": "public",
        "domain": "vulnerability_text",
        "link": "https://github.com/ahadda5/annotate_cve",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "NVD/CVE records (source data for annotation)",
        "type": "public",
        "domain": "vulnerability_text",
        "link": "https://github.com/CVEProject/cvelist",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MITRE CWE Top 25 (2022) weakness names and descriptions",
        "type": "public",
        "domain": "weakness_descriptions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "BM25",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "BERT",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "RoBERTa",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "T5 (Seq2Seq generation baseline)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Lack of publicly available, specialized annotated datasets for mapping vulnerabilities to standardized taxonomies",
        "Previous work often operated at document level and ignored weakness descriptions, attenuating relevant features",
        "Prior formulations focused on classification or entity/relation extraction despite subjectivity in expert labels; a ranking paradigm is more appropriate",
        "Little to no leveraging of human-in-the-loop training and feedback (e.g., reinforcement learning from human feedback) for this task"
      ],
      "limitations": [
        "Dataset focuses on MITRE CWE Top 25 (2022) rather than the full CWE hierarchy",
        "Reinforcement learning from human feedback is proposed but not implemented in current work",
        "Classical IR methods (e.g., TF-IDF, BM25) are unreliable for this task, requiring more semantically capable architectures",
        "Dynamic nature of cybersecurity data necessitates ongoing maintenance and updates to the dataset"
      ],
      "future_work": [
        "Incorporate reinforcement learning to leverage human annotator feedback in a human-in-the-loop framework",
        "Extend the methodology and dataset to the MITRE ATT&CK framework (TTPs)",
        "Enable AI systems to assist human analysts during triage and standardization of CVE records",
        "Maintain and expand the dataset to keep up with evolving threats and CWE lists"
      ],
      "motivation": "Automate and standardize the mapping of CVE records to MITRE CWE weaknesses to support CTI reporting, mitigating the time-consuming manual efforts and addressing the shortage of public annotated datasets.",
      "potential_research_ideas": [
        "Scale from Top 25 to the full CWE hierarchy with hierarchical and multi-label learning-to-rank",
        "Model causal chains between weaknesses (e.g., A leads to B) via graph-based or structured prediction approaches",
        "Active learning and human-in-the-loop strategies to prioritize annotation of uncertain or novel CVEs",
        "Cross-ontology mapping between CWE and ATT&CK TTPs using multi-task or joint embedding models",
        "Leverage vendor advisories, patches, and CPE metadata in multi-source models for improved disambiguation",
        "RAG (retrieval-augmented generation) for explainable CWE recommendations with evidence spans from CVE text",
        "Contrastive pretraining using pairs of CVE records and CWE descriptions; hard-negative mining from near-miss CWEs",
        "Temporal adaptation and drift handling as CWE top lists and CVE language evolve",
        "Multilingual or cross-lingual CWE mapping using multilingual transformers for non-English advisories"
      ],
      "architectural_improvement_recommendations": [
        "Two-stage retrieval: SBERT or ColBERT bi-encoder for candidate generation plus cross-encoder (e.g., BERT/RoBERTa/T5) re-ranker",
        "Hierarchical label modeling that encodes CWE taxonomy structure and supports multi-label + causal links",
        "Pairwise/listwise ranking losses (e.g., Margin/MNCE/ListNet) tuned for top-k accuracy and MRR",
        "Multi-task training to jointly predict primary CWE, secondary CWE(s), and causal relations",
        "Prompt-/instruction-tuning of T5/LLMs with CWE definitions and examples for better semantic grounding",
        "Feature fusion with structured fields (CVSS vectors, product/CPE) alongside text encoders",
        "Hard-negative mining from sibling CWE descriptions to improve discriminability",
        "Calibrated confidence estimation to support human-in-the-loop triage (e.g., temperature scaling)"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/ahadda5/annotate_cve",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Dynamic and evolving vulnerability landscape requires continuous dataset maintenance",
        "Subjectivity and potential disagreement among annotators on CWE labels",
        "Multi-label and causal relationships between weaknesses complicate automation",
        "Classical IR approaches are unreliable without semantically-aware models"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a manually annotated dataset of 4,012 CVE records mapped to MITRE CWE Top 25 weaknesses, including causal relations where applicable",
      "Formulates CVE-to-CWE mapping as a ranking task within a human-in-the-loop framework, with plans to incorporate reinforcement learning from human feedback",
      "Experimental validation showing fine-tuned Sentence-BERT and rankT5 achieve sizable gains over BM25, BERT, and RoBERTa",
      "Releases code and tools to annotate and maintain the dataset (public GitHub repository)"
    ]
  },
  {
    "arxiv_id": "2304.02838v2",
    "title": "TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph",
    "authors": "Nan Wang; Xuezhi Wen; Dalin Zhang; Xibin Zhao; Jiahui Ma; Mengxia Luo; Fan Xu; Sen Nie; Shi Wu; Jiqiang Liu",
    "abstract": "APT detection is difficult to detect due to the long-term latency, covert and slow multistage attack patterns of Advanced Persistent Threat (APT). To tackle these issues, we propose TBDetector, a transformer-based advanced persistent threat detection method for APT attack detection. Considering that provenance graphs provide rich historical information and have the powerful attacks historic correlation ability to identify anomalous activities, TBDetector employs provenance analysis for APT detection, which summarizes long-running system execution with space efficiency and utilizes transformer with self-attention based encoder-decoder to extract long-term contextual features of system states to detect slow-acting attacks. Furthermore, we further introduce anomaly scores to investigate the anomaly of different system states, where each state is calculated with an anomaly score corresponding to its similarity score and isolation score. To evaluate the effectiveness of the proposed method, we have conducted experiments on five public datasets, i.e., streamspot, cadets, shellshock, clearscope, and wget_baseline. Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method.",
    "published_date": "2023-04-06",
    "pdf_link": "https://arxiv.org/pdf/2304.02838v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Host-based Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Advanced Persistent Threat (APT) detection from host provenance graphs",
      "attack_types": [
        "Advanced Persistent Threats (APTs)",
        "Zero-day attacks",
        "Multi-stage 'low-and-slow' intrusions",
        "Shellshock (dataset scenario)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Encoder-decoder with multi-head self-attention (sequence autoencoder)",
        "novel_contribution": "Applies a transformer-based encoder-decoder to extract long-term contextual features from provenance graph-derived sequences for APT detection, trained on normal-only data."
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "K-means",
        "novel_contribution": "Used to compute similarity scores to cluster centroids for anomaly scoring in a one-class setting."
      },
      {
        "type": "primary",
        "category": "Anomaly Detection",
        "specific": "Isolation Forest",
        "novel_contribution": "Combined with similarity score to form total anomaly score for unknown attack detection."
      },
      {
        "type": "primary",
        "category": "Feature Hashing/Sketching",
        "specific": "HistoSketch",
        "novel_contribution": "Converts streaming histograms of provenance substructures into fixed-length feature vectors, enabling efficient sequence modeling."
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "One-class"
    ],
    "datasets": [
      {
        "name": "streamspot",
        "type": "public",
        "domain": "provenance_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "cadets (DARPA TC)",
        "type": "public",
        "domain": "provenance_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "shellshock",
        "type": "public",
        "domain": "provenance_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "clearscope",
        "type": "public",
        "domain": "provenance_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "wget_baseline",
        "type": "public",
        "domain": "provenance_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Existing anomaly score and tag propagation methods struggle to model long-term behavioral patterns in APTs.",
        "Graph matching approaches become computationally heavy as provenance graphs grow with long-lived APTs and can incur information loss.",
        "Difficulty detecting unknown (zero-day) APTs using prior-knowledge-driven matching rules."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "To effectively detect slow-acting, long-term, and covert APTs from provenance graphs by capturing long-term contextual features and supporting unknown attack detection.",
      "potential_research_ideas": [
        "Incorporate graph neural networks that operate directly on provenance graphs and compare against the histogram+sequence pipeline.",
        "Develop self-supervised pretraining objectives on large unlabeled provenance streams to improve feature quality for rare APT behaviors.",
        "Integrate cross-host or enterprise-wide correlation to detect distributed/multi-host APT campaigns.",
        "Design interpretable attention mechanisms to highlight suspicious substructures and provide analyst-friendly explanations.",
        "Explore online/streaming adaptation and concept drift handling for evolving system behaviors.",
        "Evaluate and harden against adversarial mimicry and poisoning attacks on provenance streams.",
        "Investigate federated or privacy-preserving learning for multi-tenant provenance data."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment the sequence autoencoder with sparse/linear-time attention variants for scalability on very long sequences.",
        "Hybrid architecture: combine transformer sequence features with GNN embeddings of localized subgraphs for richer structural context.",
        "Learn the anomaly scoring end-to-end by replacing fixed K-means + Isolation Forest with a differentiable deep one-class objective (e.g., deep SVDD-style) or energy-based models.",
        "Introduce temporal positional encodings tailored to irregular event timestamps and event-rate normalization.",
        "Use adaptive sketching that preserves rare/critical substructures with higher fidelity than uniform HistoSketch."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Transforms system call logs into provenance graphs and then into long feature sequences; uses a self-attention encoder-decoder to extract long-term contextual features to distinguish normal from anomalous behavior.",
      "Introduces an anomaly score combining similarity (to K-means centroids) and isolation (Isolation Forest) to detect unknown APTs.",
      "Evaluates on five open-source datasets (streamspot, cadets, shellshock, clearscope, wget_baseline) and reports better performance than state-of-the-art methods."
    ]
  },
  {
    "arxiv_id": "2304.07232v1",
    "title": "Evaluation of ChatGPT Model for Vulnerability Detection",
    "authors": "Anton Cheshkov; Pavel Zadorozhny; Rodion Levichev",
    "abstract": "In this technical report, we evaluated the performance of the ChatGPT and GPT-3 models for the task of vulnerability detection in code. Our evaluation was conducted on our real-world dataset, using binary and multi-label classification tasks on CWE vulnerabilities. We decided to evaluate the model because it has shown good performance on other code-based tasks, such as solving programming challenges and understanding code at a high level. However, we found that the ChatGPT model performed no better than a dummy classifier for both binary and multi-label classification tasks for code vulnerability detection.",
    "published_date": "2023-04-12",
    "pdf_link": "https://arxiv.org/pdf/2304.07232v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection",
      "specific_problem": "Detecting vulnerabilities in Java functions: (1) binary classification of vulnerable vs. patched code, (2) multi-label classification of CWE types",
      "attack_types": [
        "CWE-20: Improper Input Validation",
        "CWE-200: Exposure of Sensitive Information to an Unauthorized Actor",
        "CWE-502: Deserialization of Untrusted Data",
        "CWE-611: Improper Restriction of XML External Entity Reference",
        "CWE-79: Cross-site Scripting"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer (LLM)",
        "specific": "gpt-3.5-turbo (ChatGPT API)",
        "novel_contribution": "No novel model; zero-shot prompt-based evaluation for vulnerability detection"
      },
      {
        "type": "primary",
        "category": "Transformer (LLM)",
        "specific": "text-davinci-003 (GPT-3)",
        "novel_contribution": "No novel model; zero-shot prompt-based evaluation for vulnerability detection"
      },
      {
        "type": "baseline",
        "category": "Dummy Classifier",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Zero-shot",
      "Prompt-based inference",
      "No fine-tuning"
    ],
    "datasets": [
      {
        "name": "Authors' GitHub-derived patch-level Java vulnerability dataset (binary subset, 308 samples)",
        "type": "private",
        "domain": "source_code (Java functions)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Authors' GitHub-derived patch-level Java vulnerability dataset (multi-label subset, 120 samples: 60 vulnerable + 60 patched across top-5 CWE types)",
        "type": "private",
        "domain": "source_code (Java functions)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Dummy classifier",
        "paper_reference": null,
        "metric": "Binary F1-score (308 samples)",
        "their_result": "gpt-3.5-turbo F1 = 0.62",
        "baseline_result": "0.50"
      },
      {
        "method_name": "Dummy classifier",
        "paper_reference": null,
        "metric": "Binary F1-score (308 samples)",
        "their_result": "text-davinci-003 F1 = 0.67",
        "baseline_result": "0.50"
      },
      {
        "method_name": "Dummy classifier",
        "paper_reference": null,
        "metric": "Binary AUC (308 samples)",
        "their_result": "gpt-3.5-turbo AUC = 0.51",
        "baseline_result": "0.50"
      },
      {
        "method_name": "Dummy classifier",
        "paper_reference": null,
        "metric": "Binary AUC (308 samples)",
        "their_result": "text-davinci-003 AUC = 0.51",
        "baseline_result": "0.50"
      },
      {
        "method_name": "Dummy classifier",
        "paper_reference": null,
        "metric": "Multi-label accuracy (top-5 CWE, 120 samples incl. Negative)",
        "their_result": "gpt-3.5-turbo accuracy = 0.383",
        "baseline_result": "0.305"
      },
      {
        "method_name": "Dummy classifier",
        "paper_reference": null,
        "metric": "Multi-label accuracy (top-5 CWE, 120 samples incl. Negative)",
        "their_result": "text-davinci-003 accuracy = 0.375",
        "baseline_result": "0.305"
      },
      {
        "method_name": "Dummy classifier",
        "paper_reference": null,
        "metric": "Multi-label accuracy on vulnerable classes only (exclude Negative, 60 samples)",
        "their_result": "gpt-3.5-turbo accuracy = 0.100",
        "baseline_result": "0.218"
      },
      {
        "method_name": "Dummy classifier",
        "paper_reference": null,
        "metric": "Multi-label accuracy on vulnerable classes only (exclude Negative, 60 samples)",
        "their_result": "text-davinci-003 accuracy = 0.117",
        "baseline_result": "0.218"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can large language models such as ChatGPT and GPT-3 solve the problem of vulnerability detection?"
      ],
      "gaps_identified": [
        "GPT models are not able to distinguish vulnerable code from its fixed non-vulnerable version; AUC ~0.51 (near random).",
        "Models tend to label examples as positive, leading to a high false positive rate.",
        "When excluding the Negative class, accuracy on vulnerable classes drops further (e.g., 0.100–0.117), indicating difficulty predicting true vulnerability types.",
        "Minimal sensitivity to different prompts used; changing prompts did not materially improve performance.",
        "Anomaly observed: better prediction of vulnerability types for fixed (patched) functions than for vulnerable counterparts.",
        "Potential mismatch between ChatGPT API and the web model could affect replicability.",
        "Small sample sizes and selection bias (only files with a single modified function) limit generalizability.",
        "Manual labeling by domain experts may introduce bias or labeling errors.",
        "Single dataset and single programming language (Java) constrain external validity.",
        "Did not explore chain-of-thought prompting, which may improve reasoning."
      ],
      "limitations": [
        "Small sample size (308 binary; 120 multi-label) limits statistical power.",
        "Use of a single dataset and language (Java) limits generalizability.",
        "Potential biases from manual selection/labeling by domain experts.",
        "Selection bias: only files with a single modified function were included.",
        "Prompt choice may affect outcomes; only a finite set of prompts explored.",
        "Did not explore chain-of-thought prompting.",
        "Model training data may include CWE instances but not remediation patterns, limiting discrimination between vulnerable and fixed code.",
        "ChatGPT API may differ from web version.",
        "No comparison to established SAST tools in this study."
      ],
      "future_work": [
        "Explore chain-of-thought prompting and exemplars to improve LLM reasoning for vulnerability detection.",
        "Evaluate newer LLMs (e.g., GPT-4) on the tasks.",
        "Use larger and more diverse datasets and multiple programming languages.",
        "Employ multiple domain experts and/or automated tools for labeling to reduce bias and errors.",
        "Investigate training or adaptation that exposes models to both vulnerable and remediated code.",
        "Study alternative prompting strategies and multi-turn reasoning.",
        "Assess integration with static analysis tools."
      ],
      "motivation": "Assess whether large language models (ChatGPT, GPT-3) that perform well on code generation and understanding can detect vulnerabilities in real-world Java code.",
      "potential_research_ideas": [
        "Construct a large, public benchmark of aligned vulnerable/patched function pairs with CWE labels and line-level annotations for evaluation and training.",
        "Fine-tune code LLMs on vulnerability/patch pairs using contrastive or Siamese objectives to explicitly learn differences between vulnerable and fixed code.",
        "Integrate static analysis signals (AST/CFG/CPG features, taint flows) with LLMs via retrieval-augmentation or tool-use to guide vulnerability reasoning.",
        "Develop few-shot prompt templates with curated vulnerable vs. patched exemplars and apply self-consistency/majority voting.",
        "Build a hybrid SAST+LLM ensemble where the LLM rationalizes and prioritizes SAST alerts to reduce false positives.",
        "Investigate line-level vulnerability localization and explanation generation to improve precision and interpretability.",
        "Explore calibration methods (e.g., temperature scaling, selective prediction) to manage high false positive rates.",
        "Evaluate cross-language generalization (Java, Python, C/C++) and domain adaptation techniques.",
        "Use active learning to expand labeled datasets by querying LLM uncertainty.",
        "RAG with CWE knowledge bases and secure coding guidelines to ground predictions."
      ],
      "architectural_improvement_recommendations": [
        "Augment prompts with structured program representations (AST, CFG, data/taint flows) and retrieve similar historical vulnerable/fixed patterns.",
        "Adopt a pairwise (Siamese) architecture that jointly encodes vulnerable and patched versions to learn discriminative differences.",
        "Use self-consistency with multiple sampled rationales and majority voting; include chain-of-thought exemplars tailored to CWE categories.",
        "Implement a hybrid pipeline where SAST provides candidate sinks/sources and slices that the LLM analyzes, reducing context length and noise.",
        "Introduce a small classification head on top of a code LLM (fine-tuned) for CWE prediction with class-balanced losses and focal loss.",
        "Apply retrieval-augmented generation with CWE definitions, code examples, and remediation patterns during inference.",
        "Calibrate outputs and set abstention/triage thresholds to control false positives for practical use."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "High false positive rate and inability to distinguish vulnerable from fixed code.",
        "Potential inconsistency between ChatGPT API and web model."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Empirical evaluation of ChatGPT (gpt-3.5-turbo) and GPT-3 (text-davinci-003) for Java code vulnerability detection on real-world patch-level data.",
      "Negative result: performance comparable to a dummy classifier; AUC near random for binary classification and poor accuracy on vulnerable classes.",
      "Provided dataset composition details (projects, CWE distribution) and prompts used for both binary and multi-label tasks.",
      "Identified an anomaly where models predicted vulnerability types more accurately on fixed functions than on vulnerable ones.",
      "Outlined threats to validity and suggested future directions including chain-of-thought prompting and testing newer LLMs (e.g., GPT-4)."
    ]
  },
  {
    "arxiv_id": "2303.11751v1",
    "title": "Generative AI for Cyber Threat-Hunting in 6G-enabled IoT Networks",
    "authors": "Mohamed Amine Ferrag; Merouane Debbah; Muna Al-Hawawreh",
    "abstract": "The next generation of cellular technology, 6G, is being developed to enable a wide range of new applications and services for the Internet of Things (IoT). One of 6G's main advantages for IoT applications is its ability to support much higher data rates and bandwidth as well as to support ultra-low latency. However, with this increased connectivity will come to an increased risk of cyber threats, as attackers will be able to exploit the large network of connected devices. Generative Artificial Intelligence (AI) can be used to detect and prevent cyber attacks by continuously learning and adapting to new threats and vulnerabilities. In this paper, we discuss the use of generative AI for cyber threat-hunting (CTH) in 6G-enabled IoT networks. Then, we propose a new generative adversarial network (GAN) and Transformer-based model for CTH in 6G-enabled IoT Networks. The experimental analysis results with a new cyber security dataset demonstrate that the Transformer-based security model for CTH can detect IoT attacks with a high overall accuracy of 95%. We examine the challenges and opportunities and conclude by highlighting the potential of generative AI in enhancing the security of 6G-enabled IoT networks and call for further research to be conducted in this area.",
    "published_date": "2023-03-21",
    "pdf_link": "https://arxiv.org/pdf/2303.11751v1",
    "paper_types": [
      "empirical_analysis",
      "survey",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Threat Hunting / Intrusion Detection",
      "specific_problem": "Cyber Threat-Hunting (CTH) in 6G-enabled IoT networks",
      "attack_types": [
        "IoT attacks (unspecified)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": null,
        "novel_contribution": "Proposes a Transformer-based security model for CTH in 6G-enabled IoT networks; reported 95% overall accuracy on an IoT attack detection task."
      },
      {
        "type": "primary",
        "category": "Generative Adversarial Network (GAN)",
        "specific": null,
        "novel_contribution": "Part of the proposed GAN + Transformer-based CTH approach; role not fully specified in provided text (likely data synthesis or adversarial training)."
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "GPT",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "New cybersecurity dataset (unnamed, used in this paper's experiments)",
        "type": "private",
        "domain": "iot_network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "MNIST",
        "type": "public",
        "domain": "images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Fashion-MNIST",
        "type": "public",
        "domain": "images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIFAR-10",
        "type": "public",
        "domain": "images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Common Vulnerabilities and Exposures (CVE)",
        "type": "public",
        "domain": "vulnerability_db",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-DDoS2019",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "KDD Cup 1999",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "WebText",
        "type": "public",
        "domain": "text_corpus",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Simulation (synthetic dataset in Yang et al. 2022)",
        "type": "synthetic",
        "domain": "network_simulation",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "540K articles about cyber threats (CTI corpus in Jo et al. 2022)",
        "type": "private",
        "domain": "text_corpus",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Bot-IoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GAN-based method",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "GPT-based method",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "BERT-based method",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can generative AI be used for cyber threat-hunting (CTH) in 6G-enabled IoT networks?",
        "Can a combined GAN and Transformer-based model effectively detect IoT attacks in 6G-enabled environments?"
      ],
      "gaps_identified": [
        "Scalability issues for generative AI in 6G-enabled IoT networks",
        "Decentralized training issues (e.g., federated settings)",
        "Data quality issues and bias in training data",
        "Energy challenges for compute-intensive generative models",
        "Privacy-preserving challenges",
        "Tokenization challenges for security data"
      ],
      "limitations": [
        "Generative AI performance depends on completeness and quality of training data; biased or incomplete data degrades performance",
        "Generative AI can create false positives, wasting analyst time and resources",
        "The experimental dataset is unnamed and availability is unclear from the text",
        "Limited quantitative comparison against baselines in the provided content"
      ],
      "future_work": [
        "Investigate scalable and decentralized training approaches for 6G IoT CTH",
        "Improve data quality, labeling, and bias mitigation in security datasets",
        "Develop energy-efficient generative models suitable for edge and IoT devices",
        "Integrate privacy-preserving techniques (e.g., differential privacy, federated learning) for CTH",
        "Address tokenization and representation learning tailored to heterogeneous IoT/6G telemetry"
      ],
      "motivation": "6G-enabled IoT will vastly increase connectivity and attack surface; generative AI offers potential for adaptive, proactive cyber threat-hunting to detect and prevent attacks in such environments.",
      "potential_research_ideas": [
        "Design a multimodal CTH model that fuses network telemetry, device logs, and RF side-channel features via a unified Transformer backbone with GAN-based data augmentation for rare attack types.",
        "Develop a privacy-preserving federated GAN-Transformer pipeline for cross-organization threat-hunting in 6G IoT with robust aggregation and client drift handling.",
        "Create tokenization/representation schemes for IoT network flows (e.g., flow2vec) optimized for Transformer encoders to reduce false positives.",
        "Adversarial robustness for CTH: incorporate certified defenses and adversarial training regimes tailored to network-flow embeddings.",
        "Energy-aware CTH: distill large Transformer CTH models into edge-friendly student models and schedule inference across edge/cloud tiers.",
        "Self-supervised pretraining on unlabeled IoT traffic using masked flow modeling, followed by supervised fine-tuning for CTH."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a hierarchical Transformer with local attention for per-device sequences and global attention for cross-device correlations in 6G slices.",
        "Use a conditional GAN to synthesize class-balanced, context-conditioned IoT attack flows to address data imbalance; validate with distribution shift metrics.",
        "Introduce contrastive/self-supervised pretraining (MoCo/SimCLR-style) on flow embeddings prior to supervised CTH training.",
        "Incorporate uncertainty estimation (Monte Carlo dropout or deep ensembles) to reduce false positives and triage alerts.",
        "Integrate differential privacy noise and secure aggregation if training on distributed IoT/edge data.",
        "Deploy knowledge distillation and sparsity/quantization to meet edge constraints; benchmark latency on representative edge hardware."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Scalability in large-scale 6G-enabled IoT networks",
        "Decentralized/federated training constraints",
        "Data quality, labeling, and bias",
        "Energy consumption and resource limits on edge/IoT devices",
        "Privacy-preserving data sharing and training",
        "Tokenization/representation of heterogeneous telemetry"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Survey/discussion of generative AI use cases for IoT and cyber threat-hunting in 6G-enabled IoT networks",
      "Proposes a new GAN and Transformer-based model for cyber threat-hunting in 6G-enabled IoT networks",
      "Empirical evaluation claiming the Transformer-based CTH model achieves 'a high overall accuracy of 95%' on IoT attack detection using a new cybersecurity dataset",
      "Identification of challenges and opportunities for applying generative AI to CTH in 6G-enabled IoT networks (scalability, decentralization, data quality, energy, privacy, tokenization)"
    ]
  },
  {
    "arxiv_id": "2303.02659v1",
    "title": "Cyber Vaccine for Deepfake Immunity",
    "authors": "Ching-Chun Chang; Huy Hong Nguyen; Junichi Yamagishi; Isao Echizen",
    "abstract": "Deepfakes pose an evolving threat to cybersecurity, which calls for the development of automated countermeasures. While considerable forensic research has been devoted to the detection and localisation of deepfakes, solutions for reversing fake to real are yet to be developed. In this study, we introduce cyber vaccination for conferring immunity to deepfakes. Analogous to biological vaccination that injects antigens to induce immunity prior to infection by an actual pathogen, cyber vaccination simulates deepfakes and performs adversarial training to build a defensive immune system. Aiming at building up attack-agnostic immunity with limited computational resources, we propose to simulate various deepfakes with one single overpowered attack: face masking. The proposed immune system consists of a vaccinator for inducing immunity and a neutraliser for recovering facial content. Experimental evaluations demonstrate effective immunity to face replacement, face reenactment and various types of corruptions.",
    "published_date": "2023-03-05",
    "pdf_link": "https://arxiv.org/pdf/2303.02659v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Multimedia Security",
      "subdomain": "Digital Media Forensics",
      "specific_problem": "Pre-emptive deepfake mitigation via vaccination: reversible restoration (neutralisation) of manipulated face regions and validation of vaccinated media",
      "attack_types": [
        "face replacement (mask-dependent autoencoder-based)",
        "face replacement (mask-independent SimSwap)",
        "face reenactment (X2Face)",
        "image corruptions (blurriness, brightness, contrast, hue)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "U-Net",
        "specific": "OpenAI diffusion-style U-Net with residual connections and multi-head attention",
        "novel_contribution": "Used as vaccinator and neutraliser trained jointly with losses enforcing imperceptibility, reversibility, and validatability under a single overpowered attack model (face masking)"
      },
      {
        "type": "primary",
        "category": "Classifier",
        "specific": "MLP, LeNet, ResNet, ViT, ConvNeXT (validator variants)",
        "novel_contribution": "Validator to distinguish vaccinated vs. unvaccinated media using neutralised outputs; demonstrates that even simple models can achieve ~99% accuracy"
      },
      {
        "type": "baseline",
        "category": "Autoencoder",
        "specific": "Classic deepfake face-swap autoencoder (shared encoder, two decoders)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GAN-based face swap",
        "specific": "SimSwap (pre-trained, identity-agnostic)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Reenactment model",
        "specific": "X2Face (pre-trained)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Face recognition embedding",
        "specific": "FaceNet (for identity similarity evaluation via cosine similarity)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised (reconstruction-based)",
      "Adversarial training (simulated adversary via face masking)",
      "Data augmentation (random affine and color transforms)"
    ],
    "datasets": [
      {
        "name": "FaceForensics++",
        "type": "public",
        "domain": "face_videos",
        "link": "https://github.com/ondyari/FaceForensics",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Neutraliser-only (no vaccination, image-inpainting-like)",
        "paper_reference": null,
        "metric": "FaceNet latent-space cosine similarity (identity similarity)",
        "their_result": "“For 200 test samples, the average identity similarity with the vaccine is 0.99”",
        "baseline_result": "“and that without the vaccine is 0.57”"
      }
    ],
    "performance_metrics_used": [
      "PSNR (Peak Signal-to-Noise Ratio)",
      "SSIM (Structural Similarity Index Measure)",
      "Cosine similarity in FaceNet embedding space (identity similarity)",
      "Classification accuracy (validator)",
      "True Positive Rate (TPR)",
      "True Negative Rate (TNR)",
      "Mean Absolute Error (as part of training loss)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a single overpowered attack model (face masking) induce attack-agnostic immunity to diverse deepfake manipulations?",
        "Can vaccinated media be restored (neutralised) to original content with high fidelity while remaining imperceptible and easily validated?",
        "How robust is the proposed immune system to common image corruptions and misalignments?"
      ],
      "gaps_identified": [
        "“solutions for restoring fraudulent content are yet to be developed.”",
        "Adversarial training with many deepfake models is impractical due to computational cost and evolving attack landscape.",
        "Classical steganographic self-embedding requires non-trivial manual parameter tuning and is fragile to common transforms.",
        "Universal deepfake toolkits are difficult to integrate for real-time training due to heterogeneous inputs, generalisability, and pre/post-processing."
      ],
      "limitations": [
        "Multiple faces per image are left aside for simplicity.",
        "Neutralisation performance drops under extreme blurriness and hue adjustments; brightness has notable negative effect.",
        "Validator relies on vaccinated content; unvaccinated inputs remain masked after neutralisation (no recovery).",
        "Potential sensitivity to face detection/alignment errors; misalignment only simulated via random affine transforms during training.",
        "Evaluation limited to FaceForensics++ and specific pre-trained attack models; no in-the-wild deployment results."
      ],
      "future_work": [],
      "motivation": "Provide an attack-agnostic, resource-efficient defense that enables not only detection/localisation but also restoration of deepfaked facial content by pre-emptively vaccinating media.",
      "potential_research_ideas": [
        "Extend vaccination and neutralisation to multi-face scenarios and crowded scenes with occlusions.",
        "Incorporate temporal consistency losses and video transformers to improve frame-to-frame coherence in neutralisation.",
        "Add identity-preserving losses (e.g., ArcFace/FaceNet embeddings) and perceptual (VGG) losses to further boost fidelity under challenging corruptions.",
        "Combine vaccination with robust watermarking to provide cryptographic proof-of-vaccination and tamper evidence.",
        "Curriculum adversarial training with a spectrum of synthetic attack simulators (beyond masking) to widen immunity while keeping efficiency.",
        "Domain adaptation for in-the-wild distributions (compression artifacts, camera pipelines, social media transcodes).",
        "Investigate robustness to adaptive adversaries that attempt to remove or spoof vaccination cues.",
        "Explore diffusion-model-based neutralisers (iterative restoration) for improved recovery under severe corruptions."
      ],
      "architectural_improvement_recommendations": [
        "Introduce a spatial transformer network within the neutraliser to explicitly handle misalignment between face detections.",
        "Augment the loss with identity-preserving embedding loss and adversarial (GAN) loss for realism while keeping MAE+SSIM.",
        "Use temporal U-Nets or ConvLSTM/Video Swin backbones for sequence-level neutralisation with temporal smoothness regularisers.",
        "Employ mixed precision and lightweight backbones (MobileNet/ConvNeXt-Tiny) for edge deployment of vaccinator.",
        "Add a small auxiliary head that predicts a vaccination confidence map to guide validator and robust merging.",
        "Adopt stronger data augmentation pipelines (JPEG compression, noise, color jitter) to cover real-world post-processing.",
        "Jointly train validator with the neutraliser in a multi-task setup to encourage clearer separability between vaccinated/unvaccinated outputs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires content to be vaccinated prior to attack; unvaccinated media cannot be restored.",
        "Dependence on accurate face detection/alignment; failures can degrade neutralisation.",
        "Performance degrades under extreme blurriness and hue shifts.",
        "Adoption challenge: need ecosystem and tooling for creators/distributors to vaccinate content.",
        "Handling multiple faces and complex occlusions not addressed."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduce cyber vaccination as a pre-emptive defense paradigm to confer deepfake immunity.",
      "Propose using a single overpowered attack (face masking) to simulate diverse deepfake effects for attack-agnostic training.",
      "Design a cyber immune system comprising a vaccinator (imperceptible perturbations) and a neutraliser (restoration), plus a validator for vaccinated/unvaccinated discrimination.",
      "Training objective combining imperceptibility, reversibility, and validatability using MAE and SSIM losses.",
      "Empirical demonstration of immunity to face replacement (mask-dependent and SimSwap) and face reenactment (X2Face), with robustness to common corruptions.",
      "Show that vaccinated vs. unvaccinated media are easily distinguishable after neutralisation, achieving ~99% validation accuracy across diverse classifiers."
    ]
  },
  {
    "arxiv_id": "2303.13627v1",
    "title": "Associated Random Neural Networks for Collective Classification of Nodes in Botnet Attacks",
    "authors": "Erol Gelenbe; Mert Nakıp",
    "abstract": "Botnet attacks are a major threat to networked systems because of their ability to turn the network nodes that they compromise into additional attackers, leading to the spread of high volume attacks over long periods. The detection of such Botnets is complicated by the fact that multiple network IP addresses will be simultaneously compromised, so that Collective Classification of compromised nodes, in addition to the already available traditional methods that focus on individual nodes, can be useful. Thus this work introduces a collective Botnet attack classification technique that operates on traffic from an n-node IP network with a novel Associated Random Neural Network (ARNN) that identifies the nodes which are compromised. The ARNN is a recurrent architecture that incorporates two mutually associated, interconnected and architecturally identical n-neuron random neural networks, that act simultneously as mutual critics to reach the decision regarding which of n nodes have been compromised. A novel gradient learning descent algorithm is presented for the ARNN, and is shown to operate effectively both with conventional off-line training from prior data, and with on-line incremental training without prior off-line learning. Real data from a 107 node packet network is used with over 700,000 packets to evaluate the ARNN, showing that it provides accurate predictions. Comparisons with other well-known state of the art methods using the same learning and testing datasets, show that the ARNN offers significantly better performance.",
    "published_date": "2023-03-23",
    "pdf_link": "https://arxiv.org/pdf/2303.13627v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Botnet Detection",
      "specific_problem": "Collective classification of compromised nodes in a network under botnet attacks",
      "attack_types": [
        "Botnet (Mirai)",
        "DDoS"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Spiking Neural Network (Random Neural Network)",
        "specific": "Associated Random Neural Network (ARNN)",
        "novel_contribution": "Introduces a new recurrent 'self-critical' architecture composed of two mutually associated, identical n-neuron Random Neural Networks with cross excitatory/inhibitory connections acting as mutual critics for collective node classification; provides a new gradient-descent learning algorithm supporting both offline and online incremental training."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Online learning (incremental)"
    ],
    "datasets": [
      {
        "name": "Kitsune Network Attack Dataset (Mirai botnet scenario)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "True Positives",
      "True Negatives"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a collective classification method (ARNN) leveraging interactions among nodes more accurately identify all compromised nodes during a botnet attack than traditional single-node detectors?",
        "Can the proposed ARNN be effectively trained both offline and with online incremental updates using real network traffic?"
      ],
      "gaps_identified": [
        "Traditional single-node attack detection is insufficient to certify and capture the multi-node propagation nature of botnets; collective classification is needed.",
        "Global collective classification approaches can be computationally costly; there is a need for efficient architectures.",
        "Botnet variability and evolving traffic patterns challenge static detectors."
      ],
      "limitations": [
        "Evaluation reported on a single publicly available scenario (Mirai) within the Kitsune dataset.",
        "Relies on outputs from Local Attack Detectors (LADs) at some nodes as inputs to ARNN.",
        "Ground-truth for compromised status uses a thresholding of sent-attack ratios per time slot.",
        "The dataset reflects an unchecked attack progression: \"The Kitsune dataset does not incorporate the consequences of attack detection.\""
      ],
      "future_work": [],
      "motivation": "Botnets simultaneously compromise multiple nodes; detecting them benefits from collective classification across a network rather than isolated single-node decisions.",
      "potential_research_ideas": [
        "Extend ARNN to explicitly incorporate the network's adjacency matrix as a structural prior (masking or weighting connections) and compare to graph-based baselines.",
        "Evaluate ARNN across multiple botnet families and traffic environments to assess generalization and domain shift robustness.",
        "Hybridize ARNN with unsupervised anomaly scoring to reduce reliance on LADs and improve detection in low-label or partially instrumented settings.",
        "Uncertainty-aware ARNN variants (e.g., Bayesian or ensemble ARNN) to calibrate decisions and support active learning during online operation.",
        "Adversarial robustness studies for ARNN under evasive botnet traffic (e.g., traffic morphing, low-and-slow tactics)."
      ],
      "architectural_improvement_recommendations": [
        "Constrain or weight inter-neuron connections using the observed communication graph (adjacency matrix) to bias information flow along actual traffic paths.",
        "Introduce learnable attention over neighbors to allow the ARNN to focus on influential nodes while maintaining spiking/RNN dynamics.",
        "Incorporate per-node LAD reliability weights or gating to down-weight noisy LAD inputs during training and inference.",
        "Temporal extensions: add memory/eligibility traces or gated recurrences to model longer-range temporal dependencies across time slots.",
        "Regularize excitatory/inhibitory weight magnitudes and enforce stability constraints to improve online training robustness."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Requires the presence of Local Attack Detectors (LADs) at some nodes to provide input signals.",
        "Selection of time-slot aggregation and thresholding strategy for ground-truth labeling can affect performance."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes the Associated Random Neural Network (ARNN), a novel recurrent self-critical architecture for collective classification of compromised nodes.",
      "Develops a new gradient descent learning algorithm for ARNN supporting both offline and online incremental training.",
      "Defines an error function and learning constraints for stable training, including fixed total spiking rate per neuron.",
      "Implements and evaluates ARNN on real network traffic from a 107-node Mirai botnet scenario (over 760,000 packets), demonstrating accurate predictions.",
      "Reports that ARNN achieves significantly better performance than other well-known methods on the same train/test splits, particularly in both True Positives and True Negatives."
    ]
  },
  {
    "arxiv_id": "2303.09150v1",
    "title": "MASCARA: Systematically Generating Memorable And Secure Passphrases",
    "authors": "Avirup Mukherjee; Kousshik Murali; Shivam Kumar Jha; Niloy Ganguly; Rahul Chatterjee; Mainack Mondal",
    "abstract": "Passwords are the most common mechanism for authenticating users online. However, studies have shown that users find it difficult to create and manage secure passwords. To that end, passphrases are often recommended as a usable alternative to passwords, which would potentially be easy to remember and hard to guess. However, as we show, user-chosen passphrases fall short of being secure, while state-of-the-art machine-generated passphrases are difficult to remember. In this work, we aim to tackle the drawbacks of the systems that generate passphrases for practical use. In particular, we address the problem of generating secure and memorable passphrases and compare them against user chosen passphrases in use. We identify and characterize 72, 999 user-chosen in-use unique English passphrases from prior leaked password databases. Then we leverage this understanding to create a novel framework for measuring memorability and guessability of passphrases. Utilizing our framework, we design MASCARA, which follows a constrained Markov generation process to create passphrases that optimize for both memorability and guessability. Our evaluation of passphrases shows that MASCARA-generated passphrases are harder to guess than in-use user-generated passphrases, while being easier to remember compared to state-of-the-art machine-generated passphrases. We conduct a two-part user study with crowdsourcing platform Prolific to demonstrate that users have highest memory-recall (and lowest error rate) while using MASCARA passphrases. Moreover, for passphrases of length desired by the users, the recall rate is 60-100% higher for MASCARA-generated passphrases compared to current system-generated ones.",
    "published_date": "2023-03-16",
    "pdf_link": "https://arxiv.org/pdf/2303.09150v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Identity and Access Management",
      "subdomain": "Authentication",
      "specific_problem": "Systematically generating passphrases that jointly optimize memorability and guessability; measuring memorability and security (guess rank) of passphrases",
      "attack_types": [
        "offline password guessing",
        "probabilistic password cracking",
        "n-gram-based password guessing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Markov Model",
        "specific": "Constrained n-gram generative Markov model",
        "novel_contribution": "Constrained generation that explicitly trades off memorability (via linguistic features correlated with CER) and guessability (via Monte Carlo-estimated guess rank) to produce passphrases of arbitrary length"
      },
      {
        "type": "primary",
        "category": "Monte Carlo Estimation",
        "specific": null,
        "novel_contribution": "Monte Carlo estimate of passphrase guess ranks combined under a min-auto attacker model to quantify guessability"
      },
      {
        "type": "baseline",
        "category": "Rule-based Generation",
        "specific": "Diceware",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Template-based Generation",
        "specific": "TemplateDice (template-based Diceware with POS-tag templates)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer Language Model (for analysis)",
        "specific": "GPT-2 perplexity to assess naturalness",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Markov Model",
        "specific": "n-gram word and character models for cracking",
        "novel_contribution": "Used within min-auto attacker to estimate guess rank"
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Heuristic/Optimization"
    ],
    "datasets": [
      {
        "name": "MASCARA user-chosen English passphrase dataset (72,999 unique passphrases)",
        "type": "public",
        "domain": "passwords_passphrases",
        "link": "https://github.com/Mainack/MASCARA-passphrase-code-data",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "4iQ leaked credentials compilation (source for long passwords)",
        "type": "public",
        "domain": "passwords_passphrases",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "2,230 sentences annotated with Character Error Rate (CER) from prior user study [38]",
        "type": "public",
        "domain": "natural_language_sentences",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "User (in-use user-generated passphrases)",
        "paper_reference": null,
        "metric": "Guessability (min-auto Monte Carlo guess rank)",
        "their_result": "“MASCARA-generated passphrases are harder to guess than in-use user-generated passphrases”",
        "baseline_result": null
      },
      {
        "method_name": "Diceware",
        "paper_reference": "[54,57]",
        "metric": "Memorability (recall rate, CER)",
        "their_result": "“For passphrases of length 7 or less (preferred by most users) MASCARA provides 1.6x–2x better recall rate than deployed systems like Diceware while maintaining a less than 10% character error rate.”",
        "baseline_result": "Shay et al. [57] showed Diceware passphrases are as difficult to remember as randomly generated passwords (low memorability)."
      },
      {
        "method_name": "TemplateDice (template-based Diceware)",
        "paper_reference": "[25]",
        "metric": "Security scaling (guess rank) and memorability",
        "their_result": "“MASCARA-generated passphrases… do not suffer from any of the drawbacks of the existing systems.”",
        "baseline_result": "“The guess ranks of these passphrases gets saturated around length 8—guess rank of 8-word passphrase is nearly the same as that as of 13-word.”"
      }
    ],
    "performance_metrics_used": [
      "guess rank (min-auto across multiple cracking algorithms)",
      "Monte Carlo estimate of guess rank",
      "user study recall rate (after two days)",
      "Character Error Rate (CER)",
      "perplexity (GPT-2) as naturalness proxy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Is it possible to develop a simple automated approach for producing system-generated passphrases of arbitrary length, which is memorable by abiding grammar/sentence structure, yet hard for an adversary to guess and address shortcomings of existing passphrase-generation systems?"
      ],
      "gaps_identified": [
        "No public dataset of in-use passphrases; prior leaks do not label passphrases.",
        "Existing system-generated passphrases (e.g., Diceware) trade memorability for security; users find them hard to remember.",
        "Template-based Diceware has limited, hardcoded templates, poor scalability/extensibility, and security saturation with length.",
        "Passphrase security often measured via entropy or surveys; fewer works use guess-rank-based evaluation for passphrases.",
        "Lack of a principled, data-driven framework to jointly optimize memorability and guessability."
      ],
      "limitations": [
        "“We are not providing a one-step solution… MASCARA takes a principled and complementary approach to enhance today’s system-generated passphrases by balancing memorability and security.”",
        "“As with any user study, ecological validity is hard to ensure objectively… Participants did not know passphrases shown to them came from which system.”",
        "“We only consider English passphrases… Exploring passphrases for other languages is part of our future work.”"
      ],
      "future_work": [
        "Exploring passphrases for other languages.",
        "Potentially combining with mnemonic/contextual cue techniques to further enhance memorability (complementary per authors)."
      ],
      "motivation": "Improve practical passphrase generation by achieving a balanced memorability-security trade-off; overcome weaknesses of user-chosen phrases and current system-generated methods.",
      "potential_research_ideas": [
        "Neural language model–driven constrained generation (e.g., GPT-style or masked LMs) with explicit memorability and guessability objectives.",
        "Personalized passphrase generation that adapts linguistic style and vocabulary to a user while preserving guess rank under a privacy-preserving personalization layer.",
        "Multilingual MASCARA: extend the memorability feature set and constraints to multiple languages with language-specific syntax and morphology.",
        "Adversary-aware training: co-train the generator with a suite of state-of-the-art cracking models (PCFG, neural password models) to improve worst-case min-auto guess rank.",
        "Learned memorability predictor: train a supervised model to predict CER/recall using large-scale user studies and integrate as a differentiable objective.",
        "Context-integrated passphrases: incorporate mnemonic cues (images, stories) during generation to boost recall without leaking predictable structure.",
        "Policy-constrained generation: enforce site-specific composition policies while optimizing memorability and security.",
        "Longitudinal field study to measure real-world recall/usage over months and interactions with password managers."
      ],
      "architectural_improvement_recommendations": [
        "Replace n-gram Markov with a compact neural LM (e.g., small Transformer) finetuned on passphrase-like corpora, then apply constrained decoding for memorability and estimated guess rank.",
        "Integrate a learned memorability scorer trained on observed CER and recall labels, replacing hand-crafted correlation-based features.",
        "Expand attacker modeling beyond n-grams to include PCFG, RNN/Transformer-based password models and modern tools (e.g., PassGAN variants) in the min-auto ensemble.",
        "Use dynamic constraint weighting during decoding to meet target security budgets (guess rank thresholds) while maximizing predicted memorability.",
        "Add syntax/semantic checks via POS/dep parsing to ensure grammaticality without template saturation; include paraphrasing constraints to diversify.",
        "Efficient generation via lattice/beam search with pruning guided by both memorability and estimated guess rank."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/Mainack/MASCARA-passphrase-code-data",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Ecological validity of memorability results outside controlled user studies.",
        "Language limitation (English-only in current work).",
        "User adoption and integration into password managers with policy constraints."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Constructed the largest in-use, user-chosen English passphrase dataset (72,999 unique passphrases) from leaked password databases using segmentation heuristics.",
      "Developed a memorability–guessability measurement framework, including linguistic features correlated with CER and a Monte Carlo guess-rank estimator under a min-auto attacker.",
      "Proposed MASCARA, a constrained Markov generation system that optimizes both memorability and guessability to produce scalable, arbitrary-length passphrases.",
      "Empirical evaluation and a two-part user study showing MASCARA passphrases are harder to guess than user-generated passphrases and have higher recall and lower error than state-of-the-art machine-generated passphrases (e.g., 60–100% higher recall vs current systems; 1.6x–2x better recall than Diceware for length ≤7 with <10% CER)."
    ]
  },
  {
    "arxiv_id": "2303.15143v1",
    "title": "Collaborative Authentication for 6G Networks: An Edge Intelligence based Autonomous Approach",
    "authors": "He Fang; Zhenlong Xiao; Xianbin Wang; Li Xu; Lajos Hanzo",
    "abstract": "The conventional device authentication of wireless networks usually relies on a security server and centralized process, leading to long latency and risk of single-point of failure. While these challenges might be mitigated by collaborative authentication schemes, their performance remains limited by the rigidity of data collection and aggregated result. They also tend to ignore attacker localization in the collaborative authentication process. To overcome these challenges, a novel collaborative authentication scheme is proposed, where multiple edge devices act as cooperative peers to assist the service provider in distributively authenticating its users by estimating their received signal strength indicator (RSSI) and mobility trajectory (TRA). More explicitly, a distributed learning-based collaborative authentication algorithm is conceived, where the cooperative peers update their authentication models locally, thus the network congestion and response time remain low. Moreover, a situation-aware secure group update algorithm is proposed for autonomously refreshing the set of cooperative peers in the dynamic environment. We also develop an algorithm for localizing a malicious user by the cooperative peers once it is identified. The simulation results demonstrate that the proposed scheme is eminently suitable for both indoor and outdoor communication scenarios, and outperforms some existing benchmark schemes.",
    "published_date": "2023-03-27",
    "pdf_link": "https://arxiv.org/pdf/2303.15143v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Wireless/6G Security",
      "subdomain": "Authentication",
      "specific_problem": "Edge intelligence-based distributed collaborative device/location authentication with attacker localization",
      "attack_types": [
        "identity spoofing",
        "location spoofing (GPS spoofing)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Distributed optimization / Consensus learning",
        "specific": "Consensus ADMM (Alternating Direction Method of Multipliers)",
        "novel_contribution": "Formulates collaborative authentication as a separable convex consensus problem across edge peers and solves it with a distributed ADMM procedure, exchanging only aggregated variables to keep latency/congestion low"
      },
      {
        "type": "primary",
        "category": "Rule-based / Algorithmic",
        "specific": "Situation-aware secure group update",
        "novel_contribution": "Autonomous algorithm to adaptively refresh the set of cooperative peers and selected features based on dynamic network conditions"
      },
      {
        "type": "primary",
        "category": "Geometric localization",
        "specific": "Cooperative attacker localization",
        "novel_contribution": "Algorithm to localize a malicious user once detected using multi-peer RSSI/trajectory-derived distances"
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Distributed/Federated"
    ],
    "datasets": [
      {
        "name": "Simulated indoor scenario (RSSI and trajectory features)",
        "type": "synthetic",
        "domain": "wireless_signals_RSSI, mobility_trajectories",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Simulated outdoor scenario (RSSI and trajectory features)",
        "type": "synthetic",
        "domain": "wireless_signals_RSSI, mobility_trajectories",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Conventional centralized authentication (PKI/cryptographic schemes)",
        "paper_reference": "[13]-[16]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Physical-layer key generation schemes",
        "paper_reference": "[17]-[22]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Physical-layer authentication schemes",
        "paper_reference": "[23]-[25]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Centralized cooperative authentication schemes",
        "paper_reference": "[26]-[30]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Blockchain-based group authentication",
        "paper_reference": "[33]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "misdetection rate (MD)",
      "false alarm rate (FA)",
      "collaboration cost (communication overhead, time to reach consensus)",
      "latency/response time",
      "robustness under noisy time-varying environments",
      "number of cooperative peers vs accuracy trade-off"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to perform low-latency, reliable device/location authentication without a central server and single-point-of-failure?",
        "How to distributively fuse heterogeneous location-related features (RSSI, trajectory) across multiple edge peers for robust authentication?",
        "How to autonomously update the cooperative peer set and selected features in dynamic mobile topologies?",
        "How to localize a malicious user once spoofing is detected?",
        "How to set authentication thresholds and determine the optimal number of cooperative peers to balance accuracy and overhead?"
      ],
      "gaps_identified": [
        "Centralized authentication leads to long latency and single-point-of-failure",
        "Collaborative methods often have rigid data collection and aggregation and limited capability in processing heterogeneous data",
        "Existing collaborative authentication tends to ignore attacker localization",
        "Blockchain-based decentralized approaches can incur long latency, high computation/communication and storage costs",
        "Physical-layer authentication has low reliability in highly dynamic radio environments"
      ],
      "limitations": [
        "Assumes a single malicious node with potentially unlimited transmission power (worst-case attacker model)",
        "Assumes attacker knows the positions of all edge nodes and the legitimate user",
        "Assumes trusted cooperative edge nodes near the user",
        "Assumes the attacker is located at a different position from the legitimate user",
        "Evaluation is simulation-based (indoor/outdoor), no real-world deployment results provided",
        "Uses only RSSI and mobility trajectory as features (other modalities mentioned but not evaluated)"
      ],
      "future_work": [
        "Incorporate more location-related features (e.g., angle-of-arrival) depending on the application scenario",
        "Extend to additional dynamic mobile networks (e.g., VANETs, UAV networks) with realistic sensing modalities"
      ],
      "motivation": "Reduce latency and eliminate single points of failure by moving authentication to edge peers and improve robustness by collaboratively exploiting multi-dimensional location-related features; add autonomous peer/feature management and attacker localization.",
      "potential_research_ideas": [
        "Integrate richer radio features such as CSI, phase, AoA/TDoA to improve discrimination and localization accuracy",
        "Design Byzantine-robust consensus/ADMM to tolerate malicious or faulty peers (Byzantine-resilient distributed authentication)",
        "Incorporate uncertainty quantification and probabilistic data fusion (e.g., factor graphs or particle filters) for RSSI/trajectory fusion",
        "Use reinforcement learning for adaptive peer selection and feature selection under latency/energy constraints",
        "Develop privacy-preserving distributed learning with secure aggregation or differential privacy for shared statistics",
        "Benchmark on real-world multi-AP datasets with controlled spoofing to validate generalization and deployment readiness",
        "Explore joint authentication-and-localization with graph neural networks over the peer-user measurement graph",
        "Model and mitigate colluding adversaries and Sybil attacks within the cooperative peer set"
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment consensus ADMM with asynchronous decentralized SGD/federated averaging to handle clock skews and packet loss",
        "Adopt Byzantine-resilient aggregation (e.g., median, trimmed mean, Krum) for robustness against compromised peers",
        "Introduce trust/reputation scoring for peers to weight contributions in consensus and peer selection",
        "Apply multi-modal sensor fusion (e.g., EKF/UKF/particle filters) for combining RSSI with trajectory and AoA",
        "Implement communication-efficient updates (quantization, sparsification) to reduce overhead during consensus",
        "Add differential privacy noise or secure aggregation to protect local observations",
        "Leverage hybrid edge-cloud orchestration to offload heavy localization computations while keeping fast authentication at the edge"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Edge nodes (gateways/APs/servers) assisting a service provider in 6G/IoT-like networks",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requirement for trusted cooperative peers near users",
        "Communication overhead and synchronization to achieve consensus",
        "Dynamic topology and varying neighbor availability in mobile networks",
        "Need for sensors (cameras/LiDAR) to estimate trajectories which may raise cost and privacy concerns",
        "Robustness to heterogeneous hardware and environmental noise"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Edge intelligence-based collaborative authentication scheme using multiple cooperating edge nodes to collect location-related features (RSSI and trajectory) for distributed authentication",
      "Distributed learning-based collaborative authentication algorithm with local model updates at peers to reduce congestion and response time",
      "Situation-aware secure group update algorithm to autonomously refresh cooperative peers and selected features in dynamic environments",
      "Attacker localization algorithm executed by cooperative peers once a malicious user is identified",
      "Simulation studies for indoor and outdoor scenarios showing increased accuracy with more peers (at higher overhead) and better performance than existing benchmark schemes"
    ]
  },
  {
    "arxiv_id": "2303.07466v1",
    "title": "Deep Learning-based RF Fingerprint Authentication with Chaotic Antenna Arrays",
    "authors": "Justin McMillen; Gokhan Mumcu; Yasin Yilmaz",
    "abstract": "Radio frequency (RF) fingerprinting is a tool which allows for authentication by utilizing distinct and random distortions in a received signal based on characteristics of the transmitter. We introduce a deep learning-based authentication method for a novel RF fingerprinting system called Physically Unclonable Wireless Systems (PUWS). An element of PUWS is based on the concept of Chaotic Antenna Arrays (CAAs) that can be cost effectively manufactured by utilizing mask-free laser-enhanced direct print additive manufacturing (LE-DPAM). In our experiments, using simulation data of 300 CAAs each exhibiting 4 antenna elements, we test 3 different convolutional neural network (CNN) architectures under different channel conditions and compare their authentication performance to the current state-of-the-art RF fingerprinting authentication methods.",
    "published_date": "2023-03-13",
    "pdf_link": "https://arxiv.org/pdf/2303.07466v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Device Authentication (Physical-layer security)",
      "specific_problem": "RF fingerprint-based physical-layer authentication using Chaotic Antenna Arrays (CAA) without channel/error knowledge",
      "attack_types": [
        "device spoofing/impersonation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "ResNet-50 (modified input)",
        "novel_contribution": "Applied to CAA-generated RF fingerprints (I/Q input of size 1000×8×1) enabling >99% authentication accuracy under Rayleigh fading; eliminates need for device/channel knowledge assumed in prior CAA work."
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Inception v3 (modified input)",
        "novel_contribution": "Adapted from image classification to 1D I/Q sequence with 8 channels; achieved 99.9% test accuracy on 300 CAAs."
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Xception (modified input)",
        "novel_contribution": "Adapted for I/Q input; depthwise separable convolutions with residuals; achieved 99.9% test accuracy."
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "VGG-16 (modified input)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Simple CNN (2 conv layers + 1 dense; 'CNN-3')",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet-50 with traditional (non-CAA) RF fingerprints [5]",
        "novel_contribution": "Literature SOTA baseline cited at ~63% accuracy for 250 devices under changing channels."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "PUWS CAA simulated RF I/Q dataset (300 CAAs, 4 elements each)",
        "type": "synthetic",
        "domain": "wireless_rf_iq_samples",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CNN-3 (2 conv layers + dense)",
        "paper_reference": null,
        "metric": "Test accuracy (%)",
        "their_result": "93.3",
        "baseline_result": null
      },
      {
        "method_name": "VGG-16 (modified for 1000×8×1 I/Q)",
        "paper_reference": "[16]",
        "metric": "Test accuracy (%)",
        "their_result": "93.5",
        "baseline_result": null
      },
      {
        "method_name": "ResNet-50 (modified for 1000×8×1 I/Q, with CAA fingerprints)",
        "paper_reference": "[17]",
        "metric": "Test accuracy (%)",
        "their_result": "99.2",
        "baseline_result": null
      },
      {
        "method_name": "Inception v3 (modified for 1000×8×1 I/Q)",
        "paper_reference": "[18]",
        "metric": "Test accuracy (%)",
        "their_result": "99.9",
        "baseline_result": null
      },
      {
        "method_name": "Xception (modified for 1000×8×1 I/Q)",
        "paper_reference": "[19]",
        "metric": "Test accuracy (%)",
        "their_result": "99.9",
        "baseline_result": null
      },
      {
        "method_name": "ResNet-50 with traditional (non-CAA) RF fingerprints (literature SOTA)",
        "paper_reference": "[5]",
        "metric": "Test accuracy (%)",
        "their_result": ">99% (with CAA, this paper)",
        "baseline_result": "~63% (250 devices, traditional RF fingerprints)"
      }
    ],
    "performance_metrics_used": [
      "classification accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can chaotic antenna arrays (CAAs) augmented with deep learning enable reliable RF fingerprint-based authentication without knowledge of the wireless channel or device phase errors?",
        "How do different CNN architectures (VGG-16, ResNet-50, Inception, Xception) perform on CAA-based RF fingerprints under Rayleigh fading?",
        "Does spatially varying phase error from antenna geometry randomization enhance fingerprint distinctiveness vs. traditional RF chain imperfections?"
      ],
      "gaps_identified": [
        "Naturally occurring RF fingerprints are insufficient under realistic conditions with many devices and channel variations; state-of-the-art deep CNNs achieve ~63% accuracy on 250 devices [5].",
        "Prior CAA work assumed device knowledge of channel and own phase errors with no spatially varying phase errors, which is impractical."
      ],
      "limitations": [
        "Experiments rely on simulated data of 300 CAAs and Rayleigh fading channels; no hardware testbed results reported.",
        "Fixed SNR of 20 dB; robustness across SNRs and more diverse channel models not evaluated.",
        "Only 4 antenna elements per CAA considered in experiments."
      ],
      "future_work": [
        "Build and evaluate a physical testbed using LE-DPAM-manufactured CAAs.",
        "Assess performance under varying SNRs, mobility profiles, and channel mismatch between train/test.",
        "Explore different array sizes, element counts, and frequency bands to study scalability and generality."
      ],
      "motivation": "Improve physical-layer authentication for burgeoning IoT by creating stronger, unclonable RF fingerprints via randomized chaotic antenna arrays and leveraging deep learning to authenticate under realistic channels.",
      "potential_research_ideas": [
        "Open-set/device-enrollment framework: few-shot or metric learning to add new CAAs with minimal labeled data.",
        "Adversarial robustness: study spoofing attempts by adaptive attackers crafting waveforms to mimic CAA fingerprints; develop defenses (adversarial training, detection).",
        "Domain generalization: train models robust to channel/angle variations unseen at training using augmentation, invariance constraints, or contrastive learning.",
        "Complex-valued deep networks tailored to I/Q data, or hybrid CNN-Transformer architectures for temporal-spatial feature fusion.",
        "Multi-receiver (MIMO) authentication leveraging spatial diversity and beamforming to further enhance separability.",
        "Challenge-response protocols that exploit switch sequencing and phase diversity for active authentication.",
        "Cross-band and multi-band CAAs to enable frequency-agile authentication and resilience to narrowband interference."
      ],
      "architectural_improvement_recommendations": [
        "Replace image CNN backbones with 1D/2D CNNs for I/Q sequences plus self-attention to capture long-range temporal dependencies.",
        "Use complex-valued convolutions and normalization layers to respect I/Q structure.",
        "Incorporate angle/channel-aware augmentation and domain-adversarial training to reduce channel overfitting.",
        "Employ multi-branch networks per antenna element with late fusion plus learnable attention over elements.",
        "Calibrate with self-supervised pretraining on unlabeled I/Q to reduce label needs and improve generalization."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "TensorFlow"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Extended chaotic antenna arrays (CAAs) for RF fingerprinting to operate without channel/phase-error knowledge by using deep learning-based authentication.",
      "Demonstrated spatially varying phase errors from antenna geometry randomization that enhance RF fingerprint distinctiveness.",
      "Constructed a simulated dataset: 1200 elements forming 300 CAAs (4 elements each) at 5 GHz with Rayleigh fading; I/Q sequences of length 1000 from sequentially switched elements.",
      "Adapted multiple CNN architectures (VGG-16, ResNet-50, Inception, Xception) to I/Q inputs (1000×8×1) and achieved up to 99.9% accuracy on 300-device authentication.",
      "Showed large improvement over literature SOTA on traditional RF fingerprints (~63% accuracy) with CAA-based fingerprints (>99% with ResNet-50)."
    ]
  },
  {
    "arxiv_id": "2303.02894v2",
    "title": "A Systematic Approach to Automotive Security",
    "authors": "Masoud Ebrahimi; Stefan Marksteiner; Dejan Ničković; Roderick Bloem; David Schögler; Philipp Eisner; Samuel Sprung; Thomas Schober; Sebastian Chlup; Christoph Schmittner; Sandra König",
    "abstract": "We propose a holistic methodology for designing automotivesystems that consider security a central concern at every design stage.During the concept design, we model the system architecture and definethe security attributes of its components. We perform threat analysis onthe system model to identify structural security issues. From that analysis,we derive attack trees that define recipes describing steps to successfullyattack the system's assets and propose threat prevention measures.The attack tree allows us to derive a verification and validation (V&V)plan, which prioritizes the testing effort. In particular, we advocate usinglearning for testing approaches for the black-box components. It consistsof inferring a finite state model of the black-box component from its executiontraces. This model can then be used to generate new relevanttests, model check it against requirements, and compare two differentimplementations of the same protocol. We illustrate the methodologywith an automotive infotainment system example. Using the advocated approach, we could also document unexpected and potentially criticalbehavior in our example systems.",
    "published_date": "2023-03-06",
    "pdf_link": "https://arxiv.org/pdf/2303.02894v2",
    "paper_types": [
      "position",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Automotive Security",
      "subdomain": "Security by Design and Verification & Validation",
      "specific_problem": "Systematic security engineering methodology for automotive systems including threat modeling, attack tree-driven V&V planning, and learning-based testing of black-box components",
      "attack_types": [
        "Unauthorized access via wireless interfaces (WiFi, Bluetooth, BLE)",
        "CAN bus message spoofing",
        "CAN bus flooding (DoS)",
        "Protocol state machine flaws leading to deadlocks or persistent failure states",
        "Bypassing/weak authentication leading to session prolongation or reuse of old keys"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Automata Learning",
        "specific": "Active learning of Mealy machines (e.g., L*-family) via LearnLib/AALpy",
        "novel_contribution": "Use of active automata learning as a core V&V technique within a holistic automotive security methodology to infer explainable FSMs of black-box components and drive testing/model checking/fuzzing"
      }
    ],
    "learning_paradigm": [
      "Active Learning",
      "Model-based Testing"
    ],
    "datasets": [
      {
        "name": "THREATGET Threat Database",
        "type": "private",
        "domain": "threat_knowledge_base",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can security be systematically integrated and assessed across all stages of automotive system design?",
        "How can threat models and attack trees inform and prioritize an effective V&V plan?",
        "Can active automata learning of black-box components reveal security-relevant flaws in automotive protocols and ECUs?"
      ],
      "gaps_identified": [
        "Ad-hoc security measures by domain experts are insufficient for modern connected vehicles and regulatory demands.",
        "V&V teams often lack source code access; classical testing is limited for black-box components.",
        "Automata learning faces practical challenges: large input/output alphabets, need for abstraction mappers, and risk of inducing non-determinism with excessive abstraction.",
        "Automotive architectures may lack anomaly detection and adequate authentication/authorization on interfaces, enabling spoofing and flooding on CAN."
      ],
      "limitations": [
        "No quantitative benchmarking or comparison with alternative testing approaches.",
        "Equivalence checking relies on conformance testing approximations; true equivalence oracles are unavailable for real systems.",
        "Automata learning effectiveness depends on appropriate abstraction mapping and reset capabilities of the SUL; details are not fully specified.",
        "Evaluation limited to case studies (Bluetooth/BLE pairing, UDS secure access) without large-scale coverage metrics."
      ],
      "future_work": [
        "Continuous maintenance of threat models and V&V assets across the vehicle lifecycle, integrating new threats and software updates.",
        "Broader application of learning-based testing to additional automotive protocols and components.",
        "Further automation of abstraction refinement for large alphabets and complex interfaces.",
        "Integration of learned models with formal requirement specifications for automated model checking and test generation."
      ],
      "motivation": "Connected, software-intensive vehicles face increasing cyber-attacks; new standards (ISO/SAE 21434) and regulations (UNECE R155/R156) require systematic security engineering across the lifecycle.",
      "potential_research_ideas": [
        "Automated synthesis and refinement of abstraction mappers for automotive protocols using counterexample-guided and ML-assisted techniques.",
        "Timed/parametric automata learning to capture timing-dependent vulnerabilities in automotive stacks (e.g., BLE pairing, UDS sessions).",
        "Hybrid passive+active learning that leverages fleet or lab logs to seed and guide active exploration of black-box ECUs.",
        "Coverage-guided conformance testing that uses fuzzing heuristics to find counterexamples for the learner more efficiently.",
        "Cross-implementation differential learning to automatically discover diverging behaviors across vendors’ Bluetooth/UDS stacks.",
        "Security property mining from learned FSMs to auto-generate formal requirements and monitors for runtime IDS on in-vehicle networks."
      ],
      "architectural_improvement_recommendations": [
        "Adopt stronger conformance testing oracles (e.g., W/Wp/WV methods) and modern learning algorithms (e.g., TTT) to reduce queries and speed convergence.",
        "Integrate model checking over learned FSMs with property suites for authentication, replay protection, and session management; auto-generate regression tests from violations.",
        "Use incremental learning with fast reset strategies and virtualization/hardware-in-the-loop to handle unstable or stateful SULs.",
        "Combine automata learning with coverage-guided fuzzing (AFL-like) at the interface boundary to explore rarely triggered states.",
        "Instrument grey-box telemetry where possible to reduce non-determinism and improve abstraction fidelity."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "LearnLib",
        "AALpy",
        "THREATGET"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Not specified; experiments used Intel Wireless Controllers (AC 8265, AX200) for BLE/Bluetooth and a CAN interface to ECUs; standard desktop environment with Linux BLE host stack."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Automotive infotainment setup and ECU via OBD/CAN in lab environment using Intel wireless controllers and Linux BLE stack",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Access limitations to black-box components and need for suitable reset mechanisms.",
        "Large I/O alphabets requiring non-trivial abstraction mapping.",
        "Potential non-determinism from over-abstraction impacting learning.",
        "Availability of effective conformance oracles for equivalence testing.",
        "Need to continuously update threat models and V&V assets as software evolves."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes the Trusted methodology: a holistic, top-down process integrating concept design, threat modeling/analysis, attack tree derivation, and V&V planning for automotive security.",
      "Advocates and operationalizes learning-based testing via active automata learning to infer FSMs of black-box components for testing, model checking, and differential comparison.",
      "Demonstrates methodology on an automotive infotainment system using THREATGET to model threats, derive attack trees, and prioritize V&V.",
      "Case study findings: discovered a BLE deadlock state in Linux BLE host software triggered by out-of-order pairing requests; identified unexpected UDS secure access behaviors (session prolongation with incorrect keys and acceptance of old keys after re-authentication).",
      "Introduces threat repair via attribute changes in the architecture (e.g., enabling authentication/authorization on wireless interfaces) and ties repair outcomes to V&V requirements."
    ]
  },
  {
    "arxiv_id": "2303.17387v1",
    "title": "Explainable Intrusion Detection Systems Using Competitive Learning Techniques",
    "authors": "Jesse Ables; Thomas Kirby; Sudip Mittal; Ioana Banicescu; Shahram Rahimi; William Anderson; Maria Seale",
    "abstract": "The current state of the art systems in Artificial Intelligence (AI) enabled intrusion detection use a variety of black box methods. These black box methods are generally trained using Error Based Learning (EBL) techniques with a focus on creating accurate models. These models have high performative costs and are not easily explainable. A white box Competitive Learning (CL) based eXplainable Intrusion Detection System (X-IDS) offers a potential solution to these problem. CL models utilize an entirely different learning paradigm than EBL approaches. This different learning process makes the CL family of algorithms innately explainable and less resource intensive. In this paper, we create an X-IDS architecture that is based on DARPA's recommendation for explainable systems. In our architecture we leverage CL algorithms like, Self Organizing Maps (SOM), Growing Self Organizing Maps (GSOM), and Growing Hierarchical Self Organizing Map (GHSOM). The resulting models can be data-mined to create statistical and visual explanations. Our architecture is tested using NSL-KDD and CIC-IDS-2017 benchmark datasets, and produces accuracies that are 1% - 3% less than EBL models. However, CL models are much more explainable than EBL models. Additionally, we use a pruning process that is able to significantly reduce the size of these CL based models. By pruning our models, we are able to increase prediction speeds. Lastly, we analyze the statistical and visual explanations generated by our architecture, and we give a strategy that users could use to help navigate the set of explanations. These explanations will help users build trust with an Intrusion Detection System (IDS), and allow users to discover ways to increase the IDS's potency.",
    "published_date": "2023-03-30",
    "pdf_link": "https://arxiv.org/pdf/2303.17387v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Explainable anomaly-based network intrusion detection using competitive learning (SOM-family) models",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Self-Organizing Map",
        "specific": "SOM",
        "novel_contribution": "Used within an X-IDS architecture aligned with DARPA XAI guidelines to generate statistical and visual explanations"
      },
      {
        "type": "primary",
        "category": "Self-Organizing Map",
        "specific": "GSOM (Growing Self-Organizing Map)",
        "novel_contribution": "Applied for explainable intrusion detection within the proposed architecture"
      },
      {
        "type": "primary",
        "category": "Self-Organizing Map",
        "specific": "GHSOM (Growing Hierarchical Self-Organizing Map)",
        "novel_contribution": "Introduces a pruning process to significantly reduce model size and increase prediction speeds with little accuracy loss"
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-IDS-2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Black-box EBL models (unspecified)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "CL models are 1% - 3% less accurate than EBL models",
        "baseline_result": "EBL models' accuracies are 1% - 3% higher"
      }
    ],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Prevailing AI-enabled IDS rely on black-box EBL methods that are not innately explainable and can impose high performative costs",
        "Surrogate explanation methods (e.g., LIME, SHAP, LRP) introduce additional complexity and overhead and may be harder to trust",
        "Need for an X-IDS that meets DARPA’s XAI tenets and provides trustworthy, customizable explanations"
      ],
      "limitations": [
        "CL models are 1% - 3% less accurate than EBL models",
        "GHSOM can create more maps than users can feasibly analyze; larger maps can impose higher performative cost",
        "Explanations may require user strategies to navigate and may not always be immediately helpful without user-driven iteration"
      ],
      "future_work": [],
      "motivation": "Increase trust and explainability in intrusion detection by replacing opaque, high-cost EBL approaches with inherently explainable competitive learning models that align with DARPA XAI guidelines.",
      "potential_research_ideas": [
        "Hybrid X-IDS combining CL (for explanations) with lightweight EBL classifiers to close the 1%–3% accuracy gap while preserving transparency",
        "Online/streaming CL training for evolving network traffic to support continual learning and concept drift handling",
        "User-in-the-loop active learning to label ambiguous BMUs and refine cluster boundaries for better precision/recall trade-offs",
        "Systematic evaluation of explanation usefulness via user studies with SOC analysts to quantify trust/calibration improvements",
        "Adversarial robustness evaluation of CL-based IDS (e.g., probing sensitivity to small feature perturbations and poisoning)",
        "Cross-dataset generalization studies (train on CIC-IDS-2017, test on newer corpora) to assess robustness to data shifts",
        "Integrate causal or counterfactual explanations on top of CL maps to provide actionable remediation guidance"
      ],
      "architectural_improvement_recommendations": [
        "Develop principled pruning criteria for GHSOM (e.g., information gain, stability across bootstraps) and automatic depth control",
        "Introduce semi-supervised fine-tuning by propagating labels to BMUs with confidence thresholds to improve accuracy",
        "Add calibration layers (e.g., Platt/isotonic) on CL-derived scores to improve decision thresholds and reduce false positives",
        "Design an interactive dashboard that links global significance charts with per-node feature profiles and instance-level BMU attributions",
        "Parallelize map training and inference across tiles/levels and cache nearest-neighbor structures to reduce latency",
        "Incorporate feature selection or sparse encodings before CL training to reduce dimensionality and map growth",
        "Leverage prototype refinement via batch updates and neighborhood annealing schedules optimized by Bayesian search"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "GHSOM can produce too many maps, increasing cognitive load and performative cost; requires pruning",
        "Users need strategies to navigate and interpret the set of explanations effectively"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "An X-IDS architecture featuring SOM, GSOM, and GHSOM built using DARPA’s guidelines for explainable systems; CL models are 1%–3% less accurate than EBL models but are more explainable",
      "Analysis of statistical and visual explanations enabling users to understand model decisions (global significance and fine-grained feature explanations)",
      "A pruning process that significantly reduces GHSOM size, improving prediction speed with little accuracy loss",
      "Empirical performance analysis on NSL-KDD and CIC-IDS-2017 showing CL models within 1%–3% accuracy of EBL baselines"
    ]
  },
  {
    "arxiv_id": "2304.00648v1",
    "title": "Improving RF-DNA Fingerprinting Performance in an Indoor Multipath Environment Using Semi-Supervised Learning",
    "authors": "Mohamed k. Fadul; Donald R. Reising; Lakmali P. Weerasena; T. Daniel Loveless; Mina Sartipi",
    "abstract": "The number of Internet of Things (IoT) deployments is expected to reach 75.4 billion by 2025. Roughly 70% of all IoT devices employ weak or no encryption; thus, putting them and their connected infrastructure at risk of attack by devices that are wrongly authenticated or not authenticated at all. A physical layer security approach -- known as Specific Emitter Identification (SEI) -- has been proposed and is being pursued as a viable IoT security mechanism. SEI is advantageous because it is a passive technique that exploits inherent and distinct features that are unintentionally added to the signal by the IoT Radio Frequency (RF) front-end. SEI's passive exploitation of unintentional signal features removes any need to modify the IoT device, which makes it ideal for existing and future IoT deployments. Despite the amount of SEI research conducted, some challenges must be addressed to make SEI a viable IoT security approach. One challenge is the extraction of SEI features from signals collected under multipath fading conditions. Multipath corrupts the inherent SEI features that are used to discriminate one IoT device from another; thus, degrading authentication performance and increasing the chance of attack. This work presents two semi-supervised Deep Learning (DL) equalization approaches and compares their performance with the current state of the art. The two approaches are the Conditional Generative Adversarial Network (CGAN) and Joint Convolutional Auto-Encoder and Convolutional Neural Network (JCAECNN). Both approaches learn the channel distribution to enable multipath correction while simultaneously preserving the SEI exploited features. CGAN and JCAECNN performance is assessed using a Rayleigh fading channel under degrading SNR, up to thirty-two IoT devices, and two publicly available signal sets. The JCAECNN improves SEI performance by 10% beyond that of the current state of the art.",
    "published_date": "2023-04-02",
    "pdf_link": "https://arxiv.org/pdf/2304.00648v1",
    "paper_types": [
      "empirical_analysis",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Physical Layer Security (Wireless/IoT)",
      "subdomain": "Specific Emitter Identification (SEI) / RF-DNA fingerprinting",
      "specific_problem": "SEI for IoT device authentication under indoor multipath (Rayleigh) fading using semi-supervised equalization while preserving RF-DNA features",
      "attack_types": [
        "device impersonation/unauthorized access",
        "rogue device authentication",
        "spoofing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GAN",
        "specific": "Conditional GAN (CGAN) with label embedding",
        "novel_contribution": "Combines label embedding with CGAN to learn each emitter’s conditional feature distribution for semi-supervised channel equalization that preserves SEI features."
      },
      {
        "type": "primary",
        "category": "Autoencoder + CNN (joint training)",
        "specific": "Joint Convolutional Auto-Encoder and CNN (JCAECNN)",
        "novel_contribution": "A scalable semi-supervised architecture that jointly trains a CAE generative model and a CNN discriminative model to decompose multipath into delayed/scaled components before classification; uses exponentially decaying loss weights and dual (rectangular + polar) signal representations."
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "CNN-based SEI classifier augmented with rectangular and polar signal representations to enhance discriminatory feature learning under multipath."
      },
      {
        "type": "baseline",
        "category": "CNN + Autoencoder (pretraining)",
        "specific": "CAE-initialized CNN [41] with traditional channel estimation/equalization",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Semi-supervised",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "UTC 802.11a Wi‑Fi device dataset (Cisco AIR-CB21G-A-K9; ND=4, NB=2000 per device)",
        "type": "proprietary",
        "domain": "rf_signals",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Public signal set from [88] (authors’ public Wi‑Fi/RF signal set)",
        "type": "public",
        "domain": "rf_signals",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Public signal set from [89] (authors’ public Wi‑Fi/RF signal set)",
        "type": "public",
        "domain": "rf_signals",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CAE-initialized CNN with Nelder–Mead channel estimation and MMSE equalizer [41]",
        "paper_reference": "[41]",
        "metric": "Percent correct classification (accuracy)",
        "their_result": "\"The JCAECNN improves SEI performance by 10% beyond that of the current state of the art.\"",
        "baseline_result": null
      },
      {
        "method_name": "Prior SEI approach from authors’ earlier work [38]",
        "paper_reference": "[38]",
        "metric": "Percent correct classification (accuracy)",
        "their_result": "Direct comparison reported; JCAECNN shows improvement (exact baseline numbers not provided in excerpt).",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Percent correct classification",
      "Accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can semi-supervised DL equalization (CGAN, JCAECNN) learn the channel distribution to correct multipath while preserving SEI features?",
        "How does SEI performance vary under Rayleigh fading with degrading SNR and increasing number of devices (4/8/16/32)?",
        "Does joint generative–discriminative training (JCAECNN) outperform CGAN and prior state-of-the-art methods for RF-DNA fingerprinting?"
      ],
      "gaps_identified": [
        "Most DL-based SEI works do not rigorously evaluate under multipath; channels often static or environment specifics unstated or unknown.",
        "Assuming DL can learn invariant features directly from received signals without channel correction is flawed in time-varying multipath.",
        "Traditional channel estimation/equalization before DL (e.g., N-M + MMSE) leads to sub-optimal SEI due to estimation errors and dependence on channel statistics."
      ],
      "limitations": [
        "Evaluation uses Rayleigh TDL indoor channel models (simulated multipath) rather than over-the-air real-time indoor deployments.",
        "Primary data uses IEEE 802.11a preambles only; generalization to other protocols/channel types not shown in excerpt.",
        "Device scale evaluated up to 32 devices; larger-scale, heterogeneous hardware not shown in excerpt.",
        "Exact implementation details (code, frameworks, hyperparameters) and runtime/compute requirements not provided in excerpt."
      ],
      "future_work": [],
      "motivation": "Address the degradation of SEI (RF-DNA) features under indoor multipath to make PHY-layer authentication viable for IoT where many devices have weak/no encryption.",
      "potential_research_ideas": [
        "Evaluate JCAECNN and CGAN on real over-the-air indoor/industrial environments with controlled reflectors and mobility to validate robustness beyond Rayleigh models.",
        "Extend to other PHYs (802.11ax, BLE, LTE-M, LoRa) and multi-antenna (MIMO) scenarios; study transferability across protocols.",
        "Incorporate self-supervised or contrastive pretraining on large unlabeled RF corpora to improve feature invariance to channel dynamics.",
        "Online/continual learning for channel drift and device aging; implement domain adaptation across sites/environments.",
        "Open-set and incremental SEI (new/rogue device detection) with uncertainty estimation and calibration.",
        "Joint synchronization and equalization within the network (learned CFO/phase/noise correction) to further preserve RF-DNA.",
        "Adversarial robustness studies (e.g., replay, over-the-air perturbations) and defenses tailored to SEI."
      ],
      "architectural_improvement_recommendations": [
        "Add physics-informed convolutions or differentiable channel layers with constraints tied to TDL parameters to regularize equalization.",
        "Replace CNN back-end with temporal/convolutional transformers to capture longer-range dependencies across preamble segments.",
        "Multi-branch inputs: separate I/Q, magnitude/phase, and spectrogram paths with cross-attention fusion.",
        "Uncertainty-aware training (e.g., MC-dropout, deep ensembles) to support open-set SEI and robust decision thresholds.",
        "Curriculum learning over SNR and path count; harder-negative mining across devices/serials.",
        "Meta-learning for rapid adaptation to new environments/devices with few labeled exemplars."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Indoor Wi‑Fi scenario modeled via Rayleigh TDL (simulated multipath) using real captured 802.11a preambles",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Time-varying multipath hinders learning of invariant device-specific features.",
        "Dependence on channel conditions and SNR; robustness across environments must be ensured.",
        "Need to preserve subtle RF-DNA features during equalization without over-suppressing discriminative coloration."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Combines label embedding with a CGAN to efficiently learn each emitter’s conditional feature distribution.",
      "Augments discriminatory feature learning via rectangular and polar signal representations.",
      "Introduces two semi-supervised learning equalization approaches enabling superior CNN-based SEI under Rayleigh fading and degrading SNR.",
      "Introduces a scalable joint CAE–CNN (JCAECNN) architecture that decomposes multipath into delayed/scaled versions of the transmitted signal prior to classification.",
      "Improves JCAECNN via exponentially decaying loss-function weights.",
      "Evaluates CGAN and JCAECNN across 4, 8, 16, and 32 devices over Rayleigh fading channels.",
      "Benchmarks on two publicly available signal sets ([88], [89]) to enable cross-paper comparisons.",
      "Directly compares CGAN and JCAECNN to prior work [38], [41].",
      "Reported result: \"These contributions result in an average percent correct classification performance of 94.35% or better for SNR values of 9 dB or higher, Rayleigh fading channels comprised of five reflections/paths and an IoT deployment consisting of sixteen devices.\"",
      "Reported result: \"The JCAECNN improves SEI performance by 10% beyond that of the current state of the art.\""
    ]
  },
  {
    "arxiv_id": "2305.09673v1",
    "title": "Vulnerability Detection Using Two-Stage Deep Learning Models",
    "authors": "Mohamed Mjd Alhafi; Mohammad Hammade; Khloud Al Jallad",
    "abstract": "Application security is an essential part of developing modern software, as lots of attacks depend on vulnerabilities in software. The number of attacks is increasing globally due to technological advancements. Companies must include security in every stage of developing, testing, and deploying their software in order to prevent data breaches. There are several methods to detect software vulnerability Non-AI-based such as Static Application Security Testing (SAST) and Dynamic Application Security Testing (DAST). However, these approaches have substantial false-positive and false-negative rates. On the other side, researchers have been interested in developing an AI-based vulnerability detection system employing deep learning models like BERT, BLSTM, etc. In this paper, we proposed a two-stage solution, two deep learning models were proposed for vulnerability detection in C/C++ source codes, the first stage is CNN which detects if the source code contains any vulnerability (binary classification model) and the second stage is CNN-LTSM that classifies this vulnerability into a class of 50 different types of vulnerabilities (multiclass classification model). Experiments were done on SySeVR dataset. Results show an accuracy of 99% for the first and 98% for the second stage.",
    "published_date": "2023-05-08",
    "pdf_link": "https://arxiv.org/pdf/2305.09673v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Software Vulnerability Detection",
      "specific_problem": "Static source-code vulnerability detection and multi-class classification of CWE types in C/C++",
      "attack_types": [
        "CWE-based software vulnerabilities (50 classes; e.g., CWE-121 Stack-based Buffer Overflow)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "Stage-1 1D CNN for binary vulnerable vs. non-vulnerable classification using token-normalized code text"
      },
      {
        "type": "primary",
        "category": "CNN+LSTM",
        "specific": null,
        "novel_contribution": "Stage-2 hybrid CNN-LSTM for 50-way CWE multiclass classification"
      },
      {
        "type": "primary",
        "category": "Data sampling",
        "specific": "SMOTE",
        "novel_contribution": "Applied to address severe class imbalance across 50 vulnerability classes"
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GGNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GCN / GCE",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT (with BLSTM)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN/LSTM",
        "specific": "LSTM/GRU/BLSTM/BGRU",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Classical ML",
        "specific": "Logistic Regression, SVM, Random Forest, MLP",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "CNN (text/BOW variants)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature engineering",
        "specific": "Bag of Words",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Attention",
        "specific": "Multi-context Attention Fusion",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "SySeVR",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SeVC (Semantics-based Vulnerability Candidates) within SySeVR",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SARD (Software Assurance Reference Dataset)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NVD (National Vulnerability Database)",
        "type": "public",
        "domain": "vulnerability_records",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CVEFixes",
        "type": "public",
        "domain": "source_code_patches",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ManySStuBs4J",
        "type": "public",
        "domain": "java_bug_fixes",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ESC (Ethereum Smart Contracts)",
        "type": "public",
        "domain": "smart_contracts",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VSC (VNT Chain Smart Contracts)",
        "type": "public",
        "domain": "smart_contracts",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ReVeal (FFmpeg + QEMU)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Draper VDISC",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MSR (as referenced in experiments)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Chrome & Debian (as referenced in experiments)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "BGRU on SySeVR",
        "paper_reference": "SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities",
        "metric": "Accuracy",
        "their_result": "99.2% (Convolutional); 98.7% (Convolutional + LSTM)",
        "baseline_result": "96%"
      },
      {
        "method_name": "GGNN on ReVeal",
        "paper_reference": "Deep Learning based Vulnerability Detection: Are We There Yet?",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": "84%"
      },
      {
        "method_name": "BERT + BLSTM on NVD/SARD",
        "paper_reference": "Security Vulnerability Detection Using Deep Learning Natural Language Processing",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": "93%"
      },
      {
        "method_name": "CNN+RF on Draper VDISC",
        "paper_reference": "Automated Vulnerability Detection in Source Code Using Deep Representation Learning",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": "91.6%"
      },
      {
        "method_name": "GCE on ESC & VSC",
        "paper_reference": "Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": "89%"
      },
      {
        "method_name": "Attention Fusion Model on SARD",
        "paper_reference": "Multi-context Attention Fusion Neural Network for Software Vulnerability Identification",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": "99%"
      },
      {
        "method_name": "LR/CNN/MLP/DBN/LSTM/GRU/BLSTM/BGRU on SySeVR",
        "paper_reference": "SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities",
        "metric": "F1-score",
        "their_result": null,
        "baseline_result": "LR 0.62; CNN 0.81; MLP 0.68; DBN 0.63; LSTM 0.79; GRU 0.81; BLSTM 0.83; BGRU 0.83"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does a two-stage deep learning pipeline (binary detection followed by multi-class CWE classification) improve vulnerability detection performance on C/C++ source code?",
        "Can normalizing identifiers via regular expressions to preserve semantic roles improve tokenization-based models for code vulnerability detection?",
        "Can SMOTE mitigate severe class imbalance across vulnerability categories when training deep models?"
      ],
      "gaps_identified": [
        "Traditional SAST/DAST approaches suffer from substantial false positives and false negatives.",
        "Naive tokenization of source code fails to capture semantic dependencies due to open variable/function namespaces.",
        "Severe class imbalance across vulnerability classes limits multi-class classifiers.",
        "Existing methods often do not localize vulnerabilities or handle multiple vulnerabilities per sample."
      ],
      "limitations": [
        "Current approach does not localize the vulnerability within the code.",
        "Does not explicitly handle multiple vulnerabilities per sample.",
        "Evaluated primarily on the SySeVR dataset; cross-project/cross-language generalization not studied.",
        "No analysis of explainability, adversarial robustness, or privacy."
      ],
      "future_work": [
        "Model source code as a graph and use Graph Neural Networks.",
        "Detect multiple vulnerabilities within a sample.",
        "Detect the position (localization) of the vulnerability.",
        "Use sequence-to-sequence models to fix vulnerable code."
      ],
      "motivation": "Growing prevalence of attacks exploiting software vulnerabilities and the limitations of traditional SAST/DAST motivate AI-based methods to reduce false positives/negatives and improve detection accuracy.",
      "potential_research_ideas": [
        "Integrate code graphs (AST/CFG/PDG) with token sequences via graph-text fusion for improved context capture.",
        "End-to-end multi-task model that jointly performs detection, localization, and CWE classification.",
        "Cross-language transfer using pre-trained code models (e.g., CodeBERT/GraphCodeBERT/CodeT5) with domain adaptation.",
        "Adversarial robustness evaluation for code models (identifier renaming, dead-code insertion, reformatting) and robust training.",
        "Active learning or curriculum learning to address long-tail CWE classes beyond SMOTE.",
        "Self-supervised or contrastive pretraining on large unlabeled code corpora before fine-tuning on vulnerability labels.",
        "Calibration and threshold optimization for operational use to control false positives in CI/CD pipelines.",
        "Data-centric augmentation pipelines (semantic-preserving code transformations) to diversify training data."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment CNN/LSTM with transformer-based code encoders (CodeBERT/GraphCodeBERT/CodeT5) for richer semantic understanding.",
        "Graph-aware architecture: build Code Property Graphs and use GNNs; fuse graph embeddings with token embeddings via cross-attention.",
        "Hierarchical model (function-level and file-level) to capture broader context around vulnerable snippets.",
        "Multi-task learning with shared backbone and heads for binary detection, CWE classification, and span/localization.",
        "Improved imbalance handling (focal loss, class-balanced loss, deferred reweighting) in addition to or instead of SMOTE.",
        "Identifier handling via learned subword tokenization and variable anonymization combined with copy/pointer mechanisms.",
        "Uncertainty estimation and model calibration (temperature scaling) for reliable deployment.",
        "Post-hoc explainability (Integrated Gradients, attention rollout) tailored to code tokens/AST nodes."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a two-stage deep learning pipeline: Stage-1 1D CNN for binary vulnerability detection; Stage-2 CNN-LSTM for 50-class CWE classification.",
      "Proposes regex-based normalization of variables and function identifiers to preserve semantic roles and reduce vocabulary sparsity before tokenization.",
      "Applies SMOTE to mitigate class imbalance in multi-class vulnerability classification.",
      "Reports high performance on the SySeVR dataset: 99% accuracy (Stage-1) and 98% accuracy (Stage-2); overall comparison up to 99.2% on SySeVR.",
      "Provides empirical comparison against prior approaches reported in the literature."
    ]
  },
  {
    "arxiv_id": "2303.12367v1",
    "title": "AIIPot: Adaptive Intelligent-Interaction Honeypot for IoT Devices",
    "authors": "Volviane Saphir Mfogo; Alain Zemkoho; Laurent Njilla; Marcellin Nkenlifack; Charles Kamhoua",
    "abstract": "The proliferation of the Internet of Things (IoT) has raised concerns about the security of connected devices. There is a need to develop suitable and cost-efficient methods to identify vulnerabilities in IoT devices in order to address them before attackers seize opportunities to compromise them. The deception technique is a prominent approach to improving the security posture of IoT systems. Honeypot is a popular deception technique that mimics interaction in real fashion and encourages unauthorised users (attackers) to launch attacks. Due to the large number and the heterogeneity of IoT devices, manually crafting the low and high-interaction honeypots is not affordable. This has forced researchers to seek innovative ways to build honeypots for IoT devices. In this paper, we propose a honeypot for IoT devices that uses machine learning techniques to learn and interact with attackers automatically. The evaluation of the proposed model indicates that our system can improve the session length with attackers and capture more attacks on the IoT network.",
    "published_date": "2023-03-22",
    "pdf_link": "https://arxiv.org/pdf/2303.12367v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Deception/Honeypots",
      "specific_problem": "Adaptive intelligent-interaction honeypot that passes attacker pre-checks and elicits exploit code to increase session length and capture more IoT attacks",
      "attack_types": [
        "pre-check reconnaissance of device/services",
        "exploit delivery against IoT services",
        "web interface probing",
        "network scanning of open ports"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT",
        "novel_contribution": "Fine-tuned BERT used to rank/select likely attacker-expected responses from a req/res database to pass IoT attacker pre-checks"
      },
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": "MDP with online Q-learning and epsilon-greedy policy",
        "novel_contribution": "Models the future direction of the attacker-honeypot conversation and selects responses to maximize session length and likelihood of receiving exploit code"
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": "MDP (without transformer pre-selection) as used in IoTCandyJar",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Seq2Seq",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Reinforcement Learning",
      "Online Learning",
      "Transfer Learning"
    ],
    "datasets": [
      {
        "name": "AIIPot req/res database (requests/responses between attackers and IoT devices)",
        "type": "proprietary",
        "domain": "network_services/http_requests_responses",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "IoTCandyJar",
        "paper_reference": "[5]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "FirmPot",
        "paper_reference": "[7]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Chameleon",
        "paper_reference": "[6]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "SIPHON (high-interaction IoT honeypot)",
        "paper_reference": "[8]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "honeyd (low-interaction)",
        "paper_reference": "[2]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "U-PoT (device-specific emulation)",
        "paper_reference": "[3]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "ThingPot (device-specific emulation)",
        "paper_reference": "[4]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "session length (number of back-and-forth requests)",
      "number of captured attacks"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Low-interaction honeypots have fixed behavior and are easily detected; cannot pass attacker pre-checks",
        "High-interaction honeypots are complex, time-consuming to deploy/maintain, and do not scale due to resource costs",
        "IoTCandyJar requires long warm-up learning time (“it took two weeks for the model to learn enough to interact with attackers continuously”) and responses collected by internet scanning may include honeypot-generated responses",
        "FirmPot relies on firmware emulation and Seq2Seq mapping; may fail to capture advanced attacks, may not converge, and responses collected during scanning could be from fake web apps; approach depends heavily on availability and vulnerabilities of firmware images",
        "Heterogeneity of IoT devices and versions makes manually crafting low/high-interaction honeypots unaffordable"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve IoT honeypot interaction to pass attacker pre-checks, extend sessions, and capture exploit code cost-effectively despite IoT heterogeneity.",
      "potential_research_ideas": [
        "Integrate protocol-aware parsers and device fingerprint emulation (headers, banners, timing, TLS/HTTP quirks) to reduce honeypot detectability by sophisticated adversaries",
        "Use retrieval-augmented generation that queries a larger, curated response memory (including protocol specs and firmware docs) to select responses for rare/OOV requests",
        "Incorporate exploit/payload detectors (e.g., signature-based and ML-based) into reward shaping to directly reward elicitation of malicious payloads rather than only session length",
        "Leverage large language models fine-tuned for security dialogue with constrained decoding and strict templating to handle multi-protocol/multi-turn interactions",
        "Add active probing (counter-questions) to guide attackers toward payload disclosure while staying stealthy, modeled via constrained RL with safety shields",
        "Create a shared, sanitized benchmark of IoT honeypot request/response traces with attacker labels to enable reproducible evaluation across works"
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment BERT with a dual-encoder retrieval model that embeds requests and candidate responses for fast, scalable nearest-neighbor selection before RL re-ranking",
        "Adopt context-aware RL (POMDP) with belief tracking over attacker goals and device types; use model-based RL to simulate attacker transitions for data efficiency",
        "Use hierarchical policies: a high-level policy selects emulated device profile, while a low-level policy chooses concrete responses consistent with that profile",
        "Implement protocol-constrained decoding layers to ensure responses always comply with protocol syntax/semantics, reducing dead-end transitions",
        "Introduce uncertainty estimation (e.g., Monte Carlo dropout or ensembles) to gate when to broadcast to real devices for ground-truth responses",
        "Curate a trusted response cache built from verified real devices to avoid contamination from other honeypots; add data sanitization and deduplication pipelines"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Honeypot server integrated with an IoT device network for request broadcasting",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Potential detection by skilled attackers if responses lack consistent device fingerprinting",
        "Dataset contamination risk when sourcing responses from the internet (responses could be from other honeypots)",
        "Handling out-of-vocabulary requests and complex multi-step checks",
        "IoT heterogeneity across vendors, firmware versions, and protocols",
        "Balancing safe broadcasting of attacker requests to real devices without causing side-effects"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A honeypot based on a transformer model is proposed to capture vulnerabilities on IoT devices.",
      "Reinforcement learning concepts are used to model the future direction of the interaction between the honeypot and the attacker.",
      "A novel technique to collect a new dataset of the interaction between attackers and IoT devices is proposed.",
      "Claimed novelty: “the first to build a honeypot for IoT devices based on a transformer chatbot, which uses reinforcement learning to model the future direction of the conversation.”",
      "Evaluation claim: “our system can improve the session length with attackers and capture more attacks on the IoT network.”"
    ]
  },
  {
    "arxiv_id": "2302.13079v1",
    "title": "Privacy-Preserving Electricity Theft Detection based on Blockchain",
    "authors": "Zhiqiang Zhao; Yining Liu; Zhixin Zeng; Zhixiong Chen; Huiyu Zhou",
    "abstract": "In most electricity theft detection schemes, consumers' power consumption data is directly input into the detection center. Although it is valid in detecting the theft of consumers, the privacy of all consumers is at risk unless the detection center is assumed to be trusted. In fact, it is impractical. Moreover, existing schemes may result in some security problems, such as the collusion attack due to the presence of a trusted third party, and malicious data tampering caused by the system operator (SO) being attacked. Aiming at the problems above, we propose a blockchain-based privacy-preserving electricity theft detection scheme without a third party. Specifically, the proposed scheme uses an improved functional encryption scheme to enable electricity theft detection and load monitoring while preserving consumers' privacy; distributed storage of consumers' data with blockchain to resolve security problems such as data tampering, etc. Meanwhile, we build a long short-term memory network (LSTM) model to perform higher accuracy for electricity theft detection. The proposed scheme is evaluated in a real environment, and the results show that it is more accurate in electricity theft detection within acceptable communication and computational overhead. Our system analysis demonstrates that the proposed scheme can resist various security attacks and preserve consumers' privacy.",
    "published_date": "2023-02-25",
    "pdf_link": "https://arxiv.org/pdf/2302.13079v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Smart Grid Security",
      "subdomain": "Electricity Theft Detection",
      "specific_problem": "Privacy-preserving electricity theft detection and load monitoring without a trusted third party using blockchain and functional encryption",
      "attack_types": [
        "data_tampering",
        "false_data_injection",
        "collusion_attack",
        "replay_attack",
        "eavesdropping",
        "data_forgery",
        "non_repudiation_violation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": "Integrates an LSTM-based time-series detector with an improved functional encryption workflow enabling privacy-preserving inference of the first layer (only first-layer weights shared; decryption keys computed per neuron to avoid revealing raw readings)."
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Federated Learning",
        "specific": "CNN (federated)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feed-Forward Neural Network",
        "specific": "FNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Clustering",
        "specific": "DBSCAN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "1-D CNN",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Real environment smart meter readings from a residential area (electricity theft detection period T)",
        "type": "proprietary",
        "domain": "smart_meter_power_consumption",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "communication_overhead",
      "computational_overhead"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to perform electricity theft detection and load monitoring without exposing consumers’ fine-grained power consumption data?",
        "How to remove reliance on a trusted third party while maintaining security and operational integrity of the smart grid?",
        "Can a blockchain-backed storage and an improved functional encryption scheme enable privacy-preserving detection with acceptable overhead?"
      ],
      "gaps_identified": [
        "Reliance on trusted third parties (detection center or key distribution center) risks privacy leakage and collusion.",
        "Existing schemes insufficiently address smart grid operational security (e.g., data tampering if centralized components are attacked).",
        "Some privacy-preserving approaches incur prohibitive computation and communication overhead.",
        "Limited support for load monitoring while preserving privacy."
      ],
      "limitations": [
        "Assumes an honest-but-curious system operator; residual trust assumption remains.",
        "Relies on mining node (MN) election and blockchain consensus; security hinges on majority assumptions (e.g., 51% of SMs).",
        "Model design requires first-layer neuron count n < input length d to prevent reconstruction of raw data, which may constrain model capacity.",
        "Blockchain and cryptographic operations introduce additional latency, storage, and bandwidth overhead on SMs and MNs.",
        "Evaluation details and datasets are not publicly available, limiting independent reproducibility."
      ],
      "future_work": [],
      "motivation": "Protect consumer privacy and ensure grid security while enabling accurate electricity theft detection and load monitoring, eliminating risks from trusted third parties and mitigating attacks like collusion and data tampering.",
      "potential_research_ideas": [
        "Design a privacy-preserving transformer or Temporal Convolutional Network for smart meter time series with encrypted first-layer computation.",
        "Incorporate differential privacy or local DP noise to further bound information leakage from shared first-layer weights.",
        "Develop zero-knowledge proofs to verify correct on-chain aggregation and model inference without revealing inputs or parameters.",
        "Extend to multi-region and hierarchical detection with topology-aware models (e.g., GNNs over feeder graphs) under encryption.",
        "Online/continual learning under encryption to handle concept drift in consumption patterns.",
        "Adopt verifiable outsourced computation for model inference to reduce on-device costs while preserving privacy."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment LSTM with lightweight temporal CNNs or transformer encoders optimized for encrypted first-layer linear ops.",
        "Quantize and prune first-layer weights to reduce encrypted-domain computation and communication.",
        "Employ hybrid on-chain/off-chain storage with Merkle commitments and succinct proofs to cut blockchain storage overhead.",
        "Introduce key rotation and threshold cryptography for MN and decryption keys to strengthen collusion resistance.",
        "Use batching and packed ciphertext techniques (e.g., RLWE-based schemes) to accelerate vector-matrix products in the encrypted first layer.",
        "Incorporate adversarial training or robust loss functions to harden the detector against manipulation of encrypted inputs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Residential area smart grid with smart meters, mining node, distribution transformer meters, and SO using a blockchain network",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Blockchain throughput and storage overhead for frequent SM reporting.",
        "Cryptographic key management (secure aggregation keys DA and per-neuron DW keys).",
        "Consensus and MN election reliability; resilience to MN failures.",
        "Time synchronization for timestamps to prevent replay attacks.",
        "Resource constraints on SMs for encryption, signing, and communication.",
        "Parameter choice constraint (n < d) affecting model capacity vs. privacy."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a blockchain-based electricity theft detection scheme with distributed storage to address data tampering risks of centralized storage.",
      "Improves a functional encryption scheme to enable privacy-preserving electricity theft detection and load monitoring without a trusted key distribution center.",
      "Builds an LSTM-based model tailored for time-series smart meter data and analyzes parameter settings to achieve higher performance.",
      "System analysis shows resistance to various security attacks and privacy preservation, with evaluation indicating higher accuracy within acceptable communication and computational overhead."
    ]
  },
  {
    "arxiv_id": "2303.09999v2",
    "title": "STIXnet: A Novel and Modular Solution for Extracting All STIX Objects in CTI Reports",
    "authors": "Francesco Marchiori; Mauro Conti; Nino Vincenzo Verde",
    "abstract": "The automatic extraction of information from Cyber Threat Intelligence (CTI) reports is crucial in risk management. The increased frequency of the publications of these reports has led researchers to develop new systems for automatically recovering different types of entities and relations from textual data. Most state-of-the-art models leverage Natural Language Processing (NLP) techniques, which perform greatly in extracting a few types of entities at a time but cannot detect heterogeneous data or their relations. Furthermore, several paradigms, such as STIX, have become de facto standards in the CTI community and dictate a formal categorization of different entities and relations to enable organizations to share data consistently. This paper presents STIXnet, the first solution for the automated extraction of all STIX entities and relationships in CTI reports. Through the use of NLP techniques and an interactive Knowledge Base (KB) of entities, our approach obtains F1 scores comparable to state-of-the-art models for entity extraction (0.916) and relation extraction (0.724) while considering significantly more types of entities and relations. Moreover, STIXnet constitutes a modular and extensible framework that manages and coordinates different modules to merge their contributions uniquely and exhaustively. With our approach, researchers and organizations can extend their Information Extraction (IE) capabilities by integrating the efforts of several techniques without needing to develop new tools from scratch.",
    "published_date": "2023-03-17",
    "pdf_link": "https://arxiv.org/pdf/2303.09999v2",
    "paper_types": [
      "empirical_analysis",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Threat Intelligence",
      "subdomain": "Cyber Threat Intelligence (CTI) Processing",
      "specific_problem": "Automated extraction of all STIX entities and relationships from unstructured CTI reports",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Rule-based NLP",
        "specific": null,
        "novel_contribution": "Dependency-parsing-based shortest-path verb matching to map sentences to STIX relationship types with confidence estimation"
      },
      {
        "type": "primary",
        "category": "Sentence Embeddings",
        "specific": null,
        "novel_contribution": "Use of deep learning sentence embeddings to adjust and re-rank relation candidates by similarity to relationship label embeddings"
      },
      {
        "type": "primary",
        "category": "NER/POS/Dependency Parsing",
        "specific": null,
        "novel_contribution": "Novel entity extraction via POS tagging and dependency parsing coupled with verb-trigger heuristics to capture entities not in the KB"
      },
      {
        "type": "primary",
        "category": "Knowledge-Base String Matching",
        "specific": null,
        "novel_contribution": "KB-driven multi-alias string matching for STIX entities combined with NLP filters; interactive KB that grows with each run"
      },
      {
        "type": "primary",
        "category": "Regular Expressions",
        "specific": "IOC pattern matching",
        "novel_contribution": "Regex-based extraction of Indicators of Compromise (e.g., IPs, hashes, URLs) with normalization and artifact handling"
      },
      {
        "type": "primary",
        "category": "Supervised Classifier",
        "specific": "MITRE ATT&CK tactic/technique classifier",
        "novel_contribution": "Model trained to recognize implicit TTPs (tactics/techniques) even when not explicitly named in text"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Rule-based",
      "Knowledge-based"
    ],
    "datasets": [
      {
        "name": "STIXnet testbed (annotated CTI reports via LabelStudio)",
        "type": "public",
        "domain": "cti_reports",
        "link": "https://anonymous.4open.science/r/STIXnet-7710",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "MITRE ATT&CK Knowledge Base",
        "type": "public",
        "domain": "threat_intelligence_knowledge_base",
        "link": "https://attack.mitre.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "National Vulnerability Database (NVD) CVE descriptions",
        "type": "public",
        "domain": "vulnerability_descriptions",
        "link": "https://nvd.nist.gov/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Weerawardhana et al. [30]",
        "paper_reference": "Weerawardhana et al.",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Li et al. [14]",
        "paper_reference": "Li et al.",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Zhou et al. (2022) [36]",
        "paper_reference": "Zhou et al. 2022",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Zhou et al. (2023) [35]",
        "paper_reference": "Zhou et al. 2023",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Ranade et al. [20]",
        "paper_reference": "Ranade et al.",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Wang et al. [28]",
        "paper_reference": "Wang et al.",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "You et al. [34] (TTP extraction)",
        "paper_reference": "You et al.",
        "metric": "Accuracy (TTP extraction)",
        "their_result": "STIXnet reports entity F1=0.916, relation F1=0.724 (different task/label space)",
        "baseline_result": "0.941"
      },
      {
        "method_name": "Legoy et al. rcATT [13] (TTP prediction)",
        "paper_reference": "Legoy et al.",
        "metric": "Precision (tactics/techniques)",
        "their_result": "Different task; STIXnet F1 entity=0.916, relation=0.724",
        "baseline_result": "≈0.75"
      },
      {
        "method_name": "Gasmi et al. [9] (NVD IE)",
        "paper_reference": "Gasmi et al.",
        "metric": "Precision (entity/relation)",
        "their_result": "Different corpus/scope; STIXnet F1 entity=0.916, relation=0.724",
        "baseline_result": "Entities: 89%; Relations: 92%"
      }
    ],
    "performance_metrics_used": [
      "F1"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a modular framework automatically extract all STIX entity types and relationships from heterogeneous CTI reports?",
        "Can combining NLP, a growing Knowledge Base, and ML/DL modules achieve competitive IE performance while covering many more entity/relation types?"
      ],
      "gaps_identified": [
        "Most state-of-the-art models extract only a few entity types and cannot detect heterogeneous data or their relations.",
        "Merging results from different specialized models is non-trivial due to conflicts and differing standards/paradigms.",
        "Static, non-interactive databases are ineffective given new entities and aliases emerging in CTI reports.",
        "ML/DL IE models are hard to scale to wider domains and require retraining and re-annotation to add new STIX types.",
        "CTI vendor report styles vary; IOCs evolve frequently and must be continuously recognized and linked."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Manual STIX-compliant annotation of rapidly increasing CTI reports is time-consuming; a standardized, comprehensive, and extensible IE solution is needed to extract all STIX entities and relations for consistent sharing.",
      "potential_research_ideas": [
        "Extend STIXnet to multilingual CTI reports with cross-lingual entity linking and relation extraction.",
        "Integrate large language models for few/zero-shot extraction of rare STIX entity types and long-tail relations.",
        "Active learning loop with analysts to reduce annotation cost while expanding coverage and improving confidence calibration.",
        "Adversarially robust IOC and entity extraction resilient to obfuscation (e.g., homograph attacks, inserted noise).",
        "Joint entity-relation extraction model fine-tuned on the STIXnet dataset to complement/replace rule-based components.",
        "Coreference resolution and event extraction to better connect dispersed mentions across long reports.",
        "Graph-based reasoning (e.g., GNNs) over the intermediate knowledge graph to infer missing links and validate relations."
      ],
      "architectural_improvement_recommendations": [
        "Introduce a joint neural IE model (e.g., transformer-based sequence labeling + relation classification) to reduce reliance on handcrafted rules.",
        "Adopt contrastive learning to train relation label and sentence embeddings in the same space for improved zero-shot relation mapping.",
        "Add neural entity linking with alias expansion using KB embeddings to reduce false positives from name matching.",
        "Incorporate coreference resolution and sentence-level discourse parsing to improve relation extraction across sentences.",
        "Implement a calibrated confidence fusion layer (e.g., stacking or Bayesian model averaging) for module result merging.",
        "Use distant supervision from ATT&CK and public CTI corpora to expand training data for TTP detection.",
        "Add plug-in for multilingual tokenization and translation with back-translation consistency checks."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://anonymous.4open.science/r/STIXnet-7710",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Heterogeneous report formats and artifacts during text extraction require robust normalization.",
        "Entity conflicts and deduplication when merging outputs from multiple modules.",
        "Evolving indicators and aliases necessitate continuous KB updates.",
        "Standard alignment across STIX and ATT&CK requires careful mapping."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First system for automatically extracting all types of STIX entities (18) and relations (>100) from CTI reports.",
      "Novel modular and extensible framework for coordinating several IE modules.",
      "Methodology for integrating module results via a confidence value with minimal supervision.",
      "Released testbed (dataset and annotated reports) and code for some modules."
    ]
  },
  {
    "arxiv_id": "2303.02545v1",
    "title": "MINER: A Hybrid Data-Driven Approach for REST API Fuzzing",
    "authors": "Chenyang Lyu; Jiacheng Xu; Shouling Ji; Xuhong Zhang; Qinying Wang; Binbin Zhao; Gaoning Pan; Wei Cao; Raheem Beyah",
    "abstract": "In recent years, REST API fuzzing has emerged to explore errors on a cloud service. Its performance highly depends on the sequence construction and request generation. However, existing REST API fuzzers have trouble generating long sequences with well-constructed requests to trigger hard-to-reach states in a cloud service, which limits their performance of finding deep errors and security bugs. Further, they cannot find the specific errors caused by using undefined parameters during request generation. Therefore, in this paper, we propose a novel hybrid data-driven solution, named MINER, with three new designs working together to address the above limitations. First, MINER collects the valid sequences whose requests pass the cloud service's checking as the templates, and assigns more executions to long sequence templates. Second, to improve the generation quality of requests in a sequence template, MINER creatively leverages the state-of-the-art neural network model to predict key request parameters and provide them with appropriate parameter values. Third, MINER implements a new data-driven security rule checker to capture the new kind of errors caused by undefined parameters. We evaluate MINER against the state-of-the-art fuzzer RESTler on GitLab, Bugzilla, and WordPress via 11 REST APIs. The results demonstrate that the average pass rate of MINER is 23.42% higher than RESTler. MINER finds 97.54% more unique errors than RESTler on average and 142.86% more reproducible errors after manual analysis. We have reported all the newly found errors, and 7 of them have been confirmed as logic bugs by the corresponding vendors.",
    "published_date": "2023-03-05",
    "pdf_link": "https://arxiv.org/pdf/2303.02545v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Application Security",
      "subdomain": "API Security / Fuzzing",
      "specific_problem": "REST API fuzzing for cloud services: generating long, valid request sequences and high-quality requests; detecting errors from undefined parameter usage",
      "attack_types": [
        "use-after-free (cloud service scenario: accessing deleted resources)",
        "resource-hierarchy bugs",
        "incorrect/undefined parameter usage errors",
        "logic bugs"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Attention-based neural network",
        "specific": null,
        "novel_contribution": "Learning implicit relationships among key request parameter mutations to predict which parameters to mutate and their values for high-quality request generation in REST API fuzzing"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Online"
    ],
    "datasets": [
      {
        "name": "GitLab REST APIs (multiple endpoints, incl. Projects API)",
        "type": "public",
        "domain": "web_application_apis",
        "link": "https://gitlab.com",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Bugzilla REST APIs",
        "type": "public",
        "domain": "web_application_apis",
        "link": "https://www.bugzilla.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "WordPress REST APIs",
        "type": "public",
        "domain": "web_application_apis",
        "link": "https://wordpress.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "RESTler",
        "paper_reference": null,
        "metric": "Average pass rate",
        "their_result": "Average pass rate is 23.42% higher than RESTler",
        "baseline_result": null
      },
      {
        "method_name": "RESTler",
        "paper_reference": null,
        "metric": "Unique errors found",
        "their_result": "Finds 97.54% more unique errors than RESTler on average",
        "baseline_result": null
      },
      {
        "method_name": "RESTler",
        "paper_reference": null,
        "metric": "Reproducible errors (after manual analysis)",
        "their_result": "Finds 142.86% more reproducible errors than RESTler",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "pass rate (requests passing service checking)",
      "number of unique errors found",
      "number of reproducible errors (after manual analysis)",
      "code line coverage",
      "time overhead",
      "execution distribution across sequence lengths"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to construct long request sequences that reach deep states in cloud services?",
        "How to generate high-quality requests with appropriate parameter values to pass service checking?",
        "How to detect errors caused by using undefined parameters in request generation?"
      ],
      "gaps_identified": [
        "Existing REST API fuzzers have trouble generating long sequences with well-constructed requests to trigger hard-to-reach states.",
        "They cannot find specific errors caused by using undefined parameters during request generation.",
        "Sequence extension frequently abandons constructed templates, making it hard to build long sequences.",
        "Random parameter value selection prevents generating valid requests, resulting in low pass rates."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve REST API fuzzing effectiveness by enabling longer sequences, higher-quality request generation, and detection of undefined-parameter errors to find deep errors and security bugs in cloud services.",
      "potential_research_ideas": [
        "Replace the generic attention model with a Transformer-based sequence model trained on API specifications and historical requests to better capture parameter and inter-request dependencies.",
        "Use reinforcement learning to guide sequence template selection and extension with rewards from error discovery and pass rates.",
        "Leverage large language models to synthesize or refine Swagger/OpenAPI specs from web documentation to reduce manual spec creation overhead.",
        "Incorporate static analysis of server-side code or API schemas to constrain parameter domains and dependencies for safer, more efficient exploration.",
        "Add semantic authorization/role modeling to target access-control bugs (e.g., broken object-level authorization) during fuzzing.",
        "Develop a root-cause analysis component that clusters failing sequences and explains likely parameter/endpoint interactions responsible for errors."
      ],
      "architectural_improvement_recommendations": [
        "Adopt an encoder-decoder Transformer with attention over request templates and previously seen parameter-value pairs to predict next key mutations.",
        "Integrate grammar-constrained decoding aligned with Swagger/OpenAPI schemas to ensure syntactic validity during generation.",
        "Implement online active learning: prioritize uncertain or high-entropy predictions for targeted exploration and model updates.",
        "Combine the length-oriented scheduler with a bandit algorithm balancing long-sequence exploration and short-sequence exploitation.",
        "Augment the data-driven rule checker with a configurable suite (e.g., use-after-free, resource-hierarchy, authorization invariants) derived from specs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/puppet-meteor/MINER",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Not specified; authors report low time overhead."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Testing against real open-source cloud/web services via REST APIs (GitLab, Bugzilla, WordPress)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires Swagger/OpenAPI specifications, which may need manual construction from vendor web documentation."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Length-oriented sequence construction guided by historical valid sequences, prioritizing longer sequence templates.",
      "Attention model-based request generation to predict key parameters and appropriate values for high-quality requests.",
      "New data-driven security rule checker to detect errors caused by undefined parameter usage.",
      "Empirical evaluation on 11 REST APIs across GitLab, Bugzilla, and WordPress showing higher pass rates (+23.42%), more unique errors (+97.54%), and more reproducible errors (+142.86%) than RESTler.",
      "Open-sourced MINER to facilitate future research on REST API fuzzing."
    ]
  },
  {
    "arxiv_id": "2303.16561v2",
    "title": "Exploring and Enhancing Placement of IDS in RPL: A Federated Learning-based Approach",
    "authors": "Selim Yilmaz; Sevil Sen; Emre Aydogan",
    "abstract": "In RPL security, intrusion detection (ID) plays a vital role, especially given its susceptibility to attacks, particularly those carried out by insider threats. While numerous studies in the literature have proposed intrusion detection systems (IDS) utilizing diverse techniques, the placement of such systems within RPL topology remains largely unexplored. This study aims to address this gap by rigorously evaluating three intrusion detection architectures, considering central and distributed placement, across multiple criteria including effectiveness, cost, privacy, and security. The findings underscore the significant impact of attacker position and the proximity of IDS to attackers on detection outcomes. Hence, alongside the evaluation of traditional intrusion detection architectures, this study explores the use of federated learning (FL) for improving intrusion detection within RPL networks. FL's decentralized model training approach effectively addresses the impact of attacker position on IDS performance by ensuring the collection of relevant information from nodes regardless of their proximity to potential attackers. Moreover, this approach not only mitigates security concerns but also minimizes communication overhead among ID nodes. Consequently, FL reduces the need for extensive data transfer, thus mitigating the impact of packet loss and latency inherent in lossy networks. Additionally, the study investigates the effect of local data sharing on FL performance, clarifying the balance between effectiveness and security.",
    "published_date": "2023-03-29",
    "pdf_link": "https://arxiv.org/pdf/2303.16561v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Routing Security / Intrusion Detection for LLNs",
      "specific_problem": "Placement of IDS in RPL topologies and a federated learning-based IDS for RPL attacks",
      "attack_types": [
        "Decreased Rank (DR)",
        "Increased Version (IV)",
        "Blackhole (BH)",
        "Selective Forwarding (SF)",
        "Worst Parent (WP)",
        "DAG Inconsistency (DI)",
        "Hello Flood (HF)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": null,
        "novel_contribution": "FedID: collaborators train locally and share model weights; additionally share up to 10% of local samples to mitigate non-IID effects in RPL traffic; weight sharing reduces communication and preserves privacy in lossy LLNs."
      },
      {
        "type": "baseline",
        "category": "Ensemble/Voting (rule-based collaboration)",
        "specific": null,
        "novel_contribution": "Distributed and Collaborative ID (DCID) uses per-node IDS agents with a voting mechanism to reach decisions."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Federated"
    ],
    "datasets": [
      {
        "name": "Simulated RPL network traffic with 7 RPL-specific attacks (this paper)",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CIDwL (Central IDS with Local information)",
        "paper_reference": null,
        "metric": "detection performance (effectiveness)",
        "their_result": "“The experimental results show that FedID offers superior detection performance than CIDwL.”",
        "baseline_result": null
      },
      {
        "method_name": "CIDwG (Central IDS with Global information)",
        "paper_reference": null,
        "metric": "detection performance vs cost/communication overhead",
        "their_result": "“competitive performance with much lower cost, particularly after model’s development, in comparison to CIDwG...”",
        "baseline_result": null
      },
      {
        "method_name": "DCID (Distributed and Collaborative ID with voting)",
        "paper_reference": null,
        "metric": "detection performance vs cost/communication overhead",
        "their_result": "“competitive performance with much lower cost, particularly after model’s development, in comparison to ... DCID, making it highly suitable for LLNs.”",
        "baseline_result": null
      },
      {
        "method_name": "Single central ID node (e.g., root)",
        "paper_reference": null,
        "metric": "effectiveness across attacker locations",
        "their_result": "“A single central ID node, such as one placed at the root node, proves ineffective against attacks from multiple positions.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "detection accuracy/effectiveness",
      "communication overhead/cost",
      "energy consumption",
      "response time/latency",
      "privacy",
      "security (resilience to attacker position effects)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1 : Is one central IDS enough for effectively detecting all types of attacks that are performed at different locations?",
        "RQ2 : What is the minimum number of IDS required for effective detection?",
        "RQ3 : How do IDSs make decision together efficiently from the communication cost perspective?"
      ],
      "gaps_identified": [
        "“the placement of such systems within RPL topology remains largely unexplored.”",
        "Impact of attacker position and IDS proximity on detection outcomes is under-studied.",
        "Existing FL-based IDS for IoT rarely address RPL-specific attacks or realistic LLN constraints; most use non-RPL datasets.",
        "Prior RPL-IDS FL work focuses on a single attack (wormhole) and very small networks."
      ],
      "limitations": [
        "Distributed IDS increases overhead and energy consumption in LLNs.",
        "Federated approach requires sharing up to 10% local samples due to non-IID data, which partially relaxes strict privacy.",
        "Communication between IDS agents can be unreliable due to lossy links."
      ],
      "future_work": [],
      "motivation": "Assess how IDS placement in RPL topologies affects detection efficacy, cost, privacy, and security; and design a federated learning-based IDS to mitigate attacker-position effects and reduce communication overhead in LLNs.",
      "potential_research_ideas": [
        "Automated optimization of IDS placement (per-level or per-subtree) using reinforcement learning or combinatorial optimization under LLN constraints.",
        "Personalized/clustered federated learning across RPL levels or subtrees to better handle non-IID traffic while minimizing data sharing.",
        "Robust FL against poisoning/backdoor attacks tailored to IDS in LLNs (e.g., Krum, Trimmed-Mean, RSA, or anomaly-aware aggregation).",
        "Differential privacy or secure aggregation for FL in RPL to eliminate the need for raw sample sharing while preserving model utility.",
        "Graph-based models (e.g., GNNs over DODAG) for topology-aware intrusion detection and their federated variants.",
        "Event-triggered or topology-change-triggered FL round scheduling aligned with trickle timer dynamics to reduce communication.",
        "Communication-efficient FL (sparsification, quantization, sketching) adapted to low-power radios and lossy links.",
        "Continual/online learning to adapt to evolving attacks and dynamic RPL topologies without catastrophic forgetting.",
        "Benchmarking and releasing an open RPL IDS dataset with multiple attacks and attacker positions for reproducible evaluation.",
        "Cross-layer IDS combining RPL control-plane features with data-plane metrics to detect selective forwarding and blackhole more reliably."
      ],
      "architectural_improvement_recommendations": [
        "Incorporate FedProx/FedNova or personalized FL (pFedMe, Per-FedAvg) to mitigate non-IID without sharing raw samples.",
        "Use secure aggregation and optional differential privacy to strengthen privacy while sharing only model updates.",
        "Adopt topology-aware client selection and weighted aggregation (e.g., per-level quotas) to ensure representation across the DODAG.",
        "Employ lightweight GNNs or temporal models (e.g., TCN/LSTM) on control-message sequences and topology changes.",
        "Apply update compression (sparsification/quantization) and knowledge distillation to minimize communication and memory.",
        "Introduce robust aggregation (Median/Krum/Trimmed-Mean) and participant attestation to defend against compromised collaborators.",
        "Hybrid architecture: minimal per-level detectors with a federated coordinator at/near the root for aggregation and update orchestration."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Low-Power and Lossy Networks (LLNs) using RPL in IoT settings",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Lossy links causing packet loss and latency",
        "Energy constraints and overhead from distributed IDS communication",
        "Effect of attacker position on local observability and detection",
        "Privacy concerns when aggregating data/models",
        "Maintaining communication reliability among IDS agents in LLNs"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Comprehensive analysis of IDS placement in RPL across three architectures (CIDwL, CIDwG, DCID) over 31,626 simulation scenarios and multiple criteria (accuracy, cost, response time, privacy, security).",
      "Demonstrates the significant impact of attacker position and IDS proximity on detection outcomes; a single central IDS is ineffective against attacks from multiple positions.",
      "Shows distributing ID nodes (e.g., at least one per level) improves detection but increases overhead and energy consumption.",
      "Introduces FedID, a federated learning-based IDS for RPL that shares model weights (and up to 10% local samples) to address non-IID data and reduce communication overhead while preserving privacy.",
      "Empirical comparison showing FedID achieves superior detection to CIDwL and competitive performance to CIDwG/DCID with lower cost after model development.",
      "Investigates the effect of limited local data sharing on FL performance, clarifying the balance between effectiveness and security."
    ]
  },
  {
    "arxiv_id": "2305.09475v1",
    "title": "Reconstruction-based LSTM-Autoencoder for Anomaly-based DDoS Attack Detection over Multivariate Time-Series Data",
    "authors": "Yuanyuan Wei; Julian Jang-Jaccard; Fariza Sabrina; Wen Xu; Seyit Camtepe; Aeryn Dunmore",
    "abstract": "A Distributed Denial-of-service (DDoS) attack is a malicious attempt to disrupt the regular traffic of a targeted server, service, or network by sending a flood of traffic to overwhelm the target or its surrounding infrastructure. As technology improves, new attacks have been developed by hackers. Traditional statistical and shallow machine learning techniques can detect superficial anomalies based on shallow data and feature selection, however, these approaches cannot detect unseen DDoS attacks. In this context, we propose a reconstruction-based anomaly detection model named LSTM-Autoencoder (LSTM-AE) which combines two deep learning-based models for detecting DDoS attack anomalies. The proposed structure of long short-term memory (LSTM) networks provides units that work with each other to learn the long short-term correlation of data within a time series sequence. Autoencoders are used to identify the optimal threshold based on the reconstruction error rates evaluated on each sample across all time-series sequences. As such, a combination model LSTM-AE can not only learn delicate sub-pattern differences in attacks and benign traffic flows, but also minimize reconstructed benign traffic to obtain a lower range reconstruction error, with attacks presenting a larger reconstruction error. In this research, we trained and evaluated our proposed LSTM-AE model on reflection-based DDoS attacks (DNS, LDAP, and SNMP). The results of our experiments demonstrate that our method performs better than other state-of-the-art methods, especially for LDAP attacks, with an accuracy of over 99.",
    "published_date": "2023-04-21",
    "pdf_link": "https://arxiv.org/pdf/2305.09475v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Anomaly-based detection of reflection DDoS attacks in multivariate time-series network flow data",
      "attack_types": [
        "DDoS (reflection-based)",
        "DNS amplification",
        "LDAP amplification",
        "SNMP reflection"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN (LSTM) + Autoencoder",
        "specific": "LSTM-Autoencoder (Encoder-Decoder with RepeatVector and TimeDistributed layers)",
        "novel_contribution": "Reconstruction-based anomaly detection using MAE error per flow over fixed-length time windows; trained on benign-only traffic; threshold selected from minimized reconstruction error; flexible window-length anomaly scoring"
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "CICDDoS2019",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/ddos-2019.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random Forest (CICDDoS2019 baseline)",
        "paper_reference": "Sharafaldin et al. (CICDDoS2019) [16]",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": "Reported as highest (with ID3) among ML baselines in [16]; no exact number provided in this paper"
      },
      {
        "method_name": "ID3 (CICDDoS2019 baseline)",
        "paper_reference": "Sharafaldin et al. (CICDDoS2019) [16]",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": "Reported as highest (with RF) among ML baselines in [16]; no exact number provided in this paper"
      },
      {
        "method_name": "Naive Bayes (CICDDoS2019 baseline)",
        "paper_reference": "Sharafaldin et al. (CICDDoS2019) [16]",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Multinomial Logistic Regression (CICDDoS2019 baseline)",
        "paper_reference": "Sharafaldin et al. (CICDDoS2019) [16]",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Chronos (Autoencoder)",
        "paper_reference": "Salahuddin et al. [12]",
        "metric": "F1-score",
        "their_result": null,
        "baseline_result": "F1-score of 99% for most attack types and over 95.86% for all attack types"
      },
      {
        "method_name": "LSTM-CLOUD",
        "paper_reference": "Aydin et al. [19]",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": "99.83% (on UDP, MSSQL, SYN subsets of CICDDoS2019)"
      },
      {
        "method_name": "FlowGuard (CNN + LSTM)",
        "paper_reference": "Jia et al. [17]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "MAE (reconstruction error for anomaly scoring)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a reconstruction-based LSTM-Autoencoder trained only on benign traffic detect reflection-based DDoS (DNS, LDAP, SNMP) anomalies in multivariate time-series data?",
        "How does the choice of fixed-time window length affect MAE-based anomaly scoring and detection performance?",
        "Does the proposed LSTM-AE outperform prior ML/DL approaches on the CICDDoS2019 dataset?"
      ],
      "gaps_identified": [
        "Traditional statistical and shallow ML approaches cannot detect unseen DDoS attacks and require manual feature selection and thresholds.",
        "Autoencoders are sensitive to anomalies during training; RNNs face vanishing gradient issues.",
        "Distinguishing subtle sub-pattern differences between benign and attack traffic is challenging."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Address the inability of traditional and shallow ML techniques to detect unseen DDoS attacks and overcome limitations of existing deep learning approaches by leveraging a reconstruction-based LSTM-AE on multivariate time-series traffic.",
      "potential_research_ideas": [
        "Extend to broader DDoS families (e.g., volumetric, application-layer, TCP/UDP floods) and mixed/hybrid attacks; evaluate cross-attack generalization.",
        "Online/streaming detection with adaptive thresholds and concept drift handling for evolving traffic patterns.",
        "Cross-dataset and cross-network generalization with domain adaptation or transfer learning.",
        "Combine flow-level and packet-level features (multi-modal) and assess gains from richer inputs.",
        "Self-supervised pretraining on large unlabeled traffic followed by AE fine-tuning to improve representation quality.",
        "Robust anomaly detection under training contamination using robust losses or trimming.",
        "Explainable anomaly scoring (e.g., feature/time-step attributions) for operator trust and triage.",
        "Adversarial robustness assessment against evasion and poisoning attacks specific to anomaly detectors."
      ],
      "architectural_improvement_recommendations": [
        "Add attention mechanisms over time steps (e.g., LSTM with attention) to focus on salient subsequences.",
        "Use bidirectional or stacked LSTMs and residual connections to capture longer dependencies.",
        "Explore Transformer-based sequence autoencoders or Temporal Convolutional Networks for efficiency and long-range modeling.",
        "Replace plain AE with Variational Autoencoder or Denoising Autoencoder to improve generalization and robustness.",
        "Calibrate anomaly thresholds via Extreme Value Theory or validation-based quantile selection instead of heuristic selection.",
        "Incorporate contamination-robust training (e.g., Huber/quantile losses) to mitigate benign-only training sensitivity.",
        "Multi-scale windows (hierarchical encoder) to aggregate short- and long-term patterns.",
        "Lightweight deployment variants (e.g., pruning/quantization) for high-throughput environments."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a reconstruction-based LSTM-Autoencoder architecture for time-series anomaly detection in DDoS traffic.",
      "Applies the model to reflection-based DDoS attacks (DNS, LDAP, SNMP) using fixed-time windowed multivariate flow features.",
      "Introduces a flexible anomaly scoring technique computing MAE per flow adaptable to different time windows.",
      "Evaluates on CICDDoS2019 and reports detection accuracy exceeding 99%, outperforming comparable methods."
    ]
  },
  {
    "arxiv_id": "2303.01041v1",
    "title": "D-Score: An Expert-Based Method for Assessing the Detectability of IoT-Related Cyber-Attacks",
    "authors": "Yair Meidan; Daniel Benatar; Ron Bitton; Dan Avraham; Asaf Shabtai",
    "abstract": "IoT devices are known to be vulnerable to various cyber-attacks, such as data exfiltration and the execution of flooding attacks as part of a DDoS attack. When it comes to detecting such attacks using network traffic analysis, it has been shown that some attack scenarios are not always equally easy to detect if they involve different IoT models. That is, when targeted at some IoT models, a given attack can be detected rather accurately, while when targeted at others the same attack may result in too many false alarms. In this research, we attempt to explain this variability of IoT attack detectability and devise a risk assessment method capable of addressing a key question: how easy is it for an anomaly-based network intrusion detection system to detect a given cyber-attack involving a specific IoT model? In the process of addressing this question we (a) investigate the predictability of IoT network traffic, (b) present a novel taxonomy for IoT attack detection which also encapsulates traffic predictability aspects, (c) propose an expert-based attack detectability estimation method which uses this taxonomy to derive a detectability score (termed `D-Score') for a given combination of IoT model and attack scenario, and (d) empirically evaluate our method while comparing it with a data-driven method.",
    "published_date": "2023-03-02",
    "pdf_link": "https://arxiv.org/pdf/2303.01041v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Advance estimation of the detectability of IoT-related cyber-attacks by anomaly-based network intrusion detection systems (AIDS) for specific IoT models",
      "attack_types": [
        "Command-and-control (C&C) communication",
        "DDoS flooding",
        "Data exfiltration",
        "Bot scanning/botnet propagation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Multi-criteria decision-making",
        "specific": "Analytic Hierarchy Process (AHP)",
        "novel_contribution": "Expert-based weighting over a new IoT attack detectability taxonomy to compute a Detectability Score (D-Score) for attack–device combinations"
      }
    ],
    "learning_paradigm": [],
    "datasets": [
      {
        "name": "IoT-deNAT dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Anonymous expert questionnaire responses (40 experts)",
        "type": "public",
        "domain": "survey_responses",
        "link": "http://doi.org/10.5281/zenodo.4018614",
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Data-driven method for estimating attack detectability (learned from labeled traffic and AIDS performance)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Key Predictability Indicators (KPIs): flow incoming packets",
      "KPIs: hourly outbound flows",
      "KPIs: hourly unique destination IPs",
      "KPIs: hourly unique destination ports",
      "D-Score (0–1 scalar detectability index)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Is there a difference between the regularity/predictability of IoT network traffic and non-IoT traffic?",
        "How variable is traffic predictability among various IoT models?",
        "Can we correlate IoT model complexity (static features) with traffic predictability (dynamic features)?",
        "Why can the same attack be easy to detect on one IoT model but difficult on another by the same AIDS?",
        "Can the ability to detect a given attack scenario on a given IoT model be quantified in advance into a security index/label?"
      ],
      "gaps_identified": [
        "Prior IoT security indices/labels do not measure attack detectability; they focus on exploitability or device risk.",
        "Traffic predictability of IoT vs. non-IoT has been largely assumed, not quantitatively validated.",
        "Existing IoT security taxonomies lack behavioral/user-interaction features that affect network traffic and detectability.",
        "Variability in attack detection performance across IoT models is under-explained and under-quantified."
      ],
      "limitations": [],
      "future_work": [
        "Extend the questionnaire to additional attack scenarios using the dynamic selection mechanism.",
        "Extend/adjust threat models and scenarios without changing the taxonomy.",
        "Broaden evaluation with more IoT models and environments (homes and enterprises)."
      ],
      "motivation": "Explain and quantify why detectability of IoT attacks varies across device models and provide a practical, pre-deployment detectability label (D-Score) to aid procurement and risk assessment.",
      "potential_research_ideas": [
        "Learn a data-driven D-Score predictor from limited labeled data and calibrate it with expert priors (hybrid expert+ML).",
        "Automate extraction of dynamic predictability features from raw packet captures and map them to taxonomy features.",
        "Generalize the taxonomy and scoring to additional IoT domains (industrial IoT, healthcare) and non-TCP/IP stacks.",
        "Longitudinal studies to track D-Score drift across firmware updates and environment/user-behavior changes.",
        "Integrate D-Score into NIDS for adaptive thresholding or device-specific detection policies.",
        "Validate correlations between D-Score and real-world incident detection rates across enterprises."
      ],
      "architectural_improvement_recommendations": [
        "Adopt Bayesian AHP or probabilistic weighting to model expert uncertainty and variability.",
        "Introduce adaptive weights that update using feedback from operational NIDS outcomes (online calibration).",
        "Augment taxonomy with automatically inferred features (e.g., entropy of destinations, periodicity measures) computed from recent benign traffic.",
        "Use active learning to optimally query experts on pairwise comparisons that most reduce uncertainty.",
        "Define a standardized mapping from D-Score to actionable NIDS configurations (e.g., per-device sensitivity)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Smart home and enterprise networks with anomaly-based NIDS monitoring device traffic",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Requires expert elicitation to derive weights for each attack scenario.",
        "Heterogeneity of IoT models and firmware versions complicates feature acquisition and standardization.",
        "Collection of representative benign traffic traces for dynamic feature computation may be non-trivial.",
        "Mapping D-Score to operational NIDS tuning/policies needs validation in live environments."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Quantitatively investigate IoT vs. non-IoT network traffic predictability using datasets; examine variability among IoT models; correlate predictability with static features; leverage predictability to quantify detectability.",
      "First to explicitly and systematically explore quantification of IoT attack detectability (distinct from exploitability).",
      "Propose a novel expert-based method using a new taxonomy and AHP-derived weights to compute an IoT Attack Detectability Score (D-Score) in advance.",
      "Develop an online questionnaire with preliminary filtering and dynamic attack-scenario selection to reduce respondent burden and enable extensibility.",
      "Release anonymous responses from 40 cybersecurity experts across regions to support future research."
    ]
  },
  {
    "arxiv_id": "2303.12278v3",
    "title": "X-CANIDS: Signal-Aware Explainable Intrusion Detection System for Controller Area Network-Based In-Vehicle Network",
    "authors": "Seonghoon Jeong; Sangho Lee; Hwejae Lee; Huy Kang Kim",
    "abstract": "Controller Area Network (CAN) is an essential networking protocol that connects multiple electronic control units (ECUs) in a vehicle. However, CAN-based in-vehicle networks (IVNs) face security risks owing to the CAN mechanisms. An adversary can sabotage a vehicle by leveraging the security risks if they can access the CAN bus. Thus, recent actions and cybersecurity regulations (e.g., UNR 155) require carmakers to implement intrusion detection systems (IDSs) in their vehicles. The IDS should detect cyberattacks and provide additional information to analyze conducted attacks. Although many IDSs have been proposed, considerations regarding their feasibility and explainability remain lacking. This study proposes X-CANIDS, which is a novel IDS for CAN-based IVNs. X-CANIDS dissects the payloads in CAN messages into human-understandable signals using a CAN database. The signals improve the intrusion detection performance compared with the use of bit representations of raw payloads. These signals also enable an understanding of which signal or ECU is under attack. X-CANIDS can detect zero-day attacks because it does not require any labeled dataset in the training phase. We confirmed the feasibility of the proposed method through a benchmark test on an automotive-grade embedded device with a GPU. The results of this work will be valuable to carmakers and researchers considering the installation of in-vehicle IDSs for their vehicles.",
    "published_date": "2023-03-22",
    "pdf_link": "https://arxiv.org/pdf/2303.12278v3",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Automotive Security",
      "subdomain": "In-Vehicle Network (IVN) Intrusion Detection",
      "specific_problem": "Explainable, feasible, self-supervised intrusion detection for CAN bus using signal-level features",
      "attack_types": [
        "Fuzzing",
        "Fabrication",
        "Suspension",
        "Masquerade",
        "Replay"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": "Reconstruction-based time-series autoencoder with sliding window",
        "novel_contribution": "Signal-aware feature generation using CAN database; signal-wise reconstruction error for explainability; thresholds determined from attack-free data"
      },
      {
        "type": "primary",
        "category": "Time-series modeling",
        "specific": "Sliding-window matrix of scaled signals",
        "novel_contribution": "Feature generator stacks w most recent signal vectors into a matrix S ∈ [0,1]^{w×x} to capture temporal and lateral relationships"
      },
      {
        "type": "primary",
        "category": "Feature scaling",
        "specific": "Min–max scaling using CAN database-specified min/max",
        "novel_contribution": "Uses DBC-defined min/max to avoid train-set bias and ensure bounded [0,1] scaling"
      }
    ],
    "learning_paradigm": [
      "Self-supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "OpenDBC (e.g., hyundai_2015_ccan.dbc)",
        "type": "public",
        "domain": "can_bus",
        "link": "https://github.com/commaai/opendbc",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Attack-free CAN messages for training (unspecified source)",
        "type": "private",
        "domain": "can_bus",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "CAN evaluation datasets with injected attacks (unspecified, used for benchmarking five attack types)",
        "type": "private",
        "domain": "can_bus",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "detection latency (ms)",
      "reconstruction error (signal-wise)",
      "threshold-based anomaly decision"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can we build a self-supervised IDS for CAN that detects zero-day attacks without labeled data?",
        "Do signal-level features (via CAN database) improve detection versus raw payload bits?",
        "How can an IDS provide explainability at the signal/ECU level for forensic analysis?",
        "Is the proposed IDS feasible on automotive-grade embedded hardware with deterministic latency?"
      ],
      "gaps_identified": [
        "Lack of explainability in prior CAN IDSs for forensic analysis.",
        "Limited evaluation of feasibility and deterministic latency on embedded automotive hardware.",
        "Rare use of signal-level features due to lack of accessible payload deserialization knowledge and resources."
      ],
      "limitations": [
        "Dependence on availability and accuracy of a CAN database (DBC) to deserialize payloads.",
        "Details of datasets and attack traces are not publicly provided in the provided content, limiting reproducibility.",
        "Performance under adversarial machine learning manipulations is not evaluated."
      ],
      "future_work": [
        "Extend to CAN-FD with larger payloads (up to 512 bits) and assess scalability.",
        "Broaden coverage to additional vehicles/ECU sets and more comprehensive signal catalogs.",
        "Investigate robustness to concept drift and vehicle context changes with adaptive thresholds."
      ],
      "motivation": "Meet regulatory and practical needs (e.g., UNR 155) for in-vehicle IDSs that detect attacks, support monitoring and forensics, and are feasible and explainable.",
      "potential_research_ideas": [
        "Learning with incomplete or noisy CAN databases: jointly infer missing signal specs while training an IDS.",
        "Cross-vehicle transfer learning using canonicalized signal spaces to reduce per-vehicle onboarding costs.",
        "Multimodal IDS fusing payload-derived signals with timing/frequency features and ECU-level topology knowledge.",
        "Online/continual self-supervised adaptation to handle concept drift across routes, drivers, and software updates.",
        "Adversarial robustness evaluation against stealthy or mimicry CAN attacks tailored to reconstruction-based detectors.",
        "Explainability enhancement with causal graphs over ECUs/signals to localize attacker actions and propagation.",
        "Lightweight compression/distillation of the autoencoder for MCU-class ECUs beyond Jetson-class devices."
      ],
      "architectural_improvement_recommendations": [
        "Augment autoencoder with temporal models (e.g., TCN or lightweight GRU) for richer dynamics without heavy latency.",
        "Per-stream sub-encoders with shared backbone plus cross-signal attention to capture both local and global dependencies.",
        "Adaptive, signal-specific thresholding with EVT (extreme value theory) to control false positives across diverse signals.",
        "Hybrid model using frequency-domain features (FFT of signals) alongside time-domain matrices for certain ECUs.",
        "Uncertainty-aware decision layer (e.g., predictive intervals) to support forensics and reduce false alarms.",
        "Model pruning/quantization and TensorRT deployment to further reduce latency and power on embedded GPUs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Benchmarked on NVIDIA Jetson AGX Xavier (automotive-grade embedded GPU). Deterministic detection latency 38.2512–73.2512 ms at 200 Hz feature generation and batch size 8."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Automotive-grade embedded device (NVIDIA Jetson AGX Xavier) connected to a CAN bus",
      "scalability_discussed": true,
      "inference_time": "Deterministic detection latency of 38.2512–73.2512 ms (feature generation 200 Hz, batch size 8)",
      "deployment_challenges": [
        "Requirement for accurate CAN database (DBC) per vehicle/ECU set.",
        "Integration into vehicle ECUs with deterministic timing constraints.",
        "Handling diverse signal ranges and contexts across vehicle models."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Self-supervised intrusion detection using signals deserialized from CAN payloads (107 signals in training).",
      "Explainability via signal-wise reconstruction error to identify compromised signals/ECUs without labeled attacks.",
      "Feasibility demonstrated through benchmarking on NVIDIA Jetson AGX Xavier with deterministic latency."
    ]
  },
  {
    "arxiv_id": "2302.07589v2",
    "title": "ARGUS: Context-Based Detection of Stealthy IoT Infiltration Attacks",
    "authors": "Phillip Rieger; Marco Chilese; Reham Mohamed; Markus Miettinen; Hossein Fereidooni; Ahmad-Reza Sadeghi",
    "abstract": "IoT application domains, device diversity and connectivity are rapidly growing. IoT devices control various functions in smart homes and buildings, smart cities, and smart factories, making these devices an attractive target for attackers. On the other hand, the large variability of different application scenarios and inherent heterogeneity of devices make it very challenging to reliably detect abnormal IoT device behaviors and distinguish these from benign behaviors. Existing approaches for detecting attacks are mostly limited to attacks directly compromising individual IoT devices, or, require predefined detection policies. They cannot detect attacks that utilize the control plane of the IoT system to trigger actions in an unintended/malicious context, e.g., opening a smart lock while the smart home residents are absent.   In this paper, we tackle this problem and propose ARGUS, the first self-learning intrusion detection system for detecting contextual attacks on IoT environments, in which the attacker maliciously invokes IoT device actions to reach its goals. ARGUS monitors the contextual setting based on the state and actions of IoT devices in the environment. An unsupervised Deep Neural Network (DNN) is used for modeling the typical contextual device behavior and detecting actions taking place in abnormal contextual settings. This unsupervised approach ensures that ARGUS is not restricted to detecting previously known attacks but is also able to detect new attacks. We evaluated ARGUS on heterogeneous real-world smart-home settings and achieve at least an F1-Score of 99.64% for each setup, with a false positive rate (FPR) of at most 0.03%.",
    "published_date": "2023-02-15",
    "pdf_link": "https://arxiv.org/pdf/2302.07589v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Context-based detection of stealthy IoT infiltration attacks via control plane misuse (contextual integrity violations)",
      "attack_types": [
        "contextual attacks",
        "IoT infiltration",
        "control plane compromise",
        "unauthorized actuation (e.g., unlocking smart lock while residents are absent)",
        "cloud service compromise",
        "mobile app compromise"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": null,
        "novel_contribution": "Unsupervised deep neural network autoencoder models contextual device behavior and outputs anomaly scores for events; combined with a dynamic, per-setup thresholding scheme."
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "ARGUS smart-home context dataset (argus-data)",
        "type": "public",
        "domain": "smart_home_events_and_context (IoT device states/actions, ambient/user context, automation rules)",
        "link": "https://github.com/TRUST-TUDa/argus-data",
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "F1-Score",
      "False Positive Rate (FPR)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How can we detect attacks consisting of benign actions by leveraging contextual integrity in IoT environments?",
        "How can we autonomously personalize detection to different smart-home setups and user habits to minimize false alarms without manual policies?"
      ],
      "gaps_identified": [
        "Network-traffic-based IDS cannot detect contextual attacks because attack commands look benign and traffic is indistinguishable from normal.",
        "Policy enforcement approaches require fixed or user-defined policies, which are impractical and ignore actual user behavior.",
        "Prior contextual anomaly detection approaches require semantic information about devices, attack example data, or analyze only commands, or cannot accurately model inter-device relationships.",
        "Lack of publicly available real-world datasets capturing heterogeneous smart-home contextual behavior for this problem."
      ],
      "limitations": [
        "Scope limited to attacks that compromise the control plane and not direct compromises of IoT devices (“Aligned with existing work ARGUS considers only attacks that compromise the control plane of the IoT network but not direct attacks against the IoT devices themselves”).",
        "Assumes ARGUS components are trusted and cannot be compromised by the adversary.",
        "Assumes the local IoT setup is not compromised during training."
      ],
      "future_work": [],
      "motivation": "Detect stealthy contextual attacks where adversaries misinvoke legitimate IoT actions in abnormal contexts, which are missed by network-based IDS and impractical policy-based defenses.",
      "potential_research_ideas": [
        "Model temporal and inter-device dependencies with sequence models (e.g., Transformers, TCNs) or Graph Neural Networks capturing device-device and device-context relations.",
        "Federated or on-device privacy-preserving training across many homes to improve generalization without sharing raw events.",
        "Causal modeling to infer permissible action contexts and to enable what-if analysis for better attack attribution.",
        "Adaptive/continual learning to handle concept drift in user routines and device additions with safety constraints.",
        "Benchmarking and simulation framework for contextual attacks to standardize evaluation beyond the provided dataset.",
        "Explainable anomaly detection to present human-understandable reasons for flagged actions (e.g., counterfactuals).",
        "Robustness against adversarial manipulation of context features (sensor spoofing or event injection)."
      ],
      "architectural_improvement_recommendations": [
        "Replace/reinforce the autoencoder with a temporal Transformer or TCN conditioned on contextual features and past events.",
        "Integrate a device-context graph layer (GNN) to explicitly model relationships among devices, rules, and user presence.",
        "Use probabilistic modeling (VAE/normalizing flows) with uncertainty calibration to set thresholds via extreme value theory.",
        "Per-device and per-context adaptive thresholds with Bayesian updating rather than a single global threshold.",
        "Multi-task learning to jointly predict next action and context consistency, improving supervision signals.",
        "Add explanation modules (attention visualization, SHAP on feature embeddings) to support R2 cause identification."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Smart-home networks with heterogeneous IoT devices and vendor cloud/mobile apps",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Heterogeneity of IoT devices, protocols, and vendor APIs",
        "Need for autonomous personalization to user habits to avoid false alarms",
        "Dependence on availability/quality of context features from home automation/cloud APIs"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes ARGUS, a context-based self-learning IDS for detecting contextual IoT infiltration attacks targeting the control plane.",
      "Dynamic tuning scheme for anomaly-score classification boundary that automatically adapts to different setups.",
      "Provides the first real-world dataset capturing behavior of different smart-homes for research in this area (https://github.com/TRUST-TUDa/argus-data).",
      "Extensive evaluation on 5 heterogeneous smart-home setups; “achieve at least an F1-Score of 99.64% for each setup, with a false positive rate (FPR) of at most 0.03%”."
    ]
  },
  {
    "arxiv_id": "2303.05400v1",
    "title": "Prompt-Based Learning for Thread Structure Prediction in Cybersecurity Forums",
    "authors": "Kazuaki Kashihara; Kuntal Kumar Pal; Chitta Baral; Robert P Trevino",
    "abstract": "With recent trends indicating cyber crimes increasing in both frequency and cost, it is imperative to develop new methods that leverage data-rich hacker forums to assist in combating ever evolving cyber threats. Defining interactions within these forums is critical as it facilitates identifying highly skilled users, which can improve prediction of novel threats and future cyber attacks. We propose a method called Next Paragraph Prediction with Instructional Prompting (NPP-IP) to predict thread structures while grounded on the context around posts. This is the first time to apply an instructional prompting approach to the cybersecurity domain. We evaluate our NPP-IP with the Reddit dataset and Hacker Forums dataset that has posts and thread structures of real hacker forums' threads, and compare our method's performance with existing methods. The experimental evaluation shows that our proposed method can predict the thread structure significantly better than existing methods allowing for better social network prediction based on forum interactions.",
    "published_date": "2023-03-05",
    "pdf_link": "https://arxiv.org/pdf/2303.05400v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Threat Intelligence",
      "subdomain": "Underground forum analysis",
      "specific_problem": "Thread structure prediction (reply relationship identification) in cybersecurity/hacker forums for social network construction",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT",
        "novel_contribution": "Next Paragraph Prediction with Instructional Prompting (NPP-IP): concatenates an instruction prompt with paired posts to frame a True/False reply-relation classification task"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "RoBERTa",
        "novel_contribution": "Same NPP-IP formulation evaluated with RoBERTa language model variants"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT/RoBERTa",
        "novel_contribution": "Original Next Paragraph Prediction (NPP) without instructional prompting (pairwise post classification)"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Reddit cybersecurity forum dataset [12]",
        "type": "private",
        "domain": "forum_posts",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Hacker Forums dataset (CYR3CON annotated)",
        "type": "proprietary",
        "domain": "forum_posts",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Creator-Oriented Network (CO)",
        "paper_reference": "[13]",
        "metric": "F1 (Reddit test)",
        "their_result": "0.51 (NPP-IP with RoBERTa-Base)",
        "baseline_result": "0.01"
      },
      {
        "method_name": "Last Reply-Oriented Network (LR)",
        "paper_reference": "[13]",
        "metric": "F1 (Reddit test)",
        "their_result": "0.51 (NPP-IP with RoBERTa-Base)",
        "baseline_result": "0.20"
      },
      {
        "method_name": "NPP (original, BERT/RoBERTa variants)",
        "paper_reference": "[12]",
        "metric": "F1 (Reddit test)",
        "their_result": "0.51 (NPP-IP with RoBERTa-Base)",
        "baseline_result": "0.48 (NPP with RoBERTa-Large)"
      },
      {
        "method_name": "Creator-Oriented Network (CO)",
        "paper_reference": "[13]",
        "metric": "F1 (Hacker Forums Forum1)",
        "their_result": "0.53 (NPP-IP with BERT-Large)",
        "baseline_result": "0.47"
      },
      {
        "method_name": "Creator-Oriented Network (CO)",
        "paper_reference": "[13]",
        "metric": "F1 (Hacker Forums Forum2)",
        "their_result": "0.67 (NPP-IP with BERT-Base)",
        "baseline_result": "0.43"
      },
      {
        "method_name": "Creator-Oriented Network (CO)",
        "paper_reference": "[13]",
        "metric": "F1 (Hacker Forums Forum3)",
        "their_result": "0.58 (NPP-IP with BERT-Base)",
        "baseline_result": "0.21"
      },
      {
        "method_name": "Last Reply-Oriented Network (LR)",
        "paper_reference": "[13]",
        "metric": "F1 (Hacker Forums Forum1)",
        "their_result": "0.53 (NPP-IP with BERT-Large)",
        "baseline_result": "0.01"
      },
      {
        "method_name": "Last Reply-Oriented Network (LR)",
        "paper_reference": "[13]",
        "metric": "F1 (Hacker Forums Forum2)",
        "their_result": "0.67 (NPP-IP with BERT-Base)",
        "baseline_result": "0.16"
      },
      {
        "method_name": "Last Reply-Oriented Network (LR)",
        "paper_reference": "[13]",
        "metric": "F1 (Hacker Forums Forum3)",
        "their_result": "0.58 (NPP-IP with BERT-Base)",
        "baseline_result": "0.21"
      },
      {
        "method_name": "NPP (original, best variant per forum)",
        "paper_reference": "[12]",
        "metric": "F1 (Hacker Forums Forum1)",
        "their_result": "0.53 (NPP-IP with BERT-Large)",
        "baseline_result": "0.54 (NPP with RoBERTa-Large)"
      },
      {
        "method_name": "NPP (original, best variant per forum)",
        "paper_reference": "[12]",
        "metric": "F1 (Hacker Forums Forum2)",
        "their_result": "0.67 (NPP-IP with BERT-Base)",
        "baseline_result": "0.54 (NPP with RoBERTa-Large)"
      },
      {
        "method_name": "NPP (original, best variant per forum)",
        "paper_reference": "[12]",
        "metric": "F1 (Hacker Forums Forum3)",
        "their_result": "0.58 (NPP-IP with BERT-Base)",
        "baseline_result": "0.44 (NPP with BERT-Base)"
      }
    ],
    "performance_metrics_used": [
      "Precision",
      "Recall",
      "F1"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can instructional prompting improve next-paragraph reply prediction (thread structure prediction) on cybersecurity forums?",
        "Does training on Reddit forum data generalize to unrelated hacker forums for thread structure prediction?"
      ],
      "gaps_identified": [
        "Traditional forum social network construction methods (Creator-oriented, Last Reply-oriented) rely on temporal assumptions and limited information, leading to inaccurate social structures.",
        "Pre-trained LMs may not understand domain-specific cybersecurity vocabulary, hurting precision/recall: “the cybersecurity field is in a constant state of flux… We suspect that LMs could not understand many of the cybersecurity keywords… Thus, re-training LMs with cybersecurity data should be explored.”",
        "Annotated datasets for hacker forums are scarce and often cannot be publicly shared due to sensitivity and copyright.",
        "Quoting mechanisms in forums propagate referenced content (reference’s reference), causing false positives in pairwise reply prediction."
      ],
      "limitations": [
        "Dataset accessibility: Reddit dataset is for this study only; CYR3CON hacker forums data will not be published.",
        "Language/domain limitation: pre-trained LMs may not capture evolving cybersecurity terminology.",
        "Annotation constraints: only 20 hacker forum threads annotated; average 15.4 posts per thread.",
        "Quoted-text confounds: nested quotes lead to false positives without specialized preprocessing."
      ],
      "future_work": [
        "Train/fine-tune language models with cybersecurity-related data to better adapt to domain context.",
        "Apply the improved thread structures to downstream social network analysis, replacing assumption-based networks and quantifying advantages."
      ],
      "motivation": "Leverage data-rich hacker forums to identify interactions and prominent users for predicting novel threats and future cyber attacks by accurately reconstructing thread structures.",
      "potential_research_ideas": [
        "Pre-train or continual-train domain-specific LMs on large-scale cyber forum corpora (dark web, Telegram, Discord) for improved vocabulary and context handling.",
        "Design a quote-aware preprocessing module to remove or de-duplicate reference-of-reference content, with learnable heuristics or a sequence-tagging component to detect quoted spans.",
        "Formulate thread reconstruction as global structure prediction using graph neural networks or structured prediction (e.g., pointer networks, MST/CRF constraints) jointly over full threads.",
        "Employ contrastive learning to align true parent–child pairs against hard negatives within the same thread.",
        "Investigate soft-prompt or prefix-tuning specific to cybersecurity domains to reduce reliance on manual instructional prompts.",
        "Extend to multilingual/mixed-language hacker forums with cross-lingual transfer and domain adaptation.",
        "Incorporate user/contextual metadata (timestamps, author IDs, forum sections) in a multimodal model to disambiguate replies.",
        "Explore long-context transformers (Longformer/DeBERTa-XL/FlashAttention) to capture multi-post dependencies beyond 250 tokens."
      ],
      "architectural_improvement_recommendations": [
        "Replace hard concatenated instruction with soft prompt/prefix-tuning and instruction fine-tuning on cyber corpora.",
        "Adopt a hierarchical transformer that encodes posts and thread-level context, followed by a pointer network to select parent post.",
        "Integrate a quote-detection component to strip quoted spans or to condition the model with a mask over quoted text.",
        "Use a joint learning objective combining pairwise classification with global tree constraints (e.g., acyclicity, single-parent) via differentiable losses.",
        "Leverage domain-adaptive pretraining (DAPT) on cybersecurity forum text before supervised fine-tuning.",
        "Balance classes and calibrate thresholds; consider focal loss or hard-negative mining for imbalanced reply pairs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PyTorch",
        "torchtext 0.8.0",
        "pytorch-lightning 1.2.2",
        "transformers 3.4"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "Google Colab with Nvidia K80 12 GB GPU; batch size 8; learning rate 5e-6; >10 epochs (converged ~3); max sequence length 250; dropout 0.15."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Limited access to real hacker forum data and inability to publish datasets.",
        "Pre-trained LMs’ weak handling of rapidly evolving cybersecurity jargon.",
        "Quoted content nesting in forums leading to noisy inputs and false positives.",
        "Manual annotation cost and expertise requirements."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduced instructional prompting into Next Paragraph Prediction for forum social network construction.",
      "Applied prompt-based learning to the cybersecurity forum domain for the first time.",
      "Demonstrated improved thread structure prediction over existing methods on Reddit and real hacker forums.",
      "Showed cross-forum robustness: trained on Reddit and inferred on unrelated hacker forums."
    ]
  },
  {
    "arxiv_id": "2304.00409v2",
    "title": "DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection",
    "authors": "Yizheng Chen; Zhoujie Ding; Lamya Alowain; Xinyun Chen; David Wagner",
    "abstract": "We propose and release a new vulnerable source code dataset. We curate the dataset by crawling security issue websites, extracting vulnerability-fixing commits and source codes from the corresponding projects. Our new dataset contains 18,945 vulnerable functions spanning 150 CWEs and 330,492 non-vulnerable functions extracted from 7,514 commits. Our dataset covers 295 more projects than all previous datasets combined.   Combining our new dataset with previous datasets, we present an analysis of the challenges and promising research directions of using deep learning for detecting software vulnerabilities. We study 11 model architectures belonging to 4 families. Our results show that deep learning is still not ready for vulnerability detection, due to high false positive rate, low F1 score, and difficulty of detecting hard CWEs. In particular, we demonstrate an important generalization challenge for the deployment of deep learning-based models. We show that increasing the volume of training data may not further improve the performance of deep learning models for vulnerability detection, but might be useful to improve the generalization ability to unseen projects.   We also identify hopeful future research directions. We demonstrate that large language models (LLMs) are a promising research direction for ML-based vulnerability detection, outperforming Graph Neural Networks (GNNs) with code-structure features in our experiments. Moreover, developing source code specific pre-training objectives is a promising research direction to improve the vulnerability detection performance.",
    "published_date": "2023-04-01",
    "pdf_link": "https://arxiv.org/pdf/2304.00409v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection",
      "specific_problem": "Function-level vulnerability detection in C/C++ source code using machine learning",
      "attack_types": [
        "CWE-787 Out-of-bounds Write",
        "CWE-125 Out-of-bounds Read",
        "CWE-119 Improper Restriction of Operations within the Bounds of a Memory Buffer",
        "CWE-20 Improper Input Validation",
        "CWE-703 Improper Check or Handling of Exceptional Conditions",
        "CWE-416 Use After Free",
        "CWE-476 NULL Pointer Dereference",
        "CWE-190 Integer Overflow or Wraparound",
        "CWE-200 Exposure of Sensitive Information to an Unauthorized Actor",
        "CWE-399 Resource Management Errors"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "ReVeal (GGNN over Code Property Graphs)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "RoBERTa",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "CodeBERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "GraphCodeBERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "GPT-2 Base",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "CodeT5 Small",
        "novel_contribution": "Pretrained with code-specific objectives (e.g., variable/function name prediction)"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "CodeT5 Base",
        "novel_contribution": "Pretrained with code-specific objectives"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "NatGen (T5-family model for code)",
        "novel_contribution": "Pretrained with code-specific tasks; best-performing among evaluated LLMs on larger datasets"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "DiverseVul",
        "type": "public",
        "domain": "source_code",
        "link": "https://github.com/wagner-group/diversevul",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "CVEFixes",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "BigVul",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CrossVul",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Devign",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ReVeal dataset",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SATE IV Juliet",
        "type": "synthetic",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SARD",
        "type": "synthetic",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Draper",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "D2A",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VulDeePecker dataset",
        "type": "synthetic",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "AOSP CVE patches",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PatchDB",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "ReVeal (GNN) vs Best LLM (CodeT5/NatGen) on Combined Previous Datasets + DiverseVul",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "47.2",
        "baseline_result": "29.8"
      },
      {
        "method_name": "ReVeal (GNN) vs LLMs on CVEFixes",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "16.3 (best LLM within 8.5–16.3 range)",
        "baseline_result": "12.8"
      },
      {
        "method_name": "Best model (LLM) performance summary",
        "paper_reference": null,
        "metric": "F1 / TPR / FPR",
        "their_result": "47.2% F1, 43.3% TPR, 3.5% FPR",
        "baseline_result": null
      },
      {
        "method_name": "Generalization: seen vs unseen projects (best model)",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "9.4 (unseen projects)",
        "baseline_result": "49 (seen projects)"
      }
    ],
    "performance_metrics_used": [
      "F1 score",
      "True Positive Rate (TPR)",
      "False Positive Rate (FPR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does more training data help, or are models saturated?",
        "Does the model architecture make a big difference?",
        "Is it better to use GNNs with code-structure features or large language models for vulnerability detection?",
        "Is a larger LLM better than a smaller LLM?",
        "What are the most promising directions for improving deep learning for vulnerability detection?"
      ],
      "gaps_identified": [
        "High false positive rate and low F1 scores make current models impractical for deployment",
        "Difficulty detecting hard CWEs",
        "Severe generalization failure to unseen projects (realistic deployment setting)",
        "Label noise in datasets created from vulnerability-fixing commits",
        "Scaling data volume shows diminishing returns on top models’ test performance",
        "Need for code-specific pretraining objectives; natural-language pretraining alone is insufficient"
      ],
      "limitations": [
        "Dataset labels derived from vulnerability-fixing commits contain noise; estimated 60% accuracy on DiverseVul vulnerable-function labels",
        "Generalization cause to unseen projects is unclear",
        "Adding DiverseVul yields little improvement for the 3 best-performing models",
        "Evaluation limited to function-level granularity"
      ],
      "future_work": [
        "Develop source code-specific pretraining objectives to improve vulnerability detection",
        "Investigate methods to improve generalization to unseen projects",
        "Study and mitigate label noise from commit-based labeling",
        "Reduce false positive rates to practical levels",
        "Explore better handling of hard CWEs",
        "Further analyze why LLMs benefit more from larger datasets than GNNs"
      ],
      "motivation": "Enable rigorous evaluation and progress in ML-based vulnerability detection by providing a larger, more diverse real-world C/C++ dataset and analyzing model families and training data effects.",
      "potential_research_ideas": [
        "Domain adaptation and invariance learning to improve cross-project generalization (e.g., adversarial domain adaptation across projects/repos)",
        "CWE-aware multi-task learning to tailor representations for hard vulnerability classes",
        "Label denoising via program slicing/patch grounding, weak supervision, or confident learning",
        "Hybrid architectures that fuse code property graphs with LLMs via graph-aware adapters or graph-encoded prompts",
        "Contrastive pretraining using positive/negative function pairs from pre/post-fix commits",
        "Project-conditioned few-shot adaptation or meta-learning to quickly specialize to new codebases",
        "Interprocedural/context-augmented models that incorporate call graph and dataflow beyond single functions",
        "Self-training on unlabeled project code with pseudo-label calibration to reduce domain shift",
        "Cost-sensitive training and calibrated decision thresholds to minimize FPR at deployment",
        "Program analysis-guided data augmentation (e.g., semantics-preserving transformations) to improve robustness and generalization"
      ],
      "architectural_improvement_recommendations": [
        "Design code-specific pretraining tasks (e.g., variable/identifier recovery, data/control-flow masked modeling, vulnerability-pattern prediction)",
        "Add graph- or flow-aware adapters to Transformers to inject CPG/PDG/CFG signals without full GNN complexity",
        "Multi-granularity encoders that combine token-level LLMs with basic-block and function-level graph summaries",
        "CWE-conditioned classification heads and curriculum focusing on hard CWEs",
        "Imbalance handling via class-weighted/focal losses and hard-negative mining",
        "Confidence calibration and selective prediction to reduce false positives in practice",
        "Prompting/fine-tuning with patch diffs and surrounding file context to better ground vulnerabilities"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/wagner-group/diversevul",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High false positive rate (~3.5% FPR translates to hundreds of false positives per large project)",
        "Poor generalization to unseen projects (F1 drops from ~49% to ~9.4%)",
        "Label noise in training data from commit-based labeling"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Released DiverseVul, a new and more diverse C/C++ vulnerable source code dataset (18,945 vulnerable and 330,492 non-vulnerable functions across 7,514 commits, 150 CWEs, 797 projects)",
      "Comprehensive empirical study of 11 model architectures across 4 families (GNNs and multiple LLM families)",
      "Found that LLMs (e.g., CodeT5, NatGen) outperform state-of-the-art GNN with code-structure features when trained on larger datasets",
      "Identified significant generalization challenges to unseen projects",
      "Quantified label noise in commit-based datasets and highlighted its impact",
      "Showed that code-specific pretraining objectives are promising for improved performance",
      "Analyzed the marginal benefits of adding more training data on model performance"
    ]
  },
  {
    "arxiv_id": "2303.07987v1",
    "title": "Practically Solving LPN in High Noise Regimes Faster Using Neural Networks",
    "authors": "Haozhe Jiang; Kaiyue Wen; Yilei Chen",
    "abstract": "We conduct a systematic study of solving the learning parity with noise problem (LPN) using neural networks. Our main contribution is designing families of two-layer neural networks that practically outperform classical algorithms in high-noise, low-dimension regimes. We consider three settings where the numbers of LPN samples are abundant, very limited, and in between. In each setting we provide neural network models that solve LPN as fast as possible. For some settings we are also able to provide theories that explain the rationale of the design of our models. Comparing with the previous experiments of Esser, Kubler, and May (CRYPTO 2017), for dimension $n = 26$, noise rate $τ= 0.498$, the ''Guess-then-Gaussian-elimination'' algorithm takes 3.12 days on 64 CPU cores, whereas our neural network algorithm takes 66 minutes on 8 GPUs. Our algorithm can also be plugged into the hybrid algorithms for solving middle or large dimension LPN instances.",
    "published_date": "2023-03-14",
    "pdf_link": "https://arxiv.org/pdf/2303.07987v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cryptanalysis",
      "subdomain": "Hardness assumptions and decoding attacks",
      "specific_problem": "Solving Learning Parity with Noise (LPN) in high-noise, low-dimension regimes and integrating into hybrid reduction-decoding chains",
      "attack_types": [
        "cryptanalytic attack on LPN",
        "decoding binary random linear codes",
        "hybrid reduction-decoding acceleration (BKW + Gauss + neural decoding)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "MLP",
        "specific": "Two-layer fully-connected neural network (shallow MLP) with logistic loss, Adam optimizer, Kaiming (He) initialization",
        "novel_contribution": "Families of tailored two-layer networks for three sample regimes (abundant, restricted with weight decay, moderate) that practically outperform classical Gauss decoding at high noise; partial theory on representation/optimization/generalization justifying design"
      },
      {
        "type": "baseline",
        "category": "Classical algorithm",
        "specific": "Guess-then-Gaussian-elimination (Gauss) decoding",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Classical algorithm",
        "specific": "BKW reduction (Blum-Kalai-Wasserman) and hybrid chains",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Classical algorithm",
        "specific": "MMT decoding (May–Meurer–Thomae) and Walsh–Hadamard decoding (mentioned)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Synthetic LPN oracle samples",
        "type": "synthetic",
        "domain": "cryptographic_oracle_samples",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "BKW-reduced LPN samples (n≈26, τ≈0.498) derived from large-instance reduction",
        "type": "synthetic",
        "domain": "cryptographic_oracle_samples",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Guess-then-Gaussian-elimination (Gauss)",
        "paper_reference": "Esser, Kübler, and May (CRYPTO 2017) [EKM17]",
        "metric": "Wall-clock time",
        "their_result": "Neural network: 66 minutes on 8 GPUs for n=26, τ=0.498",
        "baseline_result": "Gauss: 3.12 days on 64 CPU cores for n=26, τ=0.498"
      },
      {
        "method_name": "Gauss (direct decoding)",
        "paper_reference": null,
        "metric": "Wall-clock time (seconds), thresholded success",
        "their_result": "n=20, τ=0.498: 730 s (single GPU); n=20, τ=0.495: 323 s; n=30, τ=0.49: 1576 s",
        "baseline_result": "n=20, τ=0.498: 6407 s (single 64-core CPU); n=20, τ=0.495: 312 s; n=30, τ=0.49: 682 s"
      },
      {
        "method_name": "Hybrid chain (BKW + Gauss/MMT) from [EKM17]",
        "paper_reference": "Esser, Kübler, and May (2017) [EKM17]",
        "metric": "Wall-clock time to solve large instance",
        "their_result": "BKW + Neural Decoding + MMT: total 3.55 hours (40 min BKW on 128 CPUs; 66 + 106 min NN on 8 GPUs; 1 min MMT) for instance derived from n=125, τ=0.25",
        "baseline_result": "Reported 4:22 days (EKM17 chain for comparable setting; note enumeration step differences)"
      }
    ],
    "performance_metrics_used": [
      "running_time (seconds/minutes/hours/days)",
      "accuracy on clean test set",
      "sample_complexity (number of LPN samples)",
      "success_rate (e.g., 7/10 attempts for Gauss)",
      "noise_rate (τ)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can neural networks practically accelerate solving LPN, especially in high-noise, low-dimension regimes?",
        "What neural architectures and training choices are effective across abundant, restricted, and moderate sample settings for LPN?",
        "Can partial theory explain why simple two-layer networks work for LPN (representation, optimization, generalization)?",
        "Can neural networks be integrated into hybrid reduction-decoding algorithms to speed up larger LPN instances?"
      ],
      "gaps_identified": [
        "Few instances where neural networks outperform conventional cryptanalytic algorithms; most successes are on block ciphers.",
        "Prior neural attacks on LWE (e.g., Wenger et al.) were not competitive with traditional algorithms.",
        "Limited theoretical understanding of why neural networks succeed in such cryptanalytic tasks.",
        "Previous decoding attempts used deeper, more complex networks; effectiveness of simpler architectures underexplored."
      ],
      "limitations": [
        "Did not compare against more sophisticated decoding algorithms such as Walsh–Hadamard or MMT for the same reduced problems.",
        "Main advantage demonstrated in high-noise, low-dimension regimes; generality to other regimes not established.",
        "Abundant-sample setting can require very large numbers of samples, which may be impractical without reductions.",
        "Overfitting risk in restricted-sample setting; requires regularization (weight decay).",
        "Reduction phase not fully optimized; enumeration steps partially bypassed in some comparisons.",
        "Relies on significant compute resources (multi-GPU, many-core CPUs) for best reported times."
      ],
      "future_work": [
        "Design neural networks with specialized structures tailored to LPN.",
        "Investigate applicability of the technique to LWE where modulus is large and noise measured in l2.",
        "Develop practically fast neural decoders for other codes beyond random linear codes."
      ],
      "motivation": "Explore whether neural networks can help break cryptographic problems like LPN and deliver practical speedups over classical decoding algorithms, with partial theoretical understanding.",
      "potential_research_ideas": [
        "Design parity-aware neural layers operating over GF(2) (e.g., XOR/Popcount-based or straight-through modulo-2 layers) to exploit problem structure.",
        "End-to-end trainable hybrid pipeline that jointly learns reduction and decoding (differentiable approximations of BKW steps).",
        "Noise-aware training objectives (e.g., calibrated Bernoulli likelihood with known τ, curriculum on τ approaching 0.5) to improve stability near high-noise.",
        "Self-supervised or contrastive pretraining on unlabeled A to reduce labeled sample complexity in restricted-sample regimes.",
        "Use Walsh–Hadamard or sparse parity features as a fixed first layer before the MLP to combine classical statistics with learning.",
        "Meta-learning across (n, τ) to rapidly adapt to new LPN instances with few samples.",
        "Theoretical analysis of generalization/optimization for shallow nets under label noise ≈0.5, possibly via PAC-Bayes or neural tangent kernel approximations.",
        "Resource-aware scheduling: GPU-CPU co-design and bit-packing for binary operations to further cut wall-clock time.",
        "Neural-guided enumeration in hybrid algorithms to reduce search space (learned heuristics for bit-guess ordering)."
      ],
      "architectural_improvement_recommendations": [
        "Introduce binarized network components (XNOR-popcount) and GF(2) linear layers to better match parity computations and improve throughput.",
        "Add a Walsh–Hadamard transform or learned sparse parity projection as a first layer, followed by logistic MLP.",
        "Adopt noise-annealing schedules and label-smoothing calibrated to τ to stabilize training at τ→0.5.",
        "Employ stronger regularization (weight decay, dropout on hidden units, early stopping via validation) for restricted-sample setting.",
        "Incorporate mixed-precision and bit-level SIMD kernels to accelerate inference/training on binary inputs.",
        "Jointly optimize reduction parameters (block sizes in BKW) with decoder hyperparameters using Bayesian optimization."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/WhenWen/Solving-LPN-using-Neural-Networks.git",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": "Neural decoding example: 66 minutes on 8 GPUs for n=26, τ=0.498; Gauss baseline: 3.12 days on 64 CPU cores (EKM17). Large instance pipeline: BKW 40 minutes on 128 CPUs, NN decoding 66 + 106 minutes on 8 GPUs, final MMT 1 minute. Table 2 NN times on a single GPU; Gauss on a single 64-core CPU; 3-hour cap for some runs."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Research compute cluster (multi-GPU and many-core CPUs)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Obtaining sufficient LPN samples without reductions in abundant-sample regime.",
        "Overfitting with limited samples; need for regularization.",
        "High compute requirements (GPUs/CPUs) for fastest times.",
        "Integration and tuning within hybrid reduction-decoding chains.",
        "Handling very high noise rates close to 0.5."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Design families of two-layer neural networks that practically outperform classical Gauss decoding in high-noise, low-dimension LPN regimes.",
      "Systematic treatment across three regimes (abundant, restricted, moderate samples) with tailored models and training choices (logistic loss, Adam, Kaiming init, weight decay for restricted samples).",
      "Partial theoretical rationale for model design in terms of representation capability, optimization, and generalization.",
      "Empirical speedups: for n=26, τ=0.498, Gauss takes 3.12 days on 64 CPU cores vs. 66 minutes on 8 GPUs for the neural method.",
      "Integration into hybrid algorithms (BKW + NN + MMT) to solve larger instances; reported total time 3.55 hours for a reduced n=125, τ=0.25 case.",
      "Demonstrated NN can learn LPN encoding at τ up to 0.498 with sufficient samples; provided time comparisons vs Gauss (Table 2).",
      "Showed L2 regularization (weight decay) mitigates overfitting in restricted-sample setting; sample complexity comparable to SOTA (Table 8).",
      "Released code and provided hyperparameter tuning guidance."
    ]
  },
  {
    "arxiv_id": "2303.12811v1",
    "title": "SignCRF: Scalable Channel-agnostic Data-driven Radio Authentication System",
    "authors": "Amani Al-shawabka; Philip Pietraski; Sudhir B Pattar; Pedram Johari; Tommaso Melodia",
    "abstract": "Radio Frequency Fingerprinting through Deep Learning (RFFDL) is a data-driven IoT authentication technique that leverages the unique hardware-level manufacturing imperfections associated with a particular device to recognize (fingerprint) the device based on variations introduced in the transmitted waveform. The proposed SignCRF is a scalable, channel-agnostic, data-driven radio authentication platform with unmatched precision in fingerprinting wireless devices based on their unique manufacturing impairments and independent of the dynamic channel irregularities caused by mobility. SignCRF consists of (i) a baseline classifier finely trained to authenticate devices with high accuracy and at scale; (ii) an environment translator carefully designed and trained to remove the dynamic channel impact from RF signals while maintaining the radio's specific signature; (iii) a Max-Rule module that selects the highest precision authentication technique between the baseline classifier and the environment translator per radio. We design, train, and validate the performance of SignCRF for multiple technologies in dynamic environments and at scale (100 LoRa and 20 WiFi devices). We demonstrate that SignCRF significantly improves the RFFDL performance by achieving as high as 5x and 8x improvement in correct authentication of WiFi and LoRa devices when compared to the state-of-the-art, respectively.",
    "published_date": "2023-03-21",
    "pdf_link": "https://arxiv.org/pdf/2303.12811v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Wireless Security",
      "subdomain": "Device Authentication",
      "specific_problem": "Radio Frequency Fingerprinting (RFFDL) that is robust to channel/environment dynamics and mobility",
      "attack_types": [
        "impersonation/spoofing",
        "adversarial evasion"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GAN",
        "specific": "CycleGAN with least-squares GAN loss (LSGAN)",
        "novel_contribution": "Per-device environment/domain translator that removes dynamic channel effects from RF IQ signals while preserving device-specific hardware signature; used to map source-domain IQ to target (base) domain for channel-agnostic authentication"
      },
      {
        "type": "primary",
        "category": "Ensemble/Rule-based selection",
        "specific": "Max-Rule module",
        "novel_contribution": "Selects, per radio, between baseline classifier and environment-translated pipeline based on TTOD performance to avoid unnecessary complexity and potential accuracy degradation"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "2D CNN from [7] (five Conv+ReLU+MaxPool blocks, then three FC layers + Softmax)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised (unpaired domain translation)",
      "Domain adaptation"
    ],
    "datasets": [
      {
        "name": "WiFi bit-similar device dataset (20 devices) from [2]",
        "type": "public",
        "domain": "rf_iq_samples",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "LoRa bit-similar device dataset (100 devices) from [7] - payload",
        "type": "public",
        "domain": "rf_iq_samples",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "LoRa bit-similar device dataset from [7] - preamble",
        "type": "public",
        "domain": "rf_iq_samples",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Baseline 2D CNN (no environment translation)",
        "paper_reference": "[7]",
        "metric": "Accuracy (worst-case Train-and-Test-in-Other-Domain, TTOD)",
        "their_result": "WiFi: from 18% to 83% (5 devices); from 9% to 34% (20 devices).",
        "baseline_result": "WiFi baseline accuracies: 18% (5 devices), 9% (20 devices)."
      },
      {
        "method_name": "DeepLoRa data augmentation",
        "paper_reference": "[7]",
        "metric": "Accuracy (worst-case across days/environments)",
        "their_result": "LoRa payload: correctly authenticated devices improved from 20% to 80% (5 devices) and from 15% to 75% (20 devices); 100-device scale: from 9% to 73%.",
        "baseline_result": "DeepLoRa best accuracy 22% (20 devices) and improvements from 19%→36% (10 devices) and 13%→22% (20 devices)."
      },
      {
        "method_name": "State-of-the-art (generic SOTA in RFFDL)",
        "paper_reference": null,
        "metric": "Correct authentication rate",
        "their_result": "Up to 100% (WiFi) and 80% (LoRa).",
        "baseline_result": "Reported as 5x (WiFi) and 8x (LoRa) lower than SignCRF."
      },
      {
        "method_name": "No defense against adversarial impersonation",
        "paper_reference": null,
        "metric": "Adversary device recognition accuracy",
        "their_result": "6%",
        "baseline_result": "73%"
      },
      {
        "method_name": "DeepRadioID (FIR filtering with feedback)",
        "paper_reference": "[3]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "ORACLE (inject impairments at transmitter)",
        "paper_reference": "[5]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Number of correctly authenticated devices",
      "TTOD (Train-and-Test-in-Other-Domain) percentage",
      "Adversary device recognition accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can we decouple hardware-level radio fingerprints from time-varying wireless channel/environment to enable channel-agnostic RFFDL?",
        "Can GAN-based unpaired domain translation preserve device-specific signatures while removing channel effects for robust authentication?",
        "Does the approach scale to large populations (e.g., 100 LoRa devices, 20 WiFi devices) and multiple technologies?"
      ],
      "gaps_identified": [
        "Existing RFFDL techniques degrade when training and testing are in different days/environments (worst-case scenario).",
        "Prior methods often rely on transmitter-side DSP, feedback, or artificial impairments, which are impractical for deployed devices.",
        "Data augmentation alone has shown limited gains and lacks generalization across technologies.",
        "No prior practical solution achieving reliable channel-agnostic authentication under mobility and environment changes."
      ],
      "limitations": [
        "Assumes device-specific impairments persist across environments (i.e., do not vanish).",
        "Customized per-device CycleGAN training is required.",
        "Requires collecting datasets in base (target) and new (source) environments; figure indicates using a small portion (e.g., 10%) of target domain data.",
        "Potential added complexity and risk of accuracy degradation due to signal manipulation, mitigated by Max-Rule selection."
      ],
      "future_work": [],
      "motivation": "Provide a practical, scalable, channel-agnostic radio authentication system that removes dependency on transmitter-side modifications/feedback and remains robust under dynamic, mobile environments.",
      "potential_research_ideas": [
        "Develop a shared or conditional generator that generalizes across many devices to reduce per-device training overhead.",
        "Investigate few-shot or meta-learning domain translators that adapt to new devices/environments with minimal data.",
        "Extend to cross-technology translation (e.g., WiFi↔LoRa) or multi-domain continual adaptation for long-term deployment.",
        "Incorporate self-supervised representation learning on IQ data to further preserve device signatures without labels.",
        "Design formal robustness evaluations against adaptive adversaries (e.g., over-the-air perturbations, replay, GAN-based spoofing).",
        "Integrate uncertainty estimation or confidence calibration to improve decision thresholds in the Max-Rule module.",
        "Explore lightweight or on-device variants for edge deployments with limited compute."
      ],
      "architectural_improvement_recommendations": [
        "Replace per-device CycleGANs with a conditional CycleGAN or U-Net style generator conditioned on device ID features to amortize training.",
        "Introduce contrastive or triplet losses on latent representations to explicitly separate device signatures from channel factors.",
        "Leverage domain-adversarial training (DANN) in the classifier to jointly learn channel-invariant features alongside the translator.",
        "Add attention mechanisms over time/frequency to focus on stable signature components while suppressing channel artifacts.",
        "Implement online/continual learning to track slow hardware drift and evolving channels without catastrophic forgetting.",
        "Optimize with quantization/pruning or knowledge distillation to reduce inference time for deployment."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Wireless IoT testbed with base-station-side processing; dynamic indoor/outdoor environments across days",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Per-device customization/training of the environment translator.",
        "Requirement to collect base (target) and source environment IQ datasets.",
        "Balancing translation complexity against risk of degrading signatures (mitigated via Max-Rule)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces SignCRF, a channel-agnostic RFFDL system that decouples radio hardware signatures from channel/environment effects using a GAN-based translator and Max-Rule selection.",
      "Demonstrates substantial gains in worst-case cross-day/environment authentication: WiFi up to 100% correct authentication and LoRa up to 80%; WiFi accuracy improvements from 18%→83% (5 devices) and 9%→34% (20 devices).",
      "Outperforms LoRa data augmentation baselines; improves correctly authenticated devices from 20%→80% (5 devices) and 15%→75% (20 devices); at 100 LoRa devices: recognition from 9%→73% (8x over SOTA).",
      "Shows resilience to adversarial actions by reducing adversary device recognition accuracy from 73% to 6%, yielding zero mis-authentication of impersonating radios.",
      "Validates across multiple technologies (WiFi, LoRa) and at scale (20 WiFi, 100 LoRa); provides the largest reported datasets in literature for these experiments.",
      "Commits to releasing code for community use."
    ]
  },
  {
    "arxiv_id": "2304.05644v1",
    "title": "Generative Adversarial Networks-Driven Cyber Threat Intelligence Detection Framework for Securing Internet of Things",
    "authors": "Mohamed Amine Ferrag; Djallel Hamouda; Merouane Debbah; Leandros Maglaras; Abderrahmane Lakas",
    "abstract": "While the benefits of 6G-enabled Internet of Things (IoT) are numerous, providing high-speed, low-latency communication that brings new opportunities for innovation and forms the foundation for continued growth in the IoT industry, it is also important to consider the security challenges and risks associated with the technology. In this paper, we propose a two-stage intrusion detection framework for securing IoTs, which is based on two detectors. In the first stage, we propose an adversarial training approach using generative adversarial networks (GAN) to help the first detector train on robust features by supplying it with adversarial examples as validation sets. Consequently, the classifier would perform very well against adversarial attacks. Then, we propose a deep learning (DL) model for the second detector to identify intrusions. We evaluated the proposed approach's efficiency in terms of detection accuracy and robustness against adversarial attacks. Experiment results with a new cyber security dataset demonstrate the effectiveness of the proposed methodology in detecting both intrusions and persistent adversarial examples with a weighted avg of 96%, 95%, 95%, and 95% for precision, recall, f1-score, and accuracy, respectively.",
    "published_date": "2023-04-12",
    "pdf_link": "https://arxiv.org/pdf/2304.05644v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Adversarially robust IoT/IIoT intrusion detection via a two-stage GAN-driven adversarial-example detector followed by a DL-based IDS",
      "attack_types": [
        "Adversarial evasion (FGSM)",
        "Backdoor",
        "Vulnerability scanner",
        "DDoS ICMP",
        "Password attack",
        "Port Scanning",
        "DDoS UDP",
        "Uploading",
        "DDoS HTTP",
        "SQL injection",
        "Ransomware",
        "DDoS TCP",
        "XSS",
        "MITM",
        "Fingerprinting"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GAN",
        "specific": null,
        "novel_contribution": "Use of a GAN discriminator as a first-stage detector to identify and filter adversarial examples in IoT traffic prior to intrusion classification"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D CNN (three Conv1d layers + FC)",
        "novel_contribution": "Unified CNN architecture used for both the GAN discriminator (adversarial detection) and the second-stage IDS classifier"
      },
      {
        "type": "baseline",
        "category": "Adversarial Example Generation",
        "specific": "FGSM",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Adversarial training",
      "Unsupervised (GAN)"
    ],
    "datasets": [
      {
        "name": "Edge-IIoTset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "f1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Adversarial training can lead to overfitting on adversarial examples and decrease generalization performance of the model.",
        "Some generative methods may be more appropriate for certain types of data or models than others.",
        "Standard CNN IDS is highly vulnerable to adversarial evasion (accuracy drop from 95.44% to 2.55% under FGSM)."
      ],
      "limitations": [
        "Relatively high percentage of invalid adversarial data for application layer features with respect to traffic boundaries, which may impact practicality of evasion.",
        "Lower recall for certain attack types (e.g., SQL injection recall 0.23; Port Scanning recall 0.52).",
        "Evaluation considers a single adversarial method (FGSM) at epsilon = 0.01.",
        "Results demonstrated on a single dataset (Edge-IIoTset)."
      ],
      "future_work": [],
      "motivation": "Improve the robustness of ML/DL-based cyber threat intelligence against adversarial evasion attacks in 6G-enabled IoT.",
      "potential_research_ideas": [
        "Evaluate robustness against a broader suite of attacks (PGD, BIM, CW, DeepFool, AutoAttack) and adaptive/transfer attacks specific to IoT traffic.",
        "Develop traffic-validity–aware adversarial training that enforces protocol/field constraints to avoid generating invalid samples.",
        "Explore diffusion models or WGAN-GP for generating diverse, realistic adversarial examples tailored to IoT network distributions.",
        "Incorporate temporal and flow context (e.g., sequence models or graph relations among flows/devices) for improved detection of multi-stage attacks.",
        "Design certified robustness approaches (e.g., randomized smoothing for tabular features) for IDS in IoT settings.",
        "Leverage self-supervised pretraining on large unlabeled IoT traffic to improve feature robustness and minority-class recall.",
        "Integrate OOD/novelty detection to identify unseen attacks and distribution shifts in IoT deployments."
      ],
      "architectural_improvement_recommendations": [
        "Replace vanilla GAN with WGAN-GP and spectral normalization to stabilize training and improve generation quality.",
        "Adopt a multi-task architecture that jointly detects adversarial inputs and classifies attacks, sharing robust intermediate representations.",
        "Introduce cost-sensitive learning or focal loss to improve recall on minority classes (e.g., SQL injection, Port Scanning).",
        "Add a traffic-constraint layer or post-processing to enforce protocol-valid feature ranges during adversarial example generation.",
        "Use an ensemble of detectors (e.g., CNN + gradient-based detectors + one-class SVM on latent features) to harden adversarial detection.",
        "Augment with temporal models (Temporal CNNs or Transformers) over flow sequences rather than single records.",
        "Apply calibration (temperature scaling) and confidence-based rejection to reduce high-confidence errors under attack.",
        "Perform feature selection or embedding learning that is robust to small perturbations (e.g., adversarially trained tabular embeddings)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PyTorch"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Experiments run on Google Colaboratory free environment; training reported for 15 epochs; FGSM epsilon = 0.01."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Adversarial examples may violate traffic boundaries (invalid values), affecting practicality and detection.",
        "Adversarial-like perturbations may arise unintentionally from software or hardware errors in real-world scenarios."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Investigated the impact of FGSM adversarial attacks on an intrusion detection model.",
      "Proposed a two-stage cyber threat intelligence framework: Stage 1 uses a GAN discriminator to detect adversarial examples; Stage 2 uses a DL (CNN) model to identify intrusions.",
      "Evaluated detection accuracy and robustness against adversarial attacks on Edge-IIoTset, reporting weighted averages of 96% precision, 95% recall, 95% F1-score, and 95% accuracy.",
      "Showed that a well-trained CNN IDS can suffer a severe accuracy drop (from 95.44% to 2.55%) under FGSM, while the GAN-based discriminator detects FGSM adversarial attacks with 96% recall and real data with 100% recall."
    ]
  },
  {
    "arxiv_id": "2303.02622v1",
    "title": "A Multi-Agent Adaptive Deep Learning Framework for Online Intrusion Detection",
    "authors": "Mahdi Soltani; Khashayar Khajavi; Mahdi Jafari Siavoshani; Amir Hossein Jahangir",
    "abstract": "The network security analyzers use intrusion detection systems (IDSes) to distinguish malicious traffic from benign ones. The deep learning-based IDSes are proposed to auto-extract high-level features and eliminate the time-consuming and costly signature extraction process. However, this new generation of IDSes still suffers from a number of challenges. One of the main issues of an IDS is facing traffic concept drift which manifests itself as new (i.e., zero-day) attacks, in addition to the changing behavior of benign users/applications. Furthermore, a practical DL-based IDS needs to be conformed to a distributed architecture to handle big data challenges.   We propose a framework for adapting DL-based models to the changing attack/benign traffic behaviors, considering a more practical scenario (i.e., online adaptable IDSes). This framework employs continual deep anomaly detectors in addition to the federated learning approach to solve the above-mentioned challenges. Furthermore, the proposed framework implements sequential packet labeling for each flow, which provides an attack probability score for the flow by gradually observing each flow packet and updating its estimation. We evaluate the proposed framework by employing different deep models (including CNN-based and LSTM-based) over the CIC-IDS2017 and CSE-CIC-IDS2018 datasets. Through extensive evaluations and experiments, we show that the proposed distributed framework is well adapted to the traffic concept drift. More precisely, our results indicate that the CNN-based models are well suited for continually adapting to the traffic concept drift (i.e., achieving an average detection rate of above 95% while needing just 128 new flows for the updating phase), and the LSTM-based models are a good candidate for sequential packet labeling in practical online IDSes (i.e., detecting intrusions by just observing their first 15 packets).",
    "published_date": "2023-03-05",
    "pdf_link": "https://arxiv.org/pdf/2303.02622v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Online network intrusion detection with concept drift adaptation, sequential packet-level labeling, and distributed multi-agent (federated) learning",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LSTM/RNN",
        "specific": "Many-to-many LSTM for sequential packet labeling",
        "novel_contribution": "Used to produce per-packet labels and update a flow’s attack probability over time for early detection"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "CNN-based models shown to be well-suited for continual adaptation to traffic concept drift within the framework"
      },
      {
        "type": "primary",
        "category": "Continual Learning",
        "specific": null,
        "novel_contribution": "Framework employs continual deep anomaly detectors to adapt to evolving benign/attack traffic; adapts with small update sets"
      },
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": null,
        "novel_contribution": "Multi-agent knowledge sharing across distributed IDS sensors without centralizing raw data"
      },
      {
        "type": "primary",
        "category": "Anomaly Detection",
        "specific": null,
        "novel_contribution": "Deep anomaly detection used as the continual learning target for adapting to zero-day and changing benign behaviors"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Online Learning",
      "Continual Learning",
      "Federated Learning"
    ],
    "datasets": [
      {
        "name": "CIC-IDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/ids-2017.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CSE-CIC-IDS2018",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/ids-2018.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "detection rate",
      "packets_to_detection (early detection threshold, e.g., first 15 packets)",
      "flows_needed_for_update (e.g., 128 flows)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can a DL-based IDS continually adapt to network traffic concept drift (including zero-day attacks and evolving benign behavior) with minimal new labeled data?",
        "Can federated learning enable effective multi-agent (multi-sensor) IDS knowledge sharing without centralizing data?",
        "How early can an IDS reliably detect intrusions by sequentially labeling packets and updating a flow’s attack probability online?"
      ],
      "gaps_identified": [
        "Most DL-based online NIDS works emphasize speed and accuracy but do not address packet interleaving and the need to separate flows for DL models.",
        "Limited attention to continuous adaptation to traffic concept drift in practical online IDS deployments.",
        "Lack of per-packet sequential labeling with reliability scoring for early detection in online settings.",
        "Insufficient exploration of distributed/multi-agent architectures for DL-based IDS with knowledge sharing."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "DL-based IDS must handle concept drift (zero-day and evolving benign patterns), operate in distributed/multi-agent environments for big-data traffic, and provide early per-packet flow labeling for timely mitigation.",
      "potential_research_ideas": [
        "Integrate transformer-based sequence models (e.g., TCN/Transformers) for packet/flow modeling and compare against LSTM for early detection.",
        "Self-supervised pretraining on large unlabeled network traffic (contrastive or masked modeling) to improve data efficiency for continual updates.",
        "Personalized federated learning for site-specific traffic while maintaining a shared global model (e.g., FedPer/FedRep/adapters).",
        "Robust federated aggregation against adversarial or poisoned clients (e.g., KRUM, FLTrust, coordinate-wise median).",
        "Drift detection modules to trigger adaptive update schedules and select minimal update sets automatically.",
        "Replay- or prototype-based continual learning with privacy (e.g., DP-noised exemplars, synthetic replay via generative models).",
        "Active learning to judiciously request labels for a small subset of flows during updates, minimizing annotation cost.",
        "Calibrated early-warning thresholds and risk-aware decision policies (early exit mechanisms) for sequential detection.",
        "Explainability of per-packet/flow decisions (e.g., attention or feature attribution) to assist analysts.",
        "Adversarial robustness studies for evasion attacks on sequential models and federated settings."
      ],
      "architectural_improvement_recommendations": [
        "Hybrid CNN–LSTM or TCN–LSTM architectures to capture both local packet features and long-range temporal dependencies.",
        "Introduce drift detectors and uncertainty estimation to control when and how to update (e.g., EWC/SI with adaptive regularization strength).",
        "Federated personalization layers/adapters to balance global knowledge with local traffic peculiarities.",
        "Experience replay or prototype memory with privacy-preserving mechanisms for continual learning.",
        "Early-exit branches with calibrated confidence for low-latency decisions after a few packets.",
        "Use robust FL aggregators and client weighting to handle non-IID traffic distributions and stragglers."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Handling interleaved packets and flow separation for DL models in online traffic.",
        "Continuous adaptation to concept drift with minimal labeled updates.",
        "Coordinating multi-agent IDS sensors and aggregating knowledge (federated learning).",
        "Setting thresholds for early detection reliability and managing false alarms.",
        "Concurrency and big-data throughput for many simultaneous flows."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Novel framework for DL-based online IDS that jointly addresses concept drift adaptation, early attack detection via per-packet sequential labeling, and multi-agent operation with federated learning.",
      "Extensive evaluation on CIC-IDS2017 and CSE-CIC-IDS2018 using CNN- and LSTM-based models in the framework.",
      "Quoted result: \"achieving an average detection rate of above 95% while needing just 128 new flows for the updating phase\" for CNN-based continual adaptation.",
      "Quoted result: \"detecting intrusions by just observing their first 15 packets\" using LSTM-based sequential packet labeling.",
      "Demonstration that distributed multi-agent IDSes can effectively share attack knowledge to improve robustness."
    ]
  },
  {
    "arxiv_id": "2302.10601v1",
    "title": "Few-shot Detection of Anomalies in Industrial Cyber-Physical System via Prototypical Network and Contrastive Learning",
    "authors": "Haili Sun; Yan Huang; Lansheng Han; Chunjie Zhou",
    "abstract": "The rapid development of Industry 4.0 has amplified the scope and destructiveness of industrial Cyber-Physical System (CPS) by network attacks. Anomaly detection techniques are employed to identify these attacks and guarantee the normal operation of industrial CPS. However, it is still a challenging problem to cope with scenarios with few labeled samples. In this paper, we propose a few-shot anomaly detection model (FSL-PN) based on prototypical network and contrastive learning for identifying anomalies with limited labeled data from industrial CPS. Specifically, we design a contrastive loss to assist the training process of the feature extractor and learn more fine-grained features to improve the discriminative performance. Subsequently, to tackle the overfitting issue during classifying, we construct a robust cost function with a specific regularizer to enhance the generalization capability. Experimental results based on two public imbalanced datasets with few-shot settings show that the FSL-PN model can significantly improve F1 score and reduce false alarm rate (FAR) for identifying anomalous signals to guarantee the security of industrial CPS.",
    "published_date": "2023-02-21",
    "pdf_link": "https://arxiv.org/pdf/2302.10601v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Industrial Control Systems Security",
      "subdomain": "Anomaly/Intrusion Detection",
      "specific_problem": "Few-shot anomaly detection for industrial CPS using network-derived/tabular features",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Metric Learning / Meta-learning",
        "specific": "Prototypical Network (PN)",
        "novel_contribution": "Prototypical classifier with InfoMax-based objective that incorporates query samples to refine prototypes and a distance-based regularizer to reduce overfitting"
      },
      {
        "type": "primary",
        "category": "Contrastive Learning",
        "specific": "Supervised Contrastive Learning with Class-Information Injection (dynamic temperature)",
        "novel_contribution": "Label-aware temperature scheduling (CII) in supervised contrastive loss to emphasize inter-class separation and preserve intra-class diversity"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Residual CNN feature extractor (4 residual blocks, global average pooling)",
        "novel_contribution": "Lightweight extractor without pooling in residual blocks; trained with supervised contrastive head then frozen to avoid overfitting"
      },
      {
        "type": "primary",
        "category": "Information-Theoretic Objective",
        "specific": "InfoMax-based robust cost function (SPInfoMax/CFD)",
        "novel_contribution": "Mutual information maximization between samples and class prototypes for few-shot classification with added distance-based regularizer"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "FSL-SCNN (Siamese CNN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "OS-SVM (one-shot/one-class SVM as described)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble Tree",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Bayesian",
        "specific": "Naive Bayes",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN/LSTM",
        "specific": "VLSTM (variational LSTM)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Few-shot learning",
      "Metric learning",
      "Meta-learning"
    ],
    "datasets": [
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "FSL-SCNN (Siamese CNN)",
        "paper_reference": null,
        "metric": "F1 score, FAR",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "OS-SVM",
        "paper_reference": null,
        "metric": "F1 score, FAR",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "F1 score, FAR",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "F1 score, FAR",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "VLSTM",
        "paper_reference": null,
        "metric": "F1 score, FAR",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "F1 score",
      "False Alarm Rate (FAR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to perform reliable anomaly detection in industrial CPS when only a few labeled anomalous samples are available?",
        "Can supervised contrastive learning produce more discriminative embeddings for few-shot CPS anomaly detection?",
        "Can prototypical networks be improved for few-shot CPS by mitigating prototype inaccuracy and classifier overfitting?"
      ],
      "gaps_identified": [
        "DL-based CPS anomaly detection methods rely on abundant labeled data and struggle in few-shot settings.",
        "Existing few-shot CPS methods lack specialized feature extraction modules and do not adequately address overfitting in both extractor and classifier.",
        "Prototypes computed from very few support samples can be inaccurate in prototypical networks.",
        "Prior contrastive-learning-based anomaly detectors often depend on thresholding or image augmentations unsuitable for CPS tabular data."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve anomaly detection for industrial CPS under limited labeled data by learning discriminative features and robust few-shot classifiers that generalize with minimal overfitting.",
      "potential_research_ideas": [
        "Evaluate and adapt the approach to real ICS process datasets (e.g., SWaT, WADI) and multimodal CPS logs to test generalization beyond generic network datasets.",
        "Extend to open-set and incremental few-shot anomaly detection where unseen attack families appear post-deployment.",
        "Integrate temporal modeling (e.g., TCNs or Transformers) to capture sequence dynamics in ICS traffic and sensor streams within the few-shot PN framework.",
        "Develop self-/semi-supervised pretraining on large unlabeled CPS data, then fine-tune with FSL-PN to further reduce label needs.",
        "Incorporate uncertainty estimation and calibration for decision thresholds under operational constraints (e.g., controlling FAR).",
        "Design adversarially robust and poisoning-resilient training for few-shot settings (e.g., robust contrastive learning, prototype smoothing).",
        "Use multi-prototype per class or learnable metric (Mahalanobis) to model intra-class heterogeneity typical in CPS data."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment the residual CNN with temporal modules (TCN/Transformer) for sequences; add positional encodings for time dependencies.",
        "Adopt a learnable metric (e.g., Mahalanobis distance with class covariance) or prototypical networks with multiple prototypes per class.",
        "Make temperature in supervised contrastive loss learnable per-class/per-episode instead of rule-based CII; include margin-based contrastive terms.",
        "Add center loss or ArcFace-style angular margins to further enlarge inter-class separation.",
        "Apply episodic data augmentation for tabular CPS (mixup/manifold mixup, feature perturbations consistent with ICS physics).",
        "Use transductive or inductive refinement of prototypes at test time with label propagation to exploit structure in unlabeled queries.",
        "Incorporate uncertainty-aware regularization (e.g., dropout ensembles) and label smoothing to mitigate overfitting."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Few labeled anomalies and class imbalance common in operational CPS.",
        "Risk of overfitting in both feature extractor and classifier when labels are scarce.",
        "Prototype accuracy sensitivity to support set quality in non-stationary environments."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "FSL-PN: a two-stage few-shot anomaly detection framework combining a residual CNN feature extractor, supervised contrastive learning, and a prototypical classifier.",
      "Supervised contrastive loss with dynamic, label-aware temperature (Class-Information Injection) to produce compact intra-class and separable inter-class embeddings.",
      "InfoMax-based robust cost function (SPInfoMax/CFD) that maximizes mutual information between samples and class prototypes and uses query samples to refine prototypes.",
      "Distance-based regularizer added to the classification loss to mitigate overfitting and improve generalization in few-shot settings.",
      "Lightweight residual feature extractor (four residual blocks, global average pooling) tailored for high-dimensional CPS/tabular data, trained then frozen to avoid overfitting.",
      "Empirical evaluation on two public, imbalanced datasets (UNSW-NB15, NSL-KDD) in few-shot settings showing improved F1 and reduced FAR over FSL-SCNN, OS-SVM, Random Forest, Naive Bayes, and VLSTM."
    ]
  },
  {
    "arxiv_id": "2302.09389v2",
    "title": "Vulnerability analysis of captcha using Deep learning",
    "authors": "Jaskaran Singh Walia; Aryan Odugoudar",
    "abstract": "Several websites improve their security and avoid dangerous Internet attacks by implementing CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart), a type of verification to identify whether the end-user is human or a robot. The most prevalent type of CAPTCHA is text-based, designed to be easily recognized by humans while being unsolvable towards machines or robots. However, as deep learning technology progresses, development of convolutional neural network (CNN) models that predict text-based CAPTCHAs becomes easier. The purpose of this research is to investigate the flaws and vulnerabilities in the CAPTCHA generating systems in order to design more resilient CAPTCHAs. To achieve this, we created CapNet, a Convolutional Neural Network. The proposed platform can evaluate both numerical and alphanumerical CAPTCHAs",
    "published_date": "2023-02-18",
    "pdf_link": "https://arxiv.org/pdf/2302.09389v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Web and Application Security",
      "subdomain": "CAPTCHA Security",
      "specific_problem": "Automated solving of text-based alphanumeric CAPTCHAs and vulnerability analysis of CAPTCHA generation schemes",
      "attack_types": [
        "CAPTCHA breaking/bypass",
        "Automated bot abuse"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "CapNet (custom CNN with five parallel character heads)",
        "novel_contribution": "Segmentation-free CNN with flattened grayscale input (200x50), five-branch architecture to predict each character via separate softmax heads; trained with small dataset and binary cross-entropy with Adam"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "VGG-19 (ImageNet pre-trained, transfer learning)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "AlexNet",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Transfer Learning"
    ],
    "datasets": [
      {
        "name": "Auto-generated CAPTCHA dataset (using python captcha 0.4 library)",
        "type": "synthetic",
        "domain": "image_captcha",
        "link": "https://github.com/lepture/captcha",
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "VGG-19 (transfer learning)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "CapNet test accuracy reported as ~96.08% (also elsewhere ~94.67%)",
        "baseline_result": null
      },
      {
        "method_name": "AlexNet",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "CapNet test accuracy reported as ~96.08% (also elsewhere ~94.67%)",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "captcha-level accuracy",
      "character-level accuracy",
      "training accuracy",
      "testing accuracy",
      "loss (binary cross-entropy)",
      "training time"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What vulnerabilities exist in current text-based CAPTCHA generation systems when attacked by deep learning models?",
        "Can a custom CNN (CapNet) trained on a small dataset accurately solve alphanumeric CAPTCHAs?",
        "Which visual properties (noise, rotation, character adjacency) most affect CAPTCHA solver performance?"
      ],
      "gaps_identified": [
        "Lack of hand-labeled CAPTCHA datasets; reliance on synthetic generation",
        "Segmentation-based approaches struggle with overlapping/skewed characters and are ineffective with rectangular windows",
        "Traditional digital image processing techniques have low feature extraction and are easily influenced by noise"
      ],
      "limitations": [
        "Evaluation limited to synthetic CAPTCHAs generated by a Python library (fixed length 5, 50x200, grayscale), not real-world provider CAPTCHAs",
        "Model confusion with rotated characters and characters in close proximity; frequent misclassification among visually similar digits (3, 8, 9) and letters (e.g., g vs 9, w vs m)",
        "Small training set (aimed at <1000 images) may limit generalization to diverse fonts/styles",
        "Baseline comparisons are qualitative (figures) without detailed quantitative reporting for alternative models"
      ],
      "future_work": [
        "Extend the initial training set with large amounts of data to cover additional font styles",
        "Hyperparameter optimization of the architecture (potentially computationally intensive)",
        "Explore metamodeling approaches for efficient hyperparameter search"
      ],
      "motivation": "Assess and expose weaknesses of commonly used text-based CAPTCHAs to inform the design of more resilient CAPTCHA systems against increasingly capable deep learning-based solvers.",
      "potential_research_ideas": [
        "Design a CAPTCHA generator that adversarially optimizes against state-of-the-art OCR/sequence models (CRNN/Transformer) using generative adversarial training while preserving human usability.",
        "Develop an uncertainty-aware CAPTCHA selection system that dynamically serves examples maximizing solver confusion (e.g., best-vs-second-best margin) while constraining human error rates.",
        "Create a benchmark suite of diverse, parameterized synthetic CAPTCHAs (fonts, rotations, occlusions, adjacency) with standardized splits and baselines for reproducible research.",
        "Investigate human-in-the-loop adaptation where CAPTCHA difficulty parameters are tuned per-user performance to maintain usability while resisting automated solvers.",
        "Evaluate solver transferability from synthetic to real-world CAPTCHAs and study domain adaptation techniques to close the sim-to-real gap."
      ],
      "architectural_improvement_recommendations": [
        "Replace per-character heads with sequence modeling (CRNN: CNN + BiLSTM + CTC loss) or Vision Transformer with CTC/attention to better handle variable spacing, overlap, and rotation.",
        "Add Spatial Transformer Networks to learn geometric normalization and reduce sensitivity to rotation and skew.",
        "Use strong data augmentation (rotation, elastic distortions, occlusions, character touching, noise level sweeps, contrast shifts) reflecting failure modes identified.",
        "Adopt label smoothing and focal loss (or class-balanced loss) to mitigate confusion among visually similar characters (3/8/9, w/m/n/v).",
        "Leverage self-supervised or synthetic pretraining on large unlabeled character corpora before fine-tuning on CAPTCHA distributions.",
        "Ensemble diverse architectures (e.g., CNN-CTC + ViT-encoder-decoder) and calibrate outputs to improve robustness and uncertainty estimates."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "TensorFlow",
        "Keras"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Reported training for 200 epochs, batch size 32; total training time ~32000 ms, ~160 ms per epoch; learning rate 0.001 with Adam optimizer"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces CapNet, a custom CNN to solve alphanumeric text CAPTCHAs with five parallel softmax heads predicting each character.",
      "Demonstrates high accuracy with small synthetic training sets (e.g., CapNet ~96% test accuracy) and analyzes misclassification patterns.",
      "Compares CapNet against transfer learning baselines (VGG-19) and other CNNs (e.g., AlexNet), noting less overfitting than baselines.",
      "Performs vulnerability analysis identifying difficult cases (rotation, character adjacency, low grayscale intensity vs noise) and provides guidance to strengthen CAPTCHA design.",
      "Outlines a preprocessing pipeline (grayscale conversion, normalization, one-hot encoding) and training setup (binary cross-entropy, Adam, LR=0.001, 200 epochs)."
    ]
  },
  {
    "arxiv_id": "2304.07226v1",
    "title": "BS-GAT Behavior Similarity Based Graph Attention Network for Network Intrusion Detection",
    "authors": "Yalu Wang; Zhijie Han; Jie Li; Xin He",
    "abstract": "With the development of the Internet of Things (IoT), network intrusion detection is becoming more complex and extensive. It is essential to investigate an intelligent, automated, and robust network intrusion detection method. Graph neural networks based network intrusion detection methods have been proposed. However, it still needs further studies because the graph construction method of the existing methods does not fully adapt to the characteristics of the practical network intrusion datasets. To address the above issue, this paper proposes a graph neural network algorithm based on behavior similarity (BS-GAT) using graph attention network. First, a novel graph construction method is developed using the behavior similarity by analyzing the characteristics of the practical datasets. The data flows are treated as nodes in the graph, and the behavior rules of nodes are used as edges in the graph, constructing a graph with a relatively uniform number of neighbors for each node. Then, the edge behavior relationship weights are incorporated into the graph attention network to utilize the relationship between data flows and the structure information of the graph, which is used to improve the performance of the network intrusion detection. Finally, experiments are conducted based on the latest datasets to evaluate the performance of the proposed behavior similarity based graph attention network for the network intrusion detection. The results show that the proposed method is effective and has superior performance comparing to existing solutions.",
    "published_date": "2023-04-07",
    "pdf_link": "https://arxiv.org/pdf/2304.07226v1",
    "paper_types": [
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Flow-based multi-class network intrusion detection using graph neural networks with behavior-similarity-driven graph construction and attention weighting",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "BS-GAT (Behavior Similarity-based Graph Attention Network)",
        "novel_contribution": "Introduces a behavior-similarity-driven graph construction that yields more uniform node degrees and incorporates behavior edge weights into GAT attention and aggregation to better leverage flow relationships and graph structure."
      },
      {
        "type": "primary",
        "category": "GNN",
        "specific": "GAT (Graph Attention Network)",
        "novel_contribution": "Modified attention to include edge behavior weights in the softmax normalization and message aggregation."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "NF-BoT-IoT-v2",
        "type": "",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "NF-ToN-IoT-v2",
        "type": "",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "NF-BoT-IoT",
        "type": "",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "NF-ToN-IoT",
        "type": "",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "BoT-IoT",
        "type": "",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "ToN-IoT",
        "type": "",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to construct a logically consistent and balanced-degree graph from network flows that better reflects behavior similarity in practical IoT NIDS datasets?",
        "Can incorporating behavior-based edge weights into GAT attention improve multi-class intrusion detection performance?"
      ],
      "gaps_identified": [
        "Existing graph construction logic is very simple and does not consider the characteristics of network data flow, leading to low accuracy, especially for multi-class problems.",
        "Direct use of existing GNN identification without considering inter-node relationships harms performance.",
        "Alert-GCN uses a custom similarity to define edges that makes neighbors highly similar, which may cause overfitting.",
        "E-GraphSAGE constructs graphs that can lead to repeated or entire neighborhood aggregation, affecting identification accuracy.",
        "E-ResGAT improves E-GraphSAGE via residual connections but inherits its graph-construction limitations."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "IoT networks are increasingly complex with rapidly growing attacks; there is a need for intelligent, automated, and robust intrusion detection that leverages graph structure in network flows and adapts to characteristics of practical datasets.",
      "potential_research_ideas": [
        "Online/dynamic graph construction for streaming flows to support real-time NIDS (incremental behavior-similarity graphs).",
        "Learn behavior edge weights end-to-end (learnable λ, μ or a parametric edge-weight network) rather than fixed hyperparameters.",
        "Integrate temporal modeling (temporal GAT or TGNN) to capture sequence and burst patterns in flows.",
        "Heterogeneous graph modeling distinguishing entity types (hosts, ports, services) and flow edges with typed relations.",
        "Contrastive/self-supervised pretraining on unlabeled flows to improve generalization to new attack types.",
        "Graph sparsification or approximate neighbor search (e.g., LSH/kNN) to reduce O(n^2) graph construction cost at scale.",
        "Robustness evaluation and defenses against poisoning/evasion on graph-based NIDS (adversarial GNN defenses).",
        "Explainability for security analysts (e.g., attention-based explanations, subgraph rationales for alerts).",
        "Cross-dataset/domain adaptation (BoT-IoT→ToN-IoT transfer) using domain adaptation or invariant risk minimization.",
        "Hierarchical graph modeling (subnet-level and host-level pooling) for scalability and better global context."
      ],
      "architectural_improvement_recommendations": [
        "Replace/static-augment attention with edge-feature-aware attention (e.g., GATv2 or E-GAT) where edge attributes (behavior rules) are inputs to attention MLP.",
        "Make λ and μ learnable via a small edge-weight generator conditioned on flow/meta-features; regularize to preserve relative ordering (self-similar > same-subnet > other).",
        "Add hierarchical pooling/readout over self-similar areas and subnet areas to capture group behaviors and reduce noise.",
        "Use residual/skip connections with layer normalization to stabilize deeper GAT stacks; combine with focal loss or class-balanced loss for imbalance.",
        "Incorporate temporal encodings (time-deltas, session windows) directly into node/edge features and attention.",
        "Employ curriculum or hard-neighbor mining to avoid over-aggregation and maintain discriminative neighborhoods.",
        "Add contrastive auxiliary loss between positive (behavior-similar) and negative pairs to sharpen embeddings."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Graph construction has O(n^2) time complexity per batch of flows, which may be costly at scale.",
        "Requires reliable access to IP/subnet/port fields to build behavior-similarity edges.",
        "Behavior edge weights (λ=0.85, μ=0.7) are hyperparameters that may require tuning per environment."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a novel behavior-similarity-driven graph construction for NIDS: flows as nodes and behavior rules as edges to yield a relatively uniform number of neighbors per node.",
      "Incorporates edge behavior relationship weights into the GAT attention and aggregation to better utilize flow relationships and graph structure.",
      "Evaluates on recent network-flow datasets (NF-BoT-IoT-v2, NF-ToN-IoT-v2), reporting that “the proposed method is effective and has superior performance comparing to existing solutions.”"
    ]
  },
  {
    "arxiv_id": "2305.00925v1",
    "title": "IoTFlowGenerator: Crafting Synthetic IoT Device Traffic Flows for Cyber Deception",
    "authors": "Joseph Bao; Murat Kantarcioglu; Yevgeniy Vorobeychik; Charles Kamhoua",
    "abstract": "Over the years, honeypots emerged as an important security tool to understand attacker intent and deceive attackers to spend time and resources. Recently, honeypots are being deployed for Internet of things (IoT) devices to lure attackers, and learn their behavior. However, most of the existing IoT honeypots, even the high interaction ones, are easily detected by an attacker who can observe honeypot traffic due to lack of real network traffic originating from the honeypot. This implies that, to build better honeypots and enhance cyber deception capabilities, IoT honeypots need to generate realistic network traffic flows. To achieve this goal, we propose a novel deep learning based approach for generating traffic flows that mimic real network traffic due to user and IoT device interactions. A key technical challenge that our approach overcomes is scarcity of device-specific IoT traffic data to effectively train a generator. We address this challenge by leveraging a core generative adversarial learning algorithm for sequences along with domain specific knowledge common to IoT devices. Through an extensive experimental evaluation with 18 IoT devices, we demonstrate that the proposed synthetic IoT traffic generation tool significantly outperforms state of the art sequence and packet generators in remaining indistinguishable from real traffic even to an adaptive attacker.",
    "published_date": "2023-05-01",
    "pdf_link": "https://arxiv.org/pdf/2305.00925v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Cyber Deception and Honeypots",
      "specific_problem": "Generating realistic synthetic IoT device network traffic flows to make IoT honeypots indistinguishable from real devices under passive traffic analysis",
      "attack_types": [
        "Passive traffic analysis",
        "IoT device fingerprinting over encrypted traffic",
        "Honeypot detection"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GAN",
        "specific": "SeqGAN",
        "novel_contribution": "Used as the core sequence generator, extended beyond uni-variate integers by coupling with a VQ-Variational Autoencoder-based discrete representation to generate multi-variate sequences with discrete and continuous elements"
      },
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": "VQ-VAE (modified as VQ-STAE: Vector Quantized-Sequence Transformer Autoencoder)",
        "novel_contribution": "Sequence transformer-based VQ-VAE to discretize multi-variate packet feature vectors and reconstruct them; enables learning and generation in a lower-dimensional discrete token space"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Sequence Transformers in encoder/decoder (within VQ-STAE)",
        "novel_contribution": "Applies transformer architectures for multivariate sequence encoding/decoding within a VQ framework for traffic flow tokenization and reconstruction"
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "DBSCAN",
        "novel_contribution": "Unsupervised extraction of packet-level signatures (length and direction patterns) to reduce dimensionality and incorporate device/activity structure"
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "Unspecified clustering for duration binning",
        "novel_contribution": "Bins inter-packet durations across multiple magnitudes to preserve variability and avoid bias in reconstruction"
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": "Multi-Layer Perceptron for packet length reconstruction",
        "novel_contribution": "Predicts packet frame lengths from packet frame tokens and discrete representations with sliding-window and look-behind; injects noise for variability"
      },
      {
        "type": "primary",
        "category": "Heuristic/Preprocessing",
        "specific": "Packet-level signature tokenization and direction inference",
        "novel_contribution": "Converts traffic into sequences of signature-derived tokens and orphans to align generation with IoT user activity patterns"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM (adversarial classifier for evaluation)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised (DBSCAN for signatures; clustering for duration bins; GAN discriminator-guided training)",
      "Self-supervised (VQ-STAE autoencoding of sequences)",
      "Adversarial Learning (GAN)",
      "Supervised (LSTM adversarial classifier used for evaluation)"
    ],
    "datasets": [
      {
        "name": "PCAP traffic captures from 18 IoT devices",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "DoppelGANger",
        "paper_reference": "Lin et al., 2019",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Adversarial classifier accuracy (device-type identification)",
      "Indistinguishability to adaptive attacker (qualitative/relative)",
      "Cross-entropy loss (training loss for models)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can we generate synthetic IoT traffic flows that are indistinguishable from real device traffic to deceive a passive, adaptive attacker?",
        "How can we overcome scarcity of device-specific IoT traffic data when training generators?",
        "Can sequence GANs augmented with discrete tokenization and reconstruction handle multivariate packet metadata (length, direction, timing, ports, protocol bits)?"
      ],
      "gaps_identified": [
        "Existing IoT honeypots are easily detected due to lack of realistic network traffic originating from honeypots",
        "Replay-based traffic generation is detectable over longer observations",
        "Generic network traffic generators do not perform well for IoT device-specific sequential discrete/continuous metadata",
        "GANs struggle with discrete sequence generation and require stabilization",
        "Scarcity of device-specific IoT traffic limits training"
      ],
      "limitations": [
        "Current sequential generation is limited to fixed-length traffic windows: \"our sequential generation algorithms is currently limited to generating fixed length sequences\"",
        "GAN mode collapse can occur and needs post-generation variety checks: \"Sometimes, the generator encounters mode collapse\"",
        "Requires device-specific packet-level signature extraction and preprocessing",
        "Duration reconstruction via clustered bins may coarsen timing variability",
        "Assumes accurate inference of device direction and availability of encrypted metadata fields"
      ],
      "future_work": [],
      "motivation": "IoT honeypots need realistic traffic flows to avoid easy detection by attackers observing network traffic; scarcity of device-specific data necessitates models that can learn from limited samples.",
      "potential_research_ideas": [
        "Variable-length and session-level generation to remove fixed-window constraints and better emulate real device sessions",
        "Conditional generation on device type and user activity to produce semantically meaningful flows and enable controllable deception",
        "Meta-learning or few-shot adaptation to rapidly personalize generators to new device types with minimal data",
        "Evaluate against stronger adaptive attackers (e.g., sequence-level likelihood tests, temporal correlation checks, active probing) and co-design robust generators",
        "Integrate diffusion models or autoregressive transformers for discrete token generation as alternatives to GANs",
        "Online learning in deployed honeypots to continually refine generation based on observed benign and attacker interactions",
        "Comprehensive statistical fidelity tests (e.g., temporal cross-correlations, inter-arrival distributions, protocol transition matrices) alongside attacker-based evaluation",
        "Cross-device, cross-environment domain adaptation to generalize between networks and firmware versions"
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment SeqGAN with transformer-based autoregressive token generators (e.g., GPT-style) to improve stability and diversity",
        "Adopt WGAN-GP or adversarial losses with gradient penalties and spectral normalization for improved GAN stability",
        "Hierarchical modeling: model activities/signatures at a high level and packets at a low level for better long-range temporal structure",
        "Joint end-to-end training of VQ-STAE and generator with curriculum learning to align tokenization with generation objectives",
        "Use VQ-VAE-2 or multi-codebook discretization to capture richer multiscale packet metadata patterns",
        "Conditional generation on extracted signature types and protocol contexts; integrate classifier-free guidance to balance fidelity/diversity",
        "Bayesian or ensemble decoders for packet length reconstruction to quantify uncertainty and avoid mode averaging",
        "Introduce differentiable duration modeling (e.g., mixture density networks) rather than discretized bins for timing fidelity"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Scapy",
        "Wireshark/tshark"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "IoT honeypots within smart home or IIoT networks (traffic observed at the Internet gateway)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Device-specific data scarcity for training",
        "Stabilizing GAN training and avoiding mode collapse",
        "Generating realistic timing across multiple magnitudes",
        "Maintaining realism under adaptive attacker scrutiny",
        "Mapping synthetic metadata back to valid encrypted packet streams"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "We develop a novel IoT traffic flow generation algorithm that can generate realistic synthetic traffic flow for cyber deception.",
      "Using signature extraction, our algorithm can easily learn how to generate realistic network traffic with access to little real IoT data.",
      "By comparing our algorithm with a state of art network traffic generator using 18 different IoT devices, we show that our algorithm performs much better in an adversarial setting.",
      "Exact quote: \"significantly outperforms state of the art sequence and packet generators in remaining indistinguishable from real traffic even to an adaptive attacker\""
    ]
  },
  {
    "arxiv_id": "2302.11773v1",
    "title": "Detecting software vulnerabilities using Language Models",
    "authors": "Marwan Omar",
    "abstract": "Recently, deep learning techniques have garnered substantial attention for their ability to identify vulnerable code patterns accurately. However, current state-of-the-art deep learning models, such as Convolutional Neural Networks (CNN), and Long Short-Term Memories (LSTMs) require substantial computational resources. This results in a level of overhead that makes their implementation unfeasible for deployment in realtime settings. This study presents a novel transformer-based vulnerability detection framework, referred to as VulDetect, which is achieved through the fine-tuning of a pre-trained large language model, (GPT) on various benchmark datasets of vulnerable code. Our empirical findings indicate that our framework is capable of identifying vulnerable software code with an accuracy of up to 92.65%. Our proposed technique outperforms SyseVR and VulDeBERT, two state-of-the-art vulnerability detection techniques",
    "published_date": "2023-02-23",
    "pdf_link": "https://arxiv.org/pdf/2302.11773v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Detection in Source Code",
      "specific_problem": "Function-level vulnerability classification of source code (primarily C/C++; claims applicability to Java) using fine-tuned transformer language models",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "GPT-2 (pretrained LLM) fine-tuned",
        "novel_contribution": "VulDetect framework: transformer-based vulnerability detection with teacher-student knowledge distillation (temperature T=3) for efficient, accurate classification"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "CodeBERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Knowledge Distillation",
        "specific": "Teacher-student distillation with KL divergence and temperature scaling (T=3); mentions online knowledge distillation with multiple teacher models",
        "novel_contribution": "Application of online/teacher-present knowledge distillation to vulnerability detection across multiple datasets to reduce compute overhead while retaining accuracy"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "SARD (Software Assurance Reference Dataset)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SeVC (Semantics-based Vulnerability Candidate)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Devign",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "D2A",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SySeVR",
        "paper_reference": "Li et al., IEEE TDSC, 2021",
        "metric": null,
        "their_result": "Paper states: “Our proposed technique outperforms SyseVR …”",
        "baseline_result": null
      },
      {
        "method_name": "VulDeBERT",
        "paper_reference": null,
        "metric": null,
        "their_result": "Paper states: “Our proposed technique outperforms … VulDeBERT …”",
        "baseline_result": null
      },
      {
        "method_name": "VulBERTa",
        "paper_reference": "Hanif and Maffeis, IJCNN 2022",
        "metric": null,
        "their_result": "Table reports comparative scores across SARD/SeVC/Devign/D2A; text claims VulDetect outperforms",
        "baseline_result": null
      },
      {
        "method_name": "DistilVulBERT",
        "paper_reference": null,
        "metric": null,
        "their_result": "Table reports comparative scores across SARD/SeVC/Devign/D2A; text claims VulDetect on par or better",
        "baseline_result": null
      },
      {
        "method_name": "CodeBERT (as model under VulDetect)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "Text: “models’ classification accuracy is significantly higher when the VulDetect technique is implemented.” (no exact number given for CodeBERT)",
        "baseline_result": null
      },
      {
        "method_name": "LSTM (as model under VulDetect)",
        "paper_reference": "Graves, 2012 (LSTM)",
        "metric": "Accuracy; F1",
        "their_result": "Worst-performing among tested models; e.g., 65.78% accuracy on SeVC; 53.5 F1 score (under VulDetect)",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1 score"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "High computational overhead of prior deep learning approaches (CNNs/LSTMs) limits feasibility for real-time deployment",
        "Traditional static analysis requires manual feature engineering; need automated, fast detection on raw code"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Reduce computational overhead while maintaining high accuracy for software vulnerability detection by leveraging transformer LLMs with knowledge distillation.",
      "potential_research_ideas": [
        "Extend VulDetect to perform fine-grained vulnerability type classification and line-level localization, not just binary classification",
        "Incorporate program structure (AST/CFG/PDG) via graph-augmented transformers or hybrid GNN+Transformer models",
        "Cross-language, cross-project transfer learning and domain adaptation to generalize beyond C/C++ to Java and others with minimal labels",
        "Adversarial robustness for code models (poisoning/backdoor defenses) tailored to code tokenization and semantics",
        "Semi/weakly supervised training using static analyzer findings as noisy labels with consistency training",
        "Contrastive pretraining on code (function pairs, vulnerability vs patched) to improve representation learning",
        "Real-time inference optimization (quantization, pruning, distillation to tiny student) for CI/CD and IDE integration"
      ],
      "architectural_improvement_recommendations": [
        "Use intermediate-layer distillation and attention transfer in addition to logit KD to better compress teacher knowledge",
        "Adopt code-aware tokenization (Byte-Pair/Unigram with identifier splitting) and de-duplication to reduce data leakage",
        "Add multi-task heads for vulnerability presence + type + severity to share representations",
        "Incorporate AST/graph encoders (e.g., GraphCodeBERT-style data flow) and fuse with transformer via cross-attention",
        "Apply focal loss or class-balanced loss to address class imbalance in datasets like SeVC",
        "Perform domain-adaptive pretraining on target codebases before fine-tuning to reduce domain shift",
        "Calibrate outputs (temperature scaling on logits) and provide uncertainty estimates for risk-aware triage"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Experiments run on ASUS TUF Gaming laptop with Intel Core i7 (8th gen), 6 cores @ 2.2 GHz; no GPU details provided."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces VulDetect, a transformer-based (GPT-2) vulnerability detection framework with knowledge distillation for efficiency and accuracy",
      "Fine-tunes a pretrained LLM on benchmark vulnerable code datasets (SARD, SeVC; also references Devign and D2A)",
      "Reports accuracy up to 92.65% (e.g., GPT-2 achieves up to 92.59% accuracy on SARD; up to 92.4 F1 on SARD)",
      "Empirically claims to outperform state-of-the-art methods SySeVR and VulDeBERT; includes comparative results with VulBERTa and DistilVulBERT",
      "Describes teacher-present distillation setup using KL divergence with temperature T=3 and combined hard+soft label loss"
    ]
  },
  {
    "arxiv_id": "2303.01126v2",
    "title": "Speaker-Aware Anti-Spoofing",
    "authors": "Xuechen Liu; Md Sahidullah; Kong Aik Lee; Tomi Kinnunen",
    "abstract": "We address speaker-aware anti-spoofing, where prior knowledge of the target speaker is incorporated into a voice spoofing countermeasure (CM). In contrast to the frequently used speaker-independent solutions, we train the CM in a speaker-conditioned way. As a proof of concept, we consider speaker-aware extension to the state-of-the-art AASIST (audio anti-spoofing using integrated spectro-temporal graph attention networks) model. To this end, we consider two alternative strategies to incorporate target speaker information at the frame and utterance levels, respectively. The experimental results on a custom protocol based on ASVspoof 2019 dataset indicates the efficiency of the speaker information via enrollment: we obtain maximum relative improvements of 25.1% and 11.6% in equal error rate (EER) and minimum tandem detection cost function (t-DCF) over a speaker-independent baseline, respectively.",
    "published_date": "2023-03-02",
    "pdf_link": "https://arxiv.org/pdf/2303.01126v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Biometric Authentication",
      "subdomain": "Voice/Speaker Verification PAD (Anti-spoofing)",
      "specific_problem": "Speaker-aware anti-spoofing CM conditioned on target speaker enrollment embeddings for logical access (synthetic/converted speech) attacks",
      "attack_types": [
        "speech synthesis (TTS)",
        "voice conversion",
        "deepfake speech",
        "logical access spoofing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN + CNN with attention (AASIST)",
        "specific": "AASIST (RawNet2 encoder + spectro-temporal graph attention + pooling + FC)",
        "novel_contribution": "Speaker-aware conditioning of AASIST by integrating target speaker enrollment embeddings at encoder (spectral- or channel-wise) or at FC input; proposed enc-spec, enc-chan, and reduced-dimension variants"
      },
      {
        "type": "baseline",
        "category": "GNN + CNN with attention (AASIST)",
        "specific": "AASIST speaker-independent baseline",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "TDNN (speaker embedding extractor)",
        "specific": "ECAPA-TDNN (pre-trained) used to extract 192-dim speaker embeddings",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "ASVspoof 2019 LA",
        "type": "public",
        "domain": "audio_speech",
        "link": "https://www.asvspoof.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VoxCeleb1",
        "type": "public",
        "domain": "audio_speech",
        "link": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "LibriSpeech",
        "type": "public",
        "domain": "audio_speech",
        "link": "https://www.openslr.org/12/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VCTK (origin of ASVspoof LA content)",
        "type": "public",
        "domain": "audio_speech",
        "link": "https://datashare.is.ed.ac.uk/handle/10283/26516",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "AASIST (speaker-independent baseline)",
        "paper_reference": "https://github.com/clovaai/aasist",
        "metric": "EER (%)",
        "their_result": "1.13 (enc-spec, Main protocol)",
        "baseline_result": "1.51"
      },
      {
        "method_name": "AASIST (speaker-independent baseline)",
        "paper_reference": "https://github.com/clovaai/aasist",
        "metric": "minimum t-DCF",
        "their_result": "0.038 (enc-spec, Main protocol)",
        "baseline_result": "0.043"
      }
    ],
    "performance_metrics_used": [
      "EER",
      "minimum t-DCF",
      "per-attack EER breakdown"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can prior knowledge of a target speaker be leveraged to improve anti-spoofing performance compared to speaker-independent CMs?",
        "What is the most effective strategy to incorporate speaker enrollment embeddings into a CM (encoder-level channel-wise vs spectral-wise vs utterance-level)?",
        "How sensitive is a speaker-aware CM to mis-specified speaker identity between enrollment and test utterances?",
        "Does adding extra bonafide-only speech data improve CM performance relative to speaker-aware conditioning?"
      ],
      "gaps_identified": [
        "Most existing speech CMs are standalone, speaker-independent, and struggle to generalize to unseen vocoders, TTS systems, domains, and codecs.",
        "Prior knowledge of the target person is often available in practical scenarios but underutilized in anti-spoofing.",
        "Previous speaker-aware efforts focused on replay detection with GMM backends or ASV backend improvements rather than deep-learning CMs for synthetic attacks."
      ],
      "limitations": [
        "Assumes the target speaker identity is known at test time; performance degrades when this assumption is violated (mis-specified identity).",
        "Experiments limited to ASVspoof 2019 LA (logical access) and a custom protocol; generalization to other datasets and physical/replay conditions not evaluated.",
        "Channel-wise integration underperformed; dimensionality reduction variants degraded performance.",
        "No evaluation under common real-world distortions (codecs, noise) beyond the dataset conditions.",
        "Training conducted with reduced batch size due to single-GPU constraints; no report of inference time or throughput.",
        "Code for the proposed modifications is not stated as released (uses open-source baselines)."
      ],
      "future_work": [
        "Use a Siamese network to encode speaker information and make it available during CM training.",
        "Explore more advanced cohort models to encode speaker information.",
        "Investigate the relationship between spoofing algorithms’ ability to model speaker information and the CM’s compensation via speaker integration.",
        "Study the utility of non-target speaker information and extensions to other scenarios.",
        "Investigate why large additional bonafide data does not always help, considering dataset cleanliness/domain mismatch."
      ],
      "motivation": "Leverage readily available target speaker enrollment information to improve anti-spoofing CMs that otherwise struggle to generalize when trained in a speaker-independent manner.",
      "potential_research_ideas": [
        "End-to-end jointly trained speaker-aware CM where the speaker encoder (e.g., ECAPA) and CM backbone are fine-tuned together with multitask or contrastive losses.",
        "Cross-attention or FiLM-based conditioning layers to modulate CM features by target speaker embeddings across multiple depths.",
        "Cohort-conditioned CMs that use multiple enrollment embeddings (target + cohort) with attention over the cohort to improve robustness.",
        "Speaker-identity consistency detection: a module to detect enrollment–test speaker mismatch and adapt or abstain accordingly.",
        "Domain generalization/adaptation for speaker-aware CMs to handle codecs, channel noise, and cross-corpus transfer.",
        "Adversarial training with spoof generators conditioned on target embeddings to stress-test and harden the CM.",
        "Calibration and score fusion with ASV backends (e.g., tandem systems) to optimize joint detection cost.",
        "Privacy-preserving speaker-aware CM via federated or representation-sanitized embeddings so enrollment data need not leave secure boundaries.",
        "Fairness analysis across gender, accent, and language for speaker-aware conditioning and debiasing strategies."
      ],
      "architectural_improvement_recommendations": [
        "Replace simple concatenation/attachment with FiLM or conditional batch normalization to inject speaker information at multiple layers.",
        "Introduce cross-attention between test utterance features and target speaker embeddings (transformer blocks) for adaptive conditioning.",
        "Use a hypernetwork that generates AASIST encoder filters or attention parameters conditioned on the speaker embedding.",
        "Adopt a projection head trained with contrastive or prototypical losses to align bonafide test features with target-speaker prototypes.",
        "Jointly fine-tune the speaker embedding extractor with the CM using multi-task losses (bonafide/spoof + speaker classification/metric learning).",
        "Explore transformer-based audio encoders with integrated spectral-temporal attention alongside graph layers for improved representation.",
        "Learned dimensionality reduction/projection (e.g., gated linear units) instead of fixed or linear projections for the enrollment embedding.",
        "Combine channel- and spectral-wise conditioning via gated fusion with learned importance weights."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PyTorch"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Trained on a single NVIDIA GeForce GTX 2080Ti; batch size reduced from 24 to 12. Feature map size (64, 23, 29); 192-dim speaker embeddings."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Requires enrollment audio for each target speaker and management of enrollment data.",
        "Performance sensitivity to mis-specified or mismatched speaker identity between enrollment and test.",
        "Unknown generalization to unseen domains, codecs, and environmental noise beyond ASVspoof LA.",
        "Integration with existing ASV systems and calibration of combined decisions (CM + ASV).",
        "Potential privacy concerns around storing and using speaker embeddings."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Formulated speaker-aware anti-spoofing as a conditional CM problem leveraging target speaker enrollment.",
      "Proposed and evaluated multiple strategies to integrate target speaker embeddings into AASIST (enc-chan, enc-spec, reduced variants, and utterance-level).",
      "Designed a custom evaluation protocol on ASVspoof 2019 LA aligning enrollment with target speakers.",
      "Demonstrated up to 25.1% relative EER improvement and 11.6% relative t-DCF improvement over a speaker-independent AASIST baseline (best: enc-spec).",
      "Conducted ablation on mis-specified speaker identity showing graceful degradation and competitive performance vs baseline.",
      "Analyzed impact of adding external bonafide-only corpora (VoxCeleb1, LibriSpeech) on CM performance."
    ]
  },
  {
    "arxiv_id": "2302.09317v1",
    "title": "Reproducing Random Forest Efficacy in Detecting Port Scanning",
    "authors": "Jason M. Pittman",
    "abstract": "Port scanning is the process of attempting to connect to various network ports on a computing endpoint to determine which ports are open and which services are running on them. It is a common method used by hackers to identify vulnerabilities in a network or system. By determining which ports are open, an attacker can identify which services and applications are running on a device and potentially exploit any known vulnerabilities in those services. Consequently, it is important to detect port scanning because it is often the first step in a cyber attack. By identifying port scanning attempts, cybersecurity professionals can take proactive measures to protect the systems and networks before an attacker has a chance to exploit any vulnerabilities. Against this background, researchers have worked for over a decade to develop robust methods to detect port scanning. One such method revealed by a recent systematic review is the random forest supervised machine learning algorithm. The review revealed six existing studies using random forest since 2021. Unfortunately, those studies each exhibit different results, do not all use the same training and testing dataset, and only two include source code. Accordingly, the goal of this work was to reproduce the six random forest studies while addressing the apparent shortcomings. The outcomes are significant for researchers looking to explore random forest to detect port scanning and for practitioners interested in reliable technology to detect the early stages of cyber attack.",
    "published_date": "2023-02-18",
    "pdf_link": "https://arxiv.org/pdf/2302.09317v1",
    "paper_types": [
      "empirical_analysis",
      "reproducibility"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Detection of port scanning in network traffic",
      "attack_types": [
        "Port scanning",
        "Port sweep",
        "TCP connect scan",
        "TCP SYN scan",
        "Stealth scans",
        "Indirect scans"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble Trees",
        "specific": "RandomForestClassifier (scikit-learn)",
        "novel_contribution": "No new model; reproducibility study with multiple hyperparameter sets (A–D) and two tuning methods (RandomizedSearchCV, GridSearchCV)."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Bertoli et al. bona fide network traffic dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MAWILab",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random Forest (Algaolahi et al., CICIDS2017)",
        "paper_reference": "Algaolahi et al.",
        "metric": "Accuracy",
        "their_result": "0.9976",
        "baseline_result": "0.9975"
      },
      {
        "method_name": "Random Forest (Baah et al., CICIDS2017)",
        "paper_reference": "Baah et al.",
        "metric": "Accuracy",
        "their_result": "0.9976",
        "baseline_result": "0.9998"
      },
      {
        "method_name": "Random Forest (Sirisha et al., NSL-KDD)",
        "paper_reference": "Sirisha et al.",
        "metric": "Accuracy",
        "their_result": "0.9976",
        "baseline_result": "0.7650"
      },
      {
        "method_name": "Random Forest (SaiKiran et al., CICIDS2017)",
        "paper_reference": "SaiKiran et al.",
        "metric": "Accuracy",
        "their_result": "0.9976",
        "baseline_result": "0.9993"
      },
      {
        "method_name": "Random Forest (Mohseni et al., CICIDS2017)",
        "paper_reference": "Mohseni et al.",
        "metric": "Accuracy",
        "their_result": "0.9976",
        "baseline_result": "0.9964"
      },
      {
        "method_name": "Random Forest (Bertoli et al., bona fide dataset)",
        "paper_reference": "Bertoli et al.",
        "metric": "F1",
        "their_result": "0.99",
        "baseline_result": "1.0000"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Recall",
      "Precision",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "To what extent does reproduction produce similar results to the original studies, and if not are the differences statistically significant?"
      ],
      "gaps_identified": [
        "Existing studies exhibit different results and do not all use the same training/testing datasets.",
        "Only two of the six recent random forest studies include source code, limiting replicability.",
        "Most studies lack detailed hyperparameters, training splits, and cross-validation details.",
        "CICIDS2017 has known data quality issues (duplicates and mislabeling).",
        "NSL-KDD has limitations that reduce its practicality for ML-based solutions."
      ],
      "limitations": [
        "Replication (exact) was infeasible due to missing implementation details; only reproduction was possible.",
        "Version drift prevented direct reuse of available source code (errors when attempting to run Bertoli et al.'s code).",
        "Evaluation used a 70/30 train-test split uniformly rather than the varied splits in source papers.",
        "Experiments focused on random forest only and primarily on the bona fide dataset.",
        "Most source studies did not specify hyperparameters, requiring constructed sets (A–D)."
      ],
      "future_work": [],
      "motivation": "Address inconsistency and lack of transparency in recent random forest-based port scan detection studies by reproducing results with a clear protocol, shared code/data, and statistical comparison.",
      "potential_research_ideas": [
        "Create a standardized, versioned benchmark suite for port scan detection with fixed train/validation/test splits across multiple datasets (CICIDS2017, MAWILab, bona fide, etc.).",
        "Cross-dataset generalization studies: train on one dataset and test on others to quantify domain shift effects.",
        "Investigate class-imbalance handling (e.g., Balanced Random Forest, cost-sensitive learning) for realistic traffic distributions.",
        "Feature engineering for temporal/sequential patterns (connection bursts, inter-arrival times) to improve detection of slow/stealthy scans.",
        "Adversarial robustness evaluation of port-scan detectors against evasion tactics (packet timing jitter, randomized scan order, packet padding).",
        "Explainability studies using feature importance, SHAP, and counterfactuals to aid SOC analyst trust and rule derivation.",
        "Online/streaming learning for real-time detection in high-throughput networks.",
        "Data curation and relabeling effort to address known CICIDS2017 issues; propose a cleaned, curated subset for scanning."
      ],
      "architectural_improvement_recommendations": [
        "Use Balanced Random Forest or class_weight tuning combined with stratified time-aware splits to handle imbalance and temporal leakage.",
        "Calibrate probabilities (e.g., Platt scaling, isotonic regression) for threshold-tunable alerting.",
        "Explore tree-based gradient boosting (XGBoost/LightGBM/CatBoost) and compare against Random Forest with unified evaluation.",
        "Automated hyperparameter optimization (Bayesian optimization) with nested cross-validation for robust model selection.",
        "Incorporate sessionization and time-windowed aggregation features to capture scan dynamics.",
        "Ensemble across feature sets and window scales; stack learners with meta-model calibration.",
        "Deploy model monitoring for data drift and concept drift with periodic retraining triggers."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "Python 3.11.1",
        "NumPy 1.24.1",
        "Pandas 1.5.3",
        "scikit-learn 1.2.1",
        "Jupyter"
      ],
      "reproducibility_score": "high",
      "computational_requirements": "Ubuntu 22.04; AMD Ryzen 9 5900X CPU; 128 GB RAM; Nvidia RTX 3090 GPU (not required for Random Forest)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Lack of standardized datasets and splits across studies hampers comparability and operationalization.",
        "Version drift of libraries causes reproducibility issues over time.",
        "Potential class imbalance in real traffic not fully addressed may impact alert quality.",
        "Model performance may vary across networks due to domain shift."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Reproduces six recent Random Forest-based port scanning detection studies with a transparent protocol.",
      "Provides detailed environment specifications and scikit-learn based implementation using both RandomizedSearchCV and GridSearchCV.",
      "Defines and evaluates multiple hyperparameter sets (A–D) and reports macro Accuracy/Recall/Precision/F1.",
      "Publishes processed dataset and code in a public GitHub repository to improve transparency.",
      "Statistically compares reproduced results to source studies and finds no significant difference (paired t-test p=0.4103)."
    ]
  },
  {
    "arxiv_id": "2303.00870v2",
    "title": "Implementing Active Learning in Cybersecurity: Detecting Anomalies in Redacted Emails",
    "authors": "Mu-Huan Chung; Lu Wang; Sharon Li; Yuhong Yang; Calvin Giang; Khilan Jerath; Abhay Raman; David Lie; Mark Chignell",
    "abstract": "Research on email anomaly detection has typically relied on specially prepared datasets that may not adequately reflect the type of data that occurs in industry settings. In our research, at a major financial services company, privacy concerns prevented inspection of the bodies of emails and attachment details (although subject headings and attachment filenames were available). This made labeling possible anomalies in the resulting redacted emails more difficult. Another source of difficulty is the high volume of emails combined with the scarcity of resources making machine learning (ML) a necessity, but also creating a need for more efficient human training of ML models. Active learning (AL) has been proposed as a way to make human training of ML models more efficient. However, the implementation of Active Learning methods is a human-centered AI challenge due to potential human analyst uncertainty, and the labeling task can be further complicated in domains such as the cybersecurity domain (or healthcare, aviation, etc.) where mistakes in labeling can have highly adverse consequences. In this paper we present research results concerning the application of Active Learning to anomaly detection in redacted emails, comparing the utility of different methods for implementing active learning in this context. We evaluate different AL strategies and their impact on resulting model performance. We also examine how ratings of confidence that experts have in their labels can inform AL. The results obtained are discussed in terms of their implications for AL methodology and for the role of experts in model-assisted email anomaly screening.",
    "published_date": "2023-03-01",
    "pdf_link": "https://arxiv.org/pdf/2303.00870v2",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Insider Threat",
      "subdomain": "Data Loss Prevention",
      "specific_problem": "Outbound email anomaly detection for potential email exfiltration using redacted email metadata",
      "attack_types": [
        "data_exfiltration",
        "insider_threat",
        "masquerader"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Active Learning",
        "specific": "Batch-mode AL with High-Risk Query (HRQ) plus Uncertainty Queries (UQ) and Random Queries (RQ)",
        "novel_contribution": "Applied HRQ-dominant sampling in a real enterprise email anomaly screening pipeline under privacy-induced label uncertainty; examined incorporating expert confidence ratings into AL."
      },
      {
        "type": "primary",
        "category": "Gradient Boosted Decision Trees",
        "specific": "LightGBM",
        "novel_contribution": "Used as the underlying active learner/classifier for email anomaly detection on redacted metadata."
      },
      {
        "type": "baseline",
        "category": "Active Learning",
        "specific": "Uncertainty Sampling (least confident, margin, entropy discussed)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Active Learning",
        "specific": "Random Sampling",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble/Committee-based AL (discussed conceptually)",
        "specific": "Query-by-Committee / Disagreement Sampling (background only)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Active Learning",
      "Human-in-the-loop"
    ],
    "datasets": [
      {
        "name": "Financial services outbound redacted email metadata (two weeks)",
        "type": "proprietary",
        "domain": "email_metadata",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Ground truth pre-labeled subset (200 email instances)",
        "type": "proprietary",
        "domain": "email_metadata",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Uncertainty Sampling (UQ)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Random Sampling (RQ)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Outside vendor automatic ML (prior attempt at company)",
        "paper_reference": null,
        "metric": "false alarm rate",
        "their_result": null,
        "baseline_result": "96% false alarm rate"
      }
    ],
    "performance_metrics_used": [
      "false alarm rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: Are experts well calibrated in terms of assigning self-confidence ratings to their labeling decisions? (i.e., do model predictions improve when experts are more confident in their labeling decisions?)",
        "RQ2: Does training ML models with groups, rather than individuals, lead to better model performance?",
        "RQ3: How well do experts agree with each other and are there individual differences in terms of how well different experts train ML models (where the quality of training is defined in terms of how well the subsequent models perform)?"
      ],
      "gaps_identified": [
        "Email anomaly detection research often relies on specially prepared datasets that may not reflect industry data.",
        "High-quality labeled data in cybersecurity is difficult to acquire due to privacy and security constraints.",
        "Imbalanced data with rare malicious events hampers supervised training and leads to high false alarm rates.",
        "Active Learning performance is under-studied for expert labeling tasks with labeler uncertainty.",
        "Crowdsourcing labels is infeasible due to sensitivity and expertise requirements."
      ],
      "limitations": [
        "Email bodies and attachment contents were not accessible to labelers; only subjects, filenames, and metadata were available.",
        "Study constrained by analyst time: 20 instances per participant per day over 8 business days.",
        "No stopping criteria were used; focus was on human interactions rather than AL convergence.",
        "Scope focused on emails employees sent to their own addresses, a specific policy-violation subset.",
        "Proprietary data prevents external replication.",
        "Potential for higher false positives due to conservative labeling under limited context."
      ],
      "future_work": [],
      "motivation": "Improve efficiency and effectiveness of anomaly detection for potential email exfiltration in a privacy-constrained enterprise setting by leveraging Active Learning while accounting for expert label uncertainty.",
      "potential_research_ideas": [
        "Model annotator reliability and confidence explicitly (e.g., Bayesian annotator models) and integrate into AL selection and loss weighting.",
        "Compare HRQ-dominant sampling against pure uncertainty, diversity-based, and hybrid strategies with formal batch selection optimization.",
        "Incorporate diversity-aware batch active learning (e.g., core-set or submodular approaches) to reduce redundancy in HRQ batches.",
        "Evaluate semi-supervised or positive-unlabeled learning to better leverage large unlabeled email pools under extreme class imbalance.",
        "Calibrate models and annotators jointly (e.g., temperature scaling for the model, calibration training for analysts) to improve decision thresholds and AL query quality.",
        "Temporal/user-behavior modeling (time-series or user baselines) to capture deviations relative to user norms for anomaly scoring.",
        "Multi-view features including organizational graph relations (manager/team) and communication network structure for improved context.",
        "Active learning under privacy constraints with differential privacy or federated approaches to broaden deployment without exposing content.",
        "Human factors experiments: measure frustration/effort under different AL strategies and design UI interventions to mitigate labeler fatigue.",
        "Post-label investigation feedback loop: incorporate downstream investigation outcomes as delayed labels to correct and refine initial screening labels."
      ],
      "architectural_improvement_recommendations": [
        "Replace simple HRQ batching with a hybrid objective that balances risk score, model uncertainty, and diversity using submodular maximization.",
        "Adopt probabilistic calibration for LightGBM outputs and use expected error reduction as the AL criterion.",
        "Use annotator-noise-aware training (e.g., loss reweighting by self-reported confidence; Dawid–Skene-style latent true label estimation).",
        "Introduce cost-sensitive learning to penalize false negatives more heavily and align with investigation costs.",
        "Leverage an ensemble (LightGBM + calibrated logistic regression + shallow neural net) and Query-by-Committee for disagreement-driven AL.",
        "Engineer behavior-change features (rolling user baselines, z-scores, weekly seasonality) to capture deviations for self-email behavior.",
        "Add diversity via clustering of candidate emails and selecting medoids from high-risk clusters."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "LightGBM"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Enterprise network at a major financial services company",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Privacy constraints prevent access to email bodies and attachment contents.",
        "Label scarcity and class imbalance leading to high false alarm risk.",
        "Analyst time constraints and potential frustration with ambiguous cases.",
        "Need for cross-department cooperation to investigate flagged emails.",
        "Batch retraining and operational overhead for AL in production.",
        "Data sensitivity and lack of ability to use crowdsourcing."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Applied and evaluated Active Learning for email anomaly detection in a privacy-constrained enterprise setting using redacted metadata.",
      "Implemented a high-risk query (HRQ) dominant sampling strategy complemented with uncertainty and random queries in batch mode.",
      "Investigated the role of expert label confidence and human factors in AL, including calibration, group vs. individual training effects, and inter-expert agreement.",
      "Engineered features suitable for redacted data (e.g., Levenshtein distance similarity between sender and recipient names/emails) to detect self-sent emails."
    ]
  },
  {
    "arxiv_id": "2303.03349v1",
    "title": "Scenario-Agnostic Zero-Trust Defense with Explainable Threshold Policy: A Meta-Learning Approach",
    "authors": "Yunfei Ge; Tao Li; Quanyan Zhu",
    "abstract": "The increasing connectivity and intricate remote access environment have made traditional perimeter-based network defense vulnerable. Zero trust becomes a promising approach to provide defense policies based on agent-centric trust evaluation. However, the limited observations of the agent's trace bring information asymmetry in the decision-making. To facilitate the human understanding of the policy and the technology adoption, one needs to create a zero-trust defense that is explainable to humans and adaptable to different attack scenarios. To this end, we propose a scenario-agnostic zero-trust defense based on Partially Observable Markov Decision Processes (POMDP) and first-order Meta-Learning using only a handful of sample scenarios. The framework leads to an explainable and generalizable trust-threshold defense policy. To address the distribution shift between empirical security datasets and reality, we extend the model to a robust zero-trust defense minimizing the worst-case loss. We use case studies and real-world attacks to corroborate the results.",
    "published_date": "2023-03-06",
    "pdf_link": "https://arxiv.org/pdf/2303.03349v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Zero-Trust Access Control",
      "specific_problem": "Learning an explainable, scenario-agnostic trust-threshold policy for zero-trust defense under partial observability (POMDP), with robustness to distribution shift",
      "attack_types": [
        "Account Takeover (ATA)",
        "Social Engineering",
        "Zero-day Exploits"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Meta-Learning",
        "specific": "First-Order Meta-Learning (gradient-based adaptation akin to MAML)",
        "novel_contribution": "Learns a meta threshold policy and adaptation mapping to rapidly adapt zero-trust defense to new attack scenarios from a handful of sample scenarios"
      },
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": "POMDP-based policy optimization with belief (trust score) updates",
        "novel_contribution": "Formulates zero-trust defense under asymmetric information as a parameterized POMDP and proves/uses threshold-policy structure for explainability"
      },
      {
        "type": "primary",
        "category": "Gradient Estimation",
        "specific": "Simultaneous Perturbation Stochastic Approximation (SPSA)",
        "novel_contribution": "Uses SPSA to estimate policy gradients for adaptation and meta-updates with finite-horizon Monte Carlo rollouts, enabling lightweight on-line adaptation"
      },
      {
        "type": "primary",
        "category": "Robust Optimization",
        "specific": "Minimax / Distributionally Robust Optimization with SGDA",
        "novel_contribution": "Scenario-Robust ZTD (SR-ZTD) minimizing worst-case loss over scenario distributions via stochastic gradient descent-ascent"
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": "Single-scenario POMDP policy optimization via SGD (ZTD)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Meta-Learning",
        "specific": "Task-agnostic average policy without adaptation (π_avg)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Meta-Learning",
      "Robust Optimization"
    ],
    "datasets": [
      {
        "name": "MITRE ATT&CK",
        "type": "public",
        "domain": "threat_knowledge_base",
        "link": "https://attack.mitre.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Synthetic POMDP scenario simulations (parameterized by attacker capability/stealthiness and system vulnerability)",
        "type": "synthetic",
        "domain": "simulated_POMDP",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Single-scenario optimal threshold policy (ZTD)",
        "paper_reference": "[12]",
        "metric": "Expected cumulative discounted cost",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Average policy without adaptation (π_avg)",
        "paper_reference": null,
        "metric": "Expected cumulative discounted cost",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Expected cumulative discounted cost U_θ(π)",
      "Worst-case loss across scenarios (minimax objective)",
      "Mean and standard deviation over repeated runs",
      "Convergence to ε-first-order stationary point (iteration complexity O(ε^-2))"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to design a zero-trust defense that is explainable to humans and adaptable to different attack scenarios under partial observability?",
        "Can a meta-learned policy enable rapid adaptation to unseen scenarios using only a few observations?",
        "How to mitigate distribution shift between empirical security datasets and real-world environments via a robust formulation minimizing worst-case loss?"
      ],
      "gaps_identified": [
        "Existing zero-trust frameworks are largely conceptual and scenario-dependent, lacking adaptation/generalization ability across varying system configurations and attacker capabilities.",
        "Information asymmetry due to partial observations complicates decision-making and requires belief/trust estimation.",
        "Distribution shift between empirical datasets and reality can degrade policy performance by overfitting to popular scenarios and failing on rare ones."
      ],
      "limitations": [
        "The approach restricts policies to threshold forms for explainability, which may limit optimality in complex settings.",
        "Gradient-based meta-learning uses SPSA with finite-horizon Monte Carlo simulations, introducing estimation noise and computational overhead.",
        "Meta-learning update ignores the Hessian-vector term to reduce complexity, which may affect optimality.",
        "Assumes a parameterized POMDP model (transition and observation structures) and cost specification that may be nontrivial to identify from real telemetry.",
        "Robustness is defined over a finite scenario set; performance under truly novel or out-of-support scenarios is not guaranteed."
      ],
      "future_work": [],
      "motivation": "Traditional perimeter-based defenses fail under modern connectivity; zero-trust requires continuous, explainable trust evaluation under partial observations and must generalize across diverse attack scenarios while remaining robust to dataset-to-reality distribution shift.",
      "potential_research_ideas": [
        "Learn the POMDP parameters (transition and observation models) from real telemetry using Bayesian or neural belief-state estimation to reduce model misspecification.",
        "Extend beyond scalar thresholds to contextual thresholding that conditions on observation quality and environment variables while preserving interpretability.",
        "Incorporate risk-sensitive objectives (e.g., CVaR) into the robust meta-learning to better handle tail-risk attack scenarios.",
        "Develop multi-agent formulations where attacker strategies are learned and co-evolve, enabling adversarial meta-learning with strategy exploration.",
        "Evaluate and adapt the framework on enterprise-scale identity and access datasets (e.g., authentication logs) to validate real-world efficacy.",
        "Introduce online concept-drift detection to trigger rapid re-meta-learning when scenario distributions shift significantly.",
        "Fuse multiple detection sources (EDR, IDS, UEBA) and learn reliability-weighted observations to improve trust estimation.",
        "Combine causal inference to disentangle spurious alerts from causal indicators of compromise for better threshold calibration."
      ],
      "architectural_improvement_recommendations": [
        "Replace SPSA with likelihood-ratio policy gradient or actor-critic methods tailored for POMDPs to reduce gradient variance.",
        "Adopt Bayesian meta-learning (e.g., probabilistic MAML) to capture uncertainty in adaptation and provide calibrated thresholds.",
        "Use model-based RL with learned dynamics of belief updates to accelerate adaptation and reduce Monte Carlo cost.",
        "Implement distributionally robust optimization with Wasserstein ambiguity sets over scenarios for tighter robustness guarantees.",
        "Introduce hierarchical meta-learning that separates attacker-capability and system-vulnerability factors for more structured adaptation.",
        "Auto-tune adaptation and meta step sizes via meta-optimizers to improve stability and convergence."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Experiments report MC horizon T=100, ~1000 scenario samples, batch size 10; SPSA perturbation schedule and step sizes provided; overall adaptation is lightweight but requires Monte Carlo rollouts."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Mapping real-world telemetry to POMDP parameters and costs (transition probabilities, detection/false-alarm rates).",
        "Handling distribution shift between empirical datasets and production environments.",
        "Balancing explainability (threshold policy) with potential loss of optimality in complex scenarios.",
        "Operational overhead of Monte Carlo-based gradient estimation for on-line adaptation.",
        "Managing IDS false positives/negatives that affect belief (trust) updates."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes Scenario-Agnostic Zero-Trust Defense (SA-ZTD) that yields explainable trust-threshold policies and adapts to new scenarios with few observations.",
      "Introduces a scenario-robust zero-trust defense (SR-ZTD) that minimizes worst-case loss across scenarios to address distribution shift.",
      "Develops a first-order meta-learning algorithm (SPSA-FOML/SGD-SGDA) to efficiently learn the meta-policy using only a handful of sample scenarios, with convergence characterization."
    ]
  },
  {
    "arxiv_id": "2303.04605v3",
    "title": "Keystroke Dynamics: Concepts, Techniques, and Applications",
    "authors": "Rashik Shadman; Ahmed Anu Wahab; Michael Manno; Matthew Lukaszewski; Daqing Hou; Faraz Hussain",
    "abstract": "Reliably identifying and verifying subjects remains integral to computer system security. Various novel authentication techniques, such as biometric authentication systems, have been developed in recent years. This paper provides a detailed review of keystroke-based authentication systems and their applications. Keystroke dynamics is a behavioral biometric that is emerging as an important tool for cybersecurity as it promises to be non-intrusive and cost-effective. In addition, no additional hardware is required, making it convenient to deploy. This survey covers novel keystroke datasets, state-of-the-art keystroke authentication algorithms, keystroke authentication on touch screen and mobile devices, and various prominent applications of such techniques beyond authentication. The paper covers all the significant aspects of keystroke dynamics and can be considered a reference for future researchers in this domain. The paper includes a discussion of the latest keystroke datasets, providing researchers with an up-to-date resource for analysis and experimentation. In addition, this survey covers the state-of-the-art algorithms adopted within this domain, offering insights into the cutting-edge techniques utilized for keystroke analysis. Moreover, this paper explains the diverse applications of keystroke dynamics, particularly focusing on security, verification, and identification uses. Furthermore, this paper presents a summary of future research opportunities, highlighting potential areas for exploration and development within the realm of keystroke dynamics. This forward-looking perspective aims to inspire further inquiry and innovation, guiding the trajectory of future studies in this dynamic field.",
    "published_date": "2023-03-08",
    "pdf_link": "https://arxiv.org/pdf/2303.04605v3",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Identity and Access Management",
      "subdomain": "Behavioral Biometrics",
      "specific_problem": "Keystroke dynamics for authentication, verification (continuous), and identification",
      "attack_types": [
        "impostor login/impersonation"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Fuzzy Logic",
        "specific": "Bell MF, Gaussian MF membership functions",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Probabilistic model",
        "specific": "Gaussian model (anomaly detector)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Meta/Pairwise coupling + classical ML",
        "specific": "Pairwise User Coupling (PUC) with machine learning classifiers",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "One-class/Anomaly detection"
    ],
    "datasets": [
      {
        "name": "Killourhy and Maxion dataset [66]",
        "type": "public",
        "domain": "keystroke_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Giot et al. dataset [47]",
        "type": "public",
        "domain": "keystroke_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Sun et al. dataset [114]",
        "type": "public",
        "domain": "keystroke_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PACE University online exams keystroke dataset (Mondal and Bours) [83]",
        "type": "",
        "domain": "keystroke_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Benchmark dataset [14] (used by Mohlala et al.)",
        "type": "",
        "domain": "keystroke_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Dataset [24] (newer benchmark referenced)",
        "type": "",
        "domain": "keystroke_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Dataset [85] (newer benchmark referenced)",
        "type": "",
        "domain": "keystroke_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Dataset [125] (webform keystroke data referenced)",
        "type": "",
        "domain": "keystroke_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Dataset [124] (newer benchmark referenced)",
        "type": "",
        "domain": "keystroke_dynamics",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [
      {
        "method_name": "Sridhar, Vaidya and Yawalkar (Fuzzy Logic with Bell and Gaussian MF) [108]",
        "paper_reference": "[108]",
        "metric": "FAR/FRR",
        "their_result": "\"For 200 samples, they achieved a FAR of 0.0% and a FRR of 0.0% for both Bell MF and Gaussian MF.\"",
        "baseline_result": null
      },
      {
        "method_name": "Mondal and Bours PUC + ML classifiers [83]",
        "paper_reference": "[83]",
        "metric": "Accuracy",
        "their_result": "\"The best accuracy achieved was 89.7%.\"",
        "baseline_result": null
      },
      {
        "method_name": "Chen et al. Gaussian model (static) on Killourhy & Maxion [66]",
        "paper_reference": "[28] using [66]",
        "metric": "EER",
        "their_result": "\"achieved an EER of 6.62%\"",
        "baseline_result": null
      },
      {
        "method_name": "Chen et al. static on Giot et al. [47]",
        "paper_reference": "[28] using [47]",
        "metric": "EER",
        "their_result": "\"achieved an EER of 5.71%\"",
        "baseline_result": null
      },
      {
        "method_name": "Chen et al. dynamic user profiles mechanism",
        "paper_reference": "[28]",
        "metric": "EER",
        "their_result": "\"EER could be decreased to 4.03% using a dynamic user profiles mechanism.\"",
        "baseline_result": null
      },
      {
        "method_name": "Chen et al. continuous auth on Sun et al. [114]",
        "paper_reference": "[28] using [114]",
        "metric": "Average EER",
        "their_result": "\"achieved an average EER of 2%\"",
        "baseline_result": null
      },
      {
        "method_name": "Mohlala, Ikuesan, and Venter forensic attribution [81]",
        "paper_reference": "[81]",
        "metric": "Subject attribution accuracy",
        "their_result": "\"Each subject’s pattern was accurately attributed ... except for one user. However, all subjects were accurately attributed using the attribution mechanism.\"",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "False Accept Rate (FAR)",
      "False Reject Rate (FRR)",
      "Equal Error Rate (EER)",
      "ROC curve",
      "AUC",
      "Average Number of Impostor Actions (ANIA)",
      "Average Number of Genuine Actions (ANGA)",
      "Authentication time",
      "Rank-n",
      "True Positive Rate (TPR)",
      "False Positive Rate (FPR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What are the latest keystroke dynamics benchmark datasets?",
        "What are the state-of-the-art algorithms for keystroke authentication and identification?",
        "How is keystroke authentication performed on touch screen and mobile devices?",
        "What are the prominent applications of keystroke dynamics beyond authentication?",
        "What performance metrics best characterize keystroke-based systems?",
        "What future research opportunities exist in keystroke dynamics?"
      ],
      "gaps_identified": [
        "Prior surveys (largely from 2013–2017) are outdated and do not cover recent datasets (e.g., [24], [114], [85], [125], [124]).",
        "Earlier surveys often focused on only one aspect (e.g., mobile devices, static-text) and did not comprehensively cover free-text, fixed-text, and semi fixed-text systems.",
        "Limited consolidated coverage of feature engineering approaches and applications across domains.",
        "Lack of up-to-date, unified reference that spans datasets, algorithms, metrics, mobile/touch capture, and applications."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Provide a comprehensive and up-to-date survey of keystroke dynamics spanning datasets, algorithms, mobile/touch capture, feature engineering, applications, and future research opportunities to guide researchers and practitioners.",
      "potential_research_ideas": [
        "Unified benchmarking protocol for static, semi fixed-text, and free-text with standardized train/test splits and continuous-authentication streams.",
        "Cross-device and cross-context domain adaptation (desktop ↔ mobile/tablet; different keyboards and layouts).",
        "Template aging and longitudinal robustness studies with continual/online learning and controlled drift handling.",
        "Privacy-preserving keystroke biometrics (secure template storage, homomorphic matching, federated learning without raw keystrokes).",
        "Adversarial resilience: study imitation attacks, keystroke injection/replay; develop robust detectors and challenge-response schemes.",
        "Multimodal fusion with mouse dynamics, touch gestures, motion sensors for improved continuous authentication.",
        "Explainable behavioral biometrics: interpretable features highlighting decisive timing patterns.",
        "Fairness and inclusivity: evaluate performance across languages, keyboard layouts, disabilities, and typing proficiency.",
        "Lightweight on-device models for mobile/edge with adaptive enrollment and resource-aware inference.",
        "Self-supervised pretraining on large unlabeled typing streams to improve few-shot enrollment."
      ],
      "architectural_improvement_recommendations": [
        "Adopt one-class deep ensembles (e.g., one-class CNN/Transformer on time intervals) for user-specific anomaly detection with uncertainty estimation.",
        "Incorporate domain-adaptive layers or adversarial domain adaptation to generalize across devices and contexts.",
        "Use sequence models (Temporal CNNs/Transformers) with attention over timing features; augment with dwell/flight derivatives and n-graph timing.",
        "Online template update with calibrated drift detection and safeguards against poisoning; use EWMA/Bayesian updating.",
        "Privacy by design: cancelable biometrics and secure sketch/extractors; encrypt templates; evaluate attack surfaces.",
        "Edge deployment optimizations: quantization, pruning, and knowledge distillation for low-latency continuous auth.",
        "Fusion architectures combining keystroke with auxiliary passive signals (cursor dynamics, accelerometer) via late fusion.",
        "Calibration strategies to auto-tune thresholds per-user to balance FAR/FRR and maximize ANIA/ANGA under constraints."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Real-world adoption has been limited despite convenience benefits.",
        "Security vs. convenience trade-off (FAR/FRR thresholding).",
        "Long authentication times can render systems impractical for security use-cases."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comprehensive survey of keystroke dynamics covering datasets, algorithms, feature engineering, mobile/touch capture, and applications.",
      "Up-to-date discussion of latest keystroke datasets to aid analysis and experimentation.",
      "Synthesis of state-of-the-art algorithms and techniques for keystroke analysis.",
      "Coverage of applications beyond authentication, including verification and identification.",
      "Detailed exposition of performance metrics specific to keystroke biometrics, including ANIA/ANGA and authentication time.",
      "Comparison against prior surveys with justification for a new, broader survey.",
      "Summary of future research opportunities to guide subsequent work."
    ]
  },
  {
    "arxiv_id": "2303.15950v1",
    "title": "A source separation approach to temporal graph modelling for computer networks",
    "authors": "Corentin Larroche",
    "abstract": "Detecting malicious activity within an enterprise computer network can be framed as a temporal link prediction task: given a sequence of graphs representing communications between hosts over time, the goal is to predict which edges should--or should not--occur in the future. However, standard temporal link prediction algorithms are ill-suited for computer network monitoring as they do not take account of the peculiar short-term dynamics of computer network activity, which exhibits sharp seasonal variations. In order to build a better model, we propose a source separation-inspired description of computer network activity: at each time step, the observed graph is a mixture of subgraphs representing various sources of activity, and short-term dynamics result from changes in the mixing coefficients. Both qualitative and quantitative experiments demonstrate the validity of our approach.",
    "published_date": "2023-03-28",
    "pdf_link": "https://arxiv.org/pdf/2303.15950v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Temporal link prediction for enterprise network monitoring and anomaly detection of malicious remote logons",
      "attack_types": [
        "intrusion",
        "malicious remote logons"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Matrix Factorization",
        "specific": "Superposed Nonnegative Matrix Factorization (SNMF)",
        "novel_contribution": "Models each time step as a mixture of L nonnegative NMF-modeled activity sources with time-varying mixing coefficients; learns U_l, V_l per source and a sparse mixing matrix W; uses multiplicative updates and seasonal prediction of mixing coefficients."
      },
      {
        "type": "primary",
        "category": "Time-series/Seasonality Modeling",
        "specific": "Seasonal averaging of mixing coefficients",
        "novel_contribution": "Predicts future mixing coefficients by averaging past coefficients at the same seasonal position (e.g., weekly period), enabling simple and robust short-term dynamics modeling."
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "VAST 2013 Mini-Challenge 3 (MC3) network traffic",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "LANL Comprehensive, Multi-Source Cyber-Security Events (Los Alamos)",
        "type": "public",
        "domain": "authentication_logons",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "silhouette score",
      "false positive rate",
      "detection rate",
      "mean squared error"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can enterprise network activity be modeled as a superposition of a small number of interpretable activity sources with time-varying mixing coefficients?",
        "Does the proposed SNMF model improve temporal link prediction and malicious activity detection on enterprise networks compared to state-of-the-art methods?"
      ],
      "gaps_identified": [
        "Standard temporal link prediction algorithms do not account for sharp short-term seasonal variations in enterprise networks.",
        "Dynamic latent space models that adjust node embeddings are better suited to smooth, node-specific dynamics of social/recommender graphs, not the global, seasonal variations in enterprise networks.",
        "Lack of labeled malicious activity makes direct estimation of detection rate difficult; thus anomaly detection is often reframed as link prediction."
      ],
      "limitations": [
        "No forgetting mechanism implemented for long-term deployment; potential drift not handled.",
        "Long-term dynamics and associated challenges are not addressed beyond simple seasonal averaging of mixing coefficients.",
        "Manual thresholding used in qualitative source visualization; cluster counts chosen via silhouette but may be dataset-specific."
      ],
      "future_work": [
        "Introduce forgetting/decay mechanisms to handle concept drift in long-term deployments.",
        "Extend modeling of long-term dynamics beyond simple seasonality (e.g., trends, regime changes)."
      ],
      "motivation": "Improve reliability of intrusion detection on enterprise networks by explicitly modeling short-term seasonal dynamics via source separation, aiming for scalability, interpretability, and robustness.",
      "potential_research_ideas": [
        "Design and evaluate online/streaming SNMF with adaptive forgetting to handle concept drift and evolving behaviors.",
        "Learn seasonal periods and regime changes automatically (e.g., multiple periods, change-point detection for W).",
        "Incorporate exogenous covariates (calendar features, maintenance windows, security policy changes) to predict mixing coefficients.",
        "Use probabilistic/Bayesian NMF with sparsity priors for uncertainty-aware anomaly scoring.",
        "Adopt Bernoulli/Poisson likelihoods tailored to binary/count edge data instead of MSE, with appropriate link functions.",
        "Hybrid architectures combining SNMF sources with GNN decoders per source to capture higher-order patterns while keeping few temporal degrees of freedom.",
        "Robust SNMF variants (e.g., outlier-robust loss) to reduce sensitivity to bursty or malicious traffic.",
        "Joint modeling of multiple event types (e.g., logons, flows, DNS) via coupled factorization to improve detection across modalities.",
        "Automatic source number selection (L) via nonparametric priors or MDL criteria.",
        "Adversarial evaluation: simulate evasive attackers to assess and harden robustness of source/mixing decomposition."
      ],
      "architectural_improvement_recommendations": [
        "Replace squared error with Bernoulli (for binary) or Poisson (for counts) likelihood and optimize via projected gradient/ALS.",
        "Add temporal regularization or autoregressive components on mixing coefficients W (e.g., ARIMA/State Space) rather than simple seasonal averaging.",
        "Introduce group sparsity/structured sparsity on U_l, V_l to yield crisper, role-based sources (e.g., servers vs workstations).",
        "Implement online multiplicative updates with exponential decay/forgetting for U, V, and W to support streaming data.",
        "Hyperparameter selection for L and K via cross-validation on link prediction AUROC/AP; add MDL or BIC-style penalties.",
        "Calibrated anomaly scoring using per-time-step normalization or conformal methods to control false positive rate.",
        "Warm-start inference of w_t at test time via a few projected gradient steps instead of pure seasonal averaging."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/cl-anssi/NetworkSourceSeparation",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Handling long-term dynamics and concept drift over months/years; currently lacks forgetting mechanism.",
        "Selecting seasonal period and hyperparameters (L, K, regularization) for different organizations.",
        "Maintaining interpretability and stability of sources as networks evolve."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces Superposed Nonnegative Matrix Factorization (SNMF) for temporal link prediction and anomaly detection in enterprise networks.",
      "Proposes a source separation hypothesis for short-term enterprise network dynamics with mixing coefficients capturing seasonality.",
      "Provides an open-source implementation of SNMF with multiplicative updates.",
      "Qualitative analysis showing interpretable activity sources and seasonal patterns on VAST 2013 MC3.",
      "Quantitative experiments on LANL dataset; claims state-of-the-art performance on a public real-world network monitoring dataset."
    ]
  },
  {
    "arxiv_id": "2304.04987v1",
    "title": "Detecting Anomalous Microflows in IoT Volumetric Attacks via Dynamic Monitoring of MUD Activity",
    "authors": "Ayyoob Hamza; Hassan Habibi Gharakheili; Theophilus A. Benson; Gustavo Batista; Vijay Sivaraman",
    "abstract": "IoT networks are increasingly becoming target of sophisticated new cyber-attacks. Anomaly-based detection methods are promising in finding new attacks, but there are certain practical challenges like false-positive alarms, hard to explain, and difficult to scale cost-effectively. The IETF recent standard called Manufacturer Usage Description (MUD) seems promising to limit the attack surface on IoT devices by formally specifying their intended network behavior. In this paper, we use SDN to enforce and monitor the expected behaviors of each IoT device, and train one-class classifier models to detect volumetric attacks.   Our specific contributions are fourfold. (1) We develop a multi-level inferencing model to dynamically detect anomalous patterns in network activity of MUD-compliant traffic flows via SDN telemetry, followed by packet inspection of anomalous flows. This provides enhanced fine-grained visibility into distributed and direct attacks, allowing us to precisely isolate volumetric attacks with microflow (5-tuple) resolution. (2) We collect traffic traces (benign and a variety of volumetric attacks) from network behavior of IoT devices in our lab, generate labeled datasets, and make them available to the public. (3) We prototype a full working system (modules are released as open-source), demonstrates its efficacy in detecting volumetric attacks on several consumer IoT devices with high accuracy while maintaining low false positives, and provides insights into cost and performance of our system. (4) We demonstrate how our models scale in environments with a large number of connected IoTs (with datasets collected from a network of IP cameras in our university campus) by considering various training strategies (per device unit versus per device type), and balancing the accuracy of prediction against the cost of models in terms of size and training time.",
    "published_date": "2023-04-11",
    "pdf_link": "https://arxiv.org/pdf/2304.04987v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Detecting volumetric attacks that conform to IoT MUD profiles and isolating anomalous microflows (5-tuple) using SDN telemetry and one-class anomaly detection",
      "attack_types": [
        "DoS",
        "DDoS",
        "TCP SYN flooding",
        "UDP flooding",
        "ICMP flooding",
        "ARP spoofing",
        "Reflection attacks (SSDP, SNMP, TCP, ICMP)",
        "Ping of Death",
        "Fraggle",
        "Flash crowd",
        "Worms"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "One-Class Classifier",
        "specific": null,
        "novel_contribution": "Multi-level inferencing combining volumetric (per-device/per-service/per-microflow activity volume) and dispersion features aligned to MUD flows; models trained on benign-only traffic per device and per device-type; dynamic SDN-driven feature collection and targeted packet mirroring."
      }
    ],
    "learning_paradigm": [
      "One-class",
      "Semi-supervised (trained on benign-only data)",
      "Anomaly detection"
    ],
    "datasets": [
      {
        "name": "Lab IoT volumetric attack traffic traces (benign + attacks)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "University campus IP camera network traffic dataset (for scalability study)",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "MUD profiles for 28 consumer IoT devices",
        "type": "public",
        "domain": "MUD_profiles",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Snort",
        "paper_reference": "[16] (as cited in the paper)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Bro/Zeek",
        "paper_reference": "[15] (as cited in the paper)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "false positive rate",
      "training time",
      "model size (memory footprint)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can volumetric attacks that conform to an IoT device’s MUD profile be detected reliably using only benign-trained models?",
        "Can we precisely isolate anomalous microflows (5-tuple) contributing to volumetric attacks to improve explainability and mitigation?",
        "What are the trade-offs between per-device and per device-type training in terms of detection accuracy, model size, and training time?",
        "How can SDN telemetry and dynamic mirroring be orchestrated to monitor and detect volumetric and distributed attacks cost-effectively?"
      ],
      "gaps_identified": [
        "Signature-based IDSs (e.g., Snort/Zeek) detect only a limited subset of IoT attacks and miss novel volumetric threats.",
        "Generic anomaly detection approaches face high false positives and lack microflow-level explainability, limiting operational utility.",
        "MUD enforcement does not limit traffic rates; volumetric attacks can conform to MUD ACEs and still succeed.",
        "Entropy-based detectors can flag anomalies but do not identify the specific microflows responsible.",
        "Slow adoption of vendor-provided MUD profiles; need for automated generation/enforcement."
      ],
      "limitations": [
        "Dependence on availability and correctness of device MUD profiles; adoption by manufacturers is still slow.",
        "MUD URL spoofing is possible with DHCP/LLDP (mitigated if X.509 extension is used).",
        "Spec-based detector can be evaded by sophisticated spoofing that conforms to MUD; hence reliance on anomaly detection.",
        "Resource constraints in SDN switches (e.g., TCAM usage) for reactive microflows and timeouts must be managed.",
        "Potential overhead from mirroring and packet inspection, especially at high bit rates.",
        "Reliance on DNS bindings for translating domain-based ACEs may introduce complexity and timing issues."
      ],
      "future_work": [
        "Further exploration of scalability across diverse IoT fleets and environments with mixed device types.",
        "Refinement of training strategies (per device vs per type) to balance accuracy and cost.",
        "Operational tuning of idle timeouts and telemetry rates to manage TCAM and overhead under varying loads."
      ],
      "motivation": "IoT deployments are increasingly targeted by sophisticated volumetric attacks that can evade traditional IDS and conform to MUD whitelists; operators need explainable, scalable anomaly detection with low false positives.",
      "potential_research_ideas": [
        "Federated or cross-site one-class training to leverage benign patterns across organizations while preserving privacy.",
        "Transfer learning or domain adaptation between device types to reduce per-device training costs.",
        "Active/online learning to adapt models to firmware updates and evolving benign patterns without extensive retraining.",
        "Integrating rate-limiting and automated mitigation policies based on microflow identification to close the loop.",
        "Hybrid detection combining entropy/sketch-based prefilters with microflow-level one-class models for high-speed links.",
        "Exploring graph-based models of device-service interactions to capture coordinated or low-and-slow attacks."
      ],
      "architectural_improvement_recommendations": [
        "Use streaming telemetry (e.g., sFlow/NetFlow/IPFIX or P4-based counters) to reduce mirroring overhead and improve scalability.",
        "Incorporate adaptive sampling and sketching for microflow dispersion estimation before promoting to 5-tuple rules.",
        "Implement hierarchical model management with per-type base models and light per-device deltas to cut memory and training time.",
        "Add resilience to DNS dynamics via caching strategies and validation of domain-IP bindings to avoid feature drift.",
        "Integrate controller-side batching and rate control for reactive rule insertion to protect TCAM and avoid churn."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "OpenFlow (SDN)",
        "Faucet SDN controller",
        "Zeek",
        "Snort"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Home/enterprise networks and a university campus network (IP cameras)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Slow adoption of vendor MUD profiles; may require auto-generated profiles.",
        "Potential spoofing of MUD URL via DHCP/LLDP unless X.509 is used.",
        "Managing SDN switch TCAM usage and idle timeouts for reactive microflows.",
        "Mirroring and packet inspection overhead at high bit rates.",
        "Dependence on DNS bindings for domain-based ACE enforcement.",
        "Avoiding controller overload by offloading packet inspection from the controller."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A multi-level inferencing model leveraging SDN telemetry to detect anomalous MUD-compliant flows and then isolate attacks at microflow (5-tuple) resolution via packet inspection.",
      "Collection and public release of labeled IoT traffic traces including benign and multiple volumetric attacks.",
      "A working SDN-based system prototype (modules open-sourced) demonstrating high-accuracy detection with low false positives and providing cost/performance insights.",
      "Scalability study comparing per-device vs per device-type training using datasets from a campus IP camera network, analyzing accuracy vs model size and training time."
    ]
  },
  {
    "arxiv_id": "2303.06513v1",
    "title": "Detection of DDoS Attacks in Software Defined Networking Using Machine Learning Models",
    "authors": "Ahmad Hamarshe; Huthaifa I. Ashqar; Mohammad Hamarsheh",
    "abstract": "The concept of Software Defined Networking (SDN) represents a modern approach to networking that separates the control plane from the data plane through network abstraction, resulting in a flexible, programmable and dynamic architecture compared to traditional networks. The separation of control and data planes has led to a high degree of network resilience, but has also given rise to new security risks, including the threat of distributed denial-of-service (DDoS) attacks, which pose a new challenge in the SDN environment. In this paper, the effectiveness of using machine learning algorithms to detect distributed denial-of-service (DDoS) attacks in software-defined networking (SDN) environments is investigated. Four algorithms, including Random Forest, Decision Tree, Support Vector Machine, and XGBoost, were tested on the CICDDoS2019 dataset, with the timestamp feature dropped among others. Performance was assessed by measures of accuracy, recall, accuracy, and F1 score, with the Random Forest algorithm having the highest accuracy, at 68.9%. The results indicate that ML-based detection is a more accurate and effective method for identifying DDoS attacks in SDN, despite the computational requirements of non-parametric algorithms.",
    "published_date": "2023-03-11",
    "pdf_link": "https://arxiv.org/pdf/2303.06513v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Detecting Distributed Denial of Service (DDoS) attacks in Software-Defined Networking (SDN) using machine learning",
      "attack_types": [
        "DrDoS_DNS",
        "DrDoS_LDAP",
        "DrDoS_MSSQL",
        "DrDoS_NetBIOS",
        "DrDoS_NTP",
        "DrDoS_SNMP",
        "DrDoS_SSDP",
        "DrDoS_UDP",
        "Portmap",
        "Syn",
        "TFTP",
        "UDP-lag"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble - Random Forest",
        "specific": "Random Forest",
        "novel_contribution": "Comparative evaluation on CICDDoS2019 for SDN DDoS detection with time-based features (e.g., timestamp) removed; balanced sampling and 20 selected flow features."
      },
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": "Used as a comparative baseline; per-attack precision/recall/F1 reported."
      },
      {
        "type": "primary",
        "category": "SVM",
        "specific": null,
        "novel_contribution": "Used as a comparative baseline; kernel not specified."
      },
      {
        "type": "primary",
        "category": "Gradient Boosting",
        "specific": "XGBoost",
        "novel_contribution": "Used as a comparative baseline; ROC curves analyzed."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CICDDoS2019",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "68.9%",
        "baseline_result": null
      },
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "63.5%",
        "baseline_result": null
      },
      {
        "method_name": "Support Vector Machine",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "59.2%",
        "baseline_result": null
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "47.8%",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "F1-score",
      "ROC curve"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How do common ML classifiers (RF, DT, SVM, XGBoost) compare for detecting DDoS attacks in SDN using CICDDoS2019?",
        "What is the impact of excluding non-realistic features (e.g., timestamp) on detection performance?",
        "Which attack types are harder to detect under realistic feature constraints?"
      ],
      "gaps_identified": [
        "Previous works often relied on time-based features (e.g., timestamp) that are impractical for real-time deployment.",
        "Limited comparative analysis of RF, SVM, DT, and XGBoost on CICDDoS2019 within SDN context.",
        "Use of limited or non-realistic feature sets in prior studies."
      ],
      "limitations": [
        "Non-parametric algorithms have significant computational requirements, making real-time, large-scale deployment challenging.",
        "Lower overall accuracy compared to some prior reports when realistic features are used (e.g., RF 68.9%).",
        "Per-attack performance is uneven; some classes have low precision/recall (e.g., DrDoS_SSDP and certain others).",
        "WebDDoS attack type excluded due to insufficient data.",
        "Evaluation limited to a single dataset and offline setting; no real-time or live-network validation reported."
      ],
      "future_work": [
        "Optimize computational efficiency of non-parametric algorithms to enable real-time, large-scale deployment.",
        "Further improve feature selection for realistic real-time use while maintaining accuracy."
      ],
      "motivation": "SDN’s centralized architecture introduces new DDoS risks; the study seeks realistic ML-based detection by avoiding impractical features and comparing multiple classifiers on a modern DDoS dataset.",
      "potential_research_ideas": [
        "Design a feature pipeline for SDN controllers that extracts only real-time computable flow features and evaluate online performance with streaming inference.",
        "Explore deep learning (e.g., temporal CNN/LSTM/Transformer on flow sequences) without timestamp reliance, using sliding windows and aggregation features.",
        "Develop hierarchical/multi-stage classifiers: first detect DDoS vs benign, then classify attack subtype to handle class imbalance and hard-to-separate classes.",
        "Conduct cross-dataset generalization studies (e.g., CICDDoS2019 to other DDoS datasets) to assess robustness and domain shift.",
        "Investigate adversarial robustness of DDoS detectors in SDN (evasion/poisoning) and defenses (adversarial training, feature smoothing).",
        "Use cost-sensitive learning or focal loss to improve recall on underperforming attack types (e.g., DrDoS_SSDP, DrDoS_SNMP).",
        "Incorporate graph/network-level features (e.g., host-level communication graphs) and GNN-based models to capture distributed patterns.",
        "Leverage online/continual learning to adapt to evolving attack patterns in SDN environments."
      ],
      "architectural_improvement_recommendations": [
        "Perform systematic feature selection (e.g., BorutaSHAP, mutual information) constrained to real-time-derivable fields from SDN controller statistics.",
        "Hyperparameter optimization (e.g., Bayesian search) for RF/XGBoost; evaluate class weighting/threshold tuning for imbalanced per-attack performance.",
        "Adopt calibrated probability outputs (Platt/Isotonic) and threshold per attack-type for improved operating points seen in ROC analysis.",
        "Implement streaming inference with micro-batching at the SDN controller and model compression (tree pruning, quantization) to meet latency budgets.",
        "Use hierarchical classification pipeline: binary DDoS detector followed by per-type classifier to improve macro-F1.",
        "Ensemble stacking/blending (RF + XGBoost + calibrated SVM) to reduce variance and improve robustness across attack types."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Pandas"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High computational cost of non-parametric models for real-time, large-scale SDN deployment.",
        "Feature feasibility in live traffic (avoiding timestamp/time-based features).",
        "Uneven per-attack performance leading to potential operational blind spots."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comparative evaluation of Random Forest, Decision Tree, SVM, and XGBoost for SDN DDoS detection on CICDDoS2019.",
      "Emphasis on realistic feature selection by excluding timestamp and using 20 flow-based features.",
      "Reported overall and per-attack precision/recall/F1 and ROC curves; Random Forest achieved highest accuracy at 68.9%.",
      "Balanced benign/malicious sampling and 80/20 train-test split on CICDDoS2019."
    ]
  },
  {
    "arxiv_id": "2304.11052v1",
    "title": "A Multiagent CyberBattleSim for RL Cyber Operation Agents",
    "authors": "Thomas Kunz; Christian Fisher; James La Novara-Gsell; Christopher Nguyen; Li Li",
    "abstract": "Hardening cyber physical assets is both crucial and labor-intensive. Recently, Machine Learning (ML) in general and Reinforcement Learning RL) more specifically has shown great promise to automate tasks that otherwise would require significant human insight/intelligence. The development of autonomous RL agents requires a suitable training environment that allows us to quickly evaluate various alternatives, in particular how to arrange training scenarios that pit attackers and defenders against each other. CyberBattleSim is a training environment that supports the training of red agents, i.e., attackers. We added the capability to train blue agents, i.e., defenders. The paper describes our changes and reports on the results we obtained when training blue agents, either in isolation or jointly with red agents. Our results show that training a blue agent does lead to stronger defenses against attacks. In particular, training a blue agent jointly with a red agent increases the blue agent's capability to thwart sophisticated red agents.",
    "published_date": "2023-04-03",
    "pdf_link": "https://arxiv.org/pdf/2304.11052v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Autonomous Cyber Defense",
      "specific_problem": "Training and evaluating multi-agent RL attacker and defender (red/blue) in simulated enterprise networks (CyberBattleSim) with a trainable blue agent and joint training",
      "attack_types": [
        "lateral movement",
        "local vulnerability exploitation",
        "remote vulnerability exploitation",
        "credential abuse"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": "PPO",
        "novel_contribution": "Introduces MARLon: multi-agent training over CyberBattleSim with PPO using AttackerWrapper/DefenderWrapper, action validation/masking via wrapper, joint turn-based training and coordinated episode resets."
      },
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": "A2C",
        "novel_contribution": "Same MARLon setting; trains blue and red agents jointly or in isolation using A2C with wrapper-based action validation and custom defender reward."
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Multi-agent RL",
      "Deep Reinforcement Learning",
      "Self-play (joint attacker–defender training)"
    ],
    "datasets": [
      {
        "name": "CyberBattleSim ToyCTF Network",
        "type": "public",
        "domain": "simulated_enterprise_network",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CyberBattleSim Chain Network (built-in topology)",
        "type": "public",
        "domain": "simulated_enterprise_network",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CyberBattleSim (environment)",
        "type": "public",
        "domain": "simulated_enterprise_network",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Q-learning (CyberBattleSim documentation benchmark)",
        "paper_reference": "CyberBattleSim documentation [10]",
        "metric": "Cumulative reward over 1,500-step episodes",
        "their_result": null,
        "baseline_result": "around 270 (trained Q agent)"
      },
      {
        "method_name": "Deep Q-learning (CyberBattleSim documentation benchmark)",
        "paper_reference": "CyberBattleSim documentation [10]",
        "metric": "Cumulative reward over 1,500-step episodes",
        "their_result": null,
        "baseline_result": "up to 430 (trained Deep Q agent)"
      },
      {
        "method_name": "Built-in random defender (non-trainable, probabilistic reimage)",
        "paper_reference": "CyberBattleSim built-in defender (described in paper)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accumulated/cumulative reward per episode",
      "episode length (max steps per episode)",
      "win/loss via network availability constraint violations (blue loses on violation with large negative reward)",
      "training timesteps"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to arrange training scenarios that pit attackers and defenders against each other to produce strong autonomous agents, particularly defenders?",
        "Does training a blue (defender) agent in isolation or jointly with a red (attacker) agent improve defensive capabilities?",
        "How to enable trainable blue agents and multi-agent training within CyberBattleSim despite interface and invalid-action constraints?"
      ],
      "gaps_identified": [
        "Original CyberBattleSim lacked a trainable blue (defender) agent; defender was static and probabilistic.",
        "CyberBattleSim’s action space could not handle invalid actions, preventing direct use of many state-of-the-art RL libraries.",
        "Observation space and interface incompatibilities with popular RL libraries (e.g., stable-baselines3).",
        "Need for multi-agent (simultaneous red/blue) training support with synchronized episode resets.",
        "Existing realistic environments (e.g., CyGIL/CybORG) face long training times and transfer challenges; CyberBattleSim focuses on conceptual exploration rather than transferability."
      ],
      "limitations": [
        "Defender reward is defined as the negative of the attacker’s last reward, making defender learning progress dependent on attacker competence; defender’s maximum reward is zero.",
        "Blue agent must satisfy a network availability constraint; breaking it ends the episode with a large negative reward, which can destabilize early training.",
        "CyberBattleSim is less concerned with transferability to real systems; realism and sim-to-real are not addressed.",
        "No public code link for MARLon and wrappers is provided in the text, limiting reproducibility."
      ],
      "future_work": [],
      "motivation": "Enable development and evaluation of autonomous red and blue RL agents with a practical, multi-agent training environment to study training arrangements and strengthen defenses.",
      "potential_research_ideas": [
        "Design defender-centric reward functions that incorporate availability, service quality, and operational cost without directly mirroring attacker rewards.",
        "Incorporate deception actions (honeypots/honeytokens) as first-class defender actions and study their impact under MARL training.",
        "Develop curriculum self-play where attacker/defender competencies co-evolve with increasing scenario difficulty and topology complexity.",
        "Investigate centralized-critic, decentralized-actor MARL methods (e.g., MADDPG, COMA, QMIX, IPPO) for this domain.",
        "Explore graph-based policy networks (GNNs) to leverage network topology and service graphs for decision-making.",
        "Study robustness to diverse red strategies via population-based training (PBT) or league training.",
        "Evaluate sim-to-real transfer by porting trained policies from CyberBattleSim to CybORG/CyGIL emulations and measuring transfer performance.",
        "Introduce constrained RL or safe RL to explicitly encode availability and service constraints.",
        "Hierarchical RL to separate high-level strategy selection from low-level parameterized actions."
      ],
      "architectural_improvement_recommendations": [
        "Implement action masking integrated into the policy (rather than only penalizing invalid actions) to improve learning efficiency.",
        "Adopt centralized critic with decentralized actors to better handle joint credit assignment between red/blue agents.",
        "Use graph neural networks over node/service features and firewall edges for both policy and value functions.",
        "Apply reward shaping that balances attacker deterrence with operational costs (e.g., reimage cost, service downtime).",
        "Leverage constrained RL (e.g., Lagrangian methods) to enforce availability without large terminal penalties.",
        "Introduce population-based or league training with diverse attacker/defender populations to improve generalization.",
        "Use recurrent policies (e.g., LSTM) for partial observability and temporal dependencies.",
        "Experiment with off-policy algorithms (e.g., SAC, TD3) with proper discrete/parametric action handling to improve sample efficiency."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "stable-baselines3",
        "OpenAI Gym",
        "CyberBattleSim"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Training for 300,000 timesteps with episodes up to 2,000 steps; joint training of two agents (red/blue) using PPO or A2C in the ToyCTF environment."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Handling invalid actions in large, parameterized action spaces.",
        "Interface incompatibilities with standard RL libraries (observation/action spaces).",
        "Coordinating environment resets across two agents in multi-agent training.",
        "Maintaining service availability while executing defensive actions (constraint satisfaction)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Extended CyberBattleSim with a trainable defender (blue agent) via a DefenderWrapper exposing action/observation spaces, validity checks, and a defender reward function.",
      "Introduced AttackerWrapper to handle invalid actions, provide OpenAI Gym-compatible interfaces, and optionally penalize invalid actions.",
      "Developed MARLon (Multi-Agent training on CyberBattleSim) enabling joint training of red and blue agents with coordinated step-taking and synchronized resets.",
      "Implemented and evaluated PPO and A2C agents for both red and blue, training in isolation and jointly on the ToyCTF topology.",
      "Empirically showed that training a blue agent strengthens defenses and joint training with a red agent improves the blue agent’s ability to thwart sophisticated attackers.",
      "Provided training regimen details: 300,000 timesteps, up to 2,000 steps per episode, and a 60% availability constraint with large terminal penalty for violations."
    ]
  },
  {
    "arxiv_id": "2304.10550v2",
    "title": "Deep transfer learning for intrusion detection in industrial control networks: A comprehensive review",
    "authors": "Hamza Kheddar; Yassine Himeur; Ali Ismail Awad",
    "abstract": "Globally, the external internet is increasingly being connected to industrial control systems. As a result, there is an immediate need to protect these networks from a variety of threats. The key infrastructure of industrial activity can be protected from harm using an intrusion detection system (IDS), a preventive mechanism that seeks to recognize new kinds of dangerous threats and hostile activities. This review examines the most recent artificial-intelligence techniques that are used to create IDSs in many kinds of industrial control networks, with a particular emphasis on IDS-based deep transfer learning (DTL). DTL can be seen as a type of information-fusion approach that merges and/or adapts knowledge from multiple domains to enhance the performance of a target task, particularly when labeled data in the target domain is scarce. Publications issued after 2015 were considered. These selected publications were divided into three categories: DTL-only and IDS-only works are examined in the introduction and background section, and DTL-based IDS papers are considered in the core section of this review. By reading this review paper, researchers will be able to gain a better grasp of the current state of DTL approaches used in IDSs in many different types of network. Other useful information, such as the datasets used, the type of DTL employed, the pre-trained network, IDS techniques, the evaluation metrics including accuracy/F-score and false-alarm rate, and the improvements gained, are also covered. The algorithms and methods used in several studies are presented, and the principles of DTL-based IDS subcategories are presented to the reader and illustrated deeply and clearly",
    "published_date": "2023-04-19",
    "pdf_link": "https://arxiv.org/pdf/2304.10550v2",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Industrial Control Systems Security",
      "subdomain": "Intrusion Detection Systems (IDS)",
      "specific_problem": "Deep transfer learning approaches for intrusion detection in industrial control networks (ICNs/ICS/SCADA)",
      "attack_types": [
        "Denial-of-Service (DoS)",
        "Distributed DoS (DDoS)",
        "Man-in-the-Middle (MITM)",
        "Wireless LAN intrusions",
        "Return-oriented programming payload detection",
        "Smart grid cyberattacks",
        "False Data Injection Attacks (FDIA)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transfer Learning",
        "specific": "Deep Transfer Learning (DTL) with fine-tuning and knowledge transfer",
        "novel_contribution": "Paper provides a comprehensive taxonomy and review; no new model proposed."
      },
      {
        "type": "primary",
        "category": "Domain Adaptation",
        "specific": "DANN (Domain-Adversarial Neural Network)",
        "novel_contribution": "Reviewed as part of adversarial DTL taxonomy."
      },
      {
        "type": "primary",
        "category": "Domain Adaptation",
        "specific": "MMD/TCA/CORAL",
        "novel_contribution": "Reviewed MMD-based and discrepancy-based DA (e.g., Maximum Mean Discrepancy, Transfer Component Analysis, CORAL)."
      },
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "Federated Transfer Learning (FTL)",
        "novel_contribution": "Reviewed FTL-based IDS approaches and positioning for privacy-aware ICNs."
      },
      {
        "type": "primary",
        "category": "Multi-task Learning",
        "specific": null,
        "novel_contribution": "Reviewed as a DTL subcategory for IDS."
      },
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": "Deep Auto-Encoder (AE), Variants incl. RVAE",
        "novel_contribution": "Reviewed as feature learning within DTL-based IDS."
      },
      {
        "type": "primary",
        "category": "HMM",
        "specific": "Hidden Markov Model (HMM)",
        "novel_contribution": "Reviewed as a category within DTL-based IDS."
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "ConvNet; ConvLSTM",
        "novel_contribution": "Reviewed as backbones adapted via DTL (fine-tuning/DA)."
      },
      {
        "type": "primary",
        "category": "RNN/LSTM",
        "specific": "LSTM/ConvLSTM, seq2seq",
        "novel_contribution": "Reviewed sequence models in DTL-based IDS."
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "Generative Adversarial Network",
        "novel_contribution": "Reviewed under adversarial DTL and data augmentation contexts."
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Support Vector Machine",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "KNN",
        "specific": "k-Nearest Neighbors",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "MLP/DNN",
        "specific": "Multilayer Perceptron / Deep Neural Network",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "DBN",
        "specific": "Deep Belief Network",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Semi-supervised",
      "Transfer Learning",
      "Domain Adaptation",
      "Federated Learning"
    ],
    "datasets": [
      {
        "name": "SWaT (Secure Water Treatment)",
        "type": "public",
        "domain": "ics_sensor_timeseries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "WADI (Water Distribution)",
        "type": "public",
        "domain": "ics_sensor_timeseries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "F1-score (F-score)",
      "False Alarm Rate (FAR)",
      "Attack Detection Rate (ADR)",
      "AUC (Area Under ROC)",
      "ROC (Receiver Operating Characteristics)",
      "True Positive (TP) / False Positive (FP)",
      "Recognition Rate (RR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What deep transfer learning (DTL) approaches are being used to build IDS for industrial control networks?",
        "How do DTL categories (e.g., domain adaptation, multi-task, adversarial, federated, partial) map to IDS techniques (signature-, anomaly-, specification-based)?",
        "What datasets, pre-trained networks, evaluation metrics, and reported improvements are used in DTL-based IDS for ICNs?",
        "What open challenges and future research directions exist for applying DTL to IDS in ICNs, especially in 5G and beyond?"
      ],
      "gaps_identified": [
        "Lack of a thorough, comprehensive survey dedicated to DTL-based IDS applications prior to this work.",
        "Data scarcity and distribution inconsistency between training and target domains hinder DL-based IDS performance in ICNs.",
        "Existing IDS models are often application-specific and struggle with novel or rare attacks due to limited labeled target data.",
        "ICS/ICN-specific constraints (real-time operation, fixed business logic, limited compute/energy) are often not fully addressed by conventional IDS approaches.",
        "Many ICS protocols lack authentication/encryption, facilitating MITM and packet tampering, increasing the need for robust IDS."
      ],
      "limitations": [
        "Paper selection restricted to works published from 2016 onward (modernity criterion), which may exclude earlier relevant contributions.",
        "Survey methodology prioritizes high-impact venues and highly cited works, potentially introducing selection bias.",
        "As a review, no unified experimental benchmark or re-evaluation across methods is provided."
      ],
      "future_work": [
        "Highlight and systematize open challenges and future research paths for IDS-based DTL in ICNs.",
        "Advance DTL-based IDS suitable for 5G/6G-era requirements (QoS, interoperability, robustness, privacy, security).",
        "Explore and mature federated transfer learning (FTL) approaches for privacy-aware, cross-organization ICS intrusion detection.",
        "Develop ICN-specific datasets and benchmarks that reflect real distribution shifts, scarce labels, and operational constraints."
      ],
      "motivation": "ICS are increasingly connected to external networks, heightening cyber risk. DTL promises to mitigate data scarcity and distribution shift in IDS for ICNs. A comprehensive synthesis of DTL-based IDS methods, datasets, and challenges has been missing.",
      "potential_research_ideas": [
        "Create standardized, multi-site ICS DTL benchmarks capturing cross-domain shifts (plants, protocols) with clear train-target splits and privacy-preserving access.",
        "Design multi-modal domain adaptation for ICNs that jointly aligns network traffic and physical process sensor time series with causality-aware constraints.",
        "Develop continual/online DTL for concept drift in ICS operations, integrating drift detection and rapid low-label adaptation.",
        "Leverage self-supervised and contrastive pretraining tailored to ICS logs/sensor data to reduce labeled target data needs for IDS.",
        "Integrate federated transfer learning with differential privacy and secure aggregation for cross-operator IDS collaboration without sharing raw data.",
        "Construct digital twin-driven synthetic data generation with domain randomization to improve target generalization and evaluate robustness.",
        "Study adversarial robustness of DTL-based IDS under poisoning/evasion tailored to ICS constraints and APT-like stealth patterns.",
        "Build explainable DTL-based IDS with physics-informed priors and feature attributions linked to control process semantics to support operators.",
        "Investigate lightweight DTL via knowledge distillation/pruning/quantization for real-time edge deployment on resource-limited ICS nodes."
      ],
      "architectural_improvement_recommendations": [
        "Combine discrepancy-based (MMD/CORAL/TCA) with adversarial DA (DANN) in a unified objective with class-conditional alignment for ICS attack classes.",
        "Adopt sequence-focused backbones (ConvLSTM/Temporal Transformers) with domain-specific positional encodings for periodic ICS processes.",
        "Use multi-task heads to jointly predict attack type, severity, and affected layer (field/supervisory) to guide transfer.",
        "Introduce physics-informed constraints or simulators-in-the-loop during training to penalize impossible process dynamics.",
        "Apply cross-domain contrastive learning across plants/protocols to learn domain-invariant representations before fine-tuning.",
        "Employ hierarchical FTL: site-level local adaptation, global aggregation, and per-protocol adapters to handle heterogeneity.",
        "Incorporate uncertainty estimation (e.g., MC Dropout, deep ensembles) to defer low-confidence alerts and reduce FAR in novel targets."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Industrial control networks (ICS/SCADA, IIoT)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Strict real-time operation; even small delays can be catastrophic for ICS processes.",
        "Resource constraints on field devices (limited energy/compute/storage).",
        "IDS must not disrupt operational processes or fixed business logic.",
        "Legacy systems and software/hardware updates complicate security integration.",
        "Lack of authentication/encryption in some ICS protocols facilitates MITM and packet tampering.",
        "Heterogeneity of devices, protocols, and standards increases attack surface and complicates model generalization."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Provides a comprehensive taxonomy of DTL models for IDS (inductive, transductive, adversarial, partial, federated, multi-task, etc.).",
      "Presents a thorough taxonomy of IDS techniques for ICNs (signature-based, anomaly-based, specification-based) and maps them to DTL approaches.",
      "Surveys DTL-based IDS applications across multiple network types (e.g., NIDS, HIDS, wireless, smart grid, cloud) with design decisions, pros/cons.",
      "Covers datasets, pre-trained models, evaluation metrics (accuracy/F-score, FAR), and reported improvements in the literature.",
      "Details ICN layers and their security needs, contextualizing IDS requirements for industrial environments.",
      "Highlights existing research challenges and outlines future directions for DTL-based IDS in ICNs."
    ]
  },
  {
    "arxiv_id": "2303.02503v1",
    "title": "Zero-Effort Two-Factor Authentication Using Wi-Fi Radio Wave Transmission and Machine Learning",
    "authors": "Ali Abdullah S. AlQahtani; Thamraa Alshayeb",
    "abstract": "The proliferation of sensitive information being stored online highlights the pressing need for secure and efficient user authentication methods. To address this issue, this paper presents a novel zero-effort two-factor authentication (2FA) approach that combines the unique characteristics of a users environment and Machine Learning (ML) to confirm their identity. Our proposed approach utilizes Wi-Fi radio wave transmission and ML algorithms to analyze beacon frame characteristics and Received Signal Strength Indicator (RSSI) values from Wi-Fi access points to determine the users location. The aim is to provide a secure and efficient method of authentication without the need for additional hardware or software. A prototype was developed using Raspberry Pi devices and experiments were conducted to demonstrate the effectiveness and practicality of the proposed approach. Results showed that the proposed system can significantly enhance the security of sensitive information in various industries such as finance, healthcare, and retail. This study sheds light on the potential of Wi-Fi radio waves and RSSI values as a means of user authentication and the power of ML to identify patterns in wireless signals for security purposes. The proposed system holds great promise in revolutionizing the field of 2FA and user authentication, offering a new era of secure and seamless access to sensitive information.",
    "published_date": "2023-03-04",
    "pdf_link": "https://arxiv.org/pdf/2303.02503v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Identity and Access Management",
      "subdomain": "Multi-factor Authentication",
      "specific_problem": "Zero-effort two-factor authentication using Wi-Fi beacon frame characteristics and RSSI with ML-based location verification",
      "attack_types": [
        "Impersonation/Spoofing",
        "Unauthorized Access"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": "Applied to classify 'authentic' vs 'unauthorized' based on Wi-Fi SSID, frequency, and RSSI for 0E2FA."
      },
      {
        "type": "primary",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": "Applied to classify 'authentic' vs 'unauthorized' based on Wi-Fi SSID, frequency, and RSSI for 0E2FA."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Wi-Fi RSSI and Beacon Frames for 0E2FA (per [21], IEEEDataPort)",
        "type": "public",
        "domain": "wireless_signals",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Sensitivity (Recall)",
      "Specificity",
      "Precision",
      "F1 Score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can ML on Wi-Fi beacon frame characteristics (SSID, BSSID/frequency) and RSSI reliably authenticate a user via location as a zero-effort second factor?",
        "What is the classification performance (accuracy, sensitivity, specificity, precision, F1) of tree-based models for distinguishing 'authentic' vs 'unauthorized' contexts based on Wi-Fi signals?"
      ],
      "gaps_identified": [
        "Traditional 2FA can be inconvenient, especially on-the-go; there is a need for zero-effort 2FA leveraging environmental features.",
        "Prior 2FA schemes across IoT, healthcare, VANETs, mobile apps still need improvement: “However, more research and development is needed to improve the security and effectiveness of these protocols.”"
      ],
      "limitations": [
        "Evaluation limited to a prototype with two Raspberry Pi devices and a central server; not deployed in real-world organizational environments.",
        "Dataset derived from limited environments and a fixed threshold distance (7 feet vs 7.5 feet) which may not generalize across settings.",
        "Uses only basic features (SSID, frequency, RSSI); does not leverage richer channel features (e.g., CSI) or temporal dynamics.",
        "No analysis of adversarial threats such as signal spoofing, replay, or environmental manipulation.",
        "No discussion of user privacy implications of continuous Wi-Fi environment fingerprinting."
      ],
      "future_work": [
        "“This study can be extended to consider more features or use more sophisticated models that might improve the performance of the proposed system.”",
        "“Future work may also include testing the proposed system in real-world scenarios and evaluating the performance.”"
      ],
      "motivation": "Increase security and usability by providing a zero-effort two-factor authentication method that leverages the user’s environment via Wi‑Fi radio waves and ML without requiring additional hardware or user interaction.",
      "potential_research_ideas": [
        "Incorporate Channel State Information (CSI) and temporal signal dynamics to create robust location fingerprints beyond RSSI.",
        "Develop defenses and evaluation protocols against adversarial signal spoofing, AP MAC cloning, replay, and environmental manipulation.",
        "Cross-device and cross-site generalization using domain adaptation and calibration-free techniques for heterogeneous hardware and environments.",
        "Multi-sensor fusion (Bluetooth, ultra-wideband, inertial sensors) to improve robustness and reduce false accepts/denies.",
        "Privacy-preserving training and inference (e.g., federated learning, differential privacy) for environment fingerprints.",
        "Online learning to adapt to environmental drift (new/removed APs, layout changes) with concept drift detection.",
        "Confidence scoring and risk-based policies (e.g., step-up authentication when low confidence).",
        "Benchmarking dataset and standardized evaluation suite for zero-effort MFA using wireless signals."
      ],
      "architectural_improvement_recommendations": [
        "Augment features with CSI, channel variance, AP density, and temporal sequences; use sequence models (Temporal CNNs/RNNs/Transformers).",
        "Use robust ensemble methods combining tree models with one-class anomaly detection to handle unseen environments.",
        "Calibrate and normalize RSSI across devices; apply domain adaptation to mitigate hardware heterogeneity.",
        "Adversarial training and signal-level anomaly detection (e.g., PHY fingerprints) to resist spoofing.",
        "Introduce a confidence-aware decision layer with fallback to traditional MFA when uncertainty is high.",
        "Implement privacy-preserving training (federated learning) and apply differential privacy to stored fingerprints."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Prototype server: desktop running Ubuntu 16.04 LTS (64-bit) hosting ML module and database (phpMyAdmin). Data collection with two Raspberry Pi devices. No specific GPU or training time reported; models are lightweight (DT, RF)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Prototype with two Wi‑Fi devices (mobile + login) and a central server; intended for enterprise, healthcare, and retail environments.",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "RSSI variability due to multipath, interference, and environmental changes.",
        "Device heterogeneity and calibration differences affecting RSSI readings.",
        "AP churn (added/removed APs) potentially invalidating stored fingerprints.",
        "Potential for Wi‑Fi signal spoofing or replay to subvert location verification.",
        "Privacy concerns with continuous collection of environmental Wi‑Fi fingerprints.",
        "User requirement of two Wi‑Fi-enabled devices and background app.",
        "Choice and tuning of distance thresholds; gray areas near threshold."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a novel zero-effort two-factor authentication system leveraging Wi‑Fi beacon frame characteristics and RSSI with ML-based analysis.",
      "Implements a working prototype using two Raspberry Pi devices and a central server.",
      "Collects and releases a labeled dataset (available on IEEEDataPort [21]) with 4,825 samples across ‘authentic’ and ‘unauthorized’ contexts and six columns (RPi, SSID, Frequency (Hz), RSSI (dBm), Location, Label).",
      "Demonstrates feasibility with supervised learning (Decision Tree and Random Forest) achieving approximately 0.92 accuracy and F1≈0.926–0.927: “DT: Accuracy 0.924, F1 0.926; RF: Accuracy 0.922, F1 0.927.”",
      "Shows potential applicability across finance, healthcare, and retail for seamless, zero-effort MFA."
    ]
  },
  {
    "arxiv_id": "2304.01166v1",
    "title": "Effective Feature Extraction for Intrusion Detection System using Non-negative Matrix Factorization and Univariate analysis",
    "authors": "Swapnil Mane; Vaibhav Khatavkar; Niranjan Gijare; Pranav Bhendawade",
    "abstract": "An Intrusion detection system (IDS) is essential for avoiding malicious activity. Mostly, IDS will be improved by machine learning approaches, but the model efficiency is degrading because of more headers (or features) present in the packet (each record). The proposed model extracts practical features using Non-negative matrix factorization and chi-square analysis. The more number of features increases the exponential time and risk of overfitting the model. Using both techniques, the proposed model makes a hierarchical approach that will reduce the features quadratic error and noise. The proposed model is implemented on three publicly available datasets, which gives significant improvement. According to recent research, the proposed model has improved performance by 4.66% and 0.39% with respective NSL-KDD and CICD 2017.",
    "published_date": "2023-04-03",
    "pdf_link": "https://arxiv.org/pdf/2304.01166v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Feature extraction/dimensionality reduction to improve IDS classification accuracy and reduce overfitting/time",
      "attack_types": [
        "Brute Force (CICIDS-2017 Web Attacks)",
        "XSS (CICIDS-2017 Web Attacks)",
        "SQL Injection (CICIDS-2017 Web Attacks)",
        "ipsweep (NSL-KDD)",
        "smurf (NSL-KDD)",
        "teardrop (NSL-KDD)",
        "pod (NSL-KDD)",
        "buffer overflow (NSL-KDD)",
        "land (NSL-KDD)",
        "rootkit (NSL-KDD)",
        "multihop (NSL-KDD)",
        "phf (NSL-KDD)",
        "spy (NSL-KDD)",
        "warezmaster (NSL-KDD)",
        "ftp write (NSL-KDD)",
        "neptune (NSL-KDD)",
        "satan (NSL-KDD)",
        "warezclient (NSL-KDD)",
        "guess passwd (NSL-KDD)",
        "port sweep (NSL-KDD)",
        "nmap (NSL-KDD)",
        "imap (NSL-KDD)",
        "back (NSL-KDD)",
        "loadmodule (NSL-KDD)",
        "perl (NSL-KDD)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Matrix Factorization",
        "specific": "Non-negative Matrix Factorization (NMF)",
        "novel_contribution": "Used to compress original IDS feature space into U components prior to supervised selection in a hierarchical pipeline"
      },
      {
        "type": "primary",
        "category": "Feature Selection",
        "specific": "Univariate chi-square (SelectKBest)",
        "novel_contribution": "Applied after NMF to select top-V high-scoring features, forming the final compact feature set"
      },
      {
        "type": "primary",
        "category": "Feature Engineering/Transformation",
        "specific": "TF-IDF transformation",
        "novel_contribution": "Applied to numeric feature values prior to NMF and chi-square to normalize value importance across records"
      },
      {
        "type": "baseline",
        "category": "Probabilistic Classifier",
        "specific": "Naive Bayes",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Model",
        "specific": "Linear Regression (as reported)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Support Vector Machine",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Instance-based",
        "specific": "K Nearest Neighbors (KNN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "CART (unspecified)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble - Bagging",
        "specific": "Random Forest",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Military Network Environment (Kaggle)",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.kaggle.com/sampadab17/network-intrusion-detection",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS-2017 (Web Attack subset, Thursday morning)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD (KDDTrain+_20Percent)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Recent research on NSL-KDD (aggregate)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "\"the proposed model has achieved 4.66%\" improvement on NSL-KDD",
        "baseline_result": null
      },
      {
        "method_name": "Recent research on CICIDS-2017 (aggregate)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "\"the proposed model has achieved ... 0.39%\" improvement on CICIDS-2017",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "High-dimensional IDS feature sets degrade model efficiency and increase risk of overfitting",
        "More features increase training time (described as exponential) and noise",
        "Need for effective, practical feature extraction combining multiple techniques for IDS",
        "Limited prior work (as noted) on the specific Kaggle military network dataset"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Reduce dimensionality and noise in IDS features to improve accuracy and reduce training time by combining NMF with univariate chi-square in a hierarchical feature extraction pipeline.",
      "potential_research_ideas": [
        "Evaluate the pipeline on full CICIDS-2017 (all attack types) and other modern datasets (UNSW-NB15, BoT-IoT) with standardized splits",
        "Replace/augment TF-IDF with numeric-suitable scaling (e.g., Quantile, RobustScaler) and study impact vs TF-IDF",
        "Incorporate embedded feature selection (e.g., L1-regularized linear models, tree-based importance) in a stacked/ensemble selection with NMF+chi2",
        "Develop a non-negative autoencoder (NNAE) to learn non-negative latent features and compare to NMF in the same pipeline",
        "Integrate drift detection and adaptive feature selection over time for streaming IDS",
        "Assess resilience to adversarially perturbed features and design robust feature selection criteria (e.g., stability selection)"
      ],
      "architectural_improvement_recommendations": [
        "Tune NMF initialization and rank selection (U) via nested cross-validation; compare SVD-based vs random init per [3]",
        "Use pipeline primitives with proper scaling for numeric features (StandardScaler/MinMaxScaler) instead of TF-IDF; evaluate mutual information vs chi-square for mixed types",
        "Adopt model-based feature selection (L1-LR/Lasso, tree-based) after NMF and compare with chi-square",
        "Add PCA/ICA baselines and compare reconstruction error and classifier accuracy to quantify benefits of non-negativity",
        "Report comprehensive metrics (precision/recall/F1, ROC-AUC, FAR/DR) and per-class results for imbalanced subsets (e.g., SQLi=21 samples)",
        "Implement stratified cross-validation and fixed random seeds; publish code and exact hyperparameters for reproducibility"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "scikit-learn",
        "pandas",
        "NumPy",
        "seaborn"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High-dimensional feature spaces increase training time and risk of overfitting; requires dimensionality reduction prior to deployment"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a hierarchical feature extraction pipeline combining Non-negative Matrix Factorization (NMF) and univariate chi-square selection for IDS",
      "Applies preprocessing with simple imputer, label encoding, and TF-IDF transformation prior to feature extraction",
      "Demonstrates increased accuracy on three publicly available datasets; shows correlation matrices before/after feature extraction",
      "Reports improvements over recent research: \"4.66%\" (NSL-KDD) and \"0.39%\" (CICIDS-2017 Web Attack subset)"
    ]
  },
  {
    "arxiv_id": "2302.12415v3",
    "title": "Harnessing the Speed and Accuracy of Machine Learning to Advance Cybersecurity",
    "authors": "Khatoon Mohammed",
    "abstract": "As cyber attacks continue to increase in frequency and sophistication, detecting malware has become a critical task for maintaining the security of computer systems. Traditional signature-based methods of malware detection have limitations in detecting complex and evolving threats. In recent years, machine learning (ML) has emerged as a promising solution to detect malware effectively. ML algorithms are capable of analyzing large datasets and identifying patterns that are difficult for humans to identify. This paper presents a comprehensive review of the state-of-the-art ML techniques used in malware detection, including supervised and unsupervised learning, deep learning, and reinforcement learning. We also examine the challenges and limitations of ML-based malware detection, such as the potential for adversarial attacks and the need for large amounts of labeled data. Furthermore, we discuss future directions in ML-based malware detection, including the integration of multiple ML algorithms and the use of explainable AI techniques to enhance the interpret ability of ML-based detection systems. Our research highlights the potential of ML-based techniques to improve the speed and accuracy of malware detection, and contribute to enhancing cybersecurity",
    "published_date": "2023-02-24",
    "pdf_link": "https://arxiv.org/pdf/2302.12415v3",
    "paper_types": [
      "position",
      "survey"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection",
      "specific_problem": "Survey of ML-based malware detection techniques; discussion of challenges (e.g., adversarial attacks, labeled data scarcity) and future directions (multi-model integration, explainable AI).",
      "attack_types": [
        "adversarial evasion",
        "data poisoning",
        "backdoor/trojan",
        "zero-day exploitation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT",
        "novel_contribution": "Applied as the task and attribute classifier in a controlled adversarial text generation setup; extension of CAT.Gen to IMDB with grammatical validation and efficiency improvements."
      },
      {
        "type": "primary",
        "category": "Encoder-Decoder",
        "specific": null,
        "novel_contribution": "Encoder-decoder with attribute classifier for controllable adversarial text generation targeting sentiment; includes grammatical validation and attribute manipulation."
      },
      {
        "type": "primary",
        "category": "Adversarial Training/Optimization",
        "specific": "Projected Gradient Descent (PGD) inner ascent",
        "novel_contribution": "Use of PGD inner ascent to efficiently generate large batches of adversarial examples at scale."
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM (RNN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GAN",
        "specific": "Natural-GAN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "VAE",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Encoder-Decoder",
        "specific": "SCPN (Syntactically Controlled Paraphrase Network)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Adversarial Attack",
        "specific": "TextFooler (Jin et al., 2020)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Adversarial Attack",
        "specific": "Alzantot et al. (2018) Genetic Attack / NL-adv",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Adversarial Training",
        "specific": "FreeLB",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Reinforcement Learning",
      "Adversarial Training"
    ],
    "datasets": [
      {
        "name": "IMDB (gong2018adversarial)",
        "type": "public",
        "domain": "text_reviews",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Amazon Reviews",
        "type": "public",
        "domain": "text_reviews",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Yelp Polarity",
        "type": "public",
        "domain": "text_reviews",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SNLI (Stanford Natural Language Inference)",
        "type": "public",
        "domain": "natural_language_inference",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "TextFooler (Jin et al., 2020)",
        "paper_reference": "Jin et al., 2020",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Alzantot et al. (2018) synonym-based attack (a.k.a. NL-adv)",
        "paper_reference": "Alzantot et al., 2018",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Natural-GAN",
        "paper_reference": "Zhao et al., 2018",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Transferability"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What are state-of-the-art ML techniques used for malware detection?",
        "What challenges and limitations affect ML-based malware detection (e.g., adversarial attacks, large labeled data requirements)?",
        "What future directions can enhance ML-based malware detection (e.g., integrating multiple ML algorithms, explainable AI)?"
      ],
      "gaps_identified": [
        "Public cybersecurity datasets often lack diversity or realism and may not reflect real-world threats.",
        "ML-based detectors can be fooled by adversarial attacks, undermining reliability.",
        "Need for large amounts of labeled data for effective training.",
        "Temporal distribution shifts are often not considered in model design/evaluation."
      ],
      "limitations": [
        "Training instability when using Gumbel-Softmax for soft embeddings; tendency to replicate input sentences.",
        "Computational burden when training large batches of adversarial samples, especially on large datasets (e.g., Yelp Polarity).",
        "Scope limitations in prior work (e.g., CAT.Gen limited to Amazon Reviews and RNN).",
        "No quantitative results reported in the provided text for the proposed adversarial generation approach."
      ],
      "future_work": [
        "Integrate multiple ML algorithms to improve malware detection performance.",
        "Adopt explainable AI techniques to improve interpretability and identify vulnerabilities.",
        "Address adversarial robustness via adversarial training and robust optimization.",
        "Account for temporal shifts and non-stationarity in real-world deployments."
      ],
      "motivation": "Signature-based malware detection struggles with complex, evolving threats; ML can analyze large datasets and learn patterns to improve speed and accuracy of detection, but faces challenges such as adversarial attacks and data scarcity.",
      "potential_research_ideas": [
        "Design a realistic, diverse benchmark suite for ML-based malware detection with evolving, temporally split data and adversarial scenarios.",
        "Develop explainable malware detectors that provide actionable rationales and highlight features driving alerts, integrated with analyst feedback loops.",
        "Apply certified robustness techniques (e.g., interval bound propagation, randomized smoothing) to static/dynamic malware detectors.",
        "Leverage self-supervised or weakly supervised learning on large unlabeled malware corpora to reduce labeled data needs.",
        "Create multi-modal malware detection models combining static, dynamic, and behavioral telemetry with cross-view consistency training.",
        "Adversarial example generation tailored to malware domains (e.g., PE feature-space constrained attacks) to harden detectors."
      ],
      "architectural_improvement_recommendations": [
        "For the controlled adversarial text generator: replace single-layer MLP projector with a lightweight transformer or deeper MLP with spectral normalization for stability.",
        "Use constrained decoding with grammar and semantic consistency constraints (e.g., masked LM guidance) instead of post-hoc grammatical validation.",
        "Adopt curriculum adversarial training (mix of FreeLB/PGD strengths) with temperature scheduling to mitigate Gumbel-Softmax instability.",
        "Introduce temporal validation splits and concept drift detectors in evaluation for security datasets.",
        "For malware detection surveys: propose a standardized evaluation protocol with attack-aware metrics (ASR under constraints, robust accuracy, compute cost)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Not specified; mentions substantial compute and computational burden for large-scale adversarial sample training; PGD inner ascent used to improve efficiency."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Need for large amounts of labeled data for training.",
        "Susceptibility to adversarial attacks that can induce misclassification.",
        "Public datasets may lack diversity and realism, causing dataset shift in production.",
        "Computational burden for large-scale adversarial training and robustness evaluation.",
        "Temporal non-stationarity and concept drift not adequately addressed."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comprehensive review of ML techniques for malware detection (supervised, unsupervised, deep, reinforcement learning).",
      "Analysis of challenges and limitations of ML-based malware detection, including adversarial attacks and labeled data needs.",
      "Discussion of future directions such as integrating multiple ML algorithms and employing explainable AI.",
      "Method-oriented section proposing enhancements to controlled adversarial text generation: application to IMDB with transformer-based classifier, grammatical validation, and PGD-based efficiency improvements; notes on stabilizing training (temperature tuning, dropout, small projector)."
    ]
  },
  {
    "arxiv_id": "2304.01440v1",
    "title": "A Deep Multi-Modal Cyber-Attack Detection in Industrial Control Systems",
    "authors": "Sepideh Bahadoripour; Ethan MacDonald; Hadis Karimipour",
    "abstract": "The growing number of cyber-attacks against Industrial Control Systems (ICS) in recent years has elevated security concerns due to the potential catastrophic impact. Considering the complex nature of ICS, detecting a cyber-attack in them is extremely challenging and requires advanced methods that can harness multiple data modalities. This research utilizes network and sensor modality data from ICS processed with a deep multi-modal cyber-attack detection model for ICS. Results using the Secure Water Treatment (SWaT) system show that the proposed model can outperform existing single modality models and recent works in the literature by achieving 0.99 precision, 0.98 recall, and 0.98 f-measure, which shows the effectiveness of using both modalities in a combined model for detecting cyber-attacks.",
    "published_date": "2023-04-04",
    "pdf_link": "https://arxiv.org/pdf/2304.01440v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Industrial Control Systems Security",
      "subdomain": "Intrusion/Attack Detection",
      "specific_problem": "Multi-modal cyber-attack detection in ICS using combined sensor and network modalities (binary classification)",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN (LSTM)",
        "specific": "Stacked LSTM (3 layers) for network modality",
        "novel_contribution": "Learns temporal representation of network packet sequences per sensor timestamp; last LSTM output used as network representation for fusion"
      },
      {
        "type": "primary",
        "category": "Fully Connected DNN (MLP)",
        "specific": "4-layer ReLU DNN for sensor modality",
        "novel_contribution": "Maps 51-dimensional sensor/actuator features to a latent space for fusion"
      },
      {
        "type": "primary",
        "category": "Fusion Network",
        "specific": "2-layer fully connected ReLU fusion",
        "novel_contribution": "Joint representation learning from sensor and network latent spaces with a single end-to-end training"
      },
      {
        "type": "baseline",
        "category": "Fully Connected DNN (MLP)",
        "specific": "Sensor-only model (ablation)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN (LSTM)",
        "specific": "Network-only stacked LSTM (ablation)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "1D CNN (Kravchik & Shabtai [29])",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoencoder",
        "specific": "Undercomplete AE (Kravchik & Shabtai [29])",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Rule-based/Pattern Mining",
        "specific": "Logical Analysis of Data (LAD-ADS) [16]",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Secure Water Treatment (SWaT) dataset [30]",
        "type": "",
        "domain": "sensor_timeseries + network_traffic (ICS water treatment)",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Water storage system dataset (Zolanvari et al. [2])",
        "type": "",
        "domain": "ICS (water storage) - unspecified features",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Three smart grid datasets (Sakhnini et al. [15])",
        "type": "",
        "domain": "smart_grid",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "ICS sensor dataset (LAD-ADS) [16]",
        "type": "",
        "domain": "ICS sensor_timeseries",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Three smart grid datasets (SAE-based model) [17]",
        "type": "",
        "domain": "smart_grid",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Multiple ICS datasets (GSA-based clustering) [18]",
        "type": "",
        "domain": "ICS (unspecified)",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Large-scale smart grid dataset [22]",
        "type": "",
        "domain": "smart_grid",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Two ICS datasets (deep representation learning for imbalance) [24]",
        "type": "",
        "domain": "ICS (unspecified)",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Gas pipeline dataset (raw network traffic) [25]",
        "type": "",
        "domain": "network_traffic (ICS gas pipeline)",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Four power system datasets [26]",
        "type": "",
        "domain": "power_system (unspecified)",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [
      {
        "method_name": "Sensor-only DNN (ablation)",
        "paper_reference": null,
        "metric": "precision",
        "their_result": "0.99",
        "baseline_result": "0.98"
      },
      {
        "method_name": "Sensor-only DNN (ablation)",
        "paper_reference": null,
        "metric": "recall",
        "their_result": "0.98",
        "baseline_result": "0.68"
      },
      {
        "method_name": "Sensor-only DNN (ablation)",
        "paper_reference": null,
        "metric": "f1_score",
        "their_result": "0.98",
        "baseline_result": "0.80"
      },
      {
        "method_name": "Network-only stacked LSTM (ablation)",
        "paper_reference": null,
        "metric": "precision",
        "their_result": "0.99",
        "baseline_result": "0.95"
      },
      {
        "method_name": "Network-only stacked LSTM (ablation)",
        "paper_reference": null,
        "metric": "recall",
        "their_result": "0.98",
        "baseline_result": "0.63"
      },
      {
        "method_name": "Network-only stacked LSTM (ablation)",
        "paper_reference": null,
        "metric": "f1_score",
        "their_result": "0.98",
        "baseline_result": "0.75"
      },
      {
        "method_name": "LAD-ADS",
        "paper_reference": "[16]",
        "metric": "precision",
        "their_result": "0.99",
        "baseline_result": "0.94"
      },
      {
        "method_name": "LAD-ADS",
        "paper_reference": "[16]",
        "metric": "recall",
        "their_result": "0.98",
        "baseline_result": "0.89"
      },
      {
        "method_name": "LAD-ADS",
        "paper_reference": "[16]",
        "metric": "f1_score",
        "their_result": "0.98",
        "baseline_result": "0.91"
      },
      {
        "method_name": "1D CNN (Kravchik & Shabtai)",
        "paper_reference": "[29]",
        "metric": "precision",
        "their_result": "0.99",
        "baseline_result": "0.90"
      },
      {
        "method_name": "1D CNN (Kravchik & Shabtai)",
        "paper_reference": "[29]",
        "metric": "recall",
        "their_result": "0.98",
        "baseline_result": "0.87"
      },
      {
        "method_name": "1D CNN (Kravchik & Shabtai)",
        "paper_reference": "[29]",
        "metric": "f1_score",
        "their_result": "0.98",
        "baseline_result": "0.88"
      },
      {
        "method_name": "Undercomplete Autoencoder (Kravchik & Shabtai)",
        "paper_reference": "[29]",
        "metric": "precision",
        "their_result": "0.99",
        "baseline_result": "0.96"
      },
      {
        "method_name": "Undercomplete Autoencoder (Kravchik & Shabtai)",
        "paper_reference": "[29]",
        "metric": "recall",
        "their_result": "0.98",
        "baseline_result": "0.93"
      },
      {
        "method_name": "Undercomplete Autoencoder (Kravchik & Shabtai)",
        "paper_reference": "[29]",
        "metric": "f1_score",
        "their_result": "0.98",
        "baseline_result": "0.94"
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall",
      "f1_score",
      "confusion_matrix"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Existing ML-based ICS attack detection methods do not consider multi-modality (sensor and network) jointly",
        "Conventional ML methods are sensitive to imbalanced ICS data, leading to poor recall"
      ],
      "limitations": [
        "Need to synchronize sensor and network datasets before training; time-consuming and the main limitation",
        "Highly imbalanced dataset; single-modality models suffered low recall"
      ],
      "future_work": [],
      "motivation": "Rising ICS cyber-attacks with potentially catastrophic impact; ICS differ from IT systems and require advanced methods capable of harnessing multiple data modalities for effective detection.",
      "potential_research_ideas": [
        "Attention-based multimodal fusion (e.g., cross-attention or transformers) to better align sensor and network streams",
        "Self-supervised or contrastive pretraining on each modality to reduce labeled data dependence",
        "Online/streaming multimodal detection with concept drift adaptation for ICS",
        "Domain adaptation across plants/datasets (e.g., SWaT to other ICS) to improve generalization",
        "Causal or physics-informed modeling to incorporate process constraints into detection",
        "Anomaly segmentation at event/attack-stage level rather than sample-level binary labels",
        "Active learning to efficiently label rare attack samples in imbalanced regimes",
        "Multitask learning to jointly detect and localize attack sources/components",
        "Federated or split learning multimodal architectures for privacy-preserving training across sites",
        "Robustness evaluation and defenses against adversarial manipulation of either modality"
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment LSTM with temporal convolutional networks or transformer encoders for network packet sequences",
        "Cross-attention fusion between sensor and network latent sequences to handle misalignment and highlight relevant interactions",
        "Learned temporal alignment (e.g., differentiable dynamic time warping) prior to fusion to reduce manual synchronization overhead",
        "Multi-scale feature extraction (dilated temporal convs) for both modalities",
        "Cost-sensitive training or focal loss to further mitigate class imbalance",
        "Calibrated decision thresholds or post-hoc probability calibration to control false alarms",
        "Ensemble late-fusion of modality-specific detectors with gating network",
        "Uncertainty estimation (e.g., MC dropout) to flag low-confidence predictions for operator review",
        "Lightweight deployment via knowledge distillation to real-time ICS constraints",
        "Protocol-aware feature augmentation for ICS network traffic (e.g., Modbus/DNP3 semantics)"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Synchronizing sensor and network modalities before training/inference is time-consuming",
        "Handling severe class imbalance without sacrificing recall or causing false alarms",
        "Increased system complexity from multimodal pipelines in ICS operational constraints"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a deep multimodal ICS cyber-attack detection model combining a 4-layer sensor DNN and a 3-layer stacked LSTM for network data with a 2-layer fusion network",
      "End-to-end training to learn joint abstract representations from sensor and network modalities",
      "Empirical evaluation on the SWaT dataset (449,920 samples; 87.9% normal, 12.1% attack) with imputation and min-max normalization",
      "Achieves 0.99 precision, 0.98 recall, and 0.98 f-measure; reports confusion matrix with ~0.1% false alarms and 2.3% evaded attacks",
      "Outperforms single-modality ablations and prior works (LAD-ADS, CNN, AE) on precision, recall, and F1",
      "Discusses main limitation: time-consuming synchronization of multimodal data prior to training"
    ]
  },
  {
    "arxiv_id": "2303.04477v1",
    "title": "Graph Neural Networks Enhanced Smart Contract Vulnerability Detection of Educational Blockchain",
    "authors": "Zhifeng Wang; Wanxuan Wu; Chunyan Zeng; Jialong Yao; Yang Yang; Hongmin Xu",
    "abstract": "With the development of blockchain technology, more and more attention has been paid to the intersection of blockchain and education, and various educational evaluation systems and E-learning systems are developed based on blockchain technology. Among them, Ethereum smart contract is favored by developers for its ``event-triggered\" mechanism for building education intelligent trading systems and intelligent learning platforms. However, due to the immutability of blockchain, published smart contracts cannot be modified, so problematic contracts cannot be fixed by modifying the code in the educational blockchain. In recent years, security incidents due to smart contract vulnerabilities have caused huge property losses, so the detection of smart contract vulnerabilities in educational blockchain has become a great challenge. To solve this problem, this paper proposes a graph neural network (GNN) based vulnerability detection for smart contracts in educational blockchains. Firstly, the bytecodes are decompiled to get the opcode. Secondly, the basic blocks are divided, and the edges between the basic blocks according to the opcode execution logic are added. Then, the control flow graphs (CFG) are built. Finally, we designed a GNN-based model for vulnerability detection. The experimental results show that the proposed method is effective for the vulnerability detection of smart contracts. Compared with the traditional approaches, it can get good results with fewer layers of the GCN model, which shows that the contract bytecode and GCN model are efficient in vulnerability detection.",
    "published_date": "2023-03-08",
    "pdf_link": "https://arxiv.org/pdf/2303.04477v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Security",
      "specific_problem": "Detecting timestamp-dependence vulnerability in Ethereum smart contracts from EVM bytecode using CFG + GNN",
      "attack_types": [
        "timestamp dependency"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "GCN (Graph Convolutional Network)",
        "novel_contribution": "Constructs CFGs from EVM bytecode with both jump and sequential edges; uses identity node features (no semantic operands) and tests shallow 1–4 layer GCNs for binary vulnerability detection."
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "GRU-based RNN (referenced prior work)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM (referenced prior work)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Unspecified public smart contract source code dataset",
        "type": "public",
        "domain": "smart_contract_source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Compiled EVM bytecode dataset with CFGs (1420 contracts; 472 timestamp-dependent)",
        "type": "proprietary",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Oyente (symbolic execution tool)",
        "paper_reference": "Oyente [13]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "ContractFuzzer (fuzzing-based tool)",
        "paper_reference": "ContractFuzzer [14]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "GRU-based RNN for opcode sequences",
        "paper_reference": "[16]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "LSTM-based opcode sequence classifier",
        "paper_reference": "[18]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Recall",
      "Precision",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a GCN over CFGs derived from EVM bytecode effectively detect timestamp-dependence vulnerabilities in smart contracts?",
        "How does the number of GCN layers (1–4) affect detection performance (Accuracy, Recall, Precision, F1-score)?"
      ],
      "gaps_identified": [
        "Existing non-deep-learning tools (symbolic execution, fuzzing) may miss vulnerabilities or be inefficient.",
        "Sequence models (RNN/LSTM) ignore graph-structured control-flow information in smart contracts.",
        "Public datasets are largely source code; bytecode-level datasets suited for CFG/GNN are scarce.",
        "Compiler version incompatibility complicates reproducible dataset construction from source code."
      ],
      "limitations": [
        "Only timestamp-dependency vulnerability is labeled and evaluated (binary classification).",
        "Node features use an identity matrix; no semantic processing of operands/opcodes.",
        "Edge types are not differentiated (jump vs sequential edges are both present but not encoded as types/weights).",
        "No quantitative comparison against established tools or prior deep models is reported.",
        "Dataset details (source, link) and release are not provided."
      ],
      "future_work": [
        "Add semantic processing of operands/opcodes to improve accuracy.",
        "Classify/encode edges (e.g., jump vs sequential) to improve performance."
      ],
      "motivation": "Smart contract vulnerabilities in educational blockchain systems can cause large losses and cannot be patched post-deployment due to blockchain immutability; efficient automatic detection at bytecode level is needed.",
      "potential_research_ideas": [
        "Multi-label/multi-class detection covering multiple vulnerability types (reentrancy, overflow, tx-origin, etc.) from bytecode CFGs.",
        "Joint control-flow and data-flow graph modeling (heterogeneous graphs) for richer program semantics.",
        "Pretrained opcode/bytecode embeddings via self-supervised learning on large corpora of contracts to initialize node features.",
        "Neural-symbolic hybrids that integrate lightweight symbolic execution features with GNN representations.",
        "Contract-level interpretability: subgraph attribution highlighting vulnerable paths and instructions.",
        "Domain adaptation from general Ethereum contracts to educational-blockchain-specific contracts.",
        "Robustness evaluation under compiler/version changes and obfuscation, with augmentation strategies."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment GCN with edge-aware GNNs (e.g., R-GCN, Edge-Conditioned Convolution) to encode edge types and directions.",
        "Use Graph Attention Networks (GAT) or gated GNNs (GGNN) to better capture long-range control dependencies.",
        "Augment node features with opcode embeddings, operand constants, basic-block statistics, and positional encodings.",
        "Incorporate graph pooling/readout mechanisms (e.g., DiffPool, SAGPool) for contract-level representation learning.",
        "Adopt multi-task learning to jointly predict multiple vulnerability labels and auxiliary tasks (e.g., opcode n-gram prediction).",
        "Leverage heterogeneous graphs that include function-level, call-graph, and storage access nodes/edges.",
        "Encode edge directionality and temporal execution order explicitly; consider message-passing unrolled along topological order."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Compiler version compatibility when generating bytecode from public source code.",
        "Bytecode-only analysis may miss high-level semantic cues.",
        "Limited labeled data per vulnerability type; potential class imbalance.",
        "Generalization across compiler versions and optimization settings."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Builds a GCN model that predicts smart contract vulnerabilities on educational blockchain use cases.",
      "Shows that vulnerabilities can be detected effectively using only smart contract bytecode by constructing CFGs as GNN inputs.",
      "\"Compared with the traditional approaches, it can get good results with fewer layers of the GCN model.\"",
      "Provides a bytecode-to-CFG construction that includes both jump and sequential edges and explores 1–4 GCN layers.",
      "Identifies that adding semantic processing or edge classification could increase accuracy."
    ]
  },
  {
    "arxiv_id": "2305.00656v1",
    "title": "File Fragment Classification using Light-Weight Convolutional Neural Networks",
    "authors": "Mustafa Ghaleb; Kunwar Saaim; Muhamad Felemban; Saleh Al-Saleh; Ahmad Al-Mulhem",
    "abstract": "In digital forensics, file fragment classification is an important step toward completing file carving process. There exist several techniques to identify the type of file fragments without relying on meta-data, such as using features like header/footer and N-gram to identify the fragment type. Recently, convolutional neural network (CNN) models have been used to build classification models to achieve this task. However, the number of parameters in CNNs tends to grow exponentially as the number of layers increases. This results in a dramatic increase in training and inference time. In this paper, we propose light-weight file fragment classification models based on depthwise separable CNNs. The evaluation results show that our proposed models provide faster inference time with comparable accuracy as compared to the state-of-art CNN based models. In particular, our models were able to achieve an accuracy of 79\\% on the FFT-75 dataset with nearly 100K parameters and 164M FLOPs, which is 4x smaller and 6x faster than the state-of-the-art classifier in the literature.",
    "published_date": "2023-05-01",
    "pdf_link": "https://arxiv.org/pdf/2305.00656v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Digital Forensics",
      "subdomain": "File Carving",
      "specific_problem": "File fragment classification (content-based, metadata-agnostic)",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Depthwise separable 1D CNN with inception-style parallel branches (DSC)",
        "novel_contribution": "Light-weight architecture for file fragment classification using depthwise separable convolutions and 1D inception blocks to reduce parameters/FLOPs while maintaining accuracy."
      },
      {
        "type": "primary",
        "category": "CNN + Attention",
        "specific": "Depthwise separable 1D CNN with Squeeze-and-Excitation (DSC-SE)",
        "novel_contribution": "Adds SE attention blocks after inception blocks for channel-wise feature recalibration with minimal compute overhead."
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Modified depthwise separable 1D CNN (M-DSC)",
        "novel_contribution": "Replaces initial 1D conv with depthwise conv; swaps Hardswish for ReLU; uses Group Normalization and dropout to reduce memory/compute overhead of BatchNorm and improve regularization."
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "FiFTy (prior CNN-based file fragment classifier)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM (bidirectional + unidirectional)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Transfer Learning"
    ],
    "datasets": [
      {
        "name": "FFT-75 dataset",
        "type": "public",
        "domain": "file_fragments",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "FiFTy",
        "paper_reference": "[33]",
        "metric": "Accuracy (Scenario 1, 75 classes, 4096-byte fragments)",
        "their_result": "79.27% (DSC family)",
        "baseline_result": "77.04%"
      },
      {
        "method_name": "FiFTy",
        "paper_reference": "[33]",
        "metric": "FLOPs (Scenario 1, 4096-byte fragments)",
        "their_result": "164.88 MFLOPs (DSC)",
        "baseline_result": "1047.59 MFLOPs"
      },
      {
        "method_name": "FiFTy",
        "paper_reference": "[33]",
        "metric": "Parameters",
        "their_result": "~100K",
        "baseline_result": ">400K"
      },
      {
        "method_name": "FiFTy",
        "paper_reference": "[33]",
        "metric": "Inference time (GPU)",
        "their_result": "~15x faster than FiFTy",
        "baseline_result": "1x (FiFTy baseline)"
      },
      {
        "method_name": "FiFTy",
        "paper_reference": "[33]",
        "metric": "Inference time (CPU)",
        "their_result": "~5x faster (4096-byte) and ~9x faster (512-byte)",
        "baseline_result": "1x (FiFTy baseline)"
      },
      {
        "method_name": "RNN (LSTM)",
        "paper_reference": "[18]",
        "metric": "Inference time (GPU)",
        "their_result": "~105x faster than LSTM",
        "baseline_result": "1x (RNN baseline)"
      },
      {
        "method_name": "RNN (LSTM)",
        "paper_reference": "[18]",
        "metric": "End-to-end throughput on 1GB data",
        "their_result": "~660x faster (4096-byte); ~87x faster (512-byte)",
        "baseline_result": "1x (RNN baseline)"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "FLOPs",
      "inference time (ms per block / throughput)",
      "parameter count"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can depthwise separable 1D CNNs deliver substantially faster inference with comparable or better accuracy than prior CNN/RNN models for file fragment classification?",
        "Do Squeeze-and-Excitation blocks and normalization/activation changes improve the accuracy-speed-parameter trade-off for this task?",
        "How does fragment size (512 vs. 4096 bytes) affect accuracy and efficiency across models?"
      ],
      "gaps_identified": [
        "Standard CNNs suffer from exponential parameter growth with depth, inflating training and inference time for file fragment classification.",
        "RNNs are slow and encounter vanishing gradients on long byte sequences (4096-byte fragments).",
        "Existing datasets can be highly imbalanced; balanced benchmarks like FFT-75 are needed for fair evaluation.",
        "Need for lightweight models suitable for resource-limited devices used in digital forensics."
      ],
      "limitations": [
        "Convolution kernel sizes were not tuned; the paper reused kernel sizes (11, 19, 27) from prior work (FiFTy).",
        "Evaluation focuses on FFT-75; generalization to other datasets or real-world images was not reported in the excerpt.",
        "No analysis of robustness to adversarial manipulations or obfuscation of file fragments was provided.",
        "No deployment study; inference time reported on lab hardware."
      ],
      "future_work": [],
      "motivation": "Reduce inference latency and resource footprint of file fragment classification to enable efficient digital forensics and operation on resource-limited hardware, without sacrificing accuracy.",
      "potential_research_ideas": [
        "Self-supervised pretraining on large unlabeled binary corpora (contrastive or masked byte modeling) to improve accuracy without additional labels.",
        "Hierarchical multi-task classification (predict both use-group and fine-grained type) to regularize and improve rare-class performance.",
        "Domain adaptation to unseen devices/file systems and to different fragment size distributions.",
        "Hybrid Conv-Transformer or lightweight attention (Performer/Linformer) to capture longer-range byte dependencies while keeping compute low.",
        "Neural architecture search (NAS) for kernel sizes/expansion factors/branch widths tailored to 1D byte data.",
        "Robustness research: training against obfuscation, partial encryption, or high-entropy noise; incorporate entropy/byte-frequency features.",
        "Multi-modal feature fusion (e.g., n-grams/entropy/statistical features + learned CNN embeddings).",
        "Variable-length fragment handling via scale-invariant pooling and dynamic convolution/dilation.",
        "On-device optimization: quantization, pruning, and early-exit mechanisms for strict latency targets."
      ],
      "architectural_improvement_recommendations": [
        "Tune branch kernel sizes and strides with Bayesian optimization or NAS instead of reusing prior values.",
        "Adopt MobileNetV3/EfficientNetV2-style blocks adapted to 1D, including squeeze-and-excitation and h-swish with compound scaling.",
        "Introduce dilated depthwise convolutions and residual connections to extend receptive field without added parameters.",
        "Replace or complement GroupNorm with LayerNorm; benchmark across fragment sizes and batch regimes.",
        "Knowledge distillation from a larger teacher (e.g., FiFTy or Conv-Transformer) to the DSC student for accuracy gains at same size.",
        "Mixed-precision (FP16/BF16) and quantization-aware training for inference speedups on CPU/GPU/edge NPUs.",
        "Channel shuffle or split-attention (e.g., ECA, Coordinate Attention) for improved channel interaction at low cost.",
        "Learned byte embeddings with positional encodings and sub-byte tokenization exploration; compare to fixed 32-dim embedding."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PyTorch",
        "Optuna"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Training/eval on dual Intel Xeon E5-2620 (12C/24T), 192 GB RAM, single Nvidia Titan X GPU; Ubuntu 20.04; PyTorch 1.5.0. Models ~100K params; FLOPs (Scenario 1, 4096B): ~165 MFLOPs (DSC/DSC-SE) and 89 MFLOPs (M-DSC)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "GPU: ~15x faster than FiFTy; ~105x faster than RNN. CPU: ~5x faster (4096B) and ~9x faster (512B) than FiFTy. Throughput on 1GB: FiFTy ~25x slower (4096B); ~8x slower (512B).",
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces three light-weight file fragment classifiers (DSC, DSC-SE, M-DSC) based on depthwise separable 1D CNNs with inception-style branches.",
      "Achieves faster inference with comparable or better accuracy than prior CNN (FiFTy) and dramatically faster than RNN baselines.",
      "Reports 79.27% accuracy on FFT-75 Scenario 1 with ~100K parameters and ~164 MFLOPs, versus FiFTy 77.04% with >400K params and ~1 GFLOP.",
      "Demonstrates large FLOP reductions: ~6.3x fewer (4096-byte fragments) and ~87x fewer (512-byte) than FiFTy.",
      "Shows substantial inference-time speedups: ~15x over FiFTy and ~105x over RNN on GPU; up to ~25x over FiFTy on CPU for 4096-byte fragments.",
      "Explores transfer learning across fragment sizes, observing 6–8% accuracy gains when pretraining on 512-byte data for 4096-byte models."
    ]
  },
  {
    "arxiv_id": "2305.00382v2",
    "title": "Constructing a Knowledge Graph from Textual Descriptions of Software Vulnerabilities in the National Vulnerability Database",
    "authors": "Anders Mølmen Høst; Pierre Lison; Leon Moonen",
    "abstract": "Knowledge graphs have shown promise for several cybersecurity tasks, such as vulnerability assessment and threat analysis. In this work, we present a new method for constructing a vulnerability knowledge graph from information in the National Vulnerability Database (NVD). Our approach combines named entity recognition (NER), relation extraction (RE), and entity prediction using a combination of neural models, heuristic rules, and knowledge graph embeddings. We demonstrate how our method helps to fix missing entities in knowledge graphs used for cybersecurity and evaluate the performance.",
    "published_date": "2023-04-30",
    "pdf_link": "https://arxiv.org/pdf/2305.00382v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Management and Analysis",
      "specific_problem": "Constructing and completing a vulnerability knowledge graph from NVD CVE descriptions to predict missing CWE types and affected products (CPEs)",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "SecBERT (BERT-based)",
        "novel_contribution": "Fine-tuned for NER on NVD CVE descriptions to jointly extract IOB and domain labels"
      },
      {
        "type": "baseline",
        "category": "Linear classifier",
        "specific": "Averaged Perceptron (AP)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Tensor factorization / Knowledge Graph Embedding",
        "specific": "TuckER",
        "novel_contribution": "Applied to vulnerability KG for entity prediction (predicting CWE and CPE) using triples extracted from NVD"
      },
      {
        "type": "primary",
        "category": "Rule-based / Heuristic",
        "specific": "Ontology-guided relation extraction with ordering heuristics",
        "novel_contribution": "Introduces a vulnerability ontology and deterministic rules to derive relations (e.g., vendor–product–version) from text structure"
      },
      {
        "type": "baseline",
        "category": "Weak supervision",
        "specific": "Distant supervision for NER/RE labeling (Bridges et al., 2014)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Weakly-supervised (distant supervision)"
    ],
    "datasets": [
      {
        "name": "National Vulnerability Database (NVD) CVE records (2003–2022)",
        "type": "public",
        "domain": "vulnerability_descriptions (text) with CWE/CPE metadata",
        "link": "https://nvd.nist.gov/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CWE taxonomy (Common Weakness Enumeration)",
        "type": "public",
        "domain": "vulnerability_taxonomy",
        "link": "https://cwe.mitre.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CPE dictionary (Common Platform Enumeration)",
        "type": "public",
        "domain": "software_product_identifiers",
        "link": "https://nvd.nist.gov/products/cpe",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Bridges et al. (2014) cybersecurity corpus with distant supervision labels",
        "type": "public",
        "domain": "cybersecurity_text (for NER/RE labeling)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "CTI-KG labeled triples (~3000 triples) from threat reports (Rastogi et al., 2023)",
        "type": "public",
        "domain": "threat_intelligence_triples",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Averaged Perceptron NER (this paper’s baseline)",
        "paper_reference": "Bridges et al., 2014",
        "metric": "NER overall Precision/Recall/F1 (entity-level)",
        "their_result": "P=0.93, R=0.93, F1=0.93 (SecBERT)",
        "baseline_result": "P=0.925, R=0.84, F1=0.88 (Averaged Perceptron)"
      },
      {
        "method_name": "Bridges et al. (2014) AP IOB labeling (reported) vs this paper reproduction",
        "paper_reference": "Bridges et al., 2014",
        "metric": "IOB labeling F1",
        "their_result": "0.93 (reproduction)",
        "baseline_result": "0.96 (Bridges et al., reported)"
      },
      {
        "method_name": "Bridges et al. (2014) AP domain labeling (reported) vs this paper reproduction",
        "paper_reference": "Bridges et al., 2014",
        "metric": "Domain labeling F1",
        "their_result": "0.94 (reproduction)",
        "baseline_result": "0.99 (Bridges et al., reported)"
      },
      {
        "method_name": "TuckER (entity prediction) vs Rastogi et al. (2023)",
        "paper_reference": "Rastogi et al., 2023",
        "metric": "Hits@10 / Hits@3 / Hits@1 / MRR",
        "their_result": "0.760 / 0.728 / 0.682 / 0.710",
        "baseline_result": "0.804 / 0.759 / 0.739 / 0.750"
      },
      {
        "method_name": "Relation Extraction precision (manual sample)",
        "paper_reference": "Jones et al., 2015 (semi-supervised RE labeling)",
        "metric": "Precision",
        "their_result": "0.77 (manual validation on 100 extracted triples)",
        "baseline_result": "0.82 (reported by Jones et al. after manual validation)"
      }
    ],
    "performance_metrics_used": [
      "Precision",
      "Recall",
      "F1",
      "Hits@10",
      "Hits@3",
      "Hits@1",
      "MRR"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can our knowledge graph predict vulnerability weakness types and vulnerable products?"
      ],
      "gaps_identified": [
        "Knowledge graphs for cybersecurity often have missing or incorrect entities and relations",
        "Limited labeled data for NER/RE in this domain; reliance on distant supervision",
        "Prior KGE models (e.g., TransE) struggle with 1-to-n, n-to-1, and n-to-n relations common in cybersecurity data",
        "Lack of high-precision relation labeling tailored to vulnerability descriptions",
        "Overlap in CWE categories can confuse models during prediction"
      ],
      "limitations": [
        "No ground truth dataset for relation extraction; evaluated precision via manual validation of a small sample (n=100)",
        "Relation extraction precision (0.77) below prior semi-supervised methods (0.82)",
        "Entity prediction includes predicting CVE-IDs, which is unnecessary and may harm metrics",
        "Input labels may be noisy due to distant supervision-generated annotations",
        "Comparisons to TuckER results on different corpora (threat reports) are not strictly apples-to-apples"
      ],
      "future_work": [
        "Better labeling of relations through distant supervision approaches",
        "Integrate BERT-based models for relation extraction",
        "Utilize CPE vectors for relation labeling and then train ML models for RE",
        "Incorporate background knowledge to avoid predicting trivial/known entities (e.g., CVE-IDs)"
      ],
      "motivation": "Enable automated construction and completion of a vulnerability knowledge graph from NVD to support tasks like vulnerability assessment by predicting missing CWE types and affected products.",
      "potential_research_ideas": [
        "Develop a joint NER+RE transformer model (e.g., span-based or sequence-to-graph) fine-tuned on vulnerability texts to replace rule-based RE",
        "Create a distant supervision program for RE using CPE/CWE dictionaries and pattern libraries (e.g., Snorkel labeling functions) to scale high-quality labels",
        "Introduce entity linking and canonicalization for vendor/product/version (CPE) and CWE mapping using lexical and embedding-based matchers",
        "Incorporate literal-aware and text-aware KGE (e.g., KEPLER, DKRL, description encoders) to leverage CVE description text during embedding",
        "Explore alternative KGE models suited for 1-to-N relations (ComplEx, RotatE, BoxE) and ensemble them with TuckER",
        "Add temporal modeling of CVEs/CWEs (dynamic KGE) to capture evolving vulnerability landscapes",
        "Design a classifier to directly predict CWE from text and fuse with KGE outputs (late fusion or joint training)",
        "Leverage LLMs for weak supervision and consistency checking of extracted triples (human-in-the-loop verification)",
        "Construct a benchmark with gold RE annotations for NVD descriptions to enable rigorous evaluation"
      ],
      "architectural_improvement_recommendations": [
        "Replace rule-based RE with supervised transformer-based RE (e.g., BERT/DeBERTa/SpanBERT with CRF or biaffine heads) trained on weakly supervised labels refined by manual audits",
        "Adopt a joint extraction architecture (multi-task NER+RE) to reduce error propagation from NER to RE",
        "Integrate an entity linking module to map extracted vendor/product/version strings to canonical CPE URIs using fuzzy matching + embedding similarity",
        "Introduce background knowledge constraints in KGE (e.g., typed constraints, avoid CVE-ID prediction, relation cardinality priors)",
        "Evaluate and potentially switch/ensemble KGE models (ComplEx/RotatE/BoxE) with advanced negative sampling strategies",
        "Use text-enhanced embeddings: encode CVE descriptions and attach to entities/relations for literal-aware KGE",
        "Employ data programming (Snorkel) for scalable RE labeling using CPE vectors, regexes, and ontology constraints",
        "Add CRF decoding to the NER head for better boundary detection; try domain-specific encoders (SecureBERT) as alternatives to SecBERT"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "NER: SecBERT fine-tuned with batch size 8, learning rate 5e-5; AP limited to 4,000 CVEs due to computational constraints. KGE: TuckER trained for 300 epochs on ~4M triples (including reversed); tuning via grid search; experiments run on eX3 HPC infrastructure."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Label noise from distant supervision can degrade downstream RE/KGE performance",
        "Lack of high-quality RE ground truth hampers validation and tuning",
        "Ambiguity/overlap in CWE categories complicates predictions",
        "Rapidly growing NVD scale requires efficient extraction and embedding updates"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "An end-to-end approach for extracting and assessing vulnerability data from NVD to build a vulnerability knowledge graph",
      "A vulnerability ontology to guide relation extraction and knowledge graph construction",
      "A rule-based relation extraction model for CVE descriptions",
      "Demonstration of missing-entity prediction (CWE, CPE) using TuckER knowledge graph embeddings",
      "Empirical evaluation: NER (SecBERT vs AP), RE (manual precision), and KGE entity prediction metrics"
    ]
  },
  {
    "arxiv_id": "2303.04247v1",
    "title": "Vulnerability Mimicking Mutants",
    "authors": "Aayush Garg; Renzo Degiovanni; Mike Papadakis; Yves Le Traon",
    "abstract": "With the increasing release of powerful language models trained on large code corpus (e.g. CodeBERT was trained on 6.4 million programs), a new family of mutation testing tools has arisen with the promise to generate more \"natural\" mutants in the sense that the mutated code aims at following the implicit rules and coding conventions typically produced by programmers. In this paper, we study to what extent the mutants produced by language models can semantically mimic the observable behavior of security-related vulnerabilities (a.k.a. Vulnerability-mimicking Mutants), so that designing test cases that are failed by these mutants will help in tackling mimicked vulnerabilities. Since analyzing and running mutants is computationally expensive, it is important to prioritize those mutants that are more likely to be vulnerability mimicking prior to any analysis or test execution. Taking this into account, we introduce VMMS, a machine learning based approach that automatically extracts the features from mutants and predicts the ones that mimic vulnerabilities. We conducted our experiments on a dataset of 45 vulnerabilities and found that 16.6% of the mutants fail one or more tests that are failed by 88.9% of the respective vulnerabilities. More precisely, 3.9% of the mutants from the entire mutant set are vulnerability-mimicking mutants that mimic 55.6% of the vulnerabilities. Despite the scarcity, VMMS predicts vulnerability-mimicking mutants with 0.63 MCC, 0.80 Precision, and 0.51 Recall, demonstrating that the features of vulnerability-mimicking mutants can be automatically learned by machine learning models to statically predict these without the need of investing effort in defining such features.",
    "published_date": "2023-03-07",
    "pdf_link": "https://arxiv.org/pdf/2303.04247v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Secure Software Testing",
      "specific_problem": "Predicting and selecting vulnerability-mimicking mutants generated by language-model-based mutation tools",
      "attack_types": [
        "Improper Input Validation (CWE-20)",
        "Permissions, Privileges, and Access Controls (CWE-264/CWE-284/CWE-269)",
        "Loop with Unreachable Exit Condition / Infinite Loop (CWE-835, DoS)",
        "Improper Restriction of XML External Entity Reference (XXE) (CWE-611)",
        "Cross-site Scripting (XSS) (CWE-79)",
        "Improper Neutralization in Output / Injection (CWE-74)",
        "Improper Authentication (CWE-287)",
        "Path Traversal (CWE-22)",
        "OS Command Injection (CWE-78)",
        "Cryptographic Issues (CWE-310)",
        "Insertion of Sensitive Information into Log File (CWE-532)",
        "Deserialization of Untrusted Data (CWE-502)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Encoder-Decoder (Seq2Seq) representation learning",
        "specific": null,
        "novel_contribution": "Learns mutant embeddings automatically from code tokens without manual feature engineering to capture properties of vulnerability-mimicking mutants"
      },
      {
        "type": "primary",
        "category": "Binary Classifier",
        "specific": null,
        "novel_contribution": "Classifies mutants as vulnerability-mimicking or not using learned embeddings; achieves \"0.63 MCC, 0.80 Precision, and 0.51 Recall\""
      },
      {
        "type": "baseline",
        "category": "Language Model",
        "specific": "CodeBERT",
        "novel_contribution": "Used via the ϟBERT mutation tool to generate mutants by masked token prediction; not a predictive baseline but part of data generation"
      }
    ],
    "learning_paradigm": [
      "Unsupervised (representation learning via encoder-decoder)",
      "Supervised (binary classification for vulnerability-mimicking prediction)"
    ],
    "datasets": [
      {
        "name": "Vul4J",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Mutants generated by ϟBERT (CodeBERT-based mutation tool) over 45 Vul4J vulnerabilities",
        "type": "synthetic",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Matthews Correlation Coefficient (MCC)",
      "Precision",
      "Recall"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Are mutation testing tools using pre-trained language models effective at producing mutants that semantically mimic the behaviour of software vulnerabilities?",
        "Can machine learning automatically learn features of vulnerability-mimicking mutants to statically predict them without manual feature definition or dynamic analysis?"
      ],
      "gaps_identified": [
        "Traditional mutation operators are unlikely to exercise security-related aspects of applications.",
        "Designing security-specific mutation operators requires manual analysis of vulnerability classes and does not scale to the extensive set of realistic vulnerability types.",
        "Pattern-based operators may alter program semantics in ways perceived as unrealistic by developers.",
        "Analyzing and running large numbers of mutants is computationally expensive; prioritization is needed.",
        "Many vulnerability datasets lack Proof-of-Vulnerability (PoV) tests necessary to reproduce vulnerabilities (Vul4J is an exception)."
      ],
      "limitations": [
        "A subset of vulnerabilities in Vul4J had to be excluded due to failing tests even after applying provided fixes; final study conducted on 45 vulnerabilities.",
        "Vulnerability-mimicking mutants are scarce in the generated set (3.9% of mutants), posing a class imbalance challenge."
      ],
      "future_work": [
        "Authors suggest vulnerability-mimicking mutants can help in building regression test suites for security-intensive applications.",
        "Authors suggest the approach can be useful in evaluating and comparing fuzzing or other security testing tools."
      ],
      "motivation": "Enable security-conscious mutation testing by identifying a minimal set of mutants that semantically mimic vulnerabilities, thereby guiding test design and reducing the cost of mutant analysis and execution.",
      "potential_research_ideas": [
        "Extend VMMS to multi-language and multi-project settings (e.g., C/C++, Python) and assess cross-language transferability of learned mutant embeddings.",
        "Condition the classifier on vulnerability taxonomy (e.g., CWE-aware VMMS) to improve recall for specific vulnerability classes.",
        "Incorporate program structure (AST/CFG/PDG) via graph neural networks to enrich embeddings with control/data-flow features.",
        "Leverage cost-sensitive learning or focal losses to better handle the heavy class imbalance of vulnerability-mimicking mutants.",
        "Combine static VMMS predictions with lightweight dynamic signals (e.g., mutation impact heuristics) for a hybrid selector with improved precision-recall trade-offs.",
        "Active learning loop where human feedback on borderline mutants refines the classifier over time.",
        "Evaluate robustness of VMMS to changes in mutation generation strategies and across different LM-based mutation tools."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment the encoder-decoder embedding with a pre-trained code model (e.g., CodeBERT/GraphCodeBERT) fine-tuned for mutant representation.",
        "Add graph-based encoders (GGNN/GNN over AST/CFG) fused with token embeddings to capture semantic context.",
        "Use class-imbalance techniques (focal loss, class weighting, hard negative mining) and calibration to improve minority-class recall.",
        "Introduce multi-task learning to jointly predict vulnerability class (CWE) likelihood and mimicry, sharing representations.",
        "Apply contrastive learning to pull embeddings of mimic mutants closer to their corresponding vulnerability contexts."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Computational expense of analyzing and executing large numbers of mutants; need for prioritization.",
        "Scarcity and severe class imbalance of vulnerability-mimicking mutants.",
        "Data quality issues in vulnerability datasets (e.g., PoV tests not always stable), requiring exclusions."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Demonstrates that language-model-based mutation tools can generate mutants that mimic real software vulnerabilities: \"3.6% of the mutants semantically mimic 25 out of 45 studied vulnerabilities\" and overall \"3.9% of the mutants ... mimic 55.6% of the vulnerabilities.\"",
      "Shows that for most vulnerabilities (40/45, 88.9%) there exists at least one mutant failing at least one PoV test.",
      "Introduces VMMS, a machine-learning approach that predicts vulnerability-mimicking mutants statically, achieving \"0.63 MCC, 0.80 Precision, and 0.51 Recall.\""
    ]
  },
  {
    "arxiv_id": "2303.16956v1",
    "title": "FeDiSa: A Semi-asynchronous Federated Learning Framework for Power System Fault and Cyberattack Discrimination",
    "authors": "Muhammad Akbar Husnoo; Adnan Anwar; Haftu Tasew Reda; Nasser Hosseizadeh; Shama Naz Islam; Abdun Naser Mahmood; Robin Doss",
    "abstract": "With growing security and privacy concerns in the Smart Grid domain, intrusion detection on critical energy infrastructure has become a high priority in recent years. To remedy the challenges of privacy preservation and decentralized power zones with strategic data owners, Federated Learning (FL) has contemporarily surfaced as a viable privacy-preserving alternative which enables collaborative training of attack detection models without requiring the sharing of raw data. To address some of the technical challenges associated with conventional synchronous FL, this paper proposes FeDiSa, a novel Semi-asynchronous Federated learning framework for power system faults and cyberattack Discrimination which takes into account communication latency and stragglers. Specifically, we propose a collaborative training of deep auto-encoder by Supervisory Control and Data Acquisition sub-systems which upload their local model updates to a control centre, which then perform a semi-asynchronous model aggregation for a new global model parameters based on a buffer system and a preset cut-off time. Experiments on the proposed framework using publicly available industrial control systems datasets reveal superior attack detection accuracy whilst preserving data confidentiality and minimizing the adverse effects of communication latency and stragglers. Furthermore, we see a 35% improvement in training time, thus validating the robustness of our proposed method.",
    "published_date": "2023-03-28",
    "pdf_link": "https://arxiv.org/pdf/2303.16956v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Industrial Control Systems (ICS) / Smart Grid Security",
      "subdomain": "Intrusion Detection / Anomaly Detection",
      "specific_problem": "Discriminating cyberattacks from natural power system disturbances in distributed power grid zones under communication latency and stragglers using semi-asynchronous federated learning",
      "attack_types": [
        "Remote tripping command injection",
        "Change in IED settings",
        "False data injection (FDI)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "Semi-asynchronous FL with buffer and preset cut-off time; aggregation by clustering updates by time/version (based on [19])",
        "novel_contribution": "Introduces FeDiSa: semi-asynchronous aggregation that starts at a preset cut-off time, buffers late updates for next round, and groups updates by version to mitigate stragglers and latency while handling heterogeneity."
      },
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": "Deep Auto-Encoder (stacked RBMs/Deep Belief Network) with ReLU; softmax classification head; MSE reconstruction error thresholding",
        "novel_contribution": "Applies a representation-learning DAE within semi-asynchronous FL for SG fault vs cyberattack discrimination; threshold chosen at inflection point of reconstruction error distribution."
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "Vanilla RNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Energy-based model",
        "specific": "Restricted Boltzmann Machine (RBM)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Federated Learning",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "MSU-ORNL Power System Attack (PSA) Dataset",
        "type": "public",
        "domain": "ics_power_system_measurements",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CNN",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "92.4%",
        "baseline_result": "89.6%"
      },
      {
        "method_name": "LSTM",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "92.4%",
        "baseline_result": "78.5%"
      },
      {
        "method_name": "RBM",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "92.4%",
        "baseline_result": "73.3%"
      },
      {
        "method_name": "RNN",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "92.4%",
        "baseline_result": "69.3%"
      },
      {
        "method_name": "FedAvg",
        "paper_reference": null,
        "metric": "Training time",
        "their_result": "~35% less than synchronous baselines in presence of stragglers",
        "baseline_result": null
      },
      {
        "method_name": "FedSGD",
        "paper_reference": null,
        "metric": "Training time",
        "their_result": "~35% less than synchronous baselines in presence of stragglers",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-Measure",
      "Training time"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How to design a federated intrusion detection framework for smart grids that remains effective under communication latency and client stragglers?",
        "Can semi-asynchronous aggregation with buffering and cut-off time improve training efficiency and maintain high detection accuracy under heterogeneity?",
        "Can a deep auto-encoder effectively discriminate natural power disturbances from cyberattacks in a federated, privacy-preserving setting?"
      ],
      "gaps_identified": [
        "Synchronous FL assumes delay-free, error-free communications, which is unrealistic in SG/SCADA networks.",
        "Synchronous FL incurs communication inefficiency and penalizes faster clients due to waiting for stragglers.",
        "Resource wastage due to node selection and idle capable clients in large setups.",
        "Existing asynchronous FL often assumes data homogeneity, impractical for SG with heterogeneous IED data.",
        "Limited studies consider the effects of stragglers and communication latency for FL-based cyberattack detection in power grids."
      ],
      "limitations": [
        "Training time of FeDiSa increases as the number of impacted/straggler SCADA subsystems grows due to more rounds needed for convergence.",
        "Evaluation is performed on a single public ICS dataset (MSU-ORNL PSA).",
        "Security of aggregation against malicious/poisoned updates is not evaluated."
      ],
      "future_work": [],
      "motivation": "Address privacy and decentralization needs in smart grids while overcoming latency and straggler issues that hinder synchronous FL-based intrusion detection.",
      "potential_research_ideas": [
        "Integrate robust/Byzantine-resilient aggregators (e.g., Trimmed Mean, Krum, FLTrust) into the semi-asynchronous pipeline to handle poisoned or adversarial clients.",
        "Develop adaptive cut-off time mechanisms driven by real-time latency statistics to optimize staleness vs timeliness trade-offs.",
        "Personalized/semi-personalized FL (e.g., pFedMe, FedPer) for heterogeneous power zones with non-IID data distributions.",
        "Incorporate differential privacy and secure aggregation to strengthen privacy guarantees beyond FL’s data locality.",
        "Topology-aware models (e.g., Graph Neural Networks over grid topology) to exploit spatial correlations across substations/zones.",
        "Self-supervised or contrastive pretraining on unlabeled ICS signals to boost representation quality and reduce labeled data needs.",
        "Concept drift detection and continual learning to handle evolving attack tactics and changing grid conditions.",
        "Evaluate and extend FeDiSa to multi-dataset, cross-utility settings and multimodal signals (PMU, SCADA logs, network traffic)."
      ],
      "architectural_improvement_recommendations": [
        "Use attention-based or temporal architectures (1D CNN + BiLSTM/Transformer) on time-series features, possibly combined with reconstruction loss (hybrid predictive + reconstructive objectives).",
        "Replace/augment DAE with Variational Autoencoders or Denoising AEs; calibrate anomaly scores via EVT-based thresholding.",
        "Implement staleness-aware weighted aggregation and adaptive client selection; dynamically tune buffer size and cut-off based on observed delays.",
        "Apply gradient compression/quantization and sparsification to reduce communication load while preserving accuracy.",
        "Add secure aggregation and differential privacy; audit privacy-utility trade-offs.",
        "Provide a formal convergence and staleness analysis for the semi-asynchronous scheme; simulate wider non-IID scenarios."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Smart Grid SCADA environment with control centre and multiple SCADA sub-systems (IEDs at power grid zones)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Communication latency and unreliability between SCADA subsystems and control centre",
        "Client stragglers and intermittent dropouts",
        "Heterogeneous data distributions across power zones (non-IID)",
        "Resource constraints at edge IEDs"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes FeDiSa, a semi-asynchronous FL framework with buffering and preset cut-off time to mitigate stragglers and latency in SG cyberattack detection.",
      "Leverages a representation-learning Deep Auto-Encoder (stacked RBMs) for anomaly detection and classification in power control systems.",
      "Demonstrates superior detection performance on the MSU-ORNL PSA dataset: overall accuracy 92.4% vs CNN (89.6%), LSTM (78.5%), RBM (73.3%), RNN (69.3).",
      "Shows robustness to increasing stragglers compared to FedAvg and FedSGD; achieves approximately 35% reduction in training time under straggler conditions."
    ]
  },
  {
    "arxiv_id": "2302.10346v1",
    "title": "Exploring the Limits of Transfer Learning with Unified Model in the Cybersecurity Domain",
    "authors": "Kuntal Kumar Pal; Kazuaki Kashihara; Ujjwala Anantheswaran; Kirby C. Kuznia; Siddhesh Jagtap; Chitta Baral",
    "abstract": "With the increase in cybersecurity vulnerabilities of software systems, the ways to exploit them are also increasing. Besides these, malware threats, irregular network interactions, and discussions about exploits in public forums are also on the rise. To identify these threats faster, to detect potentially relevant entities from any texts, and to be aware of software vulnerabilities, automated approaches are necessary. Application of natural language processing (NLP) techniques in the Cybersecurity domain can help in achieving this. However, there are challenges such as the diverse nature of texts involved in the cybersecurity domain, the unavailability of large-scale publicly available datasets, and the significant cost of hiring subject matter experts for annotations. One of the solutions is building multi-task models that can be trained jointly with limited data. In this work, we introduce a generative multi-task model, Unified Text-to-Text Cybersecurity (UTS), trained on malware reports, phishing site URLs, programming code constructs, social media data, blogs, news articles, and public forum posts. We show UTS improves the performance of some cybersecurity datasets. We also show that with a few examples, UTS can be adapted to novel unseen tasks and the nature of data",
    "published_date": "2023-02-20",
    "pdf_link": "https://arxiv.org/pdf/2302.10346v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cyber Threat Intelligence",
      "subdomain": "NLP for Cybersecurity",
      "specific_problem": "Unified multi-task text-to-text model for classification, named entity recognition, event detection, and regression across heterogeneous cybersecurity texts",
      "attack_types": [
        "phishing",
        "malware/APT",
        "spam",
        "software vulnerabilities/CVE",
        "hacker threats in forums"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "T5-base (text-to-text)",
        "novel_contribution": "Unified Text-to-Text Cybersecurity (UTS): multi-task generative fine-tuning with task-specific prompt/control codes (CLS, NER, EVNT, REG) over 13 cybersecurity datasets; joint training across heterogeneous text types"
      },
      {
        "type": "primary",
        "category": "Prompting/Instruction Tuning",
        "specific": "Task-based control codes",
        "novel_contribution": "Task acronyms (CLS, NER, EVNT, REG) as prefix prompts to encourage task learning over dataset-specific memorization"
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "BiLSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Rule-based",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Tree-based",
        "specific": "Random Forest (+ SMOTE in one baseline)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT (task-specific variants)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN+CNN-CRF",
        "specific": "BiGRU + CNN-CRF",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERTOverflow (SOFTNER)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "T5-base (single-task fine-tuning per dataset)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Multi-task Learning",
      "Transfer Learning",
      "Few-shot Learning",
      "Zero-shot Inference"
    ],
    "datasets": [
      {
        "name": "MalwareTextDB-V2 (MDB-SENTCLS)",
        "type": "public",
        "domain": "apt_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MalwareTextDB-V2 (MDB-RELCLS)",
        "type": "public",
        "domain": "apt_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CyberThreatDetection (CTD)",
        "type": "public",
        "domain": "forum_posts",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SMS Spam",
        "type": "public",
        "domain": "text_messages",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PhishStorm (URL)",
        "type": "public",
        "domain": "urls",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Soft-Flaw CLS",
        "type": "public",
        "domain": "social_media",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CASIE-ARGROLE",
        "type": "public",
        "domain": "cybersecurity_news_articles",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Stucco Auto-labeled (SAL)",
        "type": "public",
        "domain": "cve_descriptions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Soft-Flaw NER",
        "type": "public",
        "domain": "social_media",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SOFTNER",
        "type": "public",
        "domain": "text_with_source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CASIE-EVTDET",
        "type": "public",
        "domain": "cybersecurity_news_articles",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CASIE-ARGDET",
        "type": "public",
        "domain": "cybersecurity_news_articles",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CVSS/CVE Impact (CVE-IMPACT)",
        "type": "public",
        "domain": "cve_descriptions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "BiLSTM (Phandi et al., 2018)",
        "paper_reference": "Phandi et al., 2018",
        "metric": "F1 (weighted)",
        "their_result": "84.44 (UTS) / 84.04 (T5-single)",
        "baseline_result": "57.00 (Previous Best) for MDB-SENTCLS"
      },
      {
        "method_name": "Rule-based (Phandi et al., 2018)",
        "paper_reference": "Phandi et al., 2018",
        "metric": "F1 (weighted)",
        "their_result": "99.69 (UTS) / 99.79 (T5-single)",
        "baseline_result": "85.70 (Previous Best) for MDB-RELCLS"
      },
      {
        "method_name": "CNN + Word Embedding",
        "paper_reference": "Queiroz et al., 2019",
        "metric": "Positive Recall",
        "their_result": "92.00 (UTS) / 92.17 (T5-single)",
        "baseline_result": "93.00 (Previous Best) for CTD"
      },
      {
        "method_name": "Random Forest + SMOTE",
        "paper_reference": "Mohasseb et al., 2020",
        "metric": "F1 (macro)",
        "their_result": "98.54 (UTS) / 99.45 (T5-single)",
        "baseline_result": "91.90 (Previous Best) for SMS-SPAM"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": "Marchal et al., 2014",
        "metric": "F1 (macro)",
        "their_result": "99.01 (UTS) / 98.99 (T5-single)",
        "baseline_result": "94.70 (Previous Best) for URL (PhishStorm)"
      },
      {
        "method_name": "BiGRU + CNN-CRF",
        "paper_reference": "Simran et al., 2019",
        "metric": "F1 (weighted)",
        "their_result": "97.60 (UTS) / 98.46 (T5-single)",
        "baseline_result": "93.40 (Previous Best) for SAL"
      },
      {
        "method_name": "BERTOverflow (SOFTNER)",
        "paper_reference": "Tabassum et al., 2020",
        "metric": "F1 (weighted)",
        "their_result": "77.02 (UTS) / 72.90 (T5-single)",
        "baseline_result": "79.10 (Previous Best) for SOFTNER"
      },
      {
        "method_name": "BERT (task-specific system)",
        "paper_reference": "Satyapanich et al., 2020",
        "metric": "F1 (weighted)",
        "their_result": "83.53 (UTS) / 81.43 (T5-single)",
        "baseline_result": "79.90 (Previous Best) for CASIE-EVTDET"
      },
      {
        "method_name": "Non event-specific system",
        "paper_reference": "Satyapanich et al., 2020",
        "metric": "F1 (macro)",
        "their_result": "92.50 (UTS) / 91.67 (T5-single)",
        "baseline_result": "82.90 (Previous Best) for CASIE-ARGROLE"
      },
      {
        "method_name": "None reported (no prior best)",
        "paper_reference": null,
        "metric": "Exact-match Accuracy (regression)",
        "their_result": "76.95 (UTS) / 76.58 (T5-single)",
        "baseline_result": "NA for CVE-IMPACT"
      }
    ],
    "performance_metrics_used": [
      "F1 (weighted)",
      "F1 (macro)",
      "Positive Recall",
      "Exact-match Accuracy (for regression)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "R1: How does UTS perform, compared to T5 and previous best?",
        "R2: To what extent Task Transfer is possible with UTS in few-shot settings?",
        "R3: To what extent Domain Transfer is possible with UTS in few-shot settings?",
        "R4: Is it possible to perform Zero-shot Domain Transfer with UTS?"
      ],
      "gaps_identified": [
        "Diverse nature of cybersecurity texts (natural language descriptions, URLs, malware reports, code, logs) complicates modeling",
        "Scarcity of large-scale publicly available annotated datasets in cybersecurity",
        "High cost of hiring subject matter experts for annotations"
      ],
      "limitations": [
        "Performance on SOFTNER dropped ~2% vs T5-single and did not surpass domain-specific embeddings used by SOFTNER authors",
        "Entity Typing (ET) few-shot performance is poor with FS-20 and lags behind full-data training, indicating difficulty in generating unseen types",
        "Task transfer is challenging when data nature changes (Domain Unknown Task Related setting showed large gap vs full training)",
        "Domain transfer to Twitter NER (Soft-Flaw) lags behind full-data T5 (FS-100 still below T5-FL by ~11 F1 points)"
      ],
      "future_work": [],
      "motivation": "Build a robust unified model that can learn multiple NLP tasks jointly from limited, heterogeneous cybersecurity data to reduce annotation cost and improve adaptability.",
      "potential_research_ideas": [
        "Continued pretraining of the backbone on large unlabeled cybersecurity corpora (CVE, threat reports, forums) to improve domain adaptation before multitask fine-tuning",
        "Task- and domain-specific adapter or LoRA modules to enhance transfer while keeping a unified backbone",
        "Constrained decoding or structured prediction for extraction (e.g., finite-state constrained beam search) to improve NER/ET precision and type correctness",
        "Semi-supervised and active learning over streaming CTI data to mitigate annotation scarcity, with SME-in-the-loop verification",
        "Generative-data augmentation using LLMs guided by security ontologies (e.g., MITRE ATT&CK, CWE) to balance rare event types and entities",
        "MoE (Mixture-of-Experts) multitask architecture to scale to more tasks/domains without interference",
        "Uncertainty estimation and calibration for generative outputs to support triaging in SOC workflows",
        "Domain-adversarial training or meta-learning for robust domain transfer (e.g., from news to Twitter)",
        "Hybrid models that combine span classification/tagging with generative decoding to improve extraction stability",
        "Joint prediction of CVSS vector components via sequence-to-structured decoding rather than exact score generation"
      ],
      "architectural_improvement_recommendations": [
        "Scale backbone to T5-large/3B and compare multitask interference vs gains; apply gradient surgery or multi-task weighting (e.g., Uncertainty/GradNorm)",
        "Introduce task-specific soft prompts/adapters (prefix-tuning/LoRA) with shared backbone to reduce forgetting and improve transfer",
        "Apply curriculum learning and temperature-based sampling to balance datasets of very different sizes; harmonize label spaces via ontology mapping",
        "Use constrained decoding templates for NER/ED (entity*type separated by markers) with validity checks; adopt pointer-generator or span-classifier heads",
        "Perform domain-adaptive pretraining (DAPT) on cybersecurity corpora, then task-adaptive pretraining (TAPT) per dataset before joint training",
        "Add adversarial and noise-robust training (URL perturbations, obfuscations) to improve robustness; perform label smoothing and calibration",
        "Leverage retrieval-augmented generation with a CTI knowledge base to improve event argument typing"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "T5-base (220M) trained jointly for up to 30 epochs; lr=5e-5, warmup ratio=0.01, beam size=4, batch size=12; trained on four 81GB Nvidia A100 GPUs; ~24 hours average training time"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Dataset scarcity and high annotation cost by SMEs",
        "Domain shift across heterogeneous text types (news, forums, URLs, tweets, code) impacts transfer",
        "Harmonizing entity/role type ontologies across datasets to avoid conflicts",
        "Stability of generative extraction outputs and need for post-processing/validation"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Unified Text-to-Text Cybersecurity (UTS): a generative multi-task T5-based model trained on heterogeneous cybersecurity texts",
      "Established a benchmark by processing 13 existing cybersecurity datasets into a text-to-text format across 8 NLP tasks",
      "Demonstrated improved or competitive performance vs previous best on 8 datasets (up to ~27% absolute F1 gains) and showed task/domain transfer in few-shot and zero-shot settings"
    ]
  },
  {
    "arxiv_id": "2304.13232v1",
    "title": "Multi-criteria Hardware Trojan Detection: A Reinforcement Learning Approach",
    "authors": "Amin Sarihi; Peter Jamieson; Ahmad Patooghy; Abdel-Hameed A. Badawy",
    "abstract": "Hardware Trojans (HTs) are undesired design or manufacturing modifications that can severely alter the security and functionality of digital integrated circuits. HTs can be inserted according to various design criteria, e.g., nets switching activity, observability, controllability, etc. However, to our knowledge, most HT detection methods are only based on a single criterion, i.e., nets switching activity. This paper proposes a multi-criteria reinforcement learning (RL) HT detection tool that features a tunable reward function for different HT detection scenarios. The tool allows for exploring existing detection strategies and can adapt new detection scenarios with minimal effort. We also propose a generic methodology for comparing HT detection methods fairly. Our preliminary results show an average of 84.2% successful HT detection in ISCAS-85 benchmark",
    "published_date": "2023-04-26",
    "pdf_link": "https://arxiv.org/pdf/2304.13232v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Hardware Trojan Detection",
      "specific_problem": "Post-silicon test-based detection of hardware Trojans using multi-criteria reinforcement learning and tunable reward functions",
      "attack_types": [
        "rare-trigger hardware Trojans",
        "combinational trigger HTs (2-, 3-, 4-, 5-input triggers)",
        "HTs inserted based on low switching activity and controllability/observability criteria"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": "PPO (Proximal Policy Optimization, Stable Baselines)",
        "novel_contribution": "Multi-criteria RL-based HT detector with three tunable reward functions (D1: state-difference, D2: inverse switching activity with 10x bonus for unseen triggers, D3: controllability/SCOAP-based) and pruning of dependent rare nets; multi-binary action/state mapping to primary inputs/rare nets"
      },
      {
        "type": "baseline",
        "category": "Heuristic/Search",
        "specific": "Random test vectors",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Test Generation",
        "specific": "MERO (rare-net excitation)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Traditional ML",
        "specific": "Random Forest on handcrafted features (Hasegawa et al., 2017)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Combinatorial Optimization",
        "specific": "TARMAC (maximal clique sampling for rare triggers)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": "DETERRENT (RL to cover rare nets)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "HW2VEC (graph embeddings + DNN classifier)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning"
    ],
    "datasets": [
      {
        "name": "ISCAS-85",
        "type": "public",
        "domain": "hardware_netlists",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "HT-inserted ISCAS-85 (Sarihi et al., 2022)",
        "type": "public",
        "domain": "hardware_netlists",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "Generated test vectors (this paper)",
        "type": "synthetic",
        "domain": "test_vectors_for_hardware_netlists",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Trust-Hub benchmarks",
        "type": "public",
        "domain": "hardware_netlists",
        "link": "https://trust-hub.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "MERO",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Random Forest (Hasegawa et al., 2017)",
        "paper_reference": "Hasegawa et al. (2017)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "TARMAC",
        "paper_reference": "Lyu and Mishra (2020)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "DETERRENT",
        "paper_reference": "Gohil et al. (2022)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "HW2VEC",
        "paper_reference": "Yu et al. (2021)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Random test vectors (c432 case study)",
        "paper_reference": null,
        "metric": "Detection accuracy on c432 (overall, unspecified trigger width mix)",
        "their_result": "RL approach underperformed on c432 vs random; see per-width values in Table 1 for D1/D2/D3",
        "baseline_result": "\"detecting 99% of the HTs\" with 20,000 additional random test vectors on c432"
      },
      {
        "method_name": "Internal comparison: D2 vs D1 (example c880, 5-input HTs)",
        "paper_reference": null,
        "metric": "Detection accuracy (%)",
        "their_result": "D2: 79.3%",
        "baseline_result": "D1: 85.1%"
      },
      {
        "method_name": "Internal comparison: D3 vs D2 (example c3540, 4-input HTs)",
        "paper_reference": null,
        "metric": "Detection accuracy (%)",
        "their_result": "D3: 98.8%",
        "baseline_result": "D2: 97.1%"
      }
    ],
    "performance_metrics_used": [
      "detection accuracy (%)",
      "confidence value (Conf.Val) using FP and FN with user-defined beta",
      "false positive rate (FP)",
      "false negative rate (FN)",
      "training time (hours)",
      "training timesteps",
      "episodes per run",
      "speedup factor (preprocessing graph to adjacency matrices/dicts)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a multi-criteria, tunable-reward RL agent detect HTs inserted under different criteria (switching activity, controllability)?",
        "Can a generic confidence metric enable fair comparison of heterogeneous HT detection methods from a security engineer’s perspective?"
      ],
      "gaps_identified": [
        "Most HT detection methods use a single criterion (nets’ switching activity).",
        "Available HT benchmarks are limited in size and variety and are human-crafted, introducing bias.",
        "Some prior methods assume pre-silicon access to internal nets, which may not hold in post-silicon settings."
      ],
      "limitations": [
        "Preliminary results limited to six ISCAS-85 circuits and HTs with 2–5 input triggers.",
        "On c432, random testing achieved 99% detection, outperforming the RL approach, indicating circuit-dependent efficacy.",
        "Confidence metric assumes independence of FN and FP and relies on user-defined beta; FP is zero for test-based methods using a golden model.",
        "Reward design requires thresholds (e.g., for rare nets) and pruning choices that may affect generalization."
      ],
      "future_work": [],
      "motivation": "Provide a multi-criteria HT detector beyond switching-activity-only approaches and a universal metric to compare HT detectors fairly across scenarios.",
      "potential_research_ideas": [
        "Formulate HT detection as a multi-objective RL problem jointly optimizing rare-net coverage, controllability, and observability with Pareto-frontier selection.",
        "Meta-RL or reward learning to automatically adapt reward weights per circuit class without manual threshold tuning.",
        "Hybrid GNN+RL: use a GNN to produce net importance priors or embeddings to guide the RL policy for large designs.",
        "Curriculum RL that gradually increases HT trigger width or rarity to stabilize training on large circuits.",
        "Ensemble or bandit-based selection among D1/D2/D3 (and new rewards) per circuit with online performance estimation.",
        "Evaluate and train on larger, modern industrial-scale netlists; generate or release a comprehensive HT-inserted benchmark suite with standardized splits.",
        "Integrate partial-scan/DFT constraints and power/side-channel observations to augment state and reward for post-silicon applicability.",
        "Use model-based RL or planning (e.g., learned transition models) to reduce sample complexity and training time."
      ],
      "architectural_improvement_recommendations": [
        "Adopt multi-objective PPO with dynamic scalarization (e.g., Chebyshev or adaptive weights) to balance switching activity and controllability rewards.",
        "Incorporate a graph neural network encoder over the netlist to produce state features instead of hand-crafted rare-net vectors.",
        "Reward shaping via potential-based methods aligned with SCOAP gradients to improve convergence.",
        "Add intrinsic exploration bonuses (e.g., count-based or RND) to reduce overfitting to specific rare nets.",
        "Implement policy selection or mixture-of-experts across D1/D2/D3 with gating based on circuit statistics.",
        "Leverage parallelized environment simulators and batched logic simulation to further reduce wall-clock training time.",
        "Automate threshold selection for rare nets using percentile-based or Bayesian optimization strategies."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Python",
        "Stable Baselines (PPO)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Training started at 450k timesteps on c432 and increased 10% per larger circuit; episode length 10; trained in parallel on six ISCAS-85 circuits; ~27 hours total training; preprocessing adjacency matrices/dicts yielded ~3.7x training and ~3.2x testing speedups; 20k testing episodes; 20k test vectors collected above a reward threshold."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires a golden netlist; applicability depends on post-silicon access to accurate reference models.",
        "Training time and sample complexity can be high on large circuits.",
        "Reward/threshold tuning (e.g., rare-net thresholds, controllability thresholds) is circuit-dependent.",
        "Effectiveness can vary by circuit; in some cases random test vectors may suffice or perform better.",
        "Selecting the appropriate reward scenario (D1/D2/D3) for a given circuit requires guidance."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a multi-criteria RL-based HT detection tool with tunable reward functions (D1, D2, D3) to target different insertion strategies.",
      "Proposes a pruning strategy to avoid over-counting dependent rare nets and accelerate convergence.",
      "Presents a generic confidence metric to fairly compare HT detection methods across scenarios.",
      "Empirical evaluation on ISCAS-85 with HTs of varying trigger widths; reports an average of 84.2% successful HT detection.",
      "Releases generated test patterns (link removed for blind review) and reports practical training/testing speedups via adjacency-matrix preprocessing."
    ]
  },
  {
    "arxiv_id": "2302.08348v4",
    "title": "A robust statistical framework for cyber-vulnerability prioritisation under partial information in threat intelligence",
    "authors": "Mario Angelelli; Serena Arima; Christian Catalano; Enrico Ciavolino",
    "abstract": "Proactive cyber-risk assessment is gaining momentum due to the wide range of sectors that can benefit from the prevention of cyber-incidents by preserving integrity, confidentiality, and the availability of data. The rising attention to cybersecurity also results from the increasing connectivity of cyber-physical systems, which generates multiple sources of uncertainty about emerging cyber-vulnerabilities. This work introduces a robust statistical framework for quantitative and qualitative reasoning under uncertainty about cyber-vulnerabilities and their prioritisation. Specifically, we take advantage of mid-quantile regression to deal with ordinal risk assessments, and we compare it to current alternatives for cyber-risk ranking and graded responses. For this purpose, we identify a novel accuracy measure suited for rank invariance under partial knowledge of the whole set of existing vulnerabilities. The model is tested on both simulated and real data from selected databases that support the evaluation, exploitation, or response to cyber-vulnerabilities in realistic contexts. Such datasets allow us to compare multiple models and accuracy measures, discussing the implications of partial knowledge about cyber-vulnerabilities on threat intelligence and decision-making in operational scenarios.",
    "published_date": "2023-02-16",
    "pdf_link": "https://arxiv.org/pdf/2302.08348v4",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Threat Intelligence",
      "subdomain": "Vulnerability Management and Risk Scoring",
      "specific_problem": "Prioritisation and ranking of cyber-vulnerabilities under partial/unknown information",
      "attack_types": [
        "denial-of-service",
        "malware injection",
        "data exfiltration",
        "privilege escalation",
        "0-day exploitation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Regression",
        "specific": "Mid-quantile regression",
        "novel_contribution": "Use of mid-quantile regression for robust ordinal cyber-risk assessments and graded responses under partial information"
      },
      {
        "type": "baseline",
        "category": "Generalized Linear Model",
        "specific": "Ordered Logit (proportional odds)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Regression",
        "specific": "Rank-transform Linear Regression",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Simulated vulnerabilities data",
        "type": "synthetic",
        "domain": "vulnerability_metadata",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Selected public vulnerability databases (integrated)",
        "type": "public",
        "domain": "vulnerability_metadata",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Ordered Logit (OrdLog)",
        "paper_reference": "McCullagh, 1980",
        "metric": "proposed rank accuracy index (invariance to unknown vulnerabilities)",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Rank-transform Linear Regression (LinReg)",
        "paper_reference": "Giudici and Raffinetti, 2021",
        "metric": "proposed rank accuracy index (invariance to unknown vulnerabilities)",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Proposed rank accuracy index suited for rank invariance under partial knowledge of vulnerabilities"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to assess cyber-risk based on partial information on known vulnerabilities without relying on specific statistical properties (e.g., distributional assumptions) that could hardly be verified?",
        "How to measure the accuracy of such an assessment while also taking into account the presence of unknown vulnerabilities?"
      ],
      "gaps_identified": [
        "Partial knowledge and limited accessibility of high-quality cybersecurity data hinder quantitative risk assessment",
        "Dependence of many methods on restrictive distributional assumptions that may be violated in practice",
        "Subjectivity and methodological issues of qualitative/semi-qualitative risk matrices (e.g., inconsistencies, lack of correlation handling)",
        "CVSS alone does not directly link to attack likelihood and should be combined with external exploit information",
        "Lack of harmonisation across quantitative methodologies limiting comparability",
        "Potential violation of proportional odds assumption in ordered logit models",
        "Reduced interpretability of GLM parameters for operational decision-makers"
      ],
      "limitations": [
        "Data considered do not involve social engineering, insider threats, or physical effects",
        "Focuses on vulnerabilities rather than actual incidents",
        "Effectiveness depends on the availability and selection of appropriate explanatory variables"
      ],
      "future_work": [
        "Extend the framework to incorporate other threat sources (e.g., social engineering, insider threats, physical effects)",
        "Develop probabilistic modelling of cyber-threat assessment leveraging the conditional probability estimates produced by the method",
        "Explore sensitivity to hyperparameters (e.g., number of priority levels) and deviations from standard assumptions on broader datasets"
      ],
      "motivation": "Provide a flexible and interpretable statistical framework for vulnerability risk assessment and prioritisation under uncertainty and partial information, and define an accuracy measure for rank prediction that remains invariant to unknown vulnerabilities.",
      "potential_research_ideas": [
        "Combine mid-quantile regression with learning-to-rank methods (e.g., LambdaMART) tailored for partial-label and unknown-item settings",
        "Integrate knowledge-graph features (e.g., CVE–CPE–Exploit relations) to enrich explanatory variables and assess causal dependencies",
        "Design semi-supervised or PU-learning approaches to leverage unlabeled/unknown vulnerabilities in training",
        "Develop time-aware models to update rankings as new CVEs and exploits appear (online/streaming setting)",
        "Augment features via NLP from CVE descriptions, advisories, and exploit texts; assess gains in ordinal prediction",
        "Construct and release a standardised benchmark dataset for vulnerability prioritisation with explicit partial-information scenarios",
        "Use conformal prediction to output calibrated ordinal risk sets/intervals for decision risk-control"
      ],
      "architectural_improvement_recommendations": [
        "Incorporate monotonic constraints and generalized additive components to model nonlinear yet interpretable effects",
        "Use quantile generalized additive models or spline-based mid-quantile regression for flexible relationships",
        "Add ordinal calibration (e.g., isotonic regression) post-processing to improve probability estimates for graded responses",
        "Adopt Bayesian shrinkage or hierarchical mid-quantile formulations to stabilise estimates across products/vendors",
        "Introduce top-k stability and partial-order metrics alongside the proposed index for more deployment-relevant evaluation",
        "Fuse the framework with conformal risk measures to quantify uncertainty under unknown vulnerabilities"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Limited data accessibility and non-disclosure policies",
        "Heterogeneous and partially known vulnerability information",
        "Need for harmonisation across data sources and methodologies",
        "Selection and availability of context-specific explanatory variables"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduce mid-quantile-based statistical models to handle ordinal cyber-risk assessments with robust estimation and conditional probability outputs",
      "Propose a new accuracy index for rank prediction that is invariant to unknown vulnerabilities, enabling fair comparison under partial information",
      "Collect and integrate information from multiple datasets to test and compare models and accuracy measures on both simulated and real data, discussing implications for vulnerability prioritisation"
    ]
  },
  {
    "arxiv_id": "2307.02412v1",
    "title": "Android Malware Detection using Machine learning: A Review",
    "authors": "Md Naseef-Ur-Rahman Chowdhury; Ahshanul Haque; Hamdy Soliman; Mohammad Sahinur Hossen; Tanjim Fatima; Imtiaz Ahmed",
    "abstract": "Malware for Android is becoming increasingly dangerous to the safety of mobile devices and the data they hold. Although machine learning(ML) techniques have been shown to be effective at detecting malware for Android, a comprehensive analysis of the methods used is required. We review the current state of Android malware detection us ing machine learning in this paper. We begin by providing an overview of Android malware and the security issues it causes. Then, we look at the various supervised, unsupervised, and deep learning machine learning approaches that have been utilized for Android malware detection. Addi tionally, we present a comparison of the performance of various Android malware detection methods and talk about the performance evaluation metrics that are utilized to evaluate their efficacy. Finally, we draw atten tion to the drawbacks and difficulties of the methods that are currently in use and suggest possible future directions for research in this area. In addition to providing insights into the current state of Android malware detection using machine learning, our review provides a comprehensive overview of the subject.",
    "published_date": "2023-03-15",
    "pdf_link": "https://arxiv.org/pdf/2307.02412v1",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "Android Malware Detection",
      "specific_problem": "Machine-learning-based detection and classification of malicious Android applications",
      "attack_types": [
        "Android malware",
        "Evasion (anti-virtualization, anti-debugging)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Dimensionality Reduction",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Deep Learning"
    ],
    "datasets": [
      {
        "name": "20,000 Android APK dataset (10,000 benign / 10,000 malware) used in [1]",
        "type": "private",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Real-world movie dataset (users, movies, ratings) used in [2]",
        "type": "private",
        "domain": "user_item_ratings",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Synthetic stock market dataset used in [3]",
        "type": "synthetic",
        "domain": "financial_time_series",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Historical stock market dataset used in [3]",
        "type": "private",
        "domain": "financial_time_series",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Large dataset of Android malware and benign applications used in [4]",
        "type": "private",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "PUMA training dataset (>4,000 APKs, benign and malware) used in [6]",
        "type": "private",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Large dataset of software (benign and harmful) used in [7]",
        "type": "private",
        "domain": "software_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Dataset of malware samples evaluated under anti-virtualization/anti-debugging conditions used in [8]",
        "type": "private",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Traditional ML approaches (e.g., SVM, Decision Trees) vs CNN+LSTM approach in [1]",
        "paper_reference": "[1]",
        "metric": "Accuracy",
        "their_result": "97.12% accuracy (CNN+LSTM)",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "Mean Average Precision",
      "Training time",
      "Prediction/Inference time",
      "Robustness to adversarial examples",
      "False positive rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What supervised, unsupervised, and deep learning techniques have been used for Android malware detection?",
        "How do these techniques perform according to standard evaluation metrics?",
        "What static, dynamic, and hybrid feature sources are used in Android malware detection?",
        "What are the challenges and limitations of current ML-based Android malware detection methods?",
        "What directions should future research in ML-based Android malware detection take?"
      ],
      "gaps_identified": [
        "Existing studies are scattered; a comprehensive consolidation is needed.",
        "Inconsistent reporting of algorithms, datasets, and quantitative metrics in several works (e.g., some cited papers do not specify algorithms or exact metrics).",
        "Lack of standardized benchmarks and evaluation protocols across studies.",
        "Limited consideration/reporting of robustness evaluations against adversarial examples and evasion (e.g., anti-virtualization/anti-debugging)."
      ],
      "limitations": [
        "Focuses solely on ML-based Android malware detection (excludes signature-, rule-, and heuristic-based methods except for brief mention).",
        "Cited works sometimes omit critical details (algorithms, datasets, metrics), constraining depth of comparison."
      ],
      "future_work": [
        "Paper states it suggests future research directions; specific actionable directions are not detailed in the provided text."
      ],
      "motivation": "Android malware is increasing and ML shows promise; due to scattered literature, a comprehensive analysis of ML-based approaches, metrics, and limitations is needed.",
      "potential_research_ideas": [
        "Create a standardized, regularly updated Android malware detection benchmark with well-documented splits, metadata, and versioning.",
        "Develop hybrid static+dynamic multimodal models robust to anti-VM/anti-debugging evasion (e.g., on-device behavioral traces + static code semantics).",
        "Systematically study adversarial robustness of Android malware detectors and develop domain-specific adversarial training/defense strategies.",
        "Leverage self-supervised pretraining on large unlabeled APK corpora (e.g., API-call sequences, CFGs) followed by few-shot fine-tuning.",
        "Explore federated/on-device learning to protect user privacy while continuously adapting to emerging malware.",
        "Integrate uncertainty estimation and calibration to reduce false positives in deployment.",
        "Use program analysis–aware graph neural networks over call graphs/ICC graphs for better generalization across malware families."
      ],
      "architectural_improvement_recommendations": [
        "Adopt transformer-based sequence models over API-call or opcode sequences; compare to CNN/RNN baselines.",
        "Fuse static (permissions, code features) and dynamic (runtime behaviors, network patterns) via cross-modal attention.",
        "Incorporate graph neural networks over call graphs/intent communication graphs; combine with sequence encoders.",
        "Apply adversarial training with realistic evasion tactics (e.g., benign permission padding, control-flow obfuscation) and evaluate transfer robustness.",
        "Use self-supervised objectives (masked opcode prediction, contrastive learning of behaviors) to reduce label dependence.",
        "Calibrate outputs (temperature scaling) and add abstention/triage for high-uncertainty samples to minimize false positives.",
        "Perform cost-sensitive training to balance detection rates with false positive costs on-device."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Evasion via anti-virtualization and anti-debugging techniques",
        "Achieving real-time detection on smartphones (resource constraints)"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comprehensive review of ML-based Android malware detection methods.",
      "Taxonomy of approaches by learning paradigm (supervised, unsupervised, deep learning) and by feature source (static, dynamic, hybrid).",
      "Discussion of evaluation metrics, including accuracy-focused, time-focused, and robustness-focused assessments.",
      "Comparative synthesis highlighting example results (e.g., CNN+LSTM achieving 97.12% accuracy in [1]) and shortcomings of reporting in several works.",
      "Identification of drawbacks and challenges in current methods and highlighting the need for standardized evaluation and robustness assessments."
    ]
  },
  {
    "arxiv_id": "2304.10511v1",
    "title": "OutCenTR: A novel semi-supervised framework for predicting exploits of vulnerabilities in high-dimensional datasets",
    "authors": "Hadi Eskandari; Michael Bewong; Sabih ur Rehman",
    "abstract": "An ever-growing number of vulnerabilities are reported every day. Yet these vulnerabilities are not all the same; Some are more targeted than others. Correctly estimating the likelihood of a vulnerability being exploited is a critical task for system administrators. This aids the system administrators in prioritizing and patching the right vulnerabilities. Our work makes use of outlier detection techniques to predict vulnerabilities that are likely to be exploited in highly imbalanced and high-dimensional datasets such as the National Vulnerability Database. We propose a dimensionality reduction technique, OutCenTR, that enhances the baseline outlier detection models. We further demonstrate the effectiveness and efficiency of OutCenTR empirically with 4 benchmark and 12 synthetic datasets. The results of our experiments show on average a 5-fold improvement of F1 score in comparison with state-of-the-art dimensionality reduction techniques such as PCA and GRP.",
    "published_date": "2023-04-03",
    "pdf_link": "https://arxiv.org/pdf/2304.10511v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Management and Prioritization",
      "specific_problem": "Predicting the likelihood that software vulnerabilities will be exploited using semi-supervised outlier-centric feature reduction on high-dimensional, imbalanced datasets",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Feature Selection/Dimensionality Reduction",
        "specific": null,
        "novel_contribution": "OutCenTR: centroid-based semi-supervised feature reduction that computes separate centroids of labeled inliers and outliers and ranks features by a distinguishability score to improve outlier detection in high dimensions"
      },
      {
        "type": "baseline",
        "category": "Anomaly Detection (Tree Ensemble)",
        "specific": "Isolation Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Anomaly Detection (SVM)",
        "specific": "One-Class SVM (RBF kernel)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Anomaly Detection (Density-Based)",
        "specific": "Local Outlier Factor (LOF)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Dimensionality Reduction",
        "specific": "Principal Component Analysis (PCA)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Dimensionality Reduction",
        "specific": "Gaussian Random Projection (GRP)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Semi-supervised",
      "Unsupervised (Anomaly/Outlier Detection)"
    ],
    "datasets": [
      {
        "name": "NVD vulnerability dataset (curated with ExploitDB linkage)",
        "type": "proprietary",
        "domain": "vulnerability_records",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Network Intrusion dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Credit Card Fraud Detection",
        "type": "public",
        "domain": "financial_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Census dataset",
        "type": "public",
        "domain": "census_tabular",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Synthetic datasets (scikit-learn make_* generators)",
        "type": "synthetic",
        "domain": "tabular_synthetic",
        "link": "http://www.scikit-learn.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Isolation Forest on NVD",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "28.01%",
        "baseline_result": "6.87%"
      },
      {
        "method_name": "One-Class SVM (RBF) on NVD",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "8.86%",
        "baseline_result": "4.09%"
      },
      {
        "method_name": "Local Outlier Factor on NVD",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "3.70%",
        "baseline_result": "1.89%"
      },
      {
        "method_name": "Isolation Forest on Network Intrusion",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "26.65%",
        "baseline_result": "1.46%"
      },
      {
        "method_name": "One-Class SVM (RBF) on Network Intrusion",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "8.19%",
        "baseline_result": "5.20%"
      },
      {
        "method_name": "Local Outlier Factor on Network Intrusion",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "8.24%",
        "baseline_result": "35.52%"
      },
      {
        "method_name": "Isolation Forest on Fraud Detection",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "13.98%",
        "baseline_result": "12.92%"
      },
      {
        "method_name": "One-Class SVM (RBF) on Fraud Detection",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "13.97%",
        "baseline_result": "12.89%"
      },
      {
        "method_name": "Local Outlier Factor on Fraud Detection",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.31%",
        "baseline_result": "0.00%"
      },
      {
        "method_name": "Isolation Forest on Census",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "8.30%",
        "baseline_result": "4.93%"
      },
      {
        "method_name": "One-Class SVM (RBF) on Census",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "17.21%",
        "baseline_result": "5.71%"
      },
      {
        "method_name": "Local Outlier Factor on Census",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "9.38%",
        "baseline_result": "1.97%"
      }
    ],
    "performance_metrics_used": [
      "F1",
      "Recall",
      "Precision"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a semi-supervised, centroid-based feature reduction approach improve outlier detection for predicting vulnerability exploits in high-dimensional, imbalanced datasets without relying on extensive labels?",
        "Do outlier-centric feature rankings outperform PCA and GRP for the exploit prediction task?"
      ],
      "gaps_identified": [
        "Assumption of readily-available labeled datasets for exploit prediction does not hold in practice",
        "High dimensionality of vulnerability datasets impairs model learning and outlier separability",
        "Common dimensionality reduction methods (PCA, GRP) are not effective for this outlier detection problem",
        "Deep learning approaches lack interpretability and require large labeled datasets and compute"
      ],
      "limitations": [
        "OutCenTR requires a small set of labeled inliers and outliers to compute centroids",
        "Outlier detectors were configured with the true contamination ratio, which may not be known in real-world deployment",
        "Results show method does not universally improve all detectors on all datasets (e.g., LOF degraded on the Network Intrusion dataset)"
      ],
      "future_work": [],
      "motivation": "Prioritize patching by estimating the likelihood that a vulnerability will be exploited under label scarcity, high dimensionality, and need for interpretability.",
      "potential_research_ideas": [
        "Integrate textual embeddings from CVE/NVD descriptions (e.g., transformer-based) with OutCenTR feature ranking for multimodal exploit prediction",
        "Develop unsupervised or positive–unlabeled (PU) variants of OutCenTR that remove dependence on labeled outliers",
        "Estimate contamination ratio automatically and adapt thresholds online for non-stationary exploit rates",
        "Model temporal dynamics and concept drift in vulnerability/exploit emergence (time-aware OutCenTR)",
        "Leverage graphs of CVE–CWE–CPE–vendor links with graph-based anomaly detection combined with OutCenTR-selected attributes",
        "Active learning to choose the most informative samples to label for centroid construction",
        "Uncertainty calibration for outlier scores to support risk-aware prioritization",
        "Benchmark and release a standardized, versioned exploit-label dataset for reproducible evaluation"
      ],
      "architectural_improvement_recommendations": [
        "Use robust location estimators (median, geometric median) and dispersion (MAD) for centroid computation to reduce sensitivity to noise",
        "Adopt Mahalanobis distance or learned metric for distinguishability score to account for feature covariance",
        "Stability selection or bootstrapped feature ranking to improve robustness of ARank across samples",
        "Hybrid ensemble: combine OutCenTR-selected features with learned representations (e.g., shallow autoencoders) while retaining interpretability via feature ranking",
        "Adaptive feature budget t selection using validation curves or information criteria rather than fixed 10%",
        "Joint optimization of detector hyperparameters with OutCenTR selection via Bayesian optimization",
        "Threshold calibration using extreme value theory on outlier scores for principled decision boundaries",
        "Incorporate cost-sensitive weighting reflecting patching/prioritization costs and exploit impact"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "scikit-learn"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Experiments run on a 3 GHz 10-Core Intel Xeon with 64GB RAM; scikit-learn implementations of OCSVM, Isolation Forest, LOF; default OutCenTR selects top 10% attributes."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Scarcity and delay of reliable exploit labels",
        "Severe class imbalance",
        "High dimensionality of vulnerability features",
        "Unknown contamination rate in production settings",
        "Concept drift in vulnerability characteristics over time"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Propose a novel semi-supervised, outlier-centric framework (OutCenTR) for predicting exploits of vulnerabilities",
      "Introduce a centroid-based feature reduction technique that ranks attributes by distinguishability between inlier and outlier centroids",
      "Demonstrate effectiveness and efficiency on 4 real-world high-dimensional datasets and 12 synthetic datasets",
      "Show improvements over PCA and GRP for this task, reporting on average a 5-fold F1 improvement"
    ]
  },
  {
    "arxiv_id": "2303.06514v1",
    "title": "Credit Card Fraud Detection Using Enhanced Random Forest Classifier for Imbalanced Data",
    "authors": "AlsharifHasan Mohamad Aburbeian; Huthaifa I. Ashqar",
    "abstract": "The credit card has become the most popular payment method for both online and offline transactions. The necessity to create a fraud detection algorithm to precisely identify and stop fraudulent activity arises as a result of both the development of technology and the rise in fraud cases. This paper implements the random forest (RF) algorithm to solve the issue in the hand. A dataset of credit card transactions was used in this study. The main problem when dealing with credit card fraud detection is the imbalanced dataset in which most of the transaction are non-fraud ones. To overcome the problem of the imbalanced dataset, the synthetic minority over-sampling technique (SMOTE) was used. Implementing the hyperparameters technique to enhance the performance of the random forest classifier. The results showed that the RF classifier gained an accuracy of 98% and about 98% of F1-score value, which is promising. We also believe that our model is relatively easy to apply and can overcome the issue of imbalanced data for fraud detection applications.",
    "published_date": "2023-03-11",
    "pdf_link": "https://arxiv.org/pdf/2303.06514v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Fraud Detection",
      "subdomain": "Credit Card Fraud Detection",
      "specific_problem": "Binary classification of fraudulent vs. legitimate credit card transactions under severe class imbalance",
      "attack_types": [
        "credit card transaction fraud",
        "online/card-not-present fraud"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": "Enhanced via hyperparameter tuning (grid search) and trained on SMOTE-balanced data"
      },
      {
        "type": "primary",
        "category": "Data augmentation / Oversampling",
        "specific": "SMOTE",
        "novel_contribution": "Applied to rebalance the minority fraud class to 50:50 prior to training"
      },
      {
        "type": "primary",
        "category": "Hyperparameter Optimization",
        "specific": "Grid Search",
        "novel_contribution": "Used to select best RF hyperparameters"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Kaggle credit card transactions dataset (94,682 transactions)",
        "type": "public",
        "domain": "financial_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "ROC AUC",
      "Confusion Matrix"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can an enhanced Random Forest with SMOTE-based rebalancing accurately detect both fraud and non-fraud transactions?",
        "Do metrics beyond accuracy (precision, recall, F1, ROC AUC) demonstrate reliable performance under class imbalance?"
      ],
      "gaps_identified": [
        "Prior studies often reported only accuracy on highly imbalanced credit card datasets, which is insufficient and leads to bias toward the majority class.",
        "Imbalanced datasets cause supervised models to predict only the majority (legitimate) class."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Address skewed class distributions in credit card fraud detection and evaluate models with metrics appropriate for imbalanced classification.",
      "potential_research_ideas": [
        "Evaluate cost-sensitive learning (class-weighted RF/GBM) versus SMOTE to reduce synthetic data artifacts while optimizing recall on fraud.",
        "Incorporate temporal and session-level behavioral features; test time-aware validation and concept-drift handling for evolving fraud tactics.",
        "Compare ensemble approaches (XGBoost/LightGBM, CatBoost) and stacking with calibrated probability outputs for threshold-tuned alerting.",
        "Explore semi-supervised and unsupervised anomaly detection (Isolation Forest, Deep SVDD) to detect novel fraud patterns.",
        "Develop online/streaming detection with incremental learning and drift detectors (ADWIN, DDM) for real-time deployment.",
        "Apply threshold optimization under business costs (cost-sensitive ROC/precision-recall optimization) and constrained optimization for false positive budgets.",
        "Add post-hoc explainability (SHAP) for analyst triage and feedback loops to improve precision on high-cost false positives."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment SMOTE with class-weighted learning or SMOTE variants (SMOTE-Tomek, SMOTE-ENN) to reduce overfitting and boundary noise.",
        "Adopt gradient boosting (LightGBM/XGBoost) with monotone constraints or categorical handling; compare against tuned RF with probability calibration (isotonic/Platt).",
        "Use time-based splits and rolling-origin evaluation to prevent temporal leakage and better estimate live performance.",
        "Implement threshold tuning per segment (merchant, geography, channel) and conformal prediction for risk scoring with coverage guarantees.",
        "Integrate feature engineering pipelines (frequency/recency features, merchant velocity, device fingerprint signals) and embedding methods for categorical fields.",
        "Introduce model monitoring with drift detection and periodic retraining triggers; log calibration drift and class prior shift.",
        "Calibrate outputs and provide SHAP-based explanations to support human-in-the-loop triage."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Severe class imbalance necessitating rebalancing or cost-sensitive training",
        "Evolving fraud behavior leading to concept drift",
        "Risk of bias toward legitimate class if not properly handled"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Implemented an enhanced Random Forest classifier with hyperparameter tuning for credit card fraud detection under class imbalance.",
      "Applied SMOTE to rebalance the dataset to a 50:50 fraud/non-fraud ratio before training.",
      "Reported multiple metrics appropriate for imbalanced data, including precision, recall, F1, and ROC AUC.",
      "Exact quote: \"The results showed that the RF classifier gained an accuracy of 98% and about 98% of F1-score value, which is promising.\"",
      "Provided detailed confusion matrix counts: TP=83,736; TN=87,242; FP=3,826; FN=320; ROC AUC=0.98."
    ]
  },
  {
    "arxiv_id": "2302.12452v1",
    "title": "Machine Learning Based Intrusion Detection Systems for IoT Applications",
    "authors": "Abhishek Verma; Virender Ranga",
    "abstract": "Internet of Things (IoT) and its applications are the most popular research areas at present. The characteristics of IoT on one side make it easily applicable to real-life applications, whereas on the other side expose it to cyber threats. Denial of Service (DoS) is one of the most catastrophic attacks against IoT. In this paper, we investigate the prospects of using machine learning classification algorithms for securing IoT against DoS attacks. A comprehensive study is carried on the classifiers which can advance the development of anomaly-based intrusion detection systems (IDSs). Performance assessment of classifiers is done in terms of prominent metrics and validation methods. Popular datasets CIDDS-001, UNSW-NB15, and NSL-KDD are used for benchmarking classifiers. Friedman and Nemenyi tests are employed to analyze the significant differences among classifiers statistically. In addition, Raspberry Pi is used to evaluate the response time of classifiers on IoT specific hardware. We also discuss a methodology for selecting the best classifier as per application requirements. The main goals of this study are to motivate IoT security researchers for developing IDSs using ensemble learning, and suggesting appropriate methods for statistical assessment of classifier's performance.",
    "published_date": "2023-02-24",
    "pdf_link": "https://arxiv.org/pdf/2302.12452v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Anomaly-based IDS for detecting DoS attacks in IoT networks",
      "attack_types": [
        "DoS",
        "DDoS"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Boosting",
        "specific": "AdaBoost",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Boosting",
        "specific": "Gradient Boosted Machine (GBM)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Boosting",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "ExtraTrees",
        "specific": "Extremely Randomized Trees (ETC)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": "CART",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": "Feedforward neural network",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CIDDS-001",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Specificity",
      "Sensitivity",
      "False Positive Rate",
      "AUC (ROC)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can machine learning classification algorithms effectively secure IoT against DoS attacks via anomaly-based IDS?",
        "Which single and ensemble classifiers perform best across CIDDS-001, UNSW-NB15, and NSL-KDD for IoT DoS detection?",
        "Are observed performance differences among classifiers statistically significant (Friedman and Nemenyi tests)?",
        "What are the response times of these classifiers on IoT-specific hardware (Raspberry Pi)?",
        "How can practitioners select the best classifier per application requirements?"
      ],
      "gaps_identified": [
        "Less work on ML-based intrusion detection specifically for IoT compared to traditional networks.",
        "No prior work found that statistically analyzed significance of classifier performance for IoT-based intrusion detection using Friedman/Nemenyi tests.",
        "Lack of prior realizations of executing classifiers on IoT hardware to measure response time.",
        "Performance of ensemble methods not studied in depth for CIDDS-001 and UNSW-NB15 datasets."
      ],
      "limitations": [],
      "future_work": [
        "Motivate IoT security researchers for developing IDSs using ensemble learning.",
        "Suggest appropriate methods for statistical assessment of classifier performance."
      ],
      "motivation": "Investigate the prospects of using ML classifiers to secure IoT against DoS, provide a comprehensive benchmarking with proper validation and statistical significance testing, and evaluate practical response time on IoT hardware (Raspberry Pi).",
      "potential_research_ideas": [
        "Design lightweight, energy-aware ensemble IDS optimized for constrained IoT devices with on-device inference.",
        "Create an IoT-native DoS/DDoS dataset capturing modern protocols (MQTT/CoAP), encrypted traffic features, and real device behaviors.",
        "Develop online/streaming anomaly detection with concept-drift handling for evolving IoT traffic.",
        "Explore federated or collaborative IDS across IoT gateways to improve detection without sharing raw data.",
        "Incorporate explainability (feature attributions, rule extraction) for operator trust and triage.",
        "Evaluate and harden models against adversarial evasion/poisoning attacks specific to IoT network features.",
        "Investigate cost-sensitive and imbalanced-learning strategies tailored to low FPR requirements in critical IoT settings.",
        "Integrate uncertainty estimation and calibrated decision thresholds for actionable alerting.",
        "Study multi-task or hierarchical models that jointly detect attack types and stages beyond binary DoS vs normal."
      ],
      "architectural_improvement_recommendations": [
        "Apply Bayesian hyperparameter optimization and automated feature selection/engineering to improve ensemble performance and reduce complexity.",
        "Quantize and prune tree ensembles (e.g., tree distillation to shallow models or gradient-boosted trees to small neural nets) for faster Raspberry Pi inference.",
        "Adopt online/incremental learning variants (e.g., streaming trees, adaptive boosting) to handle concept drift in IoT traffic.",
        "Use stacked or blended ensembles combining tree models with lightweight neural components and calibrate outputs (Platt/Isotonic).",
        "Employ federated learning with differential privacy at gateways to protect data while improving models.",
        "Leverage protocol-aware features (MQTT/CoAP timing, packet inter-arrival statistics) and robust aggregation to reduce false alarms.",
        "Introduce threshold optimization under application-specific cost constraints and implement conformal prediction for risk-aware alerts."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Raspberry Pi (IoT edge device) for response-time evaluation",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Anomaly-based IDS tends to have higher false alarm rates.",
        "Ensemble methods can overfit when the number of input features is large.",
        "Resource constraints on IoT hardware (compute/memory/energy) necessitate lightweight models.",
        "Dependence on dataset quality and representativeness for training effective detectors."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Performance assessment of CART, MLP, RF, AdaBoost, GBM, XGBoost, and ExtraTrees on CIDDS-001, UNSW-NB15, and NSL-KDD using repeated hold-out and repeated cross-fold validation.",
      "Statistical significance testing of classifier performance using Friedman test and Nemenyi post-hoc pairwise comparisons.",
      "Implementation and execution of classifiers on Raspberry Pi hardware to evaluate average response time.",
      "Discussion of a methodology for selecting the best classifier per application requirements and motivation toward ensemble-based IDS for IoT."
    ]
  },
  {
    "arxiv_id": "2302.05949v1",
    "title": "Machine Learning Assisted Bad Data Detection for High-throughput Substation Communication",
    "authors": "Suman Sourav; Partha P. Biswas; Vyshnavi Mohanraj; Binbin Chen; Daisuke Mashima",
    "abstract": "Electrical substations are becoming more prone to cyber-attacks due to increasing digitalization. Prevailing defense measures based on cyber rules are often inadequate to detect attacks that use legitimate-looking measurements. In this work, we design and implement a bad data detection solution for electrical substations called ResiGate, that effectively combines a physics-based approach and a machine-learning-based approach to provide substantial speed-up in high-throughput substation communication scenarios, while still maintaining high detection accuracy and confidence. While many existing physics-based schemes are designed for deployment in control centers (due to their high computational requirement), ResiGate is designed as a security appliance that can be deployed on low-cost industrial computers at the edge of the smart grid so that it can detect local substation-level attacks in a timely manner. A key challenge for this is to continuously run the computationally demanding physics-based analysis to monitor the measurement data frequently transmitted in a typical substation. To provide high throughput without sacrificing accuracy, ResiGate uses machine learning to effectively filter out most of the non-suspicious (normal) data and thereby reducing the overall computational load, allowing efficient performance even with a high volume of network traffic. We implement ResiGate on a low-cost industrial computer and our experiments confirm that ResiGate can detect attacks with zero error while sustaining a high throughput.",
    "published_date": "2023-02-12",
    "pdf_link": "https://arxiv.org/pdf/2302.05949v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Smart Grid Security",
      "subdomain": "Substation Intrusion Detection",
      "specific_problem": "Bad data/false data injection detection in substation measurement traffic with high-throughput edge deployment",
      "attack_types": [
        "False Data Injection (FDIA)",
        "Malicious measurement manipulation",
        "Man-in-the-middle (measurement tampering)",
        "Malicious commands (not primary focus)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Gradient Boosted Decision Trees",
        "specific": "GBDT (scikit-learn GradientBoostingClassifier)",
        "novel_contribution": "Used as a lightweight, substation-specific ML filter to pre-screen measurement snapshots and reduce the load on physics-based bad data detection, enabling edge deployment with high throughput while preserving accuracy"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "ResiGate synthetic substation measurement dataset (3-substation test network)",
        "type": "synthetic",
        "domain": "power_system_measurements",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "detection error rate",
      "throughput (snapshots per second)",
      "latency (per-snapshot classification time)",
      "computational load/latency of physics-based analysis"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a hybrid ML + physics-based IDS detect substation-level bad data with near-zero error while sustaining high-throughput on low-cost edge hardware?",
        "Can a lightweight ML filter (GBDT) effectively reduce the computational load on physics-based bad data detection without sacrificing accuracy?",
        "How robust is a substation-specific ML filter trained on normal configuration when evaluated on different substation configurations?"
      ],
      "gaps_identified": [
        "Existing physics-based schemes are designed for control centers and are computationally demanding, making them unsuitable for high-frequency substation data at the edge.",
        "Cyber-rule-based IDSs often fail to detect attacks that use legitimate-looking measurements.",
        "ML-only IDS approaches lack assurance; even small error rates can accumulate over long-term monitoring of many substations.",
        "Centralized detection misses high-frequency substation data due to bandwidth and latency constraints."
      ],
      "limitations": [
        "Assumes the attacker is not powerful enough to launch stealthy FDIAs; handling stealthy FDIA is deferred to future work.",
        "ML model was trained only on the normal configuration; generalization to all configurations not exhaustively addressed.",
        "Comparative evaluation across multiple ML algorithms is left for future work.",
        "Physics-based state estimation introduces higher latency; periodic invocation is required to catch ML false negatives.",
        "Requires accurate, up-to-date substation topology/configuration for Pandapower modeling."
      ],
      "future_work": [
        "“We plan to investigate the upgrading of the physics-analysis component to an advanced state estimator that can handle stealthy FDIA in a future work.”",
        "Comparative performance study among other ML algorithms beyond GBDT.",
        "Explore score-based ML classifiers, thresholding strategies, and ensemble models to balance false negatives and throughput.",
        "Expand training to cover more (or all) substation configurations and evaluate under broader operating conditions."
      ],
      "motivation": "Enable timely and accurate detection of local substation-level false measurement attacks at the edge by combining efficient ML filtering with accurate physics-based analysis, overcoming the computational burden and centralization constraints of traditional physics-based IDS approaches.",
      "potential_research_ideas": [
        "Develop a physics-informed ML model (e.g., hybrid GBDT + power-flow residual features or PINNs) to further reduce reliance on full state estimation while improving robustness.",
        "Design online/continual learning to adapt the ML filter to changing substation configurations and seasonal load patterns without extensive retraining.",
        "Incorporate adversarial training and robust optimization to detect stealthy/structured FDIA crafted to evade both ML and classical residual tests.",
        "Use uncertainty estimation or conformal prediction to route only low-confidence snapshots to the physics-based module.",
        "Federated or multi-substation collaborative learning to share knowledge while preserving local specificity and privacy.",
        "Joint scheduling/queuing optimization that dynamically budgets physics-based checks under bursty traffic conditions."
      ],
      "architectural_improvement_recommendations": [
        "Replace binary ML outputs with calibrated anomaly scores and use dynamic thresholds conditioned on operating regime to control PSME load.",
        "Adopt cost-sensitive training emphasizing false negative penalties; include synthetic hard negatives crafted via power-flow constraints.",
        "Integrate fast residual-based pre-checks (e.g., linearized DC residuals) before full nonlinear WLS to further reduce PSME latency.",
        "Employ ensemble models (e.g., gradient boosting + isolation forest) with quorum-based escalation to PSME.",
        "Automate topology/parameter synchronization between Zeek-derived device status and Pandapower models to minimize model staleness.",
        "Implement streaming feature engineering (temporal deltas, rate-of-change) to improve ML discrimination of transient anomalies."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "Zeek 2.6",
        "pandapower 2.1.0",
        "scikit-learn"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Low-cost industrial PC (DA Vision MPCX-H110), Intel Core i7-6700T (4 cores @ 2.8 GHz, 8 MB cache), 16 GB RAM, Ubuntu 18.04. ~20 ms per snapshot for ML filtering (~100 measurements). Sustained up to 61 snapshots/second in experiments."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Edge security appliance on substation network (industrial computer receiving mirrored traffic from industrial switches).",
      "scalability_discussed": true,
      "inference_time": "≈20 ms per snapshot for GBDT classification (~100 measurement points).",
      "deployment_challenges": [
        "Maintaining accurate, up-to-date substation topology and parameters in the physics model.",
        "Handling bursty high-throughput when multiple IEDs enter fast transmission mode.",
        "Balancing false negatives vs. physics-based workload; scheduling periodic PSME checks.",
        "Robustness to configuration changes not seen during training.",
        "Hardening the edge appliance and ensuring full network visibility via mirror ports."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Novel hybrid design (ResiGate) that augments accurate but computationally demanding physics-based analysis with an efficient ML filtering module to enable edge deployment in substations.",
      "“Handling high-throughput of up to 61 snapshots per second” on a low-cost industrial computer while maintaining the confidence and accuracy of traditional physics-based methods.",
      "Open-source, ready-to-use tool integrating Pandapower (power system simulator) with Zeek (network monitoring).",
      "Implementation on a low-cost industrial computer and evaluation on a 3-substation test network (32 IEDs, 18 load points).",
      "Lightweight ML filter (GBDT) trained on substation-specific synthetic data; “about 20 milliseconds for online classification of a snapshot of over 100 measurement points.”",
      "Experiments confirm ResiGate can “detect attacks with zero error while sustaining a high throughput.”"
    ]
  },
  {
    "arxiv_id": "2302.11418v1",
    "title": "Federated Radio Frequency Fingerprinting with Model Transfer and Adaptation",
    "authors": "Chuanting Zhang; Shuping Dang; Junqing Zhang; Haixia Zhang; Mark A. Beach",
    "abstract": "The Radio frequency (RF) fingerprinting technique makes highly secure device authentication possible for future networks by exploiting hardware imperfections introduced during manufacturing. Although this technique has received considerable attention over the past few years, RF fingerprinting still faces great challenges of channel-variation-induced data distribution drifts between the training phase and the test phase. To address this fundamental challenge and support model training and testing at the edge, we propose a federated RF fingerprinting algorithm with a novel strategy called model transfer and adaptation (MTA). The proposed algorithm introduces dense connectivity among convolutional layers into RF fingerprinting to enhance learning accuracy and reduce model complexity. Besides, we implement the proposed algorithm in the context of federated learning, making our algorithm communication efficient and privacy-preserved. To further conquer the data mismatch challenge, we transfer the learned model from one channel condition and adapt it to other channel conditions with only a limited amount of information, leading to highly accurate predictions under environmental drifts. Experimental results on real-world datasets demonstrate that the proposed algorithm is model-agnostic and also signal-irrelevant. Compared with state-of-the-art RF fingerprinting algorithms, our algorithm can improve prediction performance considerably with a performance gain of up to 15\\%.",
    "published_date": "2023-02-22",
    "pdf_link": "https://arxiv.org/pdf/2302.11418v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Wireless and Communications Security",
      "subdomain": "Physical-layer authentication / RF device identification",
      "specific_problem": "RF fingerprinting for device identification under channel-variation-induced distribution drift with privacy-preserving federated training and rapid model adaptation",
      "attack_types": [
        "spoofing",
        "impersonation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Dense connectivity (DenseNet-style) CNN with three conv layers and three dense blocks",
        "novel_contribution": "Introduces dense connectivity into RF fingerprinting to enhance feature reuse/propagation and reduce model complexity (~80k params)."
      },
      {
        "type": "primary",
        "category": "Metric Learning",
        "specific": "Triplet loss",
        "novel_contribution": "Batch-wise triplet generation on learned embeddings for device-discriminative features."
      },
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "FedAvg-style synchronous aggregation",
        "novel_contribution": "Federated RF fingerprinting across edge cloud units without sharing raw IQ data; communication-efficient and privacy-preserving."
      },
      {
        "type": "primary",
        "category": "Transfer Learning",
        "specific": "Model Transfer and Adaptation (MTA)",
        "novel_contribution": "Transfer a model trained under one channel condition and adapt with limited target-environment samples to mitigate distribution drift; model-agnostic and signal-irrelevant."
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "Two-layer MLP (512 -> 4)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Two conv layers + two linear layers (16, 64, 512, 4)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet-style (four convolutional blocks + linear layer, feature maps 32)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Federated learning",
      "Transfer learning",
      "Metric learning"
    ],
    "datasets": [
      {
        "name": "Public RF fingerprinting IQ dataset (USRP X310/B210; WiFi, 4G LTE, 5G NR; two days) from [10]",
        "type": "public",
        "domain": "rf_iq_samples",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Centralized ResNet",
        "paper_reference": null,
        "metric": "Accuracy (4G)",
        "their_result": "0.9343 (Proposed-MTA); 0.8683 (Proposed-Basic)",
        "baseline_result": "0.8257"
      },
      {
        "method_name": "Federated ResNet",
        "paper_reference": null,
        "metric": "Accuracy (4G)",
        "their_result": "0.9343 (Proposed-MTA); 0.8683 (Proposed-Basic)",
        "baseline_result": "0.7245"
      },
      {
        "method_name": "Federated CNN",
        "paper_reference": null,
        "metric": "Accuracy (4G)",
        "their_result": "0.9343 (Proposed-MTA); 0.8683 (Proposed-Basic)",
        "baseline_result": "0.7895"
      },
      {
        "method_name": "Federated MLP",
        "paper_reference": null,
        "metric": "Accuracy (4G)",
        "their_result": "0.9343 (Proposed-MTA); 0.8683 (Proposed-Basic)",
        "baseline_result": "0.7110"
      },
      {
        "method_name": "Centralized ResNet",
        "paper_reference": null,
        "metric": "Accuracy (5G)",
        "their_result": "0.9105 (Proposed-Basic); 0.9100 (Proposed-MTA)",
        "baseline_result": "0.8375"
      },
      {
        "method_name": "Federated ResNet",
        "paper_reference": null,
        "metric": "Accuracy (5G)",
        "their_result": "0.9105 (Proposed-Basic); 0.9100 (Proposed-MTA)",
        "baseline_result": "0.7448"
      },
      {
        "method_name": "Federated CNN",
        "paper_reference": null,
        "metric": "Accuracy (5G)",
        "their_result": "0.9105 (Proposed-Basic); 0.9100 (Proposed-MTA)",
        "baseline_result": "0.7725"
      },
      {
        "method_name": "Federated MLP",
        "paper_reference": null,
        "metric": "Accuracy (5G)",
        "their_result": "0.9105 (Proposed-Basic); 0.9100 (Proposed-MTA)",
        "baseline_result": "0.7123"
      },
      {
        "method_name": "Centralized ResNet",
        "paper_reference": null,
        "metric": "Accuracy (WiFi)",
        "their_result": "0.9800 (Proposed-MTA); 0.7508 (Proposed-Basic)",
        "baseline_result": "0.9690"
      },
      {
        "method_name": "Federated ResNet",
        "paper_reference": null,
        "metric": "Accuracy (WiFi)",
        "their_result": "0.9800 (Proposed-MTA); 0.7508 (Proposed-Basic)",
        "baseline_result": "0.7688"
      },
      {
        "method_name": "Federated CNN",
        "paper_reference": null,
        "metric": "Accuracy (WiFi)",
        "their_result": "0.9800 (Proposed-MTA); 0.7508 (Proposed-Basic)",
        "baseline_result": "0.8213"
      },
      {
        "method_name": "Federated MLP",
        "paper_reference": null,
        "metric": "Accuracy (WiFi)",
        "their_result": "0.9800 (Proposed-MTA); 0.7508 (Proposed-Basic)",
        "baseline_result": "0.7205"
      },
      {
        "method_name": "Centralized ResNet",
        "paper_reference": null,
        "metric": "Accuracy (Hybrid 4G+5G+WiFi)",
        "their_result": "0.9003 (Proposed-MTA); 0.7721 (Proposed-Basic)",
        "baseline_result": "0.7268"
      },
      {
        "method_name": "Federated ResNet",
        "paper_reference": null,
        "metric": "Accuracy (Hybrid 4G+5G+WiFi)",
        "their_result": "0.9003 (Proposed-MTA); 0.7721 (Proposed-Basic)",
        "baseline_result": "0.7692"
      },
      {
        "method_name": "Federated CNN",
        "paper_reference": null,
        "metric": "Accuracy (Hybrid 4G+5G+WiFi)",
        "their_result": "0.9003 (Proposed-MTA); 0.7721 (Proposed-Basic)",
        "baseline_result": "0.7553"
      },
      {
        "method_name": "Federated MLP",
        "paper_reference": null,
        "metric": "Accuracy (Hybrid 4G+5G+WiFi)",
        "their_result": "0.9003 (Proposed-MTA); 0.7721 (Proposed-Basic)",
        "baseline_result": "0.6923"
      },
      {
        "method_name": "Federated ResNet + MTA",
        "paper_reference": null,
        "metric": "Accuracy (4G; effect of MTA)",
        "their_result": "N/A (not the proposed model)",
        "baseline_result": "0.8255 (with MTA) vs 0.7245 (without)"
      },
      {
        "method_name": "Federated ResNet + MTA",
        "paper_reference": null,
        "metric": "Accuracy (Hybrid; effect of MTA)",
        "their_result": "N/A (not the proposed model)",
        "baseline_result": "0.7847 (with MTA) vs 0.7692 (without)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Model size (# parameters)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How to perform RF device identification while preserving data privacy across distributed edge units?",
        "How to mitigate channel-variation-induced data distribution drift between training and testing for RF fingerprinting?",
        "Can dense connectivity reduce CNN model complexity while improving RF fingerprinting accuracy?",
        "Can a learned model be transferred and adapted efficiently to new channel conditions with limited data?"
      ],
      "gaps_identified": [
        "Centralized RF fingerprinting requires raw data transfer to a server, conflicting with privacy requirements.",
        "Significant data distribution drift between training and testing due to time-varying channels degrades performance.",
        "Deep CNNs for RF fingerprinting can be time-consuming and parameter-heavy to train.",
        "Earlier methods relied on handcrafted features with non-deterministic and task-dependent significance."
      ],
      "limitations": [
        "Communication overhead remains a concern; authors note future work to further reduce communication.",
        "Evaluation uses four devices and specific USRP hardware; broader scalability to larger device populations is not demonstrated in the presented results."
      ],
      "future_work": [
        "Further reducing the communication (overhead/cost) in federated training and adaptation."
      ],
      "motivation": "Enhance wireless/IoT network security via RF fingerprinting without sharing raw IQ data, improve robustness to environment-induced distribution drifts, and reduce model complexity for efficient edge deployment.",
      "potential_research_ideas": [
        "Unsupervised or semi-supervised target-domain adaptation for RF fingerprinting to reduce or remove labeled target data needs during MTA.",
        "Channel-invariant representation learning using contrastive/self-supervised objectives on IQ streams across channel conditions.",
        "Meta-learning or parameter-efficient adaptation (adapters/LoRA) to further reduce adaptation data and communication.",
        "Incorporate complex-valued neural networks or transformers tailored to IQ sequences for richer feature extraction.",
        "Personalized federated learning for site-specific calibration while maintaining a strong global model.",
        "Differential privacy or secure aggregation to strengthen privacy guarantees in FL for IQ data.",
        "Adversarial robustness evaluation and defenses against RF spoofing or adversarial perturbations in the IQ domain.",
        "Scalable benchmarking across hundreds/thousands of devices and diverse hardware/channel settings."
      ],
      "architectural_improvement_recommendations": [
        "Add attention mechanisms or lightweight transformer encoders over temporal IQ windows to capture long-range dependencies.",
        "Use parameter-efficient fine-tuning (adapters, low-rank updates) for MTA to cut communication and adaptation cost.",
        "Apply normalization/conditioning layers (e.g., FiLM, AdaIN) to explicitly factor out channel effects.",
        "Adopt communication-efficient FL optimizers and compressors (FedProx/FedAdam, quantization/sparsification).",
        "Explore complex-valued convolutions and activations aligned with IQ signal properties.",
        "Combine triplet loss with supervised cross-entropy or use InfoNCE-style contrastive losses for more stable training."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Local training: Adam optimizer, 10 local epochs, batch size 10, learning rate 1e-4; 50 global rounds; 10% client participation per round; model ~80k parameters. Hardware specifics and runtime not reported."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Edge network with multiple edge cloud units and a central server (federated learning).",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Channel variation causes distribution drift between training and deployment environments.",
        "Data privacy constraints disallow raw IQ data sharing.",
        "Communication overhead of federated training and adaptation.",
        "Requires limited target-environment samples for effective adaptation."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "A federated RF fingerprinting algorithm that preserves data privacy by avoiding raw data centralization.",
      "A dense-connectivity CNN framework tailored to RF fingerprinting, reducing model complexity (~80k params) while improving accuracy.",
      "Model Transfer and Adaptation (MTA) strategy to adapt a learned model to new channel conditions with limited data; model-agnostic and signal-irrelevant.",
      "Empirical validation on real-world IQ datasets across WiFi/4G/5G, showing up to ~15% accuracy gains over state-of-the-art baselines; highest accuracy on all tested signals with MTA."
    ]
  },
  {
    "arxiv_id": "2304.03657v2",
    "title": "SCART: Simulation of Cyber Attacks for Real-Time",
    "authors": "Eliron Rahimi; Kfir Girstein; Roman Malits; Avi Mendelson",
    "abstract": "Real-Time systems are essential for promptly responding to external stimuli and completing tasks within predefined time constraints. Ensuring high reliability and robust security in these systems is therefore critical. This requires addressing reliability-related events, such as sensor failures and subsystem malfunctions, as well as cybersecurity threats. This paper introduces a novel cyber-attack simulation infrastructure designed to enhance simulation environments for real-time systems. The proposed infrastructure integrates reliability-oriented events and sophisticated cybersecurity attacks, including those targeting single or multiple sensors. We present the SCART framework and dataset, addressing a central challenge in real-time systems: the lack of scalable testing environments to assess the impact of cyber-attacks on critical systems and evaluate the effectiveness of defensive mechanisms. This limitation arises from the inherent risks of executing attacks or inducing malfunctions in operational systems. By leveraging simulation-based capabilities, the framework generates training and testing data for data-driven approaches, such as machine learning, which are otherwise difficult to train or validate under live conditions. This development enables the exploration of innovative methodologies to strengthen the resilience of real-time systems against cyber-attacks. The comprehensive functionalities of the proposed infrastructure improve the accuracy and security of critical systems while fostering the creation of advanced algorithms. These advancements hold the potential to significantly enhance anomaly detection in real-time systems and fortify their defenses against cyber threats. Our code is available at https://github.com/kfirgirstein/SCART.",
    "published_date": "2023-04-07",
    "pdf_link": "https://arxiv.org/pdf/2304.03657v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cyber-Physical Systems Security",
      "subdomain": "Embedded/Real-Time Systems and UAV Security",
      "specific_problem": "Simulation-based injection of cyber-attacks and reliability faults into real-time system simulators to generate datasets and evaluate anomaly detection",
      "attack_types": [
        "GPS spoofing",
        "sensor value manipulation/tampering (single- and multi-sensor)",
        "controller/management interface compromise",
        "firmware-level attack (supply chain/HTH insertion)",
        "internal communication/bus manipulation (proxy/relay)",
        "environmental attacks (e.g., visual adversarial patches)",
        "multi-vector coordinated attacks"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Simulation-based data generation (discrete event simulation)",
        "specific": null,
        "novel_contribution": "SCART attack layer and scenario mechanism (Listeners, Conditions, Actions) to inject cyber-attacks into real-time simulators and generate multi-sensor time-series data"
      },
      {
        "type": "baseline",
        "category": "Time-series anomaly detection",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "SCART multi-sensor time-series dataset",
        "type": "synthetic",
        "domain": "uav_sensor_time_series",
        "link": "https://github.com/kfirgirstein/SCART",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "SWaT (Secure Water Treatment)",
        "type": "unknown",
        "domain": "industrial_control_system_sensors",
        "link": null,
        "is_new_contribution": false,
        "availability": "unknown"
      },
      {
        "name": "SKAB",
        "type": "unknown",
        "domain": "unknown",
        "link": null,
        "is_new_contribution": false,
        "availability": "unknown"
      },
      {
        "name": "Numenta Anomaly Benchmark (NAB)",
        "type": "unknown",
        "domain": "general_time_series",
        "link": null,
        "is_new_contribution": false,
        "availability": "unknown"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "true positive rate (anomalies)",
      "true negative rate (normal instances)",
      "detection rate per class"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can an external SCART attack layer augment real-time simulators to safely and realistically inject cyber-attacks and reliability faults?",
        "How well do existing time-series anomaly detection algorithms detect anomalies in SCART-generated data?"
      ],
      "gaps_identified": [
        "“the lack of scalable testing environments to assess the impact of cyber-attacks on critical systems and evaluate the effectiveness of defensive mechanisms.”",
        "Risks of executing attacks or inducing malfunctions in operational systems prevent live testing/training.",
        "Existing simulators typically focus on normal conditions rather than simulating failures or security attacks.",
        "Purely synthetic data often fails to accurately represent anomalies from real-world/cyberattack phenomena.",
        "Co-simulation and multi-agent modeling face challenges for complex real-time systems.",
        "Existing benchmarks may lack robustness and scalability for certain research purposes."
      ],
      "limitations": [
        "“the experiments and evaluations in this work primarily focus on attacks through communication interfaces.”",
        "Assumption in scenario engine: “we assume only one anomaly occurs per run.”",
        "Evaluation uses existing anomaly detection algorithms; specific algorithms are not enumerated in the provided text.",
        "Simulation-based evaluation; no real hardware deployment reported in the provided text."
      ],
      "future_work": [],
      "motivation": "Enable safe, scalable, and realistic evaluation of cyber-attacks and defensive mechanisms for real-time systems, and generate training/testing data for ML-based anomaly detection that is otherwise hard to obtain under live conditions.",
      "potential_research_ideas": [
        "Automated adversary/scenario generation using reinforcement learning or search-based fuzzing to discover hard-to-detect multi-sensor attacks.",
        "Extend SCART beyond UAVs to other CPS domains (automotive, industrial robotics, medical devices) and compare cross-domain transferability of detectors.",
        "Support multiple concurrent and cascading anomalies to reflect complex real incidents and evaluate detector robustness.",
        "Generate paired HITL datasets to study sim-to-real transfer for anomaly detection.",
        "Create a standardized benchmark suite with clearly defined splits, labels, and evaluation protocols derived from SCART scenarios.",
        "Causality-aware anomaly detection leveraging SCART’s ground-truth of injected causes and affected signals.",
        "Adversarial training of detectors using SCART-generated curricula of progressively harder attacks.",
        "Formal verification-in-the-loop to validate that injected attacks meet specified temporal/causal properties."
      ],
      "architectural_improvement_recommendations": [
        "Introduce a scenario DSL/configuration language with validators for Listeners–Conditions–Actions to ease authoring and reuse.",
        "Allow concurrent scenarios with a scheduler and conflict-resolution policies to model overlapping attacks.",
        "Emit detailed ground-truth metadata (attack graph, affected components, timestamps) for explainable AD training.",
        "Provide first-class adapters for ROS2/MAVLink and standardized sensor/bus interfaces to ease porting across simulators.",
        "Modular plug-ins for attack injection points (firmware, bus, controller, environment) via a uniform API.",
        "Dataset export pipeline to common AD formats (e.g., NAB-like CSV with labels) and streaming sinks (Kafka) for online AD.",
        "Deterministic replay and time-synchronization tools to reproduce scenarios across Gazebo, AirSim, and jMAVSim.",
        "Configuration for multiple anomalies per run and stochastic parameterization to improve dataset diversity."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/kfirgirstein/SCART",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Digital twin simulators for PX4 UAVs (Gazebo, AirSim, jMAVSim); SITL/HITL context discussed",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Executing attacks on operational systems is risky; simulations are used instead.",
        "Portability/integration across heterogeneous simulators and interfaces (sensors, buses).",
        "Single-anomaly-per-run assumption may limit realism for complex incidents.",
        "Bridging sim-to-real gaps when transferring trained detectors to real deployments."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introducing the SCART environment and demonstrating its efficiency and capabilities.",
      "Abstract framework architecture to integrate a cyber-attack layer into real-time system simulations.",
      "Proof-of-concept integration with a digital twin simulation for PX4 drones.",
      "Development of a multi-sensor time-series dataset for anomaly detection training/testing.",
      "Execution of 2,048 attack configurations across multiple simulators (Gazebo, AirSim, jMAVSim).",
      "Empirical evaluation where “algorithms identified approximately 86% of non-anomalous instances and 78% of anomalous instances.”"
    ]
  },
  {
    "arxiv_id": "2303.14241v2",
    "title": "Data Depth and Core-based Trend Detection on Blockchain Transaction Networks",
    "authors": "Jason Zhu; Arijit Khan; Cuneyt Gurcan Akcora",
    "abstract": "Blockchains are significantly easing trade finance, with billions of dollars worth of assets being transacted daily. However, analyzing these networks remains challenging due to the sheer volume and complexity of the data. We introduce a method named InnerCore that detects market manipulators within blockchain-based networks and offers a sentiment indicator for these networks. This is achieved through data depth-based core decomposition and centered motif discovery, ensuring scalability. InnerCore is a computationally efficient, unsupervised approach suitable for analyzing large temporal graphs. We demonstrate its effectiveness by analyzing and detecting three recent real-world incidents from our datasets: the catastrophic collapse of LunaTerra, the Proof-of-Stake switch of Ethereum, and the temporary peg loss of USDC - while also verifying our results against external ground truth. Our experiments show that InnerCore can match the qualified analysis accurately without human involvement, automating blockchain analysis in a scalable manner, while being more effective and efficient than baselines and state-of-the-art attributed change detection approach in dynamic graphs.",
    "published_date": "2023-03-24",
    "pdf_link": "https://arxiv.org/pdf/2303.14241v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain/Cryptocurrency Security",
      "subdomain": "On-chain Transaction and Market Abuse Analysis",
      "specific_problem": "Unsupervised detection of market manipulators and significant trend changes in blockchain transaction networks via depth-based core decomposition and motif-centric ranking",
      "attack_types": [
        "market_manipulation",
        "fraud/e-crime",
        "illicit_transactions"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Graph Core Decomposition / Statistical Depth",
        "specific": "Mahalanobis depth; AlphaCore-style depth-based core decomposition adapted as InnerCore",
        "novel_contribution": "InnerCore: data depth-based core discovery on directed, weighted temporal graphs to identify influential traders; defines InnerCore expansion/decay sentiment metrics"
      },
      {
        "type": "primary",
        "category": "Graph Motif Mining and Ranking",
        "specific": "Centered motif discovery with NF-IAF score percentile ranking",
        "novel_contribution": "Centered-motif approach filters address roles and ranks anomalous addresses without supervision to surface market manipulators"
      },
      {
        "type": "baseline",
        "category": "Graph Core Decomposition",
        "specific": "graph k-core",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph Core Decomposition",
        "specific": "AlphaCore",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Dynamic Graph Change/Anomaly Detection",
        "specific": "State-of-the-art attributed change detection in dynamic graphs (citation [20])",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Ethereum daily transaction network snapshots",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "USDC stablecoin transaction network (temporary peg loss, March 2023)",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Terra/Luna-UST transaction network (LunaTerra collapse, May 2022)",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Ethereum network around Proof-of-Stake switch (The Merge, Sept 2022)",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "graph k-core",
        "paper_reference": "[9]",
        "metric": null,
        "their_result": "“InnerCore analysis reduces large graphs having more than 400K nodes and 1M edges to an induced subgraph of less than 300 nodes and 90K edges” and achieves ∼4 s/day runtime on ~500K node graphs",
        "baseline_result": null
      },
      {
        "method_name": "AlphaCore",
        "paper_reference": "[67]",
        "metric": null,
        "their_result": "Reported as more effective and efficient than AlphaCore on evaluated tasks",
        "baseline_result": null
      },
      {
        "method_name": "Attributed change detection in dynamic graphs (SoTA)",
        "paper_reference": "[20]",
        "metric": null,
        "their_result": "Reported as more effective and efficient than the state-of-the-art attributed change detection approach",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "runtime",
      "scalability (node/edge reduction)",
      "qualitative detection against external ground truth events",
      "rank-based anomaly surfacing (NF-IAF percentile)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Detect the node set S_t at time t whose behavior characterizes the future success of the underlying asset at t′>t",
        "Categorize nodes’ behavior in terms of the future health and success of the underlying asset"
      ],
      "gaps_identified": [
        "Analyzing blockchain networks is challenging due to scale and anonymous actors; need scalable real-time analysis",
        "Traditional k-core ignores direction, weights, and features; need feature-aware core methods",
        "Scarcity of qualified, timely human analysis for rapidly evolving on-chain events"
      ],
      "limitations": [
        "Predictions cannot anticipate malicious transactions originating externally; focus is on detection: “predictions can only go so far… At most, what we can do is to detect e-crime transactions”",
        "Method operates on daily snapshots (may miss sub-daily dynamics) [implied by design]"
      ],
      "future_work": [],
      "motivation": "Enable scalable, unsupervised, and explainable analysis of large temporal blockchain graphs to detect e-crime and influential market manipulators and provide sentiment indicators, reducing analyst burden and time-to-insight.",
      "potential_research_ideas": [
        "Extend InnerCore to streaming/online setting with minute-level snapshots and near-real-time alerts",
        "Multi-chain joint analysis (cross-chain bridges) to detect coordinated manipulation across ecosystems",
        "Learn adaptive depth thresholds (epsilon) via change-point detection or Bayesian optimization using weak signals (price, volume)",
        "Combine centered motifs with higher-order temporal motifs and causal graphs to better isolate manipulation patterns",
        "Integrate off-chain signals (news, social, exchange order books) for multimodal anomaly ranking",
        "Evaluate adversarial robustness (attackers perturbing transaction patterns to evade depth/motif scores) and design defenses",
        "Develop a benchmarking suite with labeled manipulation events and synthetic injects for rigorous quantitative evaluation"
      ],
      "architectural_improvement_recommendations": [
        "Use robust covariance estimators for depth (e.g., Minimum Covariance Determinant) to handle heavy-tailed transaction features",
        "Implement incremental/online covariance and core updates to support streaming graphs",
        "Auto-tune depth threshold epsilon via validation on historical event windows with change-point criteria",
        "Augment node features with contract semantics (ERC types), DeFi role tags, and temporal decay factors",
        "Incorporate multi-resolution cores (hourly/daily/weekly) and fuse signals for more stable sentiment indicators",
        "Leverage parallel motif counting and sketching (e.g., HyperLogLog for neighbor stats) for further speed-ups"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Runs in ∼4 seconds per daily Ethereum graph with ∼500K nodes and >1M edges; no GPU requirements stated"
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Blockchain analytics pipelines for public chains (e.g., Ethereum, Terra)",
      "scalability_discussed": true,
      "inference_time": "~4 seconds per daily Ethereum snapshot (~500K nodes, >1M edges)",
      "deployment_challenges": [
        "Handling massive, rapidly evolving graphs",
        "Anonymity of addresses and limited ground truth labels",
        "Need for real-time or near-real-time processing",
        "Selecting thresholds and parameters across assets with different scales"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "InnerCore: a data depth-based core discovery method to identify influential traders in blockchain networks",
      "Explainable behavior via InnerCore expansion and decay sentiment metrics",
      "Unsupervised address discovery using centered motifs and NF-IAF ranking to detect manipulators/e-crime",
      "Scalability: seconds-level runtime on large daily graphs; more effective and efficient than baselines and state-of-the-art attributed change detection; validated on LunaTerra collapse, Ethereum PoS switch, and USDC peg loss with external ground truth verification"
    ]
  },
  {
    "arxiv_id": "2303.09045v1",
    "title": "Web and Mobile Platforms for Managing Elections based on IoT And Machine Learning Algorithms",
    "authors": "G. M. I. K. Galagoda; W. M. C. A. Karunarathne; R. S. Bates; K. M. H. V. P. Gangathilaka; Kanishka Yapa; Erandika Gamage",
    "abstract": "The global pandemic situation has severely affected all countries. As a result, almost all countries had to adjust to online technologies to continue their processes. In addition, Sri Lanka is yearly spending ten billion on elections. We have examined a proper way of minimizing the cost of hosting these events online. To solve the existing problems and increase the time potency and cost reduction we have used IoT and ML-based technologies. IoT-based data will identify, register, and be used to secure from fraud, while ML algorithms manipulate the election data and produce winning predictions, weather-based voters attendance, and election violence. All the data will be saved in cloud computing and a standard database to store and access the data. This study mainly focuses on four aspects of an E-voting system. The most frequent problems across the world in E-voting are the security, accuracy, and reliability of the systems. E-government systems must be secured against various cyber-attacks and ensure that only authorized users can access valuable, and sometimes sensitive information. Being able to access a system without passwords but using biometric details has been there for a while now, however, our proposed system has a different approach to taking the credentials, processing, and combining the images, reformatting and producing the output, and tracking. In addition, we ensure to enhance e-voting safety. While ML-based algorithms use different data sets and provide predictions in advance.",
    "published_date": "2023-03-16",
    "pdf_link": "https://arxiv.org/pdf/2303.09045v1",
    "paper_types": [
      "new_technique"
    ],
    "security_domain": {
      "primary": "Application Security",
      "subdomain": "E-voting Security",
      "specific_problem": "Design of a secure web/mobile e-voting management platform using IoT-based biometric authentication and ML to predict election results, voter turnout (weather-based), and election violence risk",
      "attack_types": [
        "cyber-attacks (general)",
        "fraudulent voting/identity fraud",
        "unauthorized access"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Unspecified",
        "specific": null,
        "novel_contribution": "Integrated ML election result prediction within an e-voting management platform; details of algorithm not specified"
      },
      {
        "type": "primary",
        "category": "Unspecified",
        "specific": null,
        "novel_contribution": "Weather-based voter attendance predictor using OpenWeather API features (visibility, humidity, temperature, wind speed, cloudiness)"
      },
      {
        "type": "primary",
        "category": "Unspecified",
        "specific": null,
        "novel_contribution": "Election violence risk prediction by area using historical incident data"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "User biometric fingerprints and facial images (enrollment)",
        "type": "private",
        "domain": "biometric_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Historical voting results and station attendance (Sri Lanka)",
        "type": "private",
        "domain": "election_results",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Weather data via OpenWeather API",
        "type": "public",
        "domain": "weather",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Historical election violence incidents by area (Sri Lanka)",
        "type": "private",
        "domain": "incident_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can IoT-based biometrics be used to securely authorize voters for e-voting while reducing fraud?",
        "Can ML models predict election results partway through the election using historical data?",
        "Can weather data be used to predict voter attendance at different locations?",
        "Can ML predict election violence risk by area to aid election management?",
        "Can an online platform significantly reduce the cost and time of conducting elections?"
      ],
      "gaps_identified": [
        "E-voting systems face challenges in security, accuracy, and reliability",
        "Need for robust e-voter authorization mechanisms beyond passwords (biometric-based)",
        "High financial cost of traditional elections",
        "Cybersecurity measures for e-government/e-voting systems need strengthening",
        "Observations from prior systems indicate shortcomings in electronic voting security and the need for voter-verifiable audit trails"
      ],
      "limitations": [],
      "future_work": [
        "Focus more on cybersecurity aspects, user authorization with biometric details, image processing technologies, cloud and database safety, and ethical hacking",
        "Further development of interactive dashboards and predictive models",
        "Collection and integration of more comprehensive historical datasets for training and validation"
      ],
      "motivation": "Minimize the high cost of elections, enable safe online election management during/after the pandemic, and address security/authorization challenges in e-voting while adding predictive analytics for planning.",
      "potential_research_ideas": [
        "Design and integrate end-to-end verifiable (E2E-V) cryptographic voting protocols with the proposed platform",
        "Develop privacy-preserving biometric authentication (e.g., cancellable biometrics, biometric template protection) to mitigate biometric leakage",
        "Create robust turnout and violence prediction pipelines with explainability (e.g., SHAP) and uncertainty quantification for operational decision-making",
        "Investigate causal effects of weather on turnout using causal inference to improve generalization across regions/elections",
        "Model concept drift across election cycles and regions with continual learning or domain adaptation",
        "Assess adversarial robustness of the ML components and add anomaly detection for data poisoning or spoofed inputs (e.g., fake weather data, manipulated incidents)",
        "Incorporate fairness auditing to ensure predictions do not systematically disadvantage specific regions or demographics",
        "Combine geospatial-temporal models (e.g., graph-based or spatiotemporal methods) for localized violence and turnout risk mapping",
        "Prototype federated learning for violence/turnout models across jurisdictions without centralizing sensitive data"
      ],
      "architectural_improvement_recommendations": [
        "Specify and implement a formal threat model and adopt cryptographic primitives (digital signatures, secure enclaves, E2E-V with public audit)",
        "Add liveness detection and anti-spoofing for biometrics; store templates using secure enclaves/HSMs and template protection schemes",
        "Implement QR-based mobile authorization with mutual TLS, certificate pinning, and short-lived tokens",
        "Define ML pipelines with clear feature engineering, model selection (e.g., gradient boosting/GBDT, calibrated classifiers), cross-validation, and backtesting on historical elections",
        "Instrument telemetry and MLOps (data versioning, model monitoring, drift detection) for production robustness",
        "Integrate explainability dashboards and uncertainty estimates for admin decisions",
        "Harden cloud and database with least-privilege IAM, encrypted storage/transport, tamper-evident logs, and backup/DR procedures"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Conceptual cloud-based web and mobile system for election management with IoT biometric enrollment device",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Cyber-attacks against e-government/e-voting systems",
        "User authorization with biometric details and fraud prevention",
        "Cloud and database safety/security"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes an integrated web and mobile e-voting management platform leveraging IoT-based biometric authentication and QR-based mobile authorization",
      "Introduces three ML components: election result prediction, weather-based voter turnout prediction using OpenWeather variables, and election violence risk prediction by area",
      "Presents an overall system architecture with cloud database, APIs, and admin dashboards for election management",
      "Develops an IoT device for fingerprint capture and a workflow for biometric enrollment and verification"
    ]
  },
  {
    "arxiv_id": "2305.00632v1",
    "title": "Uncovering CWE-CVE-CPE Relations with Threat Knowledge Graphs",
    "authors": "Zhenpeng Shi; Nikolay Matyunin; Kalman Graffi; David Starobinski",
    "abstract": "Security assessment relies on public information about products, vulnerabilities, and weaknesses. So far, databases in these categories have rarely been analyzed in combination. Yet, doing so could help predict unreported vulnerabilities and identify common threat patterns. In this paper, we propose a methodology for producing and optimizing a knowledge graph that aggregates knowledge from common threat databases (CVE, CWE, and CPE). We apply the threat knowledge graph to predict associations between threat databases, specifically between products, vulnerabilities, and weaknesses. We evaluate the prediction performance both in closed world with associations from the knowledge graph, and in open world with associations revealed afterward. Using rank-based metrics (i.e., Mean Rank, Mean Reciprocal Rank, and Hits@N scores), we demonstrate the ability of the threat knowledge graph to uncover many associations that are currently unknown but will be revealed in the future, which remains useful over different time periods. We propose approaches to optimize the knowledge graph, and show that they indeed help in further uncovering associations.",
    "published_date": "2023-05-01",
    "pdf_link": "https://arxiv.org/pdf/2305.00632v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Intelligence and Threat Modeling",
      "specific_problem": "Predicting and uncovering associations among CVE (vulnerabilities), CWE (weaknesses), and CPE (products) using a threat knowledge graph and link prediction",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Knowledge Graph Embedding",
        "specific": "TransE",
        "novel_contribution": "Applied to a threat knowledge graph constructed from CVE, CWE, CPE (plus optimizations) to predict future CVE-CPE and CVE-CWE associations; shown to perform best among compared KGE models for this task"
      },
      {
        "type": "baseline",
        "category": "Knowledge Graph Embedding",
        "specific": "DistMult",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Knowledge Graph Embedding",
        "specific": "ComplEx",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised"
    ],
    "datasets": [
      {
        "name": "CVE (Common Vulnerabilities and Exposures)",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://cve.mitre.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CWE (Common Weakness Enumeration)",
        "type": "public",
        "domain": "weakness_taxonomy",
        "link": "https://cwe.mitre.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CPE (Common Platform Enumeration)",
        "type": "public",
        "domain": "product_platforms",
        "link": "https://nvd.nist.gov/products/cpe",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NVD associations (CVE–CWE–CPE links)",
        "type": "public",
        "domain": "vulnerability_knowledge_associations",
        "link": "https://nvd.nist.gov",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CAPEC (Common Attack Pattern Enumeration and Classification)",
        "type": "public",
        "domain": "attack_pattern_taxonomy",
        "link": "https://capec.mitre.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CVSS Vectors",
        "type": "public",
        "domain": "severity_scoring",
        "link": "https://www.first.org/cvss/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Threat Knowledge Graph (snapshot as of Aug 4, 2021)",
        "type": "synthetic",
        "domain": "threat_knowledge_graph",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Threat Knowledge Graph (snapshot as of Mar 29, 2022)",
        "type": "synthetic",
        "domain": "threat_knowledge_graph",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "DistMult",
        "paper_reference": null,
        "metric": "Rank-based metrics (Mean Rank, Mean Reciprocal Rank, Hits@N)",
        "their_result": "Authors report TransE performs best; e.g., \"achieving a 0.606 Hits@10 score in predicting CVE-CPE associations\" (closed-world).",
        "baseline_result": null
      },
      {
        "method_name": "ComplEx",
        "paper_reference": null,
        "metric": "Rank-based metrics (Mean Rank, Mean Reciprocal Rank, Hits@N)",
        "their_result": "Authors report TransE performs best for this task.",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Mean Rank (MR)",
      "Mean Reciprocal Rank (MRR)",
      "Hits@N (Hits@10)",
      "Precision",
      "Recall",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a threat knowledge graph aggregating CVE, CWE, and CPE uncover and predict associations that are not yet reported?",
        "Which knowledge graph embedding model (TransE, DistMult, ComplEx) performs best for predicting CVE–CPE and CVE–CWE associations?",
        "How well does the model perform under closed-world versus open-world (future data) evaluation?",
        "Do knowledge graph optimizations (e.g., removing obsolete entries, integrating CAPEC and CVSS) improve predictive performance?"
      ],
      "gaps_identified": [
        "Threat databases (CVE, CWE, CPE) have rarely been analyzed in combination.",
        "NVD associations are manually curated and are incomplete at any given time due to vetting delays.",
        "Prior automated methods often treat CVE entries independently, making implicit relations hard to identify.",
        "Previous knowledge-graph-based works either excluded CPE or evaluated only under closed-world assumptions, leaving open-world predictive validity unclear.",
        "Threat databases can be inconsistent and not readily usable without processing and normalization."
      ],
      "limitations": [
        "Ground truth for open-world evaluation depends on when NVD associations are added; incompleteness may affect measured performance.",
        "Performance and predictions rely on the quality and consistency of public databases (CVE/CWE/CPE/NVD).",
        "Threshold selection is required to convert rank scores to binary predictions; operating point sensitivity is not fully detailed in the excerpt."
      ],
      "future_work": [],
      "motivation": "Enable earlier identification of vulnerabilities and weaknesses by predicting unreported associations across CVE, CWE, and CPE; support threat modeling and vulnerability scanning with more complete knowledge.",
      "potential_research_ideas": [
        "Incorporate temporal knowledge graph embedding models to explicitly model time-evolving associations (e.g., TTransE, HyTE, diachronic KGE).",
        "Leverage text encoders (e.g., transformer-based language models) to integrate CVE/CWE descriptions and references as multimodal node/edge features.",
        "Use relational GNNs (e.g., R-GCN, CompGCN) for message passing over the threat knowledge graph and compare with translational embeddings.",
        "Introduce hyper-relational or n-ary facts (e.g., qualifiers for version ranges, configuration context, CVSS metrics) and evaluate hyper-KGE models.",
        "Active learning with analysts-in-the-loop to validate top-predicted links and iteratively refine the model.",
        "Uncertainty estimation and calibration for link predictions to support risk-based prioritization.",
        "Augment with additional sources (e.g., ExploitDB, KEV catalog, SBOM data, VEX) to improve coverage and precision.",
        "Develop temporal drift detection to identify when the model needs retraining as databases evolve.",
        "Constraint-based neuro-symbolic reasoning to enforce domain rules (e.g., version compatibility, product hierarchies) alongside embeddings.",
        "Assess transferability across vendors/products and create benchmarks for cross-domain generalization."
      ],
      "architectural_improvement_recommendations": [
        "Adopt temporal KGE or dynamic R-GCN to incorporate timestamps for CVE publication and association updates.",
        "Fuse textual embeddings from CVE/NVD descriptions with structural KGE via late fusion or joint training.",
        "Model version and configuration as qualifiers using hyper-relational KGs; train with models like StarE or Query2Box.",
        "Weight edges by confidence/staleness (e.g., older links down-weighted) and learn relation-specific margins in TransE.",
        "Employ rule mining (AMIE+/AnyBURL) to extract logical patterns and integrate with embeddings for neuro-symbolic link prediction.",
        "Scale training with industrial KGE frameworks (DGL-KE, PyTorch-BigGraph) and negative sampling strategies tuned per relation type.",
        "Calibrate decision thresholds per relation type using validation curves to optimize precision/recall trade-offs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Lag and incompleteness in NVD-curated associations reduce immediate ground truth coverage.",
        "Data inconsistencies across CPE and CVE entries require cleaning and normalization.",
        "Evolving databases necessitate periodic retraining and maintenance of the knowledge graph."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposed and implemented a threat knowledge graph aggregating CVE, CWE, and CPE with entities and attributes mapped into triples; included relations among weaknesses, views, and categories.",
      "Compared multiple KGE models (TransE, DistMult, ComplEx) and found TransE consistently best for this task.",
      "Closed-world evaluation demonstrating high-quality embeddings, e.g., \"achieving a 0.606 Hits@10 score in predicting CVE-CPE associations.\"",
      "Open-world evaluation predicting associations revealed after Aug 4, 2021, reporting \"a 0.358 Hits@10 score in predicting newly added CVE-CWE associations, and an F1-score of 0.681 for CVE-CPE predictions.\"",
      "Demonstrated prediction usefulness over different time periods using an additional snapshot (Mar 29, 2022).",
      "Optimized the knowledge graph by removing obsolete entries and incorporating CAPEC and CVSS data, showing further improvements, especially from removing old entries."
    ]
  },
  {
    "arxiv_id": "2302.02012v3",
    "title": "DeTorrent: An Adversarial Padding-only Traffic Analysis Defense",
    "authors": "James K Holland; Jason Carpenter; Se Eun Oh; Nicholas Hopper",
    "abstract": "While anonymity networks like Tor aim to protect the privacy of their users, they are vulnerable to traffic analysis attacks such as Website Fingerprinting (WF) and Flow Correlation (FC). Recent implementations of WF and FC attacks, such as Tik-Tok and DeepCoFFEA, have shown that the attacks can be effectively carried out, threatening user privacy. Consequently, there is a need for effective traffic analysis defense.   There are a variety of existing defenses, but most are either ineffective, incur high latency and bandwidth overhead, or require additional infrastructure. As a result, we aim to design a traffic analysis defense that is efficient and highly resistant to both WF and FC attacks. We propose DeTorrent, which uses competing neural networks to generate and evaluate traffic analysis defenses that insert 'dummy' traffic into real traffic flows. DeTorrent operates with moderate overhead and without delaying traffic. In a closed-world WF setting, it reduces an attacker's accuracy by 61.5%, a reduction 10.5% better than the next-best padding-only defense. Against the state-of-the-art FC attacker, DeTorrent reduces the true positive rate for a $10^{-5}$ false positive rate to about .12, which is less than half that of the next-best defense. We also demonstrate DeTorrent's practicality by deploying it alongside the Tor network and find that it maintains its performance when applied to live traffic.",
    "published_date": "2023-02-03",
    "pdf_link": "https://arxiv.org/pdf/2302.02012v3",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Anonymity Networks (Tor)",
      "specific_problem": "Traffic analysis defense without delaying traffic (padding-only) against Website Fingerprinting and Flow Correlation",
      "attack_types": [
        "Website Fingerprinting (WF)",
        "Flow Correlation (FC)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN (LSTM)",
        "specific": null,
        "novel_contribution": "LSTM generator outputs real-time dummy-padding schedules conditioned on past traffic; trained adversarially to minimize attacker success while avoiding explicit delays."
      },
      {
        "type": "primary",
        "category": "GAN-style adversarial training",
        "specific": null,
        "novel_contribution": "Competing generator-discriminator framework tailored to traffic defense; discriminator attempts WF/FC while generator learns padding robust to adversarial retraining."
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Deep Fingerprinting-style CNN",
        "novel_contribution": "Used (with modifications) as embedder/discriminator architecture for WF and to evaluate generator; not novel itself but adapted for the adversarial framework."
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Tik-Tok (WF attack)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "DNN embedding + voting",
        "specific": "DeepCoFFEA (FC attack)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Adversarial example generator",
        "specific": "Blind Adversarial Perturbations (BAP)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Padding/state-machine defenses",
        "specific": "WTF-PAD, FRONT, Spring, Interspace",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Window-timing obfuscation",
        "specific": "Decaf (FC defense)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Adversarial training",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Closed-world Tor WF dataset (authors' collection)",
        "type": "unknown",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "DeepCoFFEA evaluation setting/dataset (for FC)",
        "type": "unknown",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "unspecified"
      },
      {
        "name": "Live Tor traffic during pluggable transport deployment",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Tik-Tok (WF attack)",
        "paper_reference": "Rahman et al., 2021",
        "metric": "Closed-world accuracy",
        "their_result": "\"DeTorrent reduced closed-world Tik-Tok attack accuracy from 93.4% to 31.9%\"",
        "baseline_result": "93.4% (no defense)"
      },
      {
        "method_name": "Next-best padding-only WF defense (unspecified)",
        "paper_reference": null,
        "metric": "Reduction in attack accuracy (closed-world)",
        "their_result": "\"reduces an attacker's accuracy by 61.5%\"",
        "baseline_result": "10.5% less reduction than DeTorrent (i.e., DeTorrent is 10.5% better)"
      },
      {
        "method_name": "DeepCoFFEA (FC attack) + Decaf (defense)",
        "paper_reference": "Oh et al., DeepCoFFEA; Decaf (same paper)",
        "metric": "TPR at FPR = 1e-5",
        "their_result": "\"about .12\"",
        "baseline_result": ".29 (Decaf)"
      },
      {
        "method_name": "WTF-PAD",
        "paper_reference": "Juarez et al., 2016",
        "metric": "WF attack accuracy (various) / bandwidth overhead",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "FRONT",
        "paper_reference": "Gong and Wang, 2020",
        "metric": "WF attack accuracy / overhead",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Spring / Interspace (circuit padding)",
        "paper_reference": "Cherubin et al., 2022",
        "metric": "WF attack accuracy / overhead",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "BAP (blind adversarial perturbations)",
        "paper_reference": "Nasr et al., 2021",
        "metric": "WF/FC attack success post-retraining",
        "their_result": "Implemented; less effective under attacker retraining (no numbers given in provided text)",
        "baseline_result": null
      },
      {
        "method_name": "Deep Fingerprinting (WF attack)",
        "paper_reference": "Sirinam et al., 2018",
        "metric": "Closed-world accuracy",
        "their_result": "Used as discriminator basis; numeric comparison not quoted in provided text",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Closed-world accuracy (WF)",
      "True Positive Rate at fixed False Positive Rate (e.g., TPR at FPR=1e-5 for FC)",
      "Bandwidth overhead (%)",
      "Qualitative: no added latency (no explicit delays)",
      "Transferability drop (%)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can we design a padding-only, no-delay traffic analysis defense that is robust to both WF and FC, and to adaptive (retrained) attackers?",
        "Can adversarially trained competing neural networks learn unpredictable, real-time padding strategies that resist retraining?",
        "What level of bandwidth overhead is required to substantially degrade SOTA WF and FC attacks without adding latency?"
      ],
      "gaps_identified": [
        "Many existing defenses are ineffective, incur high latency/bandwidth overhead, or require additional infrastructure.",
        "Adversarial defenses often require knowledge of future traffic, delay traffic, or fail under adversarial retraining.",
        "Need for a single defense effective against both WF and FC and agnostic to attack models."
      ],
      "limitations": [
        "Bandwidth overhead is high (~97–99%) even though no explicit delays are introduced.",
        "Effectiveness primarily demonstrated in closed-world WF and a particular FC setting; generalization to broader open-world or varied network conditions not fully established in provided text.",
        "Attackers beyond DNNs (e.g., classical ML or hybrid side-information attacks) are discussed conceptually but not comprehensively evaluated in the excerpt."
      ],
      "future_work": [
        "Evaluate robustness in open-world WF and with non-DNN attackers (e.g., SVM/k-NN) and side-information-assisted attacks.",
        "Optimize generator to reduce bandwidth overhead while maintaining defense strength.",
        "Extended live deployments across diverse Tor conditions; long-term adaptive attacker-vs-defense dynamics."
      ],
      "motivation": "Design an efficient, padding-only, no-delay defense that significantly reduces the effectiveness of both WF and FC attacks, and remains robust to adaptive adversaries via adversarial training.",
      "potential_research_ideas": [
        "Open-world WF evaluation with DeTorrent and adaptive attackers; integrate side-channel features (e.g., burst directions) in discriminator to stress-test robustness.",
        "Multi-objective training to explicitly trade off bandwidth overhead vs. attack degradation using constrained optimization or Lagrangian methods.",
        "Replace LSTM generator with Transformer/State-space models for longer-range temporal patterns; compare stability and unpredictability.",
        "Hybrid defense combining DeTorrent padding with limited traffic-splitting (when available) to further confuse local vs. remote adversaries.",
        "Meta-adversary training loop where discriminator family includes non-DNN (e.g., similarity metrics, SVM) to improve attack-model agnosticism.",
        "Incorporate differentiable Tor-like queuing/channel models to better simulate network effects during training."
      ],
      "architectural_improvement_recommendations": [
        "Introduce an explicit overhead regularizer and latency budget in the generator loss to minimize padding while keeping no-delay constraint.",
        "Use ensemble discriminators (Tik-Tok, DF-style CNNs, metric-learning models) during training to improve robustness to attacker diversity.",
        "Adopt stochastic policy networks or diffusion-based sequence generators to increase unpredictability of padding schedules.",
        "Curriculum/adversary scheduling: cycle discriminators and periodically retrain on defended traces to emulate adaptive attackers.",
        "Knowledge distillation to a lightweight generator for deployment to reduce computational load on clients."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Tor pluggable transport (client-side)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Bandwidth overhead near 100% may stress user and network resources.",
        "Adaptive attackers can retrain; defense must maintain unpredictability over time.",
        "Integration with Tor circuit padding framework and ensuring no unintended latency.",
        "Heterogeneous network conditions may affect generator decisions and effectiveness."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes DeTorrent, an adversarial padding-only traffic analysis defense using competing neural networks (generator-discriminator).",
      "Generator implemented as an LSTM for real-time dummy-packet scheduling without delaying traffic.",
      "Demonstrates strong reductions against SOTA attacks: \"reduces an attacker's accuracy by 61.5%\" in closed-world WF; Tik-Tok accuracy from 93.4% to 31.9%.",
      "Against DeepCoFFEA (FC), achieves TPR≈0.12 at FPR=1e-5, less than half of Decaf's 0.29, with ~97–99% bandwidth overhead.",
      "Implements a Tor pluggable transport and shows maintained performance on live Tor traffic; demonstrates transferability with only ~0.7% drop across partitions.",
      "Positions defense to resist adversarial retraining by jointly training generator and discriminator."
    ]
  },
  {
    "arxiv_id": "2302.05530v1",
    "title": "Machine Learning Based Approach to Recommend MITRE ATT&CK Framework for Software Requirements and Design Specifications",
    "authors": "Nicholas Lasky; Benjamin Hallis; Mounika Vanamala; Rushit Dave; Jim Seliya",
    "abstract": "Engineering more secure software has become a critical challenge in the cyber world. It is very important to develop methodologies, techniques, and tools for developing secure software. To develop secure software, software developers need to think like an attacker through mining software repositories. These aim to analyze and understand the data repositories related to software development. The main goal is to use these software repositories to support the decision-making process of software development. There are different vulnerability databases like Common Weakness Enumeration (CWE), Common Vulnerabilities and Exposures database (CVE), and CAPEC. We utilized a database called MITRE. MITRE ATT&CK tactics and techniques have been used in various ways and methods, but tools for utilizing these tactics and techniques in the early stages of the software development life cycle (SDLC) are lacking. In this paper, we use machine learning algorithms to map requirements to the MITRE ATT&CK database and determine the accuracy of each mapping depending on the data split.",
    "published_date": "2023-02-10",
    "pdf_link": "https://arxiv.org/pdf/2302.05530v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software/Application Security",
      "subdomain": "Secure SDLC / Requirements Engineering Security",
      "specific_problem": "Automatically map software requirements and design specifications to MITRE ATT&CK tactics/techniques to surface relevant threats and mitigations early in the SDLC",
      "attack_types": [
        "initial access",
        "execution",
        "impact",
        "resource development",
        "command and control",
        "persistence",
        "defense evasion",
        "privilege escalation",
        "credential access",
        "lateral movement",
        "collection",
        "exfiltration"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "SVM",
        "specific": null,
        "novel_contribution": "Applied supervised multi-class text classification to map functional requirements to five grouped MITRE ATT&CK tactic classes"
      },
      {
        "type": "baseline",
        "category": "Neural Network",
        "specific": null,
        "novel_contribution": "Baseline classifier for the same mapping task"
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": "Baseline classifier for the same mapping task"
      },
      {
        "type": "baseline",
        "category": "Naive Bayes",
        "specific": null,
        "novel_contribution": "Baseline classifier for the same mapping task"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Collected functional requirements dataset (614 items)",
        "type": "private",
        "domain": "software_requirements_text (SRS)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "MITRE ATT&CK",
        "type": "public",
        "domain": "attack_taxonomy",
        "link": "https://attack.mitre.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Neural Network",
        "paper_reference": null,
        "metric": "Accuracy (70% train / 30% test)",
        "their_result": "0.57 (SVM)",
        "baseline_result": "0.53"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Accuracy (70% train / 30% test)",
        "their_result": "0.57 (SVM)",
        "baseline_result": "0.50"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "Accuracy (70% train / 30% test)",
        "their_result": "0.57 (SVM)",
        "baseline_result": "0.51"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "Accuracy (60% train / 40% test)",
        "their_result": "0.47 (SVM)",
        "baseline_result": "0.49"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "Accuracy (80% train / 20% test)",
        "their_result": "0.48 (SVM)",
        "baseline_result": "0.50"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Recall",
      "F1 Score",
      "Precision"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can machine learning algorithms map software functional requirements to relevant MITRE ATT&CK tactics/techniques?",
        "Which algorithms perform best for this mapping task and under which train/test splits?",
        "How does data split proportion (training vs. testing) affect mapping accuracy?",
        "Can this approach support development of an automated tool for early-stage SDLC security recommendations?"
      ],
      "gaps_identified": [
        "Lack of tools to utilize MITRE ATT&CK tactics and techniques in early SDLC stages (requirements and design).",
        "Manual navigation of the large MITRE knowledge base is difficult for developers to identify relevant items.",
        "Prior approaches used CAPEC and text similarity; limited evaluation of ML-based mapping to ATT&CK."
      ],
      "limitations": [
        "Relatively small dataset (614 requirements) limiting performance and generalization.",
        "Manual mapping to MITRE classes performed by multiple people, introducing potential human error and inconsistency.",
        "Only 12 of 14 MITRE tactics were used and tactics were grouped into five broad classes, reducing granularity.",
        "No public release of dataset or code; limited details on feature engineering and model hyperparameters."
      ],
      "future_work": [
        "Obtain more functional requirements to improve training and accuracy.",
        "Incorporate more algorithms to evaluate and potentially improve performance.",
        "Develop a practical tool for industry (e.g., financial sector) to automatically map requirements to attacks and mitigations."
      ],
      "motivation": "Enable secure software engineering by providing automated, early-stage SDLC support that maps requirements/design specifications to MITRE ATT&CK to identify potential threats and mitigations, reducing developer effort and oversight.",
      "potential_research_ideas": [
        "Formulate the task as hierarchical and/or multi-label classification directly predicting tactics and techniques (and even procedures) rather than grouped classes.",
        "Leverage pre-trained language models (e.g., BERT, domain-adapted models) for requirement text encoding and fine-tune on the mapping task.",
        "Active learning/human-in-the-loop annotation to expand the dataset and reduce mapping inconsistency.",
        "Weak supervision or distant supervision using MITRE textual descriptions to bootstrap labels from unlabeled requirements.",
        "Evaluate transferability across domains (finance, healthcare, IoT) and perform domain adaptation.",
        "Construct an explainable recommendation system that highlights key phrases in requirements and links them to specific ATT&CK evidence and mitigations.",
        "Integrate knowledge graphs connecting requirements, CWE/CVE/CAPEC, and ATT&CK for joint reasoning."
      ],
      "architectural_improvement_recommendations": [
        "Use robust text preprocessing and TF-IDF with n-grams, followed by calibrated linear SVM or logistic regression with class weighting.",
        "Adopt transformer-based encoders (e.g., BERT/RoBERTa) with hierarchical heads: first predict tactic(s), then technique(s).",
        "Switch from single-class to multi-label classification to accommodate requirements mapping to multiple tactics.",
        "Perform stratified k-fold cross-validation with proper class balancing and hyperparameter tuning.",
        "Measure and improve inter-annotator agreement; create detailed labeling guidelines and adjudication.",
        "Incorporate semantic similarity between requirements and ATT&CK descriptions via dual-encoder retrieval plus classifier reranking.",
        "Augment training data with paraphrasing and synonym expansion to improve robustness."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "scikit-learn",
        "pandas"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Current accuracy (~0.57 at best split) may be insufficient for production without human oversight.",
        "Manual labeling inconsistency affects reliability; requires robust labeling process for scale.",
        "Coverage limited to 12 of 14 tactics and grouped classes reduces recommendation granularity."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Compiled and manually labeled a dataset of 614 functional software requirements mapped to MITRE ATT&CK (12 tactics grouped into five classes).",
      "Formulated automated mapping of requirements to ATT&CK as a supervised multi-class classification task.",
      "Implemented and evaluated four ML algorithms (SVM, Naive Bayes, Neural Network, Random Forest) across multiple train/test splits using accuracy, recall, precision, and F1.",
      "Observed best average performance with SVM at a 70%/30% train/test split (accuracy/recall/F1/precision = 0.57).",
      "Outlined a path to an industrial tool that recommends relevant ATT&CK items and mitigations from requirements."
    ]
  },
  {
    "arxiv_id": "2302.04332v2",
    "title": "Continuous Learning for Android Malware Detection",
    "authors": "Yizheng Chen; Zhoujie Ding; David Wagner",
    "abstract": "Machine learning methods can detect Android malware with very high accuracy. However, these classifiers have an Achilles heel, concept drift: they rapidly become out of date and ineffective, due to the evolution of malware apps and benign apps. Our research finds that, after training an Android malware classifier on one year's worth of data, the F1 score quickly dropped from 0.99 to 0.76 after 6 months of deployment on new test samples.   In this paper, we propose new methods to combat the concept drift problem of Android malware classifiers. Since machine learning technique needs to be continuously deployed, we use active learning: we select new samples for analysts to label, and then add the labeled samples to the training set to retrain the classifier. Our key idea is, similarity-based uncertainty is more robust against concept drift. Therefore, we combine contrastive learning with active learning. We propose a new hierarchical contrastive learning scheme, and a new sample selection technique to continuously train the Android malware classifier. Our evaluation shows that this leads to significant improvements, compared to previously published methods for active learning. Our approach reduces the false negative rate from 14% (for the best baseline) to 9%, while also reducing the false positive rate (from 0.86% to 0.48%). Also, our approach maintains more consistent performance across a seven-year time period than past methods.",
    "published_date": "2023-02-08",
    "pdf_link": "https://arxiv.org/pdf/2302.04332v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Mobile/Android Malware Detection",
      "specific_problem": "Continuous learning under concept drift for Android malware classification using active learning",
      "attack_types": [
        "Android malware",
        "novel malware families",
        "concept drift",
        "evasion via evolution of apps"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Contrastive Learning",
        "specific": "Hierarchical supervised contrastive learning",
        "novel_contribution": "New hierarchical contrastive loss that encodes a malware/benign hierarchy and family-level similarity to mitigate class imbalance and improve detection of unseen malware families"
      },
      {
        "type": "primary",
        "category": "Active Learning",
        "specific": "Uncertainty-based sampling via pseudo loss",
        "novel_contribution": "Introduces pseudo loss: averages contrastive loss over pairs formed with a test sample and training samples to quantify uncertainty for sample selection"
      },
      {
        "type": "primary",
        "category": "Neural Network Classifier",
        "specific": "Encoder + binary classifier (end-to-end training with BCE + hierarchical contrastive loss)",
        "novel_contribution": "Engineering finding: warm-start (continued training) yields significant gains over cold-start in security settings with severe class imbalance"
      },
      {
        "type": "baseline",
        "category": "Active Learning",
        "specific": "Uncertainty sampling by prediction confidence",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Contrastive Learning",
        "specific": "CADE (supervised contrastive learning + distance-based OOD score)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Conformal Prediction",
        "specific": "TRANSCENDENT (credibility and confidence via nonconformity)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Active Learning",
      "Continual Learning"
    ],
    "datasets": [
      {
        "name": "APIGraph",
        "type": "public",
        "domain": "android_apps",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "AndroZoo (2019–2021 subset)",
        "type": "public",
        "domain": "android_apps",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Best prior active learning method (unspecified in excerpt)",
        "paper_reference": null,
        "metric": "False Negative Rate (FNR)",
        "their_result": "9%",
        "baseline_result": "14%"
      },
      {
        "method_name": "Best prior active learning method (unspecified in excerpt)",
        "paper_reference": null,
        "metric": "False Positive Rate (FPR)",
        "their_result": "0.48%",
        "baseline_result": "0.86%"
      },
      {
        "method_name": "Uncertainty sampling (prediction confidence)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "CADE (supervised contrastive + distance-based OOD)",
        "paper_reference": "[54]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "TRANSCENDENT (conformal prediction-based OOD)",
        "paper_reference": "[8,21]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "F1 score",
      "False Negative Rate (FNR)",
      "False Positive Rate (FPR)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How can we maintain Android malware detector performance over time under severe concept drift with limited analyst labeling budgets?",
        "Can contrastive learning-based similarity and a new uncertainty measure improve active learning for continuous malware detection?"
      ],
      "gaps_identified": [
        "Concept drift rapidly degrades Android malware classifiers (“F1 score quickly dropped from 0.99 to 0.76 after 6 months”).",
        "Existing supervised contrastive methods (e.g., CADE) struggle under real-world class imbalance, often misclassifying new malware families as benign.",
        "No existing uncertainty measure for contrastively learned encoders suitable for active learning.",
        "Prior work underemphasized warm-start vs cold-start distinctions in security classification despite strong imbalance and data dynamics."
      ],
      "limitations": [
        "Assumes human analysts can provide both binary (benign/malicious) and malware family labels for selected samples.",
        "Evaluation limited to Android datasets (APIGraph 2012–2018; AndroZoo 2019–2021); generalization to other platforms or modalities not demonstrated in the excerpt."
      ],
      "future_work": [],
      "motivation": "Combat concept drift in Android malware detection by reducing labeling effort and maintaining accuracy through an uncertainty-aware, similarity-based continual learning approach.",
      "potential_research_ideas": [
        "Generalize pseudo loss uncertainty to other representation learning paradigms (e.g., graph/self-supervised models) and assess across diverse security domains (network IDS, PE malware).",
        "Replace the encoder with graph neural networks over API-call or ICC graphs to exploit structural semantics in Android apps.",
        "Leverage semi-supervised or weakly supervised family labeling (e.g., clustering + few-shot labeling) to relax the requirement for analyst-provided family labels.",
        "Integrate rehearsal-based continual learning or sample-retirement strategies with the active loop to control memory while avoiding catastrophic forgetting.",
        "Investigate adaptive labeling budgets guided by real-time drift detection to further reduce analyst effort.",
        "Explore calibration techniques and conformal wrappers on top of the contrastive encoder to improve uncertainty reliability.",
        "Extend to multi-granularity outputs (benign/malicious/family/subfamily) with hierarchical decisions and selective abstention."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a prototype-based classifier in the embedding space with class/family prototypes to stabilize decisions under drift.",
        "Perform hard-negative mining and margin scheduling in the hierarchical contrastive loss to better separate benign vs. malicious and inter-family boundaries.",
        "Pretrain the encoder on large unlabeled Android corpora (self-supervised pretraining) before supervised hierarchical contrastive fine-tuning.",
        "Incorporate temporal/context features (e.g., app release time, update sequences) to explicitly model drift-aware similarity.",
        "Use ensemble encoders or feature dropout to improve uncertainty calibration of the pseudo loss.",
        "Augment with graph-based features (API/permission/call graphs) and multi-view fusion to enrich the representation."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/wagner-group/active-learning",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Concept drift necessitating periodic updates",
        "Severe class imbalance (majority benign)",
        "Limited analyst labeling budget",
        "Requirement for family labels from analysts",
        "Choosing warm-start vs. cold-start retraining strategies"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a new hierarchical contrastive learning scheme tailored to Android malware detection under class imbalance.",
      "Introduces a novel uncertainty score for contrastive models, the pseudo loss, enabling effective active learning sample selection.",
      "Engineering insights for continuous learning in security, showing warm-start training can significantly outperform cold-start under imbalance.",
      "Exact quoted result: “Our approach reduces the false negative rate from 14% (for the best baseline) to 9%, while also reducing the false positive rate (from 0.86% to 0.48%).”",
      "Exact quoted result: “the F1 score quickly dropped from 0.99 to 0.76 after 6 months of deployment on new test samples.”",
      "Exact quoted result: “the improvement of F1 score ranges from 8.99% to 16.50% across different labeling budgets compared to the best prior method.”",
      "Maintains more consistent performance across a seven-year period than past methods; reduces analyst labeling by up to 8× for maintaining performance (per excerpt)."
    ]
  },
  {
    "arxiv_id": "2302.02324v1",
    "title": "Towards Scalable EM-based Anomaly Detection For Embedded Devices Through Synthetic Fingerprinting",
    "authors": "Kurt A. Vedros; Georgios Michail Makrakis; Constantinos Kolias; Robert C. Ivans; Craig Rieger",
    "abstract": "Embedded devices are omnipresent in modern networks including the ones operating inside critical environments. However, due to their constrained nature, novel mechanisms are required to provide external, and non-intrusive anomaly detection. Among such approaches, one that has gained traction is based on the analysis of the electromagnetic (EM) signals that get emanated during a device's operation. However, one of the most neglected challenges of this approach is the requirement for manually gathering and fingerprinting the signals that correspond to each execution path of the software/firmware. Indeed, even simple programs are comprised of hundreds if not thousands of branches thus, making the fingerprinting stage an extremely time-consuming process that involves the manual labor of a human specialist. To address this issue, we propose a framework for generating synthetic EM signals directly from the machine code. The synthetic signals can be used to train a Machine Learning based (ML) system for anomaly detection. The main advantage of the proposed approach is that it completely removes the need for an elaborate and error-prone fingerprinting stage, thus, dramatically increasing the scalability of the corresponding protection mechanisms. The experimental evaluations indicate that our method provides high detection accuracy (above 90% AUC score) when employed for the detection of injection attacks. Moreover, the proposed methodology inflicts only a small penalty (-1.3%) in accuracy for the detection of the injection of as little as four malicious instructions when compared to the same methods if real signals were to be used.",
    "published_date": "2023-02-05",
    "pdf_link": "https://arxiv.org/pdf/2302.02324v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT/Embedded Systems Security",
      "subdomain": "Side-channel-based Anomaly Detection",
      "specific_problem": "Scalable EM-based anomaly detection for embedded devices via synthetic fingerprinting generated from machine code",
      "attack_types": [
        "code injection",
        "instruction injection",
        "buffer overflow exploitation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Distance-based anomaly detection",
        "specific": "k-nearest neighbors (sum of k-NN Euclidean distances) with transduction/hypothesis testing and a voting mechanism across execution paths",
        "novel_contribution": "Extends an existing semi-supervised, transductive anomaly detection method by adding a voting mechanism over multiple execution-path baselines; trains strictly on synthetic EM signals generated from ASM sequences"
      }
    ],
    "learning_paradigm": [
      "Semi-supervised"
    ],
    "datasets": [
      {
        "name": "EM signals from Arduino Mega (ATmega2560) running Program A (benign) and Program B (benign update)",
        "type": "private",
        "domain": "side_channel_em",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "EM signals for malicious Program B variants (code injection: +4 instructions, +2 instructions)",
        "type": "private",
        "domain": "side_channel_em",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Synthetic EM signals generated from ASM sequences of Program B using an instruction-to-signal library",
        "type": "synthetic",
        "domain": "side_channel_em",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Instruction-to-signal library (AVR subset; context-aware S(ci-1||ci))",
        "type": "private",
        "domain": "side_channel_em",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Same anomaly detection method trained on real EM signals (fingerprinting with real signals)",
        "paper_reference": null,
        "metric": "AUC",
        "their_result": "\"high detection accuracy (above 90% AUC score)\" when using synthetic signals",
        "baseline_result": null
      },
      {
        "method_name": "Same anomaly detection method trained on real EM signals (fingerprinting with real signals)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "\"only a small penalty (-1.3%) in accuracy for the detection of the injection of as little as four malicious instructions\" (synthetic vs real)",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "AUC",
      "Accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can synthetic EM signals generated directly from machine code replace manual EM fingerprinting for anomaly detection in embedded devices?",
        "What database structure and generation methodology are needed to synthesize realistic EM signals for arbitrary execution paths?",
        "How well can synthetic-signal-trained models detect code injection attacks compared to models trained on real EM signals?"
      ],
      "gaps_identified": [
        "Manual, exhaustive EM fingerprinting of each execution path is time-consuming, error-prone, and a key roadblock to deployment.",
        "Rarely executed branches are often omitted from fingerprinting, yielding wrong predictions in rare yet normal situations.",
        "Firmware/software updates force re-fingerprinting from scratch.",
        "Instruction context affects EM signal morphology, requiring context-aware signal blocks.",
        "Community lacks open, exhaustive instruction-to-EM-signal libraries for architectures like AVR/x86."
      ],
      "limitations": [
        "Assumes only one subsequent instruction is affected by the current instruction's EM footprint; authors note further investigation is required.",
        "Experiments conducted in a virtual noise-free environment; robustness under real operational noise not evaluated.",
        "Evaluation on a single platform (Arduino Mega, ATmega2560) and simple programs with one execution path; generalizability untested.",
        "Instruction-to-signal database creation is acknowledged as time-consuming and large in size.",
        "Pre-processing such as noise elimination and multi-sensor setups were omitted for simplicity.",
        "Comparison baselines limited to real vs synthetic signal training for the same method; no comparisons against other anomaly detection algorithms."
      ],
      "future_work": [
        "\"further investigation is required\" regarding how many subsequent instructions are affected by a given instruction's EM footprint.",
        "Construct and potentially open-source comprehensive instruction-to-EM-signal libraries per architecture.",
        "Extend to multi-sensor EM capture (e.g., CPU plus other components) with noise reduction pre-processing.",
        "Apply the approach beyond anomaly detection to side-channel analysis tasks such as inferring cryptographic keys."
      ],
      "motivation": "Eliminate the elaborate, error-prone manual EM fingerprinting of all execution paths to dramatically increase the scalability of EM-based protection mechanisms for embedded devices.",
      "potential_research_ideas": [
        "Build and release a standardized, context-aware instruction-to-EM-signal corpus for multiple architectures (AVR, ARM Cortex-M, RISC-V) with sampling parameters and metadata.",
        "Model broader context dependence (S(ci-2||ci-1||ci)) using Markov models or sequence models to capture longer-range EM effects.",
        "Learn a neural generative mapper from ASM/micro-ops to EM waveforms, conditioned on timing and micro-architecture, to reduce the need for exhaustive libraries.",
        "Incorporate realistic noise and channel models to synthesize deployable field-like EM signals; evaluate robustness in noisy and variable probe-placement scenarios.",
        "Multi-sensor fusion: jointly model EM from CPU and other components; assess gains in detection fidelity using late/early fusion.",
        "Domain adaptation: align synthetic and real EM distributions using adversarial adaptation or optimal transport for improved detection with limited real data.",
        "Online calibration: adapt the synthetic-trained baseline to device drift and firmware updates via few-shot real EM samples and conformal recalibration.",
        "Adversary-aware evaluation: test resistance to malicious EM camouflage or instruction padding designed to mimic normal EM signatures."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment kNN distances with learned embeddings (e.g., CNN/Transformer encoders on raw EM waveforms) and one-class objectives (OC-SVM, Deep SVDD).",
        "Use dynamic time warping (DTW) or time-warp invariant similarity for strangeness computation to handle timing jitter and instruction-duration variability.",
        "Adopt formal conformal prediction calibration for p-values across execution paths with multiple-testing control.",
        "Employ anomaly score ensembles (distance-, density-, and reconstruction-based) to improve robustness.",
        "Integrate context-aware synthetic generation (conditioning on preceding k instructions) and validate optimal context length empirically.",
        "Add noise-robust pre-processing (bandpass filtering, denoising autoencoders) and augmentations matched to field conditions."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Commodity data acquisition hardware (EM probe, amplifier, PicoScope). Model training uses kNN distance computations; no GPU requirements specified."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Embedded device (Arduino Mega, lab setting)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Building and maintaining a comprehensive instruction-to-EM-signal library per architecture.",
        "Handling rare execution paths and firmware updates without missing normal states.",
        "Sensitivity to probe placement, sampling parameters, and environmental noise.",
        "Device- and board-level variability affecting EM signatures and transferability.",
        "Synchronization and timing alignment across runs; variable instruction durations."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a framework to generate synthetic EM signals directly from machine code for use in anomaly detection.",
      "Defines the requirements and structure of a context-aware library of EM signal blocks (e.g., S(ci-1||ci)).",
      "Presents a methodology to synthesize EM sequences for entire code paths from instruction-level building blocks.",
      "Extends a semi-supervised, transductive anomaly detection method with a voting mechanism across execution paths.",
      "Demonstrates detection performance with synthetic training data: \"above 90% AUC score\" for injection attacks.",
      "Shows only a \"small penalty (-1.3%)\" in accuracy for detecting injection of four malicious instructions compared to training with real EM signals."
    ]
  },
  {
    "arxiv_id": "2303.03372v1",
    "title": "ALMOST: Adversarial Learning to Mitigate Oracle-less ML Attacks via Synthesis Tuning",
    "authors": "Animesh Basak Chowdhury; Lilas Alrahis; Luca Collini; Johann Knechtel; Ramesh Karri; Siddharth Garg; Ozgur Sinanoglu; Benjamin Tan",
    "abstract": "Oracle-less machine learning (ML) attacks have broken various logic locking schemes. Regular synthesis, which is tailored for area-power-delay optimization, yields netlists where key-gate localities are vulnerable to learning. Thus, we call for security-aware logic synthesis. We propose ALMOST, a framework for adversarial learning to mitigate oracle-less ML attacks via synthesis tuning. ALMOST uses a simulated-annealing-based synthesis recipe generator, employing adversarially trained models that can predict state-of-the-art attacks' accuracies over wide ranges of recipes and key-gate localities. Experiments on ISCAS benchmarks confirm the attacks' accuracies drops to around 50\\% for ALMOST-synthesized circuits, all while not undermining design optimization.",
    "published_date": "2023-03-06",
    "pdf_link": "https://arxiv.org/pdf/2303.03372v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Logic Locking / Hardware Obfuscation",
      "specific_problem": "Mitigating oracle-less ML attacks on logic-locked circuits via security-aware synthesis recipe tuning",
      "attack_types": [
        "Oracle-less ML attacks on logic locking",
        "GNN-based key-bit inference (OMLA)",
        "Unsupervised correlation attack using synthesis reports (SCOPE)",
        "Structural redundancy attack (non-ML)",
        "Tensor-based structural ML attacks (SAIL, SnapShot) - background"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "OMLA-style subgraph GNN used as an attack model and as a transferable proxy (M* A)",
        "novel_contribution": "Adversarial re-training of the attacker GNN using SA-generated ‘adversarial recipes’ to create a transferable proxy model that predicts attack accuracy across wide recipe/key-gate locality variations"
      },
      {
        "type": "primary",
        "category": "Simulated Annealing",
        "specific": null,
        "novel_contribution": "Used as a black-box optimizer to generate security-aware synthesis recipes that drive attack accuracy toward ~50%"
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "OMLA",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Unsupervised ML",
        "specific": "SCOPE (correlates synthesis reports with key bits)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Adversarial Training",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "ISCAS85 combinational circuit benchmarks (c1355, c1908, c2670, c3540, c5315, c6288, c7552)",
        "type": "public",
        "domain": "hardware_netlists",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Relocked/resynthesized subgraph datasets per design (training data for attack/proxy models)",
        "type": "synthetic",
        "domain": "gate_level_subgraph_embeddings",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "OMLA on ISCAS85 c1355 (64-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "54.18%",
        "baseline_result": "57.52% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c1908 (64-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "47.80%",
        "baseline_result": "59.01% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c2670 (64-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "49.78%",
        "baseline_result": "58.01% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c3540 (64-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "46.57%",
        "baseline_result": "59.63% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c5315 (64-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "49.78%",
        "baseline_result": "62.62% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c6288 (64-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "49.88%",
        "baseline_result": "52.51% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c7552 (64-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "55.55%",
        "baseline_result": "66.33% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c1355 (128-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "51.87%",
        "baseline_result": "59.36% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c1908 (128-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "49.81%",
        "baseline_result": "62.12% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c2670 (128-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "52.11%",
        "baseline_result": "59.26% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c3540 (128-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "48.92%",
        "baseline_result": "60.25% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c5315 (128-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "52.33%",
        "baseline_result": "68.95% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c6288 (128-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "50.00%",
        "baseline_result": "53.31% (resyn2)"
      },
      {
        "method_name": "OMLA on ISCAS85 c7552 (128-bit keys)",
        "paper_reference": "[1]",
        "metric": "accuracy",
        "their_result": "51.88%",
        "baseline_result": "72.21% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c1355 (64-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "56.25%",
        "baseline_result": "60.94% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c1908 (64-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "48.44%",
        "baseline_result": "51.56% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c2670 (64-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "31.25%",
        "baseline_result": "35.94% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c3540 (64-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "37.50%",
        "baseline_result": "34.38% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c5315 (64-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "57.81%",
        "baseline_result": "45.31% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c6288 (64-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "51.56%",
        "baseline_result": "53.13% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c7552 (64-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "43.75%",
        "baseline_result": "40.63% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c1355 (128-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "50.78%",
        "baseline_result": "51.56% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c1908 (128-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "46.09%",
        "baseline_result": "46.09% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c2670 (128-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "35.15%",
        "baseline_result": "29.68% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c3540 (128-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "36.71%",
        "baseline_result": "36.71% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c5315 (128-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "39.06%",
        "baseline_result": "37.50% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c6288 (128-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "53.91%",
        "baseline_result": "59.37% (resyn2)"
      },
      {
        "method_name": "SCOPE on ISCAS85 c7552 (128-bit keys)",
        "paper_reference": "[7]",
        "metric": "accuracy",
        "their_result": "45.31%",
        "baseline_result": "46.09% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c1355 (64-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "39.06%",
        "baseline_result": "32.81% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c1908 (64-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "37.50%",
        "baseline_result": "37.50% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c2670 (64-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "31.25%",
        "baseline_result": "28.13% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c3540 (64-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "45.31%",
        "baseline_result": "50.00% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c5315 (64-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "50.00%",
        "baseline_result": "50.00% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c6288 (64-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "31.25%",
        "baseline_result": "34.38% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c7552 (64-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "32.81%",
        "baseline_result": "35.94% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c1355 (128-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "35.15%",
        "baseline_result": "39.84% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c1908 (128-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "42.96%",
        "baseline_result": "35.93% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c2670 (128-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "19.53%",
        "baseline_result": "21.09% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c3540 (128-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "44.53%",
        "baseline_result": "41.40% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c5315 (128-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "39.84%",
        "baseline_result": "41.40% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c6288 (128-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "34.38%",
        "baseline_result": "31.25% (resyn2)"
      },
      {
        "method_name": "Redundancy attack on ISCAS85 c7552 (128-bit keys)",
        "paper_reference": "[8]",
        "metric": "accuracy",
        "their_result": "35.16%",
        "baseline_result": "37.50% (resyn2)"
      }
    ],
    "performance_metrics_used": [
      "accuracy (key-bit prediction)",
      "area",
      "delay"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can we explore the synthesis search space to find some recipe(s) that provide resilience against various state-of-the-art (SOTA) ML attacks?",
        "Given any recipe, can we efficiently quantify its ML resiliency without running the various SOTA attacks?"
      ],
      "gaps_identified": [
        "Regular PPA-centric synthesis yields predictable structural transformations around key-gates that ML can learn to break logic locking",
        "Security-aware logic synthesis is lacking; current resilient locking (e.g., TRLL, UNSAIL) relies on specific structural preconditions limiting applicability",
        "Synthesis-recipe search optimizing for attack accuracy is NP-hard",
        "Attack models trained on one recipe have poor transferability to other recipes, making brute-force evaluation impractical"
      ],
      "limitations": [
        "Objective formulation does not explicitly include PPA; overheads are only empirically observed as marginal",
        "Evaluation limited to ISCAS85 combinational benchmarks and RLL (random logic locking) as the locking scheme",
        "Open-source Yosys+ABC flow only; transfer to commercial EDA flows not demonstrated",
        "Fixed recipe length (L=10) and limited SA iteration budget; some circuits did not reach 50% accuracy within budget",
        "Attacker model/evaluation focuses on specific oracle-less attacks (OMLA, SCOPE) and one structural non-ML attack; broader adversarial strategies not exhaustively covered"
      ],
      "future_work": [
        "Integrate multi-objective optimization to jointly consider security and PPA (area/delay/power)",
        "Explore alternative black-box optimizers (evolutionary algorithms, tree search, Bayesian optimization, reinforcement learning) for recipe generation",
        "Generalize to other locking schemes and larger, industrial-scale and sequential designs",
        "Port the approach to commercial EDA flows and technology libraries",
        "Richer modeling of adaptive attackers, including re-synthesis strategies guided by search/learning"
      ],
      "motivation": "Call for security-aware logic synthesis to make logic-locked designs resilient to oracle-less ML attacks by steering synthesis recipes, avoiding reliance on specialized locking structures.",
      "potential_research_ideas": [
        "Design a recipe-conditioned GNN that explicitly ingests synthesis-recipe tokens to better predict attack success and guide search",
        "Bayesian optimization or RL over synthesis recipes with uncertainty-aware surrogate models to reduce evaluation cost",
        "Multi-objective security-PPA co-optimization with Pareto front exploration and constraints on area/delay",
        "Meta-learning across many designs to learn priors for faster recipe search on new circuits",
        "Explain which synthesis transformations and localities most contribute to resilience using attribution on graph models",
        "Develop adaptive attacker frameworks that co-search re-synthesis and attack training to stress-test defenses",
        "Extend to sequential circuits and to placement/routing-aware transformations where physical synthesis affects structural leakage"
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment GNN with graph transformers or heterogeneous GNNs to model richer netlist semantics",
        "Condition proxy model on recipe embeddings (e.g., with a hypernetwork) to improve transferability and calibration",
        "Active learning loop selecting most-informative recipes/localities for labeling via re-lock/re-synthesis",
        "Ensemble proxy models (e.g., GNN + gradient-boosted trees on graph features) to improve robustness and uncertainty estimation",
        "Hierarchical search over variable-length recipes with learned priors over transformation sequences",
        "Incorporate PPA differentiable proxies to enforce security without sacrificing area/delay"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Training uses 350 epochs with adversarial augmentation every R=50 epochs (200 adversarial samples per SA iteration); SA search typically 100 iterations (initial temperature 120, acceptance=1.8); recipe length L=10; Yosys+ABC with NanGate 45nm library; GPU/CPU specifics not stated."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Integration with commercial EDA flows and proprietary technology libraries",
        "Balancing security objectives with PPA requirements in production flows",
        "Handling larger industrial-scale and sequential designs at acceptable runtime",
        "Potential adaptive attackers that may co-optimize re-synthesis to improve attack accuracy",
        "Tool/version dependence of synthesis transformations and recipe semantics"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces ALMOST, a security-centric framework that tunes synthesis recipes to mitigate oracle-less ML attacks on logic-locked circuits",
      "Adversarially trained GNN proxy model that predicts attack accuracy across diverse synthesis recipes and key-gate localities",
      "Simulated-annealing-based recipe generator to search for security-aware synthesis sequences",
      "Demonstrates that even vulnerable RLL can be made ML-resilient via synthesis tuning without undermining design optimization",
      "Reduces SOTA ML and structural attack accuracies to around 50% on ISCAS85 benchmarks",
      "Shows resilience persists even when the attacker knows the defender’s recipe and attempts re-synthesis for area/delay",
      "Promises public release of source code and artifacts"
    ]
  },
  {
    "arxiv_id": "2301.06959v1",
    "title": "SECOMlint: A linter for Security Commit Messages",
    "authors": "Sofia Reis; Corina Pasareanu; Rui Abreu; Hakan Erdogmus",
    "abstract": "Transparent and efficient vulnerability and patch disclosure are still a challenge in the security community, essentially because of the poor-quality documentation stemming from the lack of standards. SECOM is a recently-proposed standard convention for security commit messages that enables the writing of well-structured and complete commit messages for security patches. The convention prescribes different bits of security-related information essential for a better understanding of vulnerabilities by humans and tools. SECOMlint is an automated and configurable solution to help security and maintenance teams infer compliance against the SECOM standard when submitting patches to security vulnerabilities in their source version control systems. The tool leverages the natural language processing technique Named-Entity Recognition (NER) to extract security-related information from commit messages and uses it to match the compliance standards designed. We demonstrate SECOMlint at https://youtu.be/-1hzpMN_uFI; and documentation and its source code at https://tqrg.github.io/secomlint/.",
    "published_date": "2023-01-17",
    "pdf_link": "https://arxiv.org/pdf/2301.06959v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Secure Software Development Practices",
      "specific_problem": "Compliance checking and quality assurance of security commit messages documenting vulnerability fixes",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "NLP / NER",
        "specific": "spaCy pipeline with custom rule-based NER patterns",
        "novel_contribution": "Domain-specific NER entity set and rule matcher for security commit messages (e.g., VULNID, CWEID, SEVERITY, DETECTION, etc.) to assess SECOM compliance"
      },
      {
        "type": "baseline",
        "category": "Rule-based text processing",
        "specific": "Pattern/rule matching with POS tags from spaCy",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Rule-based",
      "Pretrained NLP (no model training)"
    ],
    "datasets": [
      {
        "name": "pre_secom security commit messages (500)",
        "type": "private",
        "domain": "commit_messages",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "after_secom security commit messages (500)",
        "type": "private",
        "domain": "commit_messages",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "National Vulnerability Database (NVD)",
        "type": "public",
        "domain": "vulnerability_database (used to source commit messages)",
        "link": "https://www.nist.gov/programs-projects/national-vulnerability-database-nvd",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Open Source Vulnerability (OSV) Database",
        "type": "public",
        "domain": "vulnerability_database (used to source commit messages)",
        "link": "https://osv.dev/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Compliance score (%) against SECOM rules",
      "Entity extraction count (total and average per message)",
      "Entity type coverage (#types out of designed types)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to automatically check whether a security commit message complies with the SECOM convention?",
        "Can domain-tailored NER-driven rules extract the security-relevant entities needed to judge compliance?",
        "Does using the SECOM convention increase the amount of extractable, security-relevant information in commit messages?"
      ],
      "gaps_identified": [
        "Poor-quality and non-standardized documentation of vulnerability patches in commit messages hinders transparent disclosure and maintenance.",
        "Only a small fraction of known vulnerabilities reference code fixes in public databases (e.g., OSV/NVD).",
        "Lack of automated, configurable compliance tooling for security commit message standards."
      ],
      "limitations": [
        "Evaluation datasets (pre_secom/after_secom) are subsets collected by authors and are not released, which limits reproducibility and external validation.",
        "Rule-based NER may miss entities outside defined patterns or in non-English/atypical phrasing; the paper notes extracting 10 out of 12 entity types post-SECOM.",
        "Dependence on spaCy en_core_web_lg and POS tags; quality may vary across domains/projects."
      ],
      "future_work": [
        "Make the tool more customizable and extensible, and able to generate suggestions for the writer or even potential automated refactorings.",
        "Improve configurability of rules and add generation of guidance for non-compliant fields."
      ],
      "motivation": "Enable transparent and efficient vulnerability and patch disclosure by enforcing a standard (SECOM) for security commit messages and providing automated compliance checking.",
      "potential_research_ideas": [
        "Create and release a labeled benchmark dataset for security commit messages with entity annotations (VULNID, CWEID, SEVERITY, etc.) to foster comparative research.",
        "Train and evaluate transformer-based NER models fine-tuned on security commit messages and compare against rule-based extraction.",
        "Integrate code diff/context (files changed, patch hunks) to improve disambiguation and auto-fill metadata (e.g., introduced-in commit, affected versions).",
        "Develop an LLM-based assistant that drafts SECOM-compliant messages from diffs and issue links, with human-in-the-loop editing.",
        "Multilingual SECOM compliance checking and cross-project style adaptation via prompt-tuning or domain adaptation.",
        "Active learning to iteratively refine entity patterns/models from developer feedback in CI.",
        "Link extracted entities to external knowledge graphs (CVE, CWE, CVSS) for validation and auto-correction.",
        "Evaluate the impact of SECOMlint adoption on downstream processes (vulnerability triage time, regression rates)."
      ],
      "architectural_improvement_recommendations": [
        "Augment rule-based extractor with a hybrid pipeline: transformer-based NER (e.g., RoBERTa/BERT fine-tuned) backed by rule constraints for precision.",
        "Use contextual features from the Git diff and repository metadata to validate and enrich extracted entities (e.g., SHA, versions, issue/PR links).",
        "Introduce confidence scoring and uncertainty highlighting for each extracted entity with suggest/fix actions.",
        "Implement pluggable language packs and organization-specific rule profiles with schema validation.",
        "Add active-learning loop to capture false positives/negatives from developer feedback and update patterns/models.",
        "Build a template-driven generator that auto-populates SECOM fields from detected entities and repository context."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://tqrg.github.io/secomlint/",
      "frameworks": [
        "Python",
        "spaCy"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Python 3.8+, spaCy en_core_web_lg model; CPU only; CLI tool suitable for CI integration"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Command-line tool intended for integration into the software development lifecycle (e.g., git hooks/CI), per paper description.",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Customization of rules and severities per organization requires configuration management.",
        "Coverage gaps for unconventional or terse commit messages may yield false negatives/positives.",
        "Dependency on downloading a large spaCy model may complicate air-gapped environments.",
        "Lack of multilingual support and project-specific jargon handling."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces SECOMlint, a configurable linter to check compliance of security commit messages against the SECOM standard.",
      "Defines a domain-specific set of NER entity types and rule-based extraction tailored to security commit messages (e.g., VULNID, CWEID, SEVERITY, DETECTION).",
      "Provides an open-source CLI tool and documentation, designed for easy SDLC integration.",
      "Empirical evaluation on two samples (500 pre-SECOM and 500 after-SECOM messages) showing increased extractable information when SECOM is applied: \"The mean compliance score for the before_secom sample was 76:01%... The mean compliance score for the after_secom sample was 86:61%.\"",
      "Quantifies entity extraction improvements with SECOM: \"before_secom... total of 2675 entities—an average of 5 entities per security commit message\" vs. \"after_secom... a total of 9911 different entities—an average of 20 entities per security commit message\" and \"The tool extracted 10 out of 12 types of entities\" in the after_secom sample."
    ]
  },
  {
    "arxiv_id": "2302.14172v2",
    "title": "Enhancing Vulnerability Prioritization: Data-Driven Exploit Predictions with Community-Driven Insights",
    "authors": "Jay Jacobs; Sasha Romanosky; Octavian Suciu; Benjamin Edwards; Armin Sarabi",
    "abstract": "The number of disclosed vulnerabilities has been steadily increasing over the years. At the same time, organizations face significant challenges patching their systems, leading to a need to prioritize vulnerability remediation in order to reduce the risk of attacks. Unfortunately, existing vulnerability scoring systems are either vendor-specific, proprietary, or are only commercially available. Moreover, these and other prioritization strategies based on vulnerability severity are poor predictors of actual vulnerability exploitation because they do not incorporate new information that might impact the likelihood of exploitation. In this paper we present the efforts behind building a Special Interest Group (SIG) that seeks to develop a completely data-driven exploit scoring system that produces scores for all known vulnerabilities, that is freely available, and which adapts to new information. The Exploit Prediction Scoring System (EPSS) SIG consists of more than 170 experts from around the world and across all industries, providing crowd-sourced expertise and feedback. Based on these collective insights, we describe the design decisions and trade-offs that lead to the development of the next version of EPSS. This new machine learning model provides an 82\\% performance improvement over past models in distinguishing vulnerabilities that are exploited in the wild and thus may be prioritized for remediation.",
    "published_date": "2023-02-27",
    "pdf_link": "https://arxiv.org/pdf/2302.14172v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Vulnerability Management",
      "subdomain": "Vulnerability Prioritization / Risk Scoring",
      "specific_problem": "Predict the likelihood a CVE will be exploited in the wild within the next 30 days to aid remediation prioritization",
      "attack_types": [
        "Exploitation in the wild (various CVE classes)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost",
        "novel_contribution": "Third-generation EPSS classifier trained on 1,477 engineered features with expanded exploit labels and systematic hyperparameter tuning; produces daily 30-day exploitation probabilities"
      },
      {
        "type": "primary",
        "category": "MLP/Feedforward Neural Network",
        "specific": null,
        "novel_contribution": "Auxiliary model to impute CVSSv3 vectors from CVSSv2 components for older CVEs; validated with 8-fold yearly-stratified CV achieving 74.9% exact-vector accuracy"
      },
      {
        "type": "primary",
        "category": "NLP / Keyword Extraction",
        "specific": "RAKE (Rapid Automatic Keyword Extraction)",
        "novel_contribution": "Used to extract multi-word expressions and normalize to 147 vulnerability concept features from CVE descriptions and references"
      },
      {
        "type": "baseline",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost (EPSS v2)",
        "novel_contribution": "Prior centralized EPSS model using 1,164 features; predicted 30-day exploitation window"
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": "EPSS v1 lightweight, interpretable model with 16 features predicting first-year exploitation probability"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "MITRE CVE List",
        "type": "public",
        "domain": "vulnerability_catalog",
        "link": "https://cve.mitre.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NVD (CVSS base metrics v2/v3)",
        "type": "public",
        "domain": "vulnerability_metadata",
        "link": "https://nvd.nist.gov",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NVD Reference Tags",
        "type": "public",
        "domain": "vulnerability_metadata",
        "link": "https://nvd.nist.gov",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NVD CWE Assignments",
        "type": "public",
        "domain": "vulnerability_metadata",
        "link": "https://nvd.nist.gov",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NVD CPE (Vendor fields)",
        "type": "public",
        "domain": "vulnerability_metadata",
        "link": "https://nvd.nist.gov/products/cpe",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "FortiGuard Exploit Telemetry",
        "type": "proprietary",
        "domain": "network_ids_ips_honeypot",
        "link": "https://www.fortiguard.com/",
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "AlienVault OTX Exploit Telemetry",
        "type": "public",
        "domain": "threat_intel_platform",
        "link": "https://otx.alienvault.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Shadowserver Exploit Observations",
        "type": "public",
        "domain": "honeypot_network_sensor",
        "link": "https://www.shadowserver.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "GreyNoise Exploit Observations",
        "type": "proprietary",
        "domain": "internet_scanner_honeypot",
        "link": "https://www.greynoise.io/",
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Exploit-DB",
        "type": "public",
        "domain": "exploit_code",
        "link": "https://www.exploit-db.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "GitHub (public exploit repos)",
        "type": "public",
        "domain": "exploit_code",
        "link": "https://github.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Metasploit Modules",
        "type": "public",
        "domain": "exploit_code",
        "link": "https://github.com/rapid7/metasploit-framework",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CISA Known Exploited Vulnerabilities (KEV) Catalog",
        "type": "public",
        "domain": "curated_exploited_vulnerabilities",
        "link": "https://www.cisa.gov/known-exploited-vulnerabilities",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Google Project Zero 0-day Spreadsheet",
        "type": "public",
        "domain": "curated_zero_day_cases",
        "link": "https://docs.google.com/spreadsheets/d/1lkNJ0uQwbeC1ZTRrxdtuPLCIl7mlUreoKfSIgajnSyY/view",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Trend Micro Zero Day Initiative (ZDI) Advisories",
        "type": "public",
        "domain": "vulnerability_advisories",
        "link": "https://www.zerodayinitiative.com/advisories/published/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Twitter CVE Mentions",
        "type": "public",
        "domain": "social_media",
        "link": "https://twitter.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Nuclei CVE Templates",
        "type": "public",
        "domain": "offensive_tools",
        "link": "https://github.com/projectdiscovery/nuclei-templates",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Jaeles Signatures",
        "type": "public",
        "domain": "offensive_tools",
        "link": "https://github.com/jaeles-project/jaeles-signatures",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Intrigue Ident",
        "type": "public",
        "domain": "offensive_tools",
        "link": "https://github.com/intrigueio/intrigue-ident",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Sn1per",
        "type": "public",
        "domain": "offensive_tools",
        "link": "https://github.com/1N3/Sn1per",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "EPSS v2 (XGBoost)",
        "paper_reference": "Jacobs et al. (2021) EPSS v2",
        "metric": "Area Under the Precision/Recall Curve (PR AUC)",
        "their_result": "0.779",
        "baseline_result": "0.429"
      },
      {
        "method_name": "CVSS-based prioritization",
        "paper_reference": "FIRST (2019) CVSS; prior studies cited",
        "metric": "Remediation effort to capture critical exploited vulns",
        "their_result": "Requires one-eighth the effort of a comparable strategy based on CVSS",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Area Under the Precision/Recall Curve (PR AUC)",
      "Accuracy (for CVSSv3 vector prediction)",
      "Cross-validation (8-fold yearly-stratified) accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to design a public, adaptive, data-driven exploit prediction scoring system that aligns with practitioner workflows?",
        "Can expanded labels and engineered features substantially improve prediction of exploitation in the wild over prior EPSS versions and CVSS-based approaches?",
        "What design decisions and trade-offs (e.g., centralized architecture, prediction horizon) maximize practical utility for vulnerability remediation?"
      ],
      "gaps_identified": [
        "CVSS and severity-based strategies are poor predictors of actual exploitation because they do not incorporate post-disclosure information.",
        "Existing vendor risk scores are vendor-specific, proprietary, or commercially available only, limiting transparency and access.",
        "Public exploit and list sources lack transparency about exploitation timing and duration.",
        "Aggregating exploit evidence from multiple sources yields non-uniform coverage that may induce class- and feature-dependent label noise.",
        "Earlier EPSS versions were limited in features (v1) and precision for practitioner needs (v2)."
      ],
      "limitations": [
        "Centralized architecture loses portability to score non-public vulnerabilities (e.g., zero-days without CVE).",
        "Label coverage is non-uniform across vulnerability types, potentially introducing class- and feature-dependent noise.",
        "Social media feature collection does not validate content or filter bots.",
        "Public lists (e.g., KEV, ZDI, GPZ) lack transparency on when exploitation occurred and for how long.",
        "Vendor parsing from CPE left typos/misspellings uncorrected.",
        "Reliance on proprietary partner data sources for some exploit labels constrains independent reproducibility."
      ],
      "future_work": [
        "Further research into the robustness of CVSSv3 prediction and its application to future versions of CVSS.",
        "Expand exploit telemetry partnerships and coverage to reduce label sparsity and noise.",
        "Continue improving precision for practitioner-aligned thresholds and patch cycles."
      ],
      "motivation": "Rapid growth in disclosed vulnerabilities and limited patching capacity require better prioritization than severity scores. A public, adaptive, data-driven system is needed to quantify likelihood of exploitation and align with practitioner cycles.",
      "potential_research_ideas": [
        "Develop positive-unlabeled or noise-robust learning methods to mitigate class/feature-dependent label noise from heterogeneous telemetry.",
        "Incorporate temporal/sequential models (e.g., survival analysis or time-aware gradient boosting) to better model exploitation hazard over time.",
        "Leverage code and advisory NLP (e.g., transformer-based models) to derive richer semantic features from advisories, PoCs, and commits.",
        "Graph-based modeling over CPE/CWE/vendor-product relationships to capture propagation and shared risk across ecosystems.",
        "Calibrate and personalize EPSS scores per-organization using deployment-specific context (asset exposure, patch latency) via domain adaptation.",
        "Open, community honeypot federation to create transparent, standardized labels for exploitation timing and prevalence.",
        "Causal inference to disentangle confounders (e.g., publicity, vendor popularity) from intrinsic exploitability signals."
      ],
      "architectural_improvement_recommendations": [
        "Add probability calibration and thresholding tuned to specific remediation budgets and patch cycles.",
        "Adopt time-aware boosting or survival models for 30-day window prediction to better handle recency and censoring.",
        "Implement feature attribution and stability checks (e.g., SHAP with monotonic constraints) to improve interpretability and practitioner trust.",
        "Use ensembling (stacking LightGBM/XGBoost/NGBoost) with Bayesian optimization for hyperparameters.",
        "Integrate de-duplication and normalization pipelines for vendor/CPE fields (fuzzy matching, canonicalization).",
        "Apply robust training (loss correction, sample reweighting) against suspected noisy label regions.",
        "Automate bot filtering and content validation for social media features."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Centralized public scoring service (daily EPSS scoring pipeline)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Maintaining and integrating diverse, evolving data sources at scale",
        "Non-uniform telemetry coverage leading to potential bias/noise",
        "Loss of portability for non-public vulnerabilities (e.g., zero-days)",
        "Need for continuous daily updates and retraining while ensuring stability"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Present lessons learned from developing an exploit prediction model integrating requirements from nearly 200 practitioners and researchers.",
      "Engineer novel features for exploit prediction and train an improved EPSS classifier for 30-day exploitation likelihood.",
      "Demonstrate practical utility: 82% improvement in PR AUC over v2 (0.779 vs 0.429) and reduced remediation effort to one-eighth of a CVSS-based strategy."
    ]
  },
  {
    "arxiv_id": "2301.12680v1",
    "title": "Feature-Space Bayesian Adversarial Learning Improved Malware Detector Robustness",
    "authors": "Bao Gia Doan; Shuiqiao Yang; Paul Montague; Olivier De Vel; Tamas Abraham; Seyit Camtepe; Salil S. Kanhere; Ehsan Abbasnejad; Damith C. Ranasinghe",
    "abstract": "We present a new algorithm to train a robust malware detector. Modern malware detectors rely on machine learning algorithms. Now, the adversarial objective is to devise alterations to the malware code to decrease the chance of being detected whilst preserving the functionality and realism of the malware. Adversarial learning is effective in improving robustness but generating functional and realistic adversarial malware samples is non-trivial. Because: i) in contrast to tasks capable of using gradient-based feedback, adversarial learning in a domain without a differentiable mapping function from the problem space (malware code inputs) to the feature space is hard; and ii) it is difficult to ensure the adversarial malware is realistic and functional. This presents a challenge for developing scalable adversarial machine learning algorithms for large datasets at a production or commercial scale to realize robust malware detectors. We propose an alternative; perform adversarial learning in the feature space in contrast to the problem space. We prove the projection of perturbed, yet valid malware, in the problem space into feature space will always be a subset of adversarials generated in the feature space. Hence, by generating a robust network against feature-space adversarial examples, we inherently achieve robustness against problem-space adversarial examples. We formulate a Bayesian adversarial learning objective that captures the distribution of models for improved robustness. We prove that our learning method bounds the difference between the adversarial risk and empirical risk explaining the improved robustness. We show that adversarially trained BNNs achieve state-of-the-art robustness. Notably, adversarially trained BNNs are robust against stronger attacks with larger attack budgets by a margin of up to 15% on a recent production-scale malware dataset of more than 20 million samples.",
    "published_date": "2023-01-30",
    "pdf_link": "https://arxiv.org/pdf/2301.12680v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection",
      "specific_problem": "Adversarially robust Windows PE malware detection using feature-space Bayesian adversarial learning",
      "attack_types": [
        "Evasion attacks (adversarial examples)",
        "Feature-space adversarial attacks",
        "Problem-space adversarial malware (functional, realistic, malicious)",
        "White-box attacker with perfect knowledge"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Bayesian Neural Network",
        "specific": null,
        "novel_contribution": "Formulates a Bayesian adversarial learning objective (Adv-MalBayes) that captures the distribution of models; adversarially trains BNNs in feature space and proves bounds between adversarial and empirical risk"
      },
      {
        "type": "primary",
        "category": "Adversarial Training",
        "specific": "Feature-space adversarial training",
        "novel_contribution": "Proves that problem-space adversarials project to a subset of feature-space adversarials; thus training against feature-space attacks yields robustness to constrained problem-space attacks"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Adversarial Training",
      "Bayesian Learning"
    ],
    "datasets": [
      {
        "name": "SOREL-20M",
        "type": "public",
        "domain": "malware_binaries_static",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "EMBER (feature mapping function)",
        "type": "public",
        "domain": "malware_binaries_static",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "False Positive Rate (FPR)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "RQ1. How can we overcome the challenging problem of adversarial learning for malware at a production scale to realize robust malware detectors against adversarial malware samples?",
        "RQ2. How can we formulate an adversarial learning problem for building robust malware detectors and how can we explain the robustness and benefits?",
        "RQ3. How robust are adversarially trained malware detectors, especially against problem-space (functional, realistic and malicious) adversarial malware samples?"
      ],
      "gaps_identified": [
        "Lack of scalable adversarial training for malware in the problem space due to non-differentiable inverse feature mapping",
        "Difficulty ensuring realism and functionality of problem-space adversarial malware",
        "Absence of methods that scale to production-scale datasets for neural networks in malware domain",
        "Robustness of models built on SOREL-20M features under evasion attacks was not yet understood",
        "Few studies comprehensively investigate robust defense methods for malware detectors"
      ],
      "limitations": [
        "Focus on Windows PE malware; transfer to other file formats/OS is argued but not empirically demonstrated in the main text"
      ],
      "future_work": [],
      "motivation": "Build robust, production-scale malware detectors resilient to adversarial evasion without needing infeasible problem-space adversarial generation; leverage feature-space training with Bayesian formulation to capture model uncertainty and improve robustness.",
      "potential_research_ideas": [
        "Extend feature-space Bayesian adversarial learning to dynamic behavior features and hybrid static-dynamic representations",
        "Develop certified robustness guarantees that connect feature-space robustness to concrete, allowable problem-space transformations for PE files",
        "Evaluate against and adapt to advanced problem-space attack frameworks to tighten the feature-space constraints to realistic malware operations",
        "Online/continual robust learning under distribution shift in malware streams with uncertainty-aware drift detection",
        "Combine BNNs with deep ensembles or last-layer Laplace approximations to further improve uncertainty calibration at low FPR",
        "Investigate transferability and adaptation to other ecosystems (Android, Linux, PDF) with domain-specific feature constraints",
        "Incorporate cost-sensitive training optimizing TPR at extremely low FPR regimes typical for AV settings",
        "Leverage self-supervised pretraining on large unlabeled PE corpora followed by Bayesian adversarial finetuning"
      ],
      "architectural_improvement_recommendations": [
        "Use stronger adversarial objectives such as TRADES in the Bayesian setting to balance natural and robust accuracy",
        "Adopt stochastic-gradient MCMC (e.g., SGLD/SGHMC) or SWAG/last-layer Laplace for posterior approximation in large-scale BNNs",
        "Employ adversarial weight perturbation in addition to input perturbations for added robustness",
        "Incorporate calibrated uncertainty (temperature scaling, prior selection) for thresholding at ultra-low FPR",
        "Multi-view feature fusion (imports, byte n-grams, section stats) with shared Bayesian backbone and adversarial training",
        "Curriculum adversarial training with progressively increasing feature-space budgets aligned to feasible problem-space transformations"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Training at production scale on SOREL-20M (>20M samples); feature extraction to vectorized features reported as ~160 ms per sample on average (per Appendix note)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Generating functional and realistic problem-space adversarial malware is difficult and computationally expensive",
        "Non-differentiable inverse feature mapping from feature to problem space hampers gradient-based methods",
        "Training and evaluation at production scale require substantial compute and data handling",
        "Ensuring robustness under realistic attacker constraints and larger attack budgets"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proves that projections of valid, perturbed malware in problem space lie within the set of feature-space adversarials; thus robustness to feature-space attacks implies robustness to constrained problem-space attacks.",
      "Formulates a Bayesian adversarial learning objective and algorithm (Adv-MalBayes) that captures distributions over models and scales to feature-space datasets up to 20M samples.",
      "Proves that adversarially training BNNs bounds the difference between adversarial risk and empirical risk, explaining improved robustness.",
      "Demonstrates empirically that adversarially trained BNNs achieve state-of-the-art robustness, including against stronger attacks with larger budgets by up to 15% on SOREL-20M, and establishes a benchmark for future defenses."
    ]
  },
  {
    "arxiv_id": "2303.01679v2",
    "title": "Automated Machine Learning for Deep Learning based Malware Detection",
    "authors": "Austin Brown; Maanak Gupta; Mahmoud Abdelsalam",
    "abstract": "Deep learning (DL) has proven to be effective in detecting sophisticated malware that is constantly evolving. Even though deep learning has alleviated the feature engineering problem, finding the most optimal DL model, in terms of neural architecture search (NAS) and the model's optimal set of hyper-parameters, remains a challenge that requires domain expertise. In addition, many of the proposed state-of-the-art models are very complex and may not be the best fit for different datasets. A promising approach, known as Automated Machine Learning (AutoML), can reduce the domain expertise required to implement a custom DL model. AutoML reduces the amount of human trial-and-error involved in designing DL models, and in more recent implementations can find new model architectures with relatively low computational overhead.   This work provides a comprehensive analysis and insights on using AutoML for static and online malware detection. For static, our analysis is performed on two widely used malware datasets: SOREL-20M to demonstrate efficacy on large datasets; and EMBER-2018, a smaller dataset specifically curated to hinder the performance of machine learning models. In addition, we show the effects of tuning the NAS process parameters on finding a more optimal malware detection model on these static analysis datasets. Further, we also demonstrate that AutoML is performant in online malware detection scenarios using Convolutional Neural Networks (CNNs) for cloud IaaS. We compare an AutoML technique to six existing state-of-the-art CNNs using a newly generated online malware dataset with and without other applications running in the background during malware execution.In general, our experimental results show that the performance of AutoML based static and online malware detection models are on par or even better than state-of-the-art models or hand-designed models presented in literature.",
    "published_date": "2023-03-03",
    "pdf_link": "https://arxiv.org/pdf/2303.01679v2",
    "paper_types": [
      "empirical_analysis",
      "new_dataset"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Static and Online Malware Detection",
      "specific_problem": "Applying Automated Machine Learning (AutoML) with neural architecture search and hyperparameter optimization to build deep learning models for malware detection on static PE features and online cloud IaaS host telemetry",
      "attack_types": [
        "general malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "NAS",
        "specific": "One-shot NAS for CNNs",
        "novel_contribution": "Applies one-shot AutoML NAS to derive CNN architectures for online malware detection and shows it can outperform six state-of-the-art CNNs with little overhead"
      },
      {
        "type": "primary",
        "category": "NAS",
        "specific": "Multi-trial NAS for FFNNs",
        "novel_contribution": "Conducts multi-trial NAS and HPO over FFNN (MLP) architectures for static PE malware detection; analyzes effects of NAS process parameters"
      },
      {
        "type": "primary",
        "category": "Feed Forward Neural Network",
        "specific": "Deep FFNN / MLP",
        "novel_contribution": "AutoML-discovered FFNNs for static malware detection on SOREL-20M and EMBER-2018; comparable to manually crafted models without extensive tuning"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "AutoML-derived CNN",
        "novel_contribution": "AutoML-derived CNNs for online detection using per-process system metrics framed as images in cloud IaaS"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "Six existing state-of-the-art CNNs used as baselines for online malware detection (exact architectures not specified in provided text)"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "SOREL-20M",
        "type": "public",
        "domain": "malware_binaries (static PE features)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "EMBER-2018",
        "type": "public",
        "domain": "malware_binaries (static PE features)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Online malware dataset for cloud IaaS (newly generated by authors)",
        "type": "proprietary",
        "domain": "host_performance_metrics (per-process system metrics on Linux cloud servers)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Six state-of-the-art CNNs (unspecified)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Is AutoML feasible and effective for deep learning-based static malware detection on PE datasets such as SOREL-20M and EMBER-2018?",
        "How do NAS process parameters affect the performance of AutoML-discovered models for static malware detection?",
        "Can one-shot AutoML for CNNs achieve superior performance to existing state-of-the-art CNNs for online malware detection in cloud IaaS?"
      ],
      "gaps_identified": [
        "Research on the feasibility of using AutoML for malware detection is very limited.",
        "State-of-the-art DL models adapted from other domains are often complex and may not be optimal for malware data.",
        "Hand-designed architectures require extensive domain expertise and heavy tuning.",
        "AutoML adoption and application in cybersecurity remains limited."
      ],
      "limitations": [
        "AutoML pipelines require more computational time to produce a model, even if they reduce human effort.",
        "Multi-trial NAS approaches can become unstable in later trials if not carefully controlled (general limitation discussed).",
        "Efficacy of AutoML often hinges on the volume of accessible data and the intricacy of the task."
      ],
      "future_work": [
        "Improve the efficiency and performance of AutoML models designed for malware detection.",
        "Explore AutoML’s potential in other cybersecurity areas such as Network Intrusion Detection, Security Log Analysis, and Threat Intelligence.",
        "Further study and tuning of NAS process parameters tailored to malware data characteristics."
      ],
      "motivation": "Reduce domain expertise and human trial-and-error required to design and tune deep learning architectures for malware detection as malware and data sources evolve, while addressing the mismatch and complexity of generic SOTA DL models for malware tasks.",
      "potential_research_ideas": [
        "Design malware-specific NAS search spaces (e.g., PE-header-aware layers, feature gating) to improve search efficiency and model fit.",
        "Multi-objective AutoML that jointly optimizes for accuracy, inference latency, and model size for real-time online detection on IaaS.",
        "Integrate adversarial robustness objectives into NAS/HPO to discover architectures resilient to evasion attacks.",
        "Transfer/NAS warm-start across datasets (e.g., from EMBER to SOREL-20M or to enterprise PE corpora) to reduce search cost.",
        "Continual/online AutoML that adapts architectures or hyperparameters over time with evolving malware.",
        "Explainability-aware NAS that enforces feature attribution sparsity or monotonic constraints to improve analyst trust."
      ],
      "architectural_improvement_recommendations": [
        "Constrain NAS search space with malware-domain priors (e.g., attention over PE sections, skip connections aligned with semantic fields).",
        "Introduce lightweight attention or Squeeze-and-Excitation modules in CNNs for online telemetry images to emphasize salient processes/metrics.",
        "Use neural architecture cells specialized for tabular/static features (e.g., ResNet-style MLP blocks, gated MLPs) in FFNN search.",
        "Adopt hardware-aware NAS (FLOPs/latency constraints) to ensure deployability on cloud monitoring agents.",
        "Employ regularization/hyperparameter schedules (label smoothing, mixup/cutmix for tabular proxies, stochastic depth) within HPO.",
        "Explore hybrid models (CNN+RNN/Temporal Conv) to capture temporal patterns in online telemetry beyond single time-slice images."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "AutoML incurs additional computational time; one-shot NAS reports relatively low overhead for finding CNN architectures compared to exhaustive search (exact hardware and runtimes not specified)."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Cloud IaaS Linux servers (online host telemetry with malware execution; with/without background applications)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Overhead of continuous monitoring in online detection scenarios",
        "Increased computational time for AutoML search relative to manual model selection"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Feasibility study of AutoML for deep learning-based static malware detection with AutoML-discovered FFNNs comparable to manual models without extensive tuning.",
      "Analysis of AutoML NAS process parameters and their impact on performance for static malware datasets (SOREL-20M and EMBER-2018).",
      "Demonstration that AutoML-derived CNNs outperform six state-of-the-art CNNs for online malware detection in cloud IaaS with little architecture search overhead.",
      "Introduce a newly generated online malware dataset (with/without background applications) for evaluating online detection methods.",
      "Discussion of ideas and future directions for improving efficiency and performance of AutoML models for malware detection."
    ]
  },
  {
    "arxiv_id": "2302.12205v1",
    "title": "Harris Hawks Feature Selection in Distributed Machine Learning for Secure IoT Environments",
    "authors": "Neveen Hijazi; Moayad Aloqaily; Bassem Ouni; Fakhri Karray; Merouane Debbah",
    "abstract": "The development of the Internet of Things (IoT) has dramatically expanded our daily lives, playing a pivotal role in the enablement of smart cities, healthcare, and buildings. Emerging technologies, such as IoT, seek to improve the quality of service in cognitive cities. Although IoT applications are helpful in smart building applications, they present a real risk as the large number of interconnected devices in those buildings, using heterogeneous networks, increases the number of potential IoT attacks. IoT applications can collect and transfer sensitive data. Therefore, it is necessary to develop new methods to detect hacked IoT devices. This paper proposes a Feature Selection (FS) model based on Harris Hawks Optimization (HHO) and Random Weight Network (RWN) to detect IoT botnet attacks launched from compromised IoT devices. Distributed Machine Learning (DML) aims to train models locally on edge devices without sharing data to a central server. Therefore, we apply the proposed approach using centralized and distributed ML models. Both learning models are evaluated under two benchmark datasets for IoT botnet attacks and compared with other well-known classification techniques using different evaluation indicators. The experimental results show an improvement in terms of accuracy, precision, recall, and F-measure in most cases. The proposed method achieves an average F-measure up to 99.9\\%. The results show that the DML model achieves competitive performance against centralized ML while maintaining the data locally.",
    "published_date": "2023-02-20",
    "pdf_link": "https://arxiv.org/pdf/2302.12205v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Feature-selection-driven intrusion/botnet detection for IoT devices, evaluated in centralized and distributed ML settings; also evaluated on phishing website classification",
      "attack_types": [
        "Mirai",
        "BASHLITE",
        "Phishing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Metaheuristic Optimizer",
        "specific": "Harris Hawks Optimization (HHO)",
        "novel_contribution": "Wrapper feature selection where HHO simultaneously selects a near-optimal subset of features and the number of hidden neurons of the classifier"
      },
      {
        "type": "primary",
        "category": "Shallow Neural Network",
        "specific": "Random Weight Network (RWN)",
        "novel_contribution": "Used as the base classifier within the wrapper feature selection (instead of common choices like KNN), with its hidden-layer size optimized by HHO"
      },
      {
        "type": "primary",
        "category": "Distributed/Decentralized Learning",
        "specific": "Distributed ML (local training without sharing raw data)",
        "novel_contribution": "Applies the HHO-RWN wrapper in a distributed ML scheme to preserve data locality/privacy while achieving performance competitive with centralized ML"
      },
      {
        "type": "baseline",
        "category": "Instance-based",
        "specific": "K-Nearest Neighbors (KNN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Kernel Method",
        "specific": "Support Vector Machine (SVM)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble",
        "specific": "AdaBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "Decision Tree (DT)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Distributed"
    ],
    "datasets": [
      {
        "name": "N-BaIoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Phishing Legitimate Dataset (Kaggle)",
        "type": "public",
        "domain": "web_page_features",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "HHO-SVM",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "“The accuracy rate has improved up to 2.6% compared to HHO-SVM in Security camera device.”",
        "baseline_result": null
      },
      {
        "method_name": "HHO-SVM",
        "paper_reference": null,
        "metric": "F-measure",
        "their_result": "“The F-measure rate has improved by 8.0% compared to HHO-SVM in Webcam device.”; best average F-measure up to 99.9%",
        "baseline_result": null
      },
      {
        "method_name": "HHO-AdaBoost",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "HHO-RWN average accuracy values are enhanced compared to AdaBoost (centralized).",
        "baseline_result": null
      },
      {
        "method_name": "HHO-DT",
        "paper_reference": null,
        "metric": "F-measure (Distributed)",
        "their_result": "On the Webcam dataset, HHO-RWN and HHO-DT obtained the highest F-measure with 99.9%.",
        "baseline_result": "HHO-AdaBoost achieved the second highest with 99.5%."
      },
      {
        "method_name": "HHO-kNN",
        "paper_reference": null,
        "metric": "Convergence/fitness during training",
        "their_result": "HHO-RWN shows better convergence in multiple devices (per convergence curves).",
        "baseline_result": null
      },
      {
        "method_name": "Other classifiers (aggregate)",
        "paper_reference": null,
        "metric": "Precision",
        "their_result": "“The precision enhancement rate reached 6.6% in Phishing legitimate dataset.” (centralized); in distributed, precision enhanced up to 14.5% in Phishing dataset.",
        "baseline_result": null
      },
      {
        "method_name": "Other classifiers (aggregate)",
        "paper_reference": null,
        "metric": "Recall (Distributed)",
        "their_result": "“According to the average recall results, the maximum result achieved by HHO-RWN with 99.0%, and the improvement rate reached 24.0% in the Security camera device.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F-measure"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "IoT devices generate vast, high-dimensional data; traditional ML struggles and requires efficient search/learning algorithms.",
        "Feature selection wrappers can be computationally expensive; need faster yet accurate classifiers within wrappers.",
        "Centralized ML raises privacy and single-point-of-failure concerns; need distributed approaches that keep data local.",
        "No Free Lunch theorem motivates exploring new optimizer–learner hybrids for broader applicability."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Detect IoT botnet attacks from compromised devices while preserving data privacy, by combining metaheuristic feature selection with a fast-generalizing classifier and deploying it in a distributed ML setup.",
      "potential_research_ideas": [
        "Integrate federated learning with secure aggregation and client drift handling for truly decentralized training beyond simple data partitioning.",
        "Evaluate adversarial robustness of HHO-RWN against evasion and poisoning attacks in IoT traffic and phishing domains.",
        "Extend to additional IoT datasets (e.g., Bot-IoT, ToN-IoT) and cross-device generalization to assess robustness across heterogeneous devices.",
        "Incorporate concept drift detection and online feature selection to adapt to evolving IoT traffic patterns.",
        "Add explainability (e.g., SHAP for selected features) to understand which features drive detections per device.",
        "Apply communication-efficient distributed optimization (e.g., sparse/quantized updates) and compare with standard federated averaging.",
        "Explore hybrid deep-shallow pipelines (e.g., autoencoder for representation + RWN for fast classification) with HHO selecting features/latent dims.",
        "Introduce privacy guarantees (differential privacy) and measure utility-privacy trade-offs with HHO-driven model compression."
      ],
      "architectural_improvement_recommendations": [
        "Replace manual fitness weights with multi-objective optimization (e.g., Pareto-based HHO) to jointly optimize F-measure, feature count, and neuron count without scalarization.",
        "Use stratified client sampling and weighted aggregation to reflect client data heterogeneity in the distributed setting.",
        "Warm-start HHO with filter-based preselection to cut search space and reduce wrapper runtime.",
        "Incorporate early stopping and adaptive population sizing in HHO to reduce compute while maintaining solution quality.",
        "Augment RWN with regularization (e.g., L2, dropout-like noise) and calibration to improve generalization and probability estimates.",
        "Adopt secure aggregation or homomorphic encryption for model update sharing to strengthen privacy in distributed training."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Python 3.9.12; Intel Core i7-165G7 2.8 GHz CPU, 16 GB RAM; evolutionary runs: 30 independent runs, 100 iterations, population size 200; fitness weights set to 0.99 (error), 0.01 (feature count), 0.01 (hidden neurons); max hidden neurons 1024."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "IoT devices are not well-suited for intensive computation.",
        "High-dimensional data necessitates efficient feature selection to reduce computational time.",
        "Data privacy concerns in centralized ML motivate local training without sharing raw data."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "An intrusion detection system based on HHO with RWN.",
      "RWN used as the base classifier in wrapper feature selection, unlike most literature that uses KNN.",
      "HHO jointly selects a near-optimal subset of features and the number of hidden neurons in RWN.",
      "Leverages distributed ML to maintain data privacy and applies the proposed approach in a distributed scheme.",
      "Empirical evaluation on N-BaIoT and a phishing dataset showing average F-measure up to 99.9% and competitive distributed vs centralized performance."
    ]
  },
  {
    "arxiv_id": "2304.13894v1",
    "title": "CNN based IoT Device Identification",
    "authors": "Kahraman Kostas",
    "abstract": "While the use of the Internet of Things is becoming more and more popular, many security vulnerabilities are emerging with the large number of devices being introduced to the market. In this environment, IoT device identification methods provide a preventive security measure as an important factor in identifying these devices and detecting the vulnerabilities they suffer from. In this study, we present a method that identifies devices in the Aalto dataset using the convolutional neural network (CNN).",
    "published_date": "2023-04-27",
    "pdf_link": "https://arxiv.org/pdf/2304.13894v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Device Fingerprinting/Identification",
      "specific_problem": "Identifying IoT device types from network traffic using payload-only pseudo-images with CNN",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "2D CNN on 28x28 pseudo-images created from first 784 payload bytes",
        "novel_contribution": "Applies payload-only pseudo-images (no header features) for IoT device identification; compares against CNN trained on IoTDevIDv1 fingerprint features"
      },
      {
        "type": "primary",
        "category": "AutoML/NAS",
        "specific": "AutoKeras ImageClassifier",
        "novel_contribution": "Used to search/select CNN hyperparameters and architecture"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Aalto IoT devices captures (Aalto dataset)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IoTDevIDv1 feature set (behavior-based fingerprints)",
        "type": "",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [
      {
        "method_name": "CNN with Fingerprint (IoTDevIDv1 features)",
        "paper_reference": "Kostas et al., IoTDevID (2021) [6]",
        "metric": "Accuracy",
        "their_result": "0.631 (CNN with Payload)",
        "baseline_result": "0.625 (CNN with Fingerprint)"
      },
      {
        "method_name": "CNN with Fingerprint (IoTDevIDv1 features)",
        "paper_reference": "Kostas et al., IoTDevID (2021) [6]",
        "metric": "Processing time (seconds)",
        "their_result": "209.926 (CNN with Payload)",
        "baseline_result": "20.809 (CNN with Fingerprint)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Processing time (seconds)",
      "Mann–Whitney U test p-value"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a CNN operating on payload-only pseudo-images identify IoT devices in the Aalto dataset?",
        "How does a payload-only CNN compare to a CNN trained on behavior-based fingerprint features (IoTDevIDv1) in accuracy and speed?"
      ],
      "gaps_identified": [
        "Prior CNN-based traffic classification studies cited were on traditional networks rather than IoT device identification.",
        "Limited understanding of trade-offs between payload-only versus fingerprint feature-based methods for IoT device identification."
      ],
      "limitations": [
        "Header features were intentionally not used: focus was on payload-only classification.",
        "Only the first 784 bytes (28x28) of payload were used; longer payloads were truncated and shorter ones zero-padded.",
        "Evaluation confined to Aalto IoT captures; no cross-dataset validation reported."
      ],
      "future_work": [],
      "motivation": "Provide a preventive security measure by accurately identifying IoT devices to help detect vulnerabilities; explore CNN-based identification using payload-only data.",
      "potential_research_ideas": [
        "Combine payload bytes with selective header/session metadata in a multi-branch model to test gains over payload-only.",
        "Evaluate byte-level 1D CNNs or Transformer encoders on packet bytes versus 2D pseudo-images.",
        "Incorporate temporal/flow-level context (e.g., sequence models over packets) for device-level fingerprints.",
        "Self-supervised pretraining on large unlabeled IoT traffic (contrastive learning) then fine-tune for device ID.",
        "Cross-dataset generalization: train on Aalto, test on other IoT traffic to assess robustness to environment changes.",
        "Adversarial robustness evaluation (evasion via payload padding/mutations) and robust training defenses.",
        "Efficient on-device/edge deployment via model compression/distillation while maintaining accuracy.",
        "Device embedding learning with metric learning (Siamese/Triplet) to support few-shot identification of unseen device types."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a hybrid architecture: parallel branches for payload bytes (1D CNN/Transformer) and header/session features, fused with attention.",
        "Use multi-scale CNN kernels and dilations over byte sequences to capture both local and long-range patterns.",
        "Replace 2D pseudo-images with raw byte 1D sequences plus positional encodings to avoid information distortion from reshaping.",
        "Apply self-supervised pretraining (e.g., masked byte modeling or contrastive learning) before supervised fine-tuning.",
        "Leverage flow/session aggregation (temporal CNN/LSTM/Transformer) to move from packet-level to device-level decisions."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/kahramankostas/CNN-based-IoT-Device-Identification",
      "frameworks": [
        "AutoKeras",
        "Keras",
        "TensorFlow"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "Processing time reported: 209.926s (payload CNN) vs 20.809s (fingerprint CNN)",
      "deployment_challenges": [
        "Payload-based CNN approach is ~10x slower than fingerprint-based CNN in reported processing time."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Implements a payload-only CNN device identification pipeline by converting packet payloads into 28x28 pseudo-images (first 784 bytes, zero-padded/truncated).",
      "Empirical comparison of payload-based CNN vs CNN on IoTDevIDv1 fingerprint features, showing similar accuracy (0.631 vs 0.625) but ~10x faster processing for the fingerprint approach.",
      "Provides code/script for payload-to-image conversion and CNN training using AutoKeras."
    ]
  },
  {
    "arxiv_id": "2302.06648v2",
    "title": "That Escalated Quickly: An ML Framework for Alert Prioritization",
    "authors": "Ben Gelman; Salma Taoufiq; Tamás Vörös; Konstantin Berlin",
    "abstract": "In place of in-house solutions, organizations are increasingly moving towards managed services for cyber defense. Security Operations Centers are specialized cybersecurity units responsible for the defense of an organization, but the large-scale centralization of threat detection is causing SOCs to endure an overwhelming amount of false positive alerts -- a phenomenon known as alert fatigue. Large collections of imprecise sensors, an inability to adapt to known false positives, evolution of the threat landscape, and inefficient use of analyst time all contribute to the alert fatigue problem. To combat these issues, we present That Escalated Quickly (TEQ), a machine learning framework that reduces alert fatigue with minimal changes to SOC workflows by predicting alert-level and incident-level actionability. On real-world data, the system is able to reduce the time it takes to respond to actionable incidents by $22.9\\%$, suppress $54\\%$ of false positives with a $95.1\\%$ detection rate, and reduce the number of alerts an analyst needs to investigate within singular incidents by $14\\%$.",
    "published_date": "2023-02-13",
    "pdf_link": "https://arxiv.org/pdf/2302.06648v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Security Operations",
      "subdomain": "Alert Triage and Prioritization (SOC/SIEM)",
      "specific_problem": "Predicting alert- and incident-level actionability to prioritize queues, suppress false positives, and prioritize alerts within incidents to reduce alert fatigue",
      "attack_types": [
        "Malware detection/cleanup (e.g., LemonDuck)",
        "Exploitation (e.g., ProxyShell)",
        "Credential dumping (e.g., Mimikatz)",
        "Suspicious command execution (e.g., PowerShell/Start-BitsTransfer)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": null,
        "novel_contribution": "Two supervised models (alert-level and incident-level) trained on heterogeneous alert content features and temporal/behavioral context are ensembled to produce a final risk score for triage."
      },
      {
        "type": "primary",
        "category": "Other",
        "specific": null,
        "novel_contribution": "Automatic featurization pipeline for semi-structured JSON alert data with validation, missing-value handling, and schema-agnostic feature construction feeding supervised models."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Continual/Lifelong (via analyst feedback loop)"
    ],
    "datasets": [
      {
        "name": "MDR SOC alert and incident data (beta product from a large security company)",
        "type": "proprietary",
        "domain": "log_files (semi-structured SOC alerts/endpoint events)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Queue time reduction for actionable incidents",
      "False positive suppression rate",
      "Detection rate (for actionable incidents)",
      "Within-incident alert reduction (alerts analysts must inspect)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can alert-level and incident-level actionability be predicted to reduce SOC alert fatigue with minimal workflow changes?",
        "Can an automatic featurization framework robustly handle semi-structured, heterogeneous alert JSONs at scale without manual schema engineering?",
        "Does integrating an outcome-based analyst feedback loop improve adaptation to evolving threats and sensor changes?",
        "Do temporal firing patterns and behavioral context across customers/endpoints improve prioritization compared to using alert contents alone?",
        "Can a unified triage system provide incident prioritization, false positive suppression, and within-incident alert prioritization effectively?"
      ],
      "gaps_identified": [
        "Existing work often applies classifiers to fixed alert schemas and only briefly addresses expert feedback integration.",
        "Limited ability to leverage diverse, evolving, semi-structured alert data across multiple organizations and sensors.",
        "Insufficient handling of data evolution/concept drift and adaptation to known false positives.",
        "Inefficient use of analyst time and lack of mechanisms to focus attention within incidents.",
        "Underuse of temporal firing patterns and lack of systems combining alert-level and incident-level scoring."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Large-scale centralization of threat detection in MDR/SOCs leads to overwhelming false positives and alert fatigue; TEQ aims to reduce alert fatigue and improve SOC efficiency with minimal workflow changes by predicting actionability and integrating analyst feedback.",
      "potential_research_ideas": [
        "Learning-to-rank objectives directly optimizing incident queue ordering under operational constraints (SLA-aware ranking).",
        "Active learning to selectively request analyst labels for high-uncertainty incidents and accelerate adaptation.",
        "Concept-drift detection with automated re-training triggers and per-customer/domain adaptation.",
        "Hierarchical/multi-task models jointly learning alert- and incident-level actionability with shared representations.",
        "Graph-based models linking related alerts across endpoints/customers to improve incident context and suppression decisions.",
        "Fairness/tenant-equity analysis ensuring prioritization does not disadvantage certain customers or device types.",
        "Adversarial robustness studies for alert-feature manipulation and defenses (e.g., adversarial training, invariant features).",
        "Causal inference to identify which signals/actions reduce analyst workload while maintaining detection quality.",
        "Improved incident grouping (learning-based correlation) to replace fixed 24h machine-based grouping and assess impact on triage.",
        "Calibration and uncertainty quantification (e.g., conformal prediction) to set reliable suppression thresholds per customer."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a joint multi-task architecture with shared encoder and two heads (alert-level, incident-level), with calibration (Platt/Isotonic) per tenant.",
        "Incorporate sequence/temporal encoders (e.g., Transformer/Temporal Convolution) over alert sequences within incidents and per-endpoint histories.",
        "Use gradient-boosted trees with categorical handling (CatBoost/LightGBM) on auto-features and compare to deep tabular models.",
        "Bayesian hierarchical modeling for customer-specific priors and adaptive thresholding to account for tenant heterogeneity.",
        "Implement drift detectors (e.g., ADWIN/PSI monitoring) and automated re-training pipelines with validation gates.",
        "Integrate uncertainty estimates (ensembles, MC-dropout) to abstain or escalate borderline cases.",
        "Introduce learning-to-rank losses (LambdaRank/ListNet) for queue prioritization rather than pure classification losses.",
        "Apply representation learning for semi-structured JSONs (e.g., learned embeddings for keys/values) to replace purely hand-crafted flattening."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "MDR SOC environment integrated with SIEM/EDR alerts from a large security company (beta product)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Heterogeneous, semi-structured sensor data with missing values and evolving schemas.",
        "High alert volumes requiring scalable featurization and scoring.",
        "Concept drift due to evolving threat landscape and sensor changes.",
        "Minimal-change integration into existing analyst workflows and tooling.",
        "Limited labels at incident-level and label propagation strategy.",
        "Setting and maintaining suppression thresholds to balance detection vs workload."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Demonstration of a hands-off featurization system handling semi-structured alert data without hindering downstream tasks.",
      "An ensemble operating on alert-content and temporal features, broader than prior security datasets.",
      "In-depth evaluation of alert prioritization and feature importance over time across an evolving threat landscape.",
      "First system to utilize both alert-level and incident-level scores for standard incident prioritization and within-incident alert prioritization.",
      "Simple triage system with reported results: “reduce the time it takes to respond to actionable incidents by 22.9%,” “suppress 54% of false positives with a 95.1% detection rate,” and “reduce the number of alerts an analyst needs to investigate within singular incidents by 14%.”"
    ]
  },
  {
    "arxiv_id": "2304.00623v1",
    "title": "MalIoT: Scalable and Real-time Malware Traffic Detection for IoT Networks",
    "authors": "Ethan Weitkamp; Yusuke Satani; Adam Omundsen; Jingwen Wang; Peilong Li",
    "abstract": "The machine learning approach is vital in Internet of Things (IoT) malware traffic detection due to its ability to keep pace with the ever-evolving nature of malware. Machine learning algorithms can quickly and accurately analyze the vast amount of data produced by IoT devices, allowing for the real-time identification of malicious network traffic. The system can handle the exponential growth of IoT devices thanks to the usage of distributed systems like Apache Kafka and Apache Spark, and Intel's oneAPI software stack accelerates model inference speed, making it a useful tool for real-time malware traffic detection. These technologies work together to create a system that can give scalable performance and high accuracy, making it a crucial tool for defending against cyber threats in smart communities and medical institutions.",
    "published_date": "2023-04-02",
    "pdf_link": "https://arxiv.org/pdf/2304.00623v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Malware Traffic Detection",
      "specific_problem": "Scalable, real-time detection of malicious network traffic from IoT devices using distributed streaming (Kafka/Spark) and accelerated ML/DL inference",
      "attack_types": [
        "malware_traffic"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": "Evaluated as part of MalIoT pipeline with streaming inference and oneAPI acceleration"
      },
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": "Evaluated baseline classifier within the streaming pipeline"
      },
      {
        "type": "primary",
        "category": "Linear Model",
        "specific": "Logistic Regression",
        "novel_contribution": "Evaluated baseline classifier within the streaming pipeline"
      },
      {
        "type": "primary",
        "category": "SVM",
        "specific": "Linear SVC",
        "novel_contribution": "Evaluated baseline classifier within the streaming pipeline"
      },
      {
        "type": "primary",
        "category": "Naive Bayes",
        "specific": "GaussianNB",
        "novel_contribution": "Evaluated baseline classifier within the streaming pipeline"
      },
      {
        "type": "primary",
        "category": "MLP",
        "specific": "ANN (1 hidden layer)",
        "novel_contribution": "Evaluated deep model with streaming inference; accelerated via oneAPI/TensorFlow"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D CNN",
        "novel_contribution": "Evaluated deep model on flow features in streaming inference"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "2D CNN",
        "novel_contribution": "Evaluated deep model on transformed inputs with streaming inference"
      },
      {
        "type": "primary",
        "category": "RNN/LSTM",
        "specific": "LSTM",
        "novel_contribution": "Evaluated as sequence model for traffic features"
      },
      {
        "type": "primary",
        "category": "Hybrid",
        "specific": "CNN+LSTM",
        "novel_contribution": "Evaluated hybrid temporal-spatial model"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "IoT-23 (Aposemat/Stratosphere IPS)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ToN IoT",
        "type": "public",
        "domain": "network_traffic; os_telemetry",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC IoT dataset (benign traffic supplement)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Synthesized combined training set (IoT-23 + ToN IoT + CIC IoT benign)",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random Forest (Full feature set) vs Decision Tree (Full feature set)",
        "paper_reference": null,
        "metric": "Inference time per row (ms)",
        "their_result": "Random Forest: 34.20 ms (Table 6)",
        "baseline_result": "Decision Tree: 10.78 ms (Table 6)"
      },
      {
        "method_name": "Logistic Regression (Full feature set) vs Linear SVC (Full feature set)",
        "paper_reference": null,
        "metric": "Inference time per row (ms)",
        "their_result": "Logistic Regression: 10.71 ms (Table 6)",
        "baseline_result": "Linear SVC: 10.68 ms (Table 6)"
      },
      {
        "method_name": "GaussianNB (Full feature set) vs Decision Tree (Full feature set)",
        "paper_reference": null,
        "metric": "Inference time per row (ms)",
        "their_result": "GaussianNB: 10.87 ms (Table 6)",
        "baseline_result": "Decision Tree: 10.78 ms (Table 6)"
      },
      {
        "method_name": "Random Forest (De-identified) vs Random Forest (Full)",
        "paper_reference": null,
        "metric": "Inference time per row (ms)",
        "their_result": "De-identified: 33.18 ms (Table 6)",
        "baseline_result": "Full: 34.20 ms (Table 6)"
      },
      {
        "method_name": "ANN vs LSTM",
        "paper_reference": null,
        "metric": "Inference time per row (ms)",
        "their_result": "ANN: 0.056 ms (Table 7)",
        "baseline_result": "LSTM: 0.378 ms (Table 7)"
      },
      {
        "method_name": "CNN vs CNN2D",
        "paper_reference": null,
        "metric": "Inference time per row (ms)",
        "their_result": "CNN: 0.118 ms (Table 7)",
        "baseline_result": "CNN2D: 0.102 ms (Table 7)"
      },
      {
        "method_name": "CNN+LSTM vs CNN",
        "paper_reference": null,
        "metric": "Inference time per row (ms)",
        "their_result": "CNN+LSTM: 0.226 ms (Table 7)",
        "baseline_result": "CNN: 0.118 ms (Table 7)"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "inference_time"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a distributed Kafka + Spark pipeline enable real-time, scalable IoT malware traffic detection with ML/DL?",
        "Does enriching IoT-23 with ToN IoT (and adding benign CIC IoT traffic) mitigate class imbalance and overfitting?",
        "Can Intel’s oneAPI/DAAL accelerate inference for both ML and DL models in this setting?"
      ],
      "gaps_identified": [
        "Existing ML-based solutions struggle to handle the growing number of IoT devices and detect malicious traffic with low latency.",
        "Prior studies often focus on specific malware types or attack types and limited protocols/layers.",
        "Traditional ML approaches rely heavily on manual feature engineering.",
        "Conventional solutions depend on one network premises and cannot detect attacks originating at different premises.",
        "Class imbalance and model over-fitting in prior work on IoT-23."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Real-time and scalable detection is needed due to rapidly increasing IoT malware attacks; distributed streaming and accelerated inference can improve responsiveness and accuracy for smart communities and medical institutions.",
      "potential_research_ideas": [
        "Online/continual learning with concept-drift detection to adapt models as new IoT malware emerges.",
        "Federated learning across multiple network premises to address privacy and cross-premise generalization.",
        "Graph-based models (e.g., GNNs) over host-communication graphs for improved context-aware detection.",
        "Self-supervised pretraining on large unlabeled network flows to reduce reliance on labeled data.",
        "Multi-modal fusion combining network flows with endpoint/OS telemetry from ToN IoT.",
        "Encrypted traffic-aware detection using side-channel features and TLS fingerprinting.",
        "Explainable detection approaches to provide operator-understandable alerts.",
        "Adversarial robustness evaluation and defenses against evasion/poisoning on traffic features."
      ],
      "architectural_improvement_recommendations": [
        "Integrate a concept-drift monitor and active learning loop in the Spark streaming job for periodic model refresh.",
        "Use ONNX Runtime or OpenVINO/oneDNN for unified model deployment and model quantization to edge gateways.",
        "Adopt Apache Flink or Spark Structured Streaming with low-latency settings to minimize micro-batch delays.",
        "Replace PCAP-based feature extraction with streaming Zeek/Suricata JSON events to reduce preprocessing latency for ML models.",
        "Introduce a model registry and A/B testing in the pipeline to compare models online and prevent regressions.",
        "Calibrate classifiers (e.g., Platt scaling) and threshold tuning under class imbalance with cost-sensitive loss."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/BlueJayADAL/NetSec",
      "frameworks": [
        "TensorFlow",
        "Apache Spark (Spark Streaming, SparkML)",
        "Apache Kafka",
        "Intel oneAPI/DAAL",
        "Zeek (Bro)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Evaluated on Ubuntu 18.04 LTS; CPU: Intel Core i9-9920X @3.50GHz; GPU: NVIDIA GTX 2080 Ti 11GB; RAM: 64GB; Storage: 2TB SSD; TensorFlow 2.7; Spark 3.0.1; Kafka 2.6.0; Intel DAAL v2020.1"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Proposed smart gateway within a local IoT network; streaming via Kafka/Spark",
      "scalability_discussed": true,
      "inference_time": "Per-row DL inference: ANN 0.056 ms; CNN 0.118 ms; CNN2D 0.102 ms; LSTM 0.378 ms; CNN+LSTM 0.226 ms. ML inference (full features): RF 34.20 ms; DT 10.78 ms; LR 10.71 ms; Linear SVC 10.68 ms; GaussianNB 10.87 ms.",
      "deployment_challenges": [
        "Feature extraction overhead for ML models (preprocessing time noted as longer than DL).",
        "Managing class imbalance and avoiding overfitting across heterogeneous IoT networks.",
        "End-to-end latency contributions from PCAP generation and stream ingestion.",
        "Model drift requiring periodic retraining from streaming data.",
        "Resource constraints on edge gateways when running streaming pipelines and inference."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Enriched training by combining IoT-23 with ToN IoT and supplementing with CIC IoT benign traffic to address class imbalance and overfitting.",
      "Accelerated inference using Intel’s oneAPI/DAAL; claimed “three-fold” speedup.",
      "Built a scalable streaming pipeline using Apache Kafka (producer/topic) and Apache Spark (streaming/processing) for real-time IoT malware traffic detection."
    ]
  },
  {
    "arxiv_id": "2301.13686v1",
    "title": "Detecting Unknown Encrypted Malicious Traffic in Real Time via Flow Interaction Graph Analysis",
    "authors": "Chuanpu Fu; Qi Li; Ke Xu",
    "abstract": "In this paper, we propose HyperVision, a realtime unsupervised machine learning (ML) based malicious traffic detection system. Particularly, HyperVision is able to detect unknown patterns of encrypted malicious traffic by utilizing a compact inmemory graph built upon the traffic patterns. The graph captures flow interaction patterns represented by the graph structural features, instead of the features of specific known attacks. We develop an unsupervised graph learning method to detect abnormal interaction patterns by analyzing the connectivity, sparsity, and statistical features of the graph, which allows HyperVision to detect various encrypted attack traffic without requiring any labeled datasets of known attacks. Moreover, we establish an information theory model to demonstrate that the information preserved by the graph approaches the ideal theoretical bound. We show the performance of HyperVision by real-world experiments with 92 datasets including 48 attacks with encrypted malicious traffic. The experimental results illustrate that HyperVision achieves at least 0.92 AUC and 0.86 F1, which significantly outperform the state-of-the-art methods. In particular, more than 50% attacks in our experiments can evade all these methods. Moreover, HyperVision achieves at least 80.6 Gb/s detection throughput with the average detection latency of 0.83s.",
    "published_date": "2023-01-31",
    "pdf_link": "https://arxiv.org/pdf/2301.13686v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Real-time unsupervised detection of unknown encrypted malicious traffic via flow interaction graph analysis",
      "attack_types": [
        "Encrypted flooding (e.g., link-flooding)",
        "Web attacks exploiting vulnerabilities",
        "Malware campaigns (connectivity testing, dependency update, downloading)",
        "Side-channel attack exploiting CVE-2020-36516",
        "Cryptojacking",
        "Data exfiltration (mentioned as motivation)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Graph-based anomaly detection",
        "specific": "Unsupervised graph learning on a flow interaction graph",
        "novel_contribution": "Compact in-memory flow interaction graph representing short- and long-flow interactions separately; four-step lightweight unsupervised pipeline: (1) abnormal component detection via connected components and clustering of component statistics; (2) edge pre-clustering by local adjacency; (3) critical vertex selection via vertex cover solved with Z3 SMT; (4) interaction pattern clustering around critical vertices with anomaly scoring via clustering loss."
      },
      {
        "type": "baseline",
        "category": "Header-based supervised classification",
        "specific": "TLS extensions / HTTPS headers",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Time-series modeling of related flows",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Handshake-feature classifiers",
        "specific": "TLS handshake-based",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Flow-statistics-based ML",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Per-packet feature models",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Per-flow feature models",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "HyperVision VPC Encrypted Attack Datasets (92 datasets; 48 encrypted attack datasets; 80 newly collected)",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://github.com/fuchuanpu/HyperVision",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "MAWI backbone traffic (Jan. 2020 sample, used for flow distribution analysis and as background traffic) [80]",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Five state-of-the-art methods (aggregate)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "“HyperVision achieves 13.9% ~ 36.1% accuracy improvements over five state-of-the-art methods.”",
        "baseline_result": null
      },
      {
        "method_name": "Header-based TLS extensions method",
        "paper_reference": "[16]",
        "metric": null,
        "their_result": "“more than 50% attacks in our experiments can evade all these methods” (baseline failure rate >50% of attacks)",
        "baseline_result": null
      },
      {
        "method_name": "HTTPS header-based method",
        "paper_reference": "[3]",
        "metric": null,
        "their_result": "Same aggregate statement as above",
        "baseline_result": null
      },
      {
        "method_name": "TLS handshake-based method",
        "paper_reference": "[2]",
        "metric": null,
        "their_result": "Same aggregate statement as above",
        "baseline_result": null
      },
      {
        "method_name": "Flow statistics method",
        "paper_reference": "[90]",
        "metric": null,
        "their_result": "Same aggregate statement as above",
        "baseline_result": null
      },
      {
        "method_name": "Per-packet / per-flow feature methods",
        "paper_reference": "[56], [5]",
        "metric": null,
        "their_result": "Same aggregate statement as above",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "AUC",
      "F1",
      "Accuracy improvement (%)",
      "Throughput (Gb/s)",
      "Detection latency (s)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can encrypted malicious traffic with unknown patterns be detected in real time without labeled data by analyzing multi-flow interaction patterns instead of per-flow features?",
        "How to construct a compact in-memory graph that preserves near-optimal interaction information while enabling high-speed, low-latency detection?",
        "Can an unsupervised graph learning pipeline accurately isolate abnormal interaction patterns indicative of diverse encrypted attacks?"
      ],
      "gaps_identified": [
        "Existing encrypted traffic detection methods are supervised and rely on prior knowledge/labeled datasets of known attacks; they fail on unknown patterns.",
        "Methods focusing on single-flow features cannot capture stealthy behaviors that emerge only in interaction patterns among multiple flows.",
        "Sampling- and event-based data sources (e.g., NetFlow, Zeek) cannot retain high-fidelity interaction information for detection.",
        "Existing systems struggle to provide generic detection across encrypted and non-encrypted traffic and to operate in real time at high throughput."
      ],
      "limitations": [
        "Scope limited to active attacks that generate traffic toward victims; passive attacks (eavesdropping, passive traffic analysis) are out of scope.",
        "Payloads and application-layer headers are not parsed; detection relies on packet- and flow-level metadata and interaction structure.",
        "Relies on traffic replication via port mirroring; enforcement requires external on-path defenses.",
        "Graph construction must avoid dependence explosion; mitigated via short-flow aggregation and long-flow distribution fitting (design constraint)."
      ],
      "future_work": [],
      "motivation": "Encrypted malicious traffic is increasing and evades signature and supervised ML methods; need real-time, unsupervised, generic detection using flow interaction patterns rather than payloads or known attack features.",
      "potential_research_ideas": [
        "Integrate temporal dynamics (change-point detection) over the evolving interaction graph to improve early detection of low-and-slow encrypted attacks.",
        "Leverage graph neural networks with self-supervised objectives on the interaction graph as a complementary detector to the clustering-based pipeline.",
        "Adaptive online thresholding and concept drift handling to maintain performance under shifting benign baselines (e.g., sudden TLS adoption changes).",
        "Augment features with encrypted-protocol side-channel metadata (e.g., TLS JA3/JA4 fingerprints) in a privacy-preserving way to improve separability when available.",
        "Evaluate and harden against adversarial contamination/poisoning of the interaction graph (attackers crafting benign-looking interaction patterns).",
        "Build a distributed, hierarchical graph for multi-POP or multi-tenant cloud deployments with cross-graph correlation for attacker campaign detection.",
        "Use explainable subgraph mining to extract indicative interaction motifs for SOC analysts and automated response."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment clustering stages with a lightweight online deep autoencoder or contrastive learning over edge-feature embeddings to improve anomaly scoring robustness.",
        "Introduce a streaming GNN with neighborhood sampling for real-time inference on critical vertices to capture higher-order interaction patterns.",
        "Add an online drift detector to recalibrate clustering/loss thresholds automatically based on benign control-plane feedback.",
        "Implement a distributed in-memory graph store with sharding by IP prefix and lock-free data structures to further raise throughput and reduce latency.",
        "GPU/NIC offload (e.g., DPDK + SmartNIC or CUDA) for feature extraction and pre-clustering to reduce CPU bottlenecks."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/fuchuanpu/HyperVision",
      "frameworks": [
        "DPDK",
        "Z3 SMT solver"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Prototype uses Intel DPDK for packet I/O; reported throughput at least 80.6 Gb/s (and on average >100 Gb/s) with average detection latency 0.83 s; specific hardware specs not provided; no GPU required."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Cloud VPC with >1,500 instances; off-path via router port mirroring; applicable to enterprise/backbone settings",
      "scalability_discussed": true,
      "inference_time": "Average detection latency 0.83 s",
      "deployment_challenges": [
        "Requires router port mirroring for traffic replication; integration with on-path enforcement for mitigation.",
        "Memory and concurrency management for the in-memory graph at very high rates; need to avoid dependence explosion.",
        "No payload inspection; relies on metadata and structure which may limit detection of certain stealth patterns.",
        "Operational handling of benign drift and multi-tenant traffic mix to minimize false positives."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "HyperVision: first realtime unsupervised detection for encrypted malicious traffic with unknown patterns using a flow interaction graph.",
      "Algorithms for building a compact in-memory graph that preserves multi-flow interaction patterns (short-flow aggregation; long-flow distribution fitting).",
      "Lightweight unsupervised graph learning method leveraging graph connectivity, sparsity, and statistical features to detect abnormal interactions.",
      "Information-theoretic flow-recording entropy model showing the graph captures near-optimal interaction information with high information density.",
      "Prototype with extensive real-world experiments (92 datasets; 48 encrypted attacks) showing ≥0.92 AUC, ≥0.86 F1, ≥80.6 Gb/s throughput and 0.83 s latency; 13.9%–36.1% accuracy gains over five SOTA methods; >50% of tested attacks evade all baselines."
    ]
  },
  {
    "arxiv_id": "2301.11440v1",
    "title": "Secure synchronization of artificial neural networks used to correct errors in quantum cryptography",
    "authors": "Marcin Niemiec; Tymoteusz Widlarz; Miralem Mehic",
    "abstract": "Quantum cryptography can provide a very high level of data security. However, a big challenge of this technique is errors in quantum channels. Therefore, error correction methods must be applied in real implementations. An example is error correction based on artificial neural networks. This paper considers the practical aspects of this recently proposed method and analyzes elements which influence security and efficiency. The synchronization process based on mutual learning processes is analyzed in detail. The results allowed us to determine the impact of various parameters. Additionally, the paper describes the recommended number of iterations for different structures of artificial neural networks and various error rates. All this aims to support users in choosing a suitable configuration of neural networks used to correct errors in a secure and efficient way.",
    "published_date": "2023-01-26",
    "pdf_link": "https://arxiv.org/pdf/2301.11440v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Cryptography / Quantum Security",
      "subdomain": "Quantum Key Distribution (QKD) Post-processing",
      "specific_problem": "Key reconciliation (error correction) using neural networks after QKD",
      "attack_types": [
        "Passive eavesdropping on public channel",
        "Attacker TPM synchronization (neural cryptanalysis)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Neural Network",
        "specific": "Tree Parity Machine (TPM) with Hebbian learning",
        "novel_contribution": "Empirical analysis of synchronization behavior for TPM-based QKD error correction; recommended iteration counts across K, N, L, QBER; characterization of distributional properties and parameter impact (logarithmic in K, exponential in L)."
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Online / mutual learning"
    ],
    "datasets": [
      {
        "name": "Simulated QKD keys with specified QBER",
        "type": "synthetic",
        "domain": "quantum_key_distribution_keys",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Recommended iteration counts across TPM configurations (1880 scenarios)",
        "type": "public",
        "domain": "results_table",
        "link": "http://kt.agh.edu.pl/niemiec/ICC-2023",
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Cascade protocol",
        "paper_reference": "Brassard and Salvail (1994) and subsequent improvements; cited as [13] in the paper",
        "metric": "Iterations required for reconciliation",
        "their_result": "\"requires approximately 30% less iterations than Cascade algorithm [2].\" (statement attributed to prior work [2])",
        "baseline_result": null
      },
      {
        "method_name": "BBBSS (parity-check based)",
        "paper_reference": "Bennett, Brassard, Breguet, Salvail, and Smolin (1992), cited as [6]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Winnow (Hamming code based)",
        "paper_reference": "Cited as [8]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "LDPC-based reconciliation",
        "paper_reference": "Referenced in text as low density parity check approach, via [7]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Number of iterations to synchronize",
      "Success probability (via percentile; mean+std heuristic ~84% under normal assumption)",
      "QBER (quantum bit error rate) as condition variable"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How do TPM parameters (K, N, L) and QBER affect synchronization time (iterations) and security/efficiency for QKD error correction?",
        "What is a recommended number of iterations for different TPM structures and error rates to balance success probability and security?",
        "Which TPM configurations should be preferred or avoided for practical deployments?"
      ],
      "gaps_identified": [
        "Lack of practical guidance on selecting TPM parameters and iteration counts for QKD error correction in prior proposals.",
        "Traditional reconciliation methods (Cascade/BBBSS) leak parity information over the public channel, requiring privacy amplification and shortening keys.",
        "Unclear distributional behavior (skew, variance) of synchronization iterations across configurations was previously not systematically characterized."
      ],
      "limitations": [
        "Experiments are simulation-based; no evaluation on real QKD hardware links.",
        "Input generation/security model and attacker capabilities are discussed conceptually; no empirical adversarial evaluation against active Eve beyond iteration-count rationale.",
        "Maximum retries per iteration capped at 10 and max iterations capped at 1000 to speed simulation; may truncate tails of iteration distributions.",
        "Assumes low QBER regimes typical for QKD; behavior at higher error rates not explored in depth.",
        "Results and recommended iterations depend on Hebbian learning; other learning rules (anti-Hebbian, random walk) were not comparatively evaluated."
      ],
      "future_work": [],
      "motivation": "Provide practical, secure, and efficient configuration guidance for TPM-based error correction in QKD by analyzing how neural network parameters and QBER influence synchronization and by recommending iteration counts.",
      "potential_research_ideas": [
        "Formalize theoretical bounds on synchronization time distributions and success probabilities for Alice/Bob vs Eve as functions of K, N, L, and QBER.",
        "Design adaptive stopping rules that estimate convergence online (e.g., based on output agreement rates) to replace fixed iteration budgets and further reduce leakage.",
        "Evaluate alternative learning rules (anti-Hebbian, random walk) and hybrid or variant architectures to reduce iterations and improve security margins.",
        "Integrate TPM-based reconciliation with classical codes (e.g., LDPC) in a hybrid scheme to minimize public leakage while keeping iteration counts low.",
        "Model and test robustness against active adversaries who can manipulate inputs/public messages, including desynchronization and poisoning attempts.",
        "Hardware acceleration (FPGA/ASIC) for real-time post-processing in high-rate QKD systems; explore vectorized/parallel TPM updates.",
        "Security analysis of input generation mechanisms (randomness sources, synchronization of inputs) and their effect on Eve's advantage."
      ],
      "architectural_improvement_recommendations": [
        "Adaptive selection of K and N based on measured QBER and key length to operate near optimal synchronization regimes (given logarithmic dependence on K).",
        "Careful quantization/selection of L to minimize exponential impact on iterations while preserving representation fidelity; consider variable L across layers or per-weight clipping schedules.",
        "Implement early-stopping criteria with confidence measures derived from output agreement statistics, potentially coupled with limited verification bits.",
        "Explore mini-batch style multiple-input updates per iteration to reduce communication rounds while preserving security.",
        "Benchmark Hebbian vs anti-Hebbian vs random-walk learning under identical settings to select the fastest secure rule.",
        "Harden the protocol against active attacks (authenticated channels, input-seed derivation via shared randomness, challenge scheduling)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Python",
        "NumPy",
        "Sockets (networked simulation)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "QKD post-processing (classical channel) for key reconciliation",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Selecting L carefully due to exponential impact on synchronization time.",
        "Choosing K and N given logarithmic impact and key-length constraints.",
        "Setting iteration budgets to balance success probability and security against Eve’s potential synchronization.",
        "Translating bits to integer weights (quantization) depending on L and key length.",
        "Need for privacy amplification after reconciliation to mitigate public leakage."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Analyzed the synchronization process of TPMs for QKD error correction, including security and efficiency implications.",
      "Determined the impact of K, N, L, and QBER on required iterations; found logarithmic dependence on K and exponential dependence on L.",
      "Characterized iteration distributions (often right-skewed); proposed a recommendation heuristic using mean+std to target ~84%+ success.",
      "Provided recommended iteration counts for 1880 TPM/QBER scenarios; shared results online.",
      "Outlined guidance for selecting TPM configurations to securely and efficiently correct QKD errors.",
      "Reinforced that privacy amplification remains recommended post-reconciliation and discussed security rationale versus Eve."
    ]
  },
  {
    "arxiv_id": "2303.11760v1",
    "title": "Real-Time Cyberattack Detection with Offline and Online Learning",
    "authors": "Erol Gelenbe; Mert Nakıp",
    "abstract": "This paper presents several novel algorithms for real-time cyberattack detection using the Auto-Associative Deep Random Neural Network, which were developed in the HORIZON 2020 IoTAC Project. Some of these algorithms require offline learning, while others require the algorithm to learn during its normal operation while it is also testing the flow of incoming traffic to detect possible attacks. Most of the methods we present are designed to be used at a single node, while one specific method collects data from multiple network ports to detect and monitor the spread of a Botnet. The evaluation of the accuracy of all the methods is carried out with real attack traces. These novel methods are also compared with other state-of-the-art approaches, showing that they offer better or equal performance, at lower computational learning and shorter detection times as compared to the existing approaches.",
    "published_date": "2023-03-21",
    "pdf_link": "https://arxiv.org/pdf/2303.11760v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Real-time detection of botnet/DDoS attacks and compromised device identification from network traffic using auto-associative learning trained only on normal traffic",
      "attack_types": [
        "Botnet (Mirai)",
        "DoS",
        "DDoS"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Random Neural Network",
        "specific": "Auto-Associative Deep/Dense Random Neural Network (AADRNN)",
        "novel_contribution": "Auto-associative DRNN trained only on normal traffic; incremental online semi-supervised reconstruction-based training; operates with lightweight header-derived metrics; supports single-node detection, multi-port aggregation for botnet spread monitoring, and per-device detectors with infection level output; data-driven whisker-based decision thresholding for multi-attack detection."
      },
      {
        "type": "baseline",
        "category": "K-Nearest Neighbors",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Model (L1/Lasso)",
        "specific": "Lasso",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Rule-based",
        "specific": "Simple Thresholding",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Semi-supervised",
      "Unsupervised",
      "Online Learning",
      "Incremental Learning",
      "One-class learning"
    ],
    "datasets": [
      {
        "name": "Kitsune Network Attack Dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.kaggle.com/ymirsky/network-attack-dataset-kitsune",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "KDD Cup 1999",
        "type": "public",
        "domain": "network_traffic",
        "link": "http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MedBIoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Bot-IoT",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.sciencedirect.com/science/article/pii/S0167739X18327687",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "Accuracy, TPR, TNR, FPR, FNR (Kitsune Mirai botnet detection)",
        "their_result": "AADRNN: Accuracy 99.84; TPR 99.82; TNR 99.98; FPR 0.02; FNR 0.18",
        "baseline_result": "KNN: Accuracy 99.79; TPR 99.79; TNR 99.75; FPR 0.25; FNR 0.21"
      },
      {
        "method_name": "Lasso",
        "paper_reference": null,
        "metric": "Accuracy, TPR, TNR, FPR, FNR (Kitsune Mirai botnet detection)",
        "their_result": "AADRNN: Accuracy 99.84; TPR 99.82; TNR 99.98; FPR 0.02; FNR 0.18",
        "baseline_result": "Lasso: Accuracy 99.78; TPR 99.75; TNR 99.95; FPR 0.05; FNR 0.25"
      },
      {
        "method_name": "Simple Thresholding",
        "paper_reference": null,
        "metric": "Accuracy, TPR, TNR, FPR, FNR (Kitsune Mirai botnet detection)",
        "their_result": "AADRNN: Accuracy 99.84; TPR 99.82; TNR 99.98; FPR 0.02; FNR 0.18",
        "baseline_result": "Simple Thresholding: Accuracy 93.18; TPR 93.09; TNR 93.63; FPR 6.37; FNR 6.94"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "True Positive Rate (TPR)",
      "True Negative Rate (TNR)",
      "False Positive Rate (FPR)",
      "False Negative Rate (FNR)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can an auto-associative deep random neural network trained only with normal traffic detect botnet and other cyberattacks in real time without attack-labeled data?",
        "Can incremental online learning adapt the detector to evolving normal traffic with low false alarms?",
        "Can the approach simultaneously detect multiple attack types using a single model?",
        "Can compromised IoT devices be identified (and their infection level estimated) during ongoing DDoS/Botnet attacks?"
      ],
      "gaps_identified": [
        "Resource-constrained IoT devices cannot run complex real-time detection; need lightweight methods.",
        "Need for detectors that do not require attack traffic for training and can generalize from normal-only data.",
        "Threshold selection in anomaly detection often overfits to datasets; a data-driven whisker-based threshold can mitigate this."
      ],
      "limitations": [
        "False alarms remain and are targeted for significant reduction via post-processing.",
        "Results are demonstrated on public datasets; no explicit large-scale production deployment evidence provided."
      ],
      "future_work": [
        "Examine post-processing of detector outputs to reduce false alarms by an order of magnitude.",
        "Investigate dynamic system management/traffic engineering to mitigate attack impact in specific IoT systems."
      ],
      "motivation": "Massive IoT comprises many low-cost devices that are vulnerable and cannot run complex detection; need real-time, lightweight, privacy-preserving detection that does not rely on attack data and can adapt online.",
      "potential_research_ideas": [
        "Federated/edge learning of AADRNNs across gateways to preserve privacy while improving generalization.",
        "Graph-based correlation across multi-port/multi-host detectors to track botnet propagation and coordinated attacks.",
        "Adversarial robustness evaluation and robust training against evasion/poisoning targeting header-based metrics.",
        "Concept-drift detection and adaptive thresholding to handle seasonal/diurnal traffic shifts without manual tuning.",
        "Self-supervised/contrastive pretraining on normal traffic metric sequences to improve reconstruction quality.",
        "Explainability of anomaly scores (e.g., per-metric contributions and temporal attributions) to aid operators.",
        "Extend to encrypted traffic and QUIC by enriching header-derived metrics and timing side-channels.",
        "Tight integration with SDN/NFV for closed-loop mitigation (rate limiting, quarantine) driven by detector confidence.",
        "Lightweight hardware acceleration (DPUs/SmartNICs) for in-line metric extraction and inference."
      ],
      "architectural_improvement_recommendations": [
        "Ensemble multiple one-class models (AADRNN + One-Class SVM/Isolation Forest) with calibrated fusion to reduce false alarms.",
        "Model temporal dependencies explicitly with Temporal CNN/LSTM atop metric sequences while keeping the auto-associative core.",
        "Adopt multi-timescale metric windows with attention/gating to capture short bursts and long-term trends.",
        "Use uncertainty estimation (MC dropout or deep ensembles) to drive adaptive thresholds and abstention.",
        "Implement adaptive, quantile-based thresholds with automatic recalibration under drift.",
        "Apply contrastive denoising objectives (e.g., InfoNCE) alongside reconstruction to improve discrimination.",
        "Quantize/prune the model for ultra-low footprint on gateways; batchless streaming inference pipeline."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "IoT gateway/single node; variant aggregates multiple network ports",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Resource constraints on IoT devices necessitate lightweight detection.",
        "Ensuring low false alarm rates; need for post-processing to further reduce FPs.",
        "Requirement for clean normal traffic periods for initial/ongoing training."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces novel real-time attack detection algorithms based on an Auto-Associative Deep Random Neural Network (AADRNN).",
      "Trains only on normal traffic (no attack data) and generalizes to multiple attack types.",
      "Supports both offline and incremental online learning concurrently with real-time detection.",
      "Designs lightweight, privacy-preserving metrics computed from packet headers (size, inter-transmission time, count in window).",
      "Extends detector to aggregate multiple network ports to observe botnet spread and to per-device infection level estimation.",
      "Enhances decision logic with data-driven statistical whisker thresholds for multi-attack detection.",
      "Demonstrates high accuracy: on Kitsune Mirai detection AADRNN achieves 99.82% TPR and 99.98% TNR; outperforms KNN, Lasso, and simple thresholding.",
      "Shows simultaneous multi-attack detection on KDD Cup’99 with >98% accuracy for 21 of 37 attack types.",
      "Validates compromised device identification across Kitsune, MedBIoT, and Bot-IoT datasets.",
      "Claims better or equal detection performance with lower computational learning and shorter detection times compared to existing approaches."
    ]
  },
  {
    "arxiv_id": "2303.15986v2",
    "title": "Clustered Federated Learning Architecture for Network Anomaly Detection in Large Scale Heterogeneous IoT Networks",
    "authors": "Xabier Sáez-de-Cámara; Jose Luis Flores; Cristóbal Arellano; Aitor Urbieta; Urko Zurutuza",
    "abstract": "There is a growing trend of cyberattacks against Internet of Things (IoT) devices; moreover, the sophistication and motivation of those attacks is increasing. The vast scale of IoT, diverse hardware and software, and being typically placed in uncontrolled environments make traditional IT security mechanisms such as signature-based intrusion detection and prevention systems challenging to integrate. They also struggle to cope with the rapidly evolving IoT threat landscape due to long delays between the analysis and publication of the detection rules. Machine learning methods have shown faster response to emerging threats; however, model training architectures like cloud or edge computing face multiple drawbacks in IoT settings, including network overhead and data isolation arising from the large scale and heterogeneity that characterizes these networks.   This work presents an architecture for training unsupervised models for network intrusion detection in large, distributed IoT and Industrial IoT (IIoT) deployments. We leverage Federated Learning (FL) to collaboratively train between peers and reduce isolation and network overhead problems. We build upon it to include an unsupervised device clustering algorithm fully integrated into the FL pipeline to address the heterogeneity issues that arise in FL settings. The architecture is implemented and evaluated using a testbed that includes various emulated IoT/IIoT devices and attackers interacting in a complex network topology comprising 100 emulated devices, 30 switches and 10 routers. The anomaly detection models are evaluated on real attacks performed by the testbed's threat actors, including the entire Mirai malware lifecycle, an additional botnet based on the Merlin command and control server and other red-teaming tools performing scanning activities and multiple attacks targeting the emulated devices.",
    "published_date": "2023-03-28",
    "pdf_link": "https://arxiv.org/pdf/2303.15986v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Unsupervised network anomaly detection for large-scale, heterogeneous IoT/IIoT using clustered federated learning",
      "attack_types": [
        "Mirai botnet lifecycle (scanning, brute-force login, infection/C2)",
        "Merlin C2-based botnet activity",
        "Network scanning/probing",
        "Multiple attacks targeting emulated IoT/IIoT devices (unspecified)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": null,
        "novel_contribution": "Clustered FL pipeline with fully integrated unsupervised device clustering based on model-update fingerprints to address heterogeneity and non-IID data"
      },
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": null,
        "novel_contribution": "Unsupervised autoencoder-based anomaly detector trained only on benign traffic within a federated setting"
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": null,
        "novel_contribution": "Unsupervised clustering of clients using dimensionality-reduced local model parameters/updates to form FL clusters before per-cluster FL training"
      },
      {
        "type": "primary",
        "category": "Aggregation",
        "specific": null,
        "novel_contribution": "Evaluation and optimization of different FL aggregation functions within the proposed architecture"
      },
      {
        "type": "baseline",
        "category": "Federated Learning",
        "specific": "Vanilla single global model (implied baseline without clustering)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Federated"
    ],
    "datasets": [
      {
        "name": "Gotham testbed-based emulated IoT/IIoT network traffic",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "N-BaIoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Bot-IoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a clustered federated learning architecture enable effective unsupervised anomaly detection across large, heterogeneous IoT/IIoT networks?",
        "Can unsupervised device clustering based on local model-update fingerprints mitigate non-IID-induced convergence issues in FL?",
        "What FL aggregation strategies perform best for unsupervised autoencoder-based anomaly detection under IoT heterogeneity?"
      ],
      "gaps_identified": [
        "Most FL-based IDS for IoT use supervised methods; unsupervised FL for IDS remains underexplored.",
        "Existing approaches often require manual segmentation, external fingerprinting tools, hardcoded device properties, or prior knowledge of attacks, and are not fully integrated into the FL pipeline.",
        "Centralized cloud training suffers from bandwidth, congestion, latency, and privacy/regulatory issues in large-scale IoT.",
        "Edge/on-device training leads to data islands, reducing available training data volume.",
        "Highly non-IID client data hinders global model convergence in practical FL.",
        "Common IDS datasets and typical FL evaluations do not reflect large, distributed, heterogeneous IoT environments; many studies simulate FL with small client counts (~10) and artificial partitions."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Address scalability, heterogeneity, and privacy challenges in IoT/IIoT anomaly detection by integrating federated learning with unsupervised device clustering to improve FL convergence and reduce network overhead and data isolation.",
      "potential_research_ideas": [
        "Adaptive clustering with dynamic K estimation and periodic re-clustering to track non-stationary device behavior and concept drift.",
        "Personalized FL approaches (e.g., pFedMe/FedPer/FedProx) layered atop clustered FL to blend group and per-device specialization.",
        "Secure and private model fingerprinting via secure aggregation and differential privacy to mitigate leakage from parameter updates.",
        "Adversarially robust FL for anomaly detection, including defenses against poisoning/backdoor attacks on client updates.",
        "Hierarchical clustered FL (edge/gateway/region) to improve scalability and reduce latency in very large deployments.",
        "Self-supervised representation learning for traffic features to improve anomaly detector generalization under label scarcity.",
        "Online threshold calibration and drift detectors to maintain anomaly detection performance over time.",
        "Benchmarking against diverse, real-world IoT traffic corpora and releasing a standardized clustered-FL IoT IDS benchmark.",
        "Multi-modal fusion (e.g., flows + device metadata + passive fingerprints) within privacy constraints to improve clustering quality.",
        "Communication-efficient update compression (sparsification/quantization) tuned for unsupervised autoencoders in FL."
      ],
      "architectural_improvement_recommendations": [
        "Use robust/median-based or trimmed-mean aggregation (e.g., coordinate-wise median, Krum, FedAvgM) within clusters to mitigate stragglers and outliers.",
        "Apply low-cost dimensionality reduction (random projections/PCA) and cosine-similarity metrics to stabilize model fingerprint clustering.",
        "Incorporate FedProx-style proximal terms to limit client drift in highly non-IID clusters.",
        "Introduce periodic re-clustering based on distribution shift indicators (e.g., reconstruction loss stats) to adapt cluster memberships.",
        "Adopt secure aggregation with DP noise addition tuned to retain anomaly signal while protecting update privacy.",
        "Employ lightweight self-supervised pretraining of encoders at clients to improve anomaly model initialization before FL.",
        "Add communication compression (top-k sparsification/8-bit quantization) to reduce bandwidth without hurting anomaly performance.",
        "Integrate per-device calibration and conformal prediction to set robust anomaly thresholds with coverage guarantees."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Emulated large-scale IoT/IIoT network testbed (based on Gotham testbed) with ~100 emulated devices, 30 switches, 10 routers",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Network overhead and congestion for centralized training",
        "Data isolation and limited data volume at edge devices",
        "Non-IID client distributions causing FL convergence issues",
        "IoT device heterogeneity (protocols, behaviors)",
        "Privacy and regulatory constraints on data centralization"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes and evaluates a clustered federated learning architecture for unsupervised anomaly-based IDS model training on heterogeneous IoT/IIoT networks.",
      "Introduces an unsupervised model-fingerprinting device clustering method integrated into the FL pipeline using similarities between local model parameters/updates.",
      "Trains anomaly detection via autoencoders on benign traffic only; attacks used solely for evaluation, eliminating the need for labeled attack data.",
      "Implements and evaluates the architecture on a complex emulated network scenario with 100 emulated devices, 30 switches, and 10 routers; devices use diverse protocols (e.g., MQTT, CoAP, RTSP).",
      "Evaluates models on real attacks executed in the testbed, including the full Mirai lifecycle, a Merlin C2-based botnet, and other red-team scanning/attack activities.",
      "Tests and optimizes different FL aggregation functions and provides experimental comparisons, including to a state-of-the-art approach."
    ]
  },
  {
    "arxiv_id": "2302.09286v1",
    "title": "Experimental Toolkit for Manipulating Executable Packing",
    "authors": "Alexandre D'Hondt; Charles-Henry Bertrand Van Ouytsel; Axel Legay",
    "abstract": "Be it for a malicious or legitimate purpose, packing, a transformation that consists in applying various operations like compression or encryption to a binary file, i.e. for making reverse engineering harder or obfuscating code, is widely employed since decades already. Particularly in the field of malware analysis where a stumbling block is evasion, it has proven effective and still gives a hard time to scientists who want to efficiently detect it. While already extensively covered in the scientific literature, it remains an open issue especially when considering its detection time and accuracy trade-off. Many approaches, including machine learning, have been proposed but most studies often restrict their scope (i.e. malware and PE files), rely on uncertain datasets (i.e. built based on a super-detector or using labels from an questionable source) and do no provide any open implementation, which makes comparing state-of-the-art solutions tedious. Considering the many challenges that packing implies, there exists room for improvement in the way it is addressed, especially when dealing with static detection techniques. In order to tackle with these challenges, we propose an experimental toolkit, aptly called the Packing Box, leveraging automation and containerization in an open source platform that brings a unified solution to the research community and we showcase it with some experiments including unbiased ground truth generation, data visualization, machine learning pipeline automation and performance of open source packing static detectors.",
    "published_date": "2023-02-18",
    "pdf_link": "https://arxiv.org/pdf/2302.09286v1",
    "paper_types": [
      "benchmark",
      "reproducibility",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Obfuscation and Packing Detection",
      "specific_problem": "Static detection and characterization of packed executables; unified, repeatable benchmarking of packer detectors and ML pipelines",
      "attack_types": [
        "Packing-based evasion",
        "Code obfuscation",
        "Encryption/encoding-based concealment",
        "Virtualization-based protection"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "AutoML/Model selection",
        "specific": "Grid search hyper-parameter tuning within a declarative (YAML) pipeline",
        "novel_contribution": "Open-source, containerized automation of dataset preparation, visualization, and supervised model training for packing detection"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "EMBER",
        "type": "public",
        "domain": "pe_files (features)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PackingData (2019, native PE files packed with 19 packers)",
        "type": "public",
        "domain": "pe_files (packed/unpacked executables)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PackingData extension (2021, +6 packers)",
        "type": "public",
        "domain": "pe_files (packed/unpacked executables)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ELF packed dataset (2022, native Linux files packed with 6 packers)",
        "type": "public",
        "domain": "elf_files (packed/unpacked executables)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Malfease",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "VX Heaven",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "ViruSign",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "MalwareBazaar",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusShare",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Detect It Easy! (DIE)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "PEiD (Python CLI version)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "RetDec",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "processing_time"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can we enhance repeatability of the experiments of packing detection?",
        "How can we provide a solution to build unbiased ground truths?",
        "What is the performance of state-of-the-art detectors?",
        "Can we leverage data visualization to better understand what packers do?"
      ],
      "gaps_identified": [
        "Most studies restrict scope to malware and PE files",
        "Reliance on uncertain datasets (e.g., super-detector labels or questionable sources)",
        "Lack of open implementations hinders comparison and repeatability",
        "Trade-off between detection time and accuracy remains open",
        "Feature engineering and selection for static detection remains under-explored",
        "Ground-truth quality and dataset generalization are problematic",
        "No open automation to compare models and pipelines across datasets"
      ],
      "limitations": [
        "Framework is in constant evolution; only a finite set of items integrated at the time of writing (e.g., 3 analyzers, 9 detectors, 16 packers, 3 unpackers)",
        "Focus is on static detection tools; dynamic analysis integration is not presented"
      ],
      "future_work": [
        "Integrate more analyzers, detectors, packers, and unpackers",
        "Further development and study of extended capabilities (e.g., broader formats and techniques)"
      ],
      "motivation": "Provide a unified, open-source, containerized toolkit to improve repeatability, create unbiased ground truths, enable visualization, and automate ML pipelines for executable packing detection and benchmarking.",
      "potential_research_ideas": [
        "Build standardized, cross-format (PE/ELF/Mach-O) benchmark suites of packed/unpacked binaries using the toolkit for community-wide comparisons",
        "Design packer-family and transformation-type classifiers (e.g., compressor vs protector vs virtualizer) beyond binary packed/not-packed detection",
        "Integrate dynamic unpacking and hybrid static-dynamic features to study time/accuracy trade-offs systematically",
        "Develop explainability methods for packing detectors (e.g., section-level attributions, entropy-saliency) and validate against visualization outputs",
        "Study adversarial robustness by generating adversarial packing transformations and evaluating detector susceptibility",
        "Leverage semi-supervised and unsupervised methods to reduce labeling needs and handle evolving packers",
        "Cross-OS generalization studies: train on PE and test on ELF/Mach-O using shared feature spaces or domain adaptation",
        "Raw-bytes and sequence-model baselines (e.g., 1D CNN/Transformer) versus hand-crafted features under strict compute/time budgets",
        "Automated feature synthesis from analyzer outputs (PortEx/Pefeats) with constraint-based selection for real-time constraints"
      ],
      "architectural_improvement_recommendations": [
        "Add a dynamic analysis module (sandboxed unpacking and trace collection) to complement static features",
        "Introduce dataset versioning, provenance tracking, and hashing for full reproducibility and sharing of fileless datasets",
        "Implement parallel and distributed execution (e.g., job queues) for large-scale bulk packing/detection/feature extraction",
        "Provide a standardized metrics suite and report generator (accuracy, ROC, AUROC, F1, time/memory per sample) with confidence intervals",
        "Expose a stable plugin API for new features/models/detectors and continuous integration tests for contributed YAML definitions",
        "Enable caching of intermediate artifacts (features, analyzer outputs) to reduce recomputation",
        "Offer native bindings to common ML frameworks (e.g., scikit-learn, XGBoost, PyTorch) with reproducible seeds and cross-validation templates"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "Docker"
      ],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Docker container",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Obtaining and maintaining high-quality labeled datasets over time",
        "Integrating diverse packers/detectors across OS and formats within a unified toolchain"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces the Packing Box: an open-source, containerized experimental toolkit for executable packing research",
      "Automates unbiased ground-truth dataset generation by packing cleanware with configurable packers",
      "Provides a unified pipeline for data visualization, dataset operations, and supervised ML model training via declarative YAML",
      "Integrates multiple analyzers, detectors, packers, and unpackers under common abstractions (Analyzer, Detector, Packer, Unpacker)",
      "Enables mass detection, super-detector compositions, and statistical reporting for benchmarking open-source static detectors",
      "Improves repeatability and comparability of packing detection experiments across formats (PE, ELF, Mach-O)"
    ]
  },
  {
    "arxiv_id": "2302.14374v1",
    "title": "Testing the performance of Multi-class IDS public dataset using Supervised Machine Learning Algorithms",
    "authors": "Vusumuzi Malele; Topside E Mathonsi",
    "abstract": "Machine learning, statistical-based, and knowledge-based methods are often used to implement an Anomaly-based Intrusion Detection System which is software that helps in detecting malicious and undesired activities in the network primarily through the Internet. Machine learning comprises Supervised, Semi-Supervised, and Unsupervised Learning algorithms. Supervised machine learning uses a trained label dataset. This paper uses four supervised learning algorithms Random Forest, XGBoost, K-Nearest Neighbours, and Artificial Neural Network to test the performance of the public dataset. Based on the prediction accuracy rate, the results show that Random Forest performs better on multi-class Intrusion Detection System, followed by XGBoost, K-Nearest Neighbours respective, provided prediction accuracy is taken into perspective. Otherwise, K-Nearest Neighbours was the best performer considering the time of training as the metric. It concludes that Random Forest is the best-supervised machine learning for Intrusion Detection System",
    "published_date": "2023-02-28",
    "pdf_link": "https://arxiv.org/pdf/2302.14374v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Multi-class anomaly-based intrusion detection using supervised ML on public IDS dataset",
      "attack_types": [
        "DoS",
        "Probe",
        "R2L",
        "U2R"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble Trees",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Instance-based (k-NN)",
        "specific": "K-Nearest Neighbours (k=5, Euclidean distance)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Feedforward Neural Network",
        "specific": "Artificial Neural Network (MLP, 10 layers, ReLU, Adam, alpha=0.001)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "99.7 (RF)",
        "baseline_result": "99.1"
      },
      {
        "method_name": "K-Nearest Neighbours",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "99.7 (RF)",
        "baseline_result": "97.6"
      },
      {
        "method_name": "Artificial Neural Network",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "99.7 (RF)",
        "baseline_result": "95.3"
      },
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "F1-score (%)",
        "their_result": "78.6 (RF)",
        "baseline_result": "76.3"
      },
      {
        "method_name": "K-Nearest Neighbours",
        "paper_reference": null,
        "metric": "F1-score (%)",
        "their_result": "78.6 (RF)",
        "baseline_result": "71.3"
      },
      {
        "method_name": "Artificial Neural Network",
        "paper_reference": null,
        "metric": "F1-score (%)",
        "their_result": "78.6 (RF)",
        "baseline_result": "58.7"
      },
      {
        "method_name": "K-Nearest Neighbours",
        "paper_reference": null,
        "metric": "Training time (s)",
        "their_result": "37 (RF)",
        "baseline_result": "17"
      },
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Training time (s)",
        "their_result": "37 (RF)",
        "baseline_result": "36"
      },
      {
        "method_name": "Artificial Neural Network",
        "paper_reference": null,
        "metric": "Training time (s)",
        "their_result": "37 (RF)",
        "baseline_result": "41"
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall",
      "f1_score",
      "accuracy",
      "confusion_matrix",
      "training_time"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Which supervised learning algorithm (RF, XGBoost, KNN, ANN) performs best for multi-class IDS on a public dataset, considering accuracy- and time-based metrics?"
      ],
      "gaps_identified": [
        "Prior work reports modest accuracies (e.g., 81.31% and 82.36%); comparative evaluations across common supervised algorithms on multi-class IDS remain valuable.",
        "Training time as a practical metric for IDS algorithm selection is under-discussed."
      ],
      "limitations": [
        "Evaluation limited to a single unnamed public dataset.",
        "Only four supervised algorithms considered; limited hyperparameter exploration.",
        "Performance metrics emphasize accuracy/F1; probability-based metrics such as Log Loss not evaluated.",
        "Hardware environment not reported; inference latency not measured."
      ],
      "future_work": [
        "Evaluate additional supervised algorithms such as Logistic Regression (LR) and Support Vector Machine (SVM).",
        "Consider other performance measures such as Log Loss."
      ],
      "motivation": "Assess the effectiveness of common supervised ML algorithms for anomaly-based IDS on multi-class attack detection and identify the best trade-off between accuracy and training time.",
      "potential_research_ideas": [
        "Replicate and extend the study across multiple modern IDS datasets (e.g., NSL-KDD, UNSW-NB15, CIC-IDS2017/2018/2020) to assess generalization.",
        "Address severe class imbalance (especially U2R and R2L) using rebalancing (SMOTE, class weights, focal loss) and cost-sensitive learning, and report per-class metrics.",
        "Evaluate streaming/online IDS with concept drift detection and incremental learners (e.g., online boosting/bagging, Hoeffding Trees).",
        "Incorporate calibration and probability-based evaluation (Log Loss, Brier score, calibration curves) for threshold tuning in SOC workflows.",
        "Study robustness to adversarial evasion and poisoning attacks in IDS and defenses (adversarial training, randomized smoothing).",
        "Perform comprehensive hyperparameter optimization (Bayesian search) and nested cross-validation for fair comparison.",
        "Explore stacking/ensembling RF and XGBoost with calibrated MLP heads to improve minority-class detection.",
        "Integrate explainability (SHAP/TreeExplainer) to provide operator-facing insights and rule extraction.",
        "Measure and optimize inference latency/throughput for real-time deployment on edge/gateway devices.",
        "Evaluate domain shift and data drift detection in evolving network environments."
      ],
      "architectural_improvement_recommendations": [
        "Tune RF (n_estimators, max_depth, min_samples_leaf, max_features) and XGBoost (learning_rate, n_estimators, max_depth, subsample, colsample_bytree, regularization) with Bayesian optimization.",
        "Use LightGBM/CatBoost as additional gradient boosting baselines for categorical handling and speed.",
        "Adopt class-weighting or focal loss in ANN to improve R2L/U2R recall; add batch normalization, dropout, and early stopping.",
        "Apply robust feature scaling/normalization pipelines and feature selection (mutual information, Boruta) validated via nested CV.",
        "Use stratified k-fold cross-validation and report variance to avoid single split bias.",
        "Calibrate model outputs (Platt/Isotonic) and provide threshold-optimized operating points (ROC/PR analysis).",
        "Deploy a two-stage system: fast lightweight filter (KNN or shallow tree) followed by high-precision booster (XGBoost) for flagged flows."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Training times reported: RF 37s, XGBoost 36s, KNN 17s, ANN 41s; hardware not specified."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Empirical comparison of four supervised ML algorithms (RF, XGBoost, KNN, ANN) for multi-class IDS on a public dataset.",
      "Reported confusion matrices and metrics (precision, recall, F1, accuracy) per model; RF achieved 99.7% accuracy and 78.6% F1.",
      "Analyzed training time trade-offs; KNN was fastest (17s) though less accurate than RF/XGBoost.",
      "Provided model hyperparameters and variable importance analysis for RF and XGBoost."
    ]
  },
  {
    "arxiv_id": "2303.12800v1",
    "title": "IoT Device Identification Based on Network Communication Analysis Using Deep Learning",
    "authors": "Jaidip Kotak; Yuval Elovici",
    "abstract": "Attack vectors for adversaries have increased in organizations because of the growing use of less secure IoT devices. The risk of attacks on an organization's network has also increased due to the bring your own device (BYOD) policy which permits employees to bring IoT devices onto the premises and attach them to the organization's network. To tackle this threat and protect their networks, organizations generally implement security policies in which only white listed IoT devices are allowed on the organization's network. To monitor compliance with such policies, it has become essential to distinguish IoT devices permitted within an organization's network from non white listed (unknown) IoT devices. In this research, deep learning is applied to network communication for the automated identification of IoT devices permitted on the network. In contrast to existing methods, the proposed approach does not require complex feature engineering of the network communication, because the 'communication behavior' of IoT devices is represented as small images which are generated from the device's network communication payload. The proposed approach is applicable for any IoT device, regardless of the protocol used for communication. As our approach relies on the network communication payload, it is also applicable for the IoT devices behind a network address translation (NAT) enabled router. In this study, we trained various classifiers on a publicly accessible dataset to identify IoT devices in different scenarios, including the identification of known and unknown IoT devices, achieving over 99% overall average detection accuracy.",
    "published_date": "2023-03-02",
    "pdf_link": "https://arxiv.org/pdf/2303.12800v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Device Identification / Fingerprinting",
      "specific_problem": "Identification of IoT devices (including whitelist enforcement and unknown device detection) from network traffic by modeling TCP payload as images; also IoT vs non-IoT traffic discrimination",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "MLP / Fully-connected Neural Network",
        "specific": "Single-layer fully-connected neural network on 28x28 grayscale payload images (784 inputs)",
        "novel_contribution": "Represents TCP session payload bytes as 28x28 grayscale images and performs single-session classification without feature engineering; applicable behind NAT"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "IoT Trace dataset (Sivanathan et al., 2018) - subset of TCP sessions",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Meidan et al., 2017a: TCP-session feature engineering for device-class identification (HTTP/TLS specific)",
        "paper_reference": "Meidan et al., 2017a",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Meidan et al., 2017b: White-listed IoT device identification using statistical and multi-layer features",
        "paper_reference": "Meidan et al., 2017b",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Sivanathan et al., 2017: Statistical attributes (data rates, burstiness, cycles) for IoT vs non-IoT and device identification",
        "paper_reference": "Sivanathan et al., 2017",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Aksoy and Gunes, 2019 (SysID): GA-selected protocol header features + ML to identify devices from single packet",
        "paper_reference": "Aksoy and Gunes, 2019",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Miettinen et al., 2017 (IoT SENTINEL): 23 features across 16 protocols concatenated over 12 packets",
        "paper_reference": "Miettinen et al., 2017",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Sivanathan et al., 2018: Multistage ML with flow-level and statistical features (e.g., NTP/DNS intervals, ports)",
        "paper_reference": "Sivanathan et al., 2018",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Yu et al., 2020: Multi-view wide-and-deep model on Wi-Fi BC/MC features",
        "paper_reference": "Yu et al., 2020",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can IoT device communications be identified using only TCP payload content modeled as images, without feature engineering?",
        "Can a model distinguish IoT vs non-IoT traffic from a single TCP session?",
        "Can the communication of a specific IoT device be detected within IoT-only traffic and within mixed (IoT + non-IoT) traffic?",
        "Can multiple IoT devices (and a non-IoT class) be classified simultaneously?",
        "Can unknown (non-whitelisted) IoT devices be detected in an organizational network?"
      ],
      "gaps_identified": [
        "Existing methods require manual, error-prone feature engineering and domain expertise.",
        "Many approaches use complex multistage architectures and require multiple sessions per decision.",
        "Approaches relying on header fields (e.g., ports) are brittle; vendors can change ports.",
        "Many prior methods are not applicable behind NAT because features are altered during NAT.",
        "Some prior work limited to specific protocols (e.g., HTTP/TLS) or Wi‑Fi BC/MC traffic."
      ],
      "limitations": [
        "Scope restricted to TCP protocol; UDP session data are ignored.",
        "Only devices with more than 1,000 TCP sessions were considered for training.",
        "Input payload truncated/padded to 784 bytes (28x28), potentially discarding longer payload content."
      ],
      "future_work": [],
      "motivation": "Enable automated, accurate identification of permitted (whitelisted) vs unknown IoT devices on organizational networks, addressing BYOD challenges, NAT environments, and eliminating costly feature engineering.",
      "potential_research_ideas": [
        "Extend to UDP and other IoT connectivity protocols (CoAP, Zigbee, Bluetooth) with protocol-agnostic byte/bit-level encoders.",
        "Open-set recognition for unknown device detection using probabilistic thresholds or distance-based deep embeddings.",
        "Self-supervised pretraining on large unlabeled network payloads (contrastive or masked-byte modeling) to improve accuracy and generalization.",
        "Evaluate and adapt to encrypted payloads (TLS/DTLS) using side-channel features (packet sizes/timings) fused with limited payload bytes.",
        "Temporal modeling across sequences of sessions (RNN/Transformer) to capture device behavior over time.",
        "Cross-domain generalization: train-test across different networks or NATs, vendors, and firmware versions; apply domain adaptation.",
        "Data augmentation for byte streams (e.g., random padding, byte masking, shuffling neutral regions) to improve robustness.",
        "Lightweight on-device or edge inference pipelines for real-time deployment at enterprise gateways."
      ],
      "architectural_improvement_recommendations": [
        "Replace single-layer FCNN with CNN/1D-CNN over bytes or shallow Vision CNN for better local pattern extraction.",
        "Increase input length beyond 784 bytes and use learnable byte embeddings; consider hierarchical encoders.",
        "Learn embeddings with metric learning (triplet/contrastive loss) to support open-set detection of unknown devices.",
        "Multi-view fusion: combine payload-based representation with robust header-agnostic timing/flow statistics that survive NAT.",
        "Apply domain-adversarial training to improve cross-network and cross-NAT generalization.",
        "Calibrated uncertainty (e.g., temperature scaling, Deep Ensembles) to reduce false acceptance of unknown devices."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First to classify and identify IoT devices by applying deep learning techniques on the TCP payload of network communication.",
      "Approach can differentiate IoT and non-IoT devices.",
      "Approach can identify the communication of a particular IoT device in network traffic.",
      "Approach can identify white-listed IoT devices in network communication.",
      "Applicable for identifying IoT devices behind a NAT.",
      "Requires only a single TCP session to detect the source IoT device.",
      "Eliminates feature engineering and uses a simple architecture.",
      "Achieved over 99% overall average detection accuracy on a publicly accessible dataset across scenarios (known and unknown IoT devices)."
    ]
  },
  {
    "arxiv_id": "2302.11527v1",
    "title": "A study on the invariance in security whatever the dimension of images for the steganalysis by deep-learning",
    "authors": "Kévin Planolles; Marc Chaumont; Frédéric Comby",
    "abstract": "In this paper, we study the performance invariance of convolutional neural networks when confronted with variable image sizes in the context of a more \"wild steganalysis\". First, we propose two algorithms and definitions for a fine experimental protocol with datasets owning \"similar difficulty\" and \"similar security\". The \"smart crop 2\" algorithm allows the introduction of the Nearly Nested Image Datasets (NNID) that ensure \"a similar difficulty\" between various datasets, and a dichotomous research algorithm allows a \"similar security\". Second, we show that invariance does not exist in state-of-the-art architectures. We also exhibit a difference in behavior depending on whether we test on images larger or smaller than the training images. Finally, based on the experiments, we propose to use the dilated convolution which leads to an improvement of a state-of-the-art architecture.",
    "published_date": "2023-02-22",
    "pdf_link": "https://arxiv.org/pdf/2302.11527v1",
    "paper_types": [
      "empirical_analysis",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Multimedia Security",
      "subdomain": "Image Steganalysis",
      "specific_problem": "Detecting spatial-domain stego in images under unknown/variable image dimensions (invariance in security across sizes)",
      "attack_types": [
        "Spatial-domain adaptive steganography (S-UNIWARD)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Dilated-Yedroudj-Net (proposed)",
        "novel_contribution": "Replace Yedroudj-Net's 2nd conv block with an inception-style block of parallel dilated convolutions (dilations 1, 2, 4 with 5x5 kernels) to approximate multi-scale receptive fields without resampling; aims to improve dimensional invariance."
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Yedroudj-Net",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "SID (statistical moments pooling: min/max/mean/variance)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "SiaSteg (attempted; did not converge)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Zhu-Net (attempted; did not converge)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "LSSD (mother dataset)",
        "type": "public",
        "domain": "images",
        "link": "https://www.lirmm.fr/chaumont/LSSD.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NNID-UNI-256",
        "type": "private",
        "domain": "images",
        "link": null,
        "is_new_contribution": true,
        "availability": "available_on_request"
      },
      {
        "name": "NNID-UNI-512",
        "type": "private",
        "domain": "images",
        "link": null,
        "is_new_contribution": true,
        "availability": "available_on_request"
      },
      {
        "name": "NNID-UNI-1024",
        "type": "private",
        "domain": "images",
        "link": null,
        "is_new_contribution": true,
        "availability": "available_on_request"
      },
      {
        "name": "NNID-MULTI (mixed 256/512/1024)",
        "type": "private",
        "domain": "images",
        "link": null,
        "is_new_contribution": true,
        "availability": "available_on_request"
      }
    ],
    "baselines": [
      {
        "method_name": "Yedroudj-Net (trained on MULTI)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "Dilated-Yedroudj-Net-MULTI: 78.10% (512), 78.06% (1024), 75.63% (256)",
        "baseline_result": "Yedroudj-Net-MULTI: 75.50% (512), 75.00% (1024), 73.93% (256)"
      },
      {
        "method_name": "SID (trained on MULTI)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "Dilated-Yedroudj-Net-MULTI: 78.10% (512), 78.06% (1024), 75.63% (256)",
        "baseline_result": "SID-MULTI: 69.46% (512), 70.60% (1024), 66.93% (256)"
      },
      {
        "method_name": "Yedroudj-Net (trained on a single size: 512)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "DY-512: 77.30% (512 diag), 76.25% (test 256), 76.88% (test 1024)",
        "baseline_result": "Y-512: 76.38% (512 diag), 73.48% (test 256), 73.57% (test 1024)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Do current CNN-based steganalyzers exhibit invariance in security when image dimensions at test time differ from training?",
        "How to construct datasets of different image sizes with matched difficulty and matched security to enable fair invariance evaluation?",
        "Can architectural changes (e.g., dilated convolutions) improve dimensional invariance without resampling that harms stego signal?"
      ],
      "gaps_identified": [
        "Existing works accepting variable-size images do not ensure matched dataset difficulty or matched empirical security across sizes, confounding invariance claims.",
        "Square Root Law does not hold in practice under these experimental conditions for equalizing detector accuracy across sizes.",
        "State-of-the-art architectures are not intrinsically invariant to image dimension; accuracy drops on unseen sizes and behavior flips (over-classify stego at smaller sizes, over-classify cover at larger sizes)."
      ],
      "limitations": [
        "Only two architectures (SID and Yedroudj-Net) converged and were fully studied; SiaSteg and Zhu-Net did not converge with given hyperparameters.",
        "Only spatial-domain S-UNIWARD embedding considered; other algorithms/modalities not evaluated.",
        "Relative payloads were tuned empirically via dichotomous search using a chosen detector; may not generalize across detectors.",
        "NNID datasets available only on request; full code for proposed Dilated-Yedroudj-Net not yet released at paper time.",
        "Experiments limited to grayscale RAW-developed natural images; 2048 size not reported in main results."
      ],
      "future_work": [
        "Design architectures and training schemes that achieve true invariance in security across sizes.",
        "Evaluate broader embedding algorithms (WOW, HILL, HUGO, color/image formats) and real-world pipelines.",
        "Develop detector-agnostic payload calibration or theoretical guidance beyond the Square Root Law.",
        "Improve cross-size feature alignment (reduce bias toward stego or cover depending on size)."
      ],
      "motivation": "Pursue more realistic 'in-the-wild' steganalysis where image size is unknown and varies; aim for detectors whose performance is invariant across dimensions.",
      "potential_research_ideas": [
        "Scale-invariant or scale-equivariant CNNs for steganalysis using group convolutions or steerable filters to maintain detection statistics across sizes.",
        "Contrastive alignment between NNID paired crops (mother vs smart-crop) to explicitly enforce cross-size feature invariance.",
        "Domain-adversarial training to minimize feature distribution gaps across image sizes while preserving stego sensitivity.",
        "Self-supervised pretraining with scale-jitter and noise-preserving augmentations to stabilize features before supervised fine-tuning.",
        "Curriculum learning over sizes (start small, progressively increase) combined with size-mixing within batches to encourage invariance.",
        "Learn a size-aware calibration head that normalizes logits based on estimated image size or content complexity measures.",
        "Explore wavelet/scattering transforms or frequency-domain high-pass banks that are naturally multi-scale and less sensitive to spatial size.",
        "Investigate deformable convolutions or dynamic receptive fields to adapt to image size while keeping high-frequency stego cues intact."
      ],
      "architectural_improvement_recommendations": [
        "Extend dilated convolutions beyond a single block; use multi-stage atrous spatial pyramid (ASPP)-like modules tailored for high-pass features.",
        "Replace GAP-only pooling with higher-order statistics pooling (e.g., mean+variance+skew/kurtosis or NetVLAD) to capture size-robust descriptors.",
        "Introduce cross-scale attention: parallel branches for multiple dilations with attention-based fusion and Squeeze-and-Excitation for channel recalibration.",
        "Add size-conditional normalization (FiLM/conditional BN) using the input resolution as conditioning to stabilize distributions.",
        "Apply contrastive loss between features of mother images and their smart-crop counterparts to enforce invariance.",
        "Use domain-adversarial loss treating each size as a domain to align feature distributions.",
        "Calibrate decision thresholds per size or train a small calibration model to correct size-induced bias in posterior probabilities."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Unknown and varying image dimensions in the wild degrade accuracy without proper invariance mechanisms.",
        "Resizing is undesirable as it can destroy weak stego signals; detectors must operate at native resolutions.",
        "Operationally tuning payloads per size to equalize security is infeasible; detectors should be robust without such tuning.",
        "Bias shifts with size (over-predicting stego at smaller sizes and cover at larger sizes) can cause operational false-positive/false-negative imbalances."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Define and operationalize 'invariance in security' for steganalysis across image dimensions.",
      "Propose smart crop 2 and Nearly Nested Image Datasets (NNID) ensuring same development and matched difficulty across sizes.",
      "Introduce a dichotomous search protocol to set per-size payloads achieving matched empirical security (accuracy) across datasets.",
      "Empirically show current CNN steganalyzers (SID, Yedroudj-Net) are not invariant to size; behavior differs for smaller vs larger test images.",
      "Propose Dilated-Yedroudj-Net that replaces a conv block with parallel dilated convolutions, improving accuracy and slightly improving cross-size robustness.",
      "Demonstrate that training on multiple sizes (MULTI) reduces but does not eliminate performance variation across sizes."
    ]
  },
  {
    "arxiv_id": "2301.08824v1",
    "title": "An Automated Vulnerability Detection Framework for Smart Contracts",
    "authors": "Feng Mi; Chen Zhao; Zhuoyi Wang; Sadaf MD Halim; Xiaodi Li; Zhouxiang Wu; Latifur Khan; Bhavani Thuraisingham",
    "abstract": "With the increase of the adoption of blockchain technology in providing decentralized solutions to various problems, smart contracts have become more popular to the point that billions of US Dollars are currently exchanged every day through such technology. Meanwhile, various vulnerabilities in smart contracts have been exploited by attackers to steal cryptocurrencies worth millions of dollars. The automatic detection of smart contract vulnerabilities therefore is an essential research problem. Existing solutions to this problem particularly rely on human experts to define features or different rules to detect vulnerabilities. However, this often causes many vulnerabilities to be ignored, and they are inefficient in detecting new vulnerabilities. In this study, to overcome such challenges, we propose a framework to automatically detect vulnerabilities in smart contracts on the blockchain. More specifically, first, we utilize novel feature vector generation techniques from bytecode of smart contract since the source code of smart contracts are rarely available in public. Next, the collected vectors are fed into our novel metric learning-based deep neural network(DNN) to get the detection result. We conduct comprehensive experiments on large-scale benchmarks, and the quantitative results demonstrate the effectiveness and efficiency of our approach.",
    "published_date": "2023-01-20",
    "pdf_link": "https://arxiv.org/pdf/2301.08824v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Security",
      "specific_problem": "Automatic detection of vulnerabilities in Ethereum smart contracts from bytecode",
      "attack_types": [
        "transaction-ordering dependence",
        "timestamp dependence",
        "mishandled exceptions",
        "reentrancy",
        "unsecured balance",
        "destroyable contract",
        "stack-overflow",
        "multiple code smell/vulnerability categories (e.g., 20 types in CodeSmell dataset)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "DNN/MLP",
        "specific": "Deep neural network with pairwise-contrastive metric learning regularizer plus cross-entropy",
        "novel_contribution": "Metric learning-based DNN with instance-weight strategy to reduce intra-class variance and improve discrimination in embedding space for smart contract vulnerability detection; operates on TF-IDF n-gram features derived from CFG/DFS-ordered opcode sequences"
      },
      {
        "type": "primary",
        "category": "Representation Learning",
        "specific": "TF-IDF on opcode n-grams (unigram + bigram) extracted via CFG and DFS traversal",
        "novel_contribution": "CFG-based opcode sequencing reflecting execution semantics rather than disassembler order to build more semantically faithful features"
      },
      {
        "type": "baseline",
        "category": "RNN/LSTM",
        "specific": "LSTM sequence model on opcode sequences (single-step training) [19]",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN/LSTM",
        "specific": "AWD-LSTM encoder-decoder pretraining then classifier fine-tuning on opcode sequences (two-step) [18]",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Majority/Union dataset (constructed from three tools' votes)",
        "type": "proprietary",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Unknown dataset (category-shift between train/test)",
        "type": "proprietary",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "CodeSmell dataset [21]",
        "type": "public",
        "domain": "smart_contracts",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SolidFI dataset [22]",
        "type": "synthetic",
        "domain": "smart_contracts",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "LSTM opcode sequence model",
        "paper_reference": "[19]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "AWD-LSTM encoder-decoder pretrain + classifier",
        "paper_reference": "[18]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Existing solutions rely on expert-defined features/rules and miss vulnerabilities; inefficient for detecting new vulnerabilities",
        "Symbolic execution/rule-based tools face scalability issues and high false positives",
        "Most smart contract source code is not publicly available; bytecode-only detection is more practical",
        "Prior ML approaches often depend on other tools' decisions, propagating their false positives/negatives",
        "Sequence models on opcode ignore execution semantics; prior works lacked CFG-based intermediate representation"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Automate detection of smart contract vulnerabilities from publicly available bytecode with better scalability and ability to generalize to new vulnerability types by leveraging metric learning and CFG-informed features.",
      "potential_research_ideas": [
        "Integrate graph neural networks over CFGs to learn structural semantics directly instead of TF-IDF n-grams",
        "Pretrain large transformer models on massive EVM opcode corpora with control-flow positional encodings, then fine-tune for vulnerability detection",
        "Multi-label and hierarchical vulnerability classification to capture multiple co-existing vulnerability types and code smell taxonomies",
        "Self-supervised contrastive learning on opcode/CFG views (e.g., path vs. block representations) to improve generalization to unseen vulnerability categories",
        "Cross-chain generalization: extend to other EVM-compatible chains and non-EVM smart contract platforms with domain adaptation",
        "Explainability modules that map detections back to opcode blocks/CFG paths and ABI functions for actionable insights",
        "Robustness analysis against adversarially obfuscated bytecode (e.g., opaque predicates, dead code) and defenses",
        "Online/streaming detection for on-chain monitoring with incremental updates and lightweight inference"
      ],
      "architectural_improvement_recommendations": [
        "Replace TF-IDF with learnable embeddings and a GNN over CFG basic blocks/edges; add attention pooling for contract-level representation",
        "Use metric learning variants (e.g., proxy-anchor, circle loss) with class-balanced sampling and hard mining tailored to skewed vulnerability distributions",
        "Incorporate mixed representations: opcode sequences, stack effect summaries, and gas/memory access features via multi-branch networks",
        "Adopt hierarchical models: basic block encoder -> function-level aggregator -> contract-level classifier with residual connections",
        "Calibrate outputs with temperature scaling and uncertainty estimation to reduce false positives for deployment"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A novel vulnerability detection framework for Ethereum smart contracts that constructs CFGs on low-level opcodes to better reflect execution semantics",
      "A metric learning-based DNN with an instance-weight strategy to improve discrimination in embedding space; claimed ability to help uncover new types of vulnerabilities on the fly",
      "Comprehensive empirical evaluation on multiple large-scale datasets (constructed via tool voting, category-shift, expert-labeled CodeSmell, and SolidFI bug injection), demonstrating effectiveness and efficiency"
    ]
  },
  {
    "arxiv_id": "2303.10795v3",
    "title": "Understanding Mobile App Reviews to Guide Misuse Audits",
    "authors": "Vaibhav Garg; Hui Guo; Nirav Ajmeri; Saikath Bhattacharya; Munindar P. Singh",
    "abstract": "Problem: We address the challenge in responsible computing where an exploitable mobile app is misused by one app user (an abuser) against another user or bystander (victim). We introduce the idea of a misuse audit of apps as a way of determining if they are exploitable without access to their implementation.   Method: We leverage app reviews to identify exploitable apps and their functionalities that enable misuse. First, we build a computational model to identify alarming reviews (which report misuse). Second, using the model, we identify exploitable apps and their functionalities. Third, we validate them through manual inspection of reviews.   Findings: Stories by abusers and victims mostly focus on past misuses, whereas stories by third parties mostly identify stories indicating the potential for misuse. Surprisingly, positive reviews by abusers, which exhibit language with high dominance, also reveal misuses. In total, we confirmed 156 exploitable apps facilitating the misuse. Based on our qualitative analysis, we found exploitable apps exhibiting four types of exploitable functionalities.   Implications: Our method can help identify exploitable apps and their functionalities, facilitating misuse audits of a large pool of apps.",
    "published_date": "2023-03-19",
    "pdf_link": "https://arxiv.org/pdf/2303.10795v3",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "App Privacy and Safety Auditing",
      "specific_problem": "Identifying exploitable mobile apps and their exploitable functionalities enabling interpersonal misuse via analysis of user reviews",
      "attack_types": [
        "spying",
        "stalking",
        "intimate partner surveillance (IPS)",
        "coerced/forced location tracking",
        "stealth monitoring of phone activities (chats, contacts, call history)",
        "overbroad access to profile information (e.g., last-seen, photos)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "SVM/Regression",
        "specific": "Support Vector Regressor (SVR) for multi-target regression",
        "novel_contribution": "Predicts convincingness and severity of reviews; defines alarmingness as geometric mean of the two predictions and aggregates to app-level for auditing"
      },
      {
        "type": "primary",
        "category": "Sentence Embedding",
        "specific": "Universal Sentence Encoder (USE)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Multitarget Regression (unspecified models)",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Chatterjee et al. IPS candidate list (2,707 iOS apps)",
        "type": "public",
        "domain": "app_reviews",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Seed Apple App Store reviews for IPS candidates (1,687 apps; 11.57M reviews)",
        "type": "public",
        "domain": "app_reviews",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Snowball dataset: Apple-recommended similar apps (788 apps; reviews Aug 2008–Aug 2022)",
        "type": "public",
        "domain": "app_reviews",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "100 Popular Utilities (Apple App Store) reviews",
        "type": "public",
        "domain": "app_reviews",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Annotated training corpus (1,884 reviews labeled for convincingness and severity)",
        "type": "public",
        "domain": "app_reviews",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Other baseline approaches (unspecified)",
        "paper_reference": null,
        "metric": "Recall (snowball dataset)",
        "their_result": "\"recall of 71.60%, which is much higher than the other baseline approaches\"",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Recall"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ info. What information regarding misuse audit is contained in reviews?",
        "RQ identify. How can we conduct a misuse audit through app reviews?",
        "RQ functionality. What exploitable functionalities are present in audited apps?"
      ],
      "gaps_identified": [
        "Traditional code audits miss interpersonal misuse by app users rather than developers: \"interpersonal misuse arising from app users (instead of app developers) goes unnoticed by such processes.\"",
        "App store metadata signals only legitimate purpose, not actual misuse: \"metadata indicates only their legitimate purpose and not the actual misuse.\"",
        "Relevant reviews vary linguistically across reviewer types (abuser, victim, third person), making mining nontrivial.",
        "Positive reviews by abusers with high dominance language can also reveal misuse, contrary to expectation."
      ],
      "limitations": [
        "Dependence on the presence of reviews; apps without reviews cannot be audited until reviews arrive.",
        "Collection of reviews for popular apps can be computationally expensive.",
        "Some reviews are old; temporal relevance needs checking (authors perform a relevance check).",
        "Model uses only review text; ratings/titles excluded and may omit useful signals in some contexts.",
        "Predictions include false positives; manual verification is required to confirm exploitable apps and functionalities.",
        "Initial seed based on IPS candidates and Apple App Store; generalization beyond this ecosystem requires validation."
      ],
      "future_work": [
        "Incrementally update MISSAUDITOR with new reviews as they arrive.",
        "Apply the approach to other sources such as Google Play Store and broader app categories.",
        "Automate more of the functionality extraction step to reduce manual verification burden.",
        "Track temporal drift in reviews and app functionalities over time."
      ],
      "motivation": "Enable responsible computing by auditing mobile apps for exploitability enabling interpersonal misuse (spying, stalking) without requiring code access; leverage user reviews to surface misuse potential and actual misuse.",
      "potential_research_ideas": [
        "Develop multilingual and cross-platform misuse auditing using large language models fine-tuned for convincingness and severity signals.",
        "Incorporate active learning and weak supervision to scale annotations of convincingness and severity with minimal human labeling.",
        "Detect and discount review manipulation (e.g., astroturfing by abusers or developers) via anomaly detection and reviewer behavior modeling.",
        "Causal inference to distinguish legitimate feature use from misuse and to identify features that causally elevate misuse risk.",
        "Temporal modeling to capture drift in misuse patterns and app updates (e.g., sequential models over review timelines).",
        "Human-in-the-loop audit triage dashboards that explain why an app is flagged and what functionalities are implicated.",
        "Cross-store linkage (Apple/Google) to identify developer patterns and supply-chain style risks across app families."
      ],
      "architectural_improvement_recommendations": [
        "Replace SVR+USE with a multi-task transformer (e.g., fine-tuned encoder) predicting ordinal convincingness/severity with uncertainty calibration.",
        "Model convincingness and severity via ordinal regression losses and capture label correlations with shared heads.",
        "Add interpretable rationales using attention-based or post-hoc explanation methods to highlight key spans supporting predictions.",
        "Robust app-level aggregation using robust statistics (e.g., trimmed means) and review de-duplication/weighting by reviewer credibility.",
        "Semi-supervised and self-training using high-confidence predictions to expand training data; incorporate contrastive learning for review embeddings.",
        "Integrate auxiliary signals (app metadata, update history, category, permissions) via multimodal fusion while guarding against confounding.",
        "Spam/fake-review defense using reviewer graph features and abnormality scoring prior to aggregation."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Processed 11.57M reviews in the seed dataset; collecting reviews for popular apps noted as computationally expensive. No GPU/training-time details provided."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High-volume review collection and processing cost for popular apps.",
        "Dependence on availability and timeliness of reviews; cold-start for new apps.",
        "Manual verification needed to confirm exploitable functionalities and filter false positives.",
        "Potential review manipulation or bias could affect signals; needs robustness safeguards."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces the concept of a misuse audit for apps based on user reviews, without requiring code access.",
      "Proposes MISSAUDITOR: labels reviews for convincingness and severity, defines alarmingness (geometric mean), aggregates to identify exploitable apps.",
      "Computational model using USE features and Support Vector Regressor for multi-target prediction of convincingness and severity.",
      "Empirical finding: \"Stories by abusers and victims mostly focus on past misuses, whereas stories by third parties mostly identify stories indicating the potential for misuse.\"",
      "Affective analysis shows abusers’ positive reviews exhibit higher dominance and valence than victims’ and third persons’.",
      "Confirmed \"156 exploitable apps\" and identified \"four types of exploitable functionalities.\"",
      "From the snowball dataset, \"the model yields a recall of 71.60%, which is much higher than the other baseline approaches.\"",
      "Demonstrates applicability beyond IPS-specific apps to general-purpose exploitable apps; outlines iterative auditing via similar-app expansion."
    ]
  },
  {
    "arxiv_id": "2302.01751v1",
    "title": "Motion ID: Human Authentication Approach",
    "authors": "Aleksei Gavron; Konstantin Belev; Konstantin Kudelkin; Vladislav Shikhov; Andrey Akushevich; Alexey Fartukov; Vladimir Paramonov; Dmitry Syromolotov; Artem Makoyan",
    "abstract": "We introduce a novel approach to user authentication called Motion ID. The method employs motion sensing provided by inertial measurement units (IMUs), using it to verify the persons identity via short time series of IMU data captured by the mobile device. The paper presents two labeled datasets with unlock events: the first features IMU measurements, provided by six users who continuously collected data on six different smartphones for a period of 12 weeks. The second one contains 50 hours of IMU data for one specific motion pattern, provided by 101 users. Moreover, we present a two-stage user authentication process that employs motion pattern identification and user verification and is based on data preprocessing and machine learning. The Results section details the assessment of the method proposed, comparing it with existing biometric authentication methods and the Android biometric standard. The method has demonstrated high accuracy, indicating that it could be successfully used in combination with existing methods. Furthermore, the method exhibits significant promise as a standalone solution. We provide the datasets to the scholarly community and share our project code.",
    "published_date": "2023-01-25",
    "pdf_link": "https://arxiv.org/pdf/2302.01751v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "User Authentication / Biometrics",
      "specific_problem": "Implicit behavioral authentication on smartphones using IMU-based motion patterns (pre-unlock pattern detection and user verification)",
      "attack_types": [
        "impostor attacks",
        "presentation attacks (spoofing)",
        "pattern imitation/hijacking attempts"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN (1D)",
        "specific": null,
        "novel_contribution": "Two-stage pipeline: (1) 1D CNN for Motion Patterns Identification (binary true/false unlock event) trained with cross-entropy and ROC-AUC selection; (2) multi-branch 1D CNN feature extractor over 22 engineered IMU feature streams for user verification."
      },
      {
        "type": "primary",
        "category": "Siamese Network / Metric Learning",
        "specific": "Triplet Margin Loss; Supervised Contrastive Loss",
        "novel_contribution": "Dual-head training: classification head with cross-entropy on user IDs plus Siamese head with Triplet Margin Loss (and supervised contrastive loss per Figure 3) for discriminative embeddings; twice-augmented inputs to improve robustness."
      },
      {
        "type": "primary",
        "category": "Feature engineering / Signal processing",
        "specific": null,
        "novel_contribution": "Rotate accelerometer/gyroscope/magnetometer to Earth-fixed frame; compute linear acceleration from raw signals; differences and integrals (rotated/unrotated) to form 22 feature vectors per sample; 1-second windows pre-unlock."
      },
      {
        "type": "baseline",
        "category": "Classical biometric comparators",
        "specific": "Android CDD biometric classes; fingerprint/iris/face systems",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Metric Learning",
      "Online learning (per-user fine-tuning)"
    ],
    "datasets": [
      {
        "name": "Motion Patterns Identification (Motion ID) dataset",
        "type": "public",
        "domain": "imu_sensors",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "User Verification (Motion ID) dataset",
        "type": "public",
        "domain": "imu_sensors",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "UCI-HAR",
        "type": "public",
        "domain": "imu_sensors",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "HMOG",
        "type": "public",
        "domain": "imu_sensors",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "WISDM-HARB",
        "type": "public",
        "domain": "imu_sensors",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Large multimodal smartphone biometrics dataset (1,500 volunteers)",
        "type": "private",
        "domain": "multimodal (camera, touchscreen, GPS, Bluetooth, IMU)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Study (3) IMU dataset (~30 volunteers, 1 Hz)",
        "type": "unknown",
        "domain": "imu_sensors",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      }
    ],
    "baselines": [
      {
        "method_name": "Android CDD biometric standard (Class 3/Strong)",
        "paper_reference": null,
        "metric": "TAR@FAR=1/50000 (90% target)",
        "their_result": null,
        "baseline_result": "Strong Class requires TAR(@FAR=1/50000)=90%"
      },
      {
        "method_name": "Fingerprint recognition",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Iris recognition",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Face recognition",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "ROC-AUC",
      "TAR",
      "FAR",
      "ROC curves"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can short IMU time series preceding unlock events implicitly authenticate smartphone users with accuracy comparable to Android’s biometric standard?",
        "Can a two-stage pipeline (motion pattern identification followed by user verification) provide robust authentication without explicit user interaction?",
        "What dataset design and preprocessing enable reliable pre-unlock pattern detection and user-specific verification on-device?"
      ],
      "gaps_identified": [
        "Very few IMU datasets exist and they vary widely; no standard collection protocols for biometric use.",
        "Existing IMU datasets often lack unlock-event labels crucial for this task.",
        "Common public datasets have low sampling rates (e.g., 20 Hz or 1 Hz) inadequate for biometric-grade verification.",
        "Collecting and storing rich multimodal smartphone data is impractical for resource-constrained biometric systems.",
        "Off-line training risks overfitting to seen users; per-user adaptation is needed."
      ],
      "limitations": [
        "Sample size constraints for estimating very low FAR; authors relied on bootstrap and cross-comparisons rather than fully independent 1.5M impostor trials.",
        "User Verification data collected on a single device model (Galaxy S20) and a specific motion (lifting from a table), which may limit generalization across devices/patterns.",
        "Sensor instability noted (e.g., linear accelerometer frequency spikes), requiring manual derivation of some features.",
        "On-line approach evaluated whereas Android CDD metrics define off-line class metrics; direct comparability is limited.",
        "Ergonomic effects and learning across the six locations affected consistency (first vs sixth location differences)."
      ],
      "future_work": [],
      "motivation": "Eliminate drawbacks of explicit biometrics (hardware costs, spoofing, corner cases like masks/gloves, limited applicability to non-phone devices) by leveraging ubiquitous IMUs for passive authentication.",
      "potential_research_ideas": [
        "Extend to continuous/ongoing authentication beyond pre-unlock, combining multiple daily micro-patterns.",
        "Cross-device/domain adaptation to handle different phone models, positions (pocket, bag), and additional motion patterns (e.g., picking from pocket, wrist-to-eye).",
        "Adversarial/anti-spoof modeling: detect imitation/replay of motion patterns; develop challenge-response micro-motions.",
        "Federated/on-device personalization to preserve privacy while improving per-user models.",
        "Self-/contrastive pretraining on large unlabeled IMU corpora to improve representation learning before per-user fine-tuning.",
        "Multisensor fusion with low-cost sensors (proximity, barometer, touchscreen micro-dynamics) under strict resource budgets.",
        "Calibration- and orientation-invariant representations to mitigate sensor/placement variability.",
        "Template protection and cancellable motion biometrics to improve security/privacy of embeddings."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment 1D CNNs with temporal Transformers or Temporal Convolutional Networks with dilations for longer context while maintaining efficiency.",
        "Use multi-task learning with auxiliary tasks (e.g., orientation estimation, activity recognition) to regularize embeddings.",
        "Adopt supervised contrastive learning explicitly with strong augmentations and prototype-based classification for better inter/intra-class separation.",
        "Apply domain adaptation (e.g., adversarial feature alignment) for cross-device generalization; include device-ID conditioning.",
        "Prototype/nearest-centroid or metric calibration per user with probabilistic thresholding and uncertainty estimation.",
        "Lightweight on-device inference optimizations: quantization, knowledge distillation, and streaming inference windows."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Android smartphone (on-device IMU sensing; pre-unlock prediction)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Battery and performance overhead of continuous IMU sensing and pre-unlock inference.",
        "Device heterogeneity and sensor calibration differences across models.",
        "Generalization across motion contexts (pocket, bag, table) and user ergonomics.",
        "Meeting stringent FAR targets with feasible data collection and evaluation protocols.",
        "Privacy concerns around continuous motion data collection and storage.",
        "Risk of imitation/spoofing of motion patterns without dedicated anti-spoof modules."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces Motion ID, a two-stage implicit authentication method using short IMU time series collected pre-unlock.",
      "Releases two labeled IMU datasets with unlock-event flags: (1) 12-week, 6 users × 6 smartphones daily-use dataset; (2) ~50 hours, 101 users, controlled lift-from-table motion with 300 attempts per user across 6 locations.",
      "Proposes preprocessing and engineered features (Earth-fixed rotation, derivatives/integrals, computed linear acceleration) forming 22 feature streams.",
      "Designs a multi-branch 1D CNN feature extractor with dual-head training (classification and Siamese triplet/contrastive losses) for user verification.",
      "Compares method against Android biometric standards conceptually; targets Class 3 TAR(@FAR=1/50000)=90% via bootstrap evaluation.",
      "Provides datasets and project code to the community."
    ]
  },
  {
    "arxiv_id": "2302.13234v1",
    "title": "APT Encrypted Traffic Detection Method based on Two-Parties and Multi-Session for IoT",
    "authors": "Junfeng Xu; Weiguo Lin; Wenqing Fan",
    "abstract": "APT traffic detection is an important task in network security domain, which is of great significance in the field of enterprise security. Most APT traffic uses encrypted communication protocol as data transmission medium, which greatly increases the difficulty of detection. This paper analyzes the existing problems of current APT encrypted traffic detection methods based on machine learning, and proposes an APT encrypted traffic detection method based on two parties and multi-session. This method only needs to extract a small amount of features, such as session sequence, session time interval, upstream and downstream data size, and convert them into images. Then convolutional neural network method can be used to realize image recognition. Thus, network traffic identification can be realized too. In the preliminary test of five experiments, this method achieves good experimental results, which verifies the effectiveness of the method.",
    "published_date": "2023-02-26",
    "pdf_link": "https://arxiv.org/pdf/2302.13234v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Malware Traffic Detection",
      "specific_problem": "Detection of APT command-and-control (C&C) encrypted traffic using two-party multi-session features converted to images",
      "attack_types": [
        "Advanced Persistent Threat (APT)",
        "Command & Control (C&C) over TLS/encrypted channels"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "LeNet-5-style CNN (with Softmax, dropout)",
        "novel_contribution": "Represents two-party multi-session network interactions as images encoding session order, inter-session time intervals, and up/down application-data bytes; trains a compact LeNet-5-like CNN for classification of APT C&C vs normal traffic."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Internal two-parties multi-session traffic dataset (APT C&C and normal apps: Chrome, Outlook, Excel, Youku)",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "KDD CUP 1999",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "USTC-TFC-2016",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can aggregating multi-session features between two communicating parties and converting them into images enable accurate detection of encrypted APT C&C traffic?",
        "Does a compact CNN (LeNet-5 style) suffice to classify APT C&C vs various normal encrypted traffic when using session-sequence, inter-session time, and up/down data size features?"
      ],
      "gaps_identified": [
        "Most existing methods use a single session/flow (4-tuple) as the basic identification unit, missing APT patterns that manifest across multiple sessions.",
        "Widespread use of TLS and encrypted protocols limits traditional IoC/signature/DPI-based detection effectiveness.",
        "Current ML-based encrypted traffic detection has not fully exploited multi-session features (order, timing, up/down ratios) between two parties."
      ],
      "limitations": [
        "Requires a specially created proprietary dataset; no public release of data for replication.",
        "Preliminary evaluation only; five binary classification experiments; no multi-class experiments.",
        "Limited traffic diversity: one APT group (C&C phase) and four normal applications (Chrome, Outlook, Excel, Youku).",
        "No comparison against prior ML baselines or state-of-the-art methods.",
        "Generalization to other APT families, protocols, networks, and IoT settings is untested.",
        "Operational details (time windowing, grouping heuristics, thresholds, hyperparameters) are not fully specified."
      ],
      "future_work": [
        "\"we will use more types of data to carry out the verification work\"",
        "\"expand the experimental task to multi-classification scenarios to further explore the application potential of this method\""
      ],
      "motivation": "Encrypted APT communications reduce the efficacy of signature/DPI-based detection; single-session ML approaches miss multi-session patterns common in APT C&C; propose a two-parties multi-session image-based method to capture temporal and directionality patterns.",
      "potential_research_ideas": [
        "Release and/or construct a public benchmark for two-parties multi-session encrypted traffic detection to enable reproducible comparisons.",
        "Extend to multi-class classification among multiple APT families and normal applications; hierarchical detection (malicious vs benign, then family).",
        "Sequence modeling of session groups using Transformers or temporal CNNs with positional encodings, rather than 2D image conversion, to better capture timing and order.",
        "Incorporate additional metadata channels (e.g., TLS record lengths, JA3/JA4 client/server fingerprints, TCP flags, burstiness metrics) in a multi-channel input.",
        "Self-supervised or contrastive pretraining on session-group sequences to reduce label requirements and improve generalization to unseen APTs.",
        "Domain adaptation/continual learning to handle non-stationarity across networks and time; evaluation under concept drift.",
        "Online/streaming detection with sliding windows and early decision making for near-real-time C2 detection.",
        "Explainability methods (e.g., saliency on image features or attention over sessions) to highlight discriminative multi-session patterns for analysts.",
        "Adversarial robustness study (evasion via padding, timing jitter, traffic morphing) and defenses (adversarial training, invariant features).",
        "Assess impact of TLS 1.3, encrypted SNI, QUIC/HTTP3, and traffic padding on feature utility and detection performance."
      ],
      "architectural_improvement_recommendations": [
        "Replace LeNet-5 with modern lightweight backbones (e.g., ResNet-18, EfficientNet-B0, MobileNetV3) and compare accuracy/latency trade-offs.",
        "Model session groups as sequences/graphs: use Transformer encoders with learned positional/time-gap embeddings or a GNN over session nodes with temporal edges.",
        "Encode features as multi-channel tensors (separate channels for up-bytes, down-bytes, time gaps) with learned normalization and logarithmic scaling to handle heavy tails.",
        "Use attention-based pooling over variable-length session groups; avoid fixed-size image constraints.",
        "Calibrated probabilistic outputs (temperature scaling) and threshold optimization for operational deployment; incorporate class-imbalance techniques (focal loss).",
        "Perform k-fold cross-validation and hyperparameter search; report variance and confidence intervals.",
        "Augment training with traffic perturbations (noise in timing/size) to improve robustness; consider mixup/cutmix adapted to sequence or image encodings."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Keras",
        "TensorFlow"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "Ubuntu 18.04 (64-bit); Keras + TensorFlow; 80/20 train/test split; GPU/CPU hardware and training time not specified."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Method requires grouping multiple sessions by two communicating parties (client IP, server IP, server port) over a time period.",
        "Training/evaluation requires datasets containing sufficient multi-session interactions per pair; public datasets with this structure are scarce."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes an APT encrypted traffic detection method based on two parties and multi-session, converting selected features into images and applying a CNN for classification.",
      "Defines an image encoding that visualizes per-session up/down application-layer byte sizes, session order, and inter-session time intervals for a pair of endpoints.",
      "Implements a compact LeNet-5-style CNN with two conv + pooling layers, two fully connected layers, Softmax, and dropout.",
      "Constructs an internal dataset grouped by two-party communications: APT C&C (3500 groups) and normal apps (Chrome, Outlook, Excel, Youku; 5000 groups each).",
      "Reports preliminary results over five binary classification tasks; all accuracies >90%, up to 99.8% (APT-C&C vs Outlook) and 96.1% on a mixed-normal set. Example quoted results: \"the highest 99.8% results were achieved in the APT-C&C and Outlook classification experiments\"; \"the accuracy rate is 96.1%\" on mixed normal traffic."
    ]
  },
  {
    "arxiv_id": "2302.07445v1",
    "title": "Silent Vulnerable Dependency Alert Prediction with Vulnerability Key Aspect Explanation",
    "authors": "Jiamou Sun; Zhenchang Xing; Qinghua Lu; Xiwei Xu; Liming Zhu; Thong Hoang; Dehai Zhao",
    "abstract": "Due to convenience, open-source software is widely used. For beneficial reasons, open-source maintainers often fix the vulnerabilities silently, exposing their users unaware of the updates to threats. Previous works all focus on black-box binary detection of the silent dependency alerts that suffer from high false-positive rates. Open-source software users need to analyze and explain AI prediction themselves. Explainable AI becomes remarkable as a complementary of black-box AI models, providing details in various forms to explain AI decisions. Noticing there is still no technique that can discover silent dependency alert on time, in this work, we propose a framework using an encoder-decoder model with a binary detector to provide explainable silent dependency alert prediction. Our model generates 4 types of vulnerability key aspects including vulnerability type, root cause, attack vector, and impact to enhance the trustworthiness and users' acceptance to alert prediction. By experiments with several models and inputs, we confirm CodeBERT with both commit messages and code changes achieves the best results. Our user study shows that explainable alert predictions can help users find silent dependency alert more easily than black-box predictions. To the best of our knowledge, this is the first research work on the application of Explainable AI in silent dependency alert prediction, which opens the door of the related domains.",
    "published_date": "2023-02-15",
    "pdf_link": "https://arxiv.org/pdf/2302.07445v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Supply Chain Security",
      "subdomain": "Vulnerable Dependency Detection",
      "specific_problem": "Predicting silent vulnerable dependency updates (patch commits) and generating vulnerability key aspect explanations for downstream users",
      "attack_types": [
        "directory traversal",
        "improper input validation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "CodeBERT",
        "novel_contribution": "End-to-end framework that jointly performs binary detection of silent vulnerability patches and generates textual explanations of four key vulnerability aspects from commit messages and code diffs"
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT (NER)",
        "novel_contribution": "Used to extract named-entity style key aspects from NVD/IBM descriptions to build ground-truth labels"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT (QA/span extraction)",
        "novel_contribution": "Used to extract free-form key aspects (root cause, attack vector, impact) from NVD/IBM descriptions to build ground-truth labels"
      },
      {
        "type": "primary",
        "category": "Encoder-Decoder",
        "specific": null,
        "novel_contribution": "Text generation of vulnerability key aspects coordinated with NVD templates from commit-level inputs"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Explainable Silent Dependency Alerts Dataset (8,946 commits; 2,017 repos; 25,060 aspect entries)",
        "type": "public",
        "domain": "source_code_commits_and_diffs",
        "link": "https://github.com/anonymous-dev904/aspect generation",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "NVD (Common Vulnerabilities and Exposures descriptions)",
        "type": "public",
        "domain": "vulnerability_descriptions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IBM X-Force vulnerability database",
        "type": "public",
        "domain": "vulnerability_descriptions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "GitHub Advisory Database",
        "type": "public",
        "domain": "vulnerability_descriptions_and_commit_references",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Snyk vulnerability database",
        "type": "public",
        "domain": "vulnerability_descriptions_and_commit_references",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Serena et al.'s Java vulnerability dataset (CVE-commit traceability)",
        "type": "public",
        "domain": "source_code_commits_and_traceability",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Liu et al.'s C dependency vulnerability dataset (CVE-commit traceability)",
        "type": "public",
        "domain": "source_code_commits_and_traceability",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "AUC",
      "ROUGE-1"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can we predict silent vulnerable dependency updates at commit time using commit messages and code changes?",
        "Can generating vulnerability key aspects (type, root cause, attack vector, impact) improve user acceptance and effectiveness over black-box binary predictions?",
        "Which inputs (commit messages vs. code diffs) and models yield the best performance for classification and explanation generation?"
      ],
      "gaps_identified": [
        "Existing black-box binary detectors for vulnerability patches suffer from high false-positive rates and lack explanations.",
        "Public advisories (e.g., NVD) have significant delays in publishing vulnerabilities and patches, leaving downstream users at risk.",
        "No existing technique discovers silent dependency alerts in a timely, explainable manner for downstream users.",
        "Patching commit links are often missing from advisories, complicating ground-truth collection.",
        "NVD descriptions often lack complete key aspects (especially root cause and attack vector)."
      ],
      "limitations": [
        "BERT-based NER/QA extractors used for building aspect ground truth achieve only about 0.66–0.90 F1 and required manual validation.",
        "Aspect deficiencies in NVD required supplementation from IBM X-Force; reliance on multiple sources may introduce inconsistency.",
        "Details of model computational cost and deployment considerations are not discussed in the provided text."
      ],
      "future_work": [],
      "motivation": "Enable timely and trustworthy detection of silently patched vulnerabilities in dependencies by providing human-readable explanations aligned with NVD templates, complementing tools like CodeQL and Dependabot.",
      "potential_research_ideas": [
        "Retrieval-augmented generation that conditions explanations on semantically similar historical CVEs and patches.",
        "Multi-task learning to jointly predict vulnerability patch status and structured CWE labels, with explanation generation as an auxiliary task.",
        "Leverage large code-focused LLMs (e.g., CodeT5/StarCoder) with instruction tuning for aspect generation.",
        "Active learning with developer feedback to reduce false positives and improve explanation quality over time.",
        "Cross-repository and dependency-graph context modeling to capture supply chain relationships influencing risk.",
        "Temporal models for early prediction using commit streams and release timelines.",
        "Uncertainty estimation and calibrated confidence to help triage alerts.",
        "Data augmentation and hard negative mining to address class imbalance."
      ],
      "architectural_improvement_recommendations": [
        "Hierarchical encoder that separately encodes commit messages and code diffs (files/hunks) with cross-attention fusion.",
        "Contrastive pretraining on commit-diff pairs (vuln vs. non-vuln) to improve representation robustness.",
        "Dual-encoder retrieval module to fetch similar CVE descriptions/patches to condition the generator.",
        "Graph neural networks over file/function dependency graphs to capture code context beyond diffs.",
        "Incorporate AST and code semantics (e.g., data-flow) alongside textual diffs.",
        "Confidence calibration and selective prediction (abstain) for low-certainty cases."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/anonymous-dev904/aspect generation",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "High false-positive rates in prior detectors necessitate careful thresholding and triage interfaces.",
        "Linking CVE records to specific patch commits is incomplete in public advisories.",
        "Imbalanced datasets across languages and projects.",
        "Potential variability in explanation quality depending on commit message completeness."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Provide a large dataset of patching commits and corresponding vulnerability key aspects.",
      "Propose the first approach for predicting silent vulnerable dependency updates with explanations.",
      "Conduct experiments across models and inputs; CodeBERT with commit messages and code changes achieved 0.89 AUC and 32.8–45.2 ROUGE-1.",
      "User study indicating explainable predictions help users recognize silent dependency alerts more easily than black-box predictions."
    ]
  },
  {
    "arxiv_id": "2302.02276v1",
    "title": "JPEG Steganalysis Based on Steganographic Feature Enhancement and Graph Attention Learning",
    "authors": "Qiyun Liu; Zhiguang Yang; Hanzhou Wu",
    "abstract": "The purpose of image steganalysis is to determine whether the carrier image contains hidden information or not. Since JEPG is the most commonly used image format over social networks, steganalysis in JPEG images is also the most urgently needed to be explored. However, in order to detect whether secret information is hidden within JEPG images, the majority of existing algorithms are designed in conjunction with the popular computer vision related networks, without considering the key characteristics appeared in image steganalysis. It is crucial that the steganographic signal, as an extremely weak signal, can be enhanced during its representation learning process. Motivated by this insight, in this paper, we introduce a novel representation learning algorithm for JPEG steganalysis that is mainly consisting of a graph attention learning module and a feature enhancement module. The graph attention learning module is designed to avoid global feature loss caused by the local feature learning of convolutional neural network and reliance on depth stacking to extend the perceptual domain. The feature enhancement module is applied to prevent the stacking of convolutional layers from weakening the steganographic information. In addition, pretraining as a way to initialize the network weights with a large-scale dataset is utilized to enhance the ability of the network to extract discriminative features. We advocate pretraining with ALASKA2 for the model trained with BOSSBase+BOWS2. The experimental results indicate that the proposed algorithm outperforms previous arts in terms of detection accuracy, which has verified the superiority and applicability of the proposed work.",
    "published_date": "2023-02-05",
    "pdf_link": "https://arxiv.org/pdf/2302.02276v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Multimedia Security",
      "subdomain": "Steganalysis",
      "specific_problem": "JPEG image steganalysis (binary cover vs stego detection)",
      "attack_types": [
        "J-UNIWARD",
        "UED-JC"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Graph Attention Network (GAT)",
        "novel_contribution": "Graph Attention Learning (GAL) module that models global dependencies by constructing a complete graph over 8x8 DCT block positions and learning pixel-level attention to enhance weak steganographic features; outputs a 256x256 feature map fused with CNN features."
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "Steganographic Feature Enhancement (SFE) module with two SFE layers (no pooling, stride=1, 1x1 conv shortcuts and concatenation) to prevent suppression/disappearance of weak stego signals and preserve shallow features."
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Residual CNN blocks (SRNet-type3 inspired)",
        "novel_contribution": "Four-block feature learning head with residual shortcuts and staged downsampling; final global pooling and FC+softmax for classification."
      },
      {
        "type": "primary",
        "category": "Pretraining/Transfer Learning",
        "specific": null,
        "novel_contribution": "Pretraining on ALASKA2 (QF75/95, payloads 0.1–0.5 bpnzac, J-UNIWARD/UED-JC) to initialize weights for BOSSBase+BOWS2 training, improving convergence and accuracy on small-payload detection."
      },
      {
        "type": "baseline",
        "category": "Activation/Feature Extractor",
        "specific": "SRM high-pass filters + TLU",
        "novel_contribution": "Domain-knowledge-driven preprocessing: SRM filter bank initialization (30 5x5 filters) and TLU activation with BN to extract symmetric residuals and enhance noise-like stego cues."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Transfer Learning (pretraining)"
    ],
    "datasets": [
      {
        "name": "BOSSBase v1.01",
        "type": "public",
        "domain": "images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "BOWS2",
        "type": "public",
        "domain": "images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ALASKA2",
        "type": "public",
        "domain": "images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "classification accuracy",
      "total classification error probability (PE) = min_{PFA} 1/2 (PFA + PMD)",
      "false-alarm rate (PFA)",
      "missed-detection rate (PMD)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How to prevent weak steganographic signals from being suppressed or disappearing during deep CNN processing?",
        "How to exploit global (inter-block) features of JPEG stego signals that CNNs with local receptive fields may miss?"
      ],
      "gaps_identified": [
        "CNN depth and pooling suppress extremely weak stego features; features can disappear as layers stack.",
        "Local receptive fields of CNNs cause loss of global inter-block dependencies in JPEG steganalysis, leading to reliance on deep stacking to extend perceptual field.",
        "Small datasets and random initialization make learning good residual extractors difficult without domain priors."
      ],
      "limitations": [
        "Experiments crop images to 256x256 due to limited computing resources.",
        "Graph attention network choice kept simple (2-layer GAT); authors note GAT design 'deserves further study'.",
        "Pretraining explored only selected QFs (75,95) and payload settings; generalization beyond evaluated QFs/payloads not reported.",
        "No code link provided; reproducibility depends on described hyperparameters."
      ],
      "future_work": [
        "Further study/design of graph attention architectures tailored to JPEG steganalysis.",
        "Explore broader/more diverse pretraining curricula (more QFs, payload schedules, stego algorithms).",
        "Scale to higher input resolutions and assess impact on detection, especially for very low payloads.",
        "Investigate robustness/generalization to unseen QFs, cameras, and embedding algorithms."
      ],
      "motivation": "Enhance representation learning for JPEG steganalysis by preserving weak stego signals and capturing global dependencies that conventional CNNs may miss, thereby improving detection accuracy.",
      "potential_research_ideas": [
        "Design multi-scale graph representations (nodes at DCT coefficient positions, 8x8 blocks, and macro-blocks) with hierarchical attention for cross-scale stego cue aggregation.",
        "Integrate frequency-domain features explicitly (e.g., DCT coefficient graphs per frequency) fused with spatial residual graphs via cross-attention.",
        "Self-supervised or contrastive pretraining tailored to residual/stego signals to reduce labeled pair dependence and improve low-payload performance.",
        "Domain adaptation to handle QF/camera/source mismatch between training (ALASKA2/BOSSBase+BOWS2) and deployment domains.",
        "Payload-aware multi-task learning (joint detection + payload estimation) to help networks focus on subtle signals at low embedding rates.",
        "Curriculum pretraining from high to low payloads and from simpler to harder QFs to guide representation learning.",
        "Knowledge distillation from a large teacher (with stronger global modeling) to a lightweight student for efficient deployment."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment GAT with vision transformer-style global self-attention or graph transformers to better capture long-range dependencies.",
        "Deepen GAL with multi-head, multi-layer attention and residual connections; add edge features (e.g., spatial distance, frequency relation) rather than complete unweighted graph.",
        "Construct frequency-aware graphs (separate nodes per DCT frequency band) and perform cross-frequency message passing.",
        "Incorporate selection-channel priors as attention biases to guide graph/CNN modules toward more probable modification regions.",
        "Use squeeze-and-excitation or channel attention in SFE/CNN blocks and gated residuals to modulate weak signals.",
        "Adopt learnable high-pass banks initialized from SRM but trained with spectral regularization to retain residual properties.",
        "Apply mixed-resolution training and anti-aliased downsampling to mitigate information loss when reducing feature map sizes."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PyTorch"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Single NVIDIA TITAN RTX 24 GB GPU; minibatch size 16 cover–stego pairs; Adamax optimizer; pretraining 100 epochs on ALASKA2; fine-tuning ~350,000 iterations (400 epochs) at lr=0.001 then +87,500 iterations (100 epochs) at lr=0.0001; BN with EMA decay 0.9; He initialization; L2 regularization 2e-4 on filters; FC initialized with N(0, 0.01)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes JPEG-GraphNet, a new JPEG steganalysis architecture combining CNN-based Steganographic Feature Enhancement (SFE) with Graph Attention Learning (GAL) for global feature modeling.",
      "Introduces SFE modules that remove pooling and use stride=1 with 1x1 shortcuts and concatenation to preserve and enhance weak stego signals across depths.",
      "Develops a GAL pipeline that constructs a complete graph over 8x8 block positions and applies a 2-layer GAT to compute pixel-level attention and global features, fused with SFE outputs.",
      "Advocates and validates pretraining on ALASKA2 to initialize models trained on BOSSBase+BOWS2, improving convergence and detection accuracy, especially at small payloads.",
      "Reports improved detection accuracy over prior works across payloads and QFs (75, 95), using metrics including total classification error probability."
    ]
  },
  {
    "arxiv_id": "2301.11767v1",
    "title": "CAPoW: Context-Aware AI-Assisted Proof of Work based DDoS Defense",
    "authors": "Trisha Chakraborty; Shaswata Mitra; Sudip Mittal",
    "abstract": "Critical servers can be secured against distributed denial of service (DDoS) attacks using proof of work (PoW) systems assisted by an Artificial Intelligence (AI) that learns contextual network request patterns. In this work, we introduce CAPoW, a context-aware anti-DDoS framework that injects latency adaptively during communication by utilizing context-aware PoW puzzles. In CAPoW, a security professional can define relevant request context attributes which can be learned by the AI system. These contextual attributes can include information about the user request, such as IP address, time, flow-level information, etc., and are utilized to generate a contextual score for incoming requests that influence the hardness of a PoW puzzle. These puzzles need to be solved by a user before the server begins to process their request. Solving puzzles slow down the volume of incoming adversarial requests. Additionally, the framework compels the adversary to incur a cost per request, hence making it expensive for an adversary to prolong a DDoS attack. We include the theoretical foundations of the CAPoW framework along with a description of its implementation and evaluation.",
    "published_date": "2023-01-27",
    "pdf_link": "https://arxiv.org/pdf/2301.11767v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "DDoS Mitigation",
      "specific_problem": "Adaptive Proof-of-Work (PoW) based defense using context-aware AI to throttle malicious requests",
      "attack_types": [
        "Distributed Denial of Service (DDoS)",
        "Denial of Service (DoS)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Anomaly Detection / Clustering",
        "specific": null,
        "novel_contribution": "Context-aware ensemble that learns normal patterns per context (IP, time, flow-level) from activity logs and maps deviation to a contextual score that drives PoW difficulty."
      },
      {
        "type": "primary",
        "category": "Rule-based System",
        "specific": "Policy module",
        "novel_contribution": "Security-professional-authored policies to weight contexts, select training logs, and map context scores to PoW difficulty including puzzle type selection."
      },
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": "Combination via argmax of base context models (DAbR, TAM, FLOW)",
        "novel_contribution": "Combines multiple contextual scores into a single score to set puzzle difficulty."
      },
      {
        "type": "baseline",
        "category": "Reputation / Heuristic",
        "specific": "Dynamic Attribute-based Reputation (DAbR) [29]",
        "novel_contribution": "Used as base model for IP-context; projects IP attributes and computes distance to malicious cluster."
      },
      {
        "type": "primary",
        "category": "Time-series / Pattern Mining",
        "specific": "Temporal Activity Model (TAM)",
        "novel_contribution": "Learns per-user temporal request windows from selected historical days and computes deviation-based score."
      },
      {
        "type": "primary",
        "category": "Feature-space Modeling",
        "specific": "Flow-level model (FLOW)",
        "novel_contribution": "Learns flow-level feature patterns and computes Euclidean distance to normal cluster center for scoring."
      }
    ],
    "learning_paradigm": [
      "Unsupervised / One-class (learn normal patterns from benign logs)",
      "Rule-based (policy for weighting and score-to-difficulty mapping)"
    ],
    "datasets": [
      {
        "name": "CIC-IDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Cisco Talos IP Reputation Data",
        "type": "public",
        "domain": "ip_reputation",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Server Activity Logs (organizational)",
        "type": "private",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Latency (time to solve PoW puzzle)",
      "CPU cycles/resource burning cost (qualitative)",
      "Context score distributions (per model and combined)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can contextual attributes of requests be learned to adapt PoW puzzle difficulty so that malicious users incur higher latency than legitimate users?",
        "How should PoW difficulty be set dynamically across varying contexts and server-specific requirements?",
        "Can an ensemble of context-aware models effectively throttle adversarial request rates via adaptive latency?"
      ],
      "gaps_identified": [
        "Prior PoW-based DDoS defenses lack guidance on how to set puzzle difficulty and adapt to different settings.",
        "Existing approaches insufficiently leverage context (IP, temporal, flow-level) learned from server-specific activity logs.",
        "Fairness/equity concerns across heterogeneous client hardware when using CPU-bound puzzles are under-addressed; memory-bound puzzles may reduce disparity.",
        "Susceptibility to spoofed identifiers (e.g., IP spoofing) is a challenge for context-driven defenses.",
        "Risk of model/data poisoning necessitates careful selection of trusted training logs."
      ],
      "limitations": [
        "Assumes unpolluted training data; relies on security personnel to curate safe activity logs.",
        "Policy design is non-trivial and requires expert input (e.g., context selection, weights, score-to-difficulty mapping).",
        "Adversary can spoof identifiers (e.g., IP addresses) and potentially probe to find easier contexts; defense relies on increased probing cost rather than full prevention.",
        "Evaluation is on offline dataset; no real-world deployment or large-scale scalability study reported.",
        "Implemented PoW instance is hash-based (CPU-bound), which may disadvantage low-resource legitimate clients.",
        "No quantitative comparison against existing DDoS/PoW baselines is presented."
      ],
      "future_work": [],
      "motivation": "DDoS attacks remain cheaper to launch than defend; existing PoW defenses lack adaptive, context-aware mechanisms to set puzzle difficulty. CAPoW aims to penalize contextual deviations with higher PoW difficulty to throttle attackers and impose per-request cost.",
      "potential_research_ideas": [
        "Automate policy design with reinforcement learning or Bayesian optimization to map context scores to puzzle difficulty under service-level and fairness constraints.",
        "Incorporate additional context features (e.g., TLS fingerprints, behavioral sequences, ASNs, geo, device/browser fingerprints) and multi-factor scoring to mitigate spoofing.",
        "Adopt memory-bound or bandwidth-bound puzzles adaptively per-client hardware profiling to improve fairness and attacker cost symmetry.",
        "Online/continual learning with drift detection for TAM and FLOW to handle evolving traffic patterns without catastrophic forgetting.",
        "Combine CAPoW with rate limiting, token-bucket, or client reputations for hybrid defense, dynamically switching between puzzle types based on attack stage.",
        "Explore privacy-preserving training on logs (e.g., differential privacy or federated learning) to avoid central log exposure while retaining utility.",
        "Adversarially robust anomaly detection (e.g., certified robust scoring or ensemble diversity) against probing and evasion.",
        "Formal analysis of economic costs for attacker vs defender under different puzzle types and parameterizations.",
        "Use sequence models (e.g., Transformers) on flow sequences to capture richer temporal dependencies for TAM/FLOW while keeping verifier lightweight."
      ],
      "architectural_improvement_recommendations": [
        "Replace simple Euclidean distance-to-centroid with robust one-class methods (OC-SVM, Isolation Forest) or deep autoencoders for each context, calibrated via conformal prediction.",
        "Calibrate and fuse context scores using learned weighting (e.g., logistic regression or gradient boosting) instead of argmax; add uncertainty estimation to avoid over-penalizing borderline cases.",
        "Introduce adaptive puzzle type selection (CPU-, memory-, bandwidth-, or human-in-the-loop) via a multi-armed bandit optimizing latency and false-penalty rates.",
        "Implement client capability profiling to tailor puzzle hardness and type per client while bounding maximum latency for legitimate users.",
        "Add drift detection and sliding windows for TAM/FLOW with automatic aging of logs and retraining triggers.",
        "Harden against spoofing by cross-validating multiple contexts (e.g., IP + ASN + TLS JA3 + RTT) and anomaly scores before issuing easy puzzles.",
        "Provide a verifier-side cache of recent valid solutions and rate limits to resist replay or bursty solves; integrate with queueing policies that prioritize recently validated clients."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Designing effective policies (context selection, weights, and score-to-difficulty mapping) requires expertise.",
        "Potential identifier spoofing and probing by adversaries to obtain easier puzzles.",
        "Risk of penalizing legitimate users with low-resource devices when using CPU-bound puzzles; hardware heterogeneity.",
        "Need for clean, representative training logs; vulnerability to data drift and poisoning if not carefully curated.",
        "Operational overhead to maintain/age models and retrain with updated logs."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces CAPoW, a context-aware AI-assisted PoW framework that adaptively injects latency so malicious users incur higher latency than legitimate users based on contextual deviation.",
      "Proposes a policy component to encode server-specific security requirements, including context weighting and mapping of context scores to PoW difficulty and puzzle variants.",
      "Implements and evaluates a CAPoW instance (context extractor, AI models DAbR/TAM/FLOW, policy designs, and hash-based PoW), with code released and evaluation on CIC-IDS2017 demonstrating adaptive latency injection."
    ]
  },
  {
    "arxiv_id": "2301.13577v2",
    "title": "DRAINCLoG: Detecting Rogue Accounts with Illegally-obtained NFTs using Classifiers Learned on Graphs",
    "authors": "Hanna Kim; Jian Cui; Eugene Jang; Chanhee Lee; Yongjae Lee; Jin-Woo Chung; Seungwon Shin",
    "abstract": "As Non-Fungible Tokens (NFTs) continue to grow in popularity, NFT users have become targets of phishing attacks by cybercriminals, called \\textit{NFT drainers}. Over the last year, \\$100 million worth of NFTs were stolen by drainers, and their presence remains a serious threat to the NFT trading space. However, no work has yet comprehensively investigated the behaviors of drainers in the NFT ecosystem.   In this paper, we present the first study on the trading behavior of NFT drainers and introduce the first dedicated NFT drainer detection system. We collect 127M NFT transaction data from the Ethereum blockchain and 1,135 drainer accounts from five sources for the year 2022. We find that drainers exhibit significantly different transactional and social contexts from those of regular users. With these insights, we design \\textit{DRAINCLoG}, an automatic drainer detection system utilizing Graph Neural Networks. This system effectively captures the multifaceted web of interactions within the NFT space through two distinct graphs: the NFT-User graph for transaction contexts and the User graph for social contexts. Evaluations using real-world NFT transaction data underscore the robustness and precision of our model. Additionally, we analyze the security of \\textit{DRAINCLoG} under a wide variety of evasion attacks.",
    "published_date": "2023-01-31",
    "pdf_link": "https://arxiv.org/pdf/2301.13577v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain/Web3 Security",
      "subdomain": "Fraud and Scam Detection",
      "specific_problem": "Detecting NFT drainer (rogue) accounts on Ethereum via graph-based classification",
      "attack_types": [
        "phishing",
        "account takeover/credential theft",
        "malicious smart contract approval abuse (setApprovalForAll)",
        "NFT draining (unauthorized gift transfers)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Graph Neural Network",
        "specific": null,
        "novel_contribution": "Custom GNNs over two complementary graphs (NFT-User bipartite graph with attributed edges for transaction context, and User graph with multiple edge types for social context), followed by representation fusion for drainer classification"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Ethereum NFT Transactions 2022 (collected by authors)",
        "type": "public",
        "domain": "blockchain_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NFT Drainer Accounts List (1,135 Ethereum addresses, curated from five sources)",
        "type": "public",
        "domain": "ethereum_addresses",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "No prior comprehensive study of NFT drainer behaviors in the NFT ecosystem",
        "Existing cryptocurrency phishing detectors (feature-based, Node2Vec, GNNs) are unsuitable for NFTs due to different transaction semantics and lack of NFT-specific context",
        "Prior work does not capture per-NFT transaction history (price, frequency) and multiple NFT transaction types (mint, sale, gift, burn)",
        "Relationships between NFT users (social context) and transaction type distinctions are not adequately modeled in prior approaches"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Significant rise of NFT phishing/draining with over $100M in losses; existing defenses (marketplace flags, wallet warnings) are insufficient and can be bypassed; need for an automatic, NFT-aware detection system and a measurement study of drainer behavior.",
      "potential_research_ideas": [
        "Extend detection to cross-chain/multi-marketplace settings (e.g., Solana, Polygon) and cross-chain laundering pathways",
        "Temporal GNNs or sequence models to capture fine-grained time dynamics of draining and liquidation behaviors",
        "Active learning or human-in-the-loop pipelines to rapidly incorporate newly reported drainer patterns and addresses",
        "Joint modeling of on-chain behavior with off-chain signals (e.g., phishing site telemetry, social media) for earlier detection",
        "Adversarial training and certified robustness for GNNs against behavior-shaping/evasion strategies by drainers",
        "Explainability methods tailored to graph-based NFT fraud detection to aid analyst triage and incident response",
        "Integrate marketplace policy signals (e.g., stolen item flags) and NFT collection rarity/valuation models into the classifier"
      ],
      "architectural_improvement_recommendations": [
        "Incorporate heterogeneous/relational GNNs with explicit edge-type modeling and attention over transaction types and payment modalities",
        "Fuse temporal encoders (e.g., TGAT/TGN-style) with the current dual-graph architecture to model evolving behavior",
        "Add edge- and path-level features (e.g., shortest paths to known drainer clusters, marketplace intermediaries) and meta-path based attention",
        "Use contrastive pretraining on unlabeled accounts to improve representation quality, followed by supervised fine-tuning",
        "Employ robust training (adversarial perturbations on graphs, randomized smoothing) to improve evasion resistance",
        "Calibrate outputs and attach explanation submodules (e.g., GNNExplainer/PGExplainer) for analyst-facing justifications"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Collected 127M NFT transactions from Ethereum (Jan–Dec 2022) and curated 1,135 NFT drainer accounts from five sources; promise to release drainer accounts publicly",
      "First empirical study of NFT drainer trading behavior; showed distinct transactional and social contexts vs regular users",
      "Designed DRAINCLoG: a GNN-based detection system leveraging two complementary graphs (NFT-User and User) to model transaction and social contexts",
      "Demonstrated strong performance on real-world data and analyzed security/robustness of the model under a variety of evasion attacks"
    ]
  },
  {
    "arxiv_id": "2302.01972v2",
    "title": "DCA: Delayed Charging Attack on the Electric Shared Mobility System",
    "authors": "Shuocheng Guo; Hanlin Chen; Mizanur Rahman; Xinwu Qian",
    "abstract": "An efficient operation of the electric shared mobility system (ESMS) relies heavily on seamless interconnections among shared electric vehicles (SEV), electric vehicle supply equipment (EVSE), and the grid. Nevertheless, this interconnectivity also makes the ESMS vulnerable to cyberattacks that may cause short-term breakdowns or long-term degradation of the ESMS. This study focuses on one such attack with long-lasting effects, the Delayed Charge Attack (DCA), that stealthily delays the charging service by exploiting the physical and communication vulnerabilities. To begin, we present the ESMS threat model by highlighting the assets, information flow, and access points. We next identify a linked sequence of vulnerabilities as a viable attack vector for launching DCA. Then, we detail the implementation of DCA, which can effectively bypass the detection in the SEV's battery management system and the cross-verification in the cloud environment. We test the DCA model against various Anomaly Detection (AD) algorithms by simulating the DCA dynamics in a Susceptible-Infectious-Removed-Susceptible process, where the EVSE can be compromised by the DCA or detected for repair. Using real-world taxi trip data and EVSE locations in New York City, the DCA model allows us to explore the long-term impacts and validate the system consequences. The results show that a 10-min delay results in 12-min longer queuing times and 8% more unfulfilled requests, leading to a 10.7% (\\$311.7) weekly revenue loss per driver. With the AD algorithms, the weekly revenue loss remains at least 3.8% (\\$111.8) with increased repair costs of \\$36,000, suggesting the DCA's robustness against the AD.",
    "published_date": "2023-02-03",
    "pdf_link": "https://arxiv.org/pdf/2302.01972v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Critical Infrastructure Security",
      "subdomain": "EV Charging Infrastructure Security",
      "specific_problem": "False Data Injection via Delayed Charging Attack (DCA) on Electric Shared Mobility Systems causing long-term operational degradation",
      "attack_types": [
        "False Data Injection Attack (FDIA)",
        "Delayed Charging Attack (DCA)",
        "CAN bus spoofing",
        "OCPP patch exploitation",
        "USB-based compromise of EVSE",
        "Man-in-the-Middle (MitM) (discussed)",
        "EV–EVSE interface tampering (discussed)",
        "Distributed Denial of Service (DDoS) (discussed)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Compartmental epidemiological model",
        "specific": "SIRS",
        "novel_contribution": "Models DCA dynamics and EVSE states (susceptible–infectious–removed–susceptible) to capture compromise, detection, and repair over time"
      },
      {
        "type": "baseline",
        "category": "Unsupervised anomaly detection",
        "specific": "Isolation Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Clustering",
        "specific": "K-Means",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Probabilistic mixture model",
        "specific": "Gaussian Mixture Model (EM)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "PCA-based anomaly detection",
        "specific": "Principal Component Classifier (PCC)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Statistical divergence-based detector",
        "specific": "Kullback-Leibler Divergence (KLD)-based detection",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "New York City taxi trip data",
        "type": "public",
        "domain": "mobility_trips",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "New York City EVSE (DC fast charging) locations",
        "type": "public",
        "domain": "charging_station_locations",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Isolation Forest (AD)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "K-Means clustering (AD)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Gaussian Mixture Model with EM (AD)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Principal Component Classifier (AD)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Kullback-Leibler Divergence-based detector",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Aggregate AD vs no-AD comparison",
        "paper_reference": null,
        "metric": "Weekly revenue loss per driver; repair cost; queuing time; unfulfilled requests",
        "their_result": "No AD: 10.7% ($311.7) weekly revenue loss per driver; 12-min longer queuing; 8% more unfulfilled requests (with 10-min injected delay)",
        "baseline_result": "With AD: weekly revenue loss remains at least 3.8% ($111.8) with increased repair costs of $36,000"
      }
    ],
    "performance_metrics_used": [
      "Queuing time (minutes)",
      "Unfulfilled requests (%)",
      "Weekly revenue loss per driver (%) and ($)",
      "Repair cost ($)",
      "Charging duration (minutes)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What are the viable attack vectors and threat model for ESMS enabling a Delayed Charging Attack (DCA)?",
        "How effective and stealthy is DCA in degrading ESMS performance over the long term?",
        "How robust is DCA when confronted with a variety of anomaly detection (AD) algorithms?",
        "What are the system-level consequences of DCA under realistic city-scale demand and EVSE deployment?"
      ],
      "gaps_identified": [
        "No prior studies have investigated DCA on large-scale ESMS.",
        "DCA-like anomalies are hard to detect due to high natural variability in charging duration (ranging from minutes to 1–2 hours).",
        "Existing attacks often focus on one-time breakdowns or privacy, not long-term operational degradation of ESMS."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "ESMS depends on tightly coupled SEV–EVSE–grid interactions; this interconnectivity creates attack surfaces where stealthy manipulation of charging can yield long-term operational degradation that is difficult to detect.",
      "potential_research_ideas": [
        "Design physics-informed, session-level anomaly detectors that explicitly model CC–CV charging dynamics and battery thermal constraints to detect falsified SoC streams.",
        "Develop secure cross-verification using independent metering/sensors (e.g., EV-side current sensing plus EVSE-side metrology) with cryptographic attestation to thwart cloud-level log spoofing.",
        "Create firmware attestation and secure update pipelines for EVSE (e.g., measured boot, signed updates, SBOM-based monitoring) to block OCPP-based patch exploitation.",
        "Investigate vehicle-side BMS consistency checks (e.g., model-based SoC estimation vs. EVSE-reported values) and sensor fusion to flag rate-limiting inconsistencies.",
        "Model repair-resource allocation as an optimization/game against SIRS-modeled spread to minimize revenue loss and repair cost under budget.",
        "Graph-based, spatio-temporal outbreak detection over the EVSE network to localize compromised clusters and prioritize patching.",
        "Evaluate and harden against adaptive attackers that optimize delay patterns to evade specific AD thresholds (e.g., reinforcement learning adversaries).",
        "Prototype a hardware-in-the-loop testbed combining EVSE controller, PLC/CAN gateways, and BMS emulator for empirical validation."
      ],
      "architectural_improvement_recommendations": [
        "Enforce mutual authentication and message signing between EVSE and SEV (e.g., ISO 15118 certificate-based security) for SoC and charging control exchanges.",
        "Add EV-side model-based SoC estimators with plausibility checks against EVSE-reported parameters to prevent acceptance of reduced charging rates without justification.",
        "Implement secure boot, runtime attestation, and signed OTA updates for EVSE; disable/guard USB maintenance ports with access control and logging.",
        "Deploy multi-view AD combining EVSE telemetry, EV telemetry, and CSMS logs; use robust statistics or physics-informed autoencoders to reduce false positives.",
        "Introduce rate-limiting and anomaly scoring on charging session progression (e.g., expected Ah/min given temperature and initial SoC) to detect subtle slowdowns.",
        "Use spatio-temporal outbreak detection and optimized patch scheduling (considering MTTR) to contain spread in SIRS dynamics.",
        "Maintain immutable audit logs (e.g., hash-chained records) for charging sessions to prevent cloud-level log manipulation."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "City-scale Electric Shared Mobility System (NYC context, simulation-based study)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Distinguishing DCA-induced delays from natural variability in charging duration creates detection challenges and potential false positives.",
        "High repair costs and MTTR impact when responding to detected anomalies.",
        "Potential bypass of cloud cross-verification via constant charging logs.",
        "Physical security of maintenance interfaces (USB) and securing OTA update channels (OCPP)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Presented an ESMS threat model with assets, information flows, trust boundaries, and access points.",
      "Identified a linked sequence of vulnerabilities forming a viable attack vector for launching a Delayed Charging Attack (DCA).",
      "Developed a novel DCA model that stealthily delays charging while bypassing BMS monitoring and cloud cross-verification.",
      "Formulated DCA dynamics with a SIRS process and evaluated robustness against multiple anomaly detection techniques.",
      "Built a high-fidelity simulation platform using real-world NYC taxi trips and EVSE locations to assess long-term impacts.",
      "Reported quantitative impacts: 10-min injected delay leads to +12 min queuing, +8% unfulfilled requests, and 10.7% ($311.7) weekly revenue loss per driver; with AD, losses remain at least 3.8% ($111.8) and $36,000 repair costs."
    ]
  },
  {
    "arxiv_id": "2302.08885v1",
    "title": "Towards Zero-trust Security for the Metaverse",
    "authors": "Ruizhi Cheng; Songqing Chen; Bo Han",
    "abstract": "By focusing on immersive interaction among users, the burgeoning Metaverse can be viewed as a natural extension of existing social media. Similar to traditional online social networks, there are numerous security and privacy issues in the Metaverse (e.g., attacks on user authentication and impersonation). In this paper, we develop a holistic research agenda for zero-trust user authentication in social virtual reality (VR), an early prototype of the Metaverse. Our proposed research includes four concrete steps: investigating biometrics-based authentication that is suitable for continuously authenticating VR users, leveraging federated learning (FL) for protecting user privacy in biometric data, improving the accuracy of continuous VR authentication with multimodal data, and boosting the usability of zero-trust security with adaptive VR authentication. Our preliminary study demonstrates that conventional FL algorithms are not well suited for biometrics-based authentication of VR users, leading to an accuracy of less than 10%. We discuss the root cause of this problem, the associated open challenges, and several future directions for realizing our research vision.",
    "published_date": "2023-02-17",
    "pdf_link": "https://arxiv.org/pdf/2302.08885v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Identity and Access Management",
      "subdomain": "User Authentication",
      "specific_problem": "Zero-trust continuous user authentication in social VR/Metaverse with privacy-preserving biometrics",
      "attack_types": [
        "shoulder surfing",
        "insider attack",
        "human mimicry (replay)",
        "man-in-the-middle (MitM)",
        "data poisoning"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "FedAvg (analyzed)",
        "novel_contribution": "Identifies fundamental limitation of standard FL (clients hold only positive-label data) for biometrics-based VR authentication; proposes research directions to address it"
      },
      {
        "type": "primary",
        "category": "RNN / Variational Autoencoder",
        "specific": "VRNN (Variational Recurrent Neural Network)",
        "novel_contribution": "Proposed to leverage time-series nature of biometrics to avoid embedding collapse and improve FL-based authentication"
      },
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "Personalized FL",
        "novel_contribution": "Proposed personalized models with user-specific modality combinations to boost accuracy and robustness"
      },
      {
        "type": "primary",
        "category": "Multimodal Learning",
        "specific": null,
        "novel_contribution": "Design of multimodal biometric fusion (pupil size, head/body motion, voice, gaze) with density-based within-client modality selection"
      },
      {
        "type": "primary",
        "category": "Active/Adaptive Learning",
        "specific": null,
        "novel_contribution": "Adaptive/dynamic authentication frequency and adaptive client selection for FL to balance reliability, usability, and resource usage"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "FCN (Fully Convolutional Network)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet (shallow, 3 conv layers)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Siamese Network",
        "specific": "Siamese CNN (metric learning)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Federated Learning",
        "specific": "FedAvg + FCN",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Federated Learning"
    ],
    "datasets": [
      {
        "name": "Miller et al. VR ball-throwing trajectories dataset",
        "type": "public",
        "domain": "vr_motion_trajectories",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Siamese Network (centralized, non-privacy-preserving)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "6.34% (FedAvg+FCN, privacy-preserving)",
        "baseline_result": "90.2%"
      },
      {
        "method_name": "FCN (centralized, non-privacy-preserving)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "6.34% (FedAvg+FCN, privacy-preserving)",
        "baseline_result": "89.3%"
      },
      {
        "method_name": "ResNet (centralized, non-privacy-preserving)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "6.34% (FedAvg+FCN, privacy-preserving)",
        "baseline_result": "87.2%"
      }
    ],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Which biometric modalities are most suitable for continuous, non-intrusive VR authentication under zero-trust?",
        "How can FL be leveraged for biometrics when each client holds only positive-label data without sharing raw data?",
        "Can multimodal and personalized models significantly improve continuous VR authentication accuracy and robustness (e.g., against mimicry, MitM)?",
        "How to design adaptive authentication and adaptive client selection to balance reliability, usability, and resource constraints on HMDs?",
        "What are the root causes of FL failures (e.g., embedding collapse) in this setting and how to mitigate them?"
      ],
      "gaps_identified": [
        "Existing VR authentication often uses a single modality leading to limited accuracy (~90%) and availability gaps",
        "Biometric data collection raises severe privacy concerns if centralized",
        "Many methods are intrusive (e.g., ball-throwing) and unsuitable for continuous authentication",
        "Practical constraints on HMDs (battery, compute) are not addressed in prior works",
        "Standard FL (e.g., FedAvg) fails when clients have only positive-label data; embeddings collapse and accuracy degrades with more users",
        "Naive event-based continuous auth (authenticate only when headset is put on) is unreliable and vulnerable to MitM",
        "Heterogeneous clients/resources in FL are not handled by uniform selection policies"
      ],
      "limitations": [
        "Preliminary proof-of-concept only; full MetaGuard not implemented",
        "Evaluation uses an intrusive dataset (ball-throwing) not ideal for continuous authentication",
        "Only one public dataset and limited modalities evaluated",
        "Privacy-preserving FL approach (FedAvg+FCN) achieves very low accuracy (~6.34%), demonstrating current limitations",
        "No real-world deployment or user study yet; planned large-scale study and dataset are future work"
      ],
      "future_work": [
        "Systematically benchmark multiple biometric modalities for continuous VR auth; conduct large-scale user study",
        "Create an open, diverse, comprehensive dataset for MetaGuard design and evaluation",
        "Design FL methods robust to positive-only local data (e.g., sequence models, contextual info)",
        "Multimodal fusion with personalized modality selection per user",
        "Adaptive/dynamic authentication and resource-aware client selection in FL",
        "Defenses against MitM and data poisoning in FL-based VR authentication"
      ],
      "motivation": "Metaverse/social VR will face numerous security/privacy threats; zero-trust requires continuous, non-intrusive, reliable, and privacy-preserving authentication mechanisms.",
      "potential_research_ideas": [
        "Federated contrastive/metric learning with privacy-preserving negative sampling (e.g., prototype sharing via secure aggregation) to overcome positive-only local data",
        "Self-supervised pretraining on VR motion/gaze signals to improve representation quality before supervised FL",
        "Risk-based adaptive authentication that modulates sampling/inference frequency based on anomaly scores and context",
        "Robust FL against poisoning/MitM via robust aggregation, client attestation (TEE), and update auditing",
        "Differential privacy and secure aggregation tailored for multimodal biometrics to bound leakage",
        "Liveness detection and anti-mimicry signals (micro-saccades, fine-grained head jitter) integrated into multimodal models",
        "Continual/personalized learning for drift in biometrics (voice changes, behavior shifts) with low overhead on HMDs",
        "Edge-assisted split/federated learning hybrids to reduce HMD compute while preserving privacy",
        "Creation of a realistic continuous-auth VR dataset with diverse activities, contexts, and sensors (gaze, IMU, controllers)"
      ],
      "architectural_improvement_recommendations": [
        "Use sequence models (VRNN/TCN/Transformer encoders) with triplet or prototypical losses; share class prototypes via secure aggregation to avoid embedding collapse",
        "Personalization layers (FedPer/FedRep/FedBN) plus modality-gating networks for user-specific fusion",
        "Multimodal attention fusion with reliability-aware gating; density-based modality selection implemented as a learnable sparsity mechanism",
        "Robust/regularized FL (FedProx, adaptive weighting, Byzantine-robust aggregators) to handle heterogeneity and poisoning",
        "Adaptive client selection using resource and data utility estimates; reinforcement learning for scheduling auth frequency",
        "On-device efficiency: quantization/pruning and knowledge distillation for real-time continuous inference",
        "OOD/anomaly detection heads to trigger step-up authentication under uncertainty"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Social VR on HMDs (e.g., Oculus Quest)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Computation and energy constraints on HMDs for continuous sensing, fusion, and FL training",
        "Maintaining usability with non-intrusive continuous auth",
        "Heterogeneous devices/data in FL; cannot drop clients as everyone must be authenticated",
        "Vulnerability to MitM and data poisoning during FL if not hardened",
        "Naive reliance on headset sensors can be bypassed/disabled",
        "Multimodal noise and modality unavailability during free-form interactions"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes MetaGuard: a privacy-preserving, continuous, adaptive zero-trust authentication framework for social VR",
      "Defines threat models for VR authentication (shoulder surfing, insider, mimicry, MitM, poisoning)",
      "Holistic research agenda: biometrics benchmarking, FL for privacy, personalized multimodal fusion, adaptive authentication",
      "Identifies core limitation of conventional FL (positive-only client data) causing poor accuracy (<10%) and analyzes root cause (embedding collapse)",
      "Preliminary empirical study on a public VR biometrics dataset showing FedAvg+FCN accuracy 6.34% vs centralized models ~87–90%",
      "Outlines concrete technical directions: VRNN-based temporal modeling, density-based modality selection, personalized FL, adaptive client selection"
    ]
  },
  {
    "arxiv_id": "2302.02013v4",
    "title": "IoT Botnet Detection Using an Economic Deep Learning Model",
    "authors": "Nelly Elsayed; Zag ElSayed; Magdy Bayoumi",
    "abstract": "The rapid progress in technology innovation usage and distribution has increased in the last decade. The rapid growth of the Internet of Things (IoT) systems worldwide has increased network security challenges created by malicious third parties. Thus, reliable intrusion detection and network forensics systems that consider security concerns and IoT systems limitations are essential to protect such systems. IoT botnet attacks are one of the significant threats to enterprises and individuals. Thus, this paper proposed an economic deep learning-based model for detecting IoT botnet attacks along with different types of attacks. The proposed model achieved higher accuracy than the state-of-the-art detection models using a smaller implementation budget and accelerating the training and detecting processes.",
    "published_date": "2023-02-03",
    "pdf_link": "https://arxiv.org/pdf/2302.02013v4",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "IoT botnet detection with attack category and subcategory classification",
      "attack_types": [
        "DDoS TCP",
        "DDoS UDP",
        "DoS HTTP",
        "OS fingerprinting",
        "Data exfiltration"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN",
        "specific": "GRU",
        "novel_contribution": "Lightweight GRU branch concatenated with a 1D CNN branch for temporal-spatial feature learning with very low parameter count (total 4,370 parameters) for green AI constraints"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D Conv + Global pooling",
        "novel_contribution": "Compact 1D Conv feature extractor with global pooling to minimize parameters while maintaining accuracy"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "UNSW 2018 IoT Botnet Dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "F1-Score",
      "Precision",
      "Recall",
      "Specificity",
      "Cohen's Kappa",
      "Hamming Loss",
      "ROC AUC",
      "Youden index",
      "Adjusted F-score",
      "Adjusted geometric mean",
      "Error rate",
      "Distance index",
      "Similarity index",
      "95% Confidence Interval",
      "Training time",
      "Number of parameters"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a lightweight deep learning model (economic implementation budget) detect IoT botnet attacks with accuracy comparable to or better than state-of-the-art models?",
        "Can combining GRU (temporal) and 1D CNN (spatial) features yield high performance under resource constraints for green AI on IoT settings?",
        "Can the model classify both attack category and subcategory on a realistic IoT botnet dataset?"
      ],
      "gaps_identified": [
        "IoT devices have stringent hardware/software resource limitations that many existing detection models do not account for.",
        "Need for green AI approaches that reduce power/compute while maintaining detection performance.",
        "Lack of IoT-focused security tools despite rapid proliferation of IoT systems."
      ],
      "limitations": [
        "Severe per-class performance issue for Data ex-filtration (Class 5): F1-Score 0.0; True Positive 0; AUCI marked 'Poor'.",
        "Class imbalance reflected in per-class metrics (e.g., low F1 and AUC for certain minority attack classes such as Class 2 and Class 5).",
        "Evaluation performed on a single dataset; cross-dataset generalization not reported.",
        "No analysis of explainability, adversarial robustness, or privacy impacts."
      ],
      "future_work": [],
      "motivation": "Design an economic, green-AI deep learning model for IoT botnet detection that reduces implementation budget (~75–79% fewer parameters) and accelerates training/inference while improving accuracy over state-of-the-art.",
      "potential_research_ideas": [
        "Develop class-imbalance mitigation strategies (cost-sensitive learning, focal loss, data augmentation) to improve detection of rare attack types (e.g., Data exfiltration).",
        "Cross-dataset and cross-domain generalization studies (train on UNSW IoT 2018, test on other IoT botnet datasets) to assess robustness and transferability.",
        "Integrate explainability (e.g., saliency for features/flows, attention-based explanations) to support network forensics.",
        "Adversarial robustness evaluation and defenses for IoT traffic classifiers (e.g., adversarial training, randomized smoothing).",
        "Online/streaming adaptation with concept drift detection for evolving IoT botnets.",
        "Multi-task learning to jointly detect botnet presence, attack type, and device type or family.",
        "Knowledge distillation and quantization-aware training to deploy ultra-lightweight models at the edge.",
        "Evaluate privacy-preserving learning (federated or split learning) for multi-organization IoT deployments."
      ],
      "architectural_improvement_recommendations": [
        "Address class imbalance with focal/cost-sensitive loss and calibrated decision thresholds per class.",
        "Add attention or temporal convolution (TCN) modules to enhance temporal feature modeling without large parameter growth.",
        "Resolve pooling inconsistency and adopt true GlobalAveragePooling1D (as described) or use both GAP and GMP with channel-wise attention.",
        "Apply knowledge distillation from a larger teacher to the current compact student to improve minority class recall.",
        "Perform model pruning and integer quantization for edge deployment while monitoring accuracy on minority classes.",
        "Incorporate uncertainty estimation (e.g., MC dropout) for selective routing of low-confidence flows to heavier backends.",
        "Add explainability components (e.g., feature attribution on flow features) to aid analysts."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "TensorFlow",
        "Keras",
        "NumPy"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Implemented on Google Colab; trained 4 epochs with batch size 10; reported train time 25.21 minutes; total parameters 4,370 (4,114 trainable)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Resource and power constraints of IoT devices and edge gateways.",
        "Need for fast training and detection for monitoring IoT network traffic.",
        "Class imbalance affecting reliability for rare attack classes."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "An IoT botnet detection system that can classify the botnet attack category and subcategory using deep learning.",
      "Model reduces the implementation budget by approximately 76–79% compared to state-of-the-art while increasing detection performance, requiring less training time and power for green AI."
    ]
  },
  {
    "arxiv_id": "2301.01261v1",
    "title": "Automated Black-box Testing of Mass Assignment Vulnerabilities in RESTful APIs",
    "authors": "Davide Corradini; Michele Pasqua; Mariano Ceccato",
    "abstract": "Mass assignment is one of the most prominent vulnerabilities in RESTful APIs. This vulnerability originates from a misconfiguration in common web frameworks, such that naming convention and automatic binding can be exploited by an attacker to craft malicious requests writing confidential resources and (massively) overriding data, that should be read-only and/or confidential. In this paper, we adopt a black-box testing perspective to automatically detect mass assignment vulnerabilities in RESTful APIs. Execution scenarios are generated purely based on the OpenAPI specification, that lists the available operations and their message format. Clustering is used to group similar operations and reveal read-only fields, the latter are candidate for mass assignment. Then, interaction sequences are automatically generated by instantiating abstract testing templates, trying to exploit the potential vulnerabilities. Finally, test cases are run, and their execution is assessed by a specific oracle, in order to reveal whether the vulnerability could be successfully exploited. The proposed novel approach has been implemented and evaluated on a set of case studies written in different programming languages. The evaluation highlights that the approach is quite effective in detecting seeded vulnerabilities, with a remarkably high accuracy.",
    "published_date": "2023-01-03",
    "pdf_link": "https://arxiv.org/pdf/2301.01261v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Web and API Security",
      "subdomain": "API Security Testing",
      "specific_problem": "Automated black-box detection of mass assignment vulnerabilities in RESTful APIs",
      "attack_types": [
        "Mass assignment",
        "Auto-binding vulnerability",
        "Object injection (mass assignment)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "Expectation-Maximization (EM) clustering",
        "novel_contribution": "Used to group API operations by similar input/output fields extracted from OpenAPI to infer shared resource types and reveal read-only fields."
      },
      {
        "type": "primary",
        "category": "Heuristic/Rule-based",
        "specific": null,
        "novel_contribution": "Heuristics to infer CRUD semantics from HTTP methods and detect resource identifiers (fields ending with id or name), plus read-only field detection by set differences between read vs. write schemas."
      },
      {
        "type": "primary",
        "category": "NLP preprocessing",
        "specific": "Porter stemming",
        "novel_contribution": "Applied to normalize parameter names before clustering operations."
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Heuristic/Rule-based"
    ],
    "datasets": [
      {
        "name": "VAmPI",
        "type": "public",
        "domain": "web_api",
        "link": "https://github.com/erev0s/VAmPI",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "False positives (none reported)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can mass assignment vulnerabilities in REST APIs be automatically detected from only the OpenAPI specification and black-box HTTP interaction?",
        "How accurate and effective is an OpenAPI-driven, clustering- and template-based black-box testing approach across APIs implemented in different languages/frameworks?"
      ],
      "gaps_identified": [
        "No automated black-box approach for detecting mass assignment vulnerabilities in REST APIs was previously available.",
        "Existing OWASP guidelines are manual and do not specify how to automate mass assignment detection from a black-box perspective."
      ],
      "limitations": [
        "The inference of CRUD semantics, resource types, and resource identifiers from OpenAPI and naming conventions may be imprecise (authors note potential imprecision).",
        "Evaluation uses seeded vulnerabilities rather than exclusively real-world zero-day cases.",
        "Approach requires availability of an OpenAPI specification and black-box HTTP access.",
        "Clustering-based grouping may misclassify operations when schemas are sparse or names are inconsistent."
      ],
      "future_work": [],
      "motivation": "Mass assignment remains a prevalent API vulnerability due to default framework auto-binding; there is a need for automated, black-box testing that works across languages and frameworks using only OpenAPI and HTTP access.",
      "potential_research_ideas": [
        "Extend the approach to other API-specific vulnerabilities (e.g., IDOR, BOLA, improper authorization) using similar OpenAPI-driven templates.",
        "Incorporate semantic similarity of fields using pretrained embeddings to improve clustering beyond name-based features.",
        "Develop dynamic oracle enhancements that snapshot and diff backend states (e.g., via instrumented test deployments) to reduce reliance on response fields alone.",
        "Leverage LLMs to infer read-only semantics from textual docs/descriptions/comments in OpenAPI and repository READMEs.",
        "Automate active learning over multiple runs to refine suspected read-only fields and resource-ids based on observed behavior.",
        "Generalize beyond OpenAPI by automatically inferring schemas from traffic captures and applying the same pipeline."
      ],
      "architectural_improvement_recommendations": [
        "Replace or complement EM clustering with embedding-based similarity (e.g., Sentence-BERT on field names/descriptions) and graph clustering over operation–field bipartite graphs.",
        "Augment heuristic resource-id detection with supervised ranking models trained on labeled APIs and additional cues (path templates, parameter location).",
        "Integrate static analysis hooks (when available) to cross-check inferred read-only fields against ORM/entity annotations for hybrid grey-box testing.",
        "Enhance the oracle by validating side effects via database/container snapshots in a controlled testbed and by correlating with logs.",
        "Introduce schema-aware fuzzing around injected fields (types, constraints) to bypass simple input validation and cover more corner cases."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Black-box HTTP access to target APIs and their OpenAPI specs; lightweight clustering and request execution; no specialized hardware required."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Requires accurate and complete OpenAPI specifications; incomplete docs may reduce effectiveness.",
        "Heuristics for CRUD and resource-id inference can misclassify operations, impacting test generation.",
        "Potential need for test data management and cleanup if delete operations are unavailable.",
        "Variability across frameworks and naming conventions may hinder generalization without additional normalization."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A novel automated black-box testing approach for mass assignment vulnerabilities in REST APIs using only the OpenAPI specification and HTTP access.",
      "Clustering-based grouping of operations to infer shared resource types and identify candidate read-only fields for mass assignment attacks.",
      "Template-driven generation of interaction sequences (create-/update-injection) and a security oracle to confirm successful exploitation.",
      "An annotation scheme (custom OpenAPI extensions) to record inferred CRUD semantics, resource types, and resource identifiers.",
      "Implementation evaluated on multiple case studies across languages with high accuracy and no false positives reported for seeded vulnerabilities."
    ]
  },
  {
    "arxiv_id": "2303.12812v1",
    "title": "A Comparison of Graph Neural Networks for Malware Classification",
    "authors": "Vrinda Malhotra; Katerina Potika; Mark Stamp",
    "abstract": "Managing the threat posed by malware requires accurate detection and classification techniques. Traditional detection strategies, such as signature scanning, rely on manual analysis of malware to extract relevant features, which is labor intensive and requires expert knowledge. Function call graphs consist of a set of program functions and their inter-procedural calls, providing a rich source of information that can be leveraged to classify malware without the labor intensive feature extraction step of traditional techniques. In this research, we treat malware classification as a graph classification problem. Based on Local Degree Profile features, we train a wide range of Graph Neural Network (GNN) architectures to generate embeddings which we then classify. We find that our best GNN models outperform previous comparable research involving the well-known MalNet-Tiny Android malware dataset. In addition, our GNN models do not suffer from the overfitting issues that commonly afflict non-GNN techniques, although GNN models require longer training times.",
    "published_date": "2023-03-22",
    "pdf_link": "https://arxiv.org/pdf/2303.12812v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Mobile Malware Classification (Android)",
      "specific_problem": "Android malware family classification from function call graphs (graph classification)",
      "attack_types": [
        "Android malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN - GCN",
        "specific": "Graph Convolutional Network (GCN)",
        "novel_contribution": "Applied with Local Degree Profile (LDP) node features for Android FCG graph classification; part of a comprehensive comparative study across GNNs on MalNet-Tiny."
      },
      {
        "type": "primary",
        "category": "GNN - GraphSAGE",
        "specific": "GraphSAGE (mean aggregator)",
        "novel_contribution": "Inductive GNN with LDP node features; uses PyTorch mean aggregator; evaluated for Android FCG classification."
      },
      {
        "type": "primary",
        "category": "GNN - GIN",
        "specific": "Graph Isomorphism Network (GIN)",
        "novel_contribution": "Evaluated with LDP features for FCG-based malware family classification; compared to prior GIN results on MalNet-Tiny."
      },
      {
        "type": "primary",
        "category": "GNN - Simplified GCN",
        "specific": "Simple Graph Convolution (SGC)",
        "novel_contribution": "Assessed as a lighter-weight alternative to GCN with LDP features for malware graph classification."
      },
      {
        "type": "primary",
        "category": "GNN - JK",
        "specific": "Jumping Knowledge (JK) over GNN layers",
        "novel_contribution": "Used to mitigate over-smoothing by aggregating intermediate node representations; evaluated on Android FCGs."
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "Multi-Layer Perceptron",
        "novel_contribution": "Baseline trained directly on LDP features."
      },
      {
        "type": "baseline",
        "category": "Graph Kernel",
        "specific": "Weisfeiler-Lehman Subtree Kernel (WL-Kernel) via GraKel",
        "novel_contribution": "Baseline graph kernel method for graph comparison/classification."
      },
      {
        "type": "baseline",
        "category": "Graph Embedding + Random Forest",
        "specific": "FEATHER",
        "novel_contribution": "Baseline that builds node embeddings via random-walk-weighted characteristic functions; Random Forest as classifier."
      },
      {
        "type": "baseline",
        "category": "Spectral Distance / Entropy",
        "specific": "Slaq-VNGE (Von Neumann Graph Entropy approximation)",
        "novel_contribution": "Baseline distance-based graph comparison approach."
      },
      {
        "type": "baseline",
        "category": "Spectral Distance",
        "specific": "Slaq-LSD (NetLSD approximation via heat kernel)",
        "novel_contribution": "Baseline spectral distance-based graph comparison approach."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "MalNet-Tiny",
        "type": "",
        "domain": "function_call_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "MalNet",
        "type": "",
        "domain": "function_call_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "AndroZoo",
        "type": "",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Android Malware Dataset (AMD)",
        "type": "",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Android Malware Genome (AMG)",
        "type": "",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Drebin",
        "type": "",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Andro-dumpsys",
        "type": "",
        "domain": "images",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "MMC",
        "type": "",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Comodo Cloud",
        "type": "",
        "domain": "api_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [
      {
        "method_name": "GIN on MalNet-Tiny (Freitas and Dong [12])",
        "paper_reference": "[12]",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": "0.9000"
      },
      {
        "method_name": "JK-GNN on MalNet-Tiny (Lo et al. [29])",
        "paper_reference": "[29]",
        "metric": "Accuracy",
        "their_result": null,
        "baseline_result": "0.9440"
      },
      {
        "method_name": "MLP (on LDP features)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Weisfeiler-Lehman Subtree Kernel (WL-Kernel) via GraKel",
        "paper_reference": "[22]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "FEATHER + Random Forest",
        "paper_reference": "[38]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Slaq-VNGE (VNGE approximation)",
        "paper_reference": "[41]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Slaq-LSD (NetLSD approximation)",
        "paper_reference": "[40]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can malware family classification be effectively treated as a graph classification problem using Android function call graphs (FCGs)?",
        "Do GNN architectures with Local Degree Profile (LDP) node features outperform non-GNN methods and prior comparable work on MalNet-Tiny?",
        "Do inductive GNNs mitigate overfitting relative to non-GNN techniques on Android malware graphs?",
        "What are the computational trade-offs (e.g., training time) of GNNs versus non-GNN methods for this task?"
      ],
      "gaps_identified": [
        "Traditional static methods rely on handcrafted/manual feature extraction that is labor intensive and requires expert knowledge.",
        "Non-GNN ML approaches often fail to model function-call interactions; graphs naturally capture such dependencies.",
        "Dynamic analysis is more resource/time intensive; desire to rely on static code-derived graphs.",
        "Many prior graph-based methods are transductive and may not generalize to zero-day malware; need inductive models.",
        "Opcode-based features/graphs can be brittle to obfuscation; FCGs provide richer behavioral structure."
      ],
      "limitations": [
        "GNN models require longer training times (as stated in abstract).",
        "Experiments focus on a single dataset (MalNet-Tiny) and a single node feature design (LDP)."
      ],
      "future_work": [],
      "motivation": "Explore graph-based learning using function call graphs to avoid manual feature engineering and better model interactions for Android malware classification, with emphasis on inductive methods that could generalize to zero-day malware.",
      "potential_research_ideas": [
        "Evaluate inductive generalization to true zero-day settings via temporal splits or family-holdout protocols on MalNet/MalNet-Tiny.",
        "Augment LDP with richer node/edge attributes (e.g., API categories, permissions, call frequencies, edge direction types) and assess gains.",
        "Incorporate hierarchical graph pooling (e.g., DiffPool, SAGPool) to capture program modularity and improve graph-level embeddings.",
        "Leverage pretraining/self-supervised objectives on AndroZoo FCGs (e.g., graph contrastive learning) before supervised fine-tuning on MalNet-Tiny.",
        "Combine static FCGs with lightweight dynamic cues (e.g., system call summaries) in a multimodal GNN.",
        "Investigate graph transformer or attention-based GNNs (e.g., GAT) for better long-range dependency modeling.",
        "Conduct robustness evaluations against code obfuscation/graph perturbations to assess reliability."
      ],
      "architectural_improvement_recommendations": [
        "Add attention mechanisms (GAT, Graph Transformers) on top of LDP features to weight informative neighborhoods.",
        "Use Jumping Knowledge with gated/attention-based layer aggregation and residual connections to mitigate over-smoothing.",
        "Incorporate hierarchical pooling and readout functions (e.g., Set2Set, attention readouts) for improved graph-level embeddings.",
        "Embed edge features (call type, frequency, direction) and use edge-aware GNN layers.",
        "Adopt self-supervised pretraining (graph contrastive or masked node/edge prediction) on large AndroZoo-derived graphs.",
        "Experiment with richer positional/structural encodings (e.g., Laplacian eigenvectors, shortest-path distances) alongside LDP."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PyTorch"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Not specified; authors note GNN models require longer training times than non-GNN baselines."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "GNN models require longer training times compared to non-GNN methods."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Treat Android malware classification as a graph classification problem using function call graphs (FCGs).",
      "Use Local Degree Profile (LDP) node features and train a wide range of GNN architectures; compare to non-GNN baselines.",
      "Report that best GNN models outperform prior comparable results on MalNet-Tiny.",
      "Observe that GNNs avoid overfitting commonly seen in non-GNN techniques, albeit with longer training times."
    ]
  },
  {
    "arxiv_id": "2302.07982v1",
    "title": "Correlation-Aware Neural Networks for DDoS Attack Detection In IoT Systems",
    "authors": "Arvin Hekmati; Nishant Jethwa; Eugenio Grippo; Bhaskar Krishnamachari",
    "abstract": "We present a comprehensive study on applying machine learning to detect distributed Denial of service (DDoS) attacks using large-scale Internet of Things (IoT) systems. While prior works and existing DDoS attacks have largely focused on individual nodes transmitting packets at a high volume, we investigate more sophisticated futuristic attacks that use large numbers of IoT devices and camouflage their attack by having each node transmit at a volume typical of benign traffic. We introduce new correlation-aware architectures that take into account the correlation of traffic across IoT nodes, and we also compare the effectiveness of centralized and distributed detection models. We extensively analyze the proposed architectures by evaluating five different neural network models trained on a dataset derived from a 4060-node real-world IoT system. We observe that long short-term memory (LSTM) and a transformer-based model, in conjunction with the architectures that use correlation information of the IoT nodes, provide higher performance (in terms of F1 score and binary accuracy) than the other models and architectures, especially when the attacker camouflages itself by following benign traffic distribution on each transmitting node. For instance, by using the LSTM model, the distributed correlation-aware architecture gives 81% F1 score for the attacker that camouflages their attack with benign traffic as compared to 35% for the architecture that does not use correlation information. We also investigate the performance of heuristics for selecting a subset of nodes to share their data for correlation-aware architectures to meet resource constraints.",
    "published_date": "2023-02-15",
    "pdf_link": "https://arxiv.org/pdf/2302.07982v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "DDoS Detection",
      "specific_problem": "Detecting camouflaged DDoS attacks in large-scale IoT by leveraging cross-node traffic/activity correlations; comparison of centralized vs distributed detection architectures",
      "attack_types": [
        "DDoS",
        "UDP flood",
        "SYN flood",
        "Slow-rate application-layer DDoS"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": "Used within new correlation-aware architectures (distributed and centralized) that incorporate cross-node traffic correlation features to detect camouflaged DDoS attacks"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": null,
        "novel_contribution": "Applied within correlation-aware architectures to model spatiotemporal correlations across IoT nodes"
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoencoder",
        "specific": "AEN",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Urban IoT Activity Dataset (4060 nodes) [24]",
        "type": "public",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Enhanced IoT Traffic Volume Dataset (derived from 4060-node activity) [25]",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Correlation-aware IoT DDoS training dataset + attack emulation scripts (this paper)",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": "https://github.com/ANRGUSC/correlation aware ddos iot",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "N-BaIoT (Meidan et al. 2018)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICDDoS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICDDoS2019",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CTU-13",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CSE-CIC-IDS2018 on AWS",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Bot-IoT (UNSW)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Ullah et al. 2020 IoT dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Erhan et al. 2020 dataset (4000 general)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "DARPA 2000",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CAIDA UCSD DDoS Attack 2007",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ISCX 2012 (Shiravi et al. 2012)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "No-correlation architecture (e.g., MM-NC) vs correlation-aware (MM-WC) using LSTM",
        "paper_reference": null,
        "metric": "F1 score",
        "their_result": "“the distributed correlation-aware architecture gives 81% F1 score for the attacker that camouflages their attack with benign traffic”",
        "baseline_result": "“as compared to 35% for the architecture that does not use correlation information.”"
      }
    ],
    "performance_metrics_used": [
      "F1 score",
      "binary accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can exploiting cross-node traffic/activity correlations improve detection of camouflaged DDoS attacks in large-scale IoT systems?",
        "How do centralized (one model) and distributed (per-node) detection architectures compare for IoT DDoS detection?",
        "Which neural network families (MLP, CNN, LSTM, Transformer, Autoencoder) perform best under camouflaged attack scenarios?",
        "Can we select a subset of nodes to share data for correlation-aware detection while meeting resource constraints?"
      ],
      "gaps_identified": [
        "Most prior datasets and methods assume attack traffic volume/timing is orders of magnitude different from benign, simplifying detection.",
        "Limited prior comparison of centralized versus distributed detection architectures for IoT DDoS.",
        "Existing works generally ignore cross-node correlation information when designing detection mechanisms.",
        "Existing datasets typically have few IoT nodes and lack inter-node correlation features."
      ],
      "limitations": [
        "Attack traffic is emulated using a truncated Cauchy distribution parameterized by k rather than collected from real camouflaged DDoS attacks.",
        "Packet volume modeling is fit from a single device type (a security camera in N-BaIoT) and extrapolated to all nodes.",
        "Correlation-aware features can be high-dimensional at large scale, necessitating heuristic node selection due to resource constraints.",
        "Evaluation is limited to data derived from one urban deployment (4060 nodes) and specific modeling assumptions (event-driven activity)."
      ],
      "future_work": [],
      "motivation": "The growing scale and vulnerability of IoT enable sophisticated DDoS attacks where each device mimics benign behavior; exploiting inter-node correlations may reveal such camouflaged attacks while addressing deployment constraints.",
      "potential_research_ideas": [
        "Graph-based spatiotemporal modeling (GNNs) over IoT nodes to capture dynamic inter-node correlations for DDoS detection.",
        "Learned node selection via sparse attention or reinforcement learning/bandits to balance performance and resource constraints.",
        "Federated correlation-aware detection with secure aggregation to preserve privacy while sharing only necessary statistics.",
        "Self-supervised pretraining on benign IoT activity to improve generalization to novel camouflaged attacks.",
        "Online/continual learning with drift detection to handle changing benign behaviors and adaptive attackers.",
        "Causality-aware detection to distinguish genuine correlated events from coordinated attacks.",
        "Real traffic validation with controlled camouflaged DDoS testbeds to benchmark correlation-aware detectors."
      ],
      "architectural_improvement_recommendations": [
        "Replace concatenation of selected node features with cross-node attention (spatiotemporal transformer) or message passing (GNN) for scalable correlation modeling.",
        "Impose sparsity (L1/group lasso) or structured attention to automatically select informative peer nodes.",
        "Multi-task learning: jointly predict node-level anomalies and system-level DDoS state to improve supervision.",
        "Augment features with flow-level statistics (e.g., inter-arrival times, port/protocol metadata) where available to complement packet volume.",
        "Use probabilistic calibration and threshold optimization for imbalanced scenarios and to align F1/accuracy trade-offs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/ANRGUSC/correlation aware ddos iot",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High-dimensional correlation features across thousands of nodes increase compute and communication costs",
        "Need to share data or statistics across nodes raises bandwidth and privacy concerns",
        "Resource constraints on IoT devices necessitate selective node/data sharing",
        "Trade-offs between centralized and distributed deployment models"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces correlation-aware detection architectures (centralized and distributed) that leverage inter-node traffic correlations",
      "Comprehensive empirical analysis comparing five neural network models across four architectures for camouflaged DDoS detection",
      "New synthetic dataset generation and attack emulation scripts built on a 4060-node real IoT activity dataset with tunable attack parameter k",
      "Demonstrates that LSTM and transformer with correlation-aware inputs outperform other models and non-correlation baselines (e.g., 81% vs 35% F1)",
      "Proposes and evaluates heuristics (e.g., Pearson correlation-based selection) to choose a subset of nodes for correlation-aware detection under resource constraints",
      "Releases open-source repository with dataset, attack emulation, and training/testing scripts"
    ]
  },
  {
    "arxiv_id": "2301.08403v4",
    "title": "One-shot Generative Distribution Matching for Augmented RF-based UAV Identification",
    "authors": "Amir Kazemi; Salar Basiri; Volodymyr Kindratenko; Srinivasa Salapaka",
    "abstract": "This work addresses the challenge of identifying Unmanned Aerial Vehicles (UAV) using radiofrequency (RF) fingerprinting in limited RF environments. The complexity and variability of RF signals, influenced by environmental interference and hardware imperfections, often render traditional RF-based identification methods ineffective. To address these complications, the study introduces the rigorous use of one-shot generative methods for augmenting transformed RF signals, offering a significant improvement in UAV identification. This approach shows promise in low-data regimes, outperforming deep generative methods like conditional generative adversarial networks (GANs) and variational auto-encoders (VAEs). The paper provides a theoretical guarantee for the effectiveness of one-shot generative models in augmenting limited data, setting a precedent for their application in limited RF environments. This research contributes to learning techniques in low-data regime scenarios, which may include atypical complex sequences beyond images and videos. The code and links to datasets used in this study are available at https://github.com/amir-kazemi/uav-rf-id.",
    "published_date": "2023-01-20",
    "pdf_link": "https://arxiv.org/pdf/2301.08403v4",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Wireless Security",
      "subdomain": "RF Fingerprinting",
      "specific_problem": "RF-based UAV identification in low-data regimes via one-shot generative data augmentation",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Distribution Matching / Optimal Transport (One-shot Generator)",
        "specific": "Generating by Patch Distribution Matching (GPDM)",
        "novel_contribution": "Rigorous use of one-shot GPDM for augmenting DFT-transformed RF sequences; provides theoretical upper bounds (via Wasserstein distance) on distributional closeness between real and generated sequences based on subsequence similarity."
      },
      {
        "type": "baseline",
        "category": "GAN",
        "specific": "Conditional GAN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "VAE",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "DroneRF (UAV RF dataset)",
        "type": "public",
        "domain": "rf_signals",
        "link": "https://github.com/Al-Sad/DroneRF",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Conditional GAN",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Variational Autoencoder (VAE)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can one-shot generative models effectively augment DFT-transformed RF signals to improve UAV identification in low-data regimes?",
        "What theoretical guarantees can bound the distributional distance between real and one-shot-generated sequences using subsequence (patch) similarity and Wasserstein distance?",
        "Do one-shot generative methods outperform conditional GANs and VAEs for RF-based UAV identification when training data are scarce?"
      ],
      "gaps_identified": [
        "Deep generative models (GANs/VAEs) require large amounts of data, which is unsuitable for limited RF environments.",
        "Existing data augmentation techniques are predominantly developed for computer vision and do not transfer cleanly to complex RF/time-series sequences.",
        "Lack of theoretical guarantees for one-shot generative augmentation on sequences relevant to RF fingerprinting."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Address UAV identification under limited RF data by theoretically grounded one-shot generative augmentation that can work with complex non-vision sequences.",
      "potential_research_ideas": [
        "Extend one-shot distribution-matching augmentation to raw complex I/Q time-domain RF signals and multi-antenna/multi-channel inputs.",
        "Jointly learn augmentation and classifier in a closed-loop (e.g., train-time bilevel optimization where augmentation is optimized for downstream classification).",
        "Domain adaptation of one-shot generators across diverse RF environments (humidity/temperature/EMI variations) using environment-conditioned patch distributions.",
        "Evaluate robustness to RF spoofing/replay and adversarial perturbations with adversarially guided one-shot augmentation.",
        "Learn optimal 2D embeddings of 1D spectra (beyond fixed 45x45 reshaping) that preserve locality for patch-based distribution matching."
      ],
      "architectural_improvement_recommendations": [
        "Implement a 1D or multi-scale 1D/2D hybrid GPDM variant tailored to spectral/time-series structure instead of image-only assumptions.",
        "Adaptive patch size and multi-resolution patch scheduling guided by RF spectral characteristics (e.g., harmonic bands).",
        "Condition the one-shot generator on class labels and environment metadata to produce class- and context-specific augmentations.",
        "Combine GPDM with a lightweight discriminator or contrastive regularizer to encourage class-separable augmentations.",
        "Incorporate uncertainty estimation to select informative synthetic samples for training (active augmentation)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/amir-kazemi/uav-rf-id",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Environmental interference (EMI/RFI), obstructions, and hardware imperfections degrade RF signal quality.",
        "Data scarcity in limited RF environments necessitates augmentation for reliable identification."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a theoretically grounded one-shot generative augmentation approach (via GPDM) for RF-based UAV identification in low-data regimes.",
      "Derives upper bounds on the Wasserstein distance between real and generated sequence distributions using subsequence similarity, including image-like (2D) special cases.",
      "Applies the method to DFT-transformed RF signals and demonstrates empirical improvements over conditional GAN and VAE baselines.",
      "Releases code and links to datasets for reproducibility."
    ]
  },
  {
    "arxiv_id": "2303.13521v1",
    "title": "Scamming the Scammers: Using ChatGPT to Reply Mails for Wasting Time and Resources",
    "authors": "Enrico Cambiaso; Luca Caviglione",
    "abstract": "The use of Artificial Intelligence (AI) to support cybersecurity operations is now a consolidated practice, e.g., to detect malicious code or configure traffic filtering policies. The recent surge of AI, generative techniques and frameworks with efficient natural language processing capabilities dramatically magnifies the number of possible applications aimed at increasing the security of the Internet. Specifically, the ability of ChatGPT to produce textual contents while mimicking realistic human interactions can be used to mitigate the plague of emails containing scams. Therefore, this paper investigates the use of AI to engage scammers in automatized and pointless communications, with the goal of wasting both their time and resources. Preliminary results showcase that ChatGPT is able to decoy scammers, thus confirming that AI is an effective tool to counteract threats delivered via mail. In addition, we highlight the multitude of implications and open research questions to be addressed in the perspective of the ubiquitous adoption of AI.",
    "published_date": "2023-02-10",
    "pdf_link": "https://arxiv.org/pdf/2303.13521v1",
    "paper_types": [
      "position",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Email Security",
      "subdomain": "Spam/Scam Mitigation",
      "specific_problem": "Using a generative LLM (ChatGPT) to automatically reply to scam emails to decoy attackers and waste their time/resources",
      "attack_types": [
        "advance-fee fraud (large winnings/relatives’ inheritance)",
        "investment/stock pump spam",
        "phishing (mentioned; largely excluded from experiment)",
        "malware payload delivery via attachments (e.g., PDF)",
        "links with credentials (phishing-style)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer (Large Language Model)",
        "specific": "ChatGPT (OpenAI)",
        "novel_contribution": "Feasibility study demonstrating that an off-the-shelf LLM can sustain email conversations with scammers to waste their time and resources"
      }
    ],
    "learning_paradigm": [
      "Zero-shot prompting",
      "Generative (pretrained LLM, inference-only)"
    ],
    "datasets": [
      {
        "name": "CNR Office365 scam email corpus (Nov–Dec 2022, with follow-on until Jan 11, 2023)",
        "type": "private",
        "domain": "email_text",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "number_of_emails_in_thread",
      "average_message_length_characters",
      "average_message_length_sentences",
      "thread_duration_days",
      "delivery_status_SMTP_code (e.g., 5.2.1)",
      "emails_per_day (qualitative)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Is it feasible to use ChatGPT to engage scammers in automated, unproductive conversations to waste their time and resources?",
        "What preliminary quantitative effects (e.g., thread length, duration) can be observed when using ChatGPT to reply to scam emails?",
        "What open research questions and engineering challenges arise when deploying generative AI for countering mail-based scams?",
        "How should specialized/as-a-Service implementations be designed for different email-borne hazards?",
        "How can models better emulate human behavior to avoid being fingerprinted as AI?",
        "What are the privacy and forensics implications of AI-driven email replying?",
        "How to avoid AI-to-AI unwanted traffic escalation?",
        "What ethical implications arise from using AI to 'scam the scammers'?"
      ],
      "gaps_identified": [
        "Limited prior work on using generative AI to actively engage scammers via email; most AI work focuses on detection/classification, with [19] as a notable but different LSTM-based exception.",
        "Need for problem-specific modeling, vocabulary, and specialized datasets to craft realistic replies for distinct scam categories.",
        "Risk of attackers fingerprinting AI-generated messages due to linguistic patterns, timing, or style.",
        "Data requirements and privacy constraints for collecting real emails to train/tune models.",
        "Potential difficulties for forensics and attribution as AI-generated content volume grows.",
        "Potential for AI-to-AI email exchanges increasing unwanted traffic and resource waste."
      ],
      "limitations": [
        "Small number of considered attacks and threads; preliminary study.",
        "ChatGPT could not be configured or fine-tuned; treated as a black-box, requiring preamble tweaks to elicit replies and to avoid sharing personal details.",
        "Scope limited to plain-text scam messages requesting direct replies; phishing links and service-mimicking pages excluded.",
        "General-purpose training led ChatGPT to suggest impractical actions (e.g., proposing phone calls), revealing lack of specialized tuning.",
        "Observation window bounded; some interactions outside window not analyzed.",
        "Potential selection bias via Office365 anti-spam prefiltering."
      ],
      "future_work": [
        "Specialized and as-a-Service implementations tailored to specific email threats.",
        "Modeling human behavior and linguistic variability to reduce AI fingerprintability.",
        "Privacy- and forensics-aware data handling for AI-driven mail systems.",
        "Mechanisms to mitigate AI-to-AI unwanted traffic.",
        "Ethical frameworks and governance for AI interaction with scammers."
      ],
      "motivation": "Email scams and related threats remain prevalent; the authors explore leveraging generative AI (ChatGPT) to autonomously engage scammers, wasting their time/resources and potentially reducing the impact of scam campaigns.",
      "potential_research_ideas": [
        "Create and release a benchmark dataset of annotated scam email threads (including multi-turn interactions) for training/evaluating LLMs in scam engagement.",
        "Develop an RL or bandit-based policy to optimize prompts and response strategies that maximize attacker time cost while minimizing disclosure risks.",
        "Build detectors of AI-driven adversaries (AI-to-AI interaction detection) and adaptive strategies when the counterpart is also an AI.",
        "Design privacy-preserving data pipelines (federated or synthetic augmentation) for training specialized reply models without exposing sensitive email contents.",
        "Investigate linguistic style transfer and persona-based generation to emulate realistic human variability across languages and regions.",
        "Study watermarking or provenance tagging of AI-generated emails to support forensics while avoiding attacker exploitation.",
        "Integrate voice/TTS callbots with safe scripts to handle scammer requests to move to phone, measuring cross-channel engagement effectiveness.",
        "Formalize time-wasting as a utility metric and build standardized evaluation protocols (e.g., days engaged, replies-to-demand ratio, cost-to-attacker proxies)."
      ],
      "architectural_improvement_recommendations": [
        "Introduce a guarded prompt-engineering layer with deterministic policies to block any PII disclosure and to steer conversation goals (time-wasting, non-commitment).",
        "Fine-tune an open LLM on curated scam-reply corpora; optionally use instruction-tuning with safety constraints specific to scam engagement.",
        "Add a behavior emulator: timing jitter, typos, variable register and tone, and memory of previous statements to reduce AI fingerprintability.",
        "Implement a conversation state machine with goals/subgoals (stalling tactics), and a retrieval layer for consistent persona facts without revealing real PII.",
        "Risk filters for links/attachments and an automated sandbox to safely parse and summarize attacker-provided artifacts.",
        "Scalable, multi-tenant as-a-Service deployment with rate limiting and abuse prevention to avoid contributing to unwanted traffic.",
        "Telemetry and evaluator modules to compute engagement KPIs (e.g., attacker response latency, thread duration) and trigger escalation to human-in-the-loop when needed."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Used ChatGPT via web interface and a Microsoft Office365 mailbox; manual reply scheduling with randomized delays; no model training."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Enterprise/Institutional Office365 mailbox (cnr.it domain)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Modeling human-like behavior to avoid AI fingerprinting by attackers",
        "Privacy and regulatory constraints on collecting/processing emails",
        "Forensics complications from increased AI-generated content",
        "Risk of AI-to-AI escalation contributing to unwanted traffic",
        "Operational guardrails to prevent sharing sensitive/PII information",
        "Service delivery at scale for small/medium entities (cost/data needs)"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Feasibility study: using ChatGPT as a 'security' tool to counteract malicious mail messages by engaging scammers.",
      "Preliminary quantitative assessment of the effectiveness of AI-based replies (e.g., average engagement duration, thread lengths, message sizes).",
      "Identification and discussion of key research questions and engineering challenges for deploying generative AI against mail-based scams."
    ]
  },
  {
    "arxiv_id": "2302.13865v2",
    "title": "AI-Driven Container Security Approaches for 5G and Beyond: A Survey",
    "authors": "Ilter Taha Aktolga; Elif Sena Kuru; Yigit Sever; Pelin Angin",
    "abstract": "The rising use of microservices based software deployment on the cloud leverages containerized software extensively. The security of applications running inside containers as well as the container environment itself are critical infrastructure in the cloud setting and 5G. To address the security concerns, research efforts have been focused on container security with subfields such as intrusion detection, malware detection and container placement strategies. These security efforts are roughly divided into two categories: rule based approaches and machine learning that can respond to novel threats. In this study, we have surveyed the container security literature focusing on approaches that leverage machine learning to address security challenges.",
    "published_date": "2023-02-27",
    "pdf_link": "https://arxiv.org/pdf/2302.13865v2",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Cloud and Container Security",
      "subdomain": "Container Intrusion/Anomaly/Malware Detection for 5G/Cloud Microservices",
      "specific_problem": "Survey of AI/ML-driven approaches for container security (intrusion/anomaly/malware and inter-container security) in 5G and cloud environments",
      "attack_types": [
        "Container escape",
        "Privilege escalation",
        "Arbitrary code execution",
        "Brute force",
        "OS command injection",
        "SQL injection",
        "Network scanning",
        "Denial of Service (DoS)",
        "Cryptomining",
        "Backdoor",
        "Cross-Site Scripting (XSS)",
        "Information leak",
        "Integer overflow",
        "MySQL authentication bypass",
        "Spectre",
        "Meltdown",
        "Namespace injection"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "One-Class SVM (OC-SVM)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoencoder",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "REPTree",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "Random Tree",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "SMO (Sequential Minimal Optimization)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Sequence-based Anomaly Detection",
        "specific": "STIDE",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "HMM",
        "specific": "HMM classifiers",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Isolation Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph Embedding",
        "specific": "anonymous walk embeddings",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph Embedding",
        "specific": "node2vec",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Semi-supervised Learning",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoencoder",
        "specific": "Variational Autoencoder (VAE)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GAN",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Semi-supervised",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "LID-DS",
        "type": "public",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CB-DS (container escapes)",
        "type": "private",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "CUI-2020",
        "type": "public",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Container Performance Event Dataset (CEPD)",
        "type": "public",
        "domain": "performance_events",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "VM Migration dataset (CloudSim2)",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "ADFA-LD",
        "type": "public",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Custom syscall dataset (MariaDB; attack injection)",
        "type": "proprietary",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Custom syscall and network flow dataset",
        "type": "proprietary",
        "domain": "system_calls_and_network_flow",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Auditd process graph dataset (DoS, privilege escalation)",
        "type": "proprietary",
        "domain": "process_graph",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "DDM syscall dataset (database and ML apps via Sysdig)",
        "type": "proprietary",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "ROC curve/AUC",
      "False Positive Rate",
      "Recall",
      "Detection rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Anomaly-based NIDS leveraging network flow is under-explored for containers compared to HIDS based on system calls (as highlighted by Sever et al.).",
        "Generalizability concerns in several studies due to using a single victim application and a small set of attacks.",
        "Over-reliance on BoSC frequency representations; limited incorporation of richer context (e.g., syscall arguments, graph structure) in many works."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Rapid adoption of containers for microservices and 5G VNFs increases security risk; rule-based tools miss novel threats, motivating a focused survey of ML/AI-driven container security approaches.",
      "potential_research_ideas": [
        "Build a standardized, multi-application, multi-attack benchmark suite for ML-based container security (syscalls, netflow, performance counters) to improve generalizability.",
        "Develop multi-modal IDS that fuses system calls, network flow, and performance counters for containerized VNFs in 5G.",
        "Apply domain adaptation/transfer learning to enable cross-application and cross-environment IDS for containers.",
        "Use self-supervised pretraining on large-scale container telemetry (syscalls/netflow) to reduce labeling needs.",
        "Leverage graph neural networks on syscall-argument/process graphs to model dependencies and context.",
        "Systematically evaluate and harden container IDS against adversarial ML attacks specific to container telemetry."
      ],
      "architectural_improvement_recommendations": [
        "Hybrid architectures combining sequence models (e.g., Transformers over syscall sequences) with graph encoders (GNNs over syscall-argument/process graphs).",
        "Contrastive or triplet-based representation learning to separate benign/malicious behaviors across applications.",
        "Online/continual learning with drift detection for evolving workloads in 5G VNFs.",
        "Federated learning across clusters/tenants to improve models while preserving data locality/privacy.",
        "Feature engineering pipeline that jointly leverages BoSC, n-grams, and flow-level features with attention-based fusion."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Shared-kernel isolation brittleness in containers",
        "Container escapes via runtime/engine vulnerabilities",
        "Misconfiguration of containers and runtimes",
        "Privilege escalation on host",
        "Namespace injection attacks",
        "Multi-tenant data leakage risks"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Survey focused specifically on AI/ML-driven approaches for container security in 5G/cloud settings.",
      "Covers supervised, semi-supervised, and unsupervised detection models and features (system calls, network flow, graphs, performance data).",
      "Maps container security subfields: intrusion detection, malware/attack/anomaly detection, inter-container security.",
      "Summarizes datasets used in literature (e.g., LID-DS, CB-DS, ADFA-LD, CEPD, CloudSim-based synthetic datasets) and data collection tools (Sysdig, tcpdump, auditd).",
      "Reports representative results from surveyed works (e.g., “ROC curve values reach up to 0.995”, and 100% detection in specific scenarios) and discusses limitations/generalizability."
    ]
  },
  {
    "arxiv_id": "2302.08558v2",
    "title": "Generative Adversarial Networks for Malware Detection: a Survey",
    "authors": "Aeryn Dunmore; Julian Jang-Jaccard; Fariza Sabrina; Jin Kwak",
    "abstract": "Since their proposal in the 2014 paper by Ian Goodfellow, there has been an explosion of research into the area of Generative Adversarial Networks. While they have been utilised in many fields, the realm of malware research is a problem space in which GANs have taken root. From balancing datasets to creating unseen examples in rare classes, GAN models offer extensive opportunities for application. This paper surveys the current research and literature for the use of Generative Adversarial Networks in the malware problem space. This is done with the hope that the reader may be able to gain an overall understanding as to what the Generative Adversarial model provides for this field, and for what areas within malware research it is best utilised. It covers the current related surveys, the different categories of GAN, and gives the outcomes of recent research into optimising GANs for different topics, as well as future directions for exploration.",
    "published_date": "2023-02-16",
    "pdf_link": "https://arxiv.org/pdf/2302.08558v2",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection",
      "specific_problem": "Survey of how Generative Adversarial Networks (GANs) are used for malware research and detection, including data augmentation, balancing rare classes, and generating adversarial/unseen samples",
      "attack_types": [
        "ransomware",
        "domain generation algorithms (DGA)",
        "botnet command-and-control (C2) domains"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GAN",
        "specific": "Vanilla GAN (Goodfellow GAN)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "CGAN (Conditional GAN)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "DCGAN (Deep Convolutional GAN)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "WGAN (Wasserstein GAN)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "BiGAN (Bidirectional GAN)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "CycleGAN",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "AC-GAN (Auxiliary Classifier GAN)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "MalGAN",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "ISGAN",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "InfoGAN",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "FlowGAN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "VAE",
        "specific": "Variational Autoencoder",
        "novel_contribution": "Mentioned as a common comparison/control model in surveyed works"
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Adversarial generative modeling"
    ],
    "datasets": [
      {
        "name": "DGArchive",
        "type": "public",
        "domain": "domain_names (DGA, botnet C2)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "True Positive (TP)",
      "False Positive (FP)",
      "True Negative (TN)",
      "False Negative (FN)",
      "Accuracy",
      "Precision",
      "Recall",
      "F1-Score",
      "Inception Score (IS)",
      "Mode Score (MS)",
      "Fréchet Inception Distance (FID)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What does the Generative Adversarial model provide for malware research?",
        "For which areas within malware research are GANs best utilized (e.g., augmentation of rare classes, generating unseen examples)?",
        "What are the outcomes of recent research into optimizing GANs for different malware-related topics?",
        "What future directions exist for applying GANs in malware research?"
      ],
      "gaps_identified": [
        "Lack of an up-to-date, focused survey specifically on GANs in malware research amid rapid growth in the area.",
        "Prior surveys often emphasized depth over breadth or vice versa, leaving limited variety of tasks/applications covered.",
        "Costly image translations and modality conversions remain a barrier; improved methods to avoid image translations were highlighted in related work."
      ],
      "limitations": [
        "Scope focuses on GANs applied to malware, with emphasis on image-based representations of malware.",
        "As a survey, it synthesizes literature without conducting new empirical benchmarks or unified quantitative comparisons."
      ],
      "future_work": [
        "Explore improved methods to avoid image translations to reduce overhead (noted in related survey).",
        "Broaden applications across malware modalities beyond images (implied by focus).",
        "Investigate optimization strategies for GAN stability and quality in malware domains (implied by discussion of GAN categories and metrics)."
      ],
      "motivation": "Provide an updated, accessible overview of how GANs are used in malware research, reflecting rapid recent growth; clarify GAN categories, datasets, evaluation metrics, and areas where GANs are most useful.",
      "potential_research_ideas": [
        "Develop standardized evaluation protocols for GAN-generated malware data, combining IS/FID with domain-specific validity checks (e.g., functional semantics for malware).",
        "Apply diffusion models and compare to GANs for malware data augmentation and adversarial example generation.",
        "Design semantics-preserving, functionality-constrained GANs that ensure generated malware samples retain or control specific behavioral properties for detector training.",
        "Investigate cross-modal GANs to translate between binaries, API-call sequences, network flows, and image representations to improve multi-view training.",
        "Create domain adaptation/transfer GANs to bridge dataset and temporal drifts (e.g., from old to novel ransomware families).",
        "Graph-based GANs over call graphs or CFGs for structure-aware augmentation and adversarial examples.",
        "Federated/privacy-preserving GAN training across organizations to expand data diversity without sharing raw samples."
      ],
      "architectural_improvement_recommendations": [
        "Use WGAN-GP or spectral normalization for stable GAN training in malware domains.",
        "Adopt class-conditional GANs (AC-GAN/CGAN) to better target augmentation of rare malware families.",
        "Incorporate discriminator auxiliary tasks (e.g., behavior tags) to enforce semantics during generation.",
        "Hybrid GAN-VAE or GAN-diffusion pipelines to balance sample diversity and fidelity.",
        "Integrate functionality validators (emulators/sandboxes) in the training loop to reject nonfunctional or unrealistic samples.",
        "Leverage multi-discriminator or multi-scale architectures for diverse malware feature spaces (static, dynamic, and network)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Class imbalance and scarcity of rare malware families (motivation for GAN augmentation).",
        "Overhead and complexity when converting modalities (image translations)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "An up-to-date survey focused on GANs for malware research and detection.",
      "Clarifies GAN categories and their relevance to malware applications.",
      "Summarizes evaluation metrics for GANs and malware classifiers, including IS, FID, Mode Score, and standard classification metrics.",
      "Catalogs datasets used in surveyed works (e.g., DGArchive) and their roles.",
      "Discusses applications such as data augmentation for rare classes and generation of unseen/adversarial samples.",
      "Highlights future directions and opportunities for applying and optimizing GANs in malware research."
    ]
  },
  {
    "arxiv_id": "2301.13581v1",
    "title": "Machine Learning and Port Scans: A Systematic Review",
    "authors": "Jason M. Pittman",
    "abstract": "Port scanning is the process of attempting to connect to various network ports on a computing endpoint to determine which ports are open and which services are running on them. It is a common method used by hackers to identify vulnerabilities in a network or system. By determining which ports are open, an attacker can identify which services and applications are running on a device and potentially exploit any known vulnerabilities in those services. Consequently, it is important to detect port scanning because it is often the first step in a cyber attack. By identifying port scanning attempts, cybersecurity professionals can take proactive measures to protect the systems and networks before an attacker has a chance to exploit any vulnerabilities. Against this background, researchers have worked for over a decade to develop robust methods to detect port scanning. While there have been various surveys, none have focused solely on machine learning based detection schemes specific to port scans. Accordingly, we provide a systematic review of 15 papers published between February 2021 and January 2023. We extract critical information such as training dataset, algorithm used, technique, and model accuracy. We also collect unresolved challenges and ideas for future work. The outcomes are significant for researchers looking to step off from the latest work and for practitioners interested in novel mechanisms to detect the early stages of cyber attack.",
    "published_date": "2023-01-31",
    "pdf_link": "https://arxiv.org/pdf/2301.13581v1",
    "paper_types": [
      "empirical_analysis",
      "survey"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Machine-learning-based port scan detection (identifying scanning activity in network traffic)",
      "attack_types": [
        "Port scanning",
        "TCP SYN scan",
        "TCP connect (Full connect) scan",
        "FIN scan",
        "XMAS scan",
        "NULL scan",
        "UDP scan",
        "ICMP sweep",
        "Decoy scanning",
        "Fragmented scanning",
        "Coordinated/Distributed scanning",
        "Vertical scan",
        "Horizontal scan",
        "Port sweep"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Support Vector Machine",
        "specific": "Fine Gaussian SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Regression",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Naive Bayes",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Neural Network",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Nature-inspired / metaheuristic methods",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CICIDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MAWILab",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Bona\u0017fide",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Custom dataset (Bakaletz: Nmap aggressive and stealth scans)",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "F1-score",
      "False positive rate",
      "Detection rate",
      "False negative rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: What machine learning algorithms have been used to detect port scanning?",
        "RQ2: What were the detection rates and false positive rates for those algorithms?",
        "RQ3: What datasets were used for training and evaluation of those algorithms?",
        "RQ4: What port scanning types and techniques were used for evaluation of those algorithms?"
      ],
      "gaps_identified": [
        "No prior systematic review focused solely on ML-based port scan detection; prior surveys were broader.",
        "Findings are scattered; only one study in the reviewed set cited another from the same population, indicating weak cross-referencing and fragmentation.",
        "Many studies do not specify the port scan types/techniques present in the training/evaluation datasets.",
        "Limited code availability (e.g., among RF studies, only one paper provided code).",
        "Heterogeneity of datasets and evaluation setups complicates direct comparison of results."
      ],
      "limitations": [
        "Search constrained to papers from 2021 onward (with one 2020 exception).",
        "Search may be imperfect despite multiple query strings; manual screening was required.",
        "Small final corpus (15 studies).",
        "Metrics aggregated primarily as “accuracy (F1)” with limited uniform reporting of false positives across all works.",
        "Inclusion of one 2020 paper as a specific exception to the time window."
      ],
      "future_work": [],
      "motivation": "Provide a current, focused systematic review of ML techniques for detecting port scanning—an early step in cyber attacks—filling a gap left by broader IDS surveys and consolidating scattered results.",
      "potential_research_ideas": [
        "Create a standardized benchmark for port scan detection with explicit labeling of scan types/strategies and multiple scanning tools.",
        "Study robustness to slow, stealthy, and distributed scans (including low-and-slow and coordinated scans) under strong class imbalance.",
        "Cross-network/domain generalization: evaluate models trained on one environment/dataset and tested on others (domain adaptation).",
        "Adversarial evaluation: design and assess evasion strategies for scanners and defenses (e.g., timing obfuscation, fragmentation, decoys).",
        "Real-time detection at scale using streaming/online learning with concept drift handling for evolving traffic patterns.",
        "Explainable ML for port scan detection to help differentiate benign authorized scanning from malicious reconnaissance.",
        "Multi-task learning that jointly detects scan presence and classifies scan type/technique.",
        "Fusion approaches combining flow-level features with host logs or OS/network telemetry for improved precision."
      ],
      "architectural_improvement_recommendations": [
        "Incorporate temporal/sequential models (e.g., RNN/Transformer over flow sequences) to capture scan dynamics and timing patterns.",
        "Graph-based methods over communication graphs to detect coordinated/distributed scans across hosts and subnets.",
        "Imbalanced learning strategies (focal loss, class-balanced reweighting, hard negative mining) and calibrated decision thresholds.",
        "Contrastive/self-supervised pretraining on large unlabeled traffic to improve data efficiency, then fine-tune for scan detection.",
        "Uncertainty estimation and score calibration to control false positives in operational settings.",
        "Explicit multi-label/multi-class heads for scan type classification in addition to binary detection.",
        "Cross-dataset evaluation protocols and domain adaptation layers (e.g., CORAL, adversarial domain alignment) to improve generalization."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Differentiating benign/authorized scanning from malicious reconnaissance in operational networks.",
        "Coverage of diverse scan types, strategies, and tools to avoid blind spots.",
        "Dataset representativeness and shift between lab datasets and real network environments."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First systematic review (2021–Jan 2023) focused specifically on ML-based port scan detection.",
      "Catalogs algorithms, datasets, techniques, and reported performance (e.g., “accuracy (F1)”, false positives) across 15 studies.",
      "Provides algorithm-wise summaries (RF, SVM, Regression, Naive Bayes, Neural Networks, Nature-inspired) and dataset usage (e.g., CICIDS2017, NSL-KDD, MAWILab, Bona\u0017fide, custom).",
      "Highlights gaps: sparse cross-citation among studies, limited reporting of scan types/techniques, and limited code availability.",
      "Frames port scanning taxonomy and detection context to situate results and guide future research."
    ]
  },
  {
    "arxiv_id": "2304.03691v1",
    "title": "Feature Mining for Encrypted Malicious Traffic Detection with Deep Learning and Other Machine Learning Algorithms",
    "authors": "Zihao Wang; Vrizlynn L. L. Thing",
    "abstract": "The popularity of encryption mechanisms poses a great challenge to malicious traffic detection. The reason is traditional detection techniques cannot work without the decryption of encrypted traffic. Currently, research on encrypted malicious traffic detection without decryption has focused on feature extraction and the choice of machine learning or deep learning algorithms. In this paper, we first provide an in-depth analysis of traffic features and compare different state-of-the-art traffic feature creation approaches, while proposing a novel concept for encrypted traffic feature which is specifically designed for encrypted malicious traffic analysis. In addition, we propose a framework for encrypted malicious traffic detection. The framework is a two-layer detection framework which consists of both deep learning and traditional machine learning algorithms. Through comparative experiments, it outperforms classical deep learning and traditional machine learning algorithms, such as ResNet and Random Forest. Moreover, to provide sufficient training data for the deep learning model, we also curate a dataset composed entirely of public datasets. The composed dataset is more comprehensive than using any public dataset alone. Lastly, we discuss the future directions of this research.",
    "published_date": "2023-04-07",
    "pdf_link": "https://arxiv.org/pdf/2304.03691v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Encrypted Traffic Analysis",
      "specific_problem": "Detection and classification of encrypted malicious network traffic without decryption",
      "attack_types": [
        "botnet",
        "trojan",
        "malware communication over HTTPS/TLS",
        "ransomware (motivational context)",
        "phishing (motivational context)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Feature Engineering",
        "specific": null,
        "novel_contribution": "Enc Feature: protocol-agnostic yet encrypted-only feature granularity that filters non-encrypted sessions and packets; 78 Enc features plus ratio features (No.79–143)."
      },
      {
        "type": "primary",
        "category": "Hybrid",
        "specific": null,
        "novel_contribution": "Two-layer detection framework combining deep learning and traditional machine learning for encrypted malicious traffic detection."
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble Trees",
        "specific": "Random Forest",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Composed dataset of public datasets (curated by this paper)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "CTU-13 (Stratosphere Lab)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VPN-nonVPN dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CTU Malware Capture Project",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "FIRST dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Milicenso",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ImageNet (for transfer learning in related work)",
        "type": "public",
        "domain": "images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "ResNet",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can encrypted-only, protocol-agnostic features (Enc Features) improve detection of encrypted malicious traffic versus protocol-specific and general protocol-agnostic features?",
        "Does a hybrid two-layer DL+ML framework outperform classical single-model deep learning (e.g., ResNet) and traditional ML (e.g., Random Forest) baselines for encrypted malicious traffic detection?",
        "How should network traffic features be analyzed and standardized to better represent encrypted traffic characteristics?"
      ],
      "gaps_identified": [
        "Lack of recognized standard definition and extraction logic for network traffic features.",
        "Protocol-specific features are limited to certain encryption protocols and are time-consuming to extract.",
        "Existing works often fail to fully eliminate non-encrypted packets (e.g., TLS handshake) from 'encrypted' sessions, introducing noise.",
        "Insufficient number of highly discriminatory features for encrypted traffic; feature mining is a bottleneck for performance.",
        "Deep learning studies often rely on small datasets, raising concerns about robustness and generalization."
      ],
      "limitations": [
        "Enc Features are only applicable to encrypted traffic (not suitable for non-encrypted flows).",
        "Additional preprocessing required to filter non-encrypted sessions and packets may introduce overhead."
      ],
      "future_work": [],
      "motivation": "Detect malicious encrypted traffic without decryption by creating features that capture encrypted-only characteristics and designing an effective detection framework while preserving privacy.",
      "potential_research_ideas": [
        "Evaluate Enc Features across broader protocol coverage (e.g., QUIC/HTTP3, SSH, IPSec, WireGuard) and multi-protocol mixed environments.",
        "Self-supervised or contrastive pretraining on packet sequences of encrypted traffic to reduce labeled data needs and enhance robustness.",
        "Early-stage streaming detection that uses only the first N encrypted packets for low-latency decisions.",
        "Adversarial robustness analysis against traffic morphing/padding/timing obfuscation and defense methods (e.g., adversarial training, randomized smoothing).",
        "Cross-domain generalization studies: train on one set of public corpora and test on different organizations/protocol mixes.",
        "Explainability of encrypted-traffic decisions via feature attribution (e.g., SHAP) and counterfactuals to aid analyst trust.",
        "Integrate TLS/QUIC fingerprinting (e.g., JA3/JA4) as auxiliary metadata while remaining protocol-agnostic at the core.",
        "Federated or privacy-preserving learning setups to leverage data across organizations without sharing raw traffic."
      ],
      "architectural_improvement_recommendations": [
        "Replace or complement the DL component with transformer-based sequence models over packet-level encrypted-only features.",
        "Multi-task learning to jointly predict malware family/type and malicious/benign to exploit shared representations.",
        "Calibrated confidence scoring and abstention to support human-in-the-loop triage.",
        "Online/incremental learning to adapt to evolving encryption stacks and malware behaviors.",
        "Automated feature selection/AutoML over Enc and ratio features to optimize compact, deployable models.",
        "Lightweight student models via knowledge distillation from the hybrid framework for deployment at network edges."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a novel encrypted-only, protocol-agnostic feature granularity (Enc Features) with a defined filtering process to remove non-encrypted traffic at both session and packet levels.",
      "Designs a two-layer detection framework that combines deep learning and traditional machine learning, reported to outperform classical models such as ResNet and Random Forest.",
      "Curates a composite training dataset built entirely from public datasets to provide sufficient data for deep learning.",
      "Provides an in-depth analysis and taxonomy of traffic features and compares state-of-the-art feature creation approaches.",
      "Discusses remaining challenges and future research directions for encrypted malicious traffic detection."
    ]
  },
  {
    "arxiv_id": "2302.01474v2",
    "title": "Defensive ML: Defending Architectural Side-channels with Adversarial Obfuscation",
    "authors": "Hyoungwook Nam; Raghavendra Pradyumna Pothukuchi; Bo Li; Nam Sung Kim; Josep Torrellas",
    "abstract": "Side-channel attacks that use machine learning (ML) for signal analysis have become prominent threats to computer security, as ML models easily find patterns in signals. To address this problem, this paper explores using Adversarial Machine Learning (AML) methods as a defense at the computer architecture layer to obfuscate side channels. We call this approach Defensive ML, and the generator to obfuscate signals, defender. Defensive ML is a workflow to design, implement, train, and deploy defenders for different environments. First, we design a defender architecture given the physical characteristics and hardware constraints of the side-channel. Next, we use our DefenderGAN structure to train the defender. Finally, we apply defensive ML to thwart two side-channel attacks: one based on memory contention and the other on application power. The former uses a hardware defender with ns-level response time that attains a high level of security with half the performance impact of a traditional scheme; the latter uses a software defender with ms-level response time that provides better security than a traditional scheme with only 70% of its power overhead.",
    "published_date": "2023-02-03",
    "pdf_link": "https://arxiv.org/pdf/2302.01474v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware and Architecture Security",
      "subdomain": "Microarchitectural Side-channel Defense",
      "specific_problem": "Obfuscating microarchitectural side-channel signals (memory latency contention and application power) to defeat ML-based attackers under strict hardware/software constraints",
      "attack_types": [
        "memory contention side-channel",
        "power side-channel",
        "timing side-channel"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GAN",
        "specific": "DefenderGAN (AdvGAN-inspired, with one-to-all Wasserstein loss)",
        "novel_contribution": "Design of a defender generator trained adversarially to push attacker predictions toward uniform (or flipped in binary), with a discriminator maximizing one-to-all Wasserstein distances to improve transferability to unknown classifiers; adapted for online perturbation under physical constraints"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "GRU-based generator",
        "novel_contribution": "Tiny GRU-based generator architecture for ns-scale hardware deployment; uses history window (N=32) and ReLU-bounded positive perturbations for timing channels"
      },
      {
        "type": "primary",
        "category": "Knowledge Distillation / Model Compression",
        "specific": "GAN compression + quantization (INT8/FP16)",
        "novel_contribution": "Compress trained defender to meet area/power/timing budgets; combine distillation with DefenderGAN losses; mixed-precision quantization for GRU state"
      },
      {
        "type": "primary",
        "category": "Regularization",
        "specific": "Dropout-based noise injection during training",
        "novel_contribution": "Leverages dropout as part of lightweight noise injection and robustness"
      },
      {
        "type": "baseline",
        "category": "Classical Noise Injection",
        "specific": "Gaussian noise; Gaussian sinusoid; Padding to constant",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Adversarial"
    ],
    "datasets": [
      {
        "name": "Memory contention side-channel traces (RSA, EDDSA)",
        "type": "private",
        "domain": "memory_latency_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Application power side-channel traces (real system)",
        "type": "private",
        "domain": "power_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Gaussian noise (latency perturbation)",
        "paper_reference": null,
        "metric": "Attack accuracy vs. average added cycles (slowdown)",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Gaussian sinusoid (latency perturbation)",
        "paper_reference": null,
        "metric": "Attack accuracy vs. average added cycles (slowdown)",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Padding to constant (constant-time padding)",
        "paper_reference": null,
        "metric": "Attack accuracy vs. average added cycles (slowdown)",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Traditional scheme (non-ML obfuscation)",
        "paper_reference": null,
        "metric": "Security vs. performance/power overhead",
        "their_result": "“hardware defender ... attains a high level of security with half the performance impact of a traditional scheme”; “software defender ... provides better security than a traditional scheme with only 70% of its power overhead.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Attacker classification accuracy",
      "Average added cycles / slowdown",
      "Power overhead",
      "Area and power budget (hardware)",
      "Response time (ns-level hardware; ms-level software)",
      "Transferability to adaptive/black-box classifiers",
      "Mutual information/channel capacity (conceptual)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can adversarial ML be used as a practical, on-the-fly defense to obfuscate architectural side channels against ML-based attackers?",
        "How to design, train, and deploy a defender that meets strict hardware/software constraints while minimizing information leakage and overhead?",
        "How to ensure transferability of defender noise to unknown and adaptive attacker classifiers?"
      ],
      "gaps_identified": [
        "Prior AML-for-defense methods require full traces and are post-processing, not deployable online.",
        "ML-based side-channel attacks resist basic defenses (noise, masking, shuffling), requiring large distortions with high overhead.",
        "Defenses typically target a specific attacker/classifier rather than minimizing leakage against the best possible classifier; lack of transferability evaluation to adaptive attackers."
      ],
      "limitations": [
        "Security evaluation relies on empirical expected channel capacity over a finite set of classifiers; does not guarantee absolute security against all possible classifiers.",
        "Hardware defender can only add positive integer latency (cannot reduce time), constraining perturbation space.",
        "Memory contention case validated with trace-level experiments rather than full hardware deployment; software power case tested in a real system but details on broad application classes not fully enumerated in provided text.",
        "Defender cannot be updated post-deployment in their evaluation protocol; adaptive attackers can still retrain."
      ],
      "future_work": [],
      "motivation": "Use Adversarial ML to create minimal, transferable perturbations that obfuscate side-channel signals, neutralizing ML-based attacks while satisfying tight architectural constraints and minimizing performance/power overhead.",
      "potential_research_ideas": [
        "Formal bounds on channel capacity reduction under DefenderGAN with constrained perturbations (positive-only timing noise) and limited compute.",
        "Ensemble-of-attackers training (diverse classifier families and losses) to further improve transferability to unknown/adaptive attackers.",
        "Online defender adaptation via periodic secure re-training or meta-learning without exposing update surfaces to attackers.",
        "Co-design with scheduling/traffic shaping (e.g., memory request reordering) to expand feasible perturbation space beyond additive delays.",
        "Combine adversarial obfuscation with differential privacy-inspired noise calibration to provide provable leakage guarantees.",
        "Robust control-theoretic integration for power-side channels with disturbance observers to balance QoS and obfuscation adaptively.",
        "Hardware-in-the-loop training to close sim-to-real gap for memory defender and validate timing/area/power trade-offs.",
        "Evaluation against broader attacker models (e.g., self-supervised or generative attackers) and non-neural classical methods to validate universality."
      ],
      "architectural_improvement_recommendations": [
        "Augment DefenderGAN training with an attacker ensemble (RNN/CNN/TCN/Transformer/SVM/RF) and diverse losses (CE, focal, contrastive) to harden transferability.",
        "Use temporal convolutional networks (dilated causal CNN/TCN) or lightweight hybrid GRU+TCN to capture longer-range patterns at similar or lower latency than GRU.",
        "Incorporate constrained optimization layers to explicitly enforce physical limits (e.g., integer-only, bounded max-latency) during training rather than post-hoc clipping.",
        "Multi-objective training with explicit performance/power regularization terms (e.g., Pareto front) for tunable trade-offs per deployment.",
        "Leverage neural architecture search under power/area/timing constraints to auto-derive minimal defender architectures for target technology nodes.",
        "Quantization-aware training for mixed-precision GRU state to minimize accuracy drop after INT8/FP16 deployment.",
        "Periodic secret-salted randomness in the defender to reduce attacker adaptation while preserving system-level constraints."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Hardware defender budget example: ~1 W, ~1 mm^2; operates at up to ~500 MHz with ~20k ops/inference (from 10 TOPS/W estimate). Memory defender ns-level response (DDR4-3200 ~1.25 ns transactions). Estimated max power/area for TSMC 7nm tiny DNN: ~0.74 W, ~0.69 mm^2. Software defender ms-level response; training/inference frameworks not specified."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Hardware: memory controller (on-CPU), ns-scale; Software: system-level power control framework (e.g., Maya) on real multiprocessor system",
      "scalability_discussed": true,
      "inference_time": "ns-level (memory defender), ms-level (power defender)",
      "deployment_challenges": [
        "Tight power/area/timing budgets for on-chip hardware defender.",
        "Physical constraints (e.g., only positive latency can be added).",
        "Need for transferability to unknown/adaptive attacker classifiers.",
        "Potential performance slowdown and power overhead trade-offs.",
        "Post-deployment immutability of defender parameters vs. adaptive attackers."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Identify side-channel obfuscation as an optimization problem and propose ML defenders to mitigate architectural side-channels.",
      "Propose Defensive ML: a workflow to design, train, evaluate (for transferability to adaptive attackers), and deploy defenders (with compression) for architectural side-channels.",
      "Apply Defensive ML to two side channels (memory contention and application power) showing improved security-overhead trade-offs vs. traditional schemes, including tiny ns-scale hardware and ms-scale software defenders."
    ]
  },
  {
    "arxiv_id": "2301.08428v1",
    "title": "Defending SDN against packet injection attacks using deep learning",
    "authors": "Anh Tuan Phu; Bo Li; Faheem Ullah; Tanvir Ul Huque; Ranesh Naha; Ali Babar; Hung Nguyen",
    "abstract": "The (logically) centralised architecture of the software-defined networks makes them an easy target for packet injection attacks. In these attacks, the attacker injects malicious packets into the SDN network to affect the services and performance of the SDN controller and overflow the capacity of the SDN switches. Such attacks have been shown to ultimately stop the network functioning in real-time, leading to network breakdowns. There have been significant works on detecting and defending against similar DoS attacks in non-SDN networks, but detection and protection techniques for SDN against packet injection attacks are still in their infancy. Furthermore, many of the proposed solutions have been shown to be easily by-passed by simple modifications to the attacking packets or by altering the attacking profile. In this paper, we develop novel Graph Convolutional Neural Network models and algorithms for grouping network nodes/users into security classes by learning from network data. We start with two simple classes - nodes that engage in suspicious packet injection attacks and nodes that are not. From these classes, we then partition the network into separate segments with different security policies using distributed Ryu controllers in an SDN network. We show in experiments on an emulated SDN that our detection solution outperforms alternative approaches with above 99\\% detection accuracy on various types (both old and new) of injection attacks. More importantly, our mitigation solution maintains continuous functions of non-compromised nodes while isolating compromised/suspicious nodes in real-time. All code and data are publicly available for reproducibility of our results.",
    "published_date": "2023-01-20",
    "pdf_link": "https://arxiv.org/pdf/2301.08428v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "SDN Security / Intrusion Detection and Mitigation",
      "specific_problem": "Detection and mitigation of packet injection attacks in SDN (Packet-In flooding leading to controller overload and switch rule-space overflow)",
      "attack_types": [
        "Packet injection (SDN Packet-In flooding)",
        "DoS/DDoS (slow/fast, low-rate, discontinuous)",
        "PortScan"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "HyperGCN",
        "novel_contribution": "Two-layer graph-based detector for SDN packet injection attacks using HyperGCN on hypergraphs to perform semi-supervised node classification of malicious hosts and identify attack types"
      },
      {
        "type": "primary",
        "category": "GNN",
        "specific": "GCN",
        "novel_contribution": "Dual-stage (binary detection then multi-class identification) graph convolutional classification over activity-flow aggregated host features in SDN"
      }
    ],
    "learning_paradigm": [
      "Semi-supervised",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "SDN Packet Injection Attack (Mininet/Ryu) Emulated Dataset",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": "https://github.com/nahaUoA/SDNPacketInjectionAttack",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS2017 (CIC-IDS 2017)",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/ids-2017.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to detect and identify packet injection attacks in SDN, including low-rate and discontinuous variants that evade threshold-based methods?",
        "How to mitigate packet injection attacks without overloading the SDN controller or overflowing switch rule space, while maintaining normal traffic?",
        "Can graph-based deep learning over activity flows effectively differentiate benign from malicious SDN hosts in real time?"
      ],
      "gaps_identified": [
        "Detection and protection techniques for SDN packet injection attacks are in their infancy.",
        "Many proposed solutions are easily bypassed by simple modifications to attacking packets or altering the attack profile.",
        "Threshold-based detection fails for low-rate and discontinuous packet injection attacks.",
        "Existing approaches cannot prevent switches from sending malicious Packet-In messages to the controller, causing controller overload.",
        "Switch rule-space overflow remains a risk when mitigation installs too many per-flow blocking rules."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Provide SDN-specific detection and mitigation for packet injection attacks that current methods miss (low-rate, discontinuous), avoiding controller overload and preserving normal network operations.",
      "potential_research_ideas": [
        "Extend to broader SDN threat coverage (e.g., flow-rule poisoning, topology attacks) with unified multi-task graph models.",
        "Online/continual learning for evolving attack profiles and concept drift in SDN traffic.",
        "Transfer learning or domain adaptation from public IDS datasets to SDN-specific traffic and topologies.",
        "Unsupervised or self-supervised pretraining on large unlabeled SDN flows to reduce labeling needs.",
        "Adversarial robustness evaluation and defense (e.g., adversarial training on flow features and graph structure perturbations).",
        "Integrate temporal dynamics with temporal GNNs to better capture bursty and discontinuous attack patterns.",
        "Cross-controller (multi-domain) collaborative detection with federated or split learning for large-scale SDN deployments."
      ],
      "architectural_improvement_recommendations": [
        "Adopt temporal/hybrid GNNs (e.g., TGNN, GCN+GRU) to model time-evolving flow graphs for better detection of discontinuous/slow attacks.",
        "Include edge features (flow volumes, inter-arrival times) and attention mechanisms (GAT/HyperGAT) to weigh informative host interactions.",
        "Add uncertainty estimation (MC Dropout/Deep Ensembles) to drive active learning and cautious mitigation policies.",
        "Use self-supervised graph pretraining (e.g., GraphCL) on SDN flows to improve generalization with limited labels.",
        "Implement explainability (e.g., GNNExplainer) to highlight flows/edges that drive malicious classification for operator trust.",
        "Resource-aware model compression/quantization for controller or switch-adjacent deployment with latency constraints.",
        "Rule-optimization in mitigation (aggregate/blocklists, wildcarding) to minimize rule-space usage and avoid overflow."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/nahaUoA/SDNPacketInjectionAttack",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "SDN emulation with Mininet and distributed Ryu controllers; traffic mirroring to a detection module",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires mirroring traffic to the detection module.",
        "Assumes switches operate in reactive mode and flows carry 3-tuple identifiers (IP, MAC, switch:port).",
        "Requires maintaining accurate Network_List, Observing_List, and Block_List for mitigation.",
        "Ensuring rule-space efficiency to avoid switch TCAM overflow during mitigation."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A novel graph-based deep learning model (HyperGCN/GCN) to detect and identify various packet injection attacks in SDN with high accuracy; first solution claiming real-time distinction between slow/fast DoS variants in SDN.",
      "A scalable SDN mitigation strategy that isolates malicious nodes and maintains normal operations without triggering Packet-In events; mitigation runtime scales linearly with switches, hosts, and attackers.",
      "An emulated SDN setup (Mininet + Ryu) and the first publicly available emulated dataset of packet injection attacks.",
      "Public release of all code and data for reproducibility.",
      "Extended threat models introducing low-rate and discontinuous packet injection attack variants."
    ]
  },
  {
    "arxiv_id": "2302.05728v1",
    "title": "Sequential Embedding-based Attentive (SEA) classifier for malware classification",
    "authors": "Muhammad Ahmed; Anam Qureshi; Jawwad Ahmed Shamsi; Murk Marvi",
    "abstract": "The tremendous growth in smart devices has uplifted several security threats. One of the most prominent threats is malicious software also known as malware. Malware has the capability of corrupting a device and collapsing an entire network. Therefore, its early detection and mitigation are extremely important to avoid catastrophic effects. In this work, we came up with a solution for malware detection using state-of-the-art natural language processing (NLP) techniques. Our main focus is to provide a lightweight yet effective classifier for malware detection which can be used for heterogeneous devices, be it a resource constraint device or a resourceful machine. Our proposed model is tested on the benchmark data set with an accuracy and log loss score of 99.13 percent and 0.04 respectively.",
    "published_date": "2023-02-11",
    "pdf_link": "https://arxiv.org/pdf/2302.05728v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Classification",
      "specific_problem": "Multi-class malware family classification from opcode sequences (static heuristic-based detection for smart/embedded devices)",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Embedding",
        "specific": "Learned opcode embeddings via sliding window",
        "novel_contribution": "Sequential window-based learned opcode embeddings capturing context and semantics before sequence modeling"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Parallel LSTM and GRU blocks",
        "novel_contribution": "Parallel LSTM and GRU feature extractors to capture complementary long-term dependencies with reduced time/compute"
      },
      {
        "type": "primary",
        "category": "Attention",
        "specific": "Lightweight self-attention (single-head/feed-forward scoring)",
        "novel_contribution": "Simple self-attention to emphasize rare but important opcode subsequences (addresses class imbalance impact) while remaining computationally light"
      },
      {
        "type": "primary",
        "category": "Feature Fusion",
        "specific": "Mean-averaging of LSTM/GRU feature vectors",
        "novel_contribution": "Averaging means to fuse parallel sequence representations and smooth extremes"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Hierarchical CNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "CNN with Structural Entropy",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Multimodal DL",
        "specific": "HYDRA (multimodal deep learning)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Multimodal DL",
        "specific": "Orthrus (bimodal learning architecture)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Bytes-based classifier",
        "specific": "Bytes Files Classifier",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Microsoft Malware Classification Challenge (BIG 2015) (\"Microsoft BIG 15\")",
        "type": "public",
        "domain": "malware_opcodes",
        "link": "https://www.kaggle.com/c/malware-classification",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Hierarchical CNN",
        "paper_reference": "[5] 2019 IJCNN",
        "metric": "Accuracy",
        "their_result": "0.9912 (SEA)",
        "baseline_result": "0.9913"
      },
      {
        "method_name": "Hierarchical CNN",
        "paper_reference": "[5] 2019 IJCNN",
        "metric": "F1 Score",
        "their_result": "0.9908 (SEA)",
        "baseline_result": "0.9830"
      },
      {
        "method_name": "Hierarchical CNN",
        "paper_reference": "[5] 2019 IJCNN",
        "metric": "Logloss (Kaggle)",
        "their_result": "0.0431 (SEA)",
        "baseline_result": "0.0419"
      },
      {
        "method_name": "CNN with Structural Entropy",
        "paper_reference": "[6] 2018",
        "metric": "Accuracy",
        "their_result": "0.9912 (SEA)",
        "baseline_result": "0.9828"
      },
      {
        "method_name": "CNN with Structural Entropy",
        "paper_reference": "[6] 2018",
        "metric": "F1 Score",
        "their_result": "0.9908 (SEA)",
        "baseline_result": "0.9830"
      },
      {
        "method_name": "CNN with Structural Entropy",
        "paper_reference": "[6] 2018",
        "metric": "Logloss (Kaggle)",
        "their_result": "0.0431 (SEA)",
        "baseline_result": "0.0750"
      },
      {
        "method_name": "HYDRA (multimodal DL framework)",
        "paper_reference": "[3] Computers & Security 2020",
        "metric": "Accuracy",
        "their_result": "0.9912 (SEA)",
        "baseline_result": "0.9975"
      },
      {
        "method_name": "HYDRA (multimodal DL framework)",
        "paper_reference": "[3] Computers & Security 2020",
        "metric": "F1 Score",
        "their_result": "0.9908 (SEA)",
        "baseline_result": "0.9951"
      },
      {
        "method_name": "Orthrus (bimodal learning)",
        "paper_reference": "[4] IJCNN 2020",
        "metric": "Accuracy",
        "their_result": "0.9912 (SEA)",
        "baseline_result": "0.9924"
      },
      {
        "method_name": "Orthrus (bimodal learning)",
        "paper_reference": "[4] IJCNN 2020",
        "metric": "F1 Score",
        "their_result": "0.9908 (SEA)",
        "baseline_result": "0.9872"
      },
      {
        "method_name": "Bytes Files Classifier",
        "paper_reference": "[7]",
        "metric": "Accuracy",
        "their_result": "0.9912 (SEA)",
        "baseline_result": "0.9861"
      },
      {
        "method_name": "Bytes Files Classifier",
        "paper_reference": "[7]",
        "metric": "F1 Score",
        "their_result": "0.9908 (SEA)",
        "baseline_result": "0.9719"
      },
      {
        "method_name": "Bytes Files Classifier",
        "paper_reference": "[7]",
        "metric": "Logloss (Kaggle)",
        "their_result": "0.0431 (SEA)",
        "baseline_result": "0.3677"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1 Score",
      "Log loss",
      "ROC-AUC",
      "5-fold cross-validation",
      "Confusion matrix"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Build an efficient (computationally and time-wise) malware classifier and analyze the impact of class imbalance on malware data.",
        "Compare the proposed method against existing state-of-the-art approaches on the same dataset.",
        "Report performance on Kaggle test data for external validation."
      ],
      "gaps_identified": [
        "Signature-based (static) methods struggle with polymorphic and metamorphic malware.",
        "Dynamic analysis may fail on zero-day or new malware families lacking reference metrics.",
        "Need for lightweight malware detection suitable for resource-constrained smart/embedded devices.",
        "Class imbalance in malware family datasets complicates learning minority classes."
      ],
      "limitations": [
        "Hierarchical CNN had slightly better logloss, and HYDRA had slightly better F1 than SEA on reported comparisons.",
        "No deployment or energy consumption evaluation; hardware deployment (e.g., Raspberry Pi/ESP32) and network delay left as future work.",
        "Evaluation limited to a single public dataset (Microsoft BIG 2015) and static opcode modality.",
        "No analysis of adversarial robustness, privacy, or explainability."
      ],
      "future_work": [
        "The other factors such as energy consumption, implementation on hardware devices such as Raspberry Pi or ESP32 and delay in the network are the part of future work.",
        "Combine the proposed model with other models using the average means method."
      ],
      "motivation": "Provide a lightweight yet effective malware classifier for heterogeneous devices (including resource-constrained smart devices) using NLP-inspired techniques, with fast inference and strong accuracy on a benchmark dataset.",
      "potential_research_ideas": [
        "Extend SEA to multimodal inputs by incorporating bytes/entropy images and dynamic behavior (API calls/system calls) alongside opcodes.",
        "Pre-train opcode embeddings with self-supervised objectives (e.g., masked opcode modeling or contrastive learning across variants/families) for improved generalization.",
        "Introduce cost-sensitive/focal/LDAM losses and advanced rebalancing (class-balanced sampling, deferred re-weighting) to further improve minority-family performance.",
        "Adopt efficient Transformer encoders (e.g., Performer/Linear attention/Longformer) with multi-head attention for long opcode sequences while keeping compute low.",
        "Develop explainability tools to visualize attention over opcode spans and correlate with reverse-engineered functions for analyst trust.",
        "Evaluate robustness to adversarial obfuscations (instruction substitution, dead-code insertion, reordering) and propose augmentation defenses.",
        "On-device deployment study with quantization/pruning and compilation to edge accelerators; measure energy/latency on Raspberry Pi/ESP32-class hardware.",
        "Implement open-set/OOD detection for unseen malware families and zero-day detection using energy-based or distance-aware heads.",
        "Model calibration and uncertainty estimation (e.g., temperature scaling, Dirichlet networks) to improve decision thresholds in SOC settings."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment parallel LSTM/GRU with an efficient Transformer backbone using linear-time attention; retain lightweight single-head where necessary.",
        "Use hierarchical sequence modeling (function-level or basic block-level pooling) before global attention to better capture long programs.",
        "Upgrade the attention block to multi-head with gating and attention pooling, while constraining heads for efficiency (e.g., low-rank projections).",
        "Pre-train opcode/token embeddings with domain-specific corpora; initialize SEA with these embeddings and fine-tune.",
        "Incorporate class-balanced/focal loss and mixup/cutmix-style token sequence augmentation (e.g., splice opcode windows) to address imbalance.",
        "Apply model compression (post-training quantization, structured pruning) and knowledge distillation to a tiny SEA student for embedded deployment.",
        "Add OOD/novelty detection head (e.g., Mahalanobis, energy-based) to flag unseen families."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Training on NVIDIA Tesla T4 (16GB RAM). Embedding training: 100 epochs in 16m46s on 1223 samples. Neural network training: 250 epochs in 25 minutes (~10 epochs/min). Real-time processing: 11K samples in 686s (≈0.0124 s per sample); breakdown: 0.05 s embedding extraction, 0.005 s ML helper models, 0.001 s neural network part."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "≈0.0124 seconds per sample (reported); 11K samples in 686s",
      "deployment_challenges": [
        "Energy consumption not evaluated (left as future work).",
        "Deployment on hardware devices such as Raspberry Pi or ESP32 not evaluated (future work).",
        "Network delay considerations left as future work."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Propose SEA: a lightweight sequential embedding-based attentive classifier using parallel LSTM/GRU and self-attention for malware family classification.",
      "Analyze and address class imbalance effects; demonstrate attention helps capture minority-class patterns.",
      "Comprehensive comparison with state-of-the-art methods on Microsoft BIG 2015 dataset.",
      "External validation by Kaggle test submission: Accuracy 0.9912, F1 0.9908, Logloss 0.0431.",
      "Time/compute efficiency analysis with per-sample latency ~0.0124 s and fewer trainable parameters than competitors."
    ]
  },
  {
    "arxiv_id": "2302.12890v1",
    "title": "Edge-Based Detection and Localization of Adversarial Oscillatory Load Attacks Orchestrated By Compromised EV Charging Stations",
    "authors": "Khaled Sarieddine; Mohammad Ali Sayed; Sadegh Torabi; Ribal Atallah; Chadi Assi",
    "abstract": "In this paper, we investigate an edge-based approach for the detection and localization of coordinated oscillatory load attacks initiated by exploited EV charging stations against the power grid. We rely on the behavioral characteristics of the power grid in the presence of interconnected EVCS while combining cyber and physical layer features to implement deep learning algorithms for the effective detection of oscillatory load attacks at the EVCS. We evaluate the proposed detection approach by building a real-time test bed to synthesize benign and malicious data, which was generated by analyzing real-life EV charging data collected during recent years. The results demonstrate the effectiveness of the implemented approach with the Convolutional Long-Short Term Memory model producing optimal classification accuracy (99.4\\%). Moreover, our analysis results shed light on the impact of such detection mechanisms towards building resiliency into different levels of the EV charging ecosystem while allowing power grid operators to localize attacks and take further mitigation measures. Specifically, we managed to decentralize the detection mechanism of oscillatory load attacks and create an effective alternative for operator-centric mechanisms to mitigate multi-operator and MitM oscillatory load attacks against the power grid. Finally, we leverage the created test bed to evaluate a distributed mitigation technique, which can be deployed on public/private charging stations to average out the impact of oscillatory load attacks while allowing the power system to recover smoothly within 1 second with minimal overhead.",
    "published_date": "2023-02-24",
    "pdf_link": "https://arxiv.org/pdf/2302.12890v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Critical Infrastructure Security",
      "subdomain": "Power Grid Security",
      "specific_problem": "Edge-based detection and localization of coordinated oscillatory load attacks launched from compromised EV charging stations (EVCS)",
      "attack_types": [
        "oscillatory load attacks",
        "charging oscillatory attack",
        "multi-operator coordinated attack",
        "slow oscillatory stealthy attack",
        "botnet-driven coordinated switching",
        "MitM on OCPP used to coordinate attacks"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN (ConvLSTM)",
        "specific": "Convolutional LSTM",
        "novel_contribution": "Edge-based deployment at EVCS combining cyber and physical-layer features for early detection (within first 5 seconds) and localization; decentralized, operator-agnostic detection supporting multi-operator scenarios"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "EVCS oscillatory attack testbed dataset",
        "type": "synthetic",
        "domain": "EVCS logs and power grid measurements (cyber-physical features) from a real-time testbed",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Real-life EV charging data (analyzed for synthesis)",
        "type": "proprietary",
        "domain": "EV charging session/usage data",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Kabir et al. CMS-based backpropagation neural network detection (public EVCS)",
        "paper_reference": "Kabir et al. [21] (as cited in this paper)",
        "metric": "False Negative Rate for 20-second prompt attacks",
        "their_result": null,
        "baseline_result": "about 30% false-negative rate"
      }
    ],
    "performance_metrics_used": [
      "classification accuracy (99.4%)",
      "precision (reported as high)",
      "detection latency (detect within first 5 seconds of the attack)",
      "system recovery time after mitigation (~1 second)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can oscillatory load attacks initiated by compromised EVCS be detected accurately at the edge (on the EVCS) using hybrid cyber-physical features?",
        "Can such edge-based detection enable localization to the granularity of individual charging stations and support attribution for operators and utilities?",
        "Can decentralized detection mitigate limitations of centralized CMS-based approaches (e.g., multi-operator attacks, MitM on OCPP)?",
        "Can a lightweight distributed mitigation reduce grid oscillations and allow fast recovery while preserving user QoS?"
      ],
      "gaps_identified": [
        "Centralized CMS detection mechanisms are single points of failure and can be evaded (e.g., via CMS compromise or MitM on OCPP)",
        "Physical-layer detection may detect only the impact and cannot localize attacks to specific consumer loads/EVCS",
        "Utilities lack real-time observability of individual consumer loads, hindering localization of EVCS-initiated attacks",
        "Prior work focused on specific oscillatory attacks and reported high false-negative rate for short (20s) attacks",
        "Existing literature lacks mechanisms to localize attacks to particular physical locations/charging stations"
      ],
      "limitations": [
        "Work focuses on charging oscillatory attacks; discharging/V2G is left for future studies (\"we focus on the charging oscillatory attacks, whereas future studies could include the discharging paradigm, vehicle-to-grid (V2G)\")"
      ],
      "future_work": [
        "Extend detection and mitigation to include discharging oscillatory attacks and V2G scenarios"
      ],
      "motivation": "Protect the power grid from coordinated oscillatory load attacks launched via vulnerable EVCS by providing resilient, fault-tolerant, decentralized detection and localization that overcomes limitations of centralized CMS and pure physical-layer methods.",
      "potential_research_ideas": [
        "Extend to discharging/V2G oscillatory attacks and mixed charging–discharging attack scenarios",
        "Create and release a standardized, multi-operator EVCS cyber-physical dataset for oscillatory attacks to enable benchmarking",
        "Investigate federated or collaborative learning across EVCS operators to improve detection while preserving privacy",
        "Evaluate robustness against adaptive adversaries (e.g., slow/variable-period oscillations, coordinated phase shifts, mimicry of benign patterns) and develop adversarial training defenses",
        "Incorporate explainability methods to attribute decisions to specific cyber/physical features for operator trust and forensics",
        "Develop online/continual learning to handle concept drift in EV usage patterns and seasonal grid behavior",
        "Integrate edge detection with grid-level PMU/SCADA signals via multi-modal fusion for earlier warnings and cross-validation",
        "Explore unsupervised/self-supervised pretraining on large volumes of benign EVCS data to reduce labeled data requirements"
      ],
      "architectural_improvement_recommendations": [
        "Augment ConvLSTM with temporal attention or Transformer encoders for long-range temporal dependencies",
        "Model cross-station correlations with graph neural networks (GNNs) when limited peer metadata is shareable (e.g., neighborhood or feeder topology)",
        "Adopt multi-task learning to jointly classify attack presence and estimate attack parameters (period, amplitude) for better mitigation control",
        "Use uncertainty estimation (e.g., Monte Carlo dropout or deep ensembles) to calibrate decisions and adjust mitigation aggressiveness",
        "Apply lightweight model compression/quantization and early-exit heads for strict edge resource constraints",
        "Introduce adversarial training and data augmentation that emulate slow/phase-shifted oscillations and mixed benign/attack patterns"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Edge-deployable; detection based on first ~5 seconds of activity; distributed mitigation adds up to 4s random delay per station; real-time testbed used for evaluation"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Edge deployment on public/private EV charging stations (EVCS)",
      "scalability_discussed": true,
      "inference_time": "Detects attacks by viewing the first 5 seconds of activity",
      "deployment_challenges": [
        "Heterogeneous multi-operator ecosystem with limited utility observability",
        "Centralized CMS approaches are single points of failure and vulnerable to MitM on OCPP",
        "Maintaining user QoS while mitigating attacks (random delay block up to 4 seconds)",
        "Need for localization to specific EVCS for actionable response by operators/utilities"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Edge-based deep learning detection and localization of EVCS-orchestrated oscillatory load attacks enabling decentralized, fault-tolerant decisions",
      "Creation of a real-time testbed and synthesis of benign/malicious data informed by analysis of real-life EV charging data",
      "ConvLSTM-based classifier with reported \"optimal classification accuracy (99.4%)\" and early detection using the first 5 seconds of an attack",
      "Operator-agnostic deployment that can handle multi-operator and MitM OCPP scenarios, including attacks from private charging stations",
      "Distributed, lightweight mitigation (random delay up to 4 seconds per station) that \"allow[s] the power system to recover smoothly within 1 second with minimal overhead\""
    ]
  },
  {
    "arxiv_id": "2301.03368v1",
    "title": "DRL-GAN: A Hybrid Approach for Binary and Multiclass Network Intrusion Detection",
    "authors": "Caroline Strickland; Chandrika Saha; Muhammad Zakar; Sareh Nejad; Noshin Tasnim; Daniel Lizotte; Anwar Haque",
    "abstract": "Our increasingly connected world continues to face an ever-growing amount of network-based attacks. Intrusion detection systems (IDS) are an essential security technology for detecting these attacks. Although numerous machine learning-based IDS have been proposed for the detection of malicious network traffic, the majority have difficulty properly detecting and classifying the more uncommon attack types. In this paper, we implement a novel hybrid technique using synthetic data produced by a Generative Adversarial Network (GAN) to use as input for training a Deep Reinforcement Learning (DRL) model. Our GAN model is trained with the NSL-KDD dataset for four attack categories as well as normal network flow. Ultimately, our findings demonstrate that training the DRL on specific synthetic datasets can result in better performance in correctly classifying minority classes over training on the true imbalanced dataset.",
    "published_date": "2023-01-05",
    "pdf_link": "https://arxiv.org/pdf/2301.03368v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Network intrusion detection for binary (benign vs attack) and multiclass (Normal, DoS, Probe, R2L, U2R) classification under class imbalance",
      "attack_types": [
        "DoS",
        "Probe",
        "R2L",
        "U2R"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Deep Reinforcement Learning",
        "specific": null,
        "novel_contribution": "DRL-based IDS trained on GAN-generated synthetic tabular data to improve minority-class detection; custom action/reward design for both binary and multiclass IDS"
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "CTGAN (conditional and unconditional)",
        "novel_contribution": "Used to generate class-balanced synthetic tabular traffic for NSL-KDD to mitigate minority-class scarcity"
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "copulaGAN (conditional and unconditional)",
        "novel_contribution": "Alternative tabular GAN to generate synthetic NSL-KDD data; compared to CTGAN for training DRL"
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Synthetic NSL-KDD (CTGAN)",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Synthetic NSL-KDD (copulaGAN)",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "DRL trained on original imbalanced NSL-KDD (no synthetic augmentation)",
        "paper_reference": null,
        "metric": "F1-score (per-class), Accuracy",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "Weighted F1-score",
      "ROC AUC (for synthetic/real detectability metric, reported as 1 - AUC)",
      "CSTest (avg p-values for discrete columns)",
      "KSTest (1 - D statistic for continuous columns)",
      "KSTestExtended"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does training a DRL IDS on GAN-generated synthetic datasets improve minority-class detection (precision/recall/F1) compared to training on the original imbalanced NSL-KDD?",
        "Is a hybrid GAN + DRL framework viable for both binary and multiclass network intrusion detection?",
        "How statistically similar and hard-to-distinguish are the synthetic tabular datasets compared to real NSL-KDD data (via CSTest/KSTest/detection metrics)?"
      ],
      "gaps_identified": [
        "ML-based IDS often fail to properly detect and classify uncommon (minority) attack types.",
        "Existing public datasets are imbalanced, lack traffic diversity, and become outdated; reliable data sharing is limited by privacy concerns.",
        "Generating realistic tabular network data is challenging due to categorical features (GANs typically handle continuous attributes better)."
      ],
      "limitations": [
        "Reward function assigns equal penalty (-1) for false negatives and false positives/misclassification of attack types, despite differing operational costs in security.",
        "Evaluation limited to a single benchmark dataset (NSL-KDD)."
      ],
      "future_work": [],
      "motivation": "Improve IDS performance for underrepresented (minority) attack classes by synthesizing additional data with GANs and training a DRL-based IDS on these balanced synthetic datasets.",
      "potential_research_ideas": [
        "Evaluate the GAN+DRL framework on contemporary, more realistic intrusion datasets and cross-dataset generalization to measure robustness to dataset shift.",
        "Incorporate differential privacy into tabular GANs to safely synthesize shareable datasets for IDS research.",
        "Explore diffusion models or VAEs for tabular network data synthesis and compare against CTGAN/copulaGAN.",
        "Design cost-sensitive or asymmetric reward DRL to reflect operational priorities (higher cost for missed attacks than false alarms).",
        "Add online/continual learning to adapt DRL policies to evolving traffic and novel attacks (concept drift).",
        "Leverage class-conditional generation with explicit per-attack-type controls to target hard minority subclasses (e.g., U2R variants).",
        "Adversarial training against IDS-evasion samples (e.g., IDSGAN-style adversarial traffic) to harden DRL policies.",
        "Use self-supervised pretraining on unlabeled traffic to improve DRL feature representations before policy learning.",
        "Incorporate explainability methods (e.g., SHAP for tabular data) to interpret DRL decisions and guide data augmentation."
      ],
      "architectural_improvement_recommendations": [
        "Specify and compare DRL algorithms (e.g., DQN, Double DQN, Dueling DQN, PPO, A2C) and use prioritized replay and target networks for stability.",
        "Adopt WGAN-GP or CTAB-GAN+ for improved tabular synthesis, especially for mixed continuous/categorical features.",
        "Introduce class-weighted rewards or risk-sensitive RL (CVaR) to better calibrate false negatives vs false positives.",
        "Employ feature embedding layers for categorical variables and normalization pipelines consistent between GAN and DRL.",
        "Add a calibration stage (e.g., temperature scaling) to control alert thresholds and reduce false positives in deployment.",
        "Use domain adaptation or adversarial invariance to reduce dataset bias between synthetic and real traffic during DRL training."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Dataset shift and obsolescence of public IDS datasets over time",
        "Severe class imbalance leading to poor minority attack detection",
        "Privacy constraints limiting sharing of realistic traffic data",
        "Difficulty modeling categorical network features in generative models"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Using both conditional and unconditional CTGAN and copulaGAN models to generate tabular data for minority-class balancing and large-scale training.",
      "Combining GAN and DRL techniques for network intrusion detection to increase precision and recall for underrepresented classes via a pipeline that trains GANs to synthesize data and a DRL model as an IDS for binary and multiclass classification."
    ]
  },
  {
    "arxiv_id": "2301.06799v1",
    "title": "Utilization of Impedance Disparity Incurred from Switching Activities to Monitor and Characterize Firmware Activities",
    "authors": "Md Sadik Awal; Christopher Thompson; Md Tauhidur Rahman",
    "abstract": "The massive trend toward embedded systems introduces new security threats to prevent. Malicious firmware makes it easier to launch cyberattacks against embedded systems. Systems infected with malicious firmware maintain the appearance of normal firmware operation but execute undesirable activities, which is usually a security risk. Traditionally, cybercriminals use malicious firmware to develop possible back-doors for future attacks. Due to the restricted resources of embedded systems, it is difficult to thwart these attacks using the majority of contemporary standard security protocols. In addition, monitoring the firmware operations using existing side channels from outside the processing unit, such as electromagnetic radiation, necessitates a complicated hardware configuration and in-depth technical understanding. In this paper, we propose a physical side channel that is formed by detecting the overall impedance changes induced by the firmware actions of a central processing unit. To demonstrate how this side channel can be exploited for detecting firmware activities, we experimentally validate it using impedance measurements to distinguish between distinct firmware operations with an accuracy of greater than 90%. These findings are the product of classifiers that are trained via machine learning. The implementation of our proposed methodology also leaves room for the use of hardware authentication.",
    "published_date": "2023-01-17",
    "pdf_link": "https://arxiv.org/pdf/2301.06799v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Side-channel Analysis for Embedded/IoT Devices",
      "specific_problem": "Monitoring and classifying firmware activities on microcontrollers via impedance-based side-channel to detect anomalous/malicious behavior",
      "attack_types": [
        "firmware-based attacks",
        "malware",
        "botnet",
        "backdoor"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "SVM",
        "specific": "Gaussian/RBF-kernel SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Cubic-kernel SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Quadratic-kernel SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Discriminant Analysis",
        "specific": "Quadratic Discriminant Analysis (QDA)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "KNN",
        "specific": "Subspace KNN",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Dimensionality Reduction",
        "specific": "PCA (retain 95% variance; 34 principal components)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Feature Selection",
        "specific": "Correlation-based frequency selection and decorrelation (Pearson correlation + linear independence)",
        "novel_contribution": "Two-stage selection from 10,000 VNA points to 338 dominant frequencies (3.38% of band) based on correlation with activity and inter-frequency correlation"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised (PCA for feature extraction)"
    ],
    "datasets": [
      {
        "name": "Impedance-based side-channel measurements on Arduino Due (4 firmware cases, 1,780 observations)",
        "type": "proprietary",
        "domain": "side_channel_impedance",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SVM (Gaussian kernel)",
        "paper_reference": null,
        "metric": "Test Accuracy / F1 / Precision / Recall / Specificity",
        "their_result": "\"Accuracy 93.6%, F1 93.7%, Precision 93.9%, Recall 93.6%, Specificity 97.9%\"",
        "baseline_result": null
      },
      {
        "method_name": "SVM (Cubic kernel)",
        "paper_reference": null,
        "metric": "Test Accuracy / F1 / Precision / Recall / Specificity",
        "their_result": "\"Accuracy 93.3%, F1 93.3%, Precision 93.7%, Recall 93.2%, Specificity 97.7%\"",
        "baseline_result": null
      },
      {
        "method_name": "SVM (Quadratic kernel)",
        "paper_reference": null,
        "metric": "Test Accuracy / F1 / Precision / Recall / Specificity",
        "their_result": "\"Accuracy 91.8%, F1 91.8%, Precision 92.2%, Recall 91.7%, Specificity 97.2%\"",
        "baseline_result": null
      },
      {
        "method_name": "Quadratic Discriminant Analysis",
        "paper_reference": null,
        "metric": "Test Accuracy / F1 / Precision / Recall / Specificity",
        "their_result": "\"Accuracy 91.4%, F1 91.5%, Precision 91.7%, Recall 91.4%, Specificity 97.1%\"",
        "baseline_result": null
      },
      {
        "method_name": "Subspace KNN",
        "paper_reference": null,
        "metric": "Test Accuracy / F1 / Precision / Recall / Specificity",
        "their_result": "\"Accuracy 90.8%, F1 90.9%, Precision 91.2%, Recall 90.8%, Specificity 96.9%\"",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "Specificity",
      "F1 score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can the effective impedance changes induced by firmware-driven switching activities be used as a side-channel to monitor/identify firmware operations on an MCU?",
        "Do distinct firmware activities produce distinguishable impedance signatures that enable supervised classification with high accuracy?"
      ],
      "gaps_identified": [
        "Resource-constrained embedded devices make it difficult to apply standard security protocols to thwart firmware attacks.",
        "Existing external side-channels (e.g., EM radiation) typically require complicated hardware configuration and in-depth technical understanding."
      ],
      "limitations": [],
      "future_work": [
        "\"The implementation of our proposed methodology also leaves room for the use of hardware authentication.\""
      ],
      "motivation": "Provide a lower-overhead, externally observable side-channel (impedance disparity) to monitor and characterize firmware activities on resource-constrained embedded/IoT devices without invasive modification or complex EM setups.",
      "potential_research_ideas": [
        "Create and release a large-scale, multi-device impedance side-channel dataset spanning diverse MCUs, workloads, and environmental conditions.",
        "Develop real-time, low-cost impedance sensing hardware (e.g., custom RF front-end or impedance analyzer) to replace laboratory VNA for field deployment.",
        "Investigate transfer learning and domain adaptation to generalize models across device types, boards, and power delivery networks.",
        "Fuse multiple side-channels (impedance + EM + power/current) to improve robustness and detection accuracy of malicious firmware.",
        "Assess resilience against adversarial manipulation (e.g., malware attempting to mimic benign impedance signatures) and design defenses.",
        "Model temporal dynamics using sequence models (e.g., HMMs, temporal CNNs, Transformers) over frequency-time signatures for continuous monitoring.",
        "Perform per-instruction or per-function-level attribution to localize anomalous execution segments and enable explainability.",
        "Integrate the approach with remote attestation frameworks to provide continuous run-time verification signals."
      ],
      "architectural_improvement_recommendations": [
        "Replace VNA with an embedded impedance-sensing module (swept-frequency excitation + reflectometry) and edge ML inference on a microcontroller or SBC.",
        "Adopt end-to-end feature learning with deep models (e.g., 1D CNNs on raw or log-magnitude spectra) and compare to PCA+SVM.",
        "Use more principled feature selection (mutual information, mRMR) and regularization to reduce sensor bandwidth while maintaining accuracy.",
        "Calibrate and normalize for environmental and power-supply variations (reference channels, differential measurements) to enhance robustness.",
        "Implement multi-task learning to jointly classify activity type and detect anomalies, improving sensitivity to malicious behavior.",
        "Leverage few-shot/metric learning to enable rapid onboarding of new devices without extensive labeled data."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/ChristopherThompsonUT/ArduinoRepo",
      "frameworks": [
        "MATLAB"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Embedded microcontroller (Arduino Due) lab setup with VNA connected via capacitor to 3.3V rail",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces an impedance-based physical side-channel for monitoring and characterizing firmware activities on MCUs.",
      "Experimental validation on Arduino Due using VNA-derived reflection coefficients converted to impedance; four firmware cases; total 1,780 observations.",
      "Two-stage frequency selection reducing 10,000 VNA points to 338 dominant frequencies (3.38% of band) via Pearson correlation and inter-frequency decorrelation.",
      "Dimensionality reduction with PCA (34 components explain 95% variance) and supervised classifiers achieving >90% test accuracy; best reported: \"Accuracy 93.6%, F1 93.7%\" with Gaussian SVM.",
      "Suggests applicability to hardware authentication as future extension."
    ]
  },
  {
    "arxiv_id": "2303.12947v1",
    "title": "Deep Attention Recognition for Attack Identification in 5G UAV scenarios: Novel Architecture and End-to-End Evaluation",
    "authors": "Joseanne Viana; Hamed Farkhari; Pedro Sebastiao; Luis Miguel Campos; Katerina Koutlia; Biljana Bojovic; Sandra Lagen; Rui Dinis",
    "abstract": "Despite the robust security features inherent in the 5G framework, attackers will still discover ways to disrupt 5G unmanned aerial vehicle (UAV) operations and decrease UAV control communication performance in Air-to-Ground (A2G) links. Operating under the assumption that the 5G UAV communications infrastructure will never be entirely secure, we propose Deep Attention Recognition (DAtR) as a solution to identify attacks based on a small deep network embedded in authenticated UAVs. Our proposed solution uses two observable parameters: the Signal-to-Interference-plus-Noise Ratio (SINR) and the Reference Signal Received Power (RSSI) to recognize attacks under Line-of-Sight (LoS), Non-Line-of-Sight (NLoS), and a probabilistic combination of the two conditions. In the tested scenarios, a number of attackers are located in random positions, while their power is varied in each simulation. Moreover, terrestrial users are included in the network to impose additional complexity on attack detection. To improve the systems overall performance in the attack scenarios, we propose complementing the deep network decision with two mechanisms based on data manipulation and majority voting techniques. We compare several performance parameters in our proposed Deep Network. For example, the impact of Long Short-Term-Memory (LSTM) and Attention layers in terms of their overall accuracy, the window size effect, and test the accuracy when only partial data is available in the training process. Finally, we benchmark our deep network with six widely used classifiers regarding classification accuracy. Our algorithms accuracy exceeds 4% compared with the eXtreme Gradient Boosting (XGB) classifier in LoS condition and around 3% in the short distance NLoS condition. Considering the proposed deep network, all other classifiers present lower accuracy than XGB.",
    "published_date": "2023-03-03",
    "pdf_link": "https://arxiv.org/pdf/2303.12947v1",
    "paper_types": [
      "empirical_analysis",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Wireless and Mobile Security",
      "subdomain": "Jamming and Interference Detection",
      "specific_problem": "Attack (jamming) identification on 5G UAV Air-to-Ground links using receiver-side SINR/RSSI time-series under LoS/NLoS/hybrid conditions",
      "attack_types": [
        "jamming",
        "wireless denial-of-service",
        "RF interference"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN + Attention",
        "specific": "DAtR (Deep Attention Recognition), Multi-Headed DNN with attention",
        "novel_contribution": "Convolutional-attention architecture for UAV jamming detection under LoS, NLoS, and probabilistic hybrid conditions; <100k trainable parameters; tolerates incomplete raw inputs (SINR/RSSI only)"
      },
      {
        "type": "primary",
        "category": "Data augmentation",
        "specific": "Time-Series Augmentation (TSA)",
        "novel_contribution": "Proposed complementary data manipulation to improve classification accuracy and robustness with limited/partial training data"
      },
      {
        "type": "primary",
        "category": "Ensemble/Post-processing",
        "specific": "Majority Voting Algorithm (MVA)",
        "novel_contribution": "Proposed complementary voting mechanism to reduce false alarms and stabilize decisions over windows"
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting",
        "specific": "XGBoost (XGB)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting",
        "specific": "CatBoost (CAT)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": "RF",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Support Vector Machine",
        "specific": "SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": "LR",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Naive Bayes",
        "specific": "Gaussian Naive Bayes (GNB)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM layers within MH-DNN variant",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "LoS dataset (SINR/RSSI time-series for UAV jamming identification)",
        "type": "synthetic",
        "domain": "wireless_signal_metrics",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "NLoS dataset (SINR/RSSI time-series for UAV jamming identification)",
        "type": "synthetic",
        "domain": "wireless_signal_metrics",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Hybrid LoS/NLoS dataset (probabilistic mix per 3GPP model)",
        "type": "synthetic",
        "domain": "wireless_signal_metrics",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "XGBoost (XGB)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "“accuracy exceeds 4% compared with the eXtreme Gradient Boosting (XGB) classifier in LoS condition and around 3% in the short distance NLoS condition.”",
        "baseline_result": "XGB lower by 4% (LoS) and ~3% (short-distance NLoS) than DAtR (exact values not provided)"
      },
      {
        "method_name": "CatBoost (CAT)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "DAtR outperforms CAT; exact numbers not provided",
        "baseline_result": "Lower accuracy than XGB and DAtR (exact values not provided)"
      },
      {
        "method_name": "Random Forest (RF)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "DAtR outperforms RF; exact numbers not provided",
        "baseline_result": "Lower accuracy than XGB and DAtR (exact values not provided)"
      },
      {
        "method_name": "Support Vector Machine (SVM)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "DAtR outperforms SVM; exact numbers not provided",
        "baseline_result": "Lower accuracy than XGB and DAtR (exact values not provided)"
      },
      {
        "method_name": "Logistic Regression (LR)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "DAtR outperforms LR; exact numbers not provided",
        "baseline_result": "Lower accuracy than XGB and DAtR (exact values not provided)"
      },
      {
        "method_name": "Gaussian Naive Bayes (GNB)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "DAtR outperforms GNB; exact numbers not provided",
        "baseline_result": "Lower accuracy than XGB and DAtR (exact values not provided)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Latency (accuracy-latency tradeoff discussed)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a small deep network using only SINR and RSSI identify jamming attacks on 5G UAV A2G links under LoS, NLoS, and hybrid conditions?",
        "What is the impact of LSTM vs Attention layers on overall accuracy for this task?",
        "How does input window size affect accuracy and latency?",
        "How robust is the model when only partial data is available for training?",
        "Do complementary mechanisms (Time-Series Augmentation and Majority Voting) improve accuracy and reduce false alarms?",
        "How does the proposed deep network compare against six widely used machine learning classifiers?"
      ],
      "gaps_identified": [
        "“the majority of research does not account for the effects of the wireless propagation channel in their solutions.”",
        "Collecting complete wireless parameters for DL input is challenging; models must tolerate missing/out-of-range values.",
        "UAVs impose strict constraints on memory, CPU, battery; complex DL models may be impractical onboard.",
        "Training data for all potential network conditions is hard to collect; models should support adding samples after encountering new patterns.",
        "Need for careful design of DL data formats and normalization for heterogeneous wireless parameters."
      ],
      "limitations": [
        "Evaluation is simulation-based using 3GPP CDL-A/D channel models; no real-world field trials reported.",
        "Assumes UAV is effectively an ideal ‘flying antenna’ with optimal placement and single-antenna elements.",
        "Assumes the connection link persists throughout simulations even at low SINR.",
        "Focuses on jamming identification using only two observable parameters (SINR and RSSI).",
        "Urban microcell 1 km × 1 km scenario; generalization to other deployments not empirically validated.",
        "Exact computational latency numbers and hardware profiles are not provided in the excerpt."
      ],
      "future_work": [],
      "motivation": "UAVs operating over 5G A2G links remain vulnerable to jamming; a self-identifying onboard solution is needed that is robust to propagation effects, resource-constrained, tolerant to missing data, and effective with limited measurements.",
      "potential_research_ideas": [
        "Extend inputs beyond SINR/RSSI to include RSRP/RSRQ, CQI, and limited CSI to improve separability under NLoS.",
        "Online/continual learning on UAVs with experience replay to adapt to new jammer strategies and environments.",
        "Federated learning among UAVs and ground stations to share model updates without raw data transfer.",
        "Adversarial robustness analysis and defenses for signal-level perturbations and model evasion.",
        "Field trials with SDR-based prototypes to validate under real urban multipath and mobility.",
        "Multi-task learning to jointly classify attack presence, attack power level, and jammer count.",
        "Create and release a standardized public dataset for 5G UAV jamming detection with LoS/NLoS labels.",
        "Unsupervised or self-supervised pretraining on unlabeled flight telemetry to reduce labeled data needs.",
        "Bayesian uncertainty estimation for calibrated alarms and human-in-the-loop responses.",
        "Lightweight model compression (quantization, pruning, distillation) targeting specific UAV hardware."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment CNN with Temporal Convolutional Networks (dilated causal convolutions) for longer-range temporal context at low cost.",
        "Adopt efficient attention (Performer/Linear Attention) with positional encodings to handle variable window sizes and reduce latency.",
        "Introduce masking and learnable imputation layers to explicitly handle missing/irregular samples in SINR/RSSI streams.",
        "Incorporate multi-head self-attention across features and time with residual connections and layer normalization for stability.",
        "Use knowledge distillation from a larger teacher (Transformer/TCN) into the <100k parameter student for accuracy gains.",
        "Quantization-aware training and post-training quantization to INT8 for embedded deployment.",
        "Early-exit branches with confidence-based stopping to meet latency budgets under benign conditions.",
        "Probabilistic (Bayesian) last layers for uncertainty estimation and calibrated decision thresholds.",
        "Multi-modal fusion if additional features (e.g., Doppler, mobility state, neighbor cell measurements) become available."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "<100k trainable parameters; designed for embedded/onboard inference on UAV with constrained CPU/battery; accuracy–latency tradeoff analyzed (no specific hardware reported)"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Onboard UAV receiver over 5G A2G link in urban microcell scenario",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Limited onboard memory/CPU/battery for UAVs",
        "Missing or noisy wireless measurements due to stochastic channels",
        "Need to minimize added latency while maintaining accuracy",
        "Heterogeneous and dynamic LoS/NLoS conditions",
        "Risk of false alarms; need for robust thresholding/majority voting",
        "Generalization from simulation to real-world environments"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Novel convolutional-attention deep network (DAtR) for UAV jamming detection under LoS, NLoS, and hybrid conditions, tolerant to incomplete raw inputs.",
      "Study of deep architectures (LSTM vs Attention) for 5G UAV communication data.",
      "Two complementary methods: Time-Series Augmentation (TSA) and Majority Voting Algorithm (MVA) to improve accuracy and reduce false alarms.",
      "Accuracy benchmarking against six widely used classifiers; DAtR outperforms XGB by 4% (LoS) and ~3% (short-distance NLoS).",
      "Analysis of accuracy–latency tradeoffs for attack identification."
    ]
  },
  {
    "arxiv_id": "2301.10802v1",
    "title": "NASCTY: Neuroevolution to Attack Side-channel Leakages Yielding Convolutional Neural Networks",
    "authors": "Fiske Schijlen; Lichao Wu; Luca Mariot",
    "abstract": "Side-channel analysis (SCA) can obtain information related to the secret key by exploiting leakages produced by the device. Researchers recently found that neural networks (NNs) can execute a powerful profiling SCA, even on targets protected with countermeasures. This paper explores the effectiveness of Neuroevolution to Attack Side-channel Traces Yielding Convolutional Neural Networks (NASCTY-CNNs), a novel genetic algorithm approach that applies genetic operators on architectures' hyperparameters to produce CNNs for side-channel analysis automatically. The results indicate that we can achieve performance close to state-of-the-art approaches on desynchronized leakages with mask protection, demonstrating that similar neuroevolution methods provide a solid venue for further research. Finally, the commonalities among the constructed NNs provide information on how NASCTY builds effective architectures and deals with the applied countermeasures.",
    "published_date": "2023-01-25",
    "pdf_link": "https://arxiv.org/pdf/2301.10802v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Side-channel Analysis",
      "specific_problem": "Profiling power side-channel attack against AES using automatically evolved CNN architectures, including masked and desynchronized leakages",
      "attack_types": [
        "power side-channel (profiling SCA)",
        "masking countermeasure (Boolean masking)",
        "desynchronization (random temporal shifts)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Neuroevolution / Genetic Algorithm (NAS)",
        "specific": "NASCTY-CNNs using tournament selection and polynomial mutation (nonmating GA)",
        "novel_contribution": "Genetic algorithm that evolves CNN hyperparameters for SCA; genome encodes up to 5 conv blocks (filters, kernel size, batch norm, pooling) and 1–5 dense layers; automated search tailored to SCA fitness based on guessing entropy/key rank."
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D CNN for side-channel traces with SELU activations; He init for hidden layers; Glorot uniform for softmax output",
        "novel_contribution": "Architectures are automatically discovered by GA; analysis of common structural patterns that handle masking and desynchronization."
      },
      {
        "type": "baseline",
        "category": "Loss/Optimization setup",
        "specific": "Categorical Cross-Entropy (CCE) loss; gradient descent training of candidate CNNs",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "AutoML/Neuroevolution"
    ],
    "datasets": [
      {
        "name": "ASCAD (fixed-key, masked)",
        "type": "public",
        "domain": "side_channel_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ASCAD (fixed-key, masked) with simulated desynchronization",
        "type": "public",
        "domain": "side_channel_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "key rank",
      "guessing entropy (mean key rank)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a genetic algorithm automatically discover high-performing CNN architectures for profiling SCA on masked and desynchronized traces?",
        "What architectural components (e.g., number/size of conv filters, pooling, batch normalization, dense depth) are common among well-performing CNNs for SCA?",
        "How close can GA-designed CNNs get to state-of-the-art performance on desynchronized masked leakages?"
      ],
      "gaps_identified": [
        "Designing NN architectures for SCA is largely empirical; architectures vary even on the same dataset and may not transfer across targets.",
        "Reinforcement learning-based NAS for SCA requires considerable compute and a predefined architecture description.",
        "Bayesian optimization requires choices of surrogate model and acquisition function; overall optimality remains uncertain."
      ],
      "limitations": [
        "Evaluation limited to the fixed-key ASCAD dataset targeting the third masked key byte with 700-point traces.",
        "Only identity leakage model is considered; classes are balanced via sampling.",
        "Fitness evaluation uses the same sampled training/validation data across generations, which may bias the search.",
        "Focus on CNN architectures; MLPs are not explored within NASCTY experiments in the described sections."
      ],
      "future_work": [
        "The paper suggests that similar neuroevolution methods are a solid venue for further research (exploring broader neuroevolution for SCA)."
      ],
      "motivation": "Automate the design/tuning of neural network architectures for profiling SCA to reduce manual effort and overcome limitations of RL and Bayesian optimization approaches, while approaching state-of-the-art performance on protected leakages.",
      "potential_research_ideas": [
        "Validate NASCTY across multiple SCA datasets, devices, and countermeasures (e.g., higher-order masking, jitter/noise) and study cross-target transferability.",
        "Formulate a multi-objective GA optimizing attack success (guessing entropy) alongside model size, inference time, and training cost.",
        "Co-evolve data preprocessing/augmentation (alignment, window selection, jitter simulation) jointly with network architecture.",
        "Incorporate crossover, speciation/island models, and self-adaptive mutation rates to improve search efficiency and diversity.",
        "Search over broader architectural elements: residual/skip connections, dilated/atrous conv, depthwise separable conv, and attention for 1D signals.",
        "Use early-stop surrogate fitness (e.g., learning-curve extrapolation) or information-theoretic leakage proxies to reduce evaluation cost.",
        "Investigate transfer/neural weight-sharing NAS (e.g., ENAS-style) to cut compute while maintaining performance."
      ],
      "architectural_improvement_recommendations": [
        "Extend the search space to include activation functions, optimizers, learning-rate schedules, dropout rates, and normalization placement.",
        "Add residual connections and multi-scale convolutional branches to better capture desynchronization effects.",
        "Introduce learnable alignment or temporal attention layers before/within CNN to handle misalignment.",
        "Adopt weight-sharing NAS or partial training with learning-curve extrapolation to accelerate fitness evaluation.",
        "Jointly search input windowing (trace cropping) and feature extractor depth/width to optimize receptive fields."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Need for a profiling (clone) device and labeled traces to train models.",
        "Compute budget for evolutionary search can be nontrivial due to repeated training/evaluation of candidate CNNs.",
        "Potential limited transferability across devices/implementations due to device-specific leakage characteristics.",
        "Variability of countermeasures (masking/desynchronization levels) may require re-running NAS per target."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A genetic algorithm-based methodology (NASCTY-CNNs) for automated hyperparameter tuning of CNNs for profiling side-channel analysis.",
      "Empirical evaluation on masked ASCAD traces, including desynchronization, showing performance close to state-of-the-art approaches.",
      "Analysis of commonalities among evolved CNNs, providing insights into effective architectural choices for countermeasure-resilient SCA."
    ]
  },
  {
    "arxiv_id": "2301.09892v1",
    "title": "Learning Effective Strategies for Moving Target Defense with Switching Costs",
    "authors": "Vignesh Viswanathan; Megha Bose; Praveen Paruchuri",
    "abstract": "Moving Target Defense (MTD) has emerged as a key technique in various security applications as it takes away the attacker's ability to perform reconnaissance for exploiting a system's vulnerabilities. However, most of the existing research in the field assumes unrealistic access to information about the attacker's motivations and/or actions when developing MTD strategies. Many of the existing approaches also assume complete knowledge regarding the vulnerabilities of a system and how each of these vulnerabilities can be exploited by an attacker. In this work, we aim to create algorithms that generate effective Moving Target Defense strategies that do not rely on prior knowledge about the attackers. Our work assumes that the only way the defender receives information about its own reward is via interaction with the attacker in a repeated game setting. Depending on the amount of information that can be obtained from the interactions, we devise two different algorithms using multi-armed bandit formulation to identify efficient strategies. We then evaluate our algorithms using data mined from the National Vulnerability Database to showcase that they match the performance of the state-of-the-art techniques, despite using a lot less amount of information.",
    "published_date": "2023-01-24",
    "pdf_link": "https://arxiv.org/pdf/2301.09892v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software and Application Security",
      "subdomain": "Moving Target Defense",
      "specific_problem": "Learning switching strategies for Moving Target Defense under uncertainty and switching costs in repeated attacker-defender games",
      "attack_types": [
        "exploitation of software vulnerabilities",
        "adaptive adversary behavior"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Bandit/Online Learning",
        "specific": "Follow-the-Perturbed-Leader (FPL) with Geometric Resampling",
        "novel_contribution": "FPL-MTD: adapts FPL to MTD by explicitly incorporating switching costs in the selection rule and uses Geometric Resampling to estimate inverse selection probabilities under bandit feedback"
      },
      {
        "type": "primary",
        "category": "Bandit/Online Learning",
        "specific": "FPL variant (Max-Min)",
        "novel_contribution": "FPL-MaxMin: a variant that leverages prior knowledge about vulnerabilities/attacker types to improve selection, tailored for cases with partial prior information"
      },
      {
        "type": "baseline",
        "category": "Game-Theoretic",
        "specific": "Strong Stackelberg Equilibrium (SSE) in Bayesian Stackelberg Games",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": "Model-free RL approaches for MTD switching",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Evolutionary Algorithms",
        "specific": "Genetic Algorithms for MTD switching",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Bandit/Online Learning",
        "specific": "Exp3 / FPL+GR (discussed theoretical references)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Online Learning",
      "Adversarial Bandits"
    ],
    "datasets": [
      {
        "name": "National Vulnerability Database (NVD)",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://nvd.nist.gov",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Strong Stackelberg Equilibrium (SSE)-based switching strategy for MTD",
        "paper_reference": "[1],[7],[8] (as cited in paper)",
        "metric": "Total utility (defender reward minus switching costs)",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Reinforcement Learning-based MTD switching",
        "paper_reference": "[7],[11] (as cited in paper)",
        "metric": "Total utility (defender reward minus switching costs)",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Genetic Algorithm-based MTD switching",
        "paper_reference": "[9],[10] (as cited in paper)",
        "metric": "Total utility (defender reward minus switching costs)",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Total utility (sum of defender rewards minus switching costs)",
      "Average reward per round (defender)",
      "Regret notions discussed theoretically (external regret; policy regret not sublinear under adaptive adversary)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can we learn effective MTD switching strategies without prior knowledge of attacker rewards or actions using only defender reward feedback?",
        "How to incorporate switching costs into online learning strategies for MTD while dealing with adaptive attackers?",
        "Given varying levels of available prior information about vulnerabilities/attackers, what algorithms perform well empirically?"
      ],
      "gaps_identified": [
        "Most existing MTD research assumes unrealistic access to information about attacker motivations/actions.",
        "Existing approaches often assume complete knowledge of system vulnerabilities and how attackers exploit them.",
        "Bandit algorithms lose meaningful external regret guarantees when switching costs are present; policy regret is linear under adaptive adversaries."
      ],
      "limitations": [
        "No algorithm can guarantee sublinear policy regret against an adaptive adversary with switching costs; all algorithms have Θ(T) policy regret (per [28]).",
        "Lack of meaningful theoretical performance guarantees for bandit-style methods when switching costs are included.",
        "Assumes switching cost matrix is known a priori.",
        "Evaluation details and results depend on datasets mined from NVD; attacker rationality is not assumed, which may complicate theoretical analysis."
      ],
      "future_work": [],
      "motivation": "Design practical MTD switching strategies that remain effective without unrealistic prior knowledge of attackers or full knowledge of vulnerabilities, while accounting for defender switching costs.",
      "potential_research_ideas": [
        "Contextual bandits for MTD using side information about configurations (e.g., technology stack attributes, historical CVE features) to reduce exploration cost.",
        "Non-stationary/adaptive bandits with change-point detection to react to shifts in attacker behavior or newly emerging vulnerabilities.",
        "Bayesian attacker-type inference integrated with bandit selection (e.g., Thompson Sampling with switching-cost regularization).",
        "Meta-learning across applications to transfer MTD switching policies from one system to another using shared vulnerability characteristics.",
        "Incorporate predictive CVE exploitability forecasting to guide proactive configuration switching.",
        "Multi-objective optimization balancing security utility, performance overhead, and operational constraints in MTD.",
        "Hybrid game-theoretic + bandit approaches that maintain uncertainty sets over attacker utilities and optimize robustly.",
        "Streaming evaluation against red-team/CTF logs or live honeypots to validate in-the-wild performance."
      ],
      "architectural_improvement_recommendations": [
        "Augment FPL-MTD with a switching-cost-aware regularizer (e.g., inertia or smoothness term) akin to online learning with movement costs.",
        "Use Thompson Sampling or Gaussian Perturbations instead of exponential noise if priors are available; compare variance/efficiency trade-offs.",
        "Introduce hierarchical selection: first choose subsystem (e.g., DB, language), then configuration to better structure exploration.",
        "Add contextual features and train a lightweight predictor of defender reward to initialize bandit estimates (warm-start).",
        "Incorporate adversarially robust estimators and robust regret objectives under partial observability.",
        "Implement non-stationary mechanisms (sliding windows/discounting) for reward estimates to adapt to evolving threats."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Estimating and maintaining accurate switching cost matrices across heterogeneous configurations.",
        "Operational overhead and performance impact of frequent switching.",
        "Limited observability: only defender reward feedback is available; attacker actions and utilities remain unknown.",
        "Integrating with real systems that have compatibility constraints between components."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Propose two scalable algorithms (FPL-MTD and FPL-MaxMin) for MTD switching that do not require attacker utility knowledge.",
      "Formulate the MTD switching problem with switching costs under bandit feedback and adaptive adversaries.",
      "Incorporate switching costs directly into a Follow-the-Perturbed-Leader style selection rule and use Geometric Resampling for unbiased estimation.",
      "Empirically evaluate on datasets mined from the National Vulnerability Database, demonstrating performance matching state-of-the-art methods while using less prior information."
    ]
  },
  {
    "arxiv_id": "2301.12013v2",
    "title": "Cybersecurity Threat Hunting and Vulnerability Analysis Using a Neo4j Graph Database of Open Source Intelligence",
    "authors": "Elijah Pelofske; Lorie M. Liebrock; Vincent Urias",
    "abstract": "Open source intelligence is a powerful tool for cybersecurity analysts to gather information both for analysis of discovered vulnerabilities and for detecting novel cybersecurity threats and exploits. However the scale of information that is relevant for information security on the internet is always increasing, and is intractable for analysts to parse comprehensively. Therefore methods of condensing the available open source intelligence, and automatically developing connections between disparate sources of information, is incredibly valuable. In this research, we present a system which constructs a Neo4j graph database formed by shared connections between open source intelligence text including blogs, cybersecurity bulletins, news sites, antivirus scans, social media posts (e.g., Reddit and Twitter), and threat reports. These connections are comprised of possible indicators of compromise (e.g., IP addresses, domains, hashes, email addresses, phone numbers), information on known exploits and techniques (e.g., CVEs and MITRE ATT&CK Technique ID's), and potential sources of information on cybersecurity exploits such as twitter usernames. The construction of the database of potential IoCs is detailed, including the addition of machine learning and metadata which can be used for filtering of the data for a specific domain (for example a specific natural language) when needed. Examples of utilizing the graph database for querying connections between known malicious IoCs and open source intelligence documents, including threat reports, are shown. We show three specific examples of interesting connections found in the graph database; the connections to a known exploited CVE, a known malicious IP address, and a malware hash signature.",
    "published_date": "2023-01-27",
    "pdf_link": "https://arxiv.org/pdf/2301.12013v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Threat Intelligence and Hunting",
      "subdomain": "Open Source Intelligence (OSINT) Integration and Knowledge Graphs",
      "specific_problem": "Constructing and querying a Neo4j knowledge graph that links open-source documents to indicators of compromise (IoCs) and vulnerability/technique identifiers to support threat hunting and vulnerability analysis",
      "attack_types": [
        "malware campaigns",
        "vulnerability exploitation (CVE)",
        "APT operations",
        "malicious IP infrastructure"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Text Classification",
        "specific": "Cybersecurity Topic Classification (CTC)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "NLP Multi-label Classification (MITRE ATT&CK mapping)",
        "specific": "rcATT (Reports Classification by Adversarial Tactics and Techniques)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "NLP Multi-label Classification (MITRE ATT&CK mapping)",
        "specific": "TRAM (Threat Report ATT&CK Mapper)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Language Identification",
        "specific": "langdetect",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Rule-based Pattern Matching",
        "specific": "Regex/pattern extraction for IoCs (hashes, emails, IPs, domains, CVEs, ATT&CK IDs, filenames, APT/malware names, phone numbers, Twitter usernames)",
        "novel_contribution": "Systematic extraction and bipartite graph construction from heterogeneous OSINT and antivirus scan sources"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Neo4j OSINT IoC Graph Database (constructed in this work)",
        "type": "proprietary",
        "domain": "knowledge_graph",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "OSINT Web Crawler Corpus (Reddit, Twitter, blogs, cybersecurity bulletins, news sites)",
        "type": "proprietary",
        "domain": "social_media_text, blogs, news, security_bulletins",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Structured Antivirus File Scan Data",
        "type": "proprietary",
        "domain": "antivirus_scans",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Threat Reports Corpus",
        "type": "public",
        "domain": "threat_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "MITRE ATT&CK Techniques Knowledge Base",
        "type": "public",
        "domain": "attack_techniques",
        "link": "https://attack.mitre.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CVE List (Common Vulnerabilities and Exposures)",
        "type": "public",
        "domain": "vulnerabilities",
        "link": "https://cve.mitre.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Alexa Top 1 Million Domains (used for filtering common domains)",
        "type": "public",
        "domain": "internet_domains",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "“the scale of information that is relevant for information security on the internet is always increasing and is intractable for analysts to parse comprehensively.”",
        "Open-source text contains substantial noise and false positives; there is a need to automatically connect disparate sources via IoCs.",
        "Existing automated text mining systems for IoC extraction are narrower in source coverage and data types compared to this work."
      ],
      "limitations": [
        "High false positives for some datatypes: “there exist many false positives - e.g., correlations that exist in open text that do not actually have a semantic reason for happening.”",
        "“The rcATT tool was trained on threat report text and therefore the error rates on non-threat report documents is expected to be high.”",
        "TRAM similarly likely has “high error rates for natural language text that is quite different from threat reports”.",
        "Language limitations: machine learning models use English vectorization; “other languages are not used in these models, which means that their results will be very inaccurate and should not be used.”",
        "False positive risk is higher for patterns like IP addresses and phone numbers due to format/entropy characteristics.",
        "Scalability requires substantial storage (hundreds of GB), RAM (≥32 GB), and more resources for larger datasets; pipeline is not highly parallel."
      ],
      "future_work": [
        "“other types of cybersecurity relevant strings, besides those used in this study, could be searched for and created as a type of edge in such a graph database.”",
        "The authors note “future research directions” in Section 4 (details not included in provided text)."
      ],
      "motivation": "Condense and connect heterogeneous OSINT at scale into a searchable graph to support threat hunting, malware clustering, and vulnerability analysis when manual parsing is infeasible.",
      "potential_research_ideas": [
        "Add confidence scoring and provenance-aware weighting for edges (e.g., based on source credibility, ML model confidence, language match) to reduce false positives.",
        "Apply multilingual topic and ATT&CK classification models to cover non-English OSINT; fine-tune on multilingual threat intel corpora.",
        "Entity resolution and canonicalization for APT and malware aliases to merge equivalent nodes; integrate external alias dictionaries.",
        "Temporal graph modeling (time-aware edges) to enable campaign chronology and change-point detection (e.g., newly active IoCs).",
        "Use LLM-based information extraction to capture semantic relations (actor-uses-tool-on-target, vulnerability-exploited-by) beyond substring matches.",
        "Train graph-based ranking/link prediction (e.g., GNN) to prioritize likely malicious IoCs and surface high-value documents.",
        "Integrate standardized CTI formats (STIX/TAXII) for ingestion/export and interoperability with SOC tooling.",
        "Establish an evaluation benchmark with labeled true/false IoC-document links to quantitatively measure precision/recall and support comparisons."
      ],
      "architectural_improvement_recommendations": [
        "Introduce a scoring pipeline combining regex precision checks, source trust scores, and ML classifier confidence to filter edges before insertion.",
        "Implement alias resolution and controlled vocabularies (APT/malware names) with knowledge base alignment (e.g., MISP galaxies).",
        "Add multilingual classifiers (e.g., XLM-R-based ATT&CK mappers) gated by language detection; bypass English-only models for non-English text.",
        "Adopt time-indexed graph schema and TTL policies for ephemeral IoCs; support incremental snapshotting and time-travel queries.",
        "Move ingestion to a streaming architecture with message queues (Kafka) and microservices; parallelize regex/ML steps to scale throughput.",
        "Augment extraction with NER and relation extraction (transformer-based) to capture semantically grounded links, reducing spurious matches.",
        "Provide confidence and provenance metadata on edges and nodes, surfaced in the UI for analyst triage.",
        "Add feedback loops/active learning from analyst labels to continuously improve classifiers and filter rules."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Neo4j",
        "Python 3",
        "NLTK",
        "langdetect",
        "rcATT",
        "TRAM",
        "CTC"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "Hundreds of GB storage; ≥32 GB RAM; ~8 CPU cores sufficient; more resources needed for larger scale."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Neo4j-backed system ingesting data continuously from a web crawler infrastructure; exact environment not specified",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High false positive rate for some string patterns (e.g., IPs, phone numbers).",
        "English-only ML classifiers lead to inaccuracy on non-English text; need language-aware processing.",
        "rcATT/TRAM trained on threat reports; poor generalization to other OSINT sources.",
        "Significant storage/memory requirements; limited parallelism in current pipeline.",
        "Need deduplication and noise reduction across heterogeneous sources."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A scalable pipeline and system to construct a Neo4j knowledge graph linking heterogeneous OSINT documents and structured antivirus scans to potential IoCs, CVEs, and MITRE ATT&CK IDs via pattern matches.",
      "Integration of machine learning metadata (CTC cybersecurity topic classification, rcATT/TRAM ATT&CK mapping, language detection) into document nodes to support filtering and relevance estimation.",
      "Bipartite graph design (documents ↔ IoC/identifier nodes) with large-scale statistics (e.g., 2,128,992 document nodes; extensive edge counts per IoC type as in Table 1).",
      "Deduplication via SHA256 checksums and systematic parsing of structured vs unstructured sources.",
      "Case-study demonstrations querying connections around a known exploited CVE, a known malicious IP, and a malware hash signature; example linking malware samples via shared PE resource files.",
      "Generalizable approach to incorporate additional cybersecurity-relevant string types as new edge/node classes."
    ]
  },
  {
    "arxiv_id": "2301.07346v1",
    "title": "One Size Does not Fit All: Quantifying the Risk of Malicious App Encounters for Different Android User Profiles",
    "authors": "Savino Dambra; Leyla Bilge; Platon Kotzias; Yun Shen; Juan Caballero",
    "abstract": "Previous work has investigated the particularities of security practices within specific user communities defined based on country of origin, age, prior tech abuse, and economic status. Their results highlight that current security solutions that adopt a one-size-fits-all-users approach ignore the differences and needs of particular user communities. However, those works focus on a single community or cluster users into hard-to-interpret sub-populations.   In this work, we perform a large-scale quantitative analysis of the risk of encountering malware and other potentially unwanted applications (PUA) across user communities. At the core of our study is a dataset of app installation logs collected from 12M Android mobile devices. Leveraging user-installed apps, we define intuitive profiles based on users' interests (e.g., gamers and investors), and fit a subset of 5.4M devices to those profiles. Our analysis is structured in three parts. First, we perform risk analysis on the whole population to measure how the risk of malicious app encounters is affected by different factors. Next, we create different profiles to investigate whether risk differences across users may be due to their interests. Finally, we compare a per-profile approach for classifying clean and infected devices with the classical approach that considers the whole population.   We observe that features such as the diversity of the app signers and the use of alternative markets highly correlate with the risk of malicious app encounters. We also discover that some profiles such as gamers and social-media users are exposed to more than twice the risks experienced by the average users. We also show that the classification outcome has a marked accuracy improvement when using a per-profile approach to train the prediction models. Overall, our results confirm the inadequacy of one-size-fits-all protection solutions.",
    "published_date": "2023-01-18",
    "pdf_link": "https://arxiv.org/pdf/2301.07346v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "Android Malware Detection and Risk Assessment",
      "specific_problem": "Quantifying risk of malicious (malware/PUA) app encounters across Android user profiles and evaluating per-profile vs global models for classifying infected devices",
      "attack_types": [
        "Android malware",
        "Potentially Unwanted Applications (PUA)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Linear Model",
        "specific": "Generalized Linear Model (binomial logistic regression)",
        "novel_contribution": "Use of GLMs to estimate odds ratios of malicious encounters from 10 risk factors across 8.6M devices; three models for malware, PUA, and combined."
      },
      {
        "type": "primary",
        "category": "Classical ML",
        "specific": null,
        "novel_contribution": "Per-profile classification approach for predicting device infection risk compared to a single global model, showing marked accuracy improvements."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Android App Installation Logs (Security Vendor Telemetry)",
        "type": "proprietary",
        "domain": "mobile_app_installation_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Google Play Market Metadata (categories)",
        "type": "public",
        "domain": "app_store_metadata",
        "link": "https://play.google.com/store",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusTotal APK Reports",
        "type": "public",
        "domain": "malware_scanning_reports",
        "link": "https://www.virustotal.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Global single-model classifier (whole population)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "“The outcome of the per-profile classification approach is significantly better with an average accuracy of more than 76%.”",
        "baseline_result": "“Using a single model, the accuracy score for some profiles is even worse than 50%, while for others it reaches upwards of 80%.”"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Odds ratio (from logistic regression coefficients)",
      "Pseudo R-Squared",
      "Log-Likelihood",
      "Dispersion",
      "Akaike Information Criterion (AIC)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How do different risk factors correlate with the odds of encountering malware/PUA across the whole Android population?",
        "Do users’ interests (profiles) explain risk differences across users?",
        "Does training per-profile classifiers improve clean/infected device classification compared to a single global model?"
      ],
      "gaps_identified": [
        "One-size-fits-all protection solutions ignore differences and needs of particular user communities.",
        "Prior works often focus on a single community or produce hard-to-interpret clusters; lack of interpretable, large-scale, cross-community quantification.",
        "Lack of large-scale quantitative risk assessment on the mobile ecosystem compared to enterprise/desktop studies."
      ],
      "limitations": [
        "Dataset is from a single security vendor’s opted-in telemetry; may not generalize to all Android users.",
        "Limited VirusTotal coverage after filtering (VT reports for ~10% of APKs; 20% of apps), potentially biasing labels.",
        "User-installed app identification relies on market parent inference; misses installations via IM/browser/ADB and pre-installed/system apps.",
        "No ground-truth APK files (metadata-only logs); reliance on AV labels and thresholding can introduce labeling noise.",
        "Time window limited to four months (2019-06-01 to 2019-09-30).",
        "Possible device sharing in some regions can confound per-user profiling.",
        "Geolocation via IP and limited demographic info constrain analysis of sociotechnical factors."
      ],
      "future_work": [],
      "motivation": "Promote personalized security by quantifying and comparing malware/PUA risk across user communities, moving beyond one-size-fits-all models.",
      "potential_research_ideas": [
        "Multi-task or hierarchical models that share representations across profiles while allowing profile-specific heads to improve accuracy and data efficiency.",
        "Causal inference to disentangle behaviorally-driven risk factors (e.g., alternative markets use) from confounders (region, device type).",
        "Temporal risk forecasting using sequence models over installations/updates to predict imminent infection risk per profile.",
        "Label aggregation and denoising techniques (e.g., weak supervision, snorkel-style label models) to better integrate heterogeneous AV labels and thresholds.",
        "Augment features with app-level static/dynamic analysis (permissions, trackers, network behavior) and signer reputation graphs for richer per-profile models.",
        "Active learning with on-device or edge prompts to improve labels for low-coverage devices while preserving privacy.",
        "Domain adaptation and calibration to maintain performance when market distributions shift (e.g., new regions or alternative stores).",
        "Explainability studies tailored to profiles to optimize user-facing security notifications and interventions."
      ],
      "architectural_improvement_recommendations": [
        "Adopt gradient-boosted trees or calibrated logistic regression with SHAP explanations per profile to retain interpretability with better nonlinearity handling.",
        "Implement a shared-backbone, profile-specific head architecture (multi-task learning) to capture commonalities while specializing risks.",
        "Incorporate a signer/app-store graph with node embeddings to model reputation propagation and alternative market exposure.",
        "Use cost-sensitive learning to penalize false negatives more heavily for high-risk profiles (e.g., gamers, social-media users).",
        "Apply probability calibration (Platt/Isotonic) per profile for actionable risk scores and threshold tuning.",
        "Integrate semi-supervised/self-training leveraging unlabeled apps when VT coverage is low.",
        "Perform robust evaluation with time-based splits and cross-region validation to assess generalization under distribution shifts."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Consumer Android devices via a security vendor’s backend (12M devices; 8.6M after filtering)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Privacy-sensitive data collection and anonymization requirements.",
        "Partial coverage of malware labels due to VirusTotal API limitations.",
        "Identifying user-installed apps without system partition paths; potential misclassification of installation sources.",
        "Heterogeneity of regions, devices, and markets affecting model transferability."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Large-scale quantitative analysis of malware/PUA encounter risk across Android user communities using 12M devices (8.6M after filtering).",
      "Defined intuitive, interest-based user profiles (e.g., gamers, investors) and matched 5.4M devices to profiles using installed apps.",
      "Identified key risk factors: signer diversity and alternative market usage show strong correlation with malicious encounters; app reputation and update frequency also contribute.",
      "Showed some profiles (e.g., gamers, social-media users) face more than twice the average risk.",
      "Demonstrated per-profile classification models markedly improve accuracy over a single global model (average >76% accuracy vs single-model sometimes <50%).",
      "Provided GLM-based odds ratios quantifying the effect of 10 features across malware, PUA, and combined outcomes; compared model fit with AIC and other statistics.",
      "Highlighted the inadequacy of one-size-fits-all protection solutions for mobile users."
    ]
  },
  {
    "arxiv_id": "2301.12039v1",
    "title": "Harnessing the Power of Decision Trees to Detect IoT Malware",
    "authors": "Marwan Omar",
    "abstract": "Due to its simple installation and connectivity, the Internet of Things (IoT) is susceptible to malware attacks. Being able to operate autonomously. As IoT devices have become more prevalent, they have become the most tempting targets for malware. Weak, guessable, or hard-coded passwords, and a lack of security measures contribute to these vulnerabilities along with insecure network connections and outdated update procedures. To understand IoT malware, current methods and analysis ,using static methods, are ineffective. The field of deep learning has made great strides in recent years due to their tremendous data mining, learning, and expression capabilities, cybersecurity has enjoyed tremendous growth in recent years. As a result, malware analysts will not have to spend as much time analyzing malware. In this paper, we propose a novel detection and analysis method that harnesses the power and simplicity of decision trees. The experiments are conducted using a real word dataset, MaleVis which is a publicly available dataset. Based on the results, we show that our proposed approach outperforms existing state-of-the-art solutions in that it achieves 97.23% precision and 95.89% recall in terms of detection and classification. A specificity of 96.58%, F1-score of 96.40%, an accuracy of 96.43.",
    "published_date": "2023-01-28",
    "pdf_link": "https://arxiv.org/pdf/2301.12039v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "IoT Malware Detection",
      "specific_problem": "Supervised detection and classification of IoT malware using decision trees with entropy-based feature selection",
      "attack_types": [
        "IoT malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": "Decision-tree-based classifier combined with an entropy-based ('entropy decision') feature selection/data quality step for IoT malware/intrusion detection"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet18",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "DenseNet161",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "MaleVis",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "ResNet18",
        "paper_reference": null,
        "metric": "Specificity / F1-score / Accuracy / Loss / Inference time",
        "their_result": "Spec 98.69% / F1 98.76% / Acc 97.67% / Loss 0.086 / 97 ms",
        "baseline_result": "Spec 94.14% / F1 96.39% / Acc 95.03% / Loss 0.181 / 146 ms"
      },
      {
        "method_name": "DenseNet161",
        "paper_reference": null,
        "metric": "Specificity / F1-score / Accuracy / Loss / Inference time",
        "their_result": "Spec 98.69% / F1 98.76% / Acc 97.67% / Loss 0.086 / 97 ms",
        "baseline_result": "Spec 97.97% / F1 94.67% / Acc 96.66% / Loss 0.156 / 480 ms"
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall",
      "specificity",
      "F1-score",
      "accuracy",
      "loss",
      "inference_time_ms"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a decision tree classifier with entropy-based feature selection improve detection and classification performance for IoT malware/intrusions?",
        "Does improving data quality via an entropy decision method lead to higher IDS accuracy and detection rate?"
      ],
      "gaps_identified": [
        "“current methods and analysis ,using static methods, are ineffective” for understanding IoT malware",
        "IDS limitations including real-time detection, alarm generation, and data accuracy issues can lead to less successful detections",
        "Signature-based detection is ineffective for previously unknown risks and disguised threats; anomaly-based methods can suffer high false alarms"
      ],
      "limitations": [
        "No explicit limitations of the proposed model are detailed; evaluation details are limited and datasets mentioned are inconsistent (MaleVis vs NSL-KDD/CICIDS2017)"
      ],
      "future_work": [
        "“We will implement other efficient machine learning techniques such as deep learning in various parts of our method in the future to improve the detection rate and accuracy”"
      ],
      "motivation": "IoT devices are increasingly targeted by malware due to weak security; existing static analysis methods are ineffective, motivating a simple yet effective decision-tree-based detection approach with improved data quality.",
      "potential_research_ideas": [
        "Build a unified, reproducible pipeline evaluating the approach across multiple IoT malware datasets (e.g., MaleVis plus other IoT-focused corpora) with consistent protocols.",
        "Augment static features with dynamic behavioral features from IoT sandboxing/emulation and study their impact on tree-based models.",
        "Investigate ensemble tree methods (Random Forest, XGBoost, LightGBM) and compare against single decision trees on identical features.",
        "Combine CNN-derived embeddings (from malware images/binaries) with tree classifiers (e.g., train CNN, extract fixed features, classify with XGBoost).",
        "Assess adversarial robustness of tree-based detectors to evasion/manipulation of features; devise robust feature sets or adversarial training.",
        "Apply cost-sensitive learning and calibration for imbalanced classes and operational thresholds in IDS contexts.",
        "Explore federated learning or privacy-preserving training for distributed IoT environments without centralizing sensitive data."
      ],
      "architectural_improvement_recommendations": [
        "Replace single decision tree with gradient-boosted trees (XGBoost/LightGBM) and compare gains in accuracy and calibration.",
        "Introduce rigorous feature selection/engineering pipeline (information gain, mutual information, SHAP-based pruning) with nested cross-validation.",
        "Standardize train/validation/test splits with stratification and k-fold cross-validation to improve reliability of estimates.",
        "Integrate deep feature extractors (e.g., ResNet embedders) followed by a tree ensemble classifier to capture non-linear patterns while retaining interpretability in the tree layer.",
        "Add probability calibration (Platt scaling/Isotonic regression) for better thresholding in IDS deployment.",
        "Implement real-time inference profiling and batching strategies to meet IoT gateway constraints."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": "97 ms per sample (reported as APT per Malware Classification for the proposed approach)",
      "deployment_challenges": [
        "Signature-based IDS require constant updates and cannot detect novel exposures",
        "Anomaly-based IDS prone to high false alarm rates",
        "IDS upkeep/maintenance overhead is high; difficult to update with new attacks"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Novel decision-tree-based detection and analysis method for IoT malware/IDS.",
      "Entropy-based (entropy decision) feature selection/data quality step to improve model performance.",
      "Empirical evaluation on a publicly available dataset (MaleVis) with reported high performance (e.g., precision 97.23%, recall 95.89%, specificity 96.58%, F1 96.40%, accuracy 96.43%).",
      "Quantitative comparison against deep CNN baselines (ResNet18, DenseNet161) including latency."
    ]
  },
  {
    "arxiv_id": "2302.00876v1",
    "title": "Improvement and Evaluation of Resilience of Adaptive Cruise Control Against Spoofing Attacks Using Intrusion Detection System",
    "authors": "Mubark B. Jedh; Lotfi ben Othmane; Arun K. Somani",
    "abstract": "The Adaptive Cruise Control (ACC) system automatically adjusts the vehicle speed to maintain a safe distance between the vehicle and the lead (ahead) vehicle. The controller's decision to accelerate or decelerate is computed using the target speed of the vehicle and the difference between the vehicle's distance to the lead vehicle and the safe distance from that vehicle. Spoofing the vehicle speed communicated through the Controller Area Network (CAN) of the vehicle impacts negatively the capability of the ACC (Proportional-Integral-Derivative variant) to prevent crashes with the lead vehicle. The paper reports about extending the ACC with a real-time Intrusion Detection System (IDS) capable of detecting speed spoofing attacks with reasonable response time and detection rate, and simulating the proposed extension using the CARLA simulation platform. The results of the simulation are: (1) spoofing the vehicle speed can foil the ACC to falsely accelerate, causing accidents, and (2) extending ACC with ML-based IDS to trigger the brakes when an accident is imminent may mitigate the problem. The findings suggest exploring the capabilities of ML-based IDS to support the resilience mechanisms in mitigating cyber-attacks on vehicles.",
    "published_date": "2023-02-02",
    "pdf_link": "https://arxiv.org/pdf/2302.00876v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Automotive Security",
      "subdomain": "In-vehicle Network Intrusion Detection / Controller Resilience",
      "specific_problem": "Mitigating CAN-bus speed spoofing attacks against Adaptive Cruise Control (ACC) via ML-based IDS and emergency braking integration",
      "attack_types": [
        "CAN message injection (speed spoofing)",
        "Sensor spoofing (contextual, discussed)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Anomaly Detection (unspecified ML classifier)",
        "specific": null,
        "novel_contribution": "Integrates a real-time ML-based vehicle IDS with a PID-ACC to trigger emergency braking upon speed spoofing detection; evaluates end-to-end resilience in CARLA simulation using measured IDS latency/accuracy from prior work."
      }
    ],
    "learning_paradigm": [],
    "datasets": [
      {
        "name": "CARLA simulator–generated sensor/CAN data for ACC scenarios",
        "type": "synthetic",
        "domain": "vehicle_can_bus",
        "link": "https://carla.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CAN Bus log of a moving vehicle (used for speed/lead-vehicle traces) [13]",
        "type": "public",
        "domain": "vehicle_can_bus",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Simulated real-time IDS evaluation data (from prior IDS work) [15]",
        "type": "synthetic",
        "domain": "vehicle_can_bus",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "PID-based ACC without IDS under speed spoofing",
        "paper_reference": null,
        "metric": "Crash occurrence under spoofing at 60 and 90 km/h",
        "their_result": "No crashes with ACC-IDS; emergency braking triggered when spoofing detected (Scenarios at 60 and 90 km/h).",
        "baseline_result": "Crashes occur without IDS under the same speed spoofing (60 and 90 km/h)."
      }
    ],
    "performance_metrics_used": [
      "detection rate",
      "detection latency",
      "response time (end-to-end)",
      "crash/no-crash occurrence",
      "safe stopping distance (SSD) threshold satisfaction"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does spoofing the vehicle speed on the CAN bus cause ACC (PID) to miscompute safe distance and lead to crashes?",
        "Can integrating a real-time ML-based IDS with ACC and triggering emergency braking mitigate speed spoofing attacks within practical response times?"
      ],
      "gaps_identified": [
        "Prior resilience work largely targets distance sensor spoofing or attack-specific controller designs; speed spoofing via CAN is under-addressed.",
        "Controller reformulations are attack-specific and, being public, may be circumvented; a generic IDS-driven mitigation is needed."
      ],
      "limitations": [
        "Evaluation is simulation-based in CARLA; no on-vehicle, real-road experiments.",
        "No deployable real-time vehicle IDS available for integration; used performance figures from prior simulated IDS work.",
        "Assumptions simplify reality (e.g., lower-level controller applies outputs synchronously; no dynamic objects; vehicle can ignore traffic rules).",
        "Assumes spoofing of road slope and friction has limited impact on SSD.",
        "Exact ML model details of the IDS are not specified in this paper; relies on prior work metrics."
      ],
      "future_work": [
        "Explore broader use of ML-based IDS to support resilience mechanisms in mitigating cyber-attacks on vehicles.",
        "Use alternative mitigation option: estimate/correct the true speed via ML prediction or sensor fusion when spoofing is detected.",
        "Evaluate across more scenarios (different speeds, traffic, dynamic obstacles) and conduct real-world tests."
      ],
      "motivation": "ACC relies on speed and distance; speed spoofing on CAN can mislead PID-ACC causing unsafe behavior. A practical, generic resilience mechanism via IDS may mitigate such cyber-attacks.",
      "potential_research_ideas": [
        "Design a sensor-fusion estimator (e.g., EKF/UKF + learning-based residuals) to reconstruct true speed during spoofing and maintain control without hard braking.",
        "Develop an ensemble IDS (protocol + timing + content features) tailored to CAN speed signals to improve accuracy/latency beyond the prior IDS.",
        "Integrate MPC-based upper-layer control that leverages IDS confidence to trade off braking aggressiveness vs stability.",
        "Create a digital-twin-in-the-loop framework to co-train IDS and controller policies against adaptive spoofing strategies.",
        "Study false-positive safe-handling strategies (graceful degradation, driver alerting, adaptive thresholds) to reduce unnecessary braking."
      ],
      "architectural_improvement_recommendations": [
        "Fuse redundant speed sources (wheel speeds, IMU, GPS, transmission RPM) with an EKF and cross-validate with IDS alerts before triggering emergency brake.",
        "Implement hierarchical mitigation: throttle cut, mild braking, then hard brake based on IDS confidence and SSD margin.",
        "Optimize IDS pipeline for sub-100 ms latency (e.g., lightweight models, feature precomputation, RTOS scheduling on in-vehicle hardware).",
        "Adopt confidence-aware control (augment PID/MPC cost with IDS anomaly score) to modulate acceleration smoothly under uncertainty.",
        "Log and replay CAN traffic around detections for online adaptation or periodic retraining to handle evolving attack patterns."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "CARLA",
        "Linux virtual CAN"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Simulation on AWS with 12 CPU cores, 200 GB RAM, 8 GB NVIDIA GPU; CARLA Town04/Town05; PID gains: longitudinal Kp=1.0, Ki=0.7, Kd=0; lateral Kp=1.98, Ki=0.07, Kd=0.20; dt=0.05. IDS prior work metrics used: detection latency ~152 ms; response time ~1.026 s."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "In-vehicle CAN bus with an IDS (prior work deployed on Raspberry Pi in simulated environment); integrated with ACC controller for emergency braking.",
      "scalability_discussed": false,
      "inference_time": "Reported IDS detection latency 152 ms; end-to-end response time 1.026 s (from prior work [15]).",
      "deployment_challenges": [
        "Effectiveness depends on IDS accuracy and low response time to avoid late braking.",
        "Lack of an off-the-shelf real-time vehicle IDS for direct integration; reliance on simulated performance figures."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Show that spoofing vehicle speed on CAN can cause PID-ACC to compute an unsafe distance and trigger false acceleration leading to crashes.",
      "Propose and simulate ACC-IDS: ACC extended with a real-time ML-based IDS that triggers emergency braking when speed spoofing is detected.",
      "Demonstrate in CARLA that IDS-driven braking prevents crashes under speed spoofing at 60 and 90 km/h, whereas baseline ACC without IDS crashes.",
      "Quantify IDS timing from prior work to assess feasibility (detection latency ~152 ms; response ~1.026 s, lower than typical 2.5 s driver reaction time)."
    ]
  },
  {
    "arxiv_id": "2301.06695v2",
    "title": "Quantifying and Managing Impacts of Concept Drifts on IoT Traffic Inference in Residential ISP Networks",
    "authors": "Arman Pashamokhtari; Norihiro Okui; Masataka Nakahara; Ayumu Kubota; Gustavo Batista; Hassan Habibi Gharakheili",
    "abstract": "Millions of vulnerable consumer IoT devices in home networks are the enabler for cyber crimes putting user privacy and Internet security at risk. Internet service providers (ISPs) are best poised to play key roles in mitigating risks by automatically inferring active IoT devices per household and notifying users of vulnerable ones. Developing a scalable inference method that can perform robustly across thousands of home networks is a non-trivial task. This paper focuses on the challenges of developing and applying data-driven inference models when labeled data of device behaviors is limited and the distribution of data changes (concept drift) across time and space domains. Our contributions are three-fold: (1) We collect and analyze network traffic of 24 types of consumer IoT devices from 12 real homes over six weeks to highlight the challenge of temporal and spatial concept drifts in network behavior of IoT devices; (2) We analyze the performance of two inference strategies, namely \"global inference\" (a model trained on a combined set of all labeled data from training homes) and \"contextualized inference\" (several models each trained on the labeled data from a training home) in the presence of concept drifts; and (3) To manage concept drifts, we develop a method that dynamically applies the ``closest'' model (from a set) to network traffic of unseen homes during the testing phase, yielding better performance in 20% of scenarios.",
    "published_date": "2023-01-17",
    "pdf_link": "https://arxiv.org/pdf/2301.06695v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Asset Discovery and Fingerprinting",
      "specific_problem": "Inferring IoT device types in residential home networks from IPFIX flow features under temporal and spatial concept drift",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": "Random Forest (multiclass)",
        "novel_contribution": "Applied with class-specific confidence thresholds; evaluated under temporal and spatial concept drift with global vs contextualized training strategies."
      },
      {
        "type": "primary",
        "category": "Model selection / Meta-learning",
        "specific": null,
        "novel_contribution": "Dynamic combined inference that selects and applies the 'closest' model (from a set of global and contextualized models) to unseen homes during testing."
      },
      {
        "type": "baseline",
        "category": "Training strategy",
        "specific": "Global model (single classifier trained on combined data from multiple homes)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Training strategy",
        "specific": "Contextualized models (one model per home; best static model assigned per unseen home)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Online inference (dynamic model selection)"
    ],
    "datasets": [
      {
        "name": "Residential IoT IPFIX Flow Dataset (12 homes, 24 device types, 47 days)",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Global model (combined training across homes)",
        "paper_reference": null,
        "metric": "Average prediction accuracy across testing homes (10 runs)",
        "their_result": "0.826 (dynamic combined inference; Table 3 avg last column)",
        "baseline_result": "0.818 (global; Table 3 avg second column)"
      },
      {
        "method_name": "Contextualized per-home model (best static assignment)",
        "paper_reference": null,
        "metric": "Average prediction accuracy across testing homes (10 runs)",
        "their_result": "0.826 (dynamic combined inference; Table 3 avg last column)",
        "baseline_result": "0.783 (contextualized; Table 3 avg third column)"
      }
    ],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Given a labeled dataset (training) from h homes and an unlabeled dataset (testing) from other homes, which of the global versus contextualized modeling does yield better performance in classifying devices during the testing phase?"
      ],
      "gaps_identified": [
        "Prior works trained a global model on testbed data representing a single context and did not encounter or evaluate context variations across homes.",
        "Impacts of temporal (firmware/software changes) and spatial (usage/config differences across homes) concept drifts on IoT traffic inference are underexplored.",
        "Labeled data collection for IoT device behavior is limited and costly for ISPs; methods must operate with scarce labels.",
        "Best-model selection for contextualized modeling in practice (without labels) is not addressed in prior work."
      ],
      "limitations": [
        "Model selection for contextualized modeling used ground truth labels to pick the best model for unseen homes, which is not feasible in practice.",
        "Developing automatic best-model selection methods is beyond the scope and left for future work.",
        "Evaluation is limited to 12 homes, 24 device types, and 47 days; generalization to larger geographies and longer timespans is untested.",
        "Only IPFIX flow-level features (coarse-grained) are used; some predictions have low confidence.",
        "Frequent retraining to mitigate temporal drift has practical challenges that are not resolved.",
        "Only Random Forest was evaluated; no broader model family comparison."
      ],
      "future_work": [
        "Develop practical, label-free methods to select the best model for unseen homes.",
        "Investigate retraining schedules and strategies to mitigate temporal drift.",
        "Explore other learning algorithms (e.g., neural networks) and richer features.",
        "Scale evaluation to more homes, device types, and longer periods."
      ],
      "motivation": "ISPs need robust, scalable inference of active IoT devices per household to mitigate security risks, but limited labeled data and concept drifts over time and across homes make building effective models non-trivial.",
      "potential_research_ideas": [
        "Unsupervised domain adaptation for per-home personalization (e.g., CORAL, MMD minimization, DANN) to bridge spatial drift without labels.",
        "Online drift detection (e.g., ADWIN, DDM, EDDM) on unlabeled IPFIX statistics to trigger model switching/retraining.",
        "Mixture-of-experts with a learned gating network that maps unlabeled home-level statistics to expert (home/global) selection.",
        "Self-supervised pretraining on large unlabeled flow corpora to learn domain-invariant representations for IoT device types.",
        "Active learning to select minimal labeled samples from new homes for rapid adaptation.",
        "Confidence calibration and selective classification (abstain/triage) to handle low-confidence predictions under drift.",
        "OOD detection for previously unseen device types with graceful fallback.",
        "Federated or privacy-preserving training across homes/ISPs to gather diversity without centralizing raw data."
      ],
      "architectural_improvement_recommendations": [
        "Replace static thresholds with calibrated probabilities (e.g., temperature scaling, Platt scaling) and class-specific abstention.",
        "Implement a lightweight meta-learner that embeds unlabeled home-level feature distributions and selects experts via similarity.",
        "Adopt drift-aware online learning with sliding windows and adaptive RF or incremental learners.",
        "Explore sequence models over flow time-series (e.g., temporal CNN/Transformer) to capture behavioral patterns beyond per-flow features.",
        "Integrate domain-invariant representation learning (CORAL/DANN) before the classifier to reduce spatial drift.",
        "Use hierarchical classification (device family -> type) to improve robustness under class overlap."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Residential ISP networks; data collected inside homes (PCAP) and transformed to post-NAT IPFIX to emulate ISP-edge vantage point",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Limited availability and high cost of labeled data across diverse homes",
        "Temporal concept drift due to firmware/software changes",
        "Spatial concept drift due to configuration and usage differences",
        "Need for practical, label-free model selection for unseen homes",
        "Retraining overhead and scheduling",
        "Operating on coarse-grained IPFIX features may reduce confidence",
        "Privacy considerations when collecting and handling household traffic data"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Collected and analyzed network traffic of 24 IoT device types from 12 real homes over 47 days (6,305,626 IPFIX records) to highlight temporal and spatial concept drifts.",
      "Compared global modeling (single model trained on combined homes) versus contextualized modeling (per-home models) for IoT device classification under drift.",
      "Developed a combined, dynamic inference method that selects the 'closest' model for unseen homes during testing; reported macro-level averages: global 0.818, contextualized 0.783, combined static 0.816, and dynamic 0.826 accuracy; and improvements for subsets of homes/days (e.g., better in 20% of scenarios per abstract)."
    ]
  },
  {
    "arxiv_id": "2302.02112v1",
    "title": "Detecting Security Patches via Behavioral Data in Code Repositories",
    "authors": "Nitzan Farhi; Noam Koenigstein; Yuval Shavitt",
    "abstract": "The absolute majority of software today is developed collaboratively using collaborative version control tools such as Git. It is a common practice that once a vulnerability is detected and fixed, the developers behind the software issue a Common Vulnerabilities and Exposures or CVE record to alert the user community of the security hazard and urge them to integrate the security patch. However, some companies might not disclose their vulnerabilities and just update their repository. As a result, users are unaware of the vulnerability and may remain exposed. In this paper, we present a system to automatically identify security patches using only the developer behavior in the Git repository without analyzing the code itself or the remarks that accompanied the fix (commit message). We showed we can reveal concealed security patches with an accuracy of 88.3% and F1 Score of 89.8%. This is the first time that a language-oblivious solution for this problem is presented.",
    "published_date": "2023-02-04",
    "pdf_link": "https://arxiv.org/pdf/2302.02112v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability Management",
      "specific_problem": "Detecting security patches in Git repositories using developer behavioral/meta-data (language- and code-oblivious) to reveal undisclosed vulnerability fixes",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D Convolutional Neural Network (Conv1D) with max pooling and dense layers",
        "novel_contribution": "Applies Conv1D to one-hot encoded sequences of GitHub behavioral events (event-based aggregation windows) without using code or natural language, yielding a language-oblivious detector"
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "LSTM (stacked)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "GRU (stacked)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "SecurityPatchDetection behavioral dataset (GitHub event windows linked to CVEs)",
        "type": "public",
        "domain": "software_repository_events",
        "link": "https://nitzanfarhi.github.io/datasets",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "CVE Program CSV (links to GitHub commits)",
        "type": "public",
        "domain": "vulnerability_catalog",
        "link": "https://cve.mitre.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "GitHub GraphQL API event and repository metadata",
        "type": "public",
        "domain": "software_repository_events",
        "link": "https://graphql.github.io/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "GH Archive (GitHub public event stream)",
        "type": "public",
        "domain": "software_repository_events",
        "link": "https://www.gharchive.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "LSTM (stacked)",
        "paper_reference": null,
        "metric": "Accuracy (window size 10)",
        "their_result": "Conv1D best-case accuracy 83.93%, F1 84.14%",
        "baseline_result": null
      },
      {
        "method_name": "GRU (stacked)",
        "paper_reference": null,
        "metric": "Accuracy (window size 10)",
        "their_result": "Conv1D best-case accuracy 83.93%, F1 84.14%",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1",
      "ROC",
      "AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can security patches be identified using only developer behavioral data from Git repositories, without analyzing code or natural language (commit messages)?",
        "What temporal modeling architectures (Conv1D, LSTM, GRU) and window sizes are most effective for this task?",
        "Can such behavioral modeling reveal concealed (undisclosed) security patches?"
      ],
      "gaps_identified": [
        "Prior methods rely on programming language–specific code analysis or natural language in commit messages, limiting generalization across languages.",
        "Existing works that use Git metadata use limited features or tackle different tasks rather than detecting security patches.",
        "APIs (e.g., GraphQL) omit deleted/inactive branches, reducing historical coverage if not complemented by other sources."
      ],
      "limitations": [
        "High number of false positives leading to lower precision; authors suspect many FPs are actually undisclosed security patches.",
        "GraphQL API can only access active branches; deleted/inactive branch history cannot be retrieved (partially mitigated via GH Archive).",
        "Repositories with fewer than 100 events were discarded, potentially biasing toward more active projects.",
        "Data collected for years 2015–2021 only."
      ],
      "future_work": [],
      "motivation": "Users may remain exposed when organizations do not disclose vulnerabilities; a language-oblivious approach using only behavioral data could detect concealed security patches across programming languages.",
      "potential_research_ideas": [
        "Develop a benchmark and shared task for behavior-only security patch detection across diverse ecosystems and years to enable fair comparison.",
        "Combine behavioral signals with lightweight, language-agnostic code structure metrics (e.g., AST statistics, diff entropy) to reduce false positives while preserving language independence.",
        "Self-supervised pretraining on large-scale GitHub event sequences (contrastive or masked event modeling) followed by fine-tuning for patch detection.",
        "Unsupervised/weakly supervised anomaly detection to flag potential undisclosed patches in repositories with no CVE labels.",
        "Temporal domain adaptation to handle concept drift in repository behaviors over time and across organizations.",
        "Human-in-the-loop verification workflows to triage high-confidence behavioral alerts and validate suspected undisclosed patches.",
        "Apply the method within enterprise SCM systems (GitLab/Bitbucket) and private repos to evaluate generalization."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment Conv1D with Temporal Convolutional Networks (TCN) or Transformer encoders with time-aware positional encodings for longer-range dependencies.",
        "Model event time gaps explicitly (e.g., time2vec features) rather than discarding inter-event intervals entirely.",
        "Introduce repository-level and developer-level embeddings (meta-features like repo age, owner type) fused via attention with event sequences.",
        "Use cost-sensitive learning or focal loss and calibrated decision thresholds to mitigate class imbalance and reduce false positives.",
        "Incorporate graph structure (developer–repository–issue relations) via temporal graph neural networks (TGNN) for richer context.",
        "Provide post-hoc explainability (e.g., attention weights over events, SHAP on event types and temporal features) to interpret predictions.",
        "Hyperparameter and window-size search automation (Bayesian optimization), and variable-length sequence handling with masking."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/nitzanfarhi/SecurityPatchDetection",
      "frameworks": [
        "Keras",
        "TensorFlow",
        "Python"
      ],
      "reproducibility_score": "high",
      "computational_requirements": "Training ~4 minutes on NVIDIA GeForce RTX 3080 (Intel i9-10940X CPU, 16 GB RAM); single prediction ~5 ms; optimizer SGD, batch size 32, epochs 50; 10-fold cross-validation."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "≈5 ms per prediction",
      "deployment_challenges": [
        "High false positive rate reduces precision.",
        "Incomplete historical data from GraphQL due to deleted/inactive branches."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a language-oblivious method to detect security patches using only GitHub behavioral/meta-data (no code or natural language).",
      "Constructs a temporal event-window representation (event-based aggregation with one-hot encoded event types and temporal features).",
      "Empirical comparison of Conv1D, LSTM, and GRU; Conv1D performs best with optimal window size of 10 events.",
      "Public release of code and a dataset covering more repositories than prior work.",
      "Reports performance up to Accuracy 88.3% and F1 89.8% (abstract); best detailed case shows Accuracy 83.93%, F1 84.14%, Precision 0.7550, Recall 0.8769."
    ]
  },
  {
    "arxiv_id": "2301.12778v4",
    "title": "Reassessing feature-based Android malware detection in a contemporary context",
    "authors": "Ali Muzaffar; Hani Ragab Hassen; Hind Zantout; Michael A Lones",
    "abstract": "We report the findings of a reimplementation of 18 foundational studies in feature-based machine learning for Android malware detection, published during the period 2013-2023. These studies are reevaluated on a level playing field using a contemporary Android environment and a balanced dataset of 124,000 applications. Our findings show that feature-based approaches can still achieve detection accuracies beyond 98%, despite a considerable increase in the size of the underlying Android feature sets. We observe that features derived through dynamic analysis yield only a small benefit over those derived from static analysis, and that simpler models often out-perform more complex models. We also find that API calls and opcodes are the most productive static features within our evaluation context, network traffic is the most predictive dynamic feature, and that ensemble models provide an efficient means of combining models trained on static and dynamic features. Together, these findings suggest that simple, fast machine learning approaches can still be an effective basis for malware detection, despite the increasing focus on slower, more expensive machine learning models in the literature.",
    "published_date": "2023-01-30",
    "pdf_link": "https://arxiv.org/pdf/2301.12778v4",
    "paper_types": [
      "empirical_analysis",
      "reproducibility",
      "benchmark",
      "new_dataset"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "Android Malware Detection",
      "specific_problem": "Binary classification of Android applications as malware vs benign using feature-based machine learning in a contemporary Android environment",
      "attack_types": [
        "Android malware",
        "adware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": "Late-fusion of best-performing static and dynamic models",
        "novel_contribution": "Proposes and evaluates an ensemble that achieves highest accuracy/TPR without relying on brittle network features"
      },
      {
        "type": "primary",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Support Vector Machine",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "k-Nearest Neighbour",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Feature Selection",
        "specific": "Chi-square, Variance Threshold, Pearson correlation coefficient, Mutual Information",
        "novel_contribution": "Shows aggressive feature selection significantly improves models and mitigates rapidly growing Android feature spaces"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "CNNs on opcode pseudoimages",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Sequence models",
        "specific": "API call/system call sequence modeling",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "NLP embedding",
        "specific": "word2vec on opcodes",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Balanced Android apps dataset (2019–2021, 124k)",
        "type": "public",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "UpToDown",
        "type": "public",
        "domain": "mobile_app_store",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "APKMirror",
        "type": "public",
        "domain": "mobile_app_store",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "F-Droid",
        "type": "public",
        "domain": "mobile_app_store",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusShare",
        "type": "public",
        "domain": "malware_repository",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusTotal",
        "type": "public",
        "domain": "threat_intelligence_labeling",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Drebin dataset (2014)",
        "type": "public",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "AMD (Android Malware Dataset, 2017)",
        "type": "public",
        "domain": "android_apk",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Permissions features + traditional ML (Peiravian and Zhu, 2013 and follow-ups)",
        "paper_reference": "Peiravian and Zhu (2013); later works [17–21]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "API call features (frequency/usage, sequence/graph) + ML",
        "paper_reference": "e.g., [22–26]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Opcode features (n-grams, embeddings) + ML",
        "paper_reference": "e.g., [27,28]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Opcode pseudoimages + CNN",
        "paper_reference": "e.g., [29,30]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Drebin static feature set + ML",
        "paper_reference": "Arp et al., 2014",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "System call features + ML",
        "paper_reference": "e.g., [35,36]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Dynamic API call features + ML",
        "paper_reference": "[34]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Network traffic (HTTP/TCP) features + ML",
        "paper_reference": "[37,38]; Wang et al., 2016 (HTTP)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Hybrid: permissions + network traffic",
        "paper_reference": "Kandukuru and Sharma (2017); Shyong et al. (year not specified here)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Hybrid: permissions + system calls",
        "paper_reference": "[41]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Deep learning on permissions/API (Transformers/BERT)",
        "paper_reference": "Souani et al. (BERT); Bourebaa and Benmohammed",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "F1 score",
      "True Positive Rate (TPR)",
      "True Negative Rate (TNR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Are feature-based ML approaches still sufficient for Android malware detection in a contemporary Android environment?",
        "Do dynamic features provide a significant benefit over static features for malware detection?",
        "Which static and dynamic feature types are most predictive (e.g., API calls, opcodes, network traffic, system calls)?",
        "Do simpler, traditional ML models outperform more complex deep learning models in this context?",
        "What is the impact of aggressive feature selection on performance with rapidly expanding Android feature sets?",
        "Can ensembles combining top static and dynamic models outperform individual models without relying on brittle network features?"
      ],
      "gaps_identified": [
        "Past evaluations often used small, dated, or imbalanced datasets (e.g., Drebin 2014, AMD 2017), limiting contemporary relevance.",
        "Most prior studies used historic Android OS versions yielding non-representative feature spaces (e.g., API calls grew from ~1k to >100k).",
        "Replicability issues in ML and security domains; reimplementations often diverge from published results.",
        "Weak reporting standards: over-reliance on accuracy with imbalanced data, limited metrics, lack of variance reporting and statistical testing.",
        "Increasing Android complexity inflates feature counts, creating modeling and extraction challenges."
      ],
      "limitations": [
        "Not feasible to reimplement all prior works; selection focuses on representative, foundational, and diverse approaches.",
        "Scope limited to binary malware vs benign classification; excludes multi-class family classification due to labeling ambiguity and imbalance.",
        "Dynamic analysis and reliable network traffic capture are complex and brittle, especially in virtualized environments.",
        "Dataset covers 2019–2021; results may not capture post-2021 malware evolution.",
        "Findings contextualized to the chosen balanced dataset and contemporary environment; external validity to other settings not directly tested."
      ],
      "future_work": [],
      "motivation": "To reassess the effectiveness of feature-based Android malware detection on a level playing field using a contemporary Android environment and a large, balanced, up-to-date dataset, amid a trend toward more complex end-to-end models.",
      "potential_research_ideas": [
        "Extend the reassessment to multi-class malware family classification with contemporary, consensus-based labeling and robust handling of class imbalance.",
        "Evaluate robustness to code obfuscation, packing, and evasion tactics; design adversarially robust feature-based detectors.",
        "Develop continual/online learning pipelines to handle concept drift in Android APIs and malware behaviors over time.",
        "Design lightweight on-device detectors leveraging selected static features (e.g., API calls/opcodes) with resource-aware inference.",
        "Cross-market and cross-region generalization studies and domain adaptation across app stores and Android versions.",
        "Self-supervised pretraining on large unlabeled API/opcode sequences to improve feature-based models without heavy annotation.",
        "Automated feature construction and selection with stability selection and causal feature screening to improve interpretability and robustness.",
        "Standardized community benchmark suite with unified extraction pipelines across multiple Android versions and devices.",
        "Privacy-preserving feature extraction and federated evaluation to enable data sharing across organizations.",
        "Calibrated risk scoring and threshold optimization for deployment settings with varying cost structures."
      ],
      "architectural_improvement_recommendations": [
        "Implement calibrated late-fusion ensembles with uncertainty estimation (e.g., stacking with calibrated base learners).",
        "Use sparsity-inducing models and grouped feature selection (by API family/permission group) to improve efficiency and interpretability.",
        "Adopt efficient sequence models (e.g., linear-attention transformers or temporal CNNs) for API/opcode sequences where order matters.",
        "Apply stability selection and SHAP-informed pruning to create compact, robust static feature subsets.",
        "Domain adaptation and covariate shift correction for new Android versions and evolving API surfaces.",
        "Distill dynamic models into static surrogates to avoid brittle network features while retaining performance.",
        "Active learning for targeted labeling of uncertain apps to reduce labeling cost and improve model maintenance."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Dynamic analysis is complex and resource-intensive compared to static analysis.",
        "Reliable collection of network traffic is brittle in virtualized environments.",
        "Rapid growth in Android feature space (e.g., >100k API calls) complicates feature extraction and modeling."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Reimplements and reevaluates 18 foundational feature-based Android anti-malware studies on a level playing field; majority still exceed 95% accuracy, with best models above 98%.",
      "Provides and shares a balanced, up-to-date dataset of 124,000 Android apps (2019–2021) and the tools used to create it.",
      "Finds static-feature models and traditional ML often outperform more expensive dynamic and deep learning approaches.",
      "Introduces an ensemble combining top static and dynamic models that achieves the highest accuracy and TPR without relying on brittle network features.",
      "Demonstrates that aggressive feature selection significantly improves models and offers a way to handle rapidly increasing Android feature counts."
    ]
  },
  {
    "arxiv_id": "2302.02740v1",
    "title": "AuthentiSense: A Scalable Behavioral Biometrics Authentication Scheme using Few-Shot Learning for Mobile Platforms",
    "authors": "Hossein Fereidooni; Jan König; Phillip Rieger; Marco Chilese; Bora Gökbakan; Moritz Finke; Alexandra Dmitrienko; Ahmad-Reza Sadeghi",
    "abstract": "Mobile applications are widely used for online services sharing a large amount of personal data online. One-time authentication techniques such as passwords and physiological biometrics (e.g., fingerprint, face, and iris) have their own advantages but also disadvantages since they can be stolen or emulated, and do not prevent access to the underlying device, once it is unlocked. To address these challenges, complementary authentication systems based on behavioural biometrics have emerged. The goal is to continuously profile users based on their interaction with the mobile device. However, existing behavioural authentication schemes are not (i) user-agnostic meaning that they cannot dynamically handle changes in the user-base without model re-training, or (ii) do not scale well to authenticate millions of users.   In this paper, we present AuthentiSense, a user-agnostic, scalable, and efficient behavioural biometrics authentication system that enables continuous authentication and utilizes only motion patterns (i.e., accelerometer, gyroscope and magnetometer data) while users interact with mobile apps. Our approach requires neither manually engineered features nor a significant amount of data for model training. We leverage a few-shot learning technique, called Siamese network, to authenticate users at a large scale. We perform a systematic measurement study and report the impact of the parameters such as interaction time needed for authentication and n-shot verification (comparison with enrollment samples) at the recognition stage. Remarkably, AuthentiSense achieves high accuracy of up to 97% in terms of F1-score even when evaluated in a few-shot fashion that requires only a few behaviour samples per user (3 shots). Our approach accurately authenticates users only after 1 second of user interaction. For AuthentiSense, we report a FAR and FRR of 0.023 and 0.057, respectively.",
    "published_date": "2023-02-06",
    "pdf_link": "https://arxiv.org/pdf/2302.02740v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "Continuous Authentication (Behavioral Biometrics)",
      "specific_problem": "User-agnostic, scalable continuous user authentication on mobile devices using motion-sensor behavioral biometrics with few-shot learning",
      "attack_types": [
        "Impersonation / account takeover",
        "Bots",
        "Remote Access Trojans (RATs)",
        "Emulators",
        "Sensor data injection (considered in threat model)",
        "Man-in-the-middle (assumed mitigated via TLS/SSL)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Siamese Network",
        "specific": "1D CNN-based Siamese encoder with triplet loss and Euclidean (L2) distance",
        "novel_contribution": "User-agnostic, scalable few-shot behavioral authentication using only motion sensors; L2-normalized embeddings with decision MLP and EER-based thresholding; no hand-crafted features required"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D CNN feature extractor (Conv1D + BatchNorm + MaxPool + Dense to 32-dim embedding)",
        "novel_contribution": "End-to-end feature learning from raw accelerometer, gyroscope, and magnetometer streams without feature engineering"
      },
      {
        "type": "primary",
        "category": "Feedforward Neural Network",
        "specific": "Decision network (dense layers with ReLU, BatchNorm, Dropout, sigmoid output)",
        "novel_contribution": "Binary classifier on L2 distance of embedding vectors with EER-derived thresholding"
      },
      {
        "type": "baseline",
        "category": "Siamese Network",
        "specific": "Pairwise (contrastive loss) training vs. triplet loss",
        "novel_contribution": "Ablation comparing pairwise vs. triplet sampling/training strategies"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Few-shot Learning",
      "Metric Learning"
    ],
    "datasets": [
      {
        "name": "Proprietary mobile banking motion-sensor dataset (bank customers)",
        "type": "proprietary",
        "domain": "motion_sensors",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "F1-score",
      "FAR (False Acceptance Rate)",
      "FRR (False Rejection Rate)",
      "EER (Equal Error Rate)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a Siamese few-shot learning approach provide user-agnostic, scalable continuous authentication for millions of users without retraining when the user base changes?",
        "How much user interaction time is needed for reliable authentication using motion sensors?",
        "What is the impact of n-shot verification (number of enrollment samples) on recognition performance?",
        "How do different training strategies (pairwise/contrastive vs. triplet loss) affect authentication performance?"
      ],
      "gaps_identified": [
        "Existing behavioral authentication schemes often require large amounts of training data to build accurate models",
        "They are not scalable/user-agnostic and only work for a fixed set of trained users",
        "They frequently require a per-user model, leading to resource-intensive deployment",
        "They often require long interaction times to learn user behavior precisely"
      ],
      "limitations": [
        "Assumes sensor data integrity protected by hardware security (e.g., ARM TrustZone) and a trusted service provider training environment",
        "Assumes secure communication channels (TLS/SSL) and excludes on-device MITM/replay under these assumptions",
        "Evaluation focuses on motion sensors only (accelerometer, gyroscope, magnetometer) and a single mobile app domain (banking); generalization to other apps/devices not discussed in provided text",
        "No adversarial ML evaluation reported in the provided text (e.g., spoofing of behavioral signals, model evasion)"
      ],
      "future_work": [],
      "motivation": "Complement explicit authentication with continuous, unobtrusive behavioral biometrics; overcome lack of scalability/user-agnosticism, heavy data demands, per-user models, and long interaction times in existing methods.",
      "potential_research_ideas": [
        "Multi-modal fusion with touch/keystroke, navigation, and app usage metadata to improve robustness and reduce required interaction time",
        "Cross-device and cross-app domain adaptation (e.g., meta-learning or domain generalization) to handle sensor, hardware, and context variability",
        "Adversarial robustness studies and defenses against sensor spoofing, replay, and emulator-based evasion (e.g., adversarial training or detection of synthetic motion patterns)",
        "Privacy-preserving training and inference (e.g., federated learning, secure aggregation, on-device embedding computation)",
        "Continual and personalized adaptation (e.g., lightweight on-device fine-tuning or prototype updates) with drift detection",
        "Open-set and OOD detection to recognize previously unseen users and abnormal behaviors",
        "Self-supervised pretraining on large unlabeled motion data to further reduce labeled data needs",
        "Energy-efficient and on-device deployment strategies (quantization, pruning, knowledge distillation) for real-time mobile use"
      ],
      "architectural_improvement_recommendations": [
        "Replace or complement triplet loss with prototypical networks or matching networks for simpler n-shot classification and faster enrollment",
        "Hard negative mining strategy improvements (semi-hard or distance-weighted sampling) to accelerate convergence",
        "Temporal modeling of motion sequences with CNN-LSTM/Temporal Convolution Networks to capture longer dependencies when needed",
        "Adaptive per-user thresholds or calibration layers to handle inter-user variability while remaining user-agnostic",
        "Add contrastive/self-supervised pretraining (e.g., SimCLR/TS-TCC adaptations to IMU data) before supervised fine-tuning",
        "Embed lightweight OOD detector on distances or classifier logits to improve security against unknown users/behaviors",
        "Model compression (8-bit quantization, structured pruning) for on-device inference under tight resource budgets"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "TensorFlow",
        "Keras"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Mobile banking application with a client-side Behavioral Authentication Module (BAM) potentially in ARM TrustZone; training and model management at the service provider backend/data center",
      "scalability_discussed": true,
      "inference_time": "Authenticates after approximately 1 second of user interaction (window length); exact per-sample inference latency not provided",
      "deployment_challenges": [
        "Requires trusted sensor pipeline and secure execution environment (e.g., ARM TrustZone) to protect sensor integrity",
        "Requires secure communication (TLS/SSL) and trusted service provider infrastructure",
        "Fallback handling to password after repeated failures and associated UX/security tuning",
        "Generalization across devices and app contexts may require additional calibration or adaptation"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "We present AuthentiSense, a user-agnostic behavioral authentication system that utilizes few-shot learning to authenticate users quickly at large scale without requiring a significant amount of data for model training.",
      "We develop an end-to-end neural network architecture that can dynamically handle user changes without requiring re-training and feature engineering of input data. It only utilizes motion patterns (i.e., accelerometer, gyroscope and magnetometer data).",
      "Performance: “AuthentiSense achieves high accuracy of up to 97% in terms of F1-score even when evaluated in a few-shot fashion that requires only a few behaviour samples per user (3 shots). Our approach accurately authenticates users only after 1 second of user interaction. For AuthentiSense, we report a FAR and FRR of 0.023 and 0.057, respectively.”",
      "We conduct an extensive and systematic measurement study investigating the impact of training strategy (pairwise or triplet), interaction time, and n-shot verification at recognition."
    ]
  },
  {
    "arxiv_id": "2301.01701v2",
    "title": "Extending Source Code Pre-Trained Language Models to Summarise Decompiled Binaries",
    "authors": "Ali Al-Kaswan; Toufique Ahmed; Maliheh Izadi; Anand Ashok Sawant; Premkumar Devanbu; Arie van Deursen",
    "abstract": "Reverse engineering binaries is required to understand and analyse programs for which the source code is unavailable. Decompilers can transform the largely unreadable binaries into a more readable source code-like representation. However, reverse engineering is time-consuming, much of which is taken up by labelling the functions with semantic information.   While the automated summarisation of decompiled code can help Reverse Engineers understand and analyse binaries, current work mainly focuses on summarising source code, and no suitable dataset exists for this task.   In this work, we extend large pre-trained language models of source code to summarise decompiled binary functions. Furthermore, we investigate the impact of input and data properties on the performance of such models. Our approach consists of two main components; the data and the model.   We first build CAPYBARA, a dataset of 214K decompiled function-documentation pairs across various compiler optimisations. We extend CAPYBARA further by generating synthetic datasets and deduplicating the data.   Next, we fine-tune the CodeT5 base model with CAPYBARA to create BinT5. BinT5 achieves the state-of-the-art BLEU-4 score of 60.83, 58.82, and 44.21 for summarising source, decompiled, and synthetically stripped decompiled code, respectively. This indicates that these models can be extended to decompiled binaries successfully.   Finally, we found that the performance of BinT5 is not heavily dependent on the dataset size and compiler optimisation level. We recommend future research to further investigate transferring knowledge when working with less expressive input formats such as stripped binaries.",
    "published_date": "2023-01-04",
    "pdf_link": "https://arxiv.org/pdf/2301.01701v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software and Application Security",
      "subdomain": "Binary Analysis and Reverse Engineering",
      "specific_problem": "Automatic summarization of decompiled binary functions to assist reverse engineering",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer (Encoder-Decoder)",
        "specific": "CodeT5 (base) fine-tuned",
        "novel_contribution": "Adapts a source-code pre-trained model to summarise decompiled and demi-stripped binaries (BinT5)"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Transfer Learning",
      "Fine-tuning"
    ],
    "datasets": [
      {
        "name": "CAPYBARA",
        "type": "public",
        "domain": "decompiled_functions_with_documentation",
        "link": "https://doi.org/10.5281/zenodo.7229809",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "CAPYBARA (demi-stripped variant)",
        "type": "synthetic",
        "domain": "decompiled_functions_with_identifiers_removed_post-decompilation",
        "link": "https://doi.org/10.5281/zenodo.7229809",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "CAPYBARA (deduplicated splits)",
        "type": "public",
        "domain": "decompiled_functions_with_documentation_deduplicated",
        "link": "https://doi.org/10.5281/zenodo.7229809",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "BinSwarm",
        "type": "public",
        "domain": "aligned_source_and_(stripped-)decompiled_functions",
        "link": "https://hub.docker.com/r/binswarm/cbuilds",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "BLEU-4"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can source code pre-trained language models be fine-tuned to summarise decompiled binary functions effectively?",
        "How do input properties (source, decompiled, demi-stripped/stripped) affect summarisation performance?",
        "What is the impact of compiler optimisation levels on performance?",
        "How do dataset size and duplication levels influence model performance?"
      ],
      "gaps_identified": [
        "No suitable dataset existed for summarising decompiled binaries prior to this work.",
        "Prior binary reverse engineering work primarily targets recovering names/types, not high-level semantic summaries.",
        "Stripped binaries remove most of the natural language channel, making summarisation and alignment difficult."
      ],
      "limitations": [
        "High failure rate when decompiling and aligning stripped functions; limited number of usable stripped samples (e.g., 14,245 including duplicates; 7,826 deduplicated).",
        "Performance on stripped/demi-stripped code is substantially lower than on source/decompiled code.",
        "Dataset relies on presence and quality of source documentation; many functions lack documentation (majority of aligned functions had no docs).",
        "Focus on C projects compiled for Linux using GCC/Clang and Ghidra decompiler; generalisation to other languages/toolchains not demonstrated."
      ],
      "future_work": [
        "Further investigate transferring knowledge for less expressive input formats such as stripped binaries.",
        "Explore robustness across architectures, toolchains, and decompilers beyond Ghidra.",
        "Improve alignment and recovery for stripped binaries to increase usable training data."
      ],
      "motivation": "Automate high-level function labelling to reduce time and expertise required in binary reverse engineering where source code is unavailable.",
      "potential_research_ideas": [
        "Design multi-modal models that jointly encode decompiled pseudo-C with assembly/CFG/call graphs for better semantics on stripped binaries.",
        "Pre-train on large corpora of decompiled code (self-supervised) before fine-tuning on summary pairs to reduce reliance on documentation.",
        "Apply domain adaptation or continual learning to bridge source↔decompiled distribution gaps, especially for stripped code.",
        "Use retrieval-augmented summarisation to leverage nearest neighbours from large binary codebases during inference.",
        "Combine summarisation with name/type recovery in a multitask setup to mutually reinforce performance.",
        "Leverage contrastive learning between source and decompiled views of the same function to transfer natural-channel knowledge.",
        "Incorporate dynamic analysis traces (where available) to enrich semantics for difficult functions.",
        "Explore instruction-level tokenisation and normalization schemes tailored to decompiler idiosyncrasies for robustness across tools."
      ],
      "architectural_improvement_recommendations": [
        "Augment the encoder with graph modules (e.g., GNN over CFG) fused with a Transformer to capture control/data flow.",
        "Use adapter layers or LoRA for efficient domain adaptation from source to decompiled code, enabling rapid retargeting to new toolchains.",
        "Introduce copy/pointer mechanisms and identifier placeholders to better handle limited/noisy identifiers in demi-stripped/stripped inputs.",
        "Adopt retrieval-augmented generation (RAG) to condition the decoder on similar functions from an index of decompiled code.",
        "Pre-train with masked span denoising on decompiled corpora, then fine-tune for summarisation to reduce dependence on labels.",
        "Train a joint model with auxiliary tasks (e.g., variable/type recovery) to provide richer supervision signals.",
        "Apply curriculum learning by progressively increasing optimisation/obfuscation levels during training."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/AISE-TUDelft/Capybara-BinT5",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Poor quality and alignment failures on stripped binaries reduce training/evaluation coverage.",
        "Heavy duplication in real-world binaries complicates evaluation and may bias metrics.",
        "Variability across compiler optimisations and toolchains can degrade generalisation.",
        "Dependence on decompiler accuracy and idiosyncrasies (e.g., Ghidra) affects input quality.",
        "Limited availability of reliable ground-truth summaries in the wild."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces CAPYBARA, a dataset of 214K decompiled function–documentation pairs across compiler optimisations, with demi-stripped and deduplicated variants.",
      "Presents BinT5, a fine-tuned CodeT5 model adapted to summarise decompiled code.",
      "Empirically studies the effects of input type (source/decompiled/demi-stripped), compiler optimisation level, dataset size, and duplication on summarisation performance.",
      "Reports state-of-the-art BLEU-4 scores: “60.83, 58.82, and 44.21 for summarising source, decompiled, and synthetically stripped decompiled code, respectively.”"
    ]
  },
  {
    "arxiv_id": "2301.06229v1",
    "title": "Novelty Detection in Network Traffic: Using Survival Analysis for Feature Identification",
    "authors": "Taylor Bradley; Elie Alhajjar; Nathaniel Bastian",
    "abstract": "Intrusion Detection Systems are an important component of many organizations' cyber defense and resiliency strategies. However, one downside of these systems is their reliance on known attack signatures for detection of malicious network events. When it comes to unknown attack types and zero-day exploits, modern Intrusion Detection Systems often fall short. In this paper, we introduce an unconventional approach to identifying network traffic features that influence novelty detection based on survival analysis techniques. Specifically, we combine several Cox proportional hazards models and implement Kaplan-Meier estimates to predict the probability that a classifier identifies novelty after the injection of an unknown network attack at any given time. The proposed model is successful at pinpointing PSH Flag Count, ACK Flag Count, URG Flag Count, and Down/Up Ratio as the main features to impact novelty detection via Random Forest, Bayesian Ridge, and Linear Support Vector Regression classifiers.",
    "published_date": "2023-01-16",
    "pdf_link": "https://arxiv.org/pdf/2301.06229v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Feature identification for novelty (out-of-distribution) detection in network traffic using survival analysis",
      "attack_types": [
        "DoS Hulk",
        "Brute-Force Web",
        "FTP-Patator",
        "Web XSS",
        "DoS GoldenEye",
        "Portscan"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Survival Analysis",
        "specific": "Cox proportional hazards model",
        "novel_contribution": "Uses Cox PH to estimate feature coefficients and hazard ratios that quantify each flow feature's effect on time-to-novelty detection."
      },
      {
        "type": "primary",
        "category": "Survival Analysis",
        "specific": "Kaplan-Meier estimator",
        "novel_contribution": "Uses KM survival curves to model probability of novelty detection over sequence index (time)."
      },
      {
        "type": "baseline",
        "category": "Ensemble Tree",
        "specific": "Random Forest Regressor",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Model",
        "specific": "Bayesian Ridge Regression",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "Linear Support Vector Regression (SVR)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CIC-IDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Cox model coefficients (beta)",
      "Hazard Ratio (HR)",
      "Kaplan-Meier survival function (probability of novelty detection over time)",
      "Novelty detection rate by sequence index (\"death\" probability)",
      "Accuracy (training sanity check; not reported numerically)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Which network flow features most influence a classifier’s novelty (OOD) detection in an IDS setting?",
        "How can survival analysis (Cox PH and Kaplan-Meier) be used to quantify and interpret the impact of flow features on novelty detection timing?"
      ],
      "gaps_identified": [
        "Signature-based IDS struggle with unknown attack types and zero-day exploits.",
        "Anomaly-based IDS conflate anomaly with intrusion, leading to high false positive rates.",
        "Lack of methods that explicitly quantify which network flow features drive novelty detection when models face OOD traffic."
      ],
      "limitations": [
        "Experiments do not directly account for misclassifications of novel attack types as benign (explicitly stated).",
        "Arbitrary novelty threshold (0.40–0.60) for regression output defines \"novelty detection\".",
        "Evaluation limited to a single dataset (CIC-IDS2017) and flow-level features (CICFlowMeter, 84 features).",
        "Only three classical regressors (Random Forest, Bayesian Ridge, Linear SVR) were used; no comparison to standard OOD/novelty detectors (e.g., one-class SVM, autoencoders).",
        "Results partially reported; training accuracy mentioned as a check but not quantitatively provided; some tables/figures referenced may not generalize without more metrics."
      ],
      "future_work": [],
      "motivation": "Modern IDS rely on known attack signatures and often fail on unknown/zero-day attacks; the paper proposes survival analysis to identify flow features influencing novelty detection timing.",
      "potential_research_ideas": [
        "Replace fixed 0.40–0.60 threshold with principled OOD scoring (e.g., calibrated confidence, energy score, likelihood ratio) and study its effect on survival curves and feature coefficients.",
        "Evaluate method across multiple datasets (e.g., UNSW-NB15, CSE-CIC-IDS2018, Bot-IoT) to assess feature importance stability and generalization.",
        "Compare against established novelty/OOD baselines (one-class SVM, deep autoencoders, Mahalanobis distance, ODIN, energy-based OOD) with survival-based interpretability.",
        "Extend from per-flow to sequence-aware models (RNN/Transformer) and apply deep survival analysis to jointly learn temporal dynamics and hazard of novelty.",
        "Incorporate causal feature attribution (e.g., SHAP/SurvSHAP, counterfactual survival analysis) to validate Cox-derived importance under interventions.",
        "Investigate adaptive thresholding policies driven by real-time risk and cost (false negatives vs false positives) and model them with competing risks survival analysis.",
        "Assess robustness under traffic obfuscation/adversarial manipulation and design defenses; integrate adversarial training with survival-based interpretability.",
        "Leverage self-supervised pretraining on PCAPs/flows to reduce labeled dependence and evaluate impact on time-to-novelty detection."
      ],
      "architectural_improvement_recommendations": [
        "Calibrate regression outputs (e.g., Platt scaling/temperature scaling) before applying novelty thresholds to reduce threshold-induced bias in survival outcomes.",
        "Use dedicated open-set/one-class classifiers for novelty (One-Class SVM, Isolation Forest, Deep SVDD) and feed their scores into the survival pipeline.",
        "Adopt probabilistic OOD scores (energy, KL to normal class) as the \"risk\" variable and model hazard using penalized Cox or flexible survival (e.g., DeepSurv).",
        "Include temporal/context features (sessionization, n-gram of flows, inter-arrival times) and model with sequence nets (LSTM/Transformer) plus survival head.",
        "Regularize Cox PH with L1/L2 (lasso/ridge) to improve stability of feature selection across attack combinations; perform cross-validated penalty selection.",
        "Perform sensitivity analysis on novelty threshold and sequence length; learn thresholds via cost-sensitive optimization or Bayesian decision theory.",
        "Add bootstrap/CV to report confidence intervals for HRs and KM curves and test PH assumptions; consider time-varying covariates if needed."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Selecting and maintaining appropriate novelty thresholds in production.",
        "Generalization from a single dataset and chosen attack types to diverse, evolving enterprise traffic.",
        "Dependence on flow feature extraction (CICFlowMeter-like) and sequence construction; real-time sequencing may be non-trivial.",
        "Balancing false alarms vs missed zero-days; current analysis focuses on confusion, not cost-sensitive outcomes."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces an unconventional survival-analysis-based approach to identify features that influence novelty detection in network traffic.",
      "Combines Cox proportional hazards models and Kaplan-Meier estimates to model time-to-novelty detection after injecting unknown attacks.",
      "Experimental framework: train on benign + one known attack; inject a different attack type; define novelty as regression output in [0.40, 0.60]; analyze 84 flow features.",
      "Identifies consistently influential features across classifiers: \"PSH Flag Count, ACK Flag Count, URG Flag Count, and Down/Up Ratio\" as key to novelty detection.",
      "Reports specific Cox/HR results (example, Random Forest on DoS Hulk -> Brute-Force Web): \"PSH Flag Count 0.157 (HR 1.170); ACK Flag Count -0.580 (HR 0.560); URG Flag Count -0.105 (HR 0.900); Down/Up Ratio 1.506 (HR 4.509).\",\"Kaplan-Meier analysis shows varying novelty detection speed across attack combinations; e.g., for combination 1 (RF): \"100% detection by flow index 5 (80% at index 0)\" and for combination 4: \"100% by index 14 (~35% at index 0).\""
    ]
  },
  {
    "arxiv_id": "2301.11161v1",
    "title": "New Approach to Malware Detection Using Optimized Convolutional Neural Network",
    "authors": "Marwan Omar",
    "abstract": "Cyber-crimes have become a multi-billion-dollar industry in the recent years. Most cybercrimes/attacks involve deploying some type of malware. Malware that viciously targets every industry, every sector, every enterprise and even individuals has shown its capabilities to take entire business organizations offline and cause significant financial damage in billions of dollars annually. Malware authors are constantly evolving in their attack strategies and sophistication and are developing malware that is difficult to detect and can lay dormant in the background for quite some time in order to evade security controls. Given the above argument, Traditional approaches to malware detection are no longer effective. As a result, deep learning models have become an emerging trend to detect and classify malware. This paper proposes a new convolutional deep learning neural network to accurately and effectively detect malware with high precision. This paper is different than most other papers in the literature in that it uses an expert data science approach by developing a convolutional neural network from scratch to establish a baseline of the performance model first, explores and implements an improvement model from the baseline model, and finally it evaluates the performance of the final model. The baseline model initially achieves 98% accurate rate but after increasing the depth of the CNN model, its accuracy reaches 99.183 which outperforms most of the CNN models in the literature. Finally, to further solidify the effectiveness of this CNN model, we use the improved model to make predictions on new malware samples within our dataset.",
    "published_date": "2023-01-26",
    "pdf_link": "https://arxiv.org/pdf/2301.11161v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection and Classification",
      "specific_problem": "Image-based malware family classification from PE binaries converted to grayscale images",
      "attack_types": [
        "Ransomware",
        "Botnet",
        "Banking Trojans",
        "Backdoor",
        "Worm"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "Custom CNN developed from scratch; optimized by increasing depth, improving accuracy from 98% to 99.183% on Malimg."
      },
      {
        "type": "baseline",
        "category": "k-NN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "InceptionV3",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "VGG16",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet50",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Hybrid",
        "specific": "CNN-SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "MLP-SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "GRU-SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Hybrid",
        "specific": "Hybrid CNN + SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "Shallow two-layer CNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Malimg",
        "type": "public",
        "domain": "malware_binaries_converted_to_grayscale_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ImageNet",
        "type": "public",
        "domain": "general_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "k-NN with GIST on Malimg",
        "paper_reference": "Nataraj et al. [1]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "98%"
      },
      {
        "method_name": "Feature-engineered (60/320 GIST features)",
        "paper_reference": "S. Yajamanam et al. [10]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "92%"
      },
      {
        "method_name": "Deep model pre-trained with descriptor on ImageNet",
        "paper_reference": "[11]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "92%"
      },
      {
        "method_name": "Fine-tuned shallow two-layer CNN for DDoS malware",
        "paper_reference": "Jiawei et al. [25]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "94% (benign vs malicious)"
      },
      {
        "method_name": "Inception V3 on Malimg",
        "paper_reference": "Bensaud et al. [24]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "99.24%"
      },
      {
        "method_name": "VGG16-Net on Malimg (RGB requirement mismatch on grayscale)",
        "paper_reference": "Bensaud et al. [24]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "14.31%"
      },
      {
        "method_name": "ResNet50 on Malimg (RGB requirement mismatch on grayscale)",
        "paper_reference": "Bensaud et al. [24]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "26.66%"
      },
      {
        "method_name": "CNN-SVM on Malimg",
        "paper_reference": "Bensaud et al. [24]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "93.22%"
      },
      {
        "method_name": "GRU-SVM on Malimg",
        "paper_reference": "Bensaud et al. [24]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "94.17%"
      },
      {
        "method_name": "MLP-SVM on Malimg",
        "paper_reference": "Bensaud et al. [24]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "94.55%"
      },
      {
        "method_name": "Hybrid CNN + SVM",
        "paper_reference": "Lad and Adamuthe (2020) [30]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "98.03%"
      },
      {
        "method_name": "Xception",
        "paper_reference": "Lad and Adamuthe (2020) [30]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "97.56%"
      },
      {
        "method_name": "InceptionV3",
        "paper_reference": "Lad and Adamuthe (2020) [30]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "97.22%"
      },
      {
        "method_name": "VGG16",
        "paper_reference": "Lad and Adamuthe (2020) [30]",
        "metric": "Accuracy",
        "their_result": "99.183%",
        "baseline_result": "96.96%"
      }
    ],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Investigates the impact of the dimension of the input malware images and the impact of the learning technique, i.e., CNN, applied on the performance of image-based malware classification.",
        "Can increasing CNN depth optimize performance beyond a 98% baseline on Malimg?"
      ],
      "gaps_identified": [
        "Most prior works develop an algorithm, apply it to a few datasets, achieve acceptable accuracy, but do not strive to optimize their deep learning models.",
        "Cybersecurity researchers often lack data science best practices for model optimization, leading to a lack of optimized deep learning models."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Rising volume and sophistication of malware render traditional signature- and behavior-based methods insufficient; image-based deep learning (CNN) can capture texture patterns and detect obfuscated/packed variants. The paper aims to provide an optimized CNN approach for higher accuracy.",
      "potential_research_ideas": [
        "Evaluate cross-dataset generalization (e.g., train on Malimg, test on other malware image corpora or newer PE datasets).",
        "Robustness study against packing/obfuscation variations and adversarial perturbations on malware images.",
        "Incorporate static PE header/section features and/or dynamic behavior features into a multimodal model with image inputs.",
        "Self-supervised pretraining on large unlabeled malware binaries/images to improve feature quality.",
        "Domain adaptation/transfer learning from natural-image CNNs adapted to grayscale malware images with proper channel handling.",
        "Open-set/OOD detection for novel malware families and unseen variants.",
        "Lightweight models (e.g., MobileNet/EfficientNet-lite) for endpoint/IoT deployment with quantization/pruning.",
        "Calibration and thresholding for high-precision use cases and risk-aware decision-making.",
        "Explainability via saliency/Grad-CAM over malware images for analyst trust and triage."
      ],
      "architectural_improvement_recommendations": [
        "Add residual/skip connections and batch normalization to stabilize deeper CNNs.",
        "Use multi-scale feature extraction (e.g., Inception-style parallel kernels) adapted for grayscale single-channel inputs.",
        "Introduce attention mechanisms (channel/spatial attention) to emphasize discriminative texture regions.",
        "Apply class-imbalance-aware losses (focal loss, class-balanced loss) and strong data augmentation tailored to binary-to-image domain.",
        "Perform hyperparameter optimization (Bayesian search) over depth/width, kernel sizes, learning rate schedules, and regularization.",
        "Adopt k-fold cross-validation and stratified splits by family to reduce variance and leakage risk.",
        "Add probability calibration (temperature scaling) and uncertainty estimation (MC dropout) for reliable deployment decisions.",
        "Quantization-aware training and post-training pruning/distillation for efficient inference on constrained devices.",
        "Integrate PE structural metadata as additional channels or a parallel MLP branch fused with CNN features."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a new convolutional deep learning neural network to accurately and effectively detect malware with high precision.",
      "Uses an expert data science approach: develop a CNN baseline from scratch, then implement an improvement model from the baseline model.",
      "Evaluates the performance of the final model: baseline 98% accuracy; improved depth achieves 99.183%.",
      "Claims the proposed DNN outperforms most CNN models in the literature.",
      "Uses the improved model to make predictions on new malware samples within the dataset."
    ]
  },
  {
    "arxiv_id": "2303.12891v1",
    "title": "Feature Reduction Method Comparison Towards Explainability and Efficiency in Cybersecurity Intrusion Detection Systems",
    "authors": "Adam M. Lehavi; Seongtae Kim",
    "abstract": "In the realm of cybersecurity, intrusion detection systems (IDS) detect and prevent attacks based on collected computer and network data. In recent research, IDS models have been constructed using machine learning (ML) and deep learning (DL) methods such as Random Forest (RF) and deep neural networks (DNN). Feature selection (FS) can be used to construct faster, more interpretable, and more accurate models. We look at three different FS techniques; RF information gain (RF-IG), correlation feature selection using the Bat Algorithm (CFS-BA), and CFS using the Aquila Optimizer (CFS-AO). Our results show CFS-BA to be the most efficient of the FS methods, building in 55% of the time of the best RF-IG model while achieving 99.99% of its accuracy. This reinforces prior contributions attesting to CFS-BA's accuracy while building upon the relationship between subset size, CFS score, and RF-IG score in final results.",
    "published_date": "2023-03-22",
    "pdf_link": "https://arxiv.org/pdf/2303.12891v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Network-based IDS (NIDS) classification with feature selection for efficiency and explainability on CSE-CIC-IDS2018 (binary and multiclass).",
      "attack_types": [
        "Variety of attacks in CSE-CIC-IDS2018 (6 types expanded to 13 signatures)",
        "Zero-day attacks (included in dataset)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Filter Feature Selection",
        "specific": "Correlation-based Feature Selection with Bat Algorithm (CFS-BA)",
        "novel_contribution": "Empirical comparison on CSE-CIC-IDS2018; most efficient FS with 55% of RF-IG build time while retaining 99.99% of its accuracy."
      },
      {
        "type": "primary",
        "category": "Filter Feature Selection",
        "specific": "Correlation-based Feature Selection with Aquila Optimizer (CFS-AO)",
        "novel_contribution": "Applied and compared to CFS-BA and RF-IG on CSE-CIC-IDS2018 for RF and DNN classifiers."
      },
      {
        "type": "baseline",
        "category": "Embedded Feature Selection",
        "specific": "Random Forest Information Gain (RF-IG)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Ensemble Tree",
        "specific": "Random Forest",
        "novel_contribution": "Configured with 100 trees; depth tuned with OOB score, d=20 chosen."
      },
      {
        "type": "primary",
        "category": "Deep Neural Network",
        "specific": "Feedforward DNN (50-25 hidden units)",
        "novel_contribution": "Outperformed 100-100-100 architecture on accuracy and build time; batch size 32."
      },
      {
        "type": "baseline",
        "category": "Deep Neural Network",
        "specific": "Feedforward DNN (100-100-100 hidden units)",
        "novel_contribution": "Used as an internal baseline; underperformed vs 50-25."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CSE-CIC-IDS2018",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "KDD Cup 1999",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "CIC-IDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Kyoto",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [
      {
        "method_name": "RF-IG (embedded FS)",
        "paper_reference": null,
        "metric": "Build time",
        "their_result": "CFS-BA builds in 55% of the time of the best RF-IG model.",
        "baseline_result": "RF-IG reference (100%)."
      },
      {
        "method_name": "RF-IG (embedded FS)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "CFS-BA achieves 99.99% of the accuracy of the best RF-IG model.",
        "baseline_result": "RF-IG reference (100%)."
      },
      {
        "method_name": "Prior DNN on CSE-CIC-IDS2018",
        "paper_reference": "[5]",
        "metric": "Accuracy (unspecified)",
        "their_result": "Authors report achieving better results than [5].",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1 score",
      "False Alarm Rate (FAR)",
      "Out-of-bag (OOB) score",
      "Macro-averaged metrics"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can CFS-BA and CFS-AO provide faster, more interpretable, and comparably accurate IDS models versus embedded RF-IG?",
        "What is the relationship between subset size, CFS score, and RF-IG score and the final model performance?",
        "How do RF and DNN classifiers perform on CSE-CIC-IDS2018 under different FS methods for binary and multiclass detection?"
      ],
      "gaps_identified": [
        "CFS-BA previously lacked results on CSE-CIC-IDS2018 and lacked results with RF and DNN classifiers.",
        "Aquila Optimizer (AO) had no CSE-CIC-IDS2018 results and prior work used a different fitness function than CFS.",
        "CSE-CIC-IDS2018, while more current, is less commonly reported than CIC-IDS2017 and lacks many published results.",
        "Wrapper FS methods can achieve better accuracy but require much larger build times, limiting applicability.",
        "High intercorrelation among features complicates selecting subsets that maximize CFS score while minimizing feature redundancy."
      ],
      "limitations": [
        "Cannot explore every possible feature subset; relies on metaheuristic optimizers to approximate the global maximum CFS score.",
        "Results reported on a single dataset (CSE-CIC-IDS2018).",
        "Highly skewed class distributions; approach does not describe class rebalancing methods.",
        "Correlation-based FS requires one-hot encoding for classes and focuses on linear monotonic associations (Spearman)."
      ],
      "future_work": [],
      "motivation": "Build faster, more interpretable IDS models by comparing modern filter and embedded feature selection methods and evaluating their trade-offs in efficiency and accuracy.",
      "potential_research_ideas": [
        "Evaluate CFS-BA and CFS-AO across multiple IDS datasets (e.g., CIC-IDS2017, UNSW-NB15) with standardized protocols to establish robust benchmarks.",
        "Design a multi-objective FS that jointly optimizes CFS score, IG, and model-specific performance (e.g., macro-F1) to balance relevance, redundancy, and accuracy.",
        "Incorporate cost-sensitive or class-weighted objectives into FS to explicitly reduce FAR while improving minority-class recall.",
        "Hybridize metaheuristics (e.g., BA + AO) or use ensemble FS to stabilize subset selection across runs.",
        "Investigate wrapper-lite approaches (e.g., early-stopped model-based evaluation or surrogate performance models) to approach wrapper accuracy at filter-like cost.",
        "Assess explainability by validating FS-selected features with post-hoc methods (e.g., SHAP) to check consistency and trustworthiness.",
        "Explore streaming/online FS to adapt subsets over time as network behavior drifts.",
        "Compare additional classifiers (e.g., XGBoost/LightGBM, calibrated RF) under identical FS subsets to assess classifier sensitivity."
      ],
      "architectural_improvement_recommendations": [
        "Use stratified k-fold cross-validation (and nested CV for model selection) instead of a single 50/50 split to reduce variance.",
        "Tune RF more broadly (n_estimators, max_features, class_weight) and calibrate probabilities to manage FAR.",
        "Improve DNN with class-weighted or focal loss, batch normalization, dropout, and early stopping; evaluate alternative widths/depths for skewed data.",
        "Adopt cost-sensitive thresholds or ROC/PR-based operating point selection to explicitly target low FAR.",
        "Introduce imbalanced-learning strategies (e.g., class weights, balanced sampling) to improve minority-class detection.",
        "Implement multi-objective metaheuristics optimizing both CFS score and validation macro-F1 to guide FS search.",
        "Cache correlation computations and use GPU-accelerated or vectorized operations to speed up FS scoring in large datasets.",
        "Add stability selection to report how consistently features are selected across random seeds and folds."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "scikit-learn",
        "TensorFlow"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Local: Nvidia GTX 1650 GPU, 32 GB RAM, Intel Core i7. Final runs on Google Colab Pro+ with up to 53 GB RAM. BA configured with n=100 bats, tmax=1000; RF with 100 trees and tuned depth (d=20)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Highly skewed network traffic classes.",
        "Large-scale dataset size (~16.17 million flows) requiring efficient FS and training.",
        "High intercorrelation across features complicating FS.",
        "Embedded FS (RF-IG) has substantial computational cost compared to filter methods."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comparative evaluation of three feature selection methods (RF-IG, CFS-BA, CFS-AO) for NIDS on CSE-CIC-IDS2018 using RF and DNN.",
      "Empirical finding: CFS-BA builds in 55% of the time of the best RF-IG model while achieving 99.99% of its accuracy.",
      "Analysis of the relationship between subset size, CFS score, and RF-IG score in final results.",
      "Reports DNN architecture comparison (50-25 vs 100-100-100), with 50-25 faster and more accurate in this setting.",
      "Claims improved DNN results over prior work [5] on the same dataset."
    ]
  },
  {
    "arxiv_id": "2301.11804v1",
    "title": "TrojanSAINT: Gate-Level Netlist Sampling-Based Inductive Learning for Hardware Trojan Detection",
    "authors": "Hazem Lashen; Lilas Alrahis; Johann Knechtel; Ozgur Sinanoglu",
    "abstract": "We propose TrojanSAINT, a graph neural network (GNN)-based hardware Trojan (HT) detection scheme working at the gate level. Unlike prior GNN-based art, TrojanSAINT enables both pre-/post-silicon HT detection. TrojanSAINT leverages a sampling-based GNN framework to detect and also localize HTs. For practical validation, TrojanSAINT achieves on average (oa) 78% true positive rate (TPR) and 85% true negative rate (TNR), respectively, on various TrustHub HT benchmarks. For best-case validation, TrojanSAINT even achieves 98% TPR and 96% TNR oa. TrojanSAINT outperforms related prior works and baseline classifiers. We release our source codes and result artifacts.",
    "published_date": "2023-01-27",
    "pdf_link": "https://arxiv.org/pdf/2301.11804v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Hardware Trojan Detection",
      "specific_problem": "Gate-level netlist hardware Trojan detection and localization without golden reference (pre- and post-silicon)",
      "attack_types": [
        "hardware_trojan"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "GraphSAINT sampling + GraphSAGE (GNN-RE-style architecture)",
        "novel_contribution": "Sampling-based inductive GNN on gate-level netlists for HT detection and localization with tuned classification thresholds; enables both pre- and post-silicon detection"
      },
      {
        "type": "baseline",
        "category": "Ensemble Trees",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Model",
        "specific": "Logistic Regression",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Fully Connected Neural Network",
        "specific": "3-layer FCNN (SELU, batch norm)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GNN-RE",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Inductive (subgraph sampling)"
    ],
    "datasets": [
      {
        "name": "TrustHub hardware Trojan gate-level netlists (17 benchmarks: rs232t1000, rs232t1100, rs232t1200, rs232t1300, rs232t1400, rs232t1500, rs232t1600, s15850t100, s35932t100, s35932t200, s35932t300, s38417t100, s38417t200, s38417t300, s38584t100, s38584t200, s38584t300)",
        "type": "public",
        "domain": "gate_level_netlists",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Practical validation (unknown Trojans in unseen circuits), with thresholding: average TPR/TNR",
        "their_result": "0.78/0.85",
        "baseline_result": "0.80/0.76"
      },
      {
        "method_name": "FCNN (3-layer)",
        "paper_reference": null,
        "metric": "Practical validation, with thresholding: average TPR/TNR",
        "their_result": "0.78/0.85",
        "baseline_result": "0.82/0.74"
      },
      {
        "method_name": "GNN-RE",
        "paper_reference": "[15] in paper",
        "metric": "Practical validation, with thresholding: average TPR/TNR",
        "their_result": "0.78/0.85",
        "baseline_result": "0.81/0.77"
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "Practical validation, with thresholding: average TPR/TNR",
        "their_result": "0.78/0.85",
        "baseline_result": "0.86/0.54"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Practical validation, with thresholding: average TPR/TNR",
        "their_result": "0.78/0.85",
        "baseline_result": "0.70/0.88"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "Practical validation (thresholding N/A), average TPR/TNR",
        "their_result": "0.78/0.85",
        "baseline_result": "N/A (not provided in with-thresholding table)"
      },
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Best-case (leave-one-out), with thresholding: average TPR/TNR",
        "their_result": "0.98/0.96",
        "baseline_result": "0.93/0.93"
      },
      {
        "method_name": "FCNN (3-layer)",
        "paper_reference": null,
        "metric": "Best-case (leave-one-out), with thresholding: average TPR/TNR",
        "their_result": "0.98/0.96",
        "baseline_result": "0.91/0.89"
      },
      {
        "method_name": "GNN-RE",
        "paper_reference": "[15] in paper",
        "metric": "Best-case (leave-one-out), with thresholding: average TPR/TNR",
        "their_result": "0.98/0.96",
        "baseline_result": "0.98/0.96"
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "Best-case (leave-one-out), with thresholding: average TPR/TNR",
        "their_result": "0.98/0.96",
        "baseline_result": "0.89/0.81"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Best-case (leave-one-out), with thresholding: average TPR/TNR",
        "their_result": "0.98/0.96",
        "baseline_result": "0.91/0.994"
      },
      {
        "method_name": "Related work R-HTD",
        "paper_reference": "[18] in paper",
        "metric": "Best-case (as reported by authors), average across 17 benchmarks: TPR/TNR",
        "their_result": "0.98/0.96",
        "baseline_result": "0.84/0.95"
      },
      {
        "method_name": "Related work (GLN ML method)",
        "paper_reference": "[19] in paper",
        "metric": "Best-case (as reported), average TPR/TNR",
        "their_result": "0.98/0.96",
        "baseline_result": "0.72/1.00"
      },
      {
        "method_name": "Related work (GLN ML method)",
        "paper_reference": "[20] in paper",
        "metric": "Best-case (as reported), average TPR/TNR",
        "their_result": "0.98/0.96",
        "baseline_result": "0.55/1.00"
      }
    ],
    "performance_metrics_used": [
      "TPR",
      "TNR",
      "average(TPR,TNR) for threshold selection"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a sampling-based inductive GNN operating directly on gate-level netlists detect and localize hardware Trojans without requiring a golden reference?",
        "How to address severe class imbalance (few HT gates vs many benign) in GLN graphs to improve detection performance?",
        "Can the approach generalize to unknown Trojans on unseen circuits (practical validation)?"
      ],
      "gaps_identified": [
        "Prior GNN-based HT detection cannot localize HTs.",
        "Prior GNN-based works operate at RTL, not at gate-level netlists, thus are limited to pre-silicon and cannot handle post-silicon detection.",
        "Severe class imbalance in HT datasets (HT gates as low as 0.14–11.29%, up to 1:719 ratio).",
        "GLN complexity: flattened, very large graphs (thousands to millions of gates) make standard GNNs challenging."
      ],
      "limitations": [
        "Performance is sensitive to random seeds; best-of-6 runs reported for each model.",
        "Requires threshold tuning to mitigate class imbalance; fixed threshold may not generalize optimally across designs.",
        "Feature set is relatively simple (gate type, degrees, distances) and discards directionality; related works with heavy feature engineering can outperform on small benchmarks.",
        "Directionality is discarded in graph construction, which may omit useful structural information."
      ],
      "future_work": [
        "Study the role of different feature vectors in more detail (as stated by authors)."
      ],
      "motivation": "Enable practical pre- and post-silicon HT detection and localization directly on gate-level netlists, overcoming RTL-only scope and lack of localization in prior GNN-based methods while handling GLN scale and class imbalance.",
      "potential_research_ideas": [
        "Incorporate edge directionality and types (e.g., signal vs clock/reset) and learn edge features to improve localization.",
        "Use attention-based GNNs (e.g., GAT, Graph Transformer) to better capture salient HT substructures.",
        "Apply cost-sensitive or focal loss and calibrated probability estimation to reduce reliance on post-hoc threshold tuning.",
        "Self-supervised or contrastive pretraining on large GLN corpora to improve generalization to unseen designs/technologies.",
        "Hierarchical graph modeling to reintroduce lost design hierarchy (pooling over modules) for scalability and context.",
        "Multi-task learning: jointly predict HT gate labels, HT trigger/payload type, and candidate Trojan subgraph boundaries.",
        "Domain adaptation across technology libraries and parsing variants to improve robustness.",
        "Uncertainty estimation (e.g., MC dropout) to set adaptive thresholds per design or subgraph.",
        "Active learning to query labels for suspicious regions to improve model with minimal annotation.",
        "Explainability methods tailored to circuits (e.g., subgraph extraction, logic cone relevance) to aid human auditors."
      ],
      "architectural_improvement_recommendations": [
        "Augment node features with richer structural encodings (e.g., Laplacian positional encodings, Weisfeiler-Lehman features) and timing/power hints if available.",
        "Switch to direction-aware message passing or encode direction via separate adjacency matrices and edge embeddings.",
        "Use class-balanced/focal loss with logit adjustment; incorporate calibrated Platt/temperature scaling to set thresholds systematically.",
        "Adopt attention-based aggregators (GAT) or Graph Transformers for long-range dependencies in large GLNs.",
        "Introduce hierarchical pooling (e.g., DiffPool) to model macro-to-micro context and improve scalability.",
        "Add a subgraph-level detection head to localize HT regions alongside gate-level labels.",
        "Employ multi-seed ensembling or snapshot ensembling to mitigate seed sensitivity."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/DfX-NYUAD/TrojanSAINT",
      "frameworks": [
        "PyTorch",
        "scikit-learn",
        "Python",
        "bash"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Training on 4x Nvidia V100 GPUs and 360GB RAM; GNN-RE/TrojanSAINT training ~15–30 minutes per model, FCNN ~10 minutes, others ~3 minutes total; inference takes a few seconds."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "a few seconds per model/design (as reported)",
      "deployment_challenges": [
        "Severe class imbalance requires careful thresholding/calibration.",
        "Large, flattened GLN graphs challenge memory and training stability; sampling helps but adds variance.",
        "Performance sensitivity to random seeds suggests need for ensembling/calibration.",
        "Differences in technology libraries/parsing may affect portability.",
        "Lack of golden references in-field complicates validation and threshold selection."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Parser for converting gate-level netlists to graphs with tailored features (gate type, degrees, distances to I/O).",
      "GNN-based method (GraphSAINT sampling with GraphSAGE) for detection and localization of HTs on GLNs.",
      "Threshold tuning procedure to mitigate class imbalance and improve TPR/TNR.",
      "Comprehensive empirical study: practical validation on unknown HTs/unseen circuits; outperforming prior works and strong baselines.",
      "Open-sourced code and experimental artifacts."
    ]
  },
  {
    "arxiv_id": "2301.03207v2",
    "title": "Negative Results of Fusing Code and Documentation for Learning to Accurately Identify Sensitive Source and Sink Methods An Application to the Android Framework for Data Leak Detection",
    "authors": "Jordan Samhi; Maria Kober; Abdoul Kader Kabore; Steven Arzt; Tegawendé F. Bissyandé; Jacques Klein",
    "abstract": "Apps on mobile phones manipulate all sorts of data, including sensitive data, leading to privacy-related concerns. Recent regulations like the European GDPR provide rules for the processing of personal and sensitive data, like that no such data may be leaked without the consent of the user.   Researchers have proposed sophisticated approaches to track sensitive data within mobile apps, all of which rely on specific lists of sensitive source and sink API methods. The data flow analysis results greatly depend on these lists' quality. Previous approaches either used incomplete hand-written lists that quickly became outdated or relied on machine learning. The latter, however, leads to numerous false positives, as we show.   This paper introduces CoDoC, a tool that aims to revive the machine-learning approach to precisely identify privacy-related source and sink API methods. In contrast to previous approaches, CoDoC uses deep learning techniques and combines the source code with the documentation of API methods. Firstly, we propose novel definitions that clarify the concepts of sensitive source and sink methods. Secondly, based on these definitions, we build a new ground truth of Android methods representing sensitive source, sink, and neither (i.e., no source or sink) methods that will be used to train our classifier.   We evaluate CoDoC and show that, on our validation dataset, it achieves a precision, recall, and F1 score of 91% in 10-fold cross-validation, outperforming the state-of-the-art SuSi when used on the same dataset. However, similarly to existing tools, we show that in the wild, i.e., with unseen data, CoDoC performs poorly and generates many false positive results. Our findings, together with time-tested results of previous approaches, suggest that machine-learning models for abstract concepts such as privacy fail in practice despite good lab results.",
    "published_date": "2023-01-09",
    "pdf_link": "https://arxiv.org/pdf/2301.03207v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "Privacy and Data Leak Detection",
      "specific_problem": "Automatic identification of sensitive source and sink API methods for Android taint analysis",
      "attack_types": [
        "Data leakage"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Neural embedding fusion + classifier",
        "specific": null,
        "novel_contribution": "Fuses code embeddings (Code2Vec) and documentation embeddings (Sentence-BERT) to classify Android API methods as Sensitive Source, Sink, or Neither"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Sentence-BERT",
        "novel_contribution": "Uses sentence-level embeddings of API JavaDoc for privacy-related classification"
      },
      {
        "type": "primary",
        "category": "Attention-based code model",
        "specific": "Code2Vec",
        "novel_contribution": "Retrained on Android framework Java code to capture Android-specific semantics for method-level embeddings"
      },
      {
        "type": "baseline",
        "category": "Classical ML (feature-based)",
        "specific": "SuSi (2014)",
        "novel_contribution": "Feature-based supervised ML on code properties (method names, parameter types, modifiers) without documentation"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CoDoC Ground Truth of Android Sensitive Source/Sink/Neither Methods",
        "type": "public",
        "domain": "api_methods",
        "link": "https://github.com/JordanSamhi/CoDoC",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Android Framework Methods Corpus (API 30)",
        "type": "public",
        "domain": "api_methods",
        "link": "https://android.googlesource.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SuSi",
        "paper_reference": "[3] (2014)",
        "metric": "Precision/Recall/F1 (10-fold cross-validation on same dataset)",
        "their_result": "“it achieves a precision, recall, and F1 score of 91% in 10-fold cross-validation, outperforming the state-of-the-art SuSi when used on the same dataset.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Precision",
      "Recall",
      "F1",
      "False Positive Rate (qualitative/observational in the wild)",
      "Cohen’s Kappa (inter-rater agreement for labeling)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can deep learning over fused code and documentation accurately identify privacy-related sensitive sources and sinks in Android?",
        "Do models trained on labeled Android API methods generalize to previously unseen API methods (real-world data)?",
        "Does incorporating documentation alleviate false positives observed in prior ML-based approaches like SuSi?"
      ],
      "gaps_identified": [
        "Lack of clear and consistent definitions for sensitive SOURCE and SINK in prior work.",
        "Existing lists (e.g., SuSi) are not specific to privacy analysis and produce many false positives.",
        "Prior ML approaches ignore API documentation and use limited code features, missing semantics.",
        "A lab vs. real-world generalization gap: high cross-validation scores but poor performance on unseen methods."
      ],
      "limitations": [
        "“in the wild, i.e., with unseen data, CoDoC performs poorly and generates many false positive results.”",
        "Small labeled dataset (1,015 methods) with selection seeded by SuSi outputs may introduce bias.",
        "Supervised learning may be insufficient to bridge the semantic gap between API methods and the abstract concept of privacy.",
        "Evaluation outside the lab is qualitative for false positive characterization; no comprehensive numeric FPR reported for CoDoC in the wild."
      ],
      "future_work": [
        "“novel approaches are necessary” beyond supervised ML to capture privacy semantics.",
        "“call for a more careful evaluation of machine learning results” beyond cross-validation on small datasets."
      ],
      "motivation": "Provide precise, up-to-date sensitive source/sink lists for Android taint-based privacy analysis at scale because manual curation is infeasible and existing ML-based lists yield many false positives.",
      "potential_research_ideas": [
        "Hybrid analysis: combine precise static program analysis (e.g., semantic taint preconditions, permission checks, side-effect summaries) with ML to filter candidate sources/sinks.",
        "Contextual sensitivity modeling: incorporate permission models, required intents, user interaction requirements, and component lifecycle context into the classification signal.",
        "Graph-based learning: use GNNs over call graphs/CFGs with API usage patterns to predict sensitivity conditioned on usage context rather than per-method labels only.",
        "Contrastive/multitask learning: jointly learn to predict sensitivity and related categories (permissions, data types, sink channels) with contrastive objectives between sensitive/non-sensitive methods.",
        "Uncertainty-aware deployment: calibrate models and triage with active learning/human-in-the-loop to iteratively refine labels and reduce false positives.",
        "Domain adaptation across API versions: apply continual learning or unsupervised domain adaptation to generalize from API 30 to newer frameworks.",
        "Leverage policy knowledge: incorporate ontology/knowledge graphs of privacy concepts (GDPR categories, PII taxonomy) aligned to API docs via weak supervision.",
        "Dynamic validation: integrate lightweight dynamic probes on platform test harnesses to validate whether methods actually return/send sensitive data.",
        "Instruction-tuned code LLMs: evaluate CodeBERT/GraphCodeBERT/CodeT5/LLM cross-encoders with doc-code joint encoding and instruction prompts for privacy concepts.",
        "Compositional reasoning: predict sensitivity at the level of data types and propagation summaries, then infer method-level sensitivity from summaries."
      ],
      "architectural_improvement_recommendations": [
        "Replace Code2Vec with stronger pre-trained code models (e.g., CodeBERT, GraphCodeBERT, CodeT5) and fine-tune jointly with Sentence-BERT or a unified multimodal transformer.",
        "Use a cross-encoder over (documentation, code) pairs with hierarchical attention to align doc phrases (e.g., permissions, privacy terms) to code elements (returns, parameters, side effects).",
        "Add graph features (call graph, permissions, annotations like @RequiresPermission) and feed them via a GNN or as structured inputs to the classifier.",
        "Introduce uncertainty estimation (MC Dropout, deep ensembles) and threshold calibration to reduce false positives in deployment.",
        "Adopt contrastive pretraining between sensitive vs. non-sensitive examples and between data-type nodes (PII taxonomy) and API methods.",
        "Incorporate rule-based constraints (e.g., constant-return methods cannot be sensitive sources) as differentiable or post-hoc filters."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/JordanSamhi/CoDoC",
      "frameworks": [
        "sentence-transformers (PyTorch)",
        "TensorFlow (Code2Vec)",
        "JavaParser"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Static analysis for Android framework to generate source/sink lists for taint analyzers",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High false positive rate on previously unseen API methods (poor generalization).",
        "Semantic gap between API-level signals (code/docs) and abstract privacy concepts.",
        "Need to update and validate across Android versions and hidden APIs.",
        "Manual labeling remains costly and may be biased by seeding strategies."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "CoDoC: a deep-learning approach fusing code and documentation to classify Android API methods as sensitive Source, Sink, or Neither.",
      "Novel, clarified definitions for sensitive SOURCE and SINK for privacy-focused taint analysis.",
      "A new hand-labeled ground-truth dataset of Android methods (231 Source, 130 Sink, 654 Neither; total 1,015) with perfect inter-rater agreement (Cohen’s Kappa = 1).",
      "Empirical evaluation showing 91% precision/recall/F1 in 10-fold cross-validation, outperforming SuSi on the same dataset.",
      "Negative real-world finding: despite good lab results, CoDoC (like SuSi) produces many false positives on unseen methods; ML for abstract privacy concepts fails in practice.",
      "Release of open-source prototype and all artifacts to the community (https://github.com/JordanSamhi/CoDoC)."
    ]
  },
  {
    "arxiv_id": "2301.12360v1",
    "title": "ADL-ID: Adversarial Disentanglement Learning for Wireless Device Fingerprinting Temporal Domain Adaptation",
    "authors": "Abdurrahman Elmaghbub; Bechir Hamdaoui; Weng-Keen Wong",
    "abstract": "As the journey of 5G standardization is coming to an end, academia and industry have already begun to consider the sixth-generation (6G) wireless networks, with an aim to meet the service demands for the next decade. Deep learning-based RF fingerprinting (DL-RFFP) has recently been recognized as a potential solution for enabling key wireless network applications and services, such as spectrum policy enforcement and network access control. The state-of-the-art DL-RFFP frameworks suffer from a significant performance drop when tested with data drawn from a domain that is different from that used for training data. In this paper, we propose ADL-ID, an unsupervised domain adaption framework that is based on adversarial disentanglement representation to address the temporal domain adaptation for the RFFP task. Our framework has been evaluated on real LoRa and WiFi datasets and showed about 24% improvement in accuracy when compared to the baseline CNN network on short-term temporal adaptation. It also improves the classification accuracy by up to 9% on long-term temporal adaptation. Furthermore, we release a 5-day, 2.1TB, large-scale WiFi 802.11b dataset collected from 50 Pycom devices to support the research community efforts in developing and validating robust RFFP methods.",
    "published_date": "2023-01-29",
    "pdf_link": "https://arxiv.org/pdf/2301.12360v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT/Wireless Security",
      "subdomain": "Physical-layer device identification (RF fingerprinting)",
      "specific_problem": "Temporal domain adaptation for RF device fingerprinting (RFFP) across short-term and long-term time variations",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Adversarial domain adaptation",
        "specific": "GRL-based domain discriminator (DANN-style)",
        "novel_contribution": "Integrates adversarial domain confusion with disentangled representation learning tailored for RFFP temporal portability; trains a fingerprint encoder to extract domain-invariant device features"
      },
      {
        "type": "primary",
        "category": "Disentangled representation learning",
        "specific": null,
        "novel_contribution": "Three-encoder design (fingerprint EF, source ES, target ET) with orthogonality (difference) loss to separate device-specific and domain-specific factors"
      },
      {
        "type": "primary",
        "category": "Autoencoder/Decoder",
        "specific": "Signal decoder with SI-MSE reconstruction loss",
        "novel_contribution": "Reconstructs input from combined RFF + domain-specific features to avoid trivial disentanglement solutions"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "6-block convolutional encoders for RF I/Q frames; warm-up training before enabling adversarial/disentanglement losses"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "6-layer CNN baseline [5]",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised domain adaptation (labeled source, unlabeled target)",
      "Supervised (source-domain device classification)"
    ],
    "datasets": [
      {
        "name": "WiFi 802.11b Pycom RFFP dataset (50 devices, 5 days, 2.1 TB)",
        "type": "public",
        "domain": "wireless_iq_signals",
        "link": "http://research.engr.oregonstate.edu/hamdaoui/datasets",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "LoRa RFFP dataset (NetSTAR Lab)",
        "type": "public",
        "domain": "wireless_iq_signals",
        "link": "http://research.engr.oregonstate.edu/hamdaoui/datasets",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "6-layer CNN baseline [5]",
        "paper_reference": "[5] (as cited by authors)",
        "metric": "Accuracy (%)",
        "their_result": "Short-term LoRa: 76% (cap2), 65% (cap3), 53% (cap4); Short-term WiFi: 64% (cap2), 42% (cap3), 29% (cap4). Authors: “provides a 20%−24% improvement … from 57%→76%, 41%→65%, 29%→53% (LoRa); highest gain of 9% … 55%→64%, 40%→42%, 22%→29% (WiFi).” Long-term: improved over CNN but still far from source-domain accuracy (no exact values reported).",
        "baseline_result": "Short-term LoRa: 57% (cap2), 41% (cap3), 29% (cap4); Short-term WiFi: 55% (cap2), 40% (cap3), 22% (cap4). Long-term: baseline substantially lower than source-domain; exact numbers not provided."
      }
    ],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How severely do short-term (minutes) and long-term (days) temporal variations degrade DL-based RFFP accuracy?",
        "Can adversarial disentanglement learning produce domain-invariant RFF features that improve temporal portability for device identification?",
        "How does performance differ across LoRa and WiFi datasets under temporal domain shifts?"
      ],
      "gaps_identified": [
        "DL-RFFP models are highly sensitive to domain changes (time, channel, receiver, protocol), hindering real-world deployment.",
        "Prior DA works often simulate target domains by adding white Gaussian noise, which is unrealistic for multi-setting changes.",
        "Channel equalization can remove useful spurious emissions, reducing fingerprint capacity.",
        "Data augmentation (e.g., DeepLoRa) shows limited performance and does not scale well to many devices.",
        "Methods like Tweak require recalibration whenever the target domain changes."
      ],
      "limitations": [
        "While improving over CNN, ADL-ID did not bring long-term target-domain performance close enough to source-domain performance.",
        "Smaller gains on WiFi likely due to device reboots (partial RF calibration) altering RFF distributions."
      ],
      "future_work": [
        "Dataset release “extends the opportunity to analyze other domain dimensions, such as protocol configurations and hardware receivers.”"
      ],
      "motivation": "Enable robust, unclonable physical-layer device identification for security applications (spectrum policy enforcement, network access control) by overcoming DL-RFFP’s lack of domain portability across time.",
      "potential_research_ideas": [
        "Design domain-generalization (no target data) methods for RFFP to reduce reliance on unlabeled target samples.",
        "Combine disentanglement with contrastive/self-supervised pretraining on large unlabeled RF corpora to improve invariance across reboots and aging.",
        "Incorporate class-conditional/adaptive domain discriminators and conditional alignment to preserve class structure across domains.",
        "Develop continual/online adaptation for streaming RF data to track long-term drift without catastrophic forgetting.",
        "Leverage physics-informed or channel-aware generative models to augment realistic multi-factor domain shifts (channel, hardware aging, calibration).",
        "Evaluate and extend to multi-receiver, multi-protocol, and cross-hardware settings; explore receiver-invariant embeddings.",
        "Introduce test-time adaptation or source-free UDA for deployment with privacy or data-movement constraints.",
        "Explore transformer or spectral-temporal hybrid backbones for RF I/Q with better long-range dependence modeling."
      ],
      "architectural_improvement_recommendations": [
        "Add contrastive (InfoNCE) losses between same-device samples across domains to tighten class clusters.",
        "Use class-conditional domain discriminator or CMMD/MMD alignment to maintain inter-class separation while aligning domains.",
        "Employ mutual information penalties (or Total Correlation minimization) to strengthen disentanglement beyond orthogonality.",
        "Adopt multi-domain training (multiple days/receivers) with meta-learning to improve fast adaptation to unseen temporal shifts.",
        "Upgrade backbone to lightweight RF-specific CNN-Transformer hybrids; incorporate complex-valued convolutions and spectral features.",
        "Implement source-free/test-time entropy minimization to adapt without target labels or source data retention.",
        "Regularize with consistency under channel/equalization perturbations and calibrated data augmentations."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Training: 50 epochs on an Nvidia DGX-2 node; per-device 20,000 I/Q frames of size 2x1024; warm-up 10,000 steps before enabling adversarial/disentanglement losses."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Indoor/outdoor WiFi 802.11b IoT testbed with USRP B210 receiver and 50 Pycom transmitters; LoRa testbed from prior work.",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Residual performance gap under long-term temporal variations.",
        "Dependence on unlabeled target-domain data for adaptation.",
        "Device reboots/calibration changes alter RFF distributions, reducing gains."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes ADL-ID: an adversarial-based disentanglement learning framework for temporal domain adaptation in RFFP.",
      "Releases the first large-scale WiFi 802.11b RFFP dataset (50 Pycom devices, 5 consecutive days, indoor/outdoor, 2.1 TB).",
      "Provides new insights into short-term and long-term temporal effects on RFFP performance using WiFi and LoRa datasets."
    ]
  },
  {
    "arxiv_id": "2301.03944v4",
    "title": "CHRONOS: Time-Aware Zero-Shot Identification of Libraries from Vulnerability Reports",
    "authors": "Yunbo Lyu; Thanh Le-Cong; Hong Jin Kang; Ratnadira Widyasari; Zhipeng Zhao; Xuan-Bach D. Le; Ming Li; David Lo",
    "abstract": "Tools that alert developers about library vulnerabilities depend on accurate, up-to-date vulnerability databases which are maintained by security researchers. These databases record the libraries related to each vulnerability. However, the vulnerability reports may not explicitly list every library and human analysis is required to determine all the relevant libraries. Human analysis may be slow and expensive, which motivates the need for automated approaches. Researchers and practitioners have proposed to automatically identify libraries from vulnerability reports using extreme multi-label learning (XML).   While state-of-the-art XML techniques showed promising performance, their experiment settings do not practically fit what happens in reality. Previous studies randomly split the vulnerability reports data for training and testing their models without considering the chronological order of the reports. This may unduly train the models on chronologically newer reports while testing the models on chronologically older ones. However, in practice, one often receives chronologically new reports, which may be related to previously unseen libraries. Under this practical setting, we observe that the performance of current XML techniques declines substantially, e.g., F1 decreased from 0.7 to 0.28 under experiments without and with consideration of chronological order of vulnerability reports.   We propose a practical library identification approach, namely CHRONOS, based on zero-shot learning. The novelty of CHRONOS is three-fold. First, CHRONOS fits into the practical pipeline by considering the chronological order of vulnerability reports. Second, CHRONOS enriches the data of the vulnerability descriptions and labels using a carefully designed data enhancement step. Third, CHRONOS exploits the temporal ordering of the vulnerability reports using a cache to prioritize prediction of...",
    "published_date": "2023-01-10",
    "pdf_link": "https://arxiv.org/pdf/2301.03944v4",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Supply Chain Security",
      "subdomain": "Vulnerability Management",
      "specific_problem": "Automatic identification of affected libraries and versions from vulnerability reports (CVE/NVD) under a chronological, previously-unseen label setting",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Zero-shot Extreme Multi-Label Learning (XML)",
        "specific": "ZestXML",
        "novel_contribution": "Integrates ZestXML with domain-specific data enrichment (web reference crawling, preprocessing, label subword splitting) and a time-aware cache-based reranking to handle unseen libraries chronologically"
      },
      {
        "type": "primary",
        "category": "Feature Engineering",
        "specific": "TF-IDF for descriptions and labels",
        "novel_contribution": "Applies TF-IDF to both enriched vulnerability descriptions and split label subtokens to enable zero-shot matching"
      },
      {
        "type": "primary",
        "category": "Tokenization / Subtoken Splitting",
        "specific": "Spiral token splitter",
        "novel_contribution": "Splits library/package names into subtokens to better match mentions in text across heterogeneous ecosystems"
      },
      {
        "type": "primary",
        "category": "Heuristic / Reranking",
        "specific": "Time-aware cache-based adjustment",
        "novel_contribution": "Reranks predictions to favor libraries and versions recently observed as vulnerable"
      },
      {
        "type": "baseline",
        "category": "Deep Neural Network for XML",
        "specific": "LightXML",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Tree-based XML",
        "specific": "FastXML",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Rule-based / Heuristic",
        "specific": "Direct library name matching in descriptions",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Heuristic",
        "specific": "Using only CPE configurations",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Generalized Zero-Shot Learning",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CHRONOS dataset (NVD-based vulnerability reports with library/version labels and crawled references)",
        "type": "public",
        "domain": "vulnerability_reports",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "National Vulnerability Database (NVD) CVE entries and references",
        "type": "public",
        "domain": "vulnerability_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Package registries for label space (e.g., npm, PyPI)",
        "type": "public",
        "domain": "package_metadata",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "LightXML",
        "paper_reference": "[11] (as cited in the paper)",
        "metric": "Average F1-score",
        "their_result": "“CHRONOS achieves an average F1 of 0.75, outperforming the LightXML approach by 167.9% in average F1 (0.75 to 0.28).”",
        "baseline_result": "0.28"
      },
      {
        "method_name": "FastXML",
        "paper_reference": "[14] (as cited in the paper)",
        "metric": "F1-score",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Handcrafted name matching (directly match library names in description)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "“CHRONOS performs 92.3% better.”",
        "baseline_result": null
      },
      {
        "method_name": "CPE-only approach",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "“CHRONOS performs 3 times better.”",
        "baseline_result": null
      },
      {
        "method_name": "Vanilla zero-shot model (ZestXML without data enhancement and time-aware adjustment)",
        "paper_reference": "[16] (ZestXML, as cited)",
        "metric": "Average F1-score",
        "their_result": "0.75",
        "baseline_result": "0.59"
      }
    ],
    "performance_metrics_used": [
      "F1-score (average)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Prior work randomly split data ignoring chronological order, potentially training on newer reports and testing on older ones, which is unrealistic.",
        "Existing XML models cannot predict previously unseen libraries when evaluated chronologically (labels in test not present in train).",
        "CPE configurations are not exhaustive for identifying all affected libraries/versions."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Automate and speed up manual, slow, and costly curation of vulnerability databases by accurately mapping CVE reports to affected libraries and versions, especially under realistic chronological settings with unseen labels.",
      "potential_research_ideas": [
        "Replace TF-IDF with contextual embeddings (e.g., SBERT, domain-adapted BERT) for both descriptions and labels to improve zero-shot matching.",
        "Model temporal dynamics with probabilistic/point-process methods (e.g., Hawkes processes) to learn time-aware priors rather than heuristic caching.",
        "Construct a knowledge graph linking CVEs, packages, versions, commits, advisories, and ecosystems, and apply GNN-based zero-shot label propagation.",
        "Leverage LLMs to summarize heterogeneous reference pages and extract candidate libraries/versions to feed into the XML scorer.",
        "Cross-ecosystem normalization of package identities (alias resolution) to address naming inconsistencies across registries.",
        "Online/streaming learning to continually update seen labels and adapt thresholds as new libraries appear."
      ],
      "architectural_improvement_recommendations": [
        "Swap TF-IDF with dual-encoder bi-encoders trained with contrastive learning between descriptions and label texts.",
        "Augment label descriptions with enriched metadata (README, package descriptions, changelogs) and use automated prompt-based generation of label textual descriptors.",
        "Integrate a learned reranker (e.g., LambdaMART or lightweight transformer) conditioned on temporal and ecosystem features to supersede heuristic cache reranking.",
        "Add multi-task objectives to jointly predict library and version, sharing representations but with version-aware constraints.",
        "Use subtoken-level lexical normalization and alias resolution (e.g., learned edit distance or transliteration models) to handle noisy references."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "spaCy",
        "ZestXML",
        "Spiral token splitter"
      ],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Heterogeneous and changing structures of referenced websites (1,054 unique domains) complicate reliable scraping.",
        "Maintaining up-to-date cache and accurate version metadata across ecosystems.",
        "Handling newly emerging package naming conventions and aliases across registries."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Problem reformulation to a generalized zero-shot XML task with chronological data splits (L_new ⊇ L).",
      "CHRONOS approach with data enrichment (web reference crawling, preprocessing, label subtoken splitting) and time-aware cache-based adjustment.",
      "Empirical evaluation showing average F1 = 0.75 and large gains over state-of-the-art XML baselines under realistic chronological settings.",
      "Public release of dataset and implementation."
    ]
  },
  {
    "arxiv_id": "2301.07628v5",
    "title": "Universal Neural-Cracking-Machines: Self-Configurable Password Models from Auxiliary Data",
    "authors": "Dario Pasquini; Giuseppe Ateniese; Carmela Troncoso",
    "abstract": "We introduce the concept of \"universal password model\" -- a password model that, once pre-trained, can automatically adapt its guessing strategy based on the target system. To achieve this, the model does not need to access any plaintext passwords from the target credentials. Instead, it exploits users' auxiliary information, such as email addresses, as a proxy signal to predict the underlying password distribution. Specifically, the model uses deep learning to capture the correlation between the auxiliary data of a group of users (e.g., users of a web application) and their passwords. It then exploits those patterns to create a tailored password model for the target system at inference time. No further training steps, targeted data collection, or prior knowledge of the community's password distribution is required. Besides improving over current password strength estimation techniques and attacks, the model enables any end-user (e.g., system administrators) to autonomously generate tailored password models for their systems without the often unworkable requirements of collecting suitable training data and fitting the underlying machine learning model. Ultimately, our framework enables the democratization of well-calibrated password models to the community, addressing a major challenge in the deployment of password security solutions at scale.",
    "published_date": "2023-01-18",
    "pdf_link": "https://arxiv.org/pdf/2301.07628v5",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Authentication",
      "subdomain": "Password Security",
      "specific_problem": "Universal password modeling for password strength estimation and offline guessing using auxiliary user data without target plaintext passwords",
      "attack_types": [
        "offline password guessing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Autoregressive Language Model",
        "specific": "Character-level autoregressive neural password model (maximum likelihood estimation)",
        "novel_contribution": "Self-configuring at inference time using a prior inferred from auxiliary user data to adapt the guessing strategy to the target community"
      },
      {
        "type": "primary",
        "category": "Transformer/Attention",
        "specific": "Multi-head attention mechanism",
        "novel_contribution": "Attention over sets of users’ auxiliary information to derive a robust prior over the community’s password distribution and configure the model without additional training"
      },
      {
        "type": "primary",
        "category": "Differential Privacy",
        "specific": "Gaussian mechanism ((ε, δ)-DP)",
        "novel_contribution": "Differentially private publication of configuration using auxiliary data with strong privacy (ε < 1) and limited utility loss"
      },
      {
        "type": "baseline",
        "category": "PCFG",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Dictionary-based attack",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GAN-based generator",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoregressive RNN/LM",
        "specific": "Language-specific calibrated models",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised"
    ],
    "datasets": [
      {
        "name": "Hungarian password leak",
        "type": "public",
        "domain": "plaintext_passwords",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Polish password leak",
        "type": "public",
        "domain": "plaintext_passwords",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Manually calibrated password model (e.g., by target users’ language)",
        "paper_reference": null,
        "metric": "Percentage of passwords guessed vs number of guesses",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "guess number",
      "percentage guessed at given guess budget",
      "cracking curve (guessed passwords vs log10 guesses)",
      "latency (configuration sub-second)",
      "epsilon (differential privacy)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a pre-trained password model self-configure to a target system using only auxiliary user data (e.g., emails, usernames) and no target plaintext passwords?",
        "Can attention over auxiliary information across a user community provide an accurate prior for the target password distribution?",
        "Can such a universal model outperform manually calibrated models tailored with prior knowledge (e.g., language)?",
        "Can the configuration process be made differentially private with strong guarantees and limited utility loss?"
      ],
      "gaps_identified": [
        "Password models need community-specific calibration; current practice requires collecting suitable leaks and training/tuning ML models, which is burdensome and often infeasible for end-users.",
        "System administrators cannot access plaintext passwords of their own systems, preventing intra-site training or similarity matching to pick appropriate external leaks.",
        "State-of-the-art password models require substantial expertise and compute to train and calibrate."
      ],
      "limitations": [
        "Requires availability of auxiliary user information (e.g., email addresses, usernames) for the target system to drive configuration.",
        "Effectiveness relies on correlation between auxiliary data and users’ password choices.",
        "Differential privacy introduces some utility loss (reported as limited) when publishing models."
      ],
      "future_work": [],
      "motivation": "Democratize well-calibrated password models by removing the need for targeted data collection and model training, enabling end-users to deploy accurate password strength meters and attacks without access to plaintext passwords.",
      "potential_research_ideas": [
        "Study robustness when auxiliary information is sparse, noisy, or intentionally poisoned; develop defenses against poisoning of auxiliary data.",
        "Extend auxiliary signals beyond emails/usernames (e.g., geographic, device, or organizational attributes) while maintaining strong privacy via DP.",
        "Incorporate uncertainty estimation to detect when auxiliary data is uninformative and fall back to safe default priors.",
        "Investigate federated or split-configuration settings where auxiliary data never leaves the target environment.",
        "Generalize beyond character-level to morphologically informed or subword tokenization to better capture multilingual patterns.",
        "Evaluate transfer to online targeted guessing and mixed trawling/targeted scenarios.",
        "Develop calibration diagnostics to quantify alignment between inferred prior and actual target distribution in the absence of plaintexts."
      ],
      "architectural_improvement_recommendations": [
        "Use a transformer encoder over auxiliary features with mixture-of-experts gating to select or blend password submodels at inference time.",
        "Incorporate Bayesian or ensemble approaches to quantify uncertainty in the inferred prior and adjust aggressiveness of guessing.",
        "Adopt adapters/low-rank parameter-efficient tuning modules to personalize models to contexts without full retraining.",
        "Explore graph-based encoders over auxiliary data (e.g., email domain graphs) to capture community structure.",
        "Leverage tokenization schemes (character+subword) and multilingual embeddings to strengthen cross-language generalization."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/TheAdamProject/UniversalNeuralCrackingMachines",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Client-side password strength meter within web applications; enterprise/web environments",
      "scalability_discussed": true,
      "inference_time": "Sub-second configuration (lightweight)",
      "deployment_challenges": [
        "Obtaining and standardizing auxiliary user information at registration time",
        "Balancing privacy guarantees (DP) with utility",
        "Ensuring robustness when auxiliary signals are weak or uninformative"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Introduce the concept of universal password model using auxiliary user data to learn a prior over a community’s password distribution.",
      "Develop a fully automatic approach to configure context-aware password meters and guessing attacks without target plaintext passwords.",
      "Provide a differentially private configuration mechanism enabling client-side meters with strong privacy (ε < 1) and limited utility loss.",
      "Achieve new state-of-the-art for offline password guessing and password strength metering.",
      "Release code and pre-trained models."
    ]
  },
  {
    "arxiv_id": "2301.09806v3",
    "title": "Unveiling the Risks of NFT Promotion Scams",
    "authors": "Sayak Saha Roy; Dipanjan Das; Priyanka Bose; Christopher Kruegel; Giovanni Vigna; Shirin Nilizadeh",
    "abstract": "The rapid growth in popularity and hype surrounding digital assets such as art, video, and music in the form of non-fungible tokens (NFTs) has made them a lucrative investment opportunity, with NFT-based sales surpassing $25B in 2021 alone. However, the volatility and general lack of technical understanding of the NFT ecosystem have led to the spread of various scams. The success of an NFT heavily depends on its online virality. As a result, creators use dedicated promotion services to drive engagement to their projects on social media websites, such as Twitter. However, these services are also utilized by scammers to promote fraudulent projects that attempt to steal users' cryptocurrency assets, thus posing a major threat to the ecosystem of NFT sales.   In this paper, we conduct a longitudinal study of 439 promotion services (accounts) on Twitter that have collectively promoted 823 unique NFT projects through giveaway competitions over a period of two months. Our findings reveal that more than 36% of these projects were fraudulent, comprising of phishing, rug pull, and pre-mint scams. We also found that a majority of accounts engaging with these promotions (including those for fraudulent NFT projects) are bots that artificially inflate the popularity of the fraudulent NFT collections by increasing their likes, followers, and retweet counts. This manipulation results in significant engagement from real users, who then invest in these scams. We also identify several shortcomings in existing anti-scam measures, such as blocklists, browser protection tools, and domain hosting services, in detecting NFT-based scams. We utilized our findings to develop a machine learning classifier tool that was able to proactively detect 382 new fraudulent NFT projects on Twitter.",
    "published_date": "2023-01-24",
    "pdf_link": "https://arxiv.org/pdf/2301.09806v3",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cryptocurrency Security",
      "subdomain": "NFT/Blockchain Scam Detection",
      "specific_problem": "Detecting and characterizing NFT promotion scams on Twitter (giveaway-based promotions) including phishing, rug pulls, and pre-mint scams",
      "attack_types": [
        "phishing",
        "rug pull (exit scam)",
        "pre-mint scam",
        "impersonation",
        "social engineering",
        "bot-driven astroturfing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Traditional ML Classifier",
        "specific": null,
        "novel_contribution": "A supervised classifier leveraging features from Twitter promotion dynamics to proactively detect fraudulent NFT projects; \"was able to proactively detect 382 new fraudulent NFT projects on Twitter.\""
      },
      {
        "type": "baseline",
        "category": "Bot detection",
        "specific": "Botometer",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Twitter NFT promotion dataset (2,831 promotion tweets from 439 promoter accounts covering 823 NFT projects, June 15–Aug 20, 2022)",
        "type": "private",
        "domain": "social_media_posts",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "NFT phishing websites collected from promoted projects (n=182 phishing sites; 57 with extracted contract addresses)",
        "type": "private",
        "domain": "phishing_urls",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Blockchain transaction data for promoted projects (via Etherscan and BscScan)",
        "type": "private",
        "domain": "blockchain_transactions",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Blocklist signals: Google Safe Browsing, APWG, PhishTank, OpenPhish",
        "type": "public",
        "domain": "phishing_blocklists",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusTotal aggregated detections of phishing URLs (browser protection tools)",
        "type": "public",
        "domain": "security_tool_detections",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Botometer scores for accounts engaging with promotions and promoted collections",
        "type": "private",
        "domain": "social_media_accounts",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Google Safe Browsing",
        "paper_reference": null,
        "metric": "detection rate",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "APWG blocklist",
        "paper_reference": null,
        "metric": "detection rate",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "PhishTank",
        "paper_reference": null,
        "metric": "detection rate",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "OpenPhish",
        "paper_reference": null,
        "metric": "detection rate",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "VirusTotal (aggregate of 76 browser protection tools)",
        "paper_reference": null,
        "metric": "detection rate",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "detection rate",
      "counts of fraudulent projects detected",
      "engagement metrics (followers gained, retweets, likes, replies)",
      "account suspension/removal latency"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: What are the characteristics and visibility of fraudulent NFT accounts that run promotions on Twitter?",
        "RQ2: How effective are prevalent anti-scam measures towards detecting these attacks?",
        "RQ3: What is the financial impact of these scams?"
      ],
      "gaps_identified": [
        "“We also identify several shortcomings in existing anti-scam measures, such as blocklists, browser protection tools, and domain hosting services, in detecting NFT-based scams.”",
        "“there exists no effort that measures the characteristics and negative impact of the promotion of fraudulent NFT projects on social media.”",
        "A majority of accounts engaging with these promotions are bots that artificially inflate visibility, indicating gaps in platform defenses against coordinated inauthentic behavior."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Measure and mitigate the risks posed by NFT promotion scams on Twitter, quantify their visibility and impact, evaluate existing anti-scam defenses, and build a proactive detector.",
      "potential_research_ideas": [
        "Graph-based detection leveraging promoter–promotee–participant interaction networks to identify coordinated promotion of scams.",
        "Large language model-based content and intent analysis of promotion and reply tweets to detect deceptive narratives and impersonation.",
        "Temporal change-point detection on follower/engagement time series to flag abnormal promotion-driven surges indicative of scams.",
        "Cross-platform correlation (Twitter, Discord, Telegram, NFT marketplaces) to detect multi-channel scam campaigns.",
        "On-chain and off-chain joint modeling: fuse smart-contract behavior, token distribution, and marketplace activity with social signals.",
        "Active learning with human-in-the-loop to efficiently label emerging scam patterns and reduce manual effort.",
        "Adversarial botnet detection specific to NFT promotions using behavioral fingerprints and device/browser telemetry (where available).",
        "Early-warning system for impersonation by matching promoted project metadata against known legitimate collections using fuzzy entity resolution."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a heterogeneous graph neural network over accounts, tweets, URLs, domains, and smart contracts with relational features.",
        "Incorporate URL and domain features (WHOIS age, hosting ASN, TLS cert, lexical features), and integrate VirusTotal/subdomain intel.",
        "Use semi-supervised learning (e.g., label propagation) to leverage large unlabeled promotion data with few scam labels.",
        "Model concept drift with online learning and periodic recalibration to adapt to evolving scam templates and tactics.",
        "Calibrate Botometer reliance by training an in-domain bot detector specialized for NFT promotion context; ensemble with Botometer.",
        "Add explainability via feature attribution (e.g., SHAP) and prototype examples to support moderation decisions.",
        "Implement robust training with adversarial examples (e.g., obfuscated URLs, templated text perturbations) to harden against evasion."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Twitter social media monitoring",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Longitudinal measurement study of “439 promotion services (accounts) on Twitter” that “promoted 823 unique NFT projects… over a period of two months.”",
      "Found “more than 36% of these projects were fraudulent, comprising of phishing, rug pull, and pre-mint scams.”",
      "Scam taxonomy and prevalence: Phishing 22.1% (n=182), Pre-mint 14.4% (n=119), Rugpull 9.4% (n=78).",
      "Showed that “a majority of accounts engaging with these promotions (including those for fraudulent NFT projects) are bots” that inflate popularity metrics.",
      "Quantified account moderation outcomes: 18.1% removed and 8.9% suspended; median time to removal 231 days and suspension 157 days.",
      "Identified shortcomings in anti-scam measures (blocklists, browser tools, domain hosting) for NFT-based scams.",
      "Tracked financial impact by analyzing on-chain transactions to attacker wallets.",
      "Built a machine-learning-based classifier tool that “was able to proactively detect 382 new fraudulent NFT projects on Twitter.”",
      "Extracted contract addresses for 57/182 phishing websites to further characterize NFT-based phishing."
    ]
  },
  {
    "arxiv_id": "2301.00969v1",
    "title": "Boosting Neural Networks to Decompile Optimized Binaries",
    "authors": "Ying Cao; Ruigang Liang; Kai Chen; Peiwei Hu",
    "abstract": "Decompilation aims to transform a low-level program language (LPL) (eg., binary file) into its functionally-equivalent high-level program language (HPL) (e.g., C/C++). It is a core technology in software security, especially in vulnerability discovery and malware analysis. In recent years, with the successful application of neural machine translation (NMT) models in natural language processing (NLP), researchers have tried to build neural decompilers by borrowing the idea of NMT. They formulate the decompilation process as a translation problem between LPL and HPL, aiming to reduce the human cost required to develop decompilation tools and improve their generalizability. However, state-of-the-art learning-based decompilers do not cope well with compiler-optimized binaries. Since real-world binaries are mostly compiler-optimized, decompilers that do not consider optimized binaries have limited practical significance. In this paper, we propose a novel learning-based approach named NeurDP, that targets compiler-optimized binaries. NeurDP uses a graph neural network (GNN) model to convert LPL to an intermediate representation (IR), which bridges the gap between source code and optimized binary. We also design an Optimized Translation Unit (OTU) to split functions into smaller code fragments for better translation performance. Evaluation results on datasets containing various types of statements show that NeurDP can decompile optimized binaries with 45.21% higher accuracy than state-of-the-art neural decompilation frameworks.",
    "published_date": "2023-01-03",
    "pdf_link": "https://arxiv.org/pdf/2301.00969v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Reverse Engineering / Decompilation",
      "specific_problem": "Neural decompilation of compiler-optimized binaries via LPL→IR→HPL pipeline",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": null,
        "novel_contribution": "Graph neural network model that translates low-level intermediate representation (LIR) data-dependency graphs into optimized high-level IR (HIR) code templates; coupled with a new splitting scheme (OTU) for training and inference."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "NeurDP dataset (LIR–HIR OTU pairs across optimization levels)",
        "type": "synthetic",
        "domain": "binary_assembly",
        "link": "https://github.com/zijiancogito/neur-dp-data.git",
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Coda",
        "paper_reference": "[8] (as cited in the paper)",
        "metric": "accuracy",
        "their_result": "“NeurDP is 5.8%–27.8% more accurate than Coda on unoptimized code.”",
        "baseline_result": null
      },
      {
        "method_name": "Neutron",
        "paper_reference": "[6] (as cited in the paper)",
        "metric": "accuracy",
        "their_result": "“NeurDP can decompile optimized binaries with 45.21% higher accuracy than another neural decompilation Neutron [6].”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How can neural models accurately decompile compiler-optimized binaries where HPL–LPL alignment is distorted by optimization?",
        "Can introducing an intermediate representation (HIR) as a bridge from LPL reduce the learning difficulty for optimized binaries?",
        "How to split basic blocks into optimal translation units (OTUs) that preserve single, coherent data-dependency features for effective learning?"
      ],
      "gaps_identified": [
        "Lack of high-quality labeled datasets specifically for decompilation of optimized code.",
        "Direct LPL→HPL supervision is inaccurate due to compiler optimizations (dead code elimination, loop transformations) breaking statement-level alignment.",
        "Existing neural decompilers struggle with optimized code and rely on functions/BBs that are too large or semantically mixed for effective learning.",
        "DDGs of LPL and HPL differ significantly after optimization, complicating fragment correspondence."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Real-world binaries are mostly compiler-optimized; existing learning-based decompilers do not handle optimized binaries well, limiting practical significance. Bridging with IR and splitting into OTUs aims to enable accurate neural decompilation under optimization.",
      "potential_research_ideas": [
        "Pretrain a graph-to-sequence decompiler on large unlabeled binaries using self-supervision (e.g., masked IR prediction) and fine-tune on OTU pairs.",
        "Extend to multi-ISA and multi-compiler settings (x86, ARM, clang/gcc/MSVC) with domain adaptation to improve generalizability.",
        "Joint learning of CFG recovery and statement translation (multi-task) to better reconstruct control structures end-to-end.",
        "Incorporate transformer-based decoders over GNN-encoded graphs (GraphTransformer) for more expressive code generation.",
        "Leverage optimization-aware data augmentation: compile the same sources at O0–O3 to learn invariances across optimization levels.",
        "Integrate variable and type recovery as auxiliary tasks (pointer/slot filling, type inference) to improve HPL fidelity.",
        "Adversarial robustness evaluation against obfuscation and aggressive optimizations; develop defenses (robust graph encoders).",
        "Semi-/weakly-supervised learning using partially aligned HPL with confidence weighting to reduce reliance on perfect labels.",
        "Neural IR normalization layer that attempts to reverse specific optimizations (e.g., strength reduction) before translation.",
        "Human-in-the-loop active learning to select hard OTUs from real-world binaries for annotation and model refinement."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment the GNN with a GraphTransformer encoder and a structured decoder that emits HIR templates with copy/pointer mechanisms for operand filling.",
        "Introduce contrastive learning on OTU graphs compiled under different optimization levels to learn optimization-invariant embeddings.",
        "Add a CRF or differentiable scheduler over generated HIR snippets to better reorder and merge them during block reassembly.",
        "Use program analysis-informed positional/edge features (e.g., dominance, memory aliasing, SSA phi relations) in the GNN.",
        "End-to-end differentiable HIR→HPL module (learned transduction) to replace hand-crafted rules where feasible.",
        "Curriculum learning: start with O0 OTUs, progressively introduce higher optimization levels and larger units.",
        "Knowledge distillation from rule-based decompilers for pseudo-labeling complex constructs (e.g., division patterns)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": "https://github.com/zijiancogito/neur-dp-data.git",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "NeurDP: first neural-based decompiler designed to handle compiler-optimized binaries by translating LPL→optimized HIR via GNN, then HIR→HPL.",
      "Optimal Translation Unit (OTU) splitting to create semantically coherent LIR/HIR pairs with single data-dependency features.",
      "Dataset and NN parameters released for reproducible research at https://github.com/zijiancogito/neur-dp-data.git.",
      "Empirical gains: “NeurDP can decompile optimized binaries with 45.21% higher accuracy than state-of-the-art neural decompilation frameworks”; 5.8%–27.8% better than Coda on unoptimized code; large gains (4.1%–71.23%) from OTU and IR mechanisms on optimized code.",
      "Design details for LIR/HIR representations, DDG-based GNN translation, and CFG-based reassembly; rule set for HIR→HPL statement lifting."
    ]
  },
  {
    "arxiv_id": "2302.08498v1",
    "title": "An Omnidirectional Approach to Touch-based Continuous Authentication",
    "authors": "Peter Aaby; Mario Valerio Giuffrida; William J Buchanan; Zhiyuan Tan",
    "abstract": "This paper focuses on how touch interactions on smartphones can provide a continuous user authentication service through behaviour captured by a touchscreen. While efforts are made to advance touch-based behavioural authentication, researchers often focus on gathering data, tuning classifiers, and enhancing performance by evaluating touch interactions in a sequence rather than independently. However, such systems only work by providing data representing distinct behavioural traits. The typical approach separates behaviour into touch directions and creates multiple user profiles. This work presents an omnidirectional approach which outperforms the traditional method independent of the touch direction - depending on optimal behavioural features and a balanced training set. Thus, we evaluate five behavioural feature sets using the conventional approach against our direction-agnostic method while testing several classifiers, including an Extra-Tree and Gradient Boosting Classifier, which is often overlooked. Results show that in comparison with the traditional, an Extra-Trees classifier and the proposed approach are superior when combining strokes. However, the performance depends on the applied feature set. We find that the TouchAlytics feature set outperforms others when using our approach when combining three or more strokes. Finally, we highlight the importance of reporting the mean area under the curve and equal error rate for single-stroke performance and varying the sequence of strokes separately.",
    "published_date": "2023-01-13",
    "pdf_link": "https://arxiv.org/pdf/2302.08498v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "Continuous Authentication",
      "specific_problem": "Touch-based behavioral biometric authentication using an omnidirectional (direction-agnostic) model versus traditional bidirectional (H/V) models",
      "attack_types": [
        "masquerade/unauthorized access"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble Trees",
        "specific": "ExtraTreesClassifier",
        "novel_contribution": "Applied within an omnidirectional, direction-agnostic modeling approach; shown superior to traditional bidirectional modeling when combining strokes"
      },
      {
        "type": "primary",
        "category": "Ensemble Trees",
        "specific": "GradientBoostingClassifier",
        "novel_contribution": "Evaluated as an often-overlooked classifier in touch-based continuous authentication within the proposed omnidirectional framework"
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "RBF SVM (One-vs-Rest)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "k-Nearest Neighbors",
        "specific": "kNN (OvR)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble Trees",
        "specific": "RandomForestClassifier",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Models",
        "specific": "Logistic Regression (OvR)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Neural Network",
        "specific": "MLP (scikit-learn)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "J48 (Decision Tree)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "One-vs-Rest"
    ],
    "datasets": [
      {
        "name": "Raw touchscreen interaction dataset from [9] (Serwadda et al.)",
        "type": "unknown",
        "domain": "touch_interactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "unknown"
      }
    ],
    "baselines": [
      {
        "method_name": "Traditional bidirectional modeling (separate Horizontal and Vertical stroke models)",
        "paper_reference": null,
        "metric": "AUC, EER (single-stroke and combined n-strokes)",
        "their_result": "“Results show that in comparison with the traditional, an Extra-Trees classifier and the proposed approach are superior when combining strokes.”",
        "baseline_result": null
      },
      {
        "method_name": "SVM (RBF, OvR)",
        "paper_reference": null,
        "metric": "AUC, EER",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "k-Nearest Neighbors (OvR)",
        "paper_reference": null,
        "metric": "AUC, EER",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "AUC, EER",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Gradient Boosting",
        "paper_reference": null,
        "metric": "AUC, EER",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "AUC",
      "EER"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What is the performance difference between the proposed approach versus a typical bidirectional model where stroke orientation is separated and parameters are highly optimised?",
        "What is the impact of combining n-strokes when using the typical and proposed approach?",
        "Which feature set should be used considering the different directional modelling approaches?"
      ],
      "gaps_identified": [
        "Lack of consistent comparison across directional modeling approaches (direction-specific vs. direction-agnostic).",
        "Insufficient cross-paper comparability due to differing metrics and parameter search spaces.",
        "Limited comparison and discussion of overlapping behavioral feature sets used across prior work.",
        "Effects of training data size and class imbalance on model stability not standardized across studies.",
        "Need for standardized reporting of single-stroke vs combined-stroke performance (AUC and EER)."
      ],
      "limitations": [
        "Evaluation restricted to portrait mode; landscape excluded.",
        "User pool reduced to 35 valid users after applying strict training/testing data requirements (from 138 candidates).",
        "Focus on intersession performance using one dataset; generalization to other devices/populations not validated here.",
        "Clicks and very short/ambiguous interactions removed; pipeline depends on robust stroke segmentation.",
        "Did not vary training data size (followed a fixed training size recommendation)."
      ],
      "future_work": [],
      "motivation": "Reduce modeling complexity and time by avoiding direction-specific models while retaining or improving accuracy; identify optimal behavioral features; address inconsistencies in modeling approaches and reporting practices.",
      "potential_research_ideas": [
        "Evaluate the omnidirectional approach across multiple, heterogeneous touch datasets and devices to assess cross-device/domain generalization.",
        "Develop self-supervised or contrastive representations for touch dynamics that are direction-invariant and robust to session/device shifts.",
        "Incorporate sequence models (HMMs, RNNs/Transformers) over stroke sequences to replace or augment moving-average probability fusion.",
        "Investigate adaptive/online learning for rapid personalization and drift handling in long-term continuous authentication.",
        "Study adversarial robustness (e.g., imitation, replayed touch traces) and build defenses such as liveness cues (pressure/area dynamics) or anomaly detection layers.",
        "Explore privacy-preserving on-device training (federated/DP) for behavioral biometrics.",
        "Create a standardized benchmark suite with fixed training sizes, evaluation protocols (single vs. combined strokes), and common metric reporting."
      ],
      "architectural_improvement_recommendations": [
        "Use calibrated probability ensembling across multiple classifiers/feature sets (e.g., stacking with Platt/Isotonic calibration) to improve decision fusion over stroke sequences.",
        "Adopt cost-sensitive learning or class-weighted losses instead of (or alongside) down-sampling to better utilize data under OvR imbalance.",
        "Engineer direction-invariant features explicitly (e.g., rotation-normalized trajectories, Fourier descriptors) to further support omnidirectional modeling.",
        "Leverage gradient-boosted decision tree variants (e.g., XGBoost/LightGBM/CatBoost) with careful regularization for improved intersession robustness.",
        "Replace fixed-size moving averages with learned temporal aggregation (e.g., attention-based pooling) over variable-length stroke sequences."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Python 3.8",
        "scikit-learn",
        "imbalanced-learn"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Grid over parameters yielding ~236,250 model fits across users/feature sets/classifiers with 5x5 repeated stratified CV; specific hardware not reported."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requirement for sufficient numbers of strokes per direction for balanced training; real-world data may be imbalanced.",
        "Intersession variability can degrade performance; models must handle temporal drift.",
        "Reliable segmentation to remove clicks and very short gestures is necessary.",
        "Latency/throughput trade-off due to needing multiple strokes (often ~10) to achieve stable authentication decisions."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes an omnidirectional (direction-agnostic) modeling approach for touch-based continuous authentication.",
      "Systematic comparison of five behavioral feature sets under both traditional bidirectional and proposed omnidirectional approaches.",
      "Evaluates several classifiers, including an often-overlooked Extra-Trees and Gradient Boosting, within a unified pipeline with repeated stratified CV and OvR class balancing.",
      "Findings: “an Extra-Trees classifier and the proposed approach are superior when combining strokes.”",
      "Identifies that the “TouchAlytics feature set outperforms others when using our approach when combining three or more strokes.”",
      "Emphasizes standardized reporting: “highlight the importance of reporting the mean area under the curve and equal error rate for single-stroke performance and varying the sequence of strokes separately.”",
      "Defines a method to select model parameters to reduce complexity at the cost of minor performance drops."
    ]
  },
  {
    "arxiv_id": "2301.10545v1",
    "title": "Beware of the Unexpected: Bimodal Taint Analysis",
    "authors": "Yiu Wai Chow; Max Schäfer; Michael Pradel",
    "abstract": "Static analysis is a powerful tool for detecting security vulnerabilities and other programming problems. Global taint tracking, in particular, can spot vulnerabilities arising from complicated data flow across multiple functions. However, precisely identifying which flows are problematic is challenging, and sometimes depends on factors beyond the reach of pure program analysis, such as conventions and informal knowledge. For example, learning that a parameter \"name\" of an API function \"locale\" ends up in a file path is surprising and potentially problematic. In contrast, it would be completely unsurprising to find that a parameter \"command\" passed to an API function \"execaCommand\" is eventually interpreted as part of an operating-system command. This paper presents Fluffy, a bimodal taint analysis that combines static analysis, which reasons about data flow, with machine learning, which probabilistically determines which flows are potentially problematic. The key idea is to let machine learning models predict from natural language information involved in a taint flow, such as API names, whether the flow is expected or unexpected, and to inform developers only about the latter. We present a general framework and instantiate it with four learned models, which offer different trade-offs between the need to annotate training data and the accuracy of predictions. We implement Fluffy on top of the CodeQL analysis framework and apply it to 250K JavaScript projects. Evaluating on five common vulnerability types, we find that Fluffy achieves an F1 score of 0.85 or more on four of them across a variety of datasets.",
    "published_date": "2023-01-25",
    "pdf_link": "https://arxiv.org/pdf/2301.10545v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Static Analysis / Taint Analysis",
      "specific_problem": "Identifying unexpected taint flows by combining static taint tracking with ML to surface likely problematic source-to-sink flows",
      "attack_types": [
        "Command Injection (CWE-78)",
        "Code Injection (CWE-94)",
        "Reflected XSS (CWE-79)",
        "Path Traversal (CWE-22)",
        "Clear-text logging of sensitive information (CWE-312)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Feed-forward Neural Network + RNN",
        "specific": "Binary classifier with two-layer MLP; LSTM-based bidirectional RNN encoder for documentation tokens; pre-trained identifier embeddings",
        "novel_contribution": "Uses identifier names, API names, and parameter documentation to classify whether a taint flow is expected vs unexpected, filtering static taint results"
      },
      {
        "type": "primary",
        "category": "Feed-forward Neural Network",
        "specific": "Multiclass sink prediction classifier",
        "novel_contribution": "Trained on automatically mined flows to predict the most likely sink type for a given source; flags flows as unexpected when predicted sink mismatches the observed sink"
      },
      {
        "type": "primary",
        "category": "One-Class SVM",
        "specific": "OC-SVM novelty detection",
        "novel_contribution": "Trained with a small list of terms per sink type to identify unusual (unexpected) flows without labeled negatives"
      },
      {
        "type": "primary",
        "category": "Large Language Model (LLM) few-shot",
        "specific": "OpenAI Codex prompted via few-shot learning",
        "novel_contribution": "Queries an LLM on NL cues from code (identifier and API names, docs) to decide expected vs unexpected flows without training"
      },
      {
        "type": "primary",
        "category": "Embedding",
        "specific": "VarCLR identifier embeddings",
        "novel_contribution": "State-of-the-art identifier name embeddings used to represent natural language elements of flows"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Weakly-supervised",
      "Unsupervised",
      "Few-shot learning"
    ],
    "datasets": [
      {
        "name": "CodeQL-mined taint flows from 250K JavaScript/TypeScript projects",
        "type": "public",
        "domain": "source_code",
        "link": "https://figshare.com/s/1ab456424bfb5a2ead5e",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Manually labeled expected vs unexpected flows (five taint queries)",
        "type": "public",
        "domain": "source_code",
        "link": "https://figshare.com/s/1ab456424bfb5a2ead5e",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Confirmed historical vulnerabilities (131 cases)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Newly reported vulnerabilities (16 cases; 8 confirmed)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Precision",
      "Recall",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Static taint analysis effectiveness hinges on curated source/sink policies; missing or overbroad policies cause false negatives/positives",
        "Some security policies depend on conventions and informal knowledge (identifier names, documentation) beyond pure program semantics",
        "Regex/hand-crafted heuristics for identifying sources (e.g., clear-text logging) are error-prone and require manual maintenance",
        "Hard to identify unhygienic APIs whose parameters flow to security-sensitive sinks without clear indication"
      ],
      "limitations": [
        "Trade-offs between labeling effort and prediction accuracy across the four ML instantiations",
        "Evaluation and implementation focus on JavaScript/TypeScript and specific CodeQL taint queries",
        "Approach depends on natural language signals (identifier names, docs), which may be sparse or misleading in some codebases",
        "LLM-based variant relies on an external API/model (Codex) and prompt design; behavior may vary over time"
      ],
      "future_work": [
        "Extend the approach symmetrically to predicting unexpected sinks (the paper focuses on sources)",
        "Apply the framework to additional languages and security queries beyond the five evaluated"
      ],
      "motivation": "Improve precision of taint analyses for policies that rely on informal, natural-language cues by filtering flows that are expected, surfacing only unexpected flows that are more likely problematic.",
      "potential_research_ideas": [
        "Active learning loop that prioritizes ambiguous flows for human labeling to reduce annotation effort for the binary classifier",
        "Leverage graph neural networks over interprocedural data-flow paths to capture richer structural context alongside NL cues",
        "Self-training or pseudo-labeling from high-confidence predictions to expand training data in new domains/projects",
        "Project- and package-aware models that condition on library metadata and ecosystem norms to refine expectations",
        "Model calibration and uncertainty estimation to decide when to defer to human review vs auto-filter",
        "Explainability module that highlights NL tokens and code path segments driving an 'unexpected' decision for developer trust",
        "Adversarially robust training against misleading identifier names or obfuscation",
        "Hybrid static+dynamic taint signals (e.g., selective dynamic tracing) to validate surprising flows with minimal runtime overhead"
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment VarCLR with stronger code-focused encoders (e.g., CodeBERT, CodeT5, UniXcoder) fine-tuned on flow-label tasks",
        "Encode full source-to-sink paths with path-sensitive sequence/graph encoders (GGNN/GNN or path-based models) instead of only NL fields",
        "Multi-task learning that jointly predicts sink type and expectedness to share representations and improve generalization",
        "Calibrate LLM few-shot predictions with consistency checks and ensemble prompting; integrate with retrieval of API docs",
        "Introduce confidence thresholds and cost-sensitive loss to optimize precision-recall trade-offs per vulnerability class",
        "Domain adaptation to transfer across repositories/libraries with different naming conventions (e.g., adversarial or contrastive objectives)"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://figshare.com/s/1ab456424bfb5a2ead5e",
      "frameworks": [
        "CodeQL",
        "VarCLR (pretrained embeddings)",
        "OpenAI Codex API"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "GitHub/CodeQL code scanning over 250K open-source JavaScript/TypeScript projects",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Availability and quality of identifier names and documentation vary across projects",
        "Labeling effort vs accuracy trade-offs across model variants",
        "Integration into existing static analysis pipelines and policy maintenance",
        "Generalizing across diverse libraries and coding conventions"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A bimodal taint analysis (Fluffy) that combines static analysis with machine learning to identify problematic flows",
      "A general framework with four ML instantiations (binary classifier, sink prediction, novelty detection via one-class SVM, and few-shot Codex) offering trade-offs between labeling effort and accuracy",
      "Integration into the CodeQL framework and application to 250K JavaScript/TypeScript projects",
      "Empirical results showing \"81%–97% precision, 80%–100% recall, and 76%–97% F1-score, depending on the analysis\"",
      "On five vulnerability types, \"Fluffy achieves an F1 score of 0.85 or more on four of them across a variety of datasets\"",
      "Usefulness study: detected 117/131 historical vulnerabilities and reported 16 new vulnerabilities (8 confirmed so far)"
    ]
  },
  {
    "arxiv_id": "2302.01749v1",
    "title": "Command Line Interface Risk Modeling",
    "authors": "Dr Anthony L. Faulds",
    "abstract": "Protecting sensitive data is an essential part of security in cloud computing. However, only specific privileged individuals have access to view or interact with this data; therefore, it is unscalable to depend on these individuals also to maintain the software. A solution to this is to allow non-privileged individuals access to maintain these systems but mask sensitive information from egressing. To this end, we have created a machine-learning model to predict and redact fields with sensitive data. This work concentrates on Azure PowerShell, showing how it applies to other command-line interfaces and APIs. Using the F5-score as a weighted metric, we demonstrate different transformation techniques to map this problem from an unknown field to the well-researched area of natural language processing.",
    "published_date": "2023-01-17",
    "pdf_link": "https://arxiv.org/pdf/2302.01749v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cloud Security",
      "subdomain": "Data Loss Prevention (DLP) / Information Leakage Prevention",
      "specific_problem": "Predicting and redacting sensitive fields in Azure PowerShell CLI command responses",
      "attack_types": [
        "Information leakage",
        "Data exfiltration",
        "Credential/secret exposure"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Bag-of-Words per feature",
        "specific": null,
        "novel_contribution": "Proposes separating word counts by feature (command name, module, field name, field type, parent name, parent type) to add position sensitivity for CLI tokens"
      },
      {
        "type": "primary",
        "category": "TF-IDF per feature",
        "specific": null,
        "novel_contribution": "Extends TF-IDF by applying per-feature vectors to capture differing importance of terms across CLI components"
      },
      {
        "type": "primary",
        "category": "Word Embedding",
        "specific": "Word2Vec (domain-specific)",
        "novel_contribution": "Trains a Word2Vec model on Azure PowerShell commands/responses to handle specialized vocabulary and acronyms better than generic embeddings"
      },
      {
        "type": "baseline",
        "category": "Bag-of-Words",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "TF-IDF",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Boosted Trees",
        "specific": "AdaBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Neural Network",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Manually labeled Azure PowerShell CLI field-sensitivity dataset",
        "type": "proprietary",
        "domain": "command_line_outputs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Azure PowerShell commands and responses corpus (unlabeled) for Word2Vec training",
        "type": "proprietary",
        "domain": "command_line_outputs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "F5-score (F-beta, beta=5)",
      "Precision",
      "Recall",
      "AUC-ROC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can the problem of CLI response redaction be effectively mapped to standard NLP representations?",
        "Which text transformation (BOW, TF-IDF, Word Embeddings, per-feature variants) works best for predicting sensitive fields under recall-heavy weighting (F5)?",
        "How should PascalCase CLI tokens (commands, types, field names) be tokenized to serve ML?",
        "Can a model generalize across many teams’ naming conventions with limited labeled coverage?"
      ],
      "gaps_identified": [
        "CLI data do not follow natural language grammar, reducing the effectiveness of general NLP assumptions.",
        "Pretrained word embeddings misinterpret domain-specific tokens (e.g., Az, Id) and acronyms.",
        "Homonyms/acronyms (e.g., VM) are ambiguous across contexts and not disambiguated by simple embeddings.",
        "Training data covers only a small fraction (about 4%) of all commands; generalization is challenging.",
        "Sensitive variable values cannot be included due to privacy and handling constraints.",
        "BOW/TF-IDF per feature expand dimensionality significantly, increasing training time.",
        "Lack of overarching naming standards across teams complicates modeling."
      ],
      "limitations": [
        "Variable values are omitted from training/inference to avoid egressing sensitive data and due to type heterogeneity.",
        "Labeled set derived from ~1,420 commands (~4% coverage) with 62,579 items and 2,155 redacted positives; coverage is limited.",
        "Sensitivity definition excludes IPs, URLs, ports (focuses on auth/authorization artifacts), which may miss some leakage vectors.",
        "Assumes DRIs are good users; threat model does not include malicious insiders.",
        "Word embeddings cannot handle homonyms/acronyms reliably without extra context.",
        "No feature selection is applied to reduce the expanded per-feature vector spaces.",
        "Model comparison keeps identical hyperparameters across transforms; not targeted to find absolute best model."
      ],
      "future_work": [
        "Extend approach beyond PowerShell to other CLIs and APIs.",
        "Move from binary sensitive/not-sensitive to multiclass labeling for specific PII/secret types.",
        "Predict additional risks such as commands’ likelihood of causing outages.",
        "Introduce feature selection to reduce BOW-PF/TF-IDF-PF dimensionality (e.g., tree-based importance to prune vocabulary).",
        "Explore methods to improve generalization across teams and naming variations."
      ],
      "motivation": "Enable non-privileged maintainers (DRIs) to operate Sovereign Cloud systems while masking sensitive information, scaling support without expanding privileged operator pool.",
      "potential_research_ideas": [
        "Domain-adapt a lightweight contextual language model (e.g., a small BERT variant) on CLI corpora with subword tokenization tuned for PascalCase and acronyms.",
        "Incorporate non-content value descriptors (length, charset class, entropy, mask patterns) that reveal sensitivity without exposing values, possibly via secure feature extraction at source.",
        "Active learning with operator-in-the-loop to efficiently expand labeled coverage and adapt to evolving definitions of sensitive fields.",
        "Multi-task learning to predict both sensitivity and sensitivity category (password, key, connection string), improving specificity and explainability.",
        "Graph- or hierarchy-aware models that encode field-parent/type-parent relationships (e.g., hierarchical attention or GNN over response schema).",
        "Semi-supervised learning or weak supervision using heuristic rules (e.g., regexes for secrets) to label large unlabeled corpora, then refine with ML.",
        "Calibration and risk-aware thresholding optimized for F5, with cost-sensitive learning to formalize recall preference.",
        "Federated or privacy-preserving training (e.g., DP-SGD) to leverage sensitive data locally without egress."
      ],
      "architectural_improvement_recommendations": [
        "Adopt subword tokenization (WordPiece/BPE) customized for PascalCase and common CLI acronyms to reduce OOV and handle variants.",
        "Pretrain a domain-specific masked language model on large CLI/API corpora; fine-tune for sensitivity classification with hierarchical inputs (command, field, types).",
        "Augment features with schema-aware signals (field path depth, type compatibility, presence in known secret-bearing resource types like KeyVault).",
        "Implement feature selection/pruning for BOW-PF/TF-IDF-PF using tree-based importance or mutual information to control dimensionality.",
        "Add value-derived privacy-safe features (length, character classes, entropy, checksum of templates) computed in a secure enclave to avoid leakage.",
        "Introduce hierarchical attention to weight command vs. field vs. parent-type segments differently during classification.",
        "Use threshold calibration (Platt/Isotonic) and cost-sensitive loss to directly optimize F5 preference.",
        "Deploy an active learning loop with uncertainty sampling and human feedback integration into training pipelines."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Microsoft Sovereign Cloud operational environment via a CLI used by DRIs (Azure PowerShell-based)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Handling sensitive data without egress; variable values omitted for privacy.",
        "Generalization across many teams’ inconsistent naming and acronyms.",
        "High dimensionality from per-feature vectorization increases training cost.",
        "Balancing high recall with usability; excessive redaction hinders maintenance.",
        "Limited labeled coverage relative to the full command surface."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Maps CLI risk prediction to NLP by tokenizing PascalCase command/field/type metadata into document-like inputs.",
      "Introduces per-feature BOW/TF-IDF transformations to capture positional importance of terms across CLI components.",
      "Trains a domain-specific Word2Vec to better represent Azure PowerShell vocabulary than generic embeddings.",
      "Builds and evaluates models (LR, AdaBoost Trees, Neural Networks) under a recall-weighted metric (F5-score).",
      "Defines an operational metric (F5) prioritizing recall for redaction to reduce sensitive leakage.",
      "Describes a practical redaction pipeline enabling non-privileged DRIs to operate with masked outputs, applicable to other CLIs/APIs."
    ]
  },
  {
    "arxiv_id": "2301.12800v1",
    "title": "Behavioural Reports of Multi-Stage Malware",
    "authors": "Marcus Carpenter; Chunbo Luo",
    "abstract": "The extensive damage caused by malware requires anti-malware systems to be constantly improved to prevent new threats. The current trend in malware detection is to employ machine learning models to aid in the classification process. We propose a new dataset with the objective of improving current anti-malware systems. The focus of this dataset is to improve host based intrusion detection systems by providing API call sequences for thousands of malware samples executed in Windows 10 virtual machines. A tutorial on how to create and expand this dataset is provided along with a benchmark demonstrating how to use this dataset to classify malware. The data contains long sequences of API calls for each sample, and in order to create models that can be deployed in resource constrained devices, three feature selection methods were tested. The principal innovation, however, lies in the multi-label classification system in which one sequence of APIs can be tagged with multiple labels describing its malicious behaviours.",
    "published_date": "2023-01-30",
    "pdf_link": "https://arxiv.org/pdf/2301.12800v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "benchmark"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Host-based Intrusion Detection (HIDS)",
      "specific_problem": "Multi-label behavioural classification of Windows malware via API call sequences; selecting resource-efficient subsequences for endpoint deployment",
      "attack_types": [
        "multi-stage malware behaviours",
        "Windows PE malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Multi-label classification",
        "specific": null,
        "novel_contribution": "Introduces a multi-label tagging system where one API-call sequence can be tagged with multiple behaviour labels (rather than mutually exclusive labels)."
      },
      {
        "type": "primary",
        "category": "Feature selection",
        "specific": "Sequence truncation to first 512 API calls; two additional subsequence selection algorithms (unspecified)",
        "novel_contribution": "Evaluates feature-selection methods to enable deployment on resource-constrained devices."
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "GRU",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Bidirectional GRU",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Behavioural Reports of Multi-Stage Malware (API-call sequence dataset)",
        "type": "public",
        "domain": "api_call_sequences",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "VirusShare (source of malware binaries)",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://virusshare.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusTotal (labels/reports used for multi-label annotation)",
        "type": "public",
        "domain": "threat_intel_labels",
        "link": "https://github.com/VirusTotal/vt-py",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CTU-13",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Microsoft Big 2015 (opcode-based)",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ADAF-LD (Linux API-call dataset)",
        "type": "public",
        "domain": "api_call_sequences",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can multi-label tagging of API-call sequences better capture and report multiple malicious behaviours present in a single execution trace?",
        "Which feature-selection strategy for fixed-length (512) subsequences yields the best classification performance under resource constraints suitable for endpoint/HIDS deployment?",
        "Can a Windows-10-based, API-sequence dataset improve host-based malware detection compared to prior datasets focused on static or network features?"
      ],
      "gaps_identified": [
        "Scarcity of publicly-available datasets providing API call sequences for malware on modern OSes (Windows 10).",
        "Most prior malware detection works use mutually exclusive labels (binary or multi-class), with little support for multi-label behaviour tagging.",
        "Many datasets and studies rely on network features or static features that may not be suitable/available for HIDS or fileless scenarios.",
        "Some existing API-call datasets target older or non-Windows environments, limiting modern representativeness.",
        "Feature selection is often heuristic/manual; end-to-end or principled selection for long sequences is underexplored."
      ],
      "limitations": [
        "Labels are automatically derived from VirusTotal, which the authors note is a weak form of supervision compared to expert labelling.",
        "Sequences are truncated to a fixed length (512) to meet hardware constraints, potentially losing long-range behavioural information.",
        "Dataset currently focuses on Windows 10; generalization to other OSes/environments is not evaluated in this work.",
        "Network and static features are intentionally excluded; thus, multi-modal fusion with those signals is not explored in this dataset/benchmark."
      ],
      "future_work": [
        "Investigate concept drift using the dataset’s modular/batch structure (explicitly referenced as a motivation).",
        "Regular retraining/updates for sustained detection performance on endpoints.",
        "Expanding dataset breadth (more malware families/behaviours) and OS/platform coverage.",
        "Exploring additional/learned feature-selection strategies for long API sequences."
      ],
      "motivation": "Provide a modern, host-based malware dataset of API-call sequences with a multi-label behaviour tagging scheme to improve HIDS, along with a practical pipeline/tutorial and baseline benchmarks under resource constraints.",
      "potential_research_ideas": [
        "Concept-drift and continual/online learning using the dataset’s modular batches for time-aware evaluation and adaptive HIDS.",
        "Label-denoising and weak-supervision methods to mitigate VirusTotal-derived label noise (e.g., co-teaching, confident learning).",
        "Self-supervised pretraining on large unlabeled API sequences (contrastive, masked-language-model style) for improved downstream multi-label performance.",
        "Hierarchical or long-sequence models (e.g., Temporal Convolutional Networks, Transformers with sparse/linear attention, hierarchical RNNs) to handle very long API traces without truncation.",
        "Open-vocabulary/API-token modeling (subword/BPE over API names and arguments) to generalize to unseen APIs.",
        "Multi-modal fusion (optional) with lightweight host signals (e.g., process tree metadata) while preserving HIDS deployability.",
        "Active learning and human-in-the-loop triage to refine/expand multi-label annotations.",
        "Cross-OS/domain transfer (Windows↔Linux/Android) using domain adaptation and promptable sequence encoders."
      ],
      "architectural_improvement_recommendations": [
        "Replace fixed 512 truncation with learned segmenters or attention-based selection (e.g., reinforcement learning for key-event extraction or attention-guided cropping).",
        "Adopt efficient long-sequence architectures (Performer/Longformer/TCN) or hierarchical encoders to capture long-range dependencies with bounded compute.",
        "Incorporate multi-task learning (e.g., behaviour tags + auxiliary tasks like API family prediction or process-tree relation prediction) to improve representation learning.",
        "Apply label smoothing, calibrated sigmoid thresholds, and class imbalance handling (e.g., focal loss) tailored to multi-label detection.",
        "Use weak-label correction/aggregation from multiple AV vendors (e.g., majority voting, agreement-weighted labels) to reduce noise.",
        "Perform time-split evaluations and continual fine-tuning protocols to assess drift robustness."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/marcusCarpenter97/Malware-data",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Data collection/analysis used 10 Windows 10 VMs (2 cores, 2 GB RAM each) on an Intel Core i9-10980XE host with 64 GB RAM and 4 TB SSD; benchmarks trained on an Nvidia Titan RTX GPU. Long sequences require high GPU RAM; models trained on truncated sequences of length 512 for practicality."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Targeted for endpoint/HIDS on Windows 10 hosts; authors aim for resource-constrained devices including budget PCs and IoT devices.",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Long API sequences are expensive to process; truncation/selection is required on constrained endpoints.",
        "Labels come from VirusTotal (noisy/weak supervision), which may affect reliability in production.",
        "Need for periodic retraining to address evolving malware and concept drift.",
        "Potential generalization gaps across OS versions/environments."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a new Windows 10 API-call sequence dataset for malware with multi-label behaviour annotations (principal innovation).",
      "Provides a full tutorial/pipeline to build, label (via VirusTotal), and expand the dataset using CAPE Sandbox and VMs.",
      "Benchmarks six model architectures across three feature-selection methods on the dataset (18 models total).",
      "Demonstrates that using the first 512 API calls yields higher classification accuracy than other subsequence selection methods; GRU is best on the easiest slice, while BiGRU leads on harder slices.",
      "Designs the dataset in modular batches to facilitate research on concept drift and incremental updates for sustainable HIDS."
    ]
  },
  {
    "arxiv_id": "2301.04314v2",
    "title": "ML-FEED: Machine Learning Framework for Efficient Exploit Detection",
    "authors": "Tanujay Saha; Tamjid Al-Rahat; Najwa Aaraj; Yuan Tian; Niraj K. Jha",
    "abstract": "Machine learning (ML)-based methods have recently become attractive for detecting security vulnerability exploits. Unfortunately, state-of-the-art ML models like long short-term memories (LSTMs) and transformers incur significant computation overheads. This overhead makes it infeasible to deploy them in real-time environments. We propose a novel ML-based exploit detection model, ML-FEED, that enables highly efficient inference without sacrificing performance. We develop a novel automated technique to extract vulnerability patterns from the Common Weakness Enumeration (CWE) and Common Vulnerabilities and Exposures (CVE) databases. This feature enables ML-FEED to be aware of the latest cyber weaknesses. Second, it is not based on the traditional approach of classifying sequences of application programming interface (API) calls into exploit categories. Such traditional methods that process entire sequences incur huge computational overheads. Instead, ML-FEED operates at a finer granularity and predicts the exploits triggered by every API call of the program trace. Then, it uses a state table to update the states of these potential exploits and track the progress of potential exploit chains. ML-FEED also employs a feature engineering approach that uses natural language processing-based word embeddings, frequency vectors, and one-hot encoding to detect semantically-similar instruction calls. Then, it updates the states of the predicted exploit categories and triggers an alarm when a vulnerability fingerprint executes. Our experiments show that ML-FEED is 72.9x and 75,828.9x faster than state-of-the-art lightweight LSTM and transformer models, respectively. We trained and tested ML-FEED on 79 real-world exploit categories. It predicts categories of exploit in real-time with 98.2% precision, 97.4% recall, and 97.8% F1 score. These results also outperform the LSTM and transformer baselines.",
    "published_date": "2023-01-11",
    "pdf_link": "https://arxiv.org/pdf/2301.04314v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Vulnerability and Exploit Detection",
      "specific_problem": "Real-time detection and categorization of vulnerability exploit chains from program API-call traces using a hybrid ML classifier plus state-table sequence monitor informed by CWE/CVE-derived fingerprints",
      "attack_types": [
        "SQL injection (CWE-89)",
        "Cross-Site Request Forgery (CWE-352)",
        "Multiple CVE/CWE exploit categories (79 total)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Feed-forward Neural Network",
        "specific": null,
        "novel_contribution": "Lightweight per-API-call multi-label classifier operating on rich hybrid features (embeddings + frequency vectors + one-hot) to predict potential exploits at each instruction, integrated with a state-table to track exploit chains"
      },
      {
        "type": "primary",
        "category": "Rule-based / State machine",
        "specific": "State table sequence monitor",
        "novel_contribution": "Tracks exploit progress across API calls; raises alarms when CWE/CVE vulnerability fingerprints are satisfied"
      },
      {
        "type": "primary",
        "category": "Embedding",
        "specific": "Word embeddings (NLP-based)",
        "novel_contribution": "Used to capture semantic similarity among API names/arguments combined with frequency vectors and one-hot encoding for API category/scope/package and I/O types"
      },
      {
        "type": "baseline",
        "category": "RNN/LSTM",
        "specific": "Lightweight LSTM (LSTM cell + feed-forward layer)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "GPT-2 (decoder-only)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Multi-label classification"
    ],
    "datasets": [
      {
        "name": "CWE (Common Weakness Enumeration)",
        "type": "public",
        "domain": "vulnerability_taxonomy",
        "link": "https://cwe.mitre.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CVE (Common Vulnerabilities and Exposures)",
        "type": "public",
        "domain": "vulnerability_reports",
        "link": "https://cve.mitre.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ML-FEED exploit sequences database (derived from CWE/CVE and public exploit programs)",
        "type": "synthetic",
        "domain": "program_api_traces/instruction_sequences (Java)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Attack traces for CVE vulnerabilities in three popular Java libraries",
        "type": "proprietary",
        "domain": "program_traces (Java libraries)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Lightweight LSTM",
        "paper_reference": null,
        "metric": "Speedup over baseline",
        "their_result": "\"ML-FEED is 72.9x ... faster than state-of-the-art lightweight LSTM\"",
        "baseline_result": null
      },
      {
        "method_name": "Lightweight LSTM",
        "paper_reference": null,
        "metric": "Model compactness",
        "their_result": "\"4.5x ... more compact\" than lightweight LSTM",
        "baseline_result": null
      },
      {
        "method_name": "GPT-2 Transformer",
        "paper_reference": null,
        "metric": "Speedup over baseline",
        "their_result": "\"ML-FEED is ... 75,828.9x faster than ... transformer\"",
        "baseline_result": null
      },
      {
        "method_name": "GPT-2 Transformer",
        "paper_reference": null,
        "metric": "Model compactness",
        "their_result": "\"2500.6x more compact\" than transformer",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Precision",
      "Recall",
      "F1 score",
      "Inference time / speedup",
      "Model size / compactness"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can exploit detection be performed in real-time without sacrificing detection performance compared to LSTM/Transformer sequence models?",
        "Can vulnerability fingerprints and low-level exploit sequences be automatically extracted from CWE/CVE to keep models up to date?",
        "Does operating at per-API-call granularity with a state-table effectively track exploit chains compared to whole-sequence models?"
      ],
      "gaps_identified": [
        "State-of-the-art sequence models (LSTMs/Transformers) have prohibitive computation overhead for real-time deployment.",
        "Traditional non-ML approaches require manual rules/signatures and struggle with large codebases.",
        "Prior feature extraction often omits discriminative API information (arguments, categories, scope, package/class, I/O types), hurting performance.",
        "Lack of sufficient heterogeneous vulnerability data; need a way to update models with latest exploits."
      ],
      "limitations": [
        "SDG construction can be imprecise for certain program features (e.g., reflected calls) and may generate sequences that do not occur at run time.",
        "Evaluation and tooling focus on Java; although method is general, experiments analyze Java-based exploits with WALA."
      ],
      "future_work": [],
      "motivation": "Enable highly efficient, real-time exploit detection by combining ML with explicit vulnerability knowledge (CWE/CVE), overcoming heavy overhead of sequence models and limitations of manual rule-based systems.",
      "potential_research_ideas": [
        "Extend ML-FEED to additional languages and ecosystems (C/C++, Python, mobile apps) with language-specific API mappings.",
        "Incorporate structural program information with lightweight GNNs over SDG snippets while retaining per-call efficiency.",
        "Self-supervised or contrastive pretraining on large unlabeled API traces to improve generalization to unseen exploits.",
        "Online/continual learning to automatically incorporate newly published CVEs with minimal retraining.",
        "Robustness against evasion/obfuscation (e.g., API aliasing, reflection, dead-code insertion) via invariance learning and taint-aware features.",
        "Integrate dynamic taint analysis to strengthen data-flow evidence for vulnerability fingerprints with low overhead (e.g., selective instrumentation).",
        "Develop benchmark suite and open dataset of per-API-call labeled exploit traces for reproducible evaluation."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment static embeddings with trainable subword/name-piece embeddings for API identifiers and arguments.",
        "Knowledge distillation from a large transformer trained offline to the compact ML-FEED classifier for accuracy gains without runtime cost.",
        "Quantization and pruning of the classifier for further latency and memory reductions on edge/agent deployments.",
        "Use an automata-learning approach to infer state transitions from data, complementing the hand-crafted state table.",
        "Adopt dilated temporal convolutions (TCN) over short windows as an alternative to LSTM/Transformer for limited sequence context with low cost."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "WALA (static analysis)"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Java application/library analysis (API-call traces with static/dynamic analysis)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Prior sequence models too slow for real-time environments; ML-FEED addresses efficiency.",
        "Need to extract program traces and build SDGs; SDG imprecision for features like reflection acknowledged.",
        "Administrative access constraints for exploit detection tools noted in motivation."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Hybrid system combining a lightweight per-API-call ML classifier with a state-table sequence monitor to detect exploit chains efficiently.",
      "Operate at finer granularity (per API call) instead of whole-sequence classification, dramatically reducing computation.",
      "Automated methodology to extract high-level vulnerability fingerprints from CWE and low-level vulnerability queries from CVE; used to build an exploit sequence database.",
      "Hybrid feature engineering capturing API name, category, analysis scope, package/class, and I/O types via embeddings, frequency vectors, and one-hot encoding.",
      "Empirical results: 98.2% precision, 97.4% recall, 97.8% F1 across 79 exploit categories; 72.9x and 75,828.9x faster than lightweight LSTM and GPT-2 transformer baselines; substantially more compact.",
      "Demonstrated detection of reported critical CVE vulnerabilities in three popular Java libraries."
    ]
  },
  {
    "arxiv_id": "2301.03064v1",
    "title": "Deepfake CAPTCHA: A Method for Preventing Fake Calls",
    "authors": "Lior Yasur; Guy Frankovits; Fred M. Grabovski; Yisroel Mirsky",
    "abstract": "Deep learning technology has made it possible to generate realistic content of specific individuals. These `deepfakes' can now be generated in real-time which enables attackers to impersonate people over audio and video calls. Moreover, some methods only need a few images or seconds of audio to steal an identity. Existing defenses perform passive analysis to detect fake content. However, with the rapid progress of deepfake quality, this may be a losing game.   In this paper, we propose D-CAPTCHA: an active defense against real-time deepfakes. The approach is to force the adversary into the spotlight by challenging the deepfake model to generate content which exceeds its capabilities. By doing so, passive detection becomes easier since the content will be distorted. In contrast to existing CAPTCHAs, we challenge the AI's ability to create content as opposed to its ability to classify content. In this work we focus on real-time audio deepfakes and present preliminary results on video.   In our evaluation we found that D-CAPTCHA outperforms state-of-the-art audio deepfake detectors with an accuracy of 91-100% depending on the challenge (compared to 71% without challenges). We also performed a study on 41 volunteers to understand how threatening current real-time deepfake attacks are. We found that the majority of the volunteers could not tell the difference between real and fake audio.",
    "published_date": "2023-01-08",
    "pdf_link": "https://arxiv.org/pdf/2301.03064v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Multimedia Forensics",
      "subdomain": "Deepfake Detection (Audio/Voice)",
      "specific_problem": "Active challenge-response to detect and prevent real-time deepfake (voice cloning) calls",
      "attack_types": [
        "Impersonation",
        "Social engineering",
        "Fraud/scams",
        "Espionage",
        "Sabotage",
        "Blackmail",
        "Defamation",
        "Misinformation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Challenge-Response System",
        "specific": "D-CAPTCHA",
        "novel_contribution": "Active challenges that force RT-DF systems beyond their capabilities; integrates identity-model and task-detection to make passive detection easier and more robust"
      },
      {
        "type": "primary",
        "category": "Speaker Verification",
        "specific": null,
        "novel_contribution": "Identity model used to verify the caller's identity before and during the challenge to prevent turning off RT-DF or splicing"
      },
      {
        "type": "primary",
        "category": "Task Detection Classifier",
        "specific": null,
        "novel_contribution": "Task detection model verifies that the caller actually performed the requested challenge"
      },
      {
        "type": "baseline",
        "category": "Audio Deepfake Detectors (ADDS)",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Anomaly Detection"
    ],
    "datasets": [
      {
        "name": "Collected RT-DF audio samples from five state-of-the-art voice cloning tools",
        "type": "synthetic",
        "domain": "audio_deepfakes",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "41-volunteer user study evaluating perceived realism of RT-DF audio",
        "type": "private",
        "domain": "human_subject_study",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Passive SOTA audio deepfake detectors without D-CAPTCHA challenges",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "“D-CAPTCHA outperforms state-of-the-art audio deepfake detectors with an accuracy of 91-100% depending on the challenge”",
        "baseline_result": "“71% without challenges”"
      }
    ],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can an active challenge-response (D-CAPTCHA) reliably expose real-time deepfakes during calls?",
        "Which challenges effectively push RT-DF systems beyond their current capabilities to aid detection?",
        "How threatening are current real-time deepfake (voice cloning) attacks to typical users?"
      ],
      "gaps_identified": [
        "Longevity problem: artifact-based passive detectors risk obsolescence as deepfake quality improves rapidly.",
        "Evasion problem: detectors relying on latent noise patterns can be evaded via common post-processing (e.g., low-pass filtering, compression, additive noise) routinely present in calls.",
        "Poor generalization of passive ADDS to new audio distributions/environments and novel deepfake technologies."
      ],
      "limitations": [
        "Focuses primarily on audio RT-DFs; only preliminary results on video.",
        "Initial set of CAPTCHAs; not exhaustive across all possible challenge types.",
        "Evaluation uses a limited set of five RT-DF tools and a 41-participant user study; broader real-world deployment not reported."
      ],
      "future_work": [
        "Extend D-CAPTCHA to video calls and multimodal challenges.",
        "Expand and refine the challenge set with extensible constraints on realism, identity, task complexity, and time.",
        "Further robustness evaluations against more evasive adversaries and broader RT-DF toolchains."
      ],
      "motivation": "Passive deepfake detectors face longevity and evasion issues as RT-DF quality improves; actively challenging the generator can force distortions that make detection easier and longer-lived.",
      "potential_research_ideas": [
        "Adaptive challenge generation that selects tasks online based on estimated RT-DF capability and response quality.",
        "Game-theoretic modeling of attacker–defender dynamics to optimize challenge policies under latency constraints.",
        "Multimodal D-CAPTCHA combining synchronized audio–visual tasks to tighten identity and liveness guarantees.",
        "Crowdsourced or federated learning to discover novel, high-yield challenges while preserving user privacy.",
        "Formal security model and proofs for D-CAPTCHA guarantees under bounded RT-DF capabilities and delays."
      ],
      "architectural_improvement_recommendations": [
        "Integrate strong speaker verification embeddings (e.g., modern ASV front-ends) for the identity model to improve pre/during-challenge consistency checks.",
        "Use robust task detectors (e.g., keyword spotting or ASR-lite) tailored for noisy telephony channels to verify challenge completion.",
        "Employ OOD detection on response segments to flag abnormal acoustics induced by challenges.",
        "Leverage higher sample-rate features or multi-band front-ends for challenge segments to capture artifacts beyond normal speech bands.",
        "Pipeline optimization to analyze only anticipated response windows for efficiency and lower latency."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Phone/VoIP calls or virtual meetings (e.g., Zoom)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Designing challenges that are easy for humans yet reliably difficult for RT-DF systems.",
        "User experience/usability trade-offs during live calls.",
        "Robust identity and task detection under telephony noise, compression, and variable devices.",
        "Handling evasive strategies (e.g., attempting to disable RT-DF or splice pre-recorded content).",
        "Integration into call workflows and automated assistants."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes the first active defense against real-time deepfakes (D-CAPTCHA) via challenge-response.",
      "Defines D-CAPTCHA and properties of strong deepfake CAPTCHAs with four constraints (realism, identity, task complexity, time) and methods to verify them.",
      "Evaluates five state-of-the-art RT-DF voice cloning models with a 41-volunteer user study to assess current threat levels.",
      "Demonstrates that D-CAPTCHA significantly improves detection, achieving 91–100% accuracy depending on challenge (vs. 71% without challenges), and studies robustness against evasive adversaries."
    ]
  },
  {
    "arxiv_id": "2301.07393v1",
    "title": "Using Topological Data Analysis to classify Encrypted Bits",
    "authors": "Jayati Kaushik; Aaruni Kaushik; Upasana Parashar",
    "abstract": "We present a way to apply topological data analysis for classifying encrypted bits into distinct classes. Persistent homology is applied to generate topological features of a point cloud obtained from sets of encryptions. We see that this machine learning pipeline is able to classify our data successfully where classical models of machine learning fail to perform the task. We also see that this pipeline works as a dimensionality reduction method making this approach to classify encrypted data a realistic method to classify the given encryptioned bits.",
    "published_date": "2023-01-18",
    "pdf_link": "https://arxiv.org/pdf/2301.07393v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cryptography",
      "subdomain": "Cryptanalysis",
      "specific_problem": "Classifying ciphertexts to recover the encrypted bit (0/1) under the GSW'13 homomorphic encryption scheme using supervised learning on topological features",
      "attack_types": [
        "Chosen-Plaintext Attack (CPA)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Topological Data Analysis",
        "specific": "Persistent homology (cubical persistence) with Height and Radial filtrations; vectorization via Persistence Entropy",
        "novel_contribution": "Applies TDA-derived features to classify encrypted bits; demonstrates strong dimensionality reduction (\"reducing the number of features from 9612 to 55\") and successful classification where classical ML on raw data fails"
      },
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": "Used as a classifier on TDA feature vectors; often outperforms Random Forest in this setting"
      },
      {
        "type": "primary",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": "Used as a classifier on TDA feature vectors"
      },
      {
        "type": "baseline",
        "category": "Neural Network",
        "specific": null,
        "novel_contribution": "Tried on untransformed ciphertext matrices; reported to fail to perform the task"
      },
      {
        "type": "baseline",
        "category": "Tensor Methods",
        "specific": "Tensor classification",
        "novel_contribution": "Tried on untransformed ciphertext matrices; reported to fail"
      },
      {
        "type": "baseline",
        "category": "AutoML",
        "specific": "AutoKeras",
        "novel_contribution": "AutoKeras on raw data; reported to fail"
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": "On untransformed data",
        "novel_contribution": "RF directly on raw ciphertext matrices; reported to fail"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "GSW13 encrypted bits (generated ciphertext matrices)",
        "type": "synthetic",
        "domain": "cryptographic_ciphertexts",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Neural Networks (on untransformed ciphertext matrices)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "TDA pipeline achieved accuracy up to 0.95 depending on n (e.g., Decision Tree: n=28: 0.93; n=32: 0.78; n=64: 0.82; n=128: 0.95)",
        "baseline_result": "All of these models failed to perfom the task."
      },
      {
        "method_name": "Tensor Classification (on untransformed ciphertext matrices)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "TDA pipeline achieved accuracy up to 0.95 depending on n",
        "baseline_result": "All of these models failed to perfom the task."
      },
      {
        "method_name": "AutoKeras (on untransformed ciphertext matrices)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "TDA pipeline achieved accuracy up to 0.95 depending on n",
        "baseline_result": "All of these models failed to perfom the task."
      },
      {
        "method_name": "Random Forest (on untransformed ciphertext matrices)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "TDA pipeline achieved accuracy up to 0.95 depending on n",
        "baseline_result": "All of these models failed to perfom the task."
      }
    ],
    "performance_metrics_used": [
      "Accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can topological data analysis (persistent homology) produce features that enable accurate classification of encrypted bits (0 vs 1) under GSW13?",
        "Does the TDA-based pipeline act as an effective dimensionality reduction method that makes classification of encrypted bits computationally realistic?"
      ],
      "gaps_identified": [
        "Classical supervised machine learning algorithms on raw encrypted matrices (Neural Networks, Tensor Classification, AutoKeras, Random Forest) failed to perform the task.",
        "Need for feature representations sensitive to geometric/topological patterns in encrypted data."
      ],
      "limitations": [
        "We are yet to check the feature importance. That might give us further insight into the explainability of the model.",
        "We are also yet to see if this keeps working for very large values of n.",
        "It would also be of interest to understand why Decision Tree seems to perform better most of the time.",
        "Best filtration direction reported as (-1, 1) and center as (13, 13) for n=6 without an explanation of generality."
      ],
      "future_work": [
        "Check feature importance for explainability.",
        "Test whether the approach keeps working for very large values of n.",
        "Understand why Decision Tree seems to perform better most of the time."
      ],
      "motivation": "Classify encrypted bits under a CPA setting where an encryption oracle is available, showing TDA can succeed where classical ML on raw ciphertexts fails and can reduce dimensionality to make such classification realistic.",
      "potential_research_ideas": [
        "Evaluate TDA-based classification across standard, larger GSW13/LWE parameter sets and security levels; quantify scaling behavior.",
        "Compare multiple TDA vectorizations (Betti curves, persistence images, heat kernel signatures, Wasserstein/Bottleneck amplitudes) against persistence entropy for this task.",
        "Learn filtration parameters (direction and center) or use multi-directional/multi-center filtrations combined via feature stacking or attention.",
        "Integrate topological kernels (e.g., persistence scale-space, sliced-Wasserstein kernels) with SVMs for classification of ciphertexts.",
        "Assess generalization to other homomorphic encryption schemes or cryptosystems (e.g., BFV, CKKS, BGV) and to different plaintext distributions.",
        "Conduct rigorous ablations: raw vs. TDA features; single vs. multi-filtration; classifier families (DT/RF/GBDT/XGBoost/linear SVM).",
        "Study robustness to noise and parameter variations in encryption (e.g., error terms in LWE) and to dataset shifts.",
        "Explore explainability by mapping important TDA features back to image regions/filtration steps."
      ],
      "architectural_improvement_recommendations": [
        "Adopt multi-filtration pipelines (several height directions and multiple radial centers) and concatenate their persistence-based feature vectors.",
        "Replace persistence entropy with persistence images or combine multiple vectorizations via feature fusion to improve separability.",
        "Tune gradient-boosted tree models (e.g., XGBoost/LightGBM) on TDA features which often outperform RF/DT on tabular features.",
        "Hyperparameterize filtration and vectorization within a cross-validated pipeline; optionally perform automated model selection.",
        "Consider topological kernels with SVMs to leverage the geometry of persistence diagrams directly.",
        "Add calibration and threshold analysis; report ROC-AUC, precision/recall to complement accuracy on balanced/unbalanced settings."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "giotto-tda"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Unknown performance for very large values of n.",
        "Explainability not yet analyzed (feature importance not computed)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a TDA-based pipeline (persistent homology on binary images of ciphertexts with height and radial filtrations, cubical persistence, persistence entropy) to classify encrypted bits under GSW13.",
      "Demonstrates successful classification and strong dimensionality reduction (\"reducing the number of features from 9612 to 55\").",
      "Shows that several classical ML approaches on raw ciphertext matrices (Neural Networks, Tensor Classification, AutoKeras, Random Forest) fail on this task.",
      "Provides empirical results using Decision Tree and Random Forest classifiers with accuracies, e.g., Decision Tree: n=28: 0.93; n=32: 0.76; n=64: 0.82; n=128: 0.95; Random Forest: n=28: 0.84; n=32: 0.78; n=64: 0.68; n=128: 0.78.",
      "Identifies optimal reported filtration settings via grid search: direction vector (-1, 1); radial center (13, 13) for n=6; uses train/test split of 0.7/0.3."
    ]
  },
  {
    "arxiv_id": "2301.06085v2",
    "title": "Learning Near-Optimal Intrusion Responses Against Dynamic Attackers",
    "authors": "Kim Hammar; Rolf Stadler",
    "abstract": "We study automated intrusion response and formulate the interaction between an attacker and a defender as an optimal stopping game where attack and defense strategies evolve through reinforcement learning and self-play. The game-theoretic modeling enables us to find defender strategies that are effective against a dynamic attacker, i.e. an attacker that adapts its strategy in response to the defender strategy. Further, the optimal stopping formulation allows us to prove that optimal strategies have threshold properties. To obtain near-optimal defender strategies, we develop Threshold Fictitious Self-Play (T-FP), a fictitious self-play algorithm that learns Nash equilibria through stochastic approximation. We show that T-FP outperforms a state-of-the-art algorithm for our use case. The experimental part of this investigation includes two systems: a simulation system where defender strategies are incrementally learned and an emulation system where statistics are collected that drive simulation runs and where learned strategies are evaluated. We argue that this approach can produce effective defender strategies for a practical IT infrastructure.",
    "published_date": "2023-01-11",
    "pdf_link": "https://arxiv.org/pdf/2301.06085v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Response",
      "specific_problem": "Learning automated intrusion response policies against adaptive (dynamic) attackers using an optimal-stopping game formulation",
      "attack_types": [
        "Network intrusion (reconnaissance and exploitation via gateway)",
        "Evasion against IDPS detection"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": "Threshold Fictitious Self-Play (T-FP)",
        "novel_contribution": "A fictitious self-play algorithm that exploits provable threshold structure of optimal stopping strategies to learn near-Nash defender policies against a dynamic attacker."
      },
      {
        "type": "primary",
        "category": "Game Theory",
        "specific": "Optimal stopping game (Dynkin game) with self-play",
        "novel_contribution": "Formulates intrusion response as a zero-sum optimal stopping game enabling proofs of threshold properties and best-response structure."
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": "Fictitious self-play (general)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "POMDP/MDP",
        "specific": "Best-response computation via POMDP (defender) and MDP (attacker) Bellman equations",
        "novel_contribution": "Derives best-response formulations and value functions for each player under one-sided partial observability."
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Self-Play"
    ],
    "datasets": [
      {
        "name": "Emulated IT infrastructure IDPS alert statistics",
        "type": "proprietary",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Simulation episodes generated from emulation-calibrated model",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Expected discounted cumulative reward"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can we learn near-optimal defender strategies against a dynamic (adaptive) attacker rather than a static one?",
        "Does an optimal-stopping (Dynkin game) formulation yield structural (threshold) properties that can be exploited algorithmically?",
        "Can a combined emulation–simulation workflow narrow the gap between simulation-only results and practical IT infrastructures for intrusion response?"
      ],
      "gaps_identified": [
        "Most prior work learns defender strategies against static attackers rather than dynamic/adaptive ones.",
        "Prior evaluations are largely confined to simulations, limiting generalization to practical infrastructures.",
        "Lack of game-theoretic formulations that expose structural properties (e.g., thresholds) for automated intrusion response."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Automate the derivation of effective intrusion response strategies that remain effective against adaptive attackers and are evaluated beyond pure simulation via an emulation system.",
      "potential_research_ideas": [
        "Extend the optimal-stopping game to multi-stage kill chains with multiple attacker intents and heterogeneous costs, learning hierarchical threshold policies.",
        "Relax the assumption of attacker full observability and study equilibria under two-sided partial observability with belief modeling for both players.",
        "Incorporate uncertainty in stop-action effectiveness (phi_l) with Bayesian belief updates and robust RL to handle model misspecification.",
        "Integrate deep function approximation for high-dimensional observations (e.g., raw IDPS features) with a threshold-parameterized policy head.",
        "Apply Policy-Space Response Oracles (PSRO) or CFR-style equilibrium solvers as alternative training regimes and compare exploitability.",
        "Online adaptation: deploy a cautious, safe-RL version of T-FP with conservative exploration and formal service-SLA constraints.",
        "Fuse multiple telemetry sources (EDR, NetFlow, syslogs) and learn observation models jointly with policies via representation learning.",
        "Use distributional RL to capture tail-risk of long intrusions and optimize CVaR-type objectives aligned with defender risk tolerances."
      ],
      "architectural_improvement_recommendations": [
        "Parameterize defender policies as differentiable thresholded functions and train with actor-critic while preserving monotonicity/threshold constraints.",
        "Adopt POMCP or belief-tree search for attacker/defender best-responses to improve sample efficiency under partial observability.",
        "Model uncertainty over observation and transition parameters using Bayesian RL and perform posterior sampling for robust policy learning.",
        "Incorporate PSRO with neural oracles and explicit exploitability measurement to assess convergence toward Nash equilibria.",
        "Augment the emulation-to-simulation mapping with domain randomization to improve sim-to-real transfer robustness."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Emulated enterprise IT infrastructure with gateway, servers, and an IDPS",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Balancing service availability against defensive blocking actions (e.g., gateway block disrupts clients).",
        "Accurate mapping from emulation-collected statistics to simulation parameters.",
        "Dependence on IDPS alert quality and weighting for observation modeling."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Formulates intrusion response as an optimal stopping game (Dynkin game) enabling proofs that optimal strategies have threshold properties.",
      "Proposes Threshold Fictitious Self-Play (T-FP), a self-play RL algorithm that learns near-Nash defender strategies and exploits threshold structure; reports it outperforms a state-of-the-art algorithm for the use case.",
      "Builds a two-system workflow with an emulation system to collect statistics and evaluate learned strategies, and a simulation system to learn strategies via self-play."
    ]
  },
  {
    "arxiv_id": "2301.03532v1",
    "title": "Efficient Attack Detection in IoT Devices using Feature Engineering-Less Machine Learning",
    "authors": "Arshiya Khan; Chase Cotton",
    "abstract": "Through the generalization of deep learning, the research community has addressed critical challenges in the network security domain, like malware identification and anomaly detection. However, they have yet to discuss deploying them on Internet of Things (IoT) devices for day-to-day operations. IoT devices are often limited in memory and processing power, rendering the compute-intensive deep learning environment unusable. This research proposes a way to overcome this barrier by bypassing feature engineering in the deep learning pipeline and using raw packet data as input. We introduce a feature engineering-less machine learning (ML) process to perform malware detection on IoT devices. Our proposed model, \"Feature engineering-less-ML (FEL-ML),\" is a lighter-weight detection algorithm that expends no extra computations on \"engineered\" features. It effectively accelerates the low-powered IoT edge. It is trained on unprocessed byte-streams of packets. Aside from providing better results, it is quicker than traditional feature-based methods. FEL-ML facilitates resource-sensitive network traffic security with the added benefit of eliminating the significant investment by subject matter experts in feature engineering.",
    "published_date": "2023-01-09",
    "pdf_link": "https://arxiv.org/pdf/2301.03532v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Malware/Botnet Detection",
      "specific_problem": "Lightweight detection of malicious IoT network traffic using raw byte streams without feature engineering",
      "attack_types": [
        "Botnet",
        "Hide and Seek",
        "Muhstik",
        "Linux.Hajime",
        "Okiru",
        "Mirai"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D-CNN",
        "novel_contribution": "Feature engineering-less pipeline (FEL-ML) that consumes raw byte streams from sessions/flows/packets for IoT malware detection using a compact 1D-CNN suitable for resource-constrained devices"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Aposemat IoT-23",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "USTC-TFC2016",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Stratosphere IPS Project Malware Dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ISCX VPN-nonVPN",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "QUIC dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Engineered features are increasingly ineffective due to encryption of headers and payloads in network traffic",
        "Attack-specific, feature-based models are brittle as attackers target multiple layers of network architecture",
        "Deep models and feature engineering steps are too computationally heavy for resource-constrained IoT devices",
        "Prior raw-byte approaches did not report memory/system metrics and often used deeper models (e.g., 1D-CNN + LSTM) that may overfit and be impractical for IoT"
      ],
      "limitations": [
        "Experiments use a subset (five) of the IoT-23 malicious scenarios due to very large pcap sizes, limiting coverage of all attack scenarios",
        "Full architecture details, system metrics, and deployment results are not provided in the available text",
        "No explicit quantitative comparison against traditional feature-based baselines is provided in the available text"
      ],
      "future_work": [],
      "motivation": "Enable practical, real-time IoT malware/botnet detection by eliminating feature engineering and using a lightweight 1D-CNN directly on raw byte streams to reduce computation and human expert effort while maintaining accuracy under encryption.",
      "potential_research_ideas": [
        "Extend FEL-ML to cover all IoT-23 scenarios and additional IoT malware corpora, including more botnet families and mixed-device environments",
        "Evaluate and improve adversarial robustness of byte-level models against evasion and poisoning attacks",
        "Incorporate on-device learning or federated learning to adapt to new attacks without sharing raw traffic",
        "Develop explainability methods for byte-level CNNs to highlight discriminative regions in packets/flows",
        "Benchmark end-to-end on real IoT hardware with energy, latency, and memory profiling to guide design",
        "Explore multi-task learning (e.g., jointly predict malware family and traffic characteristics) while keeping the model lightweight",
        "Investigate byte embeddings and sub-byte tokenization to capture structure without heavy preprocessing"
      ],
      "architectural_improvement_recommendations": [
        "Replace standard convolutions with depthwise-separable 1D convolutions to further reduce parameters and FLOPs",
        "Use dilated 1D convolutions and residual connections to capture longer context with minimal depth increase",
        "Apply quantization-aware training and post-training quantization for 8-bit deployment on microcontrollers",
        "Use knowledge distillation from a larger teacher to a compact student 1D-CNN",
        "Add lightweight attention (e.g., Squeeze-and-Excitation or channel attention) for improved feature selection",
        "Adopt streaming/causal convolutions and sliding-window inference for real-time processing of byte streams"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "IoT edge devices (e.g., smart appliances, routers, voice assistants)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Severe memory and processing constraints on IoT devices",
        "Need for real-time classification with minimal latency and energy",
        "Encrypted traffic limits feasibility of engineered features"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes Feature engineering-less ML (FEL-ML) that eliminates feature engineering and trains on raw byte streams of network traffic",
      "Designs a lightweight 1D-CNN architecture intended for resource-constrained IoT devices",
      "Evaluates three raw input representations (session, flow, packet) for binary and multi-label IoT botnet detection",
      "Targets faster inference and reduced memory usage compared to feature-based methods, enabling edge deployment",
      "Reduces reliance on domain experts and the human effort associated with feature engineering"
    ]
  },
  {
    "arxiv_id": "2301.00511v2",
    "title": "Asteria-Pro: Enhancing Deep-Learning Based Binary Code Similarity Detection by Incorporating Domain Knowledge",
    "authors": "Shouguo Yang; Chaopeng Dong; Yang Xiao; Yiran Cheng; Zhiqiang Shi; Zhi Li; Limin Sun",
    "abstract": "The widespread code reuse allows vulnerabilities to proliferate among a vast variety of firmware. There is an urgent need to detect these vulnerable code effectively and efficiently. By measuring code similarities, AI-based binary code similarity detection is applied to detecting vulnerable code at scale. Existing studies have proposed various function features to capture the commonality for similarity detection. Nevertheless, the significant code syntactic variability induced by the diversity of IoT hardware architectures diminishes the accuracy of binary code similarity detection. In our earlier study and the tool Asteria, we adopt a Tree-LSTM network to summarize function semantics as function commonality and the evaluation result indicates an advanced performance. However, it still has utility concerns due to excessive time costs and inadequate precision while searching for large-scale firmware bugs.   To this end, we propose a novel deep learning enhancement architecture by incorporating domain knowledge-based pre-filtration and re-ranking modules, and we develop a prototype based on Asteria called Asteria-Pro. Pre-filtration module seeks to eliminates dissimilar functions to boost subsequent deep learning model calculations, while re-ranking module aims to raises the rankings of vulnerable functions among candidates generated by deep learning model. Our evaluation indicates that pre-filtration module cuts the calculation time by 96.9% and re-ranking improves MRR and Recall by 23.71% and 36.4%. By incorporating the pre-filtration and re-ranking modules, Asteria-Pro outperforms existing state-of-the-art approaches in bug search task, by a significant large margin. We conduct a large-scale real-world firmware bug search and Asteria-Pro manages to detect 1,482 vulnerable functions with a high precision 91.65%.",
    "published_date": "2023-01-02",
    "pdf_link": "https://arxiv.org/pdf/2301.00511v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Vulnerability Discovery",
      "specific_problem": "Cross-architecture binary code similarity detection for large-scale firmware vulnerable function search",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Binary Tree-LSTM (Siamese)",
        "novel_contribution": "Core encoder from prior Asteria work retained; this paper's novelty is a domain knowledge-based pre-filtration and re-ranking architecture wrapped around the Tree-LSTM AST encoder to improve efficiency and retrieval precision."
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "Graph embedding network (Gemini)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph/Heuristic",
        "specific": "Graph isomorphism and statistical feature comparison (Diaphora)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Large-scale real-world firmware corpus (90 CVEs)",
        "type": "proprietary",
        "domain": "firmware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Asteria (Tree-LSTM AST encoder + call-graph calibration)",
        "paper_reference": "[71] (prior work referenced in paper)",
        "metric": "MRR, Recall@Top-1, runtime",
        "their_result": "“pre-filtration module cuts the calculation time by 96.9%, and the re-ranking module improves MRR and Recall by 23.71% and 36.4%, respectively… MRR to 90.8% and Recall@Top-1 to 89.6%.”",
        "baseline_result": null
      },
      {
        "method_name": "Gemini",
        "paper_reference": "[66]",
        "metric": "Bug search accuracy/efficiency",
        "their_result": "“Asteria-Pro outperforms existing state-of-the-art approaches in the bug search task by a significant margin.”",
        "baseline_result": null
      },
      {
        "method_name": "Diaphora",
        "paper_reference": null,
        "metric": "Bug search accuracy/efficiency",
        "their_result": "“Asteria-Pro outperforms existing state-of-the-art approaches in the bug search task by a significant margin.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "MRR (Mean Reciprocal Rank)",
      "Recall@Top-1",
      "Precision",
      "Average search time",
      "Runtime reduction/speedup"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "C1: How to filter out the majority of non-homologous functions before encoding ASTs, while retaining the homologous ones, to speed up vulnerability detection?",
        "C2: How to distinguish similar but non-homologous functions to reduce false positives after deep learning-based similarity detection?"
      ],
      "gaps_identified": [
        "Significant code syntactic variability across IoT architectures diminishes the accuracy of BCSD.",
        "Prior Asteria has excessive time costs (~1s per AST encode) and inadequate precision for large-scale bug search.",
        "Static analysis methods are scalable but often produce false positives due to lack of semantic information.",
        "Existing evaluations often do not align with real-world vulnerability retrieval scenarios."
      ],
      "limitations": [
        "Prior Asteria suffers from high false positives in real-world detection.",
        "Dynamic-analysis-based BCSD is not scalable for large-scale firmware due to device/emulation requirements (contextual limitation of alternative approaches)."
      ],
      "future_work": [],
      "motivation": "Improve both efficiency and precision of deep learning-based cross-architecture binary code similarity for large-scale firmware vulnerability search by injecting domain knowledge before and after the DL encoder.",
      "potential_research_ideas": [
        "Learn a supervised learning-to-rank re-ranker using features from AST, CFG, and call graphs, replacing heuristic re-ranking.",
        "Self-supervised, cross-architecture contrastive pretraining on AST/IR to reduce dependence on labeled homologous pairs.",
        "Multi-view heterogeneous graph model that jointly encodes AST, CFG, and call graphs for more robust semantics.",
        "Transformer-based tree encoders (Tree-Transformers) or code-pretrained models (e.g., CodeBERT-like) adapted to decompiled AST tokens.",
        "Robustness to decompiler variance by ensembling ASTs/IRs from multiple decompilers and training with view-invariant objectives.",
        "Active/online filtering: learn a lightweight classifier for pre-filtration instead of rule-based thresholds to maximize recall with minimal compute.",
        "Approximate nearest neighbor indexing and vector quantization to further accelerate retrieval while preserving recall.",
        "Inline- and intrinsic-aware augmentation that explicitly models compiler optimizations during training to improve matching of inlined code."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment Tree-LSTM with a tree-aware Transformer encoder to better capture long-range dependencies in ASTs.",
        "Joint encoding of AST with call-graph context via a hierarchical GNN to unify intra-function and inter-function semantics.",
        "Train a dedicated learning-to-rank head with hard negative mining for the re-ranking stage.",
        "Introduce cross-architecture contrastive objectives that align semantically equivalent nodes/subtrees across ISAs.",
        "Use multi-task learning to predict lightweight robust features used in pre-filtration, improving consistency between stages."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Prior Asteria AST encoding ~1 second per function; pre-filtration reported to reduce subsequent DL calculations by 96.9%."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Offline large-scale firmware analysis pipeline",
      "scalability_discussed": true,
      "inference_time": "Prior Asteria AST encoding about 1 second per function; Asteria-Pro reduces total search computations by 96.9% via pre-filtration.",
      "deployment_challenges": [
        "Cross-architecture variability in ISAs, calling conventions, and stack layouts.",
        "Decompilation quality impacts AST stability and downstream embedding.",
        "Compiler optimizations (inlining, intrinsics) affect similarity; though Asteria-Pro shows improved handling for inlined code.",
        "High false positives in purely static semantic methods without additional context."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduce domain knowledge-based pre-filtration to eliminate dissimilar functions before DL encoding, cutting detection time by 96.9%.",
      "Introduce domain knowledge-based re-ranking using call-relationship features to boost vulnerable functions in candidate lists, improving MRR by 23.71% and Recall@Top-1 by 36.4% (to 90.8% and 89.6%).",
      "Demonstrate that embedding pre-filtration and re-ranking also significantly improves baseline BCSD methods.",
      "Large-scale real-world firmware vulnerability search detecting 1,482 vulnerable functions with 91.65% precision.",
      "Empirical analysis showing AST is more stable than CFG across architectures for similarity representation."
    ]
  },
  {
    "arxiv_id": "2304.04819v2",
    "title": "Recent Advancements in Machine Learning For Cybercrime Prediction",
    "authors": "Lavanya Elluri; Varun Mandalapu; Piyush Vyas; Nirmalya Roy",
    "abstract": "Cybercrime is a growing threat to organizations and individuals worldwide, with criminals using sophisticated techniques to breach security systems and steal sensitive data. This paper aims to comprehensively survey the latest advancements in cybercrime prediction, highlighting the relevant research. For this purpose, we reviewed more than 150 research articles and discussed 50 most recent and appropriate ones. We start the review with some standard methods cybercriminals use and then focus on the latest machine and deep learning techniques, which detect anomalous behavior and identify potential threats. We also discuss transfer learning, which allows models trained on one dataset to be adapted for use on another dataset. We then focus on active and reinforcement learning as part of early-stage algorithmic research in cybercrime prediction. Finally, we discuss critical innovations, research gaps, and future research opportunities in Cybercrime prediction. This paper presents a holistic view of cutting-edge developments and publicly available datasets.",
    "published_date": "2023-04-10",
    "pdf_link": "https://arxiv.org/pdf/2304.04819v2",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Cyber Threat Detection",
      "subdomain": "Multiple (malware, phishing, intrusion/DDoS, social engineering, ransomware)",
      "specific_problem": "Survey of ML/DL/TL/AL/RL techniques and datasets for cybercrime prediction",
      "attack_types": [
        "Malware",
        "Phishing",
        "DDoS",
        "Social engineering",
        "Ransomware",
        "Intrusions"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting",
        "specific": "LightGBM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Naive Bayes",
        "specific": "Gaussian Naive Bayes",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "ANN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "NLP",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Knowledge-based System",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transfer Learning",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Active Learning",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Anomaly Detection",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Markov Models",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Transfer Learning",
      "Active Learning",
      "Reinforcement Learning"
    ],
    "datasets": [
      {
        "name": "Malware Classification Dataset (bytecode images)",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://github.com/AFAgarap/malware-classification/tree/master/dataset",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC VPN Non-VPN dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/vpn.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC TOR Non-TOR dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/tor.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Email corpus (monkey.org jose wiki)",
        "type": "public",
        "domain": "email_text",
        "link": "https://monkey.org/~jose/wiki/doku.php",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Fraudulent Email Corpus (Kaggle)",
        "type": "public",
        "domain": "email_text",
        "link": "https://www.kaggle.com/datasets/rtatman/fraudulent-email-corpus",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Enron Email Dataset",
        "type": "public",
        "domain": "email_text",
        "link": "https://www.cs.cmu.edu/~enron/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Microsoft Malware Classification Challenge (Kaggle)",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://www.kaggle.com/competitions/malware-classification/data",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MaleVis Malware Visualization Dataset",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://web.cs.hacettepe.edu.tr/~selman/malevis/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/nsl.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Honeynet Project data",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://www.honeynet.org/category/honeypot/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "DARPA 2000 IDS scenario-specific datasets",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.ll.mit.edu/r-d/datasets/2000-darpa-intrusion-detection-scenario-specific-datasets",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-IDS-2018",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/ids-2018.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://research.unsw.edu.au/projects/unsw-nb15-dataset",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Ransomware datasets list (GitHub Notes)",
        "type": "public",
        "domain": "text",
        "link": "https://github.com/PSJoshi/Notes/wiki/Datasets",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Phishing Detection Dataset (pdd repository)",
        "type": "public",
        "domain": "urls",
        "link": "https://github.com/ebubekirbbr/pdd/tree/master/input",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PhishLabs COVID-19 Threat Intelligence",
        "type": "public",
        "domain": "urls",
        "link": "https://www.phishlabs.com/covid-19-threat-intelligence/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Canadian Institute for Cybersecurity Datasets Index",
        "type": "public",
        "domain": "urls",
        "link": "https://www.unb.ca/cic/datasets/index.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Scammer.info (web crawl data)",
        "type": "public",
        "domain": "web_crawl_text",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "urlscan.io (web crawl data)",
        "type": "public",
        "domain": "web_crawl_text",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Phishing Website Dataset (Kaggle)",
        "type": "public",
        "domain": "urls",
        "link": "https://www.kaggle.com/datasets/akashkr/phishing-website-dataset",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "WSN-DS (Wireless Sensor Network Intrusion Dataset) 2016",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://sel.psu.edu.sa/Research/datasets/2016 WSN-DS.php.",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Kyoto 2006+ Dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": "http://www.takakura.com/Kyoto_data/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "DMD2018 (Malicious Domain Detection dataset)",
        "type": "public",
        "domain": "urls",
        "link": "https://nlp.amrita.edu/DMD2018/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Violent Views Detection Dataset (Urdu, Kaggle)",
        "type": "public",
        "domain": "text",
        "link": "https://www.kaggle.com/datasets/drkhurramshahzad/violent-views-detection-dataset-in-urdu",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CERNET2 websites (archived)",
        "type": "public",
        "domain": "urls",
        "link": "https://web.archive.org/web/20081219063350/http://www.cernet2.edu.cn/index_en.htm",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "5000best.com websites (legitimate URL list)",
        "type": "public",
        "domain": "urls",
        "link": "http://5000best.com/websites",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PhishTank",
        "type": "public",
        "domain": "urls",
        "link": "https://www.phishtank.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-IDS-2017",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/ids-2017.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Naive Bayes with NLTK",
        "paper_reference": "Kumari et al. (2018)",
        "metric": "Accuracy",
        "their_result": "77%",
        "baseline_result": null
      },
      {
        "method_name": "DT, RF, GBM, XGBoost, SVM (minimal-feature ML for COVID-19 domains)",
        "paper_reference": "Mvula et al. (2022)",
        "metric": "Accuracy",
        "their_result": "97.93%",
        "baseline_result": null
      },
      {
        "method_name": "Knowledge-based clustering method (CUC detection)",
        "paper_reference": "Shah et al. (2019)",
        "metric": "Accuracy; Sensitivity",
        "their_result": "Accuracy - 99%; Sensitivity - 90%",
        "baseline_result": null
      },
      {
        "method_name": "Naive Bayes and Random Forest (cyberbullying detection)",
        "paper_reference": "Balakrishnan et al. (2020)",
        "metric": "Accuracy",
        "their_result": "92%",
        "baseline_result": null
      },
      {
        "method_name": "LightGBM, RF, DT, LR, SVM (malicious URL classification)",
        "paper_reference": "Ahammad et al. (2022)",
        "metric": "Accuracy",
        "their_result": "86%",
        "baseline_result": null
      },
      {
        "method_name": "LightGBM (AI@TSS for technical support scam detection)",
        "paper_reference": "Chen et al. (2021)",
        "metric": "Accuracy; F1 Score",
        "their_result": "Accuracy - 98%; F1 Score - 97.95%",
        "baseline_result": null
      },
      {
        "method_name": "RF, SVM, Gaussian Naive Bayes",
        "paper_reference": "Wang et al. (2022)",
        "metric": "Accuracy",
        "their_result": "94.5%",
        "baseline_result": null
      },
      {
        "method_name": "DT, SVM, RF",
        "paper_reference": "Oh et al. (2020)",
        "metric": "Accuracy",
        "their_result": "95%",
        "baseline_result": null
      },
      {
        "method_name": "ANN and RF (phishing URL identification)",
        "paper_reference": "Mridha et al. (2021)",
        "metric": "Accuracy",
        "their_result": "99%",
        "baseline_result": null
      },
      {
        "method_name": "DT, NB, Sequential Minimal Optimization",
        "paper_reference": "Palad et al. (2019)",
        "metric": "Accuracy",
        "their_result": "79%",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1 Score",
      "Sensitivity"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What are the recent machine learning, deep learning, and transfer learning techniques used for cybercrime prediction?",
        "How are early-stage Active Learning and Reinforcement Learning being applied to cybercrime prediction?",
        "What publicly available datasets exist for cybercrime prediction tasks?",
        "Which algorithms and approaches have achieved notable performance across different cybercrime types?"
      ],
      "gaps_identified": [
        "Active Learning and Reinforcement Learning approaches for cybercrime prediction are at an early research stage.",
        "Traditional anti-phishing defenses (blocklists and heuristics) are insufficient against evolving threats.",
        "Social engineering attacks exploit human psychology, making them difficult to detect using standard security measures.",
        "Need for effective transfer learning to adapt models trained on one dataset/domain to another."
      ],
      "limitations": [
        "Scope limited to literature from 2018–2023 and 50 selected state-of-the-art papers.",
        "Focus on selected cyberattack methods to maintain scope, potentially omitting other emerging techniques.",
        "Search limited primarily to IEEE, ScienceDirect, and ACM digital libraries (though PRISMA used to mitigate bias).",
        "Survey article; no new experimental system or head-to-head benchmarking presented."
      ],
      "future_work": [
        "Further exploration of Active Learning and Reinforcement Learning in cybercrime prediction.",
        "Leveraging transfer learning to improve cross-dataset and cross-domain generalization.",
        "Curation and sharing of comprehensive, diverse, and up-to-date public datasets for new cybercrime modalities."
      ],
      "motivation": "Provide a holistic and systematic overview of cutting-edge ML/DL/TL techniques, datasets, and emerging AL/RL methods for predicting and preventing cybercrime, and to identify research gaps and opportunities.",
      "potential_research_ideas": [
        "Design a cross-domain transfer learning framework that adapts IDS/DDoS detectors across networks with minimal labeled data via domain adaptation and self-supervision.",
        "Develop an uncertainty-aware active learning loop for phishing and malicious URL detection that targets evasive samples and distribution shifts.",
        "Create a multimodal social engineering detection model combining NLP on content, behavioral interaction features, and contextual metadata.",
        "Build a graph-based threat infrastructure miner to detect phishing and TSS campaigns via URL-DNS-IP-host relationships using GNNs.",
        "Investigate robust training for URL/malware detectors using adversarial augmentation and realistic evasion strategies.",
        "Explore RL-driven adaptive defense policies (e.g., dynamic throttling, deception) for DDoS mitigation in SDN/cloud environments.",
        "Construct a privacy-preserving federated learning pipeline for cybercrime prediction across organizations without sharing raw telemetry."
      ],
      "architectural_improvement_recommendations": [
        "Apply transformer-based sequence models to URLs, logs, and packet sequences with pretraining on large-scale cyber telemetry.",
        "Use self-supervised representation learning and one-class classification for anomaly-based intrusion detection.",
        "Adopt meta-learning to quickly personalize detectors to new enterprises with few labels.",
        "Integrate Bayesian or ensemble uncertainty estimation to drive active learning and risk-aware decisions.",
        "Employ domain adversarial training or contrastive alignment for transfer across network environments.",
        "Harden models against evasion with adversarial training and feature-space smoothing."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Adversarial evasion tactics in malicious URL and web-based scams.",
        "Social engineering attacks leveraging human factors are difficult to detect reliably with automated systems."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Systematic literature review (PRISMA-guided) of ML/DL/TL techniques for cybercrime prediction (2018–2023).",
      "Survey of emerging Active Learning and Reinforcement Learning approaches in early-stage cybercrime prediction research.",
      "Curated list of publicly available cybercrime-related datasets spanning malware, network traffic/IDS, emails, and URLs.",
      "Taxonomy and discussion of key cybercrime methods (malware, phishing, DDoS, social engineering, ransomware).",
      "Consolidated summary of representative ML approaches and reported performance metrics across tasks."
    ]
  },
  {
    "arxiv_id": "2301.06031v1",
    "title": "A Review on the effectiveness of Dimensional Reduction with Computational Forensics: An Application on Malware Analysis",
    "authors": "Aye Thaw Da Naing; Justin Soh Beng Guan; Yarzar Shwe Win; Jonathan Pan",
    "abstract": "The Android operating system is pervasively adopted as the operating system platform of choice for smart devices. However, the strong adoption has also resulted in exponential growth in the number of Android based malicious software or malware. To deal with such cyber threats as part of cyber investigation and digital forensics, computational techniques in the form of machine learning algorithms are applied for such malware identification, detection and forensics analysis. However, such Computational Forensics modelling techniques are constrained the volume, velocity, variety and veracity of the malware landscape. This in turn would affect its identification and detection effectiveness. Such consequence would inherently induce the question of sustainability with such solution approach. One approach to optimise effectiveness is to apply dimensional reduction techniques like Principal Component Analysis with the intent to enhance algorithmic performance. In this paper, we evaluate the effectiveness of the application of Principle Component Analysis on Computational Forensics task of detecting Android based malware. We applied our research hypothesis to three different datasets with different machine learning algorithms. Our research result showed that the dimensionally reduced dataset would result in a measure of degradation in accuracy performance.",
    "published_date": "2023-01-15",
    "pdf_link": "https://arxiv.org/pdf/2301.06031v1",
    "paper_types": [
      "empirical_analysis",
      "reproducibility",
      "survey"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Android Malware Detection",
      "specific_problem": "Assessing the effectiveness of PCA-based dimensionality reduction for Android malware detection across multiple datasets and classifiers",
      "attack_types": [
        "Android malware",
        "Adware",
        "Ransomware",
        "Scareware",
        "SMS malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Dimensionality Reduction",
        "specific": "PCA (Principal Component Analysis)",
        "novel_contribution": "Systematic evaluation of PCA’s impact on Android malware detection across three datasets, multiple explained-variance thresholds (0.85–0.99), and multiple classifiers"
      },
      {
        "type": "primary",
        "category": "Imbalanced Learning / Resampling",
        "specific": "SMOTE",
        "novel_contribution": "Studied interaction effects of PCA with SMOTE; found PCA did not further improve accuracy over SMOTE on Malgenome"
      },
      {
        "type": "baseline",
        "category": "Ensemble/Forest",
        "specific": "FPA (Forest Penalizing Attribute)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "ADT (Alternating Decision Tree)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Rule-based",
        "specific": "Decision Table (DETAB)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Bayesian",
        "specific": "Naive Bayes (Multinomial, Kernel Estimator true in WEKA)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Bayesian",
        "specific": "Bayes Net (BN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "Decision Stump (DS)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Rule-based",
        "specific": "Conjunctive Rule (CR)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble",
        "specific": "AdaBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Instance-based",
        "specific": "k-NN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": "Decision Tree",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Model",
        "specific": "Logistic Regression",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Kernel Method",
        "specific": "SVM",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Malgenome (Android Malware Genome Project)",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Drebin",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-InvesAndMal2019",
        "type": "public",
        "domain": "app_static_features",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICAndMal2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICMalDroid2020",
        "type": "public",
        "domain": "dynamic_behavior",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "FPA (Forest Penalizing Attribute)",
        "paper_reference": "Akintola A.G. et al., 2022",
        "metric": "Accuracy",
        "their_result": "\"FPA performs the best among all the classifiers with highest accuracy at 0.9894.\" and \"...a 0.009 drop for FPA\" after PCA (variance=0.95)",
        "baseline_result": "Original (no-PCA) accuracy ~0.9894; after PCA accuracy decreased by 0.009 (absolute post-PCA value not explicitly given)"
      },
      {
        "method_name": "Decision Table (DETAB)",
        "paper_reference": "Akintola A.G. et al., 2022",
        "metric": "Accuracy, F1",
        "their_result": "\"The accuracy increased by 0.002 for DETAB\" at PCA 0.95; at PCA 0.85 \"DETAB accuracy and F-measure increased by 0.021 and 0.028\"",
        "baseline_result": "No-PCA baseline values not explicitly reported; paper notes +2% improvement over Akintola for DETAB accuracy in reproduction"
      },
      {
        "method_name": "ADT (Alternating Decision Tree)",
        "paper_reference": "Akintola A.G. et al., 2022",
        "metric": "Accuracy",
        "their_result": "\"a drop of 0.001 for ADT\" after PCA (0.95)",
        "baseline_result": "No-PCA baseline value not provided"
      },
      {
        "method_name": "Naive Bayes (NB)",
        "paper_reference": "Internal baseline (no-PCA) vs PCA",
        "metric": "Accuracy",
        "their_result": "\"When PCA with variance of 0.95 was applied, ... NB ... suffered a drop of 0.098\"; at 0.85, \"NB ... suffered a drop in accuracy of 0.099\"",
        "baseline_result": "No-PCA baseline value not provided"
      },
      {
        "method_name": "Bayes Net (BN)",
        "paper_reference": "Internal baseline (no-PCA) vs PCA",
        "metric": "Accuracy",
        "their_result": "\"When PCA with variance of 0.95 was applied, ... BN (Baye Net) suffered a drop of 0.038\"; at 0.85, \"BN suffered a drop ... of 0.022\"",
        "baseline_result": "No-PCA baseline value not provided"
      },
      {
        "method_name": "Decision Stump (DS)",
        "paper_reference": "Internal baseline (no-PCA) vs PCA",
        "metric": "Accuracy",
        "their_result": "\"DS ... improved 0.140\" with PCA (0.95)",
        "baseline_result": "No-PCA baseline value not provided"
      },
      {
        "method_name": "Conjunctive Rule (CR)",
        "paper_reference": "Internal baseline (no-PCA) vs PCA",
        "metric": "Accuracy",
        "their_result": "\"CR improved 0.145\" with PCA (0.95)",
        "baseline_result": "No-PCA baseline value not provided"
      },
      {
        "method_name": "SVM",
        "paper_reference": "Abdullah Talha Kabakus et al., 2018",
        "metric": "Accuracy, F1",
        "their_result": "\"For SVM, accuracy increased by 0.005 for Hold out and 0.003 for 10-fold. For F1-score, it increased by 0.008 and 0.003.\" (PCA vs no-PCA)",
        "baseline_result": "No-PCA baseline absolute scores not reported in text"
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": "Abdullah Talha Kabakus et al., 2018",
        "metric": "Accuracy, F1",
        "their_result": "\"For LR, accuracy increased by 0.021 for Hold out and 0.009 for 10-fold. For F1-score, it increased by 0.017 and 0.013.\" (PCA vs no-PCA)",
        "baseline_result": "No-PCA baseline absolute scores not reported in text"
      },
      {
        "method_name": "k-NN",
        "paper_reference": "Abdullah Talha Kabakus et al., 2018",
        "metric": "Accuracy, F1",
        "their_result": "\"the accuracy of k-NN in holdout increased by 0.003 while 10-Fold resulted in a drop by 0.01. The F1-score saw improvement ... by 0.004 while 10-Fold improved by 0.006.\" (PCA vs no-PCA)",
        "baseline_result": "No-PCA baseline absolute scores not reported in text"
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": "Abdullah Talha Kabakus et al., 2018",
        "metric": "Accuracy, F1",
        "their_result": "\"Decision Tree had accuracy improvement in Holdout by 0.004 and a decrease ... by 0.012 for 10-Fold. The F-measure also improved for Holdout by 0.04 but decreases by 0.012 in 10-Fold.\" (PCA vs no-PCA)",
        "baseline_result": "No-PCA baseline absolute scores not reported in text"
      },
      {
        "method_name": "Naive Bayes (Multinomial)",
        "paper_reference": "Abdullah Talha Kabakus et al., 2018",
        "metric": "Accuracy, F1, AUC",
        "their_result": "\"The result drops significantly for NB using the Multinomial model for F1-score by 0.414 and Accuracy by 0.289 for Holdout, 0.286 and 0.414 for 10-Fold.\" (PCA vs no-PCA)",
        "baseline_result": "No-PCA baseline absolute scores not reported in text"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1-score",
      "Precision",
      "Recall",
      "TPR",
      "FPR",
      "AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does PCA-based dimensionality reduction improve or degrade Android malware detection performance across multiple datasets and classifiers?",
        "How does the explained variance threshold in PCA (0.85–0.99) affect accuracy and F-measure for different algorithms?",
        "How does PCA interact with class imbalance handling (e.g., SMOTE) in Android malware detection pipelines?"
      ],
      "gaps_identified": [
        "“Most of these studies do not make direct reference to experimental results from other literature or to use different malware datasets to understand the benefits of PCA.”",
        "“However, the combination of Drebin and Malgenome dataset used in the research does not address to the issue of imbalance nature of both datasets.”",
        "“There is a need to investigate the impact of unbalance dataset on Android malware detection research.”",
        "“More studies are needed to investigate the effects of dimensionality reduction technique, feature selection techniques and balancing of datasets to improve on accuracy of malware detection…”"
      ],
      "limitations": [
        "Some cited works lacked parameter details; authors selected parameters “based on nearest metrics,” which may affect reproducibility comparability.",
        "Multinomial Naive Bayes performed poorly after PCA because PCA centering produces negative values, violating model assumptions."
      ],
      "future_work": [
        "“More studies are needed to investigate the effects of dimensionality reduction technique, feature selection techniques and balancing of datasets to improve on accuracy of malware detection.”",
        "Investigate the impact of dataset imbalance more thoroughly across Android malware datasets."
      ],
      "motivation": "Rapid growth of Android malware stresses computational forensics; dimensionality reduction (PCA) is explored to optimize effectiveness and sustainability amid volume, velocity, variety, and veracity constraints.",
      "potential_research_ideas": [
        "Evaluate supervised or class-aware dimensionality reduction (e.g., LDA, Neighborhood Components Analysis) versus PCA for Android malware.",
        "Compare PCA with non-linear methods (UMAP, t-SNE for analysis, kernel PCA) and representation learning (autoencoders) on the same datasets.",
        "Study cross-dataset generalization (train on Drebin, test on Malgenome/CIC-InvesAndMal2019) with and without dimensionality reduction.",
        "Integrate feature selection (Information Gain, mutual information, L1 regularization) before or after PCA to assess complementary benefits.",
        "Investigate NB-compatible transformations (e.g., Non-negative Matrix Factorization or PCA with post-processing to enforce non-negativity) to restore NB applicability.",
        "Systematically evaluate imbalance remedies (SMOTE variants, ADASYN, class-weighting, focal loss) in tandem with dimensionality reduction.",
        "Assess temporal robustness to malware evolution (concept drift) with streaming/online PCA and incremental learners.",
        "Explore explainability impacts of dimensionality reduction for forensics (mapping PCs back to permissions/APIs for analyst interpretation)."
      ],
      "architectural_improvement_recommendations": [
        "Use GaussianNB or ComplementNB instead of Multinomial NB after PCA; or enforce non-negativity via NMF if NB is required.",
        "Adopt a pipeline: scaling -> feature selection (IG) -> supervised DR (LDA) -> classifier; compare to PCA-only.",
        "Tune PCA components via nested cross-validation to optimize downstream metrics rather than fixed variance thresholds.",
        "Leverage tree-based models (Random Forest, XGBoost, LightGBM) that are robust to high-dimensional sparse features, possibly obviating PCA.",
        "Employ manifold learning or autoencoders for non-linear structure; pretrain with denoising objectives to reduce noise in static features.",
        "Use stratified CV with group-aware splits by family to prevent family leakage; report per-family performance.",
        "Augment with dynamic features (from sandboxes) and perform multimodal fusion; assess whether PCA helps in fused feature spaces."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "WEKA",
        "scikit-learn",
        "Python"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Static analysis can be evaded via code obfuscation.",
        "Dynamic analysis requires sandboxes and is resource/time intensive.",
        "High data volume/velocity/variety/veracity in malware landscape challenges sustained model performance.",
        "Class imbalance between benign and malware samples."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Empirical evaluation of PCA’s effect on Android malware detection across three datasets (Malgenome, Drebin, CIC-InvesAndMal2019) and multiple classifiers.",
      "Finding: “the dimensionally reduced dataset would result in a measure of degradation in accuracy performance,” with notable drops for Naive Bayes/BayesNet and gains for weak learners (Decision Stump, Conjunctive Rule).",
      "Explored PCA explained-variance thresholds (0.85–0.99) and observed minimal gains beyond 0.85 for most algorithms; detailed per-model deltas.",
      "Analyzed interaction with SMOTE; SMOTE improved performance broadly, but PCA did not further improve accuracy over SMOTE.",
      "Reproduced baselines from prior literature (Akintola 2022; Abdullah 2018) using WEKA and Python; documented parameter choices (e.g., NB kernel estimator true) and cross-validation settings.",
      "Identified practical incompatibility of Multinomial NB with PCA-transformed (centered, negative) features, leading to large performance drops."
    ]
  },
  {
    "arxiv_id": "2301.04872v2",
    "title": "Explainable Ponzi Schemes Detection on Ethereum",
    "authors": "Letterio Galletta; Fabio Pinelli",
    "abstract": "Blockchain technology has been successfully exploited for deploying new economic applications. However, it has started arousing the interest of malicious actors who deliver scams to deceive honest users and to gain economic advantages. Ponzi schemes are one of the most common scams. Here, we present a classifier for detecting smart Ponzi contracts on Ethereum, which can be used as the backbone for developing detection tools. First, we release a labelled data set with 4422 unique real-world smart contracts to address the problem of the unavailability of labelled data. Then, we show that our classifier outperforms the ones proposed in the literature when considering the AUC as a metric. Finally, we identify a small and effective set of features that ensures a good classification quality and investigate their impacts on the classification using eXplainable AI techniques.",
    "published_date": "2023-01-12",
    "pdf_link": "https://arxiv.org/pdf/2301.04872v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Security",
      "specific_problem": "Detection of Ponzi scheme smart contracts on Ethereum",
      "attack_types": [
        "Ponzi scheme",
        "Scam/Fraud"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Classical ML (unspecified)",
        "specific": null,
        "novel_contribution": "Binary classifier for detecting smart Ponzi contracts using an expanded feature set and XAI-guided feature reduction"
      },
      {
        "type": "primary",
        "category": "XAI",
        "specific": null,
        "novel_contribution": "Explainable AI analysis to quantify feature importance and impact; used to identify a small and effective feature set"
      },
      {
        "type": "baseline",
        "category": "Classical ML (unspecified)",
        "specific": "Chen et al.'s classifier",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "4422 Ethereum Smart Contracts Ponzi Detection Dataset",
        "type": "public",
        "domain": "smart_contracts + transaction_history",
        "link": "https://github.com/fpinell/ponzi_ml",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Bartoletti et al. smart Ponzi contracts (Ethereum)",
        "type": "public",
        "domain": "smart_contracts",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Chen et al. dataset of real-world smart contracts for Ponzi detection",
        "type": "public",
        "domain": "smart_contracts + transaction_history + bytecode",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SADPonzi-identified contracts",
        "type": "public",
        "domain": "smart_contracts + bytecode",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Chen et al. classifier",
        "paper_reference": "Chen et al. [6]",
        "metric": "AUC",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "AUC (ROC)",
      "Accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a supervised classifier detect smart Ponzi contracts on Ethereum with higher AUC than existing methods?",
        "Which features most effectively discriminate Ponzi vs. non-Ponzi contracts?",
        "Do newly introduced features (e.g., initiator receiving ETH, transaction ratios, temporal activity metrics) improve detection quality?",
        "How do individual features impact the classification outcome as assessed by XAI?"
      ],
      "gaps_identified": [
        "Unavailability of labeled datasets for training effective classifiers",
        "Difficulty in identifying redistribution behaviour from transactions due to similarity with other contract types (e.g., gambling), leading to potential false positives",
        "Lack of explainability analyses in prior Ponzi detection works"
      ],
      "limitations": [
        "The proposed classifier uses only transaction history features (does not analyze bytecode semantics)",
        "Class imbalance is not specifically addressed (authors note the algorithms used are not heavily affected)",
        "Evaluation details and exact comparative metrics against baselines are not fully specified in the provided text"
      ],
      "future_work": [],
      "motivation": "Protect users from blockchain scams by enabling automatic detection of Ponzi schemes and address the scarcity of labeled data; provide explainability to understand contributing factors.",
      "potential_research_ideas": [
        "Combine transaction-history features with bytecode semantic analysis (e.g., symbolic execution summaries) for hybrid models",
        "Leverage graph-based learning over investor–contract interaction graphs (e.g., GNNs) to capture redistribution dynamics",
        "Develop online/streaming detection for early-stage Ponzi identification using temporal models",
        "Cross-chain generalization: adapt and validate models on other EVM-compatible chains or Bitcoin-based schemes",
        "Robustness to evasion: study adversarial feature manipulation and design defenses",
        "Automated rule extraction from XAI explanations to assist auditors and reduce false positives on gambling-like contracts",
        "Active learning or weak supervision to expand labeled data with minimal manual effort"
      ],
      "architectural_improvement_recommendations": [
        "Evaluate and report specific tree-based ensembles (e.g., XGBoost/LightGBM) with calibrated probabilities and threshold optimization for imbalanced settings",
        "Augment features with money-flow motifs and sequence features (e.g., inter-arrival time statistics, HMM/Transformer encodings of transaction series)",
        "Integrate bytecode-derived semantic indicators (from symbolic execution or decompilation) as additional inputs",
        "Adopt SHAP-based global and local explanations with stability analysis to guide feature pruning and detect spurious correlations",
        "Incorporate cost-sensitive learning or focal loss to mitigate class imbalance without resampling",
        "Use nested cross-validation and rigorous model selection to ensure reproducibility and prevent overfitting"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/fpinell/ponzi_ml",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Potential false positives due to similarity of transaction patterns with non-fraud contracts (e.g., gambling)",
        "Scarcity and evolution of labeled data over time"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A reusable, publicly available dataset of 4422 real-world Ethereum smart contracts (3749 non-Ponzi, 673 Ponzi) with transaction history and bytecode metadata",
      "A binary classifier for smart Ponzi detection that outperforms prior work on AUC",
      "Introduction of new features and identification of a small, effective feature set for high-quality classification",
      "Explainable AI analysis to assess feature impact on classification"
    ]
  },
  {
    "arxiv_id": "2301.09201v2",
    "title": "SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis",
    "authors": "Imtiaz Karim; Kazi Samin Mubasshir; Mirza Masfiqur Rahman; Elisa Bertino",
    "abstract": "5G is the 5th generation cellular network protocol. It is the state-of-the-art global wireless standard that enables an advanced kind of network designed to connect virtually everyone and everything with increased speed and reduced latency. Therefore, its development, analysis, and security are critical. However, all approaches to the 5G protocol development and security analysis, e.g., property extraction, protocol summarization, and semantic analysis of the protocol specifications and implementations are completely manual. To reduce such manual effort, in this paper, we curate SPEC5G the first-ever public 5G dataset for NLP research. The dataset contains 3,547,586 sentences with 134M words, from 13094 cellular network specifications and 13 online websites. By leveraging large-scale pre-trained language models that have achieved state-of-the-art results on NLP tasks, we use this dataset for security-related text classification and summarization. Security-related text classification can be used to extract relevant security-related properties for protocol testing. On the other hand, summarization can help developers and practitioners understand the high level of the protocol, which is itself a daunting task. Our results show the value of our 5G-centric dataset in 5G protocol analysis automation. We believe that SPEC5G will enable a new research direction into automatic analyses for the 5G cellular network protocol and numerous related downstream tasks. Our data and code are publicly available.",
    "published_date": "2023-01-22",
    "pdf_link": "https://arxiv.org/pdf/2301.09201v2",
    "paper_types": [
      "new_dataset",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Protocol Security",
      "specific_problem": "Automating analysis of 5G cellular protocol specifications for security-related property extraction and protocol summarization",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT5G (BERT-base domain-adaptively pre-trained on SPEC5G)",
        "novel_contribution": "Domain-adaptive pretraining on 5G protocol corpora (SPEC5G), then fine-tuned for security text classification and summarization"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "RoBERTa5G (RoBERTa-base domain-adaptively pre-trained on SPEC5G)",
        "novel_contribution": "Domain-adaptive pretraining on SPEC5G"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "XLNet5G (XLNet-base domain-adaptively pre-trained on SPEC5G)",
        "novel_contribution": "Domain-adaptive pretraining on SPEC5G"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT-base",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "RoBERTa-base",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "XLNet-base",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BART-base",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "GPT-2 (small/medium/large)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "DistilGPT2",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "T5",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "ALBERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "CamemBERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Longformer",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "PEGASUS",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "mBART (large)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "DistilBERT",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised pretraining (language modeling)",
      "Supervised fine-tuning",
      "Transfer learning"
    ],
    "datasets": [
      {
        "name": "SPEC5G",
        "type": "public",
        "domain": "protocol_specifications_text",
        "link": "https://github.com/Imtiazkarimik23/SPEC5G",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "5GSum (summarization test set)",
        "type": "public",
        "domain": "protocol_specifications_text",
        "link": "https://github.com/Imtiazkarimik23/SPEC5G",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "5GSC (security sentence classification)",
        "type": "public",
        "domain": "protocol_specifications_text",
        "link": "https://github.com/Imtiazkarimik23/SPEC5G",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "3GPP specification corpora (source)",
        "type": "public",
        "domain": "protocol_specifications_text",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Web tutorials/blogs/forums (13 sources; scraped)",
        "type": "public",
        "domain": "protocol_specifications_text",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "BERT-base vs BERT5G",
        "paper_reference": null,
        "metric": "ROUGE-1/ROUGE-2/ROUGE-L (mid f-measure) on 5GSum",
        "their_result": "BERT5G: 0.543 / 0.382 / 0.472",
        "baseline_result": "BERT-base: 0.484 / 0.341 / 0.415"
      },
      {
        "method_name": "RoBERTa-base vs RoBERTa5G",
        "paper_reference": null,
        "metric": "ROUGE-1/ROUGE-2/ROUGE-L (mid f-measure) on 5GSum",
        "their_result": "RoBERTa5G: 0.540 / 0.379 / 0.469",
        "baseline_result": "RoBERTa-base: 0.489 / 0.341 / 0.418"
      },
      {
        "method_name": "XLNet-base vs XLNet5G",
        "paper_reference": null,
        "metric": "ROUGE-1/ROUGE-2/ROUGE-L (mid f-measure) on 5GSum",
        "their_result": "XLNet5G: 0.526 / 0.362 / 0.453",
        "baseline_result": "XLNet-base: 0.483 / 0.340 / 0.416"
      },
      {
        "method_name": "BERT5G vs GPT-2 (small)",
        "paper_reference": null,
        "metric": "ROUGE-1/ROUGE-2/ROUGE-L (mid f-measure) on 5GSum",
        "their_result": "BERT5G: 0.543 / 0.382 / 0.472",
        "baseline_result": "GPT-2: 0.488 / 0.340 / 0.418"
      },
      {
        "method_name": "BERT5G vs PEGASUS",
        "paper_reference": null,
        "metric": "ROUGE-1/ROUGE-2/ROUGE-L (mid f-measure) on 5GSum",
        "their_result": "BERT5G: 0.543 / 0.382 / 0.472",
        "baseline_result": "PEGASUS: 0.239 / 0.120 / 0.199"
      },
      {
        "method_name": "BERT5G vs BART-base",
        "paper_reference": null,
        "metric": "ROUGE-1/ROUGE-2/ROUGE-L (mid f-measure) on 5GSum",
        "their_result": "BERT5G: 0.543 / 0.382 / 0.472",
        "baseline_result": "BART-base: 0.357 / 0.231 / 0.311"
      },
      {
        "method_name": "BERT5G vs T5",
        "paper_reference": null,
        "metric": "ROUGE-1/ROUGE-2/ROUGE-L (mid f-measure) on 5GSum",
        "their_result": "BERT5G: 0.543 / 0.382 / 0.472",
        "baseline_result": "T5: 0.444 / 0.285 / 0.363"
      },
      {
        "method_name": "BERT5G vs GPT-2 (medium)",
        "paper_reference": null,
        "metric": "ROUGE-1/ROUGE-2/ROUGE-L (mid f-measure) on 5GSum",
        "their_result": "BERT5G: 0.543 / 0.382 / 0.472",
        "baseline_result": "GPT-2-medium: 0.481 / 0.333 / 0.408"
      },
      {
        "method_name": "BERT5G vs GPT-2 (large)",
        "paper_reference": null,
        "metric": "ROUGE-1/ROUGE-2/ROUGE-L (mid f-measure) on 5GSum",
        "their_result": "BERT5G: 0.543 / 0.382 / 0.472",
        "baseline_result": "GPT-2-large: 0.487 / 0.344 / 0.418"
      },
      {
        "method_name": "BERT5G vs DistilGPT2",
        "paper_reference": null,
        "metric": "ROUGE-1/ROUGE-2/ROUGE-L (mid f-measure) on 5GSum",
        "their_result": "BERT5G: 0.543 / 0.382 / 0.472",
        "baseline_result": "DistilGPT2: 0.483 / 0.333 / 0.412"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "ROUGE-1",
      "ROUGE-2",
      "ROUGE-L",
      "Human evaluation: Simplicity (1-5), Correctness (1-5), Contextuality (1-5)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can domain-adaptive pretraining on a large 5G specification corpus improve downstream performance on (a) protocol summarization and (b) security-related sentence classification?"
      ],
      "gaps_identified": [
        "Lack of high-quality, large, public datasets for 5G protocol NLP tasks",
        "Existing approaches for telecom protocol analysis are limited, ad-hoc, not generalizable, and often closed-source",
        "Security property extraction from specifications is a manual, expertise-heavy process",
        "5G specification documents are noisy (embedded code, tables, figures, cross-references), hindering automated NLP"
      ],
      "limitations": [],
      "future_work": [
        "Leverage SPEC5G for additional telecom-specific NLP tasks (e.g., semantic/temporal change analysis across releases)",
        "Automatic formal model extraction from natural language specifications",
        "Identification of conflicting or overlapping security guidelines",
        "Enable broader automatic analyses for the 5G cellular network protocol and related downstream tasks"
      ],
      "motivation": "Automate parts of 5G protocol analysis and security by providing a large, public, domain-specific corpus to train/evaluate NLP models, reducing manual effort in property extraction and understanding complex specifications.",
      "potential_research_ideas": [
        "Formal property and requirement extraction with sequence tagging and constrained decoding using SPEC5G, integrated with formal verification tools (e.g., TLA+/ProVerif)",
        "Cross-release change-impact and security regression analysis with temporal models trained on SPEC5G + 3GPP release metadata",
        "Retrieval-augmented generation (RAG) for question answering over 5G specs with citation grounding and section-level retrieval",
        "Hierarchical long-context summarization of entire specifications using Longformer/BigBird + pointer-generator heads",
        "Weak/active learning to scale security sentence labeling beyond 2.4k examples (self-training, data programming)",
        "Benchmarking instruction-tuned LLMs for telecom tasks with SPEC5G as domain pretraining followed by task-specific instruction tuning",
        "Graph-based modeling of inter-document references in 3GPP (GNN over spec cross-references) for consistency checking and property discovery",
        "Safety and robustness analysis: evaluate susceptibility of property extraction to prompt or text perturbations; adversarial training for robustness",
        "Multilingual adaptation (CamemBERT/mBERT) for non-English telecom resources and cross-lingual transfer",
        "Automatic test case generation from extracted properties and mapping to protocol simulators/emulators"
      ],
      "architectural_improvement_recommendations": [
        "Adopt long-sequence transformers (Longformer/BigBird) for full-section/context modeling of long 3GPP documents",
        "Use DeBERTa-v3 or ModernBERT as stronger backbones for domain-adaptive pretraining on SPEC5G",
        "RAG setup with FAISS/BM25 retrieval over SPEC5G and cross-encoder reranking for grounded summarization/QA",
        "Multi-task pretraining (MLM + sentence order prediction + contrastive objectives) tailored to spec structure (clauses, references)",
        "Hierarchical encoder-decoder for paragraph/section summarization with discourse-aware segmentation",
        "Sequence labeling (BIO) for fine-grained security property extraction with constrained decoding to ontology of property types",
        "Continual pretraining across 3GPP releases for change-aware models; adapter-based tuning for efficient updates",
        "Leverage instruction tuning and preference optimization with expert feedback for better simplification fidelity"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/Imtiazkarimik23/SPEC5G",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Pretraining and fine-tuning performed on Google Colab Pro+ with ~3000 compute units of Premium GPU (A100, high RAM)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Noisy structure of specifications (embedded code, tables, figures, cross-references) requires heavy preprocessing",
        "Specialized telecom jargon and long contexts challenge general NLP models",
        "Class imbalance and limited labeled data for security classification require careful sampling/annotation"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces SPEC5G: first public large-scale 5G protocol text dataset (3,547,587 sentences; 134M words) from 13,094 3GPP specifications and 13 web sources",
      "Releases two expert-annotated datasets: 5GSum (713 articles with summaries) and 5GSC (2,401 sentences labeled as Security/Non-Security/Undefined)",
      "Domain-adaptive pretraining of BERT, RoBERTa, and XLNet on SPEC5G (BERT5G, RoBERTa5G, XLNet5G) and evaluation on summarization and security classification",
      "Demonstrates that SPEC5G-pretrained models outperform general baselines on 5G summarization (higher ROUGE scores)",
      "Publishes all data and code to enable further research in automated 5G protocol analysis"
    ]
  },
  {
    "arxiv_id": "2301.01809v1",
    "title": "Significant Digits: Using Large-Scale Blockchain Data to Predict Fraudulent Addresses",
    "authors": "Jared Gridley; Oshani Seneviratne",
    "abstract": "Blockchain systems and cryptocurrencies have exploded in popularity over the past decade, and with this growing user base, the number of cryptocurrency scams has also surged. Given the graphical structure of blockchain networks and the abundance of data generated on these networks, we use graph mining techniques to extract essential information on transactions and apply Benford's Law to extract distributional information on address transactions. We then apply a gradient-boosting tree model to predict fraudulent addresses. Our results show that our method can detect scams with reasonable accuracy and that the features generated based on Benford's Law are the most significant features.",
    "published_date": "2023-01-03",
    "pdf_link": "https://arxiv.org/pdf/2301.01809v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Fraud/Scam Detection",
      "specific_problem": "Predicting fraudulent Ethereum addresses (including traditional and smart-contract-based Ponzi schemes and phishing-related scam addresses) from transaction data",
      "attack_types": [
        "Ponzi schemes",
        "Smart Ponzi schemes",
        "Phishing",
        "Rug pull"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Gradient Boosting Trees",
        "specific": "LightGBM",
        "novel_contribution": "Uses Benford's Law-derived features (Chi-Squared and KS fit to first/second-digit distributions) plus transaction graph statistics to classify scam vs non-scam Ethereum addresses"
      },
      {
        "type": "baseline",
        "category": "Linear Model",
        "specific": "Logistic Regression",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Boosting",
        "specific": "AdaBoost (with Decision Tree)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Authors' compiled Ethereum address dataset (1,676 addresses; ~2.6M transactions)",
        "type": "proprietary",
        "domain": "blockchain_transactions",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Amberdata Ethereum transaction API",
        "type": "proprietary",
        "domain": "blockchain_transactions",
        "link": "https://www.amberdata.io",
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "Etherscan label cloud and tagging system",
        "type": "public",
        "domain": "blockchain_labels",
        "link": "https://etherscan.io/labelcloud",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Xia et al. Uniswap scam tokens dataset",
        "type": "public",
        "domain": "blockchain_tokens",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Xia et al. multi-chain scam addresses and scam web domains dataset",
        "type": "public",
        "domain": "blockchain_labels",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Tomasz Nurkiewicz GitHub repo aggregating major crypto scams and addresses",
        "type": "public",
        "domain": "blockchain_labels",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ScamAlert (user-reported crypto scams)",
        "type": "public",
        "domain": "blockchain_labels",
        "link": "https://scam-alert.io",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "OpenSea verified addresses",
        "type": "public",
        "domain": "nft_marketplace_labels",
        "link": "https://opensea.io",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Axie Infinity verified addresses",
        "type": "public",
        "domain": "nft_game_labels",
        "link": "https://axieinfinity.com",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Support Vector Machine (SVM)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Decision Tree with AdaBoost",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "Chi-Squared goodness-of-fit",
      "Kolmogorov–Smirnov statistic"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "To what extent does Benford’s Law distinguish between fraudulent and legitimate users?",
        "How can Benford’s Law be used to build a more effective classifier for cryptocurrency Ponzi schemes?"
      ],
      "gaps_identified": [
        "No comprehensive, reliable, large-scale labeled scam address dataset exists; many sources rely on user reporting so many scams are likely not included.",
        "Scam categorization is hard because Ethereum transaction patterns vary widely (users, smart contracts, MEV bots, token contracts) and benign addresses can look irregular.",
        "Detecting use of obfuscation tools (mixers/tumblers) is complex; not all connected addresses are malicious.",
        "Phishing detection is difficult because much malicious activity happens off-chain (social engineering).",
        "Class imbalance in labeled data impairs some classifiers (e.g., LR, SVM)."
      ],
      "limitations": [
        "Did not include an explicit feature for detecting obfuscation tools due to complexity.",
        "Dataset labels aggregated from third-party sources (Etherscan, user reports) may be incomplete or noisy.",
        "Class imbalance led to poor performance for some methods (e.g., SVM, Logistic Regression).",
        "KS-test-based features were not significant in classifiers; Chi-Squared second-digit features dominated.",
        "Study limited to Ethereum addresses; may not generalize to all blockchains without adaptation."
      ],
      "future_work": [],
      "motivation": "Surging cryptocurrency adoption has been accompanied by increased scams; there is a need for automated, on-chain methods to flag potential scam addresses to protect users in decentralized finance ecosystems.",
      "potential_research_ideas": [
        "Construct and release a high-quality, multi-source, continuously updated labeled dataset of scam/non-scam blockchain addresses with provenance and confidence scores.",
        "Integrate temporal/sequential modeling of transactions (e.g., Temporal Graph Networks) to capture evolving scam behavior.",
        "Combine Benford-based features with graph neural networks (GNNs) that operate on transaction graphs to exploit structural patterns.",
        "Cross-chain and bridge-aware scam detection that unifies patterns across Ethereum and other chains using multi-chain data providers.",
        "Develop semi-supervised or positive–unlabeled (PU) learning to handle scarce/partial scam labels.",
        "Incorporate smart contract code analysis and bytecode features alongside transaction features for smart Ponzi detection.",
        "Fuse off-chain signals (web domains, social media, phishing takedowns) with on-chain features in a multimodal model.",
        "Adversarial training/evaluation against scammers who manipulate transaction amounts to mimic Benford distributions.",
        "Active learning pipelines with human-in-the-loop investigation to prioritize uncertain addresses for labeling.",
        "Model calibration and risk scoring for practical triage rather than hard labels."
      ],
      "architectural_improvement_recommendations": [
        "Augment LightGBM with a GNN encoder over the address-transaction graph; use node embeddings plus Benford features as inputs to a final classifier.",
        "Adopt temporal graph models (TGAT, TGN) to capture time-dependent behaviors; include time-decayed Benford fit metrics.",
        "Use cost-sensitive learning or focal loss and calibrated thresholding to mitigate class imbalance; include PU learning baselines.",
        "Feature engineering expansions: direction-aware and context-aware Benford metrics (incoming vs outgoing, per-counterparty, per-token), and higher-order digit/amount-binning features.",
        "Pipeline hardening: data deduplication, label provenance tracking, and automated drift detection; add SHAP-based explanations for analyst interpretability.",
        "Ensemble stacking (e.g., LightGBM + calibrated logistic layer) and hyperparameter optimization (Bayesian search)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "LightGBM"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Reliable ground truth labeling at scale is difficult; many scams are unreported or mislabeled.",
        "High diversity of benign behaviors (smart contracts, MEV bots, DeFi protocols) risks false positives.",
        "Off-chain phishing/social engineering not visible on-chain reduces detectability before loss.",
        "Handling class imbalance and distribution shift over time as scam tactics evolve.",
        "Complexity of detecting mixers/obfuscation flows limits feature coverage."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a scam-address classifier that combines transaction graph-derived statistics with Benford’s Law features (first/second-digit fits via Chi-Squared and KS).",
      "Demonstrates empirically that second-digit Benford features, especially Chi-Squared, are among the most significant predictors distinguishing scams from non-scams.",
      "Shows LightGBM outperforms Logistic Regression, Random Forest, SVM, and Decision Tree baselines on the compiled Ethereum dataset.",
      "Compiles a labeled dataset of 1,676 Ethereum addresses (~2.6M transactions) by aggregating multiple sources (Amberdata, Etherscan labels, prior works, and public repositories)."
    ]
  },
  {
    "arxiv_id": "2302.01215v1",
    "title": "Fixing Hardware Security Bugs with Large Language Models",
    "authors": "Baleegh Ahmad; Shailja Thakur; Benjamin Tan; Ramesh Karri; Hammond Pearce",
    "abstract": "Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's Codex have demonstrated capabilities in many coding-adjacent domains. In this work we consider how LLMs maybe leveraged to automatically repair security relevant bugs present in hardware designs. We focus on bug repair in code written in the Hardware Description Language Verilog. For this study we build a corpus of domain-representative hardware security bugs. We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs. The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM. We show that an ensemble of LLMs can repair all ten of our benchmarks. This ensemble outperforms the state-of-the-art Cirfix hardware bug repair tool on its own suite of bugs. These results show that LLMs can repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair framework.",
    "published_date": "2023-02-02",
    "pdf_link": "https://arxiv.org/pdf/2302.01215v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "RTL/HDL Security",
      "specific_problem": "Automated repair of security-relevant bugs in Verilog RTL designs using large language models",
      "attack_types": [
        "CWE-1234: Hardware Internal or Debug Modes Allow Override of Locks",
        "CWE-1271: Uninitialized Value on Reset for Registers Holding Security Settings",
        "CWE-1280: Access Control Check Implemented After Asset is Accessed",
        "CWE-1276: Hardware Child Block Incorrectly Connected to Parent System",
        "CWE-1245: Improper Finite State Machines (FSMs) in Hardware Logic"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM/Transformer",
        "specific": "OpenAI Codex",
        "novel_contribution": "Applied to automatically repair security-relevant bugs in Verilog; evaluated with prompt engineering and within an ensemble to maximize repair success"
      },
      {
        "type": "primary",
        "category": "LLM/Transformer",
        "specific": "CodeGen",
        "novel_contribution": "Used alongside Codex; explored parameter/prompt design and combined in an ensemble for bug repair"
      },
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": "Ensemble of LLMs (Codex + CodeGen)",
        "novel_contribution": "Ensemble strategy that \"can repair all ten of our benchmarks\" and \"outperforms the state-of-the-art Cirfix hardware bug repair tool on its own suite of bugs\""
      },
      {
        "type": "primary",
        "category": "Prompting/Prompt Engineering",
        "specific": null,
        "novel_contribution": "Design space exploration of prompts and LLM parameters for hardware bug repair; instructions-based prompting rather than template/mutation-driven repair"
      }
    ],
    "learning_paradigm": [
      "Prompt-based code generation",
      "Zero-shot/Instruction following",
      "One-shot generation (non-iterative)",
      "Ensemble inference"
    ],
    "datasets": [
      {
        "name": "Benchmark of 10 hardware security bugs in Verilog (this paper)",
        "type": "public",
        "domain": "hardware_hdl_verilog",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "MITRE CWE-inspired Verilog designs (subset of benchmark)",
        "type": "synthetic",
        "domain": "hardware_hdl_verilog",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "OpenTitan RTL modules with induced bugs (subset of benchmark)",
        "type": "public",
        "domain": "hardware_hdl_verilog",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Hack@DAC 2021 SoC RTL modules (subset of benchmark)",
        "type": "public",
        "domain": "hardware_hdl_verilog",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CirFix RTL repair benchmark suite (used for comparison)",
        "type": "public",
        "domain": "hardware_hdl_verilog",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CirFix",
        "paper_reference": "[6]",
        "metric": "Number of bugs repaired on CirFix benchmark suite",
        "their_result": "“This ensemble outperforms the state-of-the-art Cirfix hardware bug repair tool on its own suite of bugs.” Exact numbers not provided in excerpt.",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Number of bugs successfully repaired",
      "Pass/fail of security/static analysis checks for repaired designs",
      "Comparison against CirFix on CirFix benchmark suite"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "“very few techniques address the automated repair of hardware bugs.”",
        "Formal verification tools for security (e.g., Synopsys FSV) have “limited success.”",
        "Existing hardware repair (e.g., CirFix) focuses on functional bugs and requires an oracle; automated repair of security-relevant bugs is underexplored."
      ],
      "limitations": [],
      "future_work": [
        "“ultimate goal of an automated end-to-end bug repair framework.”"
      ],
      "motivation": "Hardware security bugs cannot be patched post-fabrication and hardware is often the root of trust; few tools exist to automatically repair security issues in RTL.",
      "potential_research_ideas": [
        "Integrate fault localization with LLM-based repair to achieve a fully automated end-to-end pipeline for security bug fixing in RTL.",
        "Create a large-scale, labeled dataset of (buggy, fixed) Verilog pairs covering diverse CWEs to enable fine-tuning and more robust evaluation.",
        "Apply retrieval-augmented generation that fetches hardware design patterns and security guidelines to condition LLM repairs.",
        "Use program-of-thought/self-reflection prompting where the model first explains the bug and then proposes a patch, improving reliability.",
        "Incorporate formal verification and equivalence checking loops (compile/simulate/verify) with RL-style feedback to iteratively refine patches.",
        "Extend beyond Verilog to SystemVerilog/VHDL and HLS code; study cross-language transfer and multi-lingual HDL repair.",
        "Combine static analysis for CWE detection with structure-aware patch generation using AST or control/data-flow constraints.",
        "Assess and harden against unsafe or security-degrading patches (e.g., hallucinated debug bypasses) via safety filters and rule-based guards.",
        "Benchmark against more real-world SoC codebases (e.g., RISC-V cores, peripherals) and add complex multi-module bugs requiring broader context.",
        "Study ensemble diversification strategies (different LLM families, decoding strategies, prompts) and automatic selection via patch validation signals."
      ],
      "architectural_improvement_recommendations": [
        "Adopt Verilog-aware tokenization and AST-constrained decoding to reduce syntactic and semantic errors in generated patches.",
        "Use multi-stage agents (localize -> reason -> patch -> verify) with self-consistency and majority voting across prompts/decoders.",
        "Integrate a compile/simulate/formal verification loop that scores patches; apply best-of-N and reinforcement learning from verification feedback.",
        "Add retrieval-augmented context (e.g., similar modules, secure coding patterns, CWE fix templates) to guide generation.",
        "Implement structured prompts with explicit pre/post-conditions and security properties to enforce correct patch semantics."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Curated and open-sourced a benchmark of hardware security bugs and corresponding Verilog designs (“These are open-sourced at [41].”).",
      "Designed and implemented an automated framework to use LLMs for generating repairs and evaluating them; artifacts made available [41].",
      "Built an automated end-to-end solution to detect, repair, and evaluate certain bugs using static analysis scanners from prior work [5].",
      "Explored different LLMs (OpenAI Codex, CodeGen), prompt engineering, and parameter settings; posed research questions and best practices.",
      "Demonstrated that an ensemble of LLMs can repair all 10 benchmarks and that this ensemble outperforms CirFix on its own suite of bugs."
    ]
  },
  {
    "arxiv_id": "2301.00328v1",
    "title": "Internet of Things: Digital Footprints Carry A Device Identity",
    "authors": "Rajarshi Roy Chowdhury; Azam Che Idris; Pg Emeroylariffion Abas",
    "abstract": "The usage of technologically advanced devices has seen a boom in many domains, including education, automation, and healthcare; with most of the services requiring Internet connectivity. To secure a network, device identification plays key role. In this paper, a device fingerprinting (DFP) model, which is able to distinguish between Internet of Things (IoT) and non-IoT devices, as well as uniquely identify individual devices, has been proposed. Four statistical features have been extracted from the consecutive five device-originated packets, to generate individual device fingerprints. The method has been evaluated using the Random Forest (RF) classifier and different datasets. Experimental results have shown that the proposed method achieves up to 99.8% accuracy in distinguishing between IoT and non-IoT devices and over 97.6% in classifying individual devices. These signify that the proposed method is useful in assisting operators in making their networks more secure and robust to security breaches and unauthorized access.",
    "published_date": "2023-01-01",
    "pdf_link": "https://arxiv.org/pdf/2301.00328v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Device Fingerprinting / Device Identification",
      "specific_problem": "Passive identification of IoT vs non-IoT devices and unique per-device classification from short-window packet statistics",
      "attack_types": [
        "Spoofing",
        "Unauthorized access"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Random Forest",
        "specific": "Random Forest (Weka; 100 trees, seed=1, batch size=100)",
        "novel_contribution": "Novelty lies in the fingerprint design: four statistical features (mean and std of tcp.window_size and ip.len over 5 consecutive device-originated packets). RF is used to evaluate the method."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "UNSW IoT and Non-IoT network traffic traces (Sivanathan et al.)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Lab Non-IoT dataset (UBD laboratory testbed)",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Packet-level and IEEE 802.11 MAC frame-level Network Traffic Traces Data of the D-Link IoT devices (Data in Brief, 2021)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Sivanathan et al. (2019) hourly statistical fingerprints",
        "paper_reference": "A. Sivanathan et al., IEEE TMC 2019",
        "metric": "Accuracy (per-IoT-device classification on UNSW)",
        "their_result": "97.6%+ for most IoT devices (this paper; U-IoT)",
        "baseline_result": "Over 99% accuracy using the UNSW dataset"
      },
      {
        "method_name": "Sivanathan et al. (2017) daily traffic characteristics (11 features)",
        "paper_reference": "A. Sivanathan et al., INFOCOM Workshops 2017",
        "metric": "Accuracy (IoT vs non-IoT; IoT device identification)",
        "their_result": "99.8% (IoT vs non-IoT on UNSW); 97.6%+ (per IoT device, most devices)",
        "baseline_result": "High accuracy for IoT vs non-IoT; over 95% accuracy in identifying individual IoT devices"
      },
      {
        "method_name": "Bezawada et al. (2018) 5-packet protocol header+payload features (20 features)",
        "paper_reference": "Bezawada et al., ASHES 2018",
        "metric": "Mean identification accuracy (per IoT device)",
        "their_result": "97.6%+ (per IoT device, most devices; this paper)",
        "baseline_result": "93%–100% (lab dataset of 14 IoT devices)"
      },
      {
        "method_name": "Aksoy and Gunes (2019) SysID (single-packet features)",
        "paper_reference": "Aksoy and Gunes, ICC 2019",
        "metric": "Average classification accuracy (smart home IoT device identification)",
        "their_result": "97.6%+ (per IoT device, most devices; this paper)",
        "baseline_result": "82% average classification accuracy"
      },
      {
        "method_name": "Pinheiro et al. (2019) packet length statistics (1s window)",
        "paper_reference": "Pinheiro et al., Computer Communications 2019",
        "metric": "Accuracy (IoT vs non-IoT; multi-class per-IoT-device)",
        "their_result": "99.8% (IoT vs non-IoT on UNSW); 97.6%+ (per IoT device, most devices)",
        "baseline_result": "99% (IoT vs non-IoT); about 96% (per-IoT-device)"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "RMSE"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Existing DFP models often require a large number of features and/or long packet sequences to construct fingerprints, leading to higher computational complexity and longer processing time.",
        "Need for an efficient DFP approach that uses minimal features and short windows while maintaining high accuracy for both IoT vs non-IoT categorization and per-device identification."
      ],
      "limitations": [
        "Per-device classification accuracy can drop when training data is scarce for a device (e.g., BlipcareBPmeter ~75% due to limited instances)."
      ],
      "future_work": [],
      "motivation": "Rapid growth of heterogeneous IoT and non-IoT devices makes securing networks challenging. Conventional identifiers (IP, MAC) are vulnerable to spoofing and mobility; passive device fingerprinting from traffic traces can enable robust device identification for security enforcement.",
      "potential_research_ideas": [
        "Open-set and zero-shot device identification to detect and handle previously unseen device types and models.",
        "Few-shot and class-imbalance methods to improve per-device accuracy when only a small number of instances are available (e.g., meta-learning, prototypical networks on traffic features).",
        "Domain adaptation and cross-network generalization to ensure robustness across different networks, OS updates, and firmware versions.",
        "Adversarial robustness studies for device fingerprinting (evasion via traffic shaping, TCP window manipulation) and corresponding defenses.",
        "Online/streaming DFP with sliding windows for real-time identification and rapid on-boarding of new devices.",
        "Multi-modal fusion of short-window statistics with periodic/behavioral features (e.g., DNS/NTP timings) to improve hard cases without large overhead.",
        "Explainable fingerprinting to attribute which features/time-windows drive decisions, aiding operator trust and triage.",
        "Privacy-preserving DFP via federated learning or feature aggregation that limits exposure of raw packet traces."
      ],
      "architectural_improvement_recommendations": [
        "Augment the 4-feature fingerprint with inter-arrival time statistics and directionality (uplink/downlink) computed over the same 5-packet window to improve separability with minimal overhead.",
        "Evaluate stronger tree ensembles (XGBoost/LightGBM) and calibrated probability outputs; perform hyperparameter optimization (e.g., Bayesian search).",
        "Implement open-set recognition using thresholded softmax or distance-based rejection to flag unknown devices.",
        "Use class-balanced losses or focal loss proxies by reweighting or resampling during training to mitigate class imbalance for low-instance devices.",
        "Adopt an online learning pipeline with sliding windows and incremental model updates for real-time deployment.",
        "Combine short-window features with sparse longer-horizon behavioral summaries (e.g., per-hour DNS rates) in a two-head model to retain efficiency while boosting accuracy on difficult devices."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Weka"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires extraction of device-originated traffic by MAC address to build fingerprints.",
        "Accuracy degrades for devices with very limited training instances."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a device fingerprinting model using only four statistical features computed from five consecutive device-originated packets (means and standard deviations of tcp.window_size and ip.len).",
      "Constructs a laboratory testbed and collects a non-IoT traffic dataset from 7 devices for evaluation.",
      "Evaluates the approach with a Random Forest classifier on the UNSW dataset and the lab dataset, achieving up to 99.8% accuracy for IoT vs non-IoT classification and over 97.6% for per-device identification."
    ]
  },
  {
    "arxiv_id": "2301.02505v4",
    "title": "Nested Dirichlet models for unsupervised attack pattern detection in honeypot data",
    "authors": "Francesco Sanna Passino; Anastasia Mantziou; Daniyar Ghani; Philip Thiede; Ross Bevington; Nicholas A. Heard",
    "abstract": "Cyber-systems are under near-constant threat from intrusion attempts. Attacks types vary, but each attempt typically has a specific underlying intent, and the perpetrators are typically groups of individuals with similar objectives. Clustering attacks appearing to share a common intent is very valuable to threat-hunting experts. This article explores Dirichlet distribution topic models for clustering terminal session commands collected from honeypots, which are special network hosts designed to entice malicious attackers. The main practical implications of clustering the sessions are two-fold: finding similar groups of attacks, and identifying outliers. A range of statistical models are considered, adapted to the structures of command-line syntax. In particular, concepts of primary and secondary topics, and then session-level and command-level topics, are introduced into the models to improve interpretability. The proposed methods are further extended in a Bayesian nonparametric fashion to allow unboundedness in the vocabulary size and the number of latent intents. The methods are shown to discover an unusual MIRAI variant which attempts to take over existing cryptocurrency coin-mining infrastructure, not detected by traditional topic-modelling approaches.",
    "published_date": "2023-01-06",
    "pdf_link": "https://arxiv.org/pdf/2301.02505v4",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Honeypot Analysis / Intrusion Detection",
      "specific_problem": "Unsupervised clustering of honeypot terminal sessions (command logs) to detect latent attacker intents, find similar attack groups, and identify outliers",
      "attack_types": [
        "Mirai botnet (variant detection)",
        "cryptojacking / cryptocurrency mining",
        "ransomware (as a representative attacker objective)",
        "data exfiltration (as a representative attacker objective)",
        "infrastructure takeover (as a representative attacker objective)",
        "malware deployment"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Topic Model",
        "specific": "Constrained Bayesian Clustering (single topic per session) with a shared global secondary topic",
        "novel_contribution": "Assigns a single primary topic (intent) per session plus a shared secondary topic to absorb high-frequency/common terms, improving interpretability over LDA"
      },
      {
        "type": "primary",
        "category": "Topic Model",
        "specific": "Nested constrained Bayesian clustering with session-level and command-level topics",
        "novel_contribution": "Introduces two-level topics: session-level intent distributions over command-level intents, enabling joint inference of session and command structure"
      },
      {
        "type": "primary",
        "category": "Bayesian Nonparametrics",
        "specific": "GEM stick-breaking priors for unbounded topics and vocabulary",
        "novel_contribution": "Allows an unbounded number of latent intents and growing vocabulary without specifying command-line syntax priors"
      },
      {
        "type": "primary",
        "category": "Probabilistic Generative Model",
        "specific": "Dirichlet–Categorical (Dirichlet–Multinomial) conjugate modeling of word distributions",
        "novel_contribution": "Cyber-adapted tokenization/command modeling within a constrained topic-modeling framework"
      },
      {
        "type": "baseline",
        "category": "Topic Model",
        "specific": "LDA (Latent Dirichlet Allocation)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Bayesian"
    ],
    "datasets": [
      {
        "name": "Real-world honeypot terminal session data",
        "type": "proprietary",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Simulated sessions (Supplementary Material)",
        "type": "synthetic",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "LDA (Latent Dirichlet Allocation)",
        "paper_reference": "Blei, Ng and Jordan, 2003",
        "metric": null,
        "their_result": "“The methods are shown to discover an unusual MIRAI variant which attempts to take over existing cryptocurrency coin-mining infrastructure, not detected by traditional topic-modelling approaches.”",
        "baseline_result": "Traditional topic-modelling approaches (e.g., LDA) did not detect the unusual MIRAI variant"
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can we cluster honeypot terminal sessions into latent intents when each session typically has a single primary objective?",
        "How can topic models be adapted to command-line data with session- and command-level structure to improve interpretability for threat hunters?",
        "How can we handle evolving attacks with unbounded numbers of latent intents and growing vocabularies in a principled Bayesian manner?",
        "Can a shared secondary topic capture high-frequency/common terms to yield cleaner, more interpretable primary topics?"
      ],
      "gaps_identified": [
        "Drawbacks of LDA for command lines: “(i) attackers usually have mainly one intent per session; (ii) ... analysts ... would typically prefer to have one label per session ...; (iii) models based on LDA often present unidentifiability and convergence difficulties, making reproducibility of results problematic.”",
        "High-frequency/common words degrade interpretability; removal requires repeated retraining and tuning of pruning thresholds",
        "Standard topic models ignore sentence/command-level structure within sessions",
        "Need for unbounded numbers of topics and vocabulary for practical deployment in cybersecurity settings",
        "Perplexity-based model selection may not yield interpretable topics"
      ],
      "limitations": [
        "“It is not expected to always recover the exact number in the data generating process.” (component number estimation can be inconsistent under misspecification)",
        "Reliance on tokenization decisions for command-line data (URLs, IPs, file extensions) can affect modeling",
        "Nonparametric priors require hyperparameter choices (e.g., concentration) that influence inferred component counts"
      ],
      "future_work": [
        "Account for potential power-law word counts using two-parameter GEM (Pitman–Yor) priors if observed in command-line data",
        "Automated online classification of intrusions leveraging the proposed clustering for near-real-time operations"
      ],
      "motivation": "Provide interpretable, session-level clustering of honeypot command sessions to help threat-hunters discover groups of similar attacks and outliers, while accommodating evolving intents and vocabularies.",
      "potential_research_ideas": [
        "Develop an online/streaming inference algorithm (e.g., stochastic variational inference) for the nested constrained model to support real-time honeypot monitoring",
        "Incorporate sequence information within commands and across commands (e.g., HDP-HMM or Markovian extensions) to capture temporal attack patterns",
        "Semi-supervised variant leveraging occasional analyst labels or MITRE ATT&CK mappings to anchor topics and improve interpretability",
        "Robust tokenization and adversarially-resilient preprocessing (e.g., URL/IP canonicalization, decoding obfuscations) integrated into the generative model",
        "Cross-honeypot/domain adaptation to transfer discovered intents across different environments/vendors",
        "Joint modeling of command content with metadata (e.g., IP/subnet, geolocation, time, authentication method) via hierarchical priors to improve clustering",
        "Embed word/command representations (e.g., Gaussian LDA with embeddings) while keeping single-label-per-session constraints for interpretability",
        "Active-learning loop to solicit minimal analyst feedback on ambiguous clusters for refinement"
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment GEM with Pitman–Yor (two-parameter GEM) priors to better capture power-law token distributions if present",
        "Introduce Markovian structure over command-level topics within sessions (e.g., HDP-HMM) to leverage command order",
        "Use stochastic variational inference for scalable approximate posterior inference on high-volume streams",
        "Apply posterior regularization or sparsity-inducing priors to further disentangle shared secondary topic from primary intent terms",
        "Model multi-view signals (content + metadata) with hierarchical sharing and structured priors for improved clustering fidelity",
        "Incorporate grammar- or schema-aware priors (e.g., simple shell grammar constraints) to reduce invalid token associations"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Honeypot infrastructure within enterprise networks",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High traffic volumes through honeypots require efficient/online inference",
        "Tokenization choices for URLs/IPs/file extensions materially affect downstream clustering",
        "Evolving vocabulary and emergence of new intents necessitate nonparametric handling",
        "Need for highly interpretable single-label outputs for analysts",
        "Model selection/hyperparameter tuning for nonparametric priors in operational settings"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Constrained Bayesian clustering (CBC) assigning a single primary topic per session plus a global shared secondary topic to capture high-frequency/common terms",
      "Nested constrained model introducing session-level topics as distributions over command-level topics for joint session- and command-level structure",
      "Bayesian nonparametric extensions using GEM stick-breaking priors to allow unbounded numbers of latent intents and vocabulary",
      "Cyber-specific tokenization and modeling considerations for command-line data",
      "Demonstration that the methods discover an unusual MIRAI variant targeting cryptocurrency mining infrastructure, which traditional topic models did not detect"
    ]
  }
]