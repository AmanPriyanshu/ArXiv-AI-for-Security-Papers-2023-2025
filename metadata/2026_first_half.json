[
  {
    "arxiv_id": "2601.17907v1",
    "title": "FARM: Few-shot Adaptive Malware Family Classification under Concept Drift",
    "authors": "Numan Halit Guldemir; Oluwafemi Olukoya; Jesús Martínez-del-Rincón",
    "abstract": "Malware classification models often face performance degradation due to concept drift, arising from evolving threat landscapes and the emergence of novel malware families. This paper presents FARM (Few-shot Adaptive Recognition of Malware), a framework designed to detect and adapt to both covariate and label drift in Windows Portable Executable (PE) malware classification. FARM leverages a triplet autoencoder to project samples into a discriminative latent space, enabling unsupervised drift detection via DBSCAN clustering and dynamic thresholding. For rapid adaptation, it employs few-shot learning using prototype-based classification, requiring only a handful of labeled samples. FARM also supports full retraining when enough drifted samples accumulate, updating the latent space for long-term integration. Experiments on the BenchMFC dataset demonstrate that FARM improves classification performance under covariate drift by 5.6\\%, and achieves an average F1 score of 0.85 on unseen malware families using only few-shot adaptation, which further increases to 0.94 after retraining. These results highlight FARM's robustness and adaptability in dynamic malware detection environments under limited supervision.",
    "published_date": "2026-01-25",
    "pdf_link": "https://arxiv.org/pdf/2601.17907v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Windows PE Malware Classification",
      "specific_problem": "Few-shot adaptive malware family classification under concept drift (covariate and label drift) with unsupervised drift detection and rapid adaptation",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Autoencoder + Metric Learning (Triplet Network)",
        "specific": "Triplet Autoencoder",
        "novel_contribution": "Uses a triplet-trained autoencoder to learn a discriminative latent space for Windows PE malware; distances to cluster centroids with dynamic thresholds enable drift detection."
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "DBSCAN with dynamic thresholding",
        "novel_contribution": "Unsupervised clustering in the learned embedding space; per-cluster centroid and max intra-cluster distance define dynamic acceptance thresholds for drift detection."
      },
      {
        "type": "primary",
        "category": "Metric-based Few-shot Learning",
        "specific": "Prototype-based classification (Prototypical Networks-style inference)",
        "novel_contribution": "Few-shot adaptation by forming class prototypes from a handful of labeled drifted samples; integrated with buffering and delayed retraining."
      },
      {
        "type": "baseline",
        "category": "Distance-based Classifier",
        "specific": null,
        "novel_contribution": "Used as the decision mechanism in latent space (nearest centroid/prototype using Euclidean distance)."
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Few-shot"
    ],
    "datasets": [
      {
        "name": "BenchMFC",
        "type": "public",
        "domain": "malware_binaries (Windows PE)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "EMBER features",
        "type": "public",
        "domain": "static_features (Windows PE)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Malware classifiers degrade significantly over time due to concept drift (model aging/time decay).",
        "Softmax-based classifiers remain overconfident on unseen samples, making novelty/drift detection via probabilities unreliable.",
        "Choosing retraining frequency is difficult: too frequent yields insufficient data; too infrequent misses important shifts.",
        "Labeling is expensive, slow, and noisy (vendor/human inconsistency).",
        "Most prior drift work targets Android; limited comprehensive drift detection+adaptation frameworks for Windows PE malware.",
        "Existing drift methods often detect drift but lack rapid few-shot adaptability or fine-grained class modeling."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Enable robust Windows PE malware family classification in evolving threat landscapes by detecting covariate and label drift and adapting with minimal labeled data.",
      "potential_research_ideas": [
        "Integrate dynamic (behavioral) features or hybrid static+dynamic representations to improve drift sensitivity and generalization.",
        "Explore self-supervised or contrastive pretraining on large unlabeled PE corpora to strengthen the embedding space for unseen families.",
        "Replace or complement DBSCAN with HDBSCAN or density-ratio/online clustering for better handling of varying densities and streaming data.",
        "Incorporate active learning to prioritize labeling of most-informative drifted clusters and reduce annotation cost/noise.",
        "Use calibrated uncertainty/OOD methods (e.g., energy-based scores, Mahalanobis distance) to complement thresholding for drift detection.",
        "Develop online continual learning that incrementally updates prototypes and embeddings without catastrophic forgetting.",
        "Add label-noise robust training and prototype refinement to handle inconsistent vendor labels.",
        "Leverage graph-based PE representations or GNNs over import/function relations to capture structural invariants under drift."
      ],
      "architectural_improvement_recommendations": [
        "Pretrain encoder with supervised contrastive or self-supervised objectives before triplet+MSE fine-tuning to improve latent separability.",
        "Adopt HDBSCAN with cluster stability selection and automatic threshold calibration to reduce sensitivity to epsilon/minPts.",
        "Use metric learning with class-conditional covariance (e.g., Mahalanobis metric or ProtoNets with learnable covariance) for anisotropic clusters.",
        "Introduce uncertainty calibration (temperature scaling, Dirichlet prior networks) to reduce overconfidence near thresholds.",
        "Implement rehearsal-based continual learning and prototype maintenance (merging/splitting, aging) to handle long-term evolution.",
        "Augment static EMBER features with learned byte-level or section-level CNN/Transformer embeddings for richer representations."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Need for periodic labeling of drifted clusters to form reliable prototypes.",
        "Threshold/DBSCAN parameter tuning may be environment-specific.",
        "Accumulating sufficient drifted samples for retraining while maintaining service quality.",
        "Potential label noise and inconsistency across sources."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes FARM: an integrated framework for drift detection and adaptation tailored to Windows PE malware.",
      "Triplet autoencoder to learn a discriminative latent space enabling distance-based novelty/drift detection.",
      "Unsupervised drift detection via DBSCAN clustering with dynamic per-cluster thresholds.",
      "Rapid few-shot adaptation using prototype-based classification requiring only a handful of labeled samples.",
      "Long-term integration via full retraining once sufficient drifted samples accumulate.",
      "Validation on a timestamped malware dataset (BenchMFC), with reported gains under covariate drift (+5.6% performance) and F1=0.85 on unseen families via few-shot, improving to F1=0.94 after retraining."
    ]
  },
  {
    "arxiv_id": "2601.17355v1",
    "title": "Safeguard: Security Controls at the Software Defined Network Layer",
    "authors": "Yi Lyu; Shichun Yu; Joe Catudal",
    "abstract": "Improvements in software defined networking allow for policy to be informed and modified by data-driven applications that can adjust policy to accommodate fluctuating requirements at line speed. However, there is some concern that over-correction can occur and cause unintended consequences depending on the data received. This is particularly problematic for network security features, such as machine-learning intrusion detection systems. We present Safeguard, a rule-based policy that overlaps a data-driven policy to prevent unintended responses for edge cases in network traffic. We develop a reference implementation of a network traffic classifier that enforces firewall rules for malicious traffic, and show how additional rulesets to allow known-good traffic are essential in utilizing a data-driven network policy.",
    "published_date": "2026-01-24",
    "pdf_link": "https://arxiv.org/pdf/2601.17355v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Software-Defined Networking (SDN) Security",
      "specific_problem": "Preventing over-correction and unintended blocking by data-driven (ML/analytics) intrusion detection policies via rule-based safeguards in SDN controllers",
      "attack_types": [
        "DoS",
        "DDoS",
        "ICMP flood",
        "UDP flood",
        "TCP SYN flood",
        "Port scanning",
        "Topology scanning"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Rule-based system",
        "specific": "Signature-based IDS with policy overlay (Safeguard)",
        "novel_contribution": "Safeguard: a rule-based policy layer that overlaps and constrains data-driven network policy decisions to avoid over-correction"
      }
    ],
    "learning_paradigm": [],
    "datasets": [
      {
        "name": "CloudLab SDN traffic (pre-recorded tcpdump traces with benign and hping3-generated attack flows)",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can SDN deployments that use data-driven (e.g., ML-based) intrusion detection avoid over-correction that blocks legitimate traffic?",
        "Can a simple rule-based safeguard overlay prevent unintended responses for edge cases in network traffic?",
        "What minimal set of whitelist/known-good rules meaningfully reduces false positives without disabling adaptive defenses?"
      ],
      "gaps_identified": [
        "Unbounded analytics-driven policies in SDNs may introduce unintended and deleterious behavior (over-correction).",
        "Lack of reproducible, detailed artifacts for some proposed ML-based SDN security systems.",
        "Insufficient guardrails around automated policy changes triggered by data-plane analytics.",
        "Operational exposure when relying solely on data-driven IDS decisions without policy constraints."
      ],
      "limitations": [
        "No actual ML classifier was integrated; authors used an abstracted signature-based classifier tuned to over-correct.",
        "Traffic processing was pre-recorded rather than end-to-end real-time streaming.",
        "Limited attack bandwidth (30–50 Mbps) due to resource and security constraints.",
        "Very simplified and strict detection rules; single, simplified Safeguard rule (known-good port) used.",
        "No quantitative evaluation or standard IDS metrics reported (e.g., FPR/TPR, accuracy, latency).",
        "No code/artifacts released; limited details to reproduce full pipeline.",
        "Policy actions limited to block/allow; no evaluation of alternative mitigations.",
        "No formal scalability or performance analysis of controller overhead."
      ],
      "future_work": [
        "Integrate an anomaly detection machine learning classifier to quantify safeguarding needs.",
        "Include fine-grained latency and performance measurements to assess trade-offs.",
        "Increase complexity of traffic patterns to better mimic real-world edge cases.",
        "Expand SDN policy actions beyond block/allow (logging, alerting, sinkholing/forwarding to limited-function servers)."
      ],
      "motivation": "Data-driven SDN policies (e.g., ML-based IDS) can misbehave under edge cases or maliciously crafted inputs; simple rule-based safeguards can constrain policy overreach and maintain correct operation.",
      "potential_research_ideas": [
        "Design and evaluate a constrained ML-IDS with formal safety envelopes that guarantee bounded false-positive impact in SDNs.",
        "Develop a policy synthesis engine that learns minimal whitelist/allow rules from observed benign workloads with provable non-interference with security goals.",
        "Create an online change-point detection module that adaptively tightens/relaxes safeguards based on network risk posture.",
        "Investigate multi-objective optimization of detection efficacy vs. availability (FPR cost) under SDN controller constraints.",
        "Adversarially robust ML-IDS for SDN with guardrail-aware training (cost-sensitive or constrained learning).",
        "Formal verification of SDN controller applications to prevent conflicting rules between safeguards and analytics-driven policies.",
        "Explainable IDS decisions integrated with safeguard overrides to aid operator trust and rapid rollback.",
        "Benchmark suite for SDN policy-safety stress testing with diverse benign edge cases and adaptive adversaries."
      ],
      "architectural_improvement_recommendations": [
        "Replace the signature-only detector with a streamed ML pipeline (e.g., flow-based anomaly detection with NetFlow/IPFIX features) and add confidence-driven actions.",
        "Add protocol flags and richer features (flow duration, packet size stats, inter-arrival times) and build a feature store to support both ML and rules.",
        "Introduce a graduated response policy (rate-limiting, tarpitting, micro-segmentation) before full blocks; include timed decay with evidence accumulation.",
        "Implement cryptographic whitelisting (mTLS, service identities) rather than port-based allow rules; support certificate-based safeguards.",
        "Move from HTTP to authenticated gRPC for controller-app communications; add idempotent rule push and conflict detection.",
        "Add policy audit and rollback with versioning; integrate with a controller verification tool to check invariant preservation.",
        "Distribute safeguard execution (switch-local fast path using OpenFlow meters/tables) to reduce controller load.",
        "Instrument latency and throughput tracing; add backpressure to avoid controller overload during floods."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Floodlight (OpenFlow controller)",
        "Open vSwitch",
        "tcpdump",
        "CloudLab testbed",
        "hping3 (traffic generation)"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "CloudLab SDN testbed; traffic generation 30–50 Mbps; offline/pre-recorded trace processing; no specialized hardware or GPU described."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "SDN testbed on CloudLab with Floodlight controller and Open vSwitch",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Risk of controller overload from attack traffic and from automated policy churn.",
        "Need for accurate allowlists/known-good identification without hindering agility.",
        "Integration robustness between analytics layer and controller (HTTP control channel).",
        "Absence of reproducible ML components limits transferability.",
        "Policy conflict management and rollback in live environments.",
        "Limited visibility/features (e.g., missing protocol flags) can impair detection quality."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Safeguard: a rule-based policy overlay that constrains data-driven SDN policies to prevent unintended responses and over-correction.",
      "Reference implementation on CloudLab with Floodlight and Open vSwitch demonstrating safeguard rules interacting with an analytics-driven policy.",
      "Demonstration that adding allow rules for known-good traffic prevents legitimate hosts from being blocked when analytics overreacts to edge cases.",
      "Threat model and attack demonstration (DoS/DDoS, scanning) to show potential misbehavior of unbounded analytics-driven policies.",
      "Discussion of the necessity of additional SDN policy functions and future integration with ML-based anomaly detection."
    ]
  },
  {
    "arxiv_id": "2601.17888v1",
    "title": "iResolveX: Multi-Layered Indirect Call Resolution via Static Reasoning and Learning-Augmented Refinement",
    "authors": "Monika Santra; Bokai Zhang; Mark Lim; Vishnu Asutosh Dasu; Dongrui Zeng; Gang Tan",
    "abstract": "Indirect call resolution remains a key challenge in reverse engineering and control-flow graph recovery, especially for stripped or optimized binaries. Static analysis is sound but often over-approximates, producing many false positives, whereas machine-learning approaches can improve precision but may sacrifice completeness and generalization. We present iResolveX, a hybrid multi-layered framework that combines conservative static analysis with learning-based refinement. The first layer applies a conservative value-set analysis (BPA) to ensure high recall. The second layer adds a learning-based soft-signature scorer (iScoreGen) and selective inter-procedural backward analysis with memory inspection (iScoreRefine) to reduce false positives. The final output, p-IndirectCFG, annotates indirect edges with confidence scores, enabling downstream analyses to choose appropriate precision--recall trade-offs. Across SPEC CPU2006 and real-world binaries, iScoreGen reduces predicted targets by 19.2% on average while maintaining BPA-level recall (98.2%). Combined with iScoreRefine, the total reduction reaches 44.3% over BPA with 97.8% recall (a 0.4% drop). iResolveX supports both conservative, recall-preserving and F1-optimized configurations and outperforms state-of-the-art systems.",
    "published_date": "2026-01-25",
    "pdf_link": "https://arxiv.org/pdf/2601.17888v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Binary Analysis and Reverse Engineering",
      "specific_problem": "Indirect call target resolution for control-flow graph (CFG) recovery in stripped/optimized binaries",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "MLP (Feedforward DNN)",
        "specific": "Lightweight 4 hidden-layer DNN (soft-signature scorer: iScoreGen)",
        "novel_contribution": "Soft signature scoring trained on direct call pairs with no indirect-call ground truth; feature decoupling (signature vs. context); produces confidence scores used for pruning and downstream precision–recall trade-offs"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "AttnCall",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Siamese Network",
        "specific": "CALLEE",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "SPEC CPU2006",
        "type": "public",
        "domain": "binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Real-world binaries",
        "type": "proprietary",
        "domain": "binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "BPA (block-level points-to/value-set analysis)",
        "paper_reference": "[20]",
        "metric": "AICT reduction vs. BPA and recall",
        "their_result": "“iScoreGen reduces predicted targets by 19.2% … while maintaining BPA-level recall (98.2%). Combined with iScoreRefine, the total reduction reaches 44.3% over BPA with 97.8% recall (a 0.4% drop).”",
        "baseline_result": "BPA-level recall ≈ 98.2%; AICT serves as the unpruned baseline (100%)."
      },
      {
        "method_name": "SchedExec",
        "paper_reference": "[37]",
        "metric": "AICT reduction at recall-preserving settings",
        "their_result": "“In recall-preserving settings, [iResolveX] achieves 18–48.5% more AICT reduction than prior tools at higher recall.”",
        "baseline_result": null
      },
      {
        "method_name": "BinDSA",
        "paper_reference": "[14]",
        "metric": "AICT reduction at recall-preserving settings",
        "their_result": "“In recall-preserving settings, [iResolveX] achieves 18–48.5% more AICT reduction than prior tools at higher recall.”",
        "baseline_result": null
      },
      {
        "method_name": "CALLEE",
        "paper_reference": "[58]",
        "metric": "Recall/F1 and AICT reduction comparisons (qualitative + ranges reported)",
        "their_result": "“In F1-optimized mode, it delivers 82–97% greater reduction while sustaining 80% F1 and 82–89% recall, outperforming existing systems.”",
        "baseline_result": "Relies on slices; drops small functions; requires fine-tuning with dynamic ground truth; struggles when slices are missing."
      },
      {
        "method_name": "AttnCall",
        "paper_reference": "[39]",
        "metric": "Recall on indirect calls",
        "their_result": "iResolveX sustains 82–89% recall in F1-optimized mode while delivering greater AICT reduction.",
        "baseline_result": "“AttnCall suffers from steep recall drops (as low as 70%) when handling indirect calls without fine-tuning.”"
      },
      {
        "method_name": "IDA",
        "paper_reference": "[16]",
        "metric": "Qualitative comparison of CFG accuracy/coverage",
        "their_result": "iResolveX outperforms state-of-the-art systems across conservative and F1-optimized settings.",
        "baseline_result": "Heuristic-based resolution leads to incomplete/under-approximated target sets."
      },
      {
        "method_name": "Ghidra",
        "paper_reference": "[35]",
        "metric": "Qualitative comparison of CFG accuracy/coverage",
        "their_result": "iResolveX outperforms state-of-the-art systems across conservative and F1-optimized settings.",
        "baseline_result": "Shallow heuristics/constant propagation; inaccurate CFGs."
      },
      {
        "method_name": "Angr",
        "paper_reference": "[38]",
        "metric": "Qualitative comparison of CFG accuracy/coverage and scalability",
        "their_result": "iResolveX outperforms state-of-the-art systems across conservative and F1-optimized settings.",
        "baseline_result": "Best among RE tools but lacks inter-procedural reasoning; high overhead due to emulation."
      }
    ],
    "performance_metrics_used": [
      "Average Indirect Call Targets (AICT)",
      "Recall",
      "F1-score"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How to combine static analysis soundness with ML precision to resolve indirect calls with high recall and reduced false positives?",
        "Can soft signature matching trained only on direct calls generalize to indirect calls without indirect-call ground-truth supervision?",
        "How to selectively incorporate inter-procedural backward analysis to validate ML predictions while remaining scalable?",
        "How to expose confidence-annotated CFGs so downstream analyses can choose precision–recall trade-offs?"
      ],
      "gaps_identified": [
        "Disconnect between static analysis and ML techniques; no unified approach balancing soundness and precision.",
        "ML methods rely on oversimplified intra-procedural slices and often do not generalize from direct to indirect calls; lack inter-procedural support.",
        "Existing RE tools are behind academic solutions and lack precision–recall flexibility.",
        "Static VSA approaches (e.g., BPA) are sound but severely over-approximate due to coarse memory modeling."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Indirect call resolution is a central challenge for accurate CFG recovery in stripped/optimized binaries; static analysis over-approximates and ML under-generalizes, impeding downstream security tasks that require both high recall and actionable precision.",
      "potential_research_ideas": [
        "Extend iResolveX to multiple architectures (ARM, RISC-V) and mixed-ABI binaries, studying cross-architecture generalization of soft signatures.",
        "Incorporate graph-based models (e.g., GNNs over IR/data-flow graphs) for richer context modeling while retaining the static refinement loop.",
        "Calibrate and quantify uncertainty better (e.g., temperature scaling, conformal prediction) for the confidence-annotated p-IndirectCFG.",
        "Integrate lightweight dynamic traces selectively guided by uncertainty to further reduce false positives with bounded overhead.",
        "Learn compiler/optimization-aware representations (meta-learning or domain adaptation) to handle aggressive optimizations and obfuscations.",
        "Automatic threshold selection for different downstream tasks via multi-objective optimization (precision–recall–coverage)."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment the MLP scorer with a shallow transformer or GNN over tokenized IR with positional and data-dependency edges, combined with static refinement.",
        "Introduce contrastive learning on callsite–callee pairs (including hard negatives from BPA) to improve discriminative power of soft signatures.",
        "Use joint learning with a calibration head to directly predict edge confidence with calibrated probabilities suitable for thresholding.",
        "Tighten the coupling between iScoreRefine and ML via iterative training (learning from static counterexamples identified during refinement).",
        "Augment memory modeling with learned block partition proposals (ML-assisted BPA memory partition recovery) to reduce over-approximation earlier."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Reverse engineering/binary analysis toolchain for x86-64 stripped or optimized binaries",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Handling stripped/optimized binaries with limited symbols and aggressive compiler transformations",
        "Balancing precision–recall for diverse downstream tasks (CFI, symbolic execution, malware analysis)",
        "Scaling selective inter-procedural analysis without prohibitive overhead",
        "Generalizing from direct to indirect calls across programs/compilers"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Hybrid Architecture: A unified design integrating sound static analysis with learning-based refinement.",
      "Zero-Supervision Learning: Feature decoupling enabling generalization from direct to indirect calls without indirect-call dynamic supervision.",
      "Inter-procedural reasoning: Scalable backward analysis with memory inspection to validate ML predictions.",
      "Confidence-Annotated & Context-Adaptable CFG: p-IndirectCFG with confidence scores enabling precision–recall customization.",
      "Empirical Validation: Up to 44.3% AICT reduction over BPA with only 0.4% recall loss; outperforms state-of-the-art across conservative and F1-optimized modes."
    ]
  },
  {
    "arxiv_id": "2601.17356v1",
    "title": "From Scores to Queues: Operationalizing Cross-Chain Obfuscation Signals for Smart-Contract Audits",
    "authors": "Yao Zhao; Zhang Sheng; Shengchen Duan; Shen Wang",
    "abstract": "Obfuscation substantially increases the interpretation cost of smart-contract auditing, while the comparability and transferability of obfuscation signals across chains remain unclear. We present HObfNET as an efficient surrogate of Obfs_Tool (ObfProbe), enabling fast cross-chain scoring at scale. The model aligns well with tool outputs on Ethereum (PCC 0.9158, MAPE 8.20 percent) and achieves 8-9 ms per contract, a 2.3k-5.2k times speedup over second-level Obfs_Tool runs, enabling million-scale scoring. On large BSC, Polygon, and Avalanche corpora, we find systematic score drift: fixed-threshold transfer inflates and deflates candidate queues, motivating within-chain main and extreme thresholds (p99 and p99.9) and an actionable queueing strategy. The high-score tail exhibits rare selectors, external-call opcode enrichment, and low signature density; a proxy indicator is enriched in the BSC high-score queue, enabling secondary triage. Cross-chain reuse analysis shows tail enrichment and directional diffusion, with traceable same-hash cases across chains. In publicly alignable incident samples, all fall into the p99 queue; Transit Swap DEX Hack and New Free DAO Flash Loan exhibit cross-chain spillover, indicating real-world hit and prioritization value. We deliver a two-tier audit queue and cross-chain linkage workflow to support practical multi-chain security operations.",
    "published_date": "2026-01-24",
    "pdf_link": "https://arxiv.org/pdf/2601.17356v1",
    "paper_types": [
      "empirical_analysis",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Security",
      "specific_problem": "Cross-chain obfuscation scoring and audit queue triage using a fast surrogate for tool-based obfuscation scores",
      "attack_types": [
        "Obfuscation/evasion",
        "MEV bot activity",
        "Ponzi schemes",
        "Fake decentralization",
        "Extreme centralization",
        "Flash-loan exploit",
        "DEX hack",
        "Cross-chain laundering/migration"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Hierarchical Attention Network",
        "specific": "HObfNET (local Transformer encoder + global attention, masked mean pooling, multi-task feature reconstruction)",
        "novel_contribution": "A learned surrogate for ObfProbe obfuscation scores with hierarchical sequence modeling and multi-task reconstruction to align with tool-defined feature space and Z-score"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Standard Transformer on flat byte sequence",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "GRU-HAN (GRU in hierarchical architecture, without multi-task)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Hierarchical Attention Network",
        "specific": "HAN without multi-task",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Multi-task Learning",
      "Regression"
    ],
    "datasets": [
      {
        "name": "Ethereum obfuscation-scored contracts (training/validation/test)",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "BSC runtime bytecode corpus",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Polygon runtime bytecode corpus",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Avalanche runtime bytecode corpus",
        "type": "public",
        "domain": "smart_contract_bytecode",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Incident alignment samples (Transit Swap DEX Hack, New Free DAO Flash Loan, and other publicly alignable incidents)",
        "type": "public",
        "domain": "incident_contracts",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Standard Transformer",
        "paper_reference": null,
        "metric": "MAPE",
        "their_result": "8.20%",
        "baseline_result": "16.29%"
      },
      {
        "method_name": "Standard Transformer",
        "paper_reference": null,
        "metric": "MAE",
        "their_result": "0.6341",
        "baseline_result": "0.9521"
      },
      {
        "method_name": "Standard Transformer",
        "paper_reference": null,
        "metric": "MSE",
        "their_result": "1.4477",
        "baseline_result": "2.7147"
      },
      {
        "method_name": "Standard Transformer",
        "paper_reference": null,
        "metric": "PCC",
        "their_result": "0.9158",
        "baseline_result": "0.8466"
      },
      {
        "method_name": "GRU-HAN (without multi-task)",
        "paper_reference": null,
        "metric": "MAPE",
        "their_result": "8.20%",
        "baseline_result": "14.28%"
      },
      {
        "method_name": "GRU-HAN (without multi-task)",
        "paper_reference": null,
        "metric": "MAE",
        "their_result": "0.6341",
        "baseline_result": "0.8794"
      },
      {
        "method_name": "GRU-HAN (without multi-task)",
        "paper_reference": null,
        "metric": "MSE",
        "their_result": "1.4477",
        "baseline_result": "2.4511"
      },
      {
        "method_name": "GRU-HAN (without multi-task)",
        "paper_reference": null,
        "metric": "PCC",
        "their_result": "0.9158",
        "baseline_result": "0.8484"
      },
      {
        "method_name": "HAN without multi-task",
        "paper_reference": null,
        "metric": "MAPE",
        "their_result": "8.20%",
        "baseline_result": "13.02%"
      },
      {
        "method_name": "HAN without multi-task",
        "paper_reference": null,
        "metric": "MAE",
        "their_result": "0.6341",
        "baseline_result": "0.8359"
      },
      {
        "method_name": "HAN without multi-task",
        "paper_reference": null,
        "metric": "MSE",
        "their_result": "1.4477",
        "baseline_result": "2.3371"
      },
      {
        "method_name": "HAN without multi-task",
        "paper_reference": null,
        "metric": "PCC",
        "their_result": "0.9158",
        "baseline_result": "0.8619"
      },
      {
        "method_name": "ObfProbe (SSA pipeline)",
        "paper_reference": "[1] Sheng et al. (ObfProbe)",
        "metric": "Average time per contract (ms)",
        "their_result": "8.67–8.69 ms (HObfNET across chains)",
        "baseline_result": "19,660 ms (ETH first-pass avg); ~45,000 ms for reruns without timeout"
      }
    ],
    "performance_metrics_used": [
      "MAPE",
      "MAE",
      "MSE",
      "PCC",
      "Average inference time per contract"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: Can Ethereum’s high-obfuscation cutoff be directly reused on other chains? If not, how should within-chain thresholds be set to keep audit queues actionable?",
        "RQ2: What structural features define the high-score tail, and how can they be used for executable secondary triage?",
        "RQ3: Do high-score templates reuse across chains and exhibit directional diffusion from smaller to larger ecosystems?",
        "RQ4: Do high-score queues cover real cross-chain incident contracts, thereby validating practical audit value?"
      ],
      "gaps_identified": [
        "Comparability and transferability of obfuscation signals across chains are unclear.",
        "Existing obfuscation tools (e.g., ObfProbe) are too slow for cross-chain, million-scale scoring.",
        "Fixed-threshold transfer across chains can inflate/deflate candidate queues due to distribution drift.",
        "High-score tails require structural profiling and executable features for secondary triage.",
        "Audit-relevant obfuscation signals need validation against real incidents, not just distributional analysis."
      ],
      "limitations": [
        "Model trained only on Ethereum tool-derived labels; non-Ethereum chains use surrogate predictions without tool ground-truth.",
        "Error increases with very long bytecodes; length sensitivity shows degraded MAE/MAPE at higher length quartiles.",
        "Heavy-tailed error distribution (e.g., p99 absolute error 5.4801 on ETH validation).",
        "Potential miscalibration under cross-chain drift; requires per-chain thresholds for actionable queues."
      ],
      "future_work": [],
      "motivation": "Enable practical, multi-chain smart-contract audit triage by operationalizing obfuscation scores at scale, overcoming tool runtime bottlenecks and addressing cross-chain distribution drift.",
      "potential_research_ideas": [
        "Domain adaptation or fine-tuning on small labeled subsets from BSC/Polygon/Avalanche to reduce cross-chain drift and improve calibration.",
        "Self-supervised pretraining on large unlabeled bytecode corpora (masked opcode modeling) before supervised alignment to ObfProbe scores.",
        "Graph-augmented modeling that fuses control-flow/data-flow graphs from decompilers with byte-sequence encoders for better long-range reasoning.",
        "Uncertainty estimation and conformal prediction to support risk-aware audit queuing and threshold setting per chain.",
        "Calibrated score normalization across chains (e.g., temperature scaling, quantile mapping) to stabilize queue sizes over time.",
        "Explainable obfuscation attributions (token/segment-level saliency) and selector/opcode attributions to guide secondary triage.",
        "Online learning from incident feedback and human-in-the-loop triage labels to refine thresholds and model weights.",
        "Temporal drift modeling to monitor score distribution shifts and auto-adjust main/extreme thresholds.",
        "Integration with clone/reuse detectors to identify diffusion families and proactively flag new cross-chain redeployments.",
        "Joint scoring of proxy detection and external-call patterns as auxiliary tasks to enrich triage signals."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a long-sequence Transformer (e.g., Performer/Longformer) or memory-compressed attention for very long bytecodes to mitigate length sensitivity.",
        "Incorporate mixture-of-experts with per-chain experts and a gating network for cross-chain specialization.",
        "Add a graph encoder over CFG/DFG extracted by decompilers, combined with byte-level encoders via cross-modal attention.",
        "Use contrastive learning to align tool-feature reconstructions with opcode/selector distributions, improving interpretability and robustness.",
        "Introduce quantile regression heads to directly predict p99/p99.9 membership alongside continuous scores.",
        "Implement score calibration layers (temperature scaling/Platt or isotonic) per chain for stable queue thresholds.",
        "Add uncertainty heads (e.g., MC Dropout or Deep Ensembles) and use uncertainty-aware queuing.",
        "Leverage parameter-efficient fine-tuning (LoRA/Adapters) for quick per-chain updates without full retraining."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/dcszhang/HObfNET",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": "Training on NVIDIA A100; 20 epochs; batch size 24; AdamW (lr 5e-4, weight decay 1e-4); each epoch ~6.13 hours + validation 0.52 hours. Inference batch size 200 on GPU with 8–9 ms per contract."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "8–9 ms per contract (approx. 2.3k–5.2k× faster than ObfProbe)",
      "deployment_challenges": [
        "Cross-chain score drift requires per-chain thresholds (p99/p99.9) to avoid queue inflation/deflation.",
        "Model accuracy degrades for very long bytecodes; needs long-sequence handling.",
        "Secondary triage is necessary due to tail composition (rare selectors, external-call opcode enrichment, low signature density).",
        "Reliance on tool-derived labels from Ethereum may limit generalization without cross-chain calibration."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces HObfNET, an efficient hierarchical attention surrogate for ObfProbe with strong alignment on Ethereum (PCC 0.9158, MAPE 8.20%) and 8–9 ms per-contract inference.",
      "Operationalizes within-chain main/extreme thresholds (p99/p99.9) for ETH, BSC, Polygon, Avalanche, showing fixed-threshold transfer causes 0.48%–2.32% queue inflation/deflation.",
      "Profiles high-score tail structure: rare selectors (10–50× lift), external-call opcode enrichment, and low signature density; BSC proxy indicator enrichment supports secondary triage.",
      "Quantifies cross-chain reuse: tail enrichment and directional diffusion (small → large ecosystems), with traceable same-hash cases.",
      "Validates audit value using publicly alignable incidents (e.g., Transit Swap DEX Hack, New Free DAO Flash Loan) falling into p99 queues; delivers a two-tier audit queue and cross-chain linkage workflow."
    ]
  },
  {
    "arxiv_id": "2601.17817v1",
    "title": "Multi-Agent Collaborative Intrusion Detection for Low-Altitude Economy IoT: An LLM-Enhanced Agentic AI Framework",
    "authors": "Hongjuan Li; Hui Kang; Jiahui Li; Geng Sun; Ruichen Zhang; Jiacheng Wang; Dusit Niyato; Wei Ni; Abbas Jamalipour",
    "abstract": "The rapid expansion of low-altitude economy Internet of Things (LAE-IoT) networks has created unprecedented security challenges due to dynamic three-dimensional mobility patterns, distributed autonomous operations, and severe resource constraints. Traditional intrusion detection systems designed for static ground-based networks prove inadequate for tackling the unique characteristics of aerial IoT environments, including frequent topology changes, real-time detection requirements, and energy limitations. In this article, we analyze the intrusion detection requirements for LAE-IoT networks, complemented by a comprehensive review of evaluation metrics that cover detection effectiveness, response time, and resource consumption. Then, we investigate transformative potential of agentic artificial intelligence (AI) paradigms and introduce a large language model (LLM)-enabled agentic AI framework for enhancing intrusion detection in LAE-IoT networks. This leads to our proposal of a novel multi-agent collaborative intrusion detection framework that leverages specialized LLM-enhanced agents for intelligent data processing and adaptive classification. Through experimental validation, our framework demonstrates superior performance of over 90\\% classification accuracy across multiple benchmark datasets. These results highlight the transformative potential of combining agentic AI principles with LLMs for next-generation LAE-IoT security systems.",
    "published_date": "2026-01-25",
    "pdf_link": "https://arxiv.org/pdf/2601.17817v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Intrusion detection for Low-Altitude Economy IoT (LAE-IoT) networks with dynamic 3D mobility, autonomous operations, and severe resource constraints",
      "attack_types": [
        "DDoS",
        "GPS spoofing",
        "Man-in-the-middle (MITM)",
        "Rogue node impersonation/malicious node injection",
        "Unauthorized altitude changes/trajectory manipulation",
        "Hole attacks",
        "Data exfiltration",
        "Malicious packet forwarding"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM",
        "specific": null,
        "novel_contribution": "Uses a large language model as the cognitive engine within an agentic framework for reasoning, planning, and adaptive classification in IDS for LAE-IoT"
      },
      {
        "type": "primary",
        "category": "Multi-agent system",
        "specific": "LLM-enhanced agentic AI with perception–memory–reasoning–action loop",
        "novel_contribution": "Proposes a multi-agent collaborative intrusion detection framework with specialized LLM-enhanced agents coordinating for intelligent data processing and adaptive classification"
      },
      {
        "type": "primary",
        "category": "Retrieval-Augmented Generation (RAG)",
        "specific": null,
        "novel_contribution": "Retrieval mechanisms to provide domain/context knowledge (protocols, flight parameters, threat signatures) for context-aware anomaly detection"
      },
      {
        "type": "primary",
        "category": "Reasoning methods",
        "specific": "Chain-of-thought style multi-step reasoning and planning",
        "novel_contribution": "LLM-driven multi-step strategy design for proactive and adaptive detection and response"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Unspecified multiple benchmark IDS datasets (paper claims use of multiple benchmarks)",
        "type": "unknown",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "unspecified"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "Response time",
      "CPU utilization",
      "Memory consumption",
      "Energy consumption"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to design an intrusion detection framework tailored to LAE-IoT networks that contend with dynamic 3D topologies, autonomy, and resource constraints?",
        "Which evaluation metrics appropriately balance detection effectiveness, response time, and resource/energy consumption in LAE-IoT IDS?",
        "How can LLM-enabled agentic AI provide proactive, adaptive, and collaborative detection compared to traditional static and reactive IDS?",
        "How to architect a multi-agent LLM-enhanced IDS system (perception, memory, reasoning, action) suitable for lightweight deployment in LAE-IoT?"
      ],
      "gaps_identified": [
        "Limited adaptability of traditional ML/DL IDS to rapidly evolving topologies and attack patterns without extensive retraining",
        "Insufficient autonomy of traditional approaches (high inference latency/overhead, need for human intervention, poor suitability for wide-area, intermittent connectivity)",
        "Resource constraints of LAE-IoT devices (compute, memory, energy) render many state-of-the-art models impractical",
        "Conventional IDS evaluation overlooks energy/resource efficiency crucial for battery-powered aerial devices"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Traditional ground-network IDSs are ill-suited for LAE-IoT’s dynamic, resource-constrained, real-time environments; a proactive, adaptive, and collaborative agentic AI approach is needed.",
      "potential_research_ideas": [
        "Design a public LAE-IoT-specific IDS benchmark with realistic aerial mobility, multi-tier architectures, and labeled attack scenarios (GPS spoofing, MITM during handoffs) to catalyze reproducible research.",
        "Develop energy-aware LLM distillation/quantization for on-device micro-LLMs to enable real-time inference on UAV-class hardware.",
        "Create a neurosymbolic agent that learns, verifies, and deploys explainable detection rules from LLM reasoning traces with formal safety constraints.",
        "Investigate federated/multi-agent continual learning under dynamic topology with communication-efficient model exchange and drift detection.",
        "Study adversarial robustness of LLM-augmented IDS in LAE-IoT (prompt injection, data poisoning of RAG corpora, adversarial traffic) and design defenses.",
        "Privacy-preserving RAG pipelines (e.g., on-device vector stores, encrypted retrieval) for sensitive flight/telemetry data.",
        "Build a high-fidelity LAE-IoT digital twin to generate synthetic training/evaluation scenarios for agent stress-testing and what-if planning."
      ],
      "architectural_improvement_recommendations": [
        "Introduce a hierarchical control: edge micro-LLMs on UAVs for fast triage and a stronger LLM at ground/edge for complex reasoning with adaptive offloading.",
        "Adopt event-driven scheduling to activate LLM agents only on anomaly triggers; otherwise rely on lightweight detectors to save energy.",
        "Incorporate graph-based situational awareness where agents share summaries over a dynamic communication graph with trust-weighted aggregation.",
        "Use RAG with curated, versioned, and validated domain knowledge; add retrieval filters and provenance tracking to reduce hallucinations.",
        "Add online drift detection and active learning to request labels/feedback opportunistically during missions.",
        "Quantize and sparsify LLMs (e.g., 4–8 bit, mixture-of-experts) and leverage speculative decoding to meet latency/energy constraints."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Low-Altitude Economy IoT (UAV/eVTOL, aerial-ground multi-tier networks)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Severe compute, memory, and battery constraints on aerial devices",
        "Need for real-time/near-real-time detection and response",
        "Intermittent connectivity and dynamic topology complicate coordination",
        "Potential latency/energy overheads of LLM inference and RAG on edge",
        "Robustness to topology changes, handoffs, and re-clustering events"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Analysis of unique LAE-IoT IDS challenges (dynamic topology, real-time requirements, resource constraints).",
      "Systematic comparison of traditional AI vs. agentic AI, arguing proactive, adaptive, and collaborative advantages for IDS.",
      "Proposal of a general agentic AI IDS framework with perception, memory, reasoning, and action components.",
      "Case study presenting an LLM-enhanced agentic AI system with lightweight deployment strategies for LAE-IoT.",
      "Experimental validation reporting “over 90% classification accuracy across multiple benchmark datasets.”"
    ]
  },
  {
    "arxiv_id": "2601.13515v1",
    "title": "Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests",
    "authors": "Hanlin Zhou; Huah Yong Chan; Jingfei Ni; Mengchun Wu; Qing Deng",
    "abstract": "In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.",
    "published_date": "2026-01-20",
    "pdf_link": "https://arxiv.org/pdf/2601.13515v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cloud/Container Security",
      "subdomain": "Kubernetes runtime and autoscaling defense",
      "specific_problem": "Preventing autoscaling (HPA) resource exhaustion under attack by dynamically adjusting HPA parameters and isolating attack traffic using ML-driven detection",
      "attack_types": [
        "Directory scanning/probing",
        "Autoscaling abuse (DDoS-induced scale-out)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble Decision Trees",
        "specific": "Random Forest",
        "novel_contribution": "Use Random Forest on HTTP log features (IP-based labeling of 404/403 and error logs) to detect directory-scanning attackers and to trigger dynamic HPA maxReplicas adjustments and IP redirection to honeypot pods"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Simulated Nginx HTTP access and error logs (this study)",
        "type": "synthetic",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Prometheus-extracted Nginx VTS metrics (HTTP status codes)",
        "type": "private",
        "domain": "monitoring_metrics",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "F1-score (attack classification)",
      "5XX status code count",
      "4XX/499 status code count",
      "Total request time",
      "Number of attacks redirected to honeypot",
      "HPA scaling behavior (maxReplicas changes, trigger events)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can machine learning on HTTP status/log data reliably identify attack traffic and drive dynamic HPA parameter adjustments to prevent resource waste?",
        "How do different HPA adjustment thresholds (time windows and attack ratios) affect error rates (5XX/4XX) and overall request completion time under mixed traffic?",
        "Does redirecting detected attacking IPs to honeypot pods effectively isolate attack traffic without harming availability for normal users?"
      ],
      "gaps_identified": [
        "Default HPA metrics (CPU/memory) may not reflect service health, leading to poor scaling decisions during faults or attacks.",
        "Difficulty distinguishing normal vs. abnormal (attack) traffic in autoscaling decisions.",
        "Lack of integrated, automated mechanisms to prevent HPA over-expansion under attack traffic.",
        "Sensitivity to threshold selection for triggering HPA parameter changes."
      ],
      "limitations": [
        "Exploratory, small-scale testbed: concurrency limited to 200 due to platform resource constraints.",
        "Synthetic traffic and labels: requests simulated via Python with Faker; X-Forwarded-For used to represent client IPs.",
        "Focus on a single attack class (directory scanning); Random Forest used solely for classifying directory attacks.",
        "Nginx-only service scenario (default homepage); limited generality validated empirically.",
        "Binary HPA maxReplicas adjustments (scripts set to 1 or 5) rather than continuous control.",
        "No comparison to alternative ML models or non-ML heuristics; lack of ablation studies."
      ],
      "future_work": [
        "Apply the same framework with different ML models and to other attack types beyond directory scanning.",
        "Explore and formalize threshold selection strategies for HPA adjustments under varying workloads.",
        "Generalize the architecture to broader service types beyond Nginx and different traffic patterns."
      ],
      "motivation": "Prevent resource waste and availability degradation when Kubernetes HPA scales out in response to attack traffic by using ML-driven detection on HTTP status metrics to control HPA behavior and isolate attackers.",
      "potential_research_ideas": [
        "Replace IP-based RF classification with sequence- or session-based models (e.g., temporal models) that use richer features than status codes alone.",
        "Learn adaptive HPA policies via reinforcement learning that optimize latency/error trade-offs under attack and benign load.",
        "Develop online/streaming learning for evolving attacks and concept drift in traffic patterns.",
        "Integrate multi-signal telemetry (eBPF kernel events, connection metrics, WAF signals) to improve detection robustness.",
        "Study adversarial evasion (e.g., attackers blending status codes) and design robust training and detection.",
        "Formulate threshold selection as a control problem and apply control-theoretic or Bayesian optimization methods.",
        "Evaluate in multi-tenant clusters and with service meshes (e.g., Envoy/Istio) for policy enforcement at L7."
      ],
      "architectural_improvement_recommendations": [
        "Move from IP-only features to feature-rich representations (URL paths, request rates, sequences, headers) and aggregate per-entity (user/session) to reduce false positives.",
        "Introduce a continuous controller for HPA parameters (PID/RL) rather than binary maxReplicas toggling to avoid capacity collapse.",
        "Decouple identification and enforcement using a service mesh or sidecar to enforce per-entity routing and rate-limits with lower configmap churn.",
        "Implement online retraining and drift detection to maintain model accuracy over time.",
        "Add safety constraints (minimum capacity floor) to prevent over-aggressive downscaling when detection confidence is low.",
        "Harden source identity (avoid trusting X-Forwarded-For; use ingress/controller real client IP or mTLS identity) to prevent spoofing."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Kubernetes testbed; dual/tri-layer Nginx pods with Prometheus and custom metrics adapter; Random Forest trained via Python scripts (100 trees, random_state=42); no GPU; experiments limited to ~200 concurrent requests with Nginx pod CPU limit 30m."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Kubernetes cluster (test environment) with multi-layer Nginx, Prometheus, custom metrics API, and honeypot pods",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Threshold selection critically impacts availability and error rates.",
        "Overly aggressive maxReplicas reduction can collapse capacity and spike 5XX errors.",
        "Reliance on X-Forwarded-For for IP identity may be spoofable in real deployments.",
        "Operational complexity of dynamic configmap updates and routing rules.",
        "Generalization beyond Nginx/homepage workloads not demonstrated.",
        "Handling dynamic/rotating attacker IPs and NATed clients."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Implements HPA using HTTP status code growth (5XX over 5 minutes) as custom metrics via Nginx VTS and Prometheus.",
      "Integrates a Random Forest classifier to detect directory scanning attackers and predict per-IP future attack probability.",
      "Dynamically adjusts HPA maxReplicas in response to predicted attack ratios to avoid attack-driven scale-outs.",
      "Redirects detected attacking IPs to honeypot pods to isolate attack traffic from business pods.",
      "Empirically evaluates multiple threshold and time-window configurations, showing trade-offs between availability (5XX) and cost (scaling)."
    ]
  },
  {
    "arxiv_id": "2601.15754v1",
    "title": "CAFE-GB: Scalable and Stable Feature Selection for Malware Detection via Chunk-wise Aggregated Gradient Boosting",
    "authors": "Ajvad Haneef K; Karan Kuwar Singh; Madhu Kumar S D",
    "abstract": "High-dimensional malware datasets often exhibit feature redundancy, instability, and scalability limitations, which hinder the effectiveness and interpretability of machine learning-based malware detection systems. Although feature selection is commonly employed to mitigate these issues, many existing approaches lack robustness when applied to large-scale and heterogeneous malware data. To address this gap, this paper proposes CAFE-GB (Chunk-wise Aggregated Feature Estimation using Gradient Boosting), a scalable feature selection framework designed to produce stable and globally consistent feature rankings for high-dimensional malware detection. CAFE-GB partitions training data into overlapping chunks, estimates local feature importance using gradient boosting models, and aggregates these estimates to derive a robust global ranking. Feature budget selection is performed separately through a systematic k-selection and stability analysis to balance detection performance and robustness. The proposed framework is evaluated on two large-scale malware datasets: BODMAS and CIC-AndMal2020, representing large and diverse malware feature spaces. Experimental results show that classifiers trained on CAFE-GB -selected features achieve performance parity with full-feature baselines across multiple metrics, including Accuracy, F1-score, MCC, ROC-AUC, and PR-AUC, while reducing feature dimensionality by more than 95\\%. Paired Wilcoxon signed-rank tests confirm that this reduction does not introduce statistically significant performance degradation. Additional analyses demonstrate low inter-feature redundancy and improved interpretability through SHAP-based explanations. Runtime and memory profiling further indicate reduced downstream classification overhead. Overall, CAFE-GB provides a stable, interpretable, and scalable feature selection strategy for large-scale malware detection.",
    "published_date": "2026-01-22",
    "pdf_link": "https://arxiv.org/pdf/2601.15754v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection",
      "specific_problem": "Stable and scalable feature selection for high-dimensional malware detection",
      "attack_types": [
        "Windows PE malware",
        "Android malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Gradient Boosting (tree ensemble)",
        "specific": "LightGBM",
        "novel_contribution": "Chunk-wise local feature-importance estimation aggregated into a globally consistent ranking; separate stability-aware k-selection for feature budget"
      },
      {
        "type": "baseline",
        "category": "Linear Model",
        "specific": "Logistic Regression",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble (Bagging)",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting (tree ensemble)",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting (tree ensemble)",
        "specific": "LightGBM (as classifier)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Explainability",
        "specific": "SHAP",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "BODMAS",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-AndMal2020 (static features subset)",
        "type": "public",
        "domain": "android_apps",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Full-feature Logistic Regression",
        "paper_reference": null,
        "metric": "Accuracy, F1-score, MCC, ROC-AUC, PR-AUC",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Full-feature Random Forest",
        "paper_reference": null,
        "metric": "Accuracy, F1-score, MCC, ROC-AUC, PR-AUC",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Full-feature XGBoost",
        "paper_reference": null,
        "metric": "Accuracy, F1-score, MCC, ROC-AUC, PR-AUC",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Full-feature LightGBM",
        "paper_reference": null,
        "metric": "Accuracy, F1-score, MCC, ROC-AUC, PR-AUC",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1-score",
      "Matthews Correlation Coefficient (MCC)",
      "ROC-AUC",
      "PR-AUC",
      "Wilcoxon signed-rank test (statistical significance)",
      "Jaccard similarity (feature stability)",
      "Pearson correlation (redundancy analysis)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Most existing methods rely on global importance estimation and lack stability guarantees when applied to large-scale and heterogeneous malware data.",
        "Global feature-importance methods are sensitive to class imbalance, local distributional variations, and sampling bias, producing unstable and redundant feature subsets.",
        "Locality-aware or chunk-wise feature selection strategies are underexplored in malware detection.",
        "Stability and redundancy analyses are rarely performed explicitly in malware detection studies."
      ],
      "limitations": [
        "For CIC-AndMal2020, only static features are considered in experiments.",
        "Feature subset size optimization is not performed within the ranking method itself; k is chosen via a separate stability/performance analysis."
      ],
      "future_work": [],
      "motivation": "Address stability, redundancy, and scalability issues of feature selection for high-dimensional, heterogeneous malware datasets without increasing model complexity.",
      "potential_research_ideas": [
        "Extend CAFE-GB to streaming/online settings with concept drift detection and dynamic re-ranking of features.",
        "Evaluate chunk-wise aggregation with other local learners (e.g., linear models with L1, random forests, oblique trees) and compare aggregation schemes (median, trimmed mean, rank aggregation).",
        "Integrate redundancy-aware penalization directly into aggregation (e.g., de-correlated importance or mutual information-based de-biasing).",
        "Combine static and dynamic features for Android and Windows; assess cross-modal stability and transferability of feature rankings.",
        "Incorporate adversarial robustness by testing against feature-space perturbations and adding robust importance estimation.",
        "Calibrate chunking strategy adaptively (vary chunk sizes/overlap based on distributional shift or class imbalance).",
        "Benchmark against strong feature selection baselines (L1/Lasso, Elastic Net, Boruta, ReliefF, mutual information, mRMR) under identical splits with significance testing."
      ],
      "architectural_improvement_recommendations": [
        "Use robust rank-aggregation methods (e.g., Borda count, Robust Rank Aggregation) over chunk-wise importance ranks instead of raw score summation.",
        "Weight chunks by quality (e.g., class balance, entropy) when aggregating importances; learn weights via validation.",
        "Apply stability selection with subsampling and regularization (e.g., L1-penalized trees or gradient boosting with feature subsampling) to further enhance stability.",
        "Introduce redundancy-aware re-ranking using correlation/mutual information pruning after aggregation.",
        "Parallelize chunk training and aggregation; cache feature histograms to reduce LightGBM training overhead.",
        "Assess SHAP stability across seeds/chunks to validate explanation consistency."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "LightGBM",
        "XGBoost"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "80-20 stratified split (seed=42); z-score normalization on training stats; chunk size l=15000, overlap o=0.1; LightGBM with default hyperparameters for importance (gain). Experiments repeated across 5 random seeds. Runtime and memory profiling indicate reduced downstream classification overhead."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High-dimensional malware features impose memory and computational overhead, motivating chunk-wise processing.",
        "Class imbalance and local distribution variations can bias global feature importance estimation."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "\"We propose CAFE-GB, a chunk-wise feature selection framework that aggregates local gradient boosting importance estimates to obtain stable global feature rankings for high-dimensional malware data.\"",
      "\"CAFE-GB reduces feature dimensionality by over 95% while achieving performance parity with full-feature baselines across Accuracy, F1-score, MCC, ROC-AUC, and PR-AUC.\"",
      "\"Paired Wilcoxon tests confirm that no statistically significant performance degradation is introduced.\"",
      "\"Additional analyses demonstrate low feature redundancy and improved interpretability through SHAP-based explanations.\"",
      "\"Runtime and memory profiling further indicate reduced downstream classification overhead.\""
    ]
  },
  {
    "arxiv_id": "2601.14511v1",
    "title": "Towards Transparent Malware Detection With Granular Explainability: Backtracking Meta-Coarsened Explanations Onto Assembly Flow Graphs With Graph Neural Networks",
    "authors": "Griffin Higgins; Roozbeh Razavi-Far; Hossein Shokouhinejad; Ali A. Ghorbani",
    "abstract": "As malware continues to become increasingly sophisticated, threatening, and evasive, malware detection systems must keep pace and become equally intelligent, powerful, and transparent. In this paper, we propose Assembly Flow Graph (AFG) to comprehensively represent the assembly flow of a binary executable as graph data. Importantly, AFG can be used to extract granular explanations needed to increase transparency for malware detection using Graph Neural Networks (GNNs). However, since AFGs may be large in practice, we also propose a Meta-Coarsening approach to improve computational tractability via graph reduction. To evaluate our proposed approach we consider several novel and existing metrics to quantify the granularity and quality of explanations. Lastly, we also consider several hyperparameters in our proposed Meta-Coarsening approach that can be used to control the final explanation size. We evaluate our proposed approach using the CIC-DGG-2025 dataset. Our results indicate that our proposed AFG and Meta-Coarsening approach can provide both increased explainability and inference performance at certain coarsening levels. However, most importantly, to the best of our knowledge, we are the first to consider granular explainability in malware detection using GNNs.",
    "published_date": "2026-01-20",
    "pdf_link": "https://arxiv.org/pdf/2601.14511v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection",
      "specific_problem": "Transparent, granular (instruction-level) explainability for GNN-based Windows PE malware detection via Assembly Flow Graphs and meta-coarsening with backtracking",
      "attack_types": [
        "malware (Windows PE)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": null,
        "novel_contribution": "Introduces Assembly Flow Graph (AFG) representation and a Meta-Coarsening + backtracking pipeline to obtain instruction-level explanatory subgraphs for GNN-based malware detection"
      },
      {
        "type": "primary",
        "category": "Graph Reduction / Coarsening",
        "specific": "Meta-Coarsening (coarsen CFG to C-CFG, explain, then backtrack and train on backtracked AFG)",
        "novel_contribution": "Backtrackable, hierarchical pipeline enabling tractable training/explaining on large program graphs while retaining instruction-level explainability"
      },
      {
        "type": "baseline",
        "category": "GNN Explainer",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Post-hoc Explainability"
    ],
    "datasets": [
      {
        "name": "CIC-DGG-2025 (Dynamically Generated Graphs for Malware Analysis)",
        "type": "public",
        "domain": "program_graphs (dynamic CFGs/AFGs from Windows PE binaries)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "explanation sufficiency",
      "explanation necessity",
      "characterized explanation (combined sufficiency/necessity)",
      "explanation granularity/size"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can Assembly Flow Graphs (AFGs) enable granular, instruction-level subgraph explanations for GNN-based malware detection?",
        "Can Meta-Coarsening improve computational tractability while preserving or improving explainability quality and inference performance?",
        "How do coarsening methods and coefficients (hyperparameters) control the final explanation size and quality?",
        "What metrics best quantify the granularity and quality (e.g., necessity, sufficiency, characterization) of GNN explanations for malware detection?"
      ],
      "gaps_identified": [
        "CFG-level approaches cannot provide highly characterized instruction-level subgraph explanations because instructions are not graph-primitive nodes in CFGs.",
        "Direct coarsening on large AFGs is computationally challenging/intractable.",
        "Existing explainability evaluations insufficiently quantify explanation granularity; need novel metrics."
      ],
      "limitations": [
        "AFGs can be very large, making preprocessing, embedding, training, and explaining non-trivial.",
        "Meta-Coarsening approximates direct AFG coarsening; potential divergence between C-CFG explanations and true AFG-level importance.",
        "Improved inference performance occurs only at certain coarsening levels (not uniformly)."
      ],
      "future_work": [],
      "motivation": "Malware detection needs transparent, granular explanations to understand and validate model behavior; provide instruction-level explainability while keeping computation tractable.",
      "potential_research_ideas": [
        "End-to-end differentiable, learnable coarsening/uncoarsening for hierarchical instruction–basic-block–function graphs to jointly optimize accuracy and explainability.",
        "Counterfactual instruction-level explainers for AFGs to complement factual subgraph explanations.",
        "Coarsening-aware training objectives (multi-objective loss) balancing accuracy, explanation sufficiency/necessity, and explanation size.",
        "Graph transformer architectures with positional encodings capturing instruction order within AFG paths.",
        "Heterogeneous program graphs combining CFG, call graph, and AFG in a unified model with type-aware message passing.",
        "Robustness-focused training against obfuscations (e.g., instruction substitution, dead-code insertion) while preserving explanation stability.",
        "Integrating dynamic execution traces with AFGs to align runtime semantics with static instruction-level subgraphs.",
        "Ground-truth behavioral annotation for a subset of samples to benchmark explanation faithfulness at instruction level.",
        "Privacy-preserving sharing of AFG-derived features via federated or split learning for cross-organization collaboration."
      ],
      "architectural_improvement_recommendations": [
        "Adopt hierarchical GNNs with pooling/unpooling across instruction→basic-block→function levels to natively support backtracking and multi-scale explanations.",
        "Use differentiable coarsening (e.g., learnable cluster assignments) instead of fixed coarsening to better align C-CFG explanations with AFG semantics.",
        "Incorporate graph transformers or attention-based GNNs with sequence-aware encodings for instruction lists.",
        "Employ self-interpretable GNNs (e.g., information bottleneck masks) to produce explanations during inference without separate explainers.",
        "Add coarsening-regularization terms that penalize explanation fragmentation and encourage connected, minimal subgraphs.",
        "Optimize large-graph training via memory-efficient batching, CPU–GPU pipelining, and sparse kernels tailored to long path graphs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Large AFG sizes increase preprocessing, training, and explaining costs.",
        "Direct AFG coarsening is computationally challenging; requires meta-coarsening approximation.",
        "Selecting coarsening coefficients to balance performance and explanation granularity."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a novel program graph type (Assembly Flow Graph) to represent assembly instruction flow of a binary executable.",
      "Captures granular instruction-level explainability with GNNs for enhanced transparency.",
      "Introduces a Meta-Coarsening approach to improve computational tractability and enable backtracking of explanations.",
      "Defines novel explanation metrics to quantify explanation granularity and quality (including necessity, sufficiency, and characterized explanations).",
      "Explores hyperparameters to control final explanation size and shows that certain coarsening levels can improve both explainability and inference performance.",
      "Claims to be the first to consider granular explainability in malware detection using GNNs at the assembly level."
    ]
  },
  {
    "arxiv_id": "2601.17178v1",
    "title": "TrojanGYM: A Detector-in-the-Loop LLM for Adaptive RTL Hardware Trojan Insertion",
    "authors": "Saideep Sreekumar; Zeng Wang; Akashdeep Saha; Weihua Xiao; Minghao Shao; Muhammad Shafique; Ozgur Sinanoglu; Ramesh Karri; Johann Knechtel",
    "abstract": "Hardware Trojans (HTs) remain a critical threat because learning-based detectors often overfit to narrow trigger/payload patterns and small, stylized benchmarks. We introduce TrojanGYM, an agentic, LLM-driven framework that automatically curates HT insertions to expose detector blind spots while preserving design correctness. Given high-level HT specifications, a suite of cooperating LLM agents (instantiated with GPT-4, LLaMA-3.3-70B, and Gemini-2.5Pro) proposes and refines RTL modifications that realize diverse triggers and payloads without impacting normal functionality. TrojanGYM implements a feedback-driven benchmark generation loop co-designed with HT detectors, in which constraint-aware syntactic checking and GNN-based HT detectors provide feedback that iteratively refines HT specifications and insertion strategies to better surface detector blind spots. We further propose Robust-GNN4TJ, a new implementation of the GNN4TJ with improved graph extraction, training robustness, and prediction reliability, especially on LLM-generated HT designs. On the most challenging TrojanGYM-generated benchmarks, Robust-GNN4TJ raises HT detection rates from 0% to 60% relative to a prior GNN-based detector. We instantiate TrojanGYM on SRAM, AES-128, and UART designs at RTL level, and show that it systematically produces diverse, functionally correct HTs that reach up to 83.33% evasion rates against modern GNN-based detectors, revealing robustness gaps that are not apparent when these detectors are evaluated solely on existing TrustHub-style benchmarks. Post peer-review, we will release all codes and artifacts.",
    "published_date": "2026-01-23",
    "pdf_link": "https://arxiv.org/pdf/2601.17178v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Hardware Trojan Detection and Evasion",
      "specific_problem": "Detector-in-the-loop, LLM-driven RTL hardware Trojan insertion to expose blind spots of GNN-based detectors, plus an improved GNN detector (Robust-GNN4TJ) for LLM-generated Trojans",
      "attack_types": [
        "information leakage",
        "denial of service",
        "performance degradation (power/throughput)",
        "functional manipulation/integrity violation"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "GPT-4; LLaMA-3.3-70B; Gemini-2.5 Pro",
        "novel_contribution": "Agentic multi-LLM pipeline for RTL HT analysis, planning, insertion, and iterative refinement with syntax-aware compile/repair and detector feedback (detector-in-the-loop)"
      },
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Robust-GNN4TJ",
        "novel_contribution": "New implementation of GNN4TJ with improved graph extraction, training robustness, and prediction reliability on LLM-generated HT designs; boosts detection from 0% to 60% on hardest TrojanGYM benchmarks"
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GNN4TJ (HW2VEC-style)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Adversarial evaluation (detector-in-the-loop)",
      "Agentic LLM prompting (no fine-tuning)"
    ],
    "datasets": [
      {
        "name": "Trust-Hub",
        "type": "public",
        "domain": "RTL/gate-level hardware trojan benchmarks",
        "link": "https://trust-hub.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "TrojanGYM-generated RTL HT benchmarks (SRAM, AES-128, UART variants)",
        "type": "synthetic",
        "domain": "RTL hardware designs with LLM-inserted Trojans",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GNN4TJ (prior GNN-based detector; HW2VEC-style)",
        "paper_reference": "GNN4TJ",
        "metric": "HT detection rate on TrojanGYM-generated benchmarks",
        "their_result": "Robust-GNN4TJ: 60% detection on the most challenging TrojanGYM-generated benchmarks",
        "baseline_result": "0% detection on the same benchmarks"
      },
      {
        "method_name": "Modern GNN-based detectors (unspecified variants)",
        "paper_reference": null,
        "metric": "Evasion rate (attack success)",
        "their_result": "Up to 83.33% evasion rate achieved by TrojanGYM-generated HTs",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "HT detection rate/recall",
      "Evasion rate",
      "Clean vs Trojan probability from detector"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can we generate RTL hardware Trojans that systematically expose blind spots of learning-based detectors?",
        "Can a detector-in-the-loop, property-aware LLM pipeline improve benchmark relevance and stress-test detector robustness beyond TrustHub-style datasets?",
        "How can GNN4TJ be improved to better detect LLM-generated HTs in terms of robustness and reliability?"
      ],
      "gaps_identified": [
        "Learning-based HT detectors overfit to narrow trigger/payload patterns and small, stylized benchmarks (e.g., TrustHub).",
        "Existing HT benchmark generation lacks feedback from detector behavior; generation and evaluation are decoupled.",
        "Current LLM-based HT frameworks are attack-centric and lack structural awareness, adaptive planning, and multi-stage, detector-informed evaluation.",
        "Reported detector performance on traditional benchmarks does not reflect robustness to diverse, adaptively generated HTs."
      ],
      "limitations": [
        "Scope limited to RTL-level insertion and evaluation.",
        "Evaluation focuses on GNN-based structural detectors; other modalities (e.g., side-channel) are not in the loop.",
        "Only three target designs (SRAM, AES-128, UART) are instantiated.",
        "Code and artifacts are promised post peer-review (not publicly available at the time of writing).",
        "Repair/refinement loops are bounded (up to four iterations)."
      ],
      "future_work": [],
      "motivation": "Close the gap between growing attack capability (LLM-generated RTL Trojans) and detector robustness by co-evolving benchmarks and detectors in a feedback-driven loop, and by improving GNN-based detection for LLM-generated HTs.",
      "potential_research_ideas": [
        "Extend the detector-in-the-loop to multi-modal detectors (combine structural GNNs with side-channel simulators/estimators) for harder-to-evade HT generation and evaluation.",
        "Incorporate formal equivalence and property checking (assertion-based verification, bounded model checking) into the gating loop to guarantee functional correctness under richer constraints.",
        "Localize Trojans in addition to binary detection via multi-task learning (classification + node/edge-level localization) and evaluate TrojanGYM’s ability to induce localization blind spots.",
        "Adversarial training of detectors using online-generated TrojanGYM samples with curriculum over trigger rarity, payload semantics, and structural camouflage.",
        "Generalize to gate-level netlists and post-synthesis flows; study robustness under optimization/placement-routing transformations.",
        "Fine-tune open-source LLMs on HDL corpora and Trojan patterns to reduce syntax errors and improve controllability in insertion planning.",
        "Develop a standardized, property-annotated taxonomy and metadata schema for LLM-generated HT datasets to facilitate reproducible benchmarking."
      ],
      "architectural_improvement_recommendations": [
        "Adopt graph-transformer or hetero-GNN backbones with explicit data/control-flow separation and long-range dependency modeling for HT detection.",
        "Pretrain detectors with contrastive/self-supervised graph objectives on large HDL corpora before supervised fine-tuning on HT labels.",
        "Use calibrated detection with uncertainty estimation (e.g., temperature scaling, evidential GNNs) to reduce overconfident errors on OOD LLM-generated designs.",
        "Employ ensemble detectors (diverse graph encoders and feature sets) within the feedback loop to reduce single-detector bias.",
        "Integrate static program analysis features (e.g., signal toggle rarity, taint propagation summaries) as side information to the GNN."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Pre-silicon RTL security evaluation pipeline (design-time tooling with compiler and GNN detector in the loop)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "LLM-generated code may contain syntax/structural errors requiring compile–repair loops.",
        "Potential over-reliance on a single detector family (GNNs) may bias the generation toward specific blind spots.",
        "Ensuring functional correctness beyond syntactic checks (need stronger equivalence/property checking) for deployment-grade use."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "TrojanGYM: an agentic, detector-in-the-loop LLM framework that curates RTL HT insertions to expose detector blind spots while preserving design correctness.",
      "Feedback-driven benchmark generation co-designed with GNN-based detectors, including syntax-aware checking and iterative refinement.",
      "Robust-GNN4TJ: improved implementation of GNN4TJ with better graph extraction, training robustness, and prediction reliability on LLM-generated HTs.",
      "Empirical results: On the most challenging TrojanGYM-generated benchmarks, Robust-GNN4TJ raises detection from 0% to 60%; TrojanGYM-generated HTs achieve up to 83.33% evasion against modern GNN-based detectors.",
      "Instantiation on SRAM, AES-128, and UART RTL designs producing diverse, functionally correct HTs; commitment to release code and artifacts post peer-review."
    ]
  },
  {
    "arxiv_id": "2601.17638v1",
    "title": "FOCA: Multimodal Malware Classification via Hyperbolic Cross-Attention",
    "authors": "Nitin Choudhury; Bikrant Bikram Pratap Maurya; Orchid Chetia Phukan; Arun Balaji Buduru",
    "abstract": "In this work, we introduce FOCA, a novel multimodal framework for malware classification that jointly leverages audio and visual modalities. Unlike conventional Euclidean-based fusion methods, FOCA is the first to exploit the intrinsic hierarchical relationships between audio and visual representations within hyperbolic space. To achieve this, raw binaries are transformed into both audio and visual representations, which are then processed through three key components: (i) a hyperbolic projection module that maps Euclidean embeddings into the Poincare ball, (ii) a hyperbolic cross-attention mechanism that aligns multimodal dependencies under curvature-aware constraints, and (iii) a Mobius addition-based fusion layer. Comprehensive experiments on two benchmark datasets-Mal-Net and CICMalDroid2020- show that FOCA consistently outperforms unimodal models, surpasses most Euclidean multimodal baselines, and achieves state-of-the-art performance over existing works.",
    "published_date": "2026-01-25",
    "pdf_link": "https://arxiv.org/pdf/2601.17638v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Android Malware Classification",
      "specific_problem": "Multimodal malware family/category classification from Android APK/dex binaries using binary-to-audio and binary-to-image representations with hyperbolic cross-attention fusion",
      "attack_types": [
        "adware",
        "banking malware",
        "SMS malware",
        "riskware",
        "spyware",
        "clicker+trojan",
        "addisplay",
        "smssend",
        "monitor",
        "ransom+trojan",
        "banker+trojan",
        "adware+trojan",
        "rogue",
        "benign (for CICMalDroid-2020)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Hyperbolic Neural Networks",
        "specific": "Hyperbolic cross-attention on the Poincaré ball",
        "novel_contribution": "First use of curvature-aware cross-attention to align audio-visual malware representations in hyperbolic space"
      },
      {
        "type": "primary",
        "category": "Hyperbolic Geometry Operations",
        "specific": "Exponential/log maps, Möbius addition and scalar multiplication",
        "novel_contribution": "Projection of Euclidean PTM embeddings into hyperbolic space and fusion via Möbius addition under curvature constraints"
      },
      {
        "type": "primary",
        "category": "Transformer/Attention",
        "specific": "Cross-attention (curvature-aware variant)",
        "novel_contribution": "Curvature-aware attention weights computed using hyperbolic distances for cross-modal alignment"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D-CNN downstream head (two conv layers + max pooling + FC)",
        "novel_contribution": "Lightweight CNN head to adapt frozen PTM features before hyperbolic projection"
      },
      {
        "type": "baseline",
        "category": "Transformer/Attention",
        "specific": "Vanilla Euclidean cross-attention",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Fusion",
        "specific": "Simple concatenation",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Self-supervised Speech Encoders",
        "specific": "Wav2Vec2 (base), WavLM (base), HuBERT (base)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet-50",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "VGG-19",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (Vision)",
        "specific": "ViT (base)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Transfer Learning"
    ],
    "datasets": [
      {
        "name": "CICMalDroid-2020",
        "type": "public",
        "domain": "android_apks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Mal-Net (10-class subset balanced at 800 samples per class)",
        "type": "public",
        "domain": "malware_images",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "AndroZoo (source of APKs mapped from Mal-Net signatures)",
        "type": "public",
        "domain": "android_apks",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Euclidean Cross-Attention (HuBERT ⊗ ViT)",
        "paper_reference": null,
        "metric": "Accuracy (%) / Macro-F1 (%) (Mal-Net)",
        "their_result": "82.84 / 81.72 (FOCA: HuBERT ⊞ ViT)",
        "baseline_result": "76.78 / 74.77"
      },
      {
        "method_name": "Euclidean Cross-Attention (HuBERT ⊗ ViT)",
        "paper_reference": null,
        "metric": "Accuracy (%) / Macro-F1 (%) (CICMalDroid-2020)",
        "their_result": "99.10 / 98.85 (FOCA: HuBERT ⊞ ViT)",
        "baseline_result": "92.21 / 91.89"
      },
      {
        "method_name": "Concatenation (HuBERT + ViT)",
        "paper_reference": null,
        "metric": "Accuracy (%) / Macro-F1 (%) (Mal-Net)",
        "their_result": "82.84 / 81.72 (FOCA: HuBERT ⊞ ViT)",
        "baseline_result": "70.66 / 67.03"
      },
      {
        "method_name": "Concatenation (HuBERT + ViT)",
        "paper_reference": null,
        "metric": "Accuracy (%) / Macro-F1 (%) (CICMalDroid-2020)",
        "their_result": "99.10 / 98.85 (FOCA: HuBERT ⊞ ViT)",
        "baseline_result": "80.16 / 79.85"
      },
      {
        "method_name": "Unimodal best (audio: HuBERT)",
        "paper_reference": null,
        "metric": "Accuracy (%) / Macro-F1 (%) (CICMalDroid-2020)",
        "their_result": "99.10 / 98.85 (FOCA: HuBERT ⊞ ViT)",
        "baseline_result": "80.98 / 78.80"
      },
      {
        "method_name": "Unimodal best (image: ViT)",
        "paper_reference": null,
        "metric": "Accuracy (%) / Macro-F1 (%) (Mal-Net)",
        "their_result": "82.84 / 81.72 (FOCA: HuBERT ⊞ ViT)",
        "baseline_result": "62.90 / 58.48"
      },
      {
        "method_name": "Samaneh et al. [22]",
        "paper_reference": "[22]",
        "metric": "Accuracy (%) / Macro-F1 (%) (Mal-Net / CICMalDroid-2020)",
        "their_result": "82.84 / 81.72 (Mal-Net, FOCA best) ; 99.10 / 98.85 (CICMalDroid-2020, FOCA best)",
        "baseline_result": "41.73 / 40.84 (Mal-Net) ; 96.73 / 97.84 (CICMalDroid-2020)"
      },
      {
        "method_name": "Scott et al. (MalNet) [23]",
        "paper_reference": "[23]",
        "metric": "Accuracy (%) / Macro-F1 (%) (Mal-Net / CICMalDroid-2020)",
        "their_result": "82.84 / 81.72 ; 99.10 / 98.85",
        "baseline_result": "70.12 / 67.71 ; 93.74 / 91.81"
      },
      {
        "method_name": "Devnath et al. (MalVis/PVTv2) [25]",
        "paper_reference": "[25]",
        "metric": "Accuracy (%) / Macro-F1 (%) (Mal-Net / CICMalDroid-2020)",
        "their_result": "82.84 / 81.72 ; 99.10 / 98.85",
        "baseline_result": "52.49 / 51.21 ; 92.74 / 93.83"
      },
      {
        "method_name": "Vasan et al. (Ensemble) [26]",
        "paper_reference": "[26]",
        "metric": "Accuracy (%) / Macro-F1 (%) (Mal-Net / CICMalDroid-2020)",
        "their_result": "82.84 / 81.72 ; 99.10 / 98.85",
        "baseline_result": "48.54 / 51.67 ; 95.71 / 96.46"
      },
      {
        "method_name": "Yang et al. (PVITNet) [27]",
        "paper_reference": "[27]",
        "metric": "Accuracy (%) / Macro-F1 (%) (Mal-Net / CICMalDroid-2020)",
        "their_result": "82.84 / 81.72 ; 99.10 / 98.85",
        "baseline_result": "53.71 / 53.65 ; 98.52 / 98.31"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Macro-F1"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can modeling the hierarchical relationship between binary-derived audio and image modalities in hyperbolic space improve malware classification?",
        "Does curvature-aware cross-attention provide more effective multimodal alignment than Euclidean fusion (concatenation or vanilla cross-attention)?",
        "How do different pretrained audio and vision encoders affect multimodal malware classification performance?"
      ],
      "gaps_identified": [
        "Prior multimodal malware works do not exploit implicit hierarchical relationships between audio and visual modalities during fusion.",
        "Audio representations for malware are underexplored and often restricted to spectrograms derived from traditional signal processing, limiting expressiveness.",
        "Existing fusion strategies are predominantly Euclidean (concatenation, feed-forward integration, vanilla cross-modal attention)."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve robustness and accuracy of malware family classification by jointly leveraging audio and visual modalities and explicitly modeling their hierarchy using hyperbolic geometry.",
      "potential_research_ideas": [
        "Extend FOCA to incorporate additional modalities (e.g., opcode n-grams, API call sequences, control flow graphs) using a unified hyperbolic multimodal fusion framework.",
        "Learn the curvature parameter and projection strategy end-to-end (learnable hyperbolic geometry) to adapt curvature to data.",
        "Develop hyperbolic contrastive pretraining that aligns binary-to-audio and binary-to-image representations before supervised fine-tuning.",
        "Open-set and zero-day malware detection using hyperbolic distance thresholds and hierarchical family taxonomies.",
        "Adversarially robust multimodal fusion with hyperbolic adversarial training to resist perturbations in audio/image transformations.",
        "Hierarchical label-aware losses (e.g., hyperbolic tree embeddings of malware families) to exploit inter-family relationships.",
        "Online/streaming classification with incremental updates in hyperbolic space for evolving malware datasets.",
        "Integrate dynamic analysis traces (system/API call sequences) via hyperbolic sequence encoders (e.g., hyperbolic transformers)."
      ],
      "architectural_improvement_recommendations": [
        "Make curvature (c) learnable per attention head and/or per modality to better fit local geometry.",
        "Hybrid attention: combine Euclidean self-attention within each modality with hyperbolic cross-attention across modalities.",
        "Fine-tune PTMs (Wav2Vec2/HuBERT/WavLM and ViT) on binary-derived audio/image data with low LR and layer-wise unfreezing to boost representation quality.",
        "Introduce gating to balance modality contributions based on confidence/entropy, implemented with Möbius gated fusion.",
        "Use hierarchical label embeddings (Poincaré embeddings of malware family tree) and align fused features to label embeddings with hyperbolic margin losses.",
        "Add cross-modal hyperbolic residual connections and multi-head HCA to increase capacity without sacrificing geometric consistency.",
        "Calibrate outputs with temperature scaling and hyperbolic metric learning for improved decision boundaries."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/nitinc24009/FOCA.git",
      "frameworks": [
        "Hugging Face Transformers"
      ],
      "reproducibility_score": "high",
      "computational_requirements": "2.7M–4.5M trainable parameters depending on PTM dims; Adam optimizer, lr=1e-5, batch size=32, 50 epochs; 5-fold cross-validation; dropout and early stopping."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First to explore and explicitly model the hierarchical relationship between audio and visual modalities for malware classification using hyperbolic space.",
      "Proposed FOCA: a multimodal framework with hyperbolic projection, hyperbolic cross-attention, and Möbius addition-based fusion.",
      "Comprehensive experiments on Mal-Net and CICMalDroid-2020 showing consistent gains over unimodal and Euclidean multimodal baselines; achieves new SOTA.",
      "Released code and trained models for reproducibility."
    ]
  },
  {
    "arxiv_id": "2601.16458v1",
    "title": "Bridging Expert Reasoning and LLM Detection: A Knowledge-Driven Framework for Malicious Packages",
    "authors": "Wenbo Guo; Shiwen Song; Jiaxun Guo; Zhengzi Xu; Chengwei Liu; Haoran Ou; Mengmeng Ge; Yang Liu",
    "abstract": "Open-source ecosystems such as NPM and PyPI are increasingly targeted by supply chain attacks, yet existing detection methods either depend on fragile handcrafted rules or data-driven features that fail to capture evolving attack semantics. We present IntelGuard, a retrieval-augmented generation (RAG) based framework that integrates expert analytical reasoning into automated malicious package detection. IntelGuard constructs a structured knowledge base from over 8,000 threat intelligence reports, linking malicious code snippets with behavioral descriptions and expert reasoning. When analyzing new packages, it retrieves semantically similar malicious examples and applies LLM-guided reasoning to assess whether code behaviors align with intended functionality. Experiments on 4,027 real-world packages show that IntelGuard achieves 99% accuracy and a 0.50% false positive rate, while maintaining 96.5% accuracy on obfuscated code. Deployed on PyPI.org, it discovered 54 previously unreported malicious packages, demonstrating interpretable and robust detection guided by expert knowledge.",
    "published_date": "2026-01-23",
    "pdf_link": "https://arxiv.org/pdf/2601.16458v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Supply Chain Security",
      "subdomain": "Malicious Package Detection",
      "specific_problem": "Pre-installation detection of malicious open-source packages (PyPI/npm) via static analysis augmented with expert reasoning through RAG",
      "attack_types": [
        "typosquatting",
        "dependency confusion",
        "supply chain poisoning",
        "credential theft/exfiltration",
        "data exfiltration",
        "backdoor installation/payload execution",
        "abuse of installation scripts",
        "obfuscation/encoding",
        "C2/network exfiltration"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Retrieval-Augmented Generation (RAG)",
        "specific": null,
        "novel_contribution": "Structured knowledge base built from 8,024 threat reports linking code snippets to behavioral descriptions and expert reasoning; semantic retrieval of similar malicious contexts to guide LLM analysis"
      },
      {
        "type": "primary",
        "category": "Large Language Model (LLM) reasoning",
        "specific": null,
        "novel_contribution": "LLM-guided code slicing and consistency checking of code behaviors vs. intended functionality; RAG-based reasoning to reduce hallucination and improve interpretability"
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "HDBSCAN",
        "novel_contribution": "Two-level hierarchical clustering over dual embeddings (code syntax embeddings and behavioral/reasoning embeddings) to merge functionally equivalent malicious behaviors for efficient retrieval"
      },
      {
        "type": "primary",
        "category": "Representation Learning/Embeddings",
        "specific": null,
        "novel_contribution": "Dual representations capturing both syntactic structure and behavioral semantics for retrieval"
      },
      {
        "type": "baseline",
        "category": "Dynamic sequence modeling",
        "specific": "DONAPI",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (fine-tuned)",
        "specific": "BERT (Cerebro)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph-based behavior modeling",
        "specific": "SpiderScan",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM reasoning",
        "specific": "Direct LLM analysis without RAG",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Zero-shot",
      "Retrieval-Augmented Inference",
      "Unsupervised (clustering)",
      "Static analysis with LLM reasoning"
    ],
    "datasets": [
      {
        "name": "IntelGuard Knowledge Base from Threat Intelligence Reports (8,024 reports; 4,420 malicious code contexts after filtering/validation)",
        "type": "public",
        "domain": "threat_intel_reports",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "IntelGuard Evaluation Dataset (4,027 real-world packages: 2,000 PyPI + 2,027 npm)",
        "type": "public",
        "domain": "package_source_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Obfuscated Code Samples (subset of evaluation set used for robustness testing)",
        "type": "synthetic",
        "domain": "obfuscated_package_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Open Source Vulnerabilities (OSV) database (seed list of confirmed malicious packages)",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://osv.dev",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Direct LLM analysis (no RAG)",
        "paper_reference": null,
        "metric": "Accuracy on obfuscated code",
        "their_result": "96.5%",
        "baseline_result": "52.82%"
      },
      {
        "method_name": "Rule-based static/dynamic analysis tools",
        "paper_reference": null,
        "metric": "False Positive Rate",
        "their_result": "0.50% (IntelGuard)",
        "baseline_result": "up to 6.5%"
      },
      {
        "method_name": "DONAPI",
        "paper_reference": "[18]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Cerebro (fine-tuned BERT)",
        "paper_reference": "[53]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "SpiderScan",
        "paper_reference": "[20]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "false positive rate"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can expert analytical reasoning from threat intelligence reports be transformed into a structured knowledge base to guide LLM-based malicious package detection?",
        "Does retrieval-augmented generation (RAG) reduce LLM hallucination and improve interpretability and robustness for malicious package detection?",
        "How does IntelGuard perform versus rule-based, learning-based, and LLM-only baselines on real-world packages and under obfuscation?",
        "Can the approach discover previously unknown malicious packages in a live ecosystem (PyPI)?"
      ],
      "gaps_identified": [
        "Rule-based methods require costly maintenance and are brittle against evolving attack semantics.",
        "Learning-based methods suffer from concept drift and rely on low-level statistical features that become outdated.",
        "LLM-based detectors lack systematic expert reasoning and contextual threat intelligence and suffer from hallucinations.",
        "Threat intelligence reports contain valuable expert reasoning that remains locked in unstructured formats and is inaccessible to automated systems."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Bridge human expert reasoning and LLM detection to achieve interpretable, robust, and context-aware detection of malicious packages in open-source ecosystems.",
      "potential_research_ideas": [
        "Augment the knowledge base with runtime/dynamic traces to jointly reason over static and dynamic behaviors in RAG.",
        "Automatically align extracted reasoning chains to MITRE ATT&CK and code property graphs to enable multi-view consistency checks.",
        "Develop active retrieval strategies that learn to query for missing evidence and reduce dependence on initial slices.",
        "Investigate continual/online updates of the knowledge base to handle emerging attack techniques while preserving calibration.",
        "Explore adversarially robust prompts and retrieval defenses against prompt/knowledge poisoning.",
        "Leverage small domain LMs fine-tuned on validated reasoning chains to lower inference cost while preserving interpretability.",
        "Cross-ecosystem generalization: extend to other registries (e.g., RubyGems, NuGet) and measure transfer.",
        "Integrate uncertainty estimation/calibration to gate automated takedown suggestions vs. human analyst review."
      ],
      "architectural_improvement_recommendations": [
        "Incorporate code property graphs and inter-procedural slicing to enrich retrieval signals beyond sensitive-API-centric slices.",
        "Train a lightweight reranker (e.g., cross-encoder) on validated reasoning pairs to improve retrieval precision before LLM reasoning.",
        "Instruction-tune an LLM on curated expert reasoning chains to reduce reliance on large proprietary models and improve determinism.",
        "Introduce a verification layer with symbolic checks (e.g., dataflow assertions) to validate LLM claims in the reasoning output.",
        "Adopt continual learning for the knowledge base with temporal indexing and decay to mitigate concept drift.",
        "Cache and reuse reasoning for repeated patterns with a feedback loop to update retrieval clusters incrementally."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Public package registry scanning (PyPI.org pre-installation scanning)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "LLM hallucination risk in absence of retrieval grounding",
        "Handling code obfuscation in real-world packages",
        "Ensuring high-quality knowledge extraction and validation from heterogeneous threat reports"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Knowledge-driven detection that extracts expert reasoning from threat intelligence and applies it via RAG for interpretable detection.",
      "Construction of a comprehensive knowledge base from 8,024 reports with 4,420 malicious code contexts and expert reasoning chains.",
      "Empirical results on 4,027–4,087 packages showing \"99% accuracy\" and \"0.50% false positive rate\"; robust to obfuscation with \"96.5% accuracy\" vs. \"52.82%\" for direct LLM.",
      "Real-world deployment on PyPI.org discovering 54 previously unreported malicious packages (24 confirmed and removed)."
    ]
  },
  {
    "arxiv_id": "2601.07276v2",
    "title": "A High-Recall Cost-Sensitive Machine Learning Framework for Real-Time Online Banking Transaction Fraud Detection",
    "authors": "Karthikeyan V. R.; Premnath S.; Kavinraaj S.; J. Sangeetha",
    "abstract": "Fraudulent activities on digital banking services are becoming more intricate by the day, challenging existing defenses. While older rule driven methods struggle to keep pace, even precision focused algorithms fall short when new scams are introduced. These tools typically overlook subtle shifts in criminal behavior, missing crucial signals. Because silent breaches cost institutions far more than flagged but legitimate actions, catching every possible case is crucial. High sensitivity to actual threats becomes essential when oversight leads to heavy losses. One key aim here involves reducing missed fraud cases without spiking incorrect alerts too much. This study builds a system using group learning methods adjusted through smart threshold choices. Using real world transaction records shared openly, where cheating acts rarely appear among normal activities, tests are run under practical skewed distributions. The outcomes reveal that approximately 98 percent of actual fraud is detected, outperforming standard setups that rely on unchanging rules when dealing with uneven examples across classes. When tested in live settings, the fraud detection system connects directly to an online banking transaction flow, stopping questionable activities before they are completed. Alongside this setup, a browser add on built for Chrome is designed to flag deceptive web links and reduce threats from harmful sites. These results show that adjusting decisions by cost impact and validating across entire systems makes deployment more stable and realistic for today's digital banking platforms.",
    "published_date": "2026-01-12",
    "pdf_link": "https://arxiv.org/pdf/2601.07276v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Financial/Banking Security",
      "subdomain": "Transaction Fraud Detection",
      "specific_problem": "Real-time online banking transaction fraud detection with high-recall, cost-sensitive decisioning and threshold optimization",
      "attack_types": [
        "Fraudulent transactions",
        "Account takeover",
        "Phishing-induced fraud"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble",
        "specific": null,
        "novel_contribution": "Cost-sensitive decision threshold optimization atop an ensemble of classifiers to maximize recall under heavy class imbalance; integrated into real-time transaction pipeline"
      },
      {
        "type": "primary",
        "category": "Hybrid Deep Learning + Rules",
        "specific": null,
        "novel_contribution": "Auxiliary phishing-URL detection as a Chrome extension combining a deep model with rule-based heuristics; decoupled from transaction engine for layered defense"
      },
      {
        "type": "baseline",
        "category": "Rule-based System",
        "specific": "Static thresholds/rules",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Cost-sensitive",
      "Ensemble"
    ],
    "datasets": [
      {
        "name": "Unspecified public transaction datasets from UCI",
        "type": "public",
        "domain": "financial_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Unspecified public transaction datasets from Kaggle",
        "type": "public",
        "domain": "financial_transactions",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Static rule-based fraud detection (unchanging rules/thresholds)",
        "paper_reference": null,
        "metric": "Recall (True Positive Rate); qualitative cost-sensitivity",
        "their_result": "“approximately 98% of actual fraud was caught”",
        "baseline_result": null
      },
      {
        "method_name": "Fixed 0.5-threshold classifier (non cost-sensitive)",
        "paper_reference": null,
        "metric": "Recall vs False Positive Rate; PR/ROC behavior",
        "their_result": "“approximately 98% of actual fraud was caught”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Recall (Sensitivity)",
      "Precision",
      "False Positive Rate",
      "Confusion Matrix",
      "Precision-Recall curve",
      "ROC curve",
      "Threshold-response analysis",
      "Cost-based expected misclassification cost"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to maximize fraud recall (minimize false negatives) under extreme class imbalance while keeping false positives operationally acceptable in real-time banking?",
        "Can cost-sensitive threshold optimization on ensembles improve detection compared to fixed thresholds/rule-based systems?",
        "How does a recall-driven system behave when integrated into a live online banking transaction pipeline?"
      ],
      "gaps_identified": [
        "Over-reliance on overall accuracy in prior work despite severe class imbalance",
        "Use of fixed decision thresholds (e.g., 0.5) without cost sensitivity",
        "Limited evaluation in live, end-to-end banking environments",
        "Phishing defenses often siloed from transaction-fraud systems"
      ],
      "limitations": [
        "Specific base models within the ensemble are not detailed in the provided text",
        "No comprehensive quantitative breakdown (precision/FPR/AUC) beyond the quoted recall is provided",
        "Public datasets referenced are unspecified; dataset linkage and exact schema are not detailed",
        "Computational and latency measurements for real-time deployment are not reported"
      ],
      "future_work": [],
      "motivation": "Silent/undetected frauds are far costlier than false alarms; thus, recall-centric, cost-sensitive detection aligned with operational realities is needed and must work in real-time banking flows.",
      "potential_research_ideas": [
        "Online/dynamic thresholding that adapts to cost drift and data drift using streaming calibration and drift detectors",
        "End-to-end cost-sensitive training (e.g., focal/weighted losses) rather than post-hoc thresholding; compare to decision-theoretic Bayes risk minimization",
        "User/session-level temporal models (RNN/Transformer/Temporal GNN) for sequential patterns in transactions and login/device behaviors",
        "Probabilistic calibration (isotonic/Platt/temperature scaling) with uncertainty estimation to inform human-in-the-loop triage",
        "Federated and privacy-preserving learning for cross-bank collaboration without data sharing",
        "Robustness against adversarial manipulation/poisoning of transaction features and phishing pages",
        "Causal inference to disentangle spurious correlations in imbalanced fraud data",
        "Joint modeling of phishing telemetry and transaction risk via multi-view/multimodal architectures"
      ],
      "architectural_improvement_recommendations": [
        "Introduce automated drift detection (data and concept drift) with scheduled re-optimization of thresholds and re-training",
        "Use stacked/weighted ensembles with meta-learners and calibrated probability outputs",
        "Incorporate cost-sensitive losses during training and compare against post-hoc thresholding for stability",
        "Deploy probability calibration (isotonic/Platt) and conformal prediction for calibrated risk and coverage guarantees",
        "Add a feature store and streaming inference architecture (e.g., Kafka/Flink) with low-latency model serving",
        "Integrate model monitoring for recall@operating-point, alert volumes, and cost metrics with canary/A-B rollout",
        "Leverage sequence/graph features (e.g., device-IP-merchant graphs) with GNNs for relation-aware fraud signals",
        "Enrich phishing module with modern lightweight transformers and URL/HTML/WHOIS/JARM features with continual learning"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Integrated into a live online banking transaction execution pipeline; auxiliary Chrome browser extension for phishing URL detection",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Integration with critical transaction pipelines while meeting latency requirements",
        "Cost-sensitive threshold selection and ongoing tuning under drift",
        "Handling severe class imbalance in production",
        "Operational separation and compliance boundaries between web monitoring and transaction systems",
        "Minimizing integration complexity, compliance risk, and downtime during updates"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A high-recall, cost-sensitive fraud detection framework using ensemble learning with decision threshold optimization",
      "End-to-end real-time integration into an online banking transaction pipeline for immediate enforcement",
      "System-level validation under practical imbalanced distributions with time-ordered train/test splitting",
      "Auxiliary phishing URL detection Chrome extension (hybrid deep learning + heuristics) as a layered defense",
      "Empirical result: “approximately 98% of actual fraud was caught,” outperforming standard rule-based/static-threshold setups"
    ]
  },
  {
    "arxiv_id": "2601.18068v1",
    "title": "XGuardian: Towards Explainable and Generalized AI Anti-Cheat on FPS Games",
    "authors": "Jiayi Zhang; Chenxin Sun; Chenxiong Qian",
    "abstract": "Aim-assist cheats are the most prevalent and infamous form of cheating in First-Person Shooter (FPS) games, which help cheaters illegally reveal the opponent's location and auto-aim and shoot, and thereby pose significant threats to the game industry. Although a considerable research effort has been made to automatically detect aim-assist cheats, existing works suffer from unreliable frameworks, limited generalizability, high overhead, low detection performance, and a lack of explainability of detection results. In this paper, we propose XGuardian, a server-side generalized and explainable system for detecting aim-assist cheats to overcome these limitations. It requires only two raw data inputs, pitch and yaw, which are all FPS games' must-haves, to construct novel temporal features and describe aim trajectories, which are essential for distinguishing cheaters and normal players. XGuardian is evaluated with the latest mainstream FPS game CS2, and validates its generalizability with another two different games. It achieves high detection performance and low overhead compared to prior works across different games with real-world and large-scale datasets, demonstrating wide generalizability and high effectiveness. It is able to justify its predictions and thereby shorten the ban cycle. We make XGuardian as well as our datasets publicly available.",
    "published_date": "2026-01-26",
    "pdf_link": "https://arxiv.org/pdf/2601.18068v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Application Security",
      "subdomain": "Game Anti-Cheat",
      "specific_problem": "Server-side detection of aim-assist cheats in FPS games using pitch/yaw aiming trajectories",
      "attack_types": [
        "aim-assist",
        "aimbot",
        "triggerbot",
        "wallhack"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "RNN-CNN hybrid",
        "specific": "GRU-CNN",
        "novel_contribution": "Temporal classification of generalized pitch/yaw-derived trajectory features (velocity, acceleration, angular change) for per-elimination cheating detection"
      },
      {
        "type": "primary",
        "category": "Explainability",
        "specific": "SHAP (GradientExplainer, TreeExplainer)",
        "novel_contribution": "Customized SHAP-based per-elimination and per-match explanations to pinpoint suspicious frames and feature contributions"
      },
      {
        "type": "baseline",
        "category": "Ensemble Learning",
        "specific": "Multi-view ensemble (HAWK [63])",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Unsupervised Anomaly Detection",
        "specific": "Angle anomaly detection [7]",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Traditional ML (statistical classification)",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CS2 (Counter-Strike 2) aiming/elimination trajectories",
        "type": "public",
        "domain": "game_replay_files",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Farlight84 aiming/elimination trajectories",
        "type": "public",
        "domain": "game_replay_files",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Multi-view Ensemble Learning (HAWK)",
        "paper_reference": "[63]",
        "metric": "accuracy",
        "their_result": "“improves detection accuracy by 12.5% over the state-of-the-art method”",
        "baseline_result": null
      },
      {
        "method_name": "Angle Anomaly Detection (client-side, SGX-based)",
        "paper_reference": "[7]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Statistical Classification (client-side)",
        "paper_reference": "[61,62]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Statistical Classification (server-side)",
        "paper_reference": "[2,22,30]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "recall",
      "false positive rate (FPR)",
      "accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a server-side, generalized model that uses only pitch and yaw detect aim-assist cheats effectively across different FPS games?",
        "Can per-elimination temporal modeling of aiming trajectories achieve high detection performance on large-scale real-world data?",
        "Can the system provide actionable, interpretable explanations to reduce manual review time?",
        "How well does the approach generalize across FPS sub-genres and platforms (PC and mobile)?",
        "Is the detector robust to adversarial attempts to evade detection?"
      ],
      "gaps_identified": [
        "Client-side dependency and resource constraints leading to bypass and overhead (L1)",
        "Limited real-world performance due to evaluation on small-scale, simulated datasets (L2)",
        "Limited generalizability across FPS sub-genres and engines due to non-general features (L3)",
        "Lack of explainability for practical ban justification and efficient human review (L4)"
      ],
      "limitations": [
        "Threat model acknowledges the impossibility of exhaustively evaluating all cheat variants: “we cannot exhaustively evaluate every possible cheat variant beyond our dataset”",
        "Only ‘somewhat robust’ under adversarial attacks (indicating room for stronger robustness)",
        "Server-side solutions require cooperation from game developers for access to replay/data pipelines"
      ],
      "future_work": [],
      "motivation": "Address unreliable client-side frameworks, improve real-world performance, enable cross-game generalization using only pitch/yaw, and add actionable explainability to shorten the ban cycle.",
      "potential_research_ideas": [
        "Domain adaptation and meta-learning to further improve cross-game generalization without re-training",
        "Self-supervised pretraining on large unlabeled pitch/yaw time-series for improved representations",
        "Extend to other cheat categories (e.g., movement/physics exploits) using generalized kinematic features",
        "Robust training against adaptive adversaries (e.g., adversarial augmentation, randomized smoothing)",
        "Human-in-the-loop systems that combine explanations with active learning to refine labels",
        "Real-time or near-real-time streaming detection from live telemetry with latency constraints",
        "Cross-modal fusion with non-invasive features (weapon, map context, team dynamics) while preserving generality"
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment GRU-CNN with temporal transformers or Conformer-style blocks for long-range dependencies",
        "Add attention-based instance attribution to complement SHAP for per-tick importance",
        "Contrastive learning objectives (e.g., SimCLR/TS-TCC) on trajectories to improve invariance across games and devices",
        "Per-weapon and per-input-device adapters (LoRA-style) to specialize decision boundaries",
        "Calibrated decision thresholds with cost-sensitive learning to trade off recall/FPR by context",
        "Change-point detection to isolate suspicious segments before classification to improve precision",
        "Model compression and quantization-aware training for scalable server-side inference"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": "Server-side, post-match asynchronous processing; reported as ‘marginal overhead on the server’."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Server-side, post-match analysis using replay files from an active platform with millions of users",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires cooperation from game developers/platforms for access to replay pipelines and labels",
        "Replay parsing and standardization across different engines/formats",
        "Integrating explanations into moderator workflows and calibrating thresholds to manage false positives",
        "Potential adversarial adaptation to evade per-elimination trajectory modeling"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Server-side generalized anti-cheat system (XGuardian) requiring only pitch and yaw as raw inputs",
      "Novel temporal feature design capturing velocity, acceleration, and angular change of aiming trajectories",
      "Time-series GRU-CNN classifier with an explainability framework based on SHAP and tailored visualizations",
      "Large-scale real-world evaluation on CS2 with high performance: “up to 90.7% recall while maintaining a false positive rate (FPR) of 4.1%”",
      "Demonstrated cross-game generalizability across different FPS sub-genres and platforms (PC and mobile)",
      "Empirical indication of some robustness under adversarial attacks",
      "Low server-side overhead via asynchronous post-match processing",
      "Open-sourced code and release of two new datasets (CS2, Farlight84)"
    ]
  },
  {
    "arxiv_id": "2601.09287v1",
    "title": "Explainable Autoencoder-Based Anomaly Detection in IEC 61850 GOOSE Networks",
    "authors": "Dafne Lozano-Paredes; Luis Bote-Curiel; Juan Ramón Feijóo-Martínez; Ismael Gómez-Talal; José Luis Rojo-Álvarez",
    "abstract": "The IEC 61850 Generic Object-Oriented Substation Event (GOOSE) protocol plays a critical role in real-time protection and automation of digital substations, yet its lack of native security mechanisms can expose power systems to sophisticated cyberattacks. Traditional rule-based and supervised intrusion detection techniques struggle to detect protocol-compliant and zero-day attacks under significant class imbalance and limited availability of labeled data. This paper proposes an explainable, unsupervised multi-view anomaly detection framework for IEC 61850 GOOSE networks that explicitly separates semantic integrity and temporal availability. The approach employs asymmetric autoencoders trained only on real operational GOOSE traffic to learn distinct latent representations of sequence-based protocol semantics and timing-related transmission dynamics in normal traffic. Anomaly detection is implemented using reconstruction errors mixed with statistically grounded thresholds, enabling robust detection without specified attack types. Feature-level reconstruction analysis provides intrinsic explainability by directly linking detection outcomes to IEC 61850 protocol characteristics. The proposed framework is evaluated using real substation traffic for training and a public dataset containing normal traffic and message suppression, data manipulation, and denial-of-service attacks for testing. Experimental results show attack detection rates above 99% with false positives remaining below 5% of total traffic, demonstrating strong generalization across environments and effective operation under extreme class imbalance and interpretable anomaly attribution.",
    "published_date": "2026-01-14",
    "pdf_link": "https://arxiv.org/pdf/2601.09287v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Industrial Control Systems Security",
      "subdomain": "Intrusion Detection for Power Substations (IEC 61850)",
      "specific_problem": "Unsupervised anomaly detection in IEC 61850 GOOSE traffic by separating semantic integrity and temporal availability",
      "attack_types": [
        "Message Suppression (MS)",
        "Data Manipulation (DM)",
        "Denial-of-Service (DoS)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": "Asymmetric autoencoders with multi-view (sequence vs temporal) representations",
        "novel_contribution": "Explicit separation of sequence-based protocol semantics and timing-related dynamics with statistically grounded dynamic thresholds and feature-level reconstruction explainability"
      },
      {
        "type": "primary",
        "category": "Dimensionality Reduction / Manifold Learning",
        "specific": "UMAP",
        "novel_contribution": "Used for exploratory analysis of separability in raw and learned feature spaces (diagnostic, not part of detection)"
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Real-World GOOSE Dataset from an IEC 61850 Substation (REDEIA Group environment)",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "IEC61850SecurityDataset (Biswas et al., 2019)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Detection rate (True Positive Rate/Recall)",
      "False Positive Rate (FPR)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can an unsupervised multi-view autoencoder that separately models sequence semantics and temporal dynamics detect anomalies in IEC 61850 GOOSE traffic without labeled attacks?",
        "Does separating semantic integrity from temporal availability improve robustness to class imbalance and zero-day/protocol-compliant attacks?",
        "Can feature-level reconstruction errors provide intrinsic, protocol-aligned explainability for detected anomalies?",
        "Does a model trained on real substation benign traffic generalize to a different environment and public attack datasets?"
      ],
      "gaps_identified": [
        "GOOSE lacks native authentication/encryption, exposing substations to protocol-compliant attacks.",
        "Rule-based and signature-based IDS struggle to detect zero-day and stealthy protocol-compliant attacks.",
        "Supervised ML requires labeled attack data that are scarce in operational OT environments and suffers from class imbalance.",
        "Limited interpretability of existing ML/DL anomaly detectors for IEC 61850 traffic."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Provide an explainable, unsupervised anomaly detector for IEC 61850 GOOSE that is robust to class imbalance and lack of labeled attacks by explicitly modeling semantic integrity and temporal availability.",
      "potential_research_ideas": [
        "Extend multi-view modeling to include additional IEC 61850 services (SV, MMS) with cross-protocol correlation for multi-modal anomaly detection.",
        "Develop online adaptive thresholding using extreme value theory or Bayesian uncertainty estimates to maintain performance under concept drift.",
        "Incorporate contrastive/self-supervised pretraining on benign traffic to improve latent representations and generalization.",
        "Leverage graph neural networks to model IED-to-IED relationships and topology-aware GOOSE flows for context-aware detection.",
        "Add active learning with operator feedback to refine the detector and label ambiguous windows with minimal annotation cost.",
        "Evaluate and harden against adversarial manipulation of traffic statistics (evasion), including generative attack simulations.",
        "Implement real-time, streaming inference on substation-grade hardware with latency guarantees and bounded memory footprint."
      ],
      "architectural_improvement_recommendations": [
        "Fuse the two views via an attention-based or gating mechanism to learn dynamic weighting between semantic and temporal errors per context.",
        "Replace feed-forward AEs with temporal models (Temporal Convolutional Networks or LSTM/Transformer AEs) for richer timing dynamics.",
        "Use joint multi-task training that predicts stNum/sqNum evolution alongside reconstruction to regularize semantic consistency.",
        "Adopt per-flow normalization and domain adaptation (e.g., CORAL/MMD losses) to improve cross-substation generalization.",
        "Calibrate anomaly scores with EVT-based tail modeling instead of fixed statistical thresholds to reduce false positives.",
        "Integrate post-hoc explanation tools (e.g., SHAP on reconstruction residuals) to complement intrinsic explainability."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Strict millisecond-level latency requirements in substations for protection functions.",
        "Severe class imbalance and scarcity of labeled attacks in operational OT environments.",
        "Generalization across different substations and device configurations.",
        "Protocol lacks native security; attackers can craft protocol-compliant traffic."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "An explainable, unsupervised multi-view anomaly detection framework for IEC 61850 GOOSE that explicitly separates semantic integrity and temporal availability.",
      "Asymmetric autoencoders trained only on real operational GOOSE traffic to learn distinct latent representations for sequence semantics and timing dynamics.",
      "Detection via reconstruction errors with statistically grounded thresholds, avoiding dependence on labeled attacks.",
      "Feature-level reconstruction analysis that links anomalies to IEC 61850 protocol characteristics for intrinsic interpretability.",
      "Evaluation using real substation traffic for training and a public dataset with message suppression, data manipulation, and DoS attacks for testing.",
      "Reported results: \"attack detection rates above 99% with false positives remaining below 5% of total traffic,\" indicating generalization across environments and effective operation under extreme class imbalance."
    ]
  },
  {
    "arxiv_id": "2601.14556v1",
    "title": "Constructing Multi-label Hierarchical Classification Models for MITRE ATT&CK Text Tagging",
    "authors": "Andrew Crossman; Jonah Dodd; Viralam Ramamurthy Chaithanya Kumar; Riyaz Mohammed; Andrew R. Plummer; Chandra Sekharudu; Deepak Warrier; Mohammad Yekrangian",
    "abstract": "MITRE ATT&CK is a cybersecurity knowledge base that organizes threat actor and cyber-attack information into a set of tactics describing the reasons and goals threat actors have for carrying out attacks, with each tactic having a set of techniques that describe the potential methods used in these attacks. One major application of ATT&CK is the use of its tactic and technique hierarchy by security specialists as a framework for annotating cyber-threat intelligence reports, vulnerability descriptions, threat scenarios, inter alia, to facilitate downstream analyses. To date, the tagging process is still largely done manually. In this technical note, we provide a stratified \"task space\" characterization of the MITRE ATT&CK text tagging task for organizing previous efforts toward automation using AIML methods, while also clarifying pathways for constructing new methods. To illustrate one of the pathways, we use the task space strata to stage-wise construct our own multi-label hierarchical classification models for the text tagging task via experimentation over general cyber-threat intelligence text -- using shareable computational tools and publicly releasing the models to the security community (via https://github.com/jpmorganchase/MITRE_models). Our multi-label hierarchical approach yields accuracy scores of roughly 94% at the tactic level, as well as accuracy scores of roughly 82% at the technique level. The models also meet or surpass state-of-the-art performance while relying only on classical machine learning methods -- removing any dependence on LLMs, RAG, agents, or more complex hierarchical approaches. Moreover, we show that GPT-4o model performance at the tactic level is significantly lower (roughly 60% accuracy) than our own approach. We also extend our baseline model to a corpus of threat scenarios for financial applications produced by subject matter experts.",
    "published_date": "2026-01-21",
    "pdf_link": "https://arxiv.org/pdf/2601.14556v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Threat Intelligence",
      "subdomain": "ATT&CK Tagging",
      "specific_problem": "Multi-label hierarchical classification of MITRE ATT&CK tactics and techniques from cyber-threat intelligence text",
      "attack_types": [
        "Defense Evasion",
        "Discovery",
        "Persistence",
        "Initial Access",
        "Collection",
        "Execution",
        "Lateral Movement",
        "Impact",
        "Command and Control",
        "Credential Access",
        "Privilege Escalation",
        "Reconnaissance",
        "Resource Development",
        "Exfiltration"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Linear SVM / Linear Classifier",
        "specific": "scikit-learn SGDClassifier",
        "novel_contribution": "Stage-wise 'bottom-up' construction of a two-level multi-label hierarchical pipeline: top-n tactic prediction followed by tactic-specific technique classifiers; focuses on classical ML without LLMs"
      },
      {
        "type": "primary",
        "category": "Feature Engineering",
        "specific": "TF-IDF vectorization",
        "novel_contribution": "Includes a hashing-based text encryption step during vectorization for data security"
      },
      {
        "type": "primary",
        "category": "Multi-label Classification (Problem Transformation)",
        "specific": "Top-n prediction as multi-label transformation of multiclass classifier",
        "novel_contribution": "Uses top-n (n=3) selection to approximate multi-label at tactic level and feed hierarchical stage"
      },
      {
        "type": "primary",
        "category": "Hierarchical Classification",
        "specific": "Cascaded classifiers (tactic -> technique)",
        "novel_contribution": "Technique classifiers are conditioned on predicted tactics to output top-m techniques per tactic"
      },
      {
        "type": "baseline",
        "category": "Large Language Model",
        "specific": "GPT-4o (Text-to-Text prompting)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "JPMC cyber-intelligence sentences (14,405)",
        "type": "proprietary",
        "domain": "cyber_threat_intel_text",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "JPMC financial application threat scenarios (552 scenarios; 486 with tactic labels, 306 single-labeled)",
        "type": "proprietary",
        "domain": "threat_scenarios_text",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "MITRE ATT&CK Enterprise Matrix v14 (label space)",
        "type": "public",
        "domain": "knowledge_base_labels",
        "link": "https://attack.mitre.org",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GPT-4o",
        "paper_reference": null,
        "metric": "Accuracy (tactic-level, multiclass)",
        "their_result": "0.8195",
        "baseline_result": "0.59"
      },
      {
        "method_name": "GPT-4o",
        "paper_reference": null,
        "metric": "F1 (tactic-level, multiclass)",
        "their_result": "0.7795",
        "baseline_result": "0.60"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1",
      "Top-n accuracy (n=3)",
      "Per-class (per-tactic) accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "MITRE ATT&CK text tagging is still largely manual.",
        "Early taxonomy/knowledge-graph approaches are rigid/inflexible for CTI text.",
        "TRAM restricts tagging to technique level and does not cover full hierarchy.",
        "rcATT does not utilize hierarchical relationships during classification (only post-processing)."
      ],
      "limitations": [
        "Class imbalance and sparsity in datasets are present and left as-is to replicate real-world conditions.",
        "Technique-level evaluation uses multiclass transformations rather than fully multi-label ground truth.",
        "Comparative evaluation shown includes GPT-4o; broader SOTA comparisons are referenced but not detailed in provided text."
      ],
      "future_work": [
        "Extend the multi-label hierarchical approach to Text-to-Text classification.",
        "Reuse baseline models to bootstrap modeling on new datasets (demonstrated with financial threat scenarios)."
      ],
      "motivation": "Automate and organize MITRE ATT&CK tagging of cyber-threat intelligence to reduce analyst toil, provide a clear task space for methods, and release shareable, lightweight models without reliance on LLMs.",
      "potential_research_ideas": [
        "Incorporate contextual embeddings (e.g., sentence-transformers) while retaining a lightweight linear classifier to assess gains over TF-IDF.",
        "Develop an algorithm-adaptation multi-label hierarchical model with joint loss that enforces tactic-technique consistency during training.",
        "Introduce active learning with analyst-in-the-loop feedback (as in rcATT UI concept) to efficiently label new CTI domains.",
        "Explore domain adaptation from general CTI to sector-specific corpora (e.g., finance, healthcare) and multilingual CTI.",
        "Model sub-techniques explicitly and evaluate three-level hierarchy (tactic -> technique -> sub-technique).",
        "Design a public benchmark with standardized train/test splits for tactic/technique multi-label hierarchical tagging.",
        "Evaluate robustness to paraphrase, obfuscation, and noisy CTI text; add adversarial training for textual perturbations.",
        "Add explanation modules (e.g., feature attribution for terms contributing to a tactic/technique) to aid analyst trust."
      ],
      "architectural_improvement_recommendations": [
        "Replace TF-IDF with pretrained embeddings (e.g., SBERT) and fine-tune a one-vs-rest linear classifier for multi-label outputs.",
        "Use calibrated probability thresholds per label instead of fixed top-n to better handle class imbalance.",
        "Implement hierarchical constraint decoding to ensure predicted techniques are valid children of predicted tactics.",
        "Adopt label powerset or classifier chains for multi-label dependencies across tactics and techniques.",
        "Leverage cost-sensitive learning or focal loss (if switching to neural models) to address rare tactics/techniques.",
        "Integrate a hashing vectorizer with differential privacy noise to further strengthen privacy-preserving preprocessing."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/jpmorganchase/MITRE_models",
      "frameworks": [
        "scikit-learn"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Data privacy/security for CTI text; addressed via hashing during vectorization.",
        "Class imbalance and sparsity in real-world CTI data.",
        "Ensuring hierarchical consistency between tactics and techniques."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "A stratified 'task space' formulation of the MITRE ATT&CK text tagging task to organize approaches and pathways.",
      "Stage-wise construction of a baseline multi-label hierarchical tagging system for general CTI text, aligned with CISA best practices.",
      "Comparison against GPT-4o, showing significantly higher tactic-level accuracy for the proposed approach.",
      "Demonstration of re-use to bootstrap modeling on a corpus of financial threat scenarios.",
      "Public release of a version of the tagging system and models at https://github.com/jpmorganchase/MITRE_models."
    ]
  },
  {
    "arxiv_id": "2601.15269v1",
    "title": "Lightweight LLMs for Network Attack Detection in IoT Networks",
    "authors": "Piyumi Bhagya Sudasinghe; Kushan Sudheera Kalupahana Liyanage; Harsha S. Gardiyawasam Pussewalage",
    "abstract": "The rapid growth of Internet of Things (IoT) devices has increased the scale and diversity of cyberattacks, exposing limitations in traditional intrusion detection systems. Classical machine learning (ML) models such as Random Forest and Support Vector Machine perform well on known attacks but require retraining to detect unseen or zero-day threats. This study investigates lightweight decoder-only Large Language Models (LLMs) for IoT attack detection by integrating structured-to-text conversion, Quantized Low-Rank Adaptation (QLoRA) fine-tuning, and Retrieval-Augmented Generation (RAG). Network traffic features are transformed into compact natural-language prompts, enabling efficient adaptation under constrained hardware. Experiments on the CICIoT2023 dataset show that a QLoRA-tuned LLaMA-1B model achieves an F1-score of 0.7124, comparable to the Random Forest (RF) baseline (0.7159) for known attacks. With RAG, the system attains 42.63% accuracy on unseen attack types without additional training, demonstrating practical zero-shot capability. These results highlight the potential of retrieval-enhanced lightweight LLMs as adaptable and resource-efficient solutions for next-generation IoT intrusion detection.",
    "published_date": "2026-01-21",
    "pdf_link": "https://arxiv.org/pdf/2601.15269v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Multi-class IoT network attack detection from network flow features with zero-shot detection of unseen attacks via RAG",
      "attack_types": [
        "DDoS (ICMP/UDP/TCP/PSH-ACK/RST-FIN/ACK fragmentation/UDP fragmentation/synonymous IP)",
        "DoS (HTTP/TCP/UDP/SYN)",
        "Mirai botnet floods (GREeth, GREip, UDP-plain)",
        "DNS spoofing",
        "MITM ARP spoofing",
        "Reconnaissance (host discovery, OS scan, port scan, ping sweep)",
        "Vulnerability scan",
        "Backdoor malware",
        "Browser hijacking",
        "Command injection",
        "SQL injection",
        "DDoS HTTP flood",
        "Slow Loris",
        "Dictionary brute force",
        "Cross-site scripting",
        "Uploading attack"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer (decoder-only)",
        "specific": "LLaMA-3.2-1B",
        "novel_contribution": "Lightweight decoder-only LLM fine-tuned with QLoRA for multi-class IoT attack detection using structured-to-text prompts"
      },
      {
        "type": "primary",
        "category": "Retrieval-Augmented Generation",
        "specific": "RAG over numeric feature embeddings with cosine similarity (top-20 retrieve, top-3 in-context)",
        "novel_contribution": "Zero-shot inference on unseen attack types without additional training by concatenating retrieved exemplars into prompts"
      },
      {
        "type": "primary",
        "category": "Parameter-efficient fine-tuning",
        "specific": "QLoRA (4-bit NF4 quantization + LoRA r=16, alpha=32, dropout=0.1)",
        "novel_contribution": "Resource-constrained adaptation enabling small trainable fraction (0.12%–0.44%) while maintaining competitive performance"
      },
      {
        "type": "primary",
        "category": "Prompt Engineering",
        "specific": "Structured-to-text conversion of tabular flow features",
        "novel_contribution": "Compact, semantically coherent natural-language prompts with label-only loss (after 'Answer:') for decoder-only models"
      },
      {
        "type": "baseline",
        "category": "Transformer (decoder-only)",
        "specific": "Mistral-v0.3-7B",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (decoder-only)",
        "specific": "Meta-LLaMA-3-8B (a.k.a. LLaMA-3.1/3-8B)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (decoder-only)",
        "specific": "GPT-2",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Support Vector Machine",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Zero-shot",
      "In-context Learning (via RAG)",
      "Parameter-efficient fine-tuning"
    ],
    "datasets": [
      {
        "name": "CICIoT2023",
        "type": "public",
        "domain": "network_traffic",
        "link": "https://www.unb.ca/cic/datasets/iotdataset-2023.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.7124 (LLaMA-3.2-1B)",
        "baseline_result": "0.7159"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "0.7117 (LLaMA-3.2-1B)",
        "baseline_result": "0.7171"
      },
      {
        "method_name": "Support Vector Machine (SVM)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.7124 (LLaMA-3.2-1B)",
        "baseline_result": "0.6761"
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.7124 (LLaMA-3.2-1B)",
        "baseline_result": "0.6778"
      },
      {
        "method_name": "Mistral-v0.3-7B (QLoRA)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.7124 (LLaMA-3.2-1B)",
        "baseline_result": "0.6992"
      },
      {
        "method_name": "Meta-LLaMA-3-8B (QLoRA)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.7124 (LLaMA-3.2-1B)",
        "baseline_result": "0.6792"
      },
      {
        "method_name": "GPT-2 (QLoRA)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.7124 (LLaMA-3.2-1B)",
        "baseline_result": "0.6271"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "Per-class metrics",
      "Top-3 Recall (retrieval effectiveness)",
      "Runtime (seconds)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can lightweight decoder-only LLMs fine-tuned with QLoRA match classical ML performance for known IoT attacks?",
        "Does Retrieval-Augmented Generation enable zero-shot detection of unseen attack types without additional training?",
        "Does structured-to-text conversion of flow features enable effective LLM-based classification under hardware constraints?"
      ],
      "gaps_identified": [
        "Classical ML models struggle to detect zero-day attacks without retraining",
        "Performance deteriorates in realistic multi-class, imbalanced IoT settings",
        "Supervised DL approaches generally cannot identify novel attack types without full retraining",
        "Need for resource-efficient adaptation suitable for IoT-scale deployments"
      ],
      "limitations": [
        "LLMs have higher inference time compared to classical ML; practical for offline/batch analysis but may challenge real-time use",
        "Lower per-class performance on subtle or overlapping behaviors (e.g., recon os scan, vulnerability scan, ddos synchronize flood)",
        "Balanced subset via downsampling may omit real-world class imbalance characteristics",
        "Zero-shot RAG relies on a curated retrieval knowledge base from unseen classes and quality of numeric embeddings"
      ],
      "future_work": [],
      "motivation": "Overcome retraining limitations of traditional ML for evolving IoT threats by enabling both known-attack classification and zero-shot generalization to unseen attacks using lightweight LLMs under resource constraints.",
      "potential_research_ideas": [
        "Integrate temporal/sequential context (flow sequences/windows) for improved detection of subtle reconnaissance and scanning behaviors",
        "Learned numeric-to-text encoders or discretizers to optimize tokenization versus naive textualization of numbers",
        "Hybrid encoder-decoder or encoder-only architectures (e.g., TabTransformer, T5) with instruction-tuned classification heads for better efficiency",
        "Contrastive or metric learning to align numeric feature space with textual label space, improving retrieval and zero-shot mapping",
        "Active/online learning with uncertainty-driven labeling to adapt to concept drift in IoT networks",
        "Knowledge distillation from larger LLMs or ensembles into sub-1B models for edge deployment",
        "Federated or split learning to preserve privacy across distributed IoT sites while fine-tuning adapters",
        "Adversarial robustness evaluations and defenses (e.g., feature perturbation resilience, adversarial training)",
        "Explainability methods tailored to structured-to-text prompts (e.g., token attribution mapping back to original features)",
        "Vector database and retrieval optimization (ANN indexes, learned embeddings) and retrieval-augmented calibration"
      ],
      "architectural_improvement_recommendations": [
        "Replace decoder-only backbone with an encoder or encoder-decoder model for classification efficiency while retaining RAG for zero-shot cases",
        "Add lightweight classification head with calibrated probabilities (temperature scaling) to improve decision thresholds",
        "Use learned embeddings for numeric features (embedding layers or VQVAE discretization) before prompting to reduce token counts",
        "Adopt multi-task training (class + auxiliary tasks like traffic type/protocol) to improve generalization on subtle classes",
        "Incorporate contrastive representation learning and supervised SimCLR-style losses to enhance class separability",
        "Employ more effective retrieval (FAISS/ScaNN) with supervised re-ranking and class-balanced retrieval to mitigate bias",
        "Perform longer-context fine-tuning with instruction-style prompts and few-shot exemplars to reduce reliance on external RAG",
        "Quantization-aware training and 4-bit/8-bit inference calibration for latency on edge GPUs/NPUs"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PyTorch",
        "Hugging Face Transformers",
        "PEFT/QLoRA",
        "scikit-learn"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "QLoRA fine-tuning on single GPUs: NVIDIA RTX 4080 (16 GB) for GPT-2 and LLaMA-3.2-1B; RTX 4090 (32 GB) for Mistral-7B and LLaMA-3-8B. Mixed precision FP16, 4-bit NF4 quantization, LoRA r=16, alpha=32, dropout=0.1; batch size 4–16; 3–5 epochs."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "Test runtime (seconds): LR 0.0004; RF 0.0245; SVM 0.6718; LLaMA-3.2-1B 235.16; Mistral-7B 1050.58; LLaMA-3-8B 679.51; GPT-2 191.05",
      "deployment_challenges": [
        "Higher latency and GPU requirements versus classical ML may hinder real-time inline deployment",
        "Maintaining and updating the retrieval knowledge base for RAG in dynamic environments",
        "Potential performance degradation on subtle/overlapping classes; need for calibration and class-imbalance handling",
        "Edge deployment constraints (memory/compute) even with quantization",
        "Data drift and evolving attack behaviors requiring periodic adaptation of adapters/retrieval corpus"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Adapting lightweight decoder-only LLMs with QLoRA for multi-class IoT attack detection (GPT-2, LLaMA-3.2-1B, Meta-LLaMA-3-8B, Mistral-v0.3-7B)",
      "Structured-to-text conversion of numerical network features into concise prompts",
      "Unified handling of known attacks (QLoRA fine-tuning) and unknown attacks (RAG) enabling zero-shot detection",
      "Comparative evaluation against classical ML classifiers on CICIoT2023 with standard metrics, including per-class analysis and runtime",
      "Demonstrated zero-shot performance on unseen attack types: overall 42.63% accuracy with RAG; known-attack F1 up to 0.7124 (LLaMA-1B) comparable to RF (0.7159)"
    ]
  },
  {
    "arxiv_id": "2601.17833v1",
    "title": "An Effective and Cost-Efficient Agentic Framework for Ethereum Smart Contract Auditing",
    "authors": "Xiaohui Hu; Wun Yu Chan; Yuejie Shi; Qumeng Sun; Wei-Cheng Wang; Chiachih Wu; Haoyu Wang; Ningyu He",
    "abstract": "Smart contract security is paramount, but identifying intricate business logic vulnerabilities remains a persistent challenge because existing solutions consistently fall short: manual auditing is unscalable, static analysis tools are plagued by false positives, and fuzzers struggle to navigate deep logic states within complex systems. Even emerging AI-based methods suffer from hallucinations, context constraints, and a heavy reliance on expensive, proprietary Large Language Models. In this paper, we introduce Heimdallr, an automated auditing agent designed to overcome these hurdles through four core innovations. By reorganizing code at the function level, Heimdallr minimizes context overhead while preserving essential business logic. It then employs heuristic reasoning to detect complex vulnerabilities and automatically chain functional exploits. Finally, a cascaded verification layer validates these findings to eliminate false positives. Notably, this approach achieves high performance on lightweight, open-source models like GPToss-120B without relying on proprietary systems. Our evaluations demonstrate exceptional performance, as Heimdallr successfully reconstructed 17 out of 20 real-world attacks post June 2025, resulting in total losses of $384M, and uncovered 4 confirmed zero-day vulnerabilities that safeguarded $400M in TVL. Compared to SOTA baselines including both official industrial tools and academic tools, Heimdallr at most reduces analysis time by 97.59% and financial costs by 98.77% while boosting detection precision by over 93.66%. Notably, when applied to auditing contests, Heimdallr can achieve a 92.45% detection rate at a negligible cost of $2.31 per 10K LOC. We provide production-ready auditing services and release valuable benchmarks for future work.",
    "published_date": "2026-01-25",
    "pdf_link": "https://arxiv.org/pdf/2601.17833v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Auditing",
      "specific_problem": "Automated detection of business logic vulnerabilities and exploit reconstruction in Ethereum DeFi smart contracts using an agentic LLM pipeline with verification",
      "attack_types": [
        "Business logic exploits",
        "Oracle manipulation",
        "Price manipulation",
        "Reentrancy",
        "Integer overflow/underflow",
        "Access control weaknesses",
        "Unprotected delegatecall"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer LLM (Agentic)",
        "specific": "GPT-oss-120B (open-source LLM; model-agnostic design)",
        "novel_contribution": "Plan-Remind-Solve agentic workflow for auditing; model-agnostic auditing that works with lightweight open-source models"
      },
      {
        "type": "primary",
        "category": "Neuro-symbolic reasoning",
        "specific": null,
        "novel_contribution": "Combines semantic LLM reasoning with symbolic constraints and adversarial state analysis to generate and validate vulnerability hypotheses"
      },
      {
        "type": "primary",
        "category": "Graph clustering / Community detection",
        "specific": "Louvain algorithm",
        "novel_contribution": "Contextual Profiling to batch functions/contracts by weighted control/data-flow dependencies to preserve business logic under token limits"
      },
      {
        "type": "primary",
        "category": "Graph centrality scoring",
        "specific": "Betweenness centrality; PageRank",
        "novel_contribution": "Anchor contract identification to focus LLM attention within batches"
      },
      {
        "type": "primary",
        "category": "Program analysis / Verification layer",
        "specific": null,
        "novel_contribution": "Cascaded verification with adversarial feasibility checks to filter hallucinations and suppress false positives"
      },
      {
        "type": "baseline",
        "category": "Static analyzer",
        "specific": "Slither",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Static analyzer",
        "specific": "Mythril",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Agentic LLM tools",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Zero-shot prompting",
      "Agentic planning/reasoning"
    ],
    "datasets": [
      {
        "name": "Heimdallr High-Value Zero-Day Exploits Dataset",
        "type": "public",
        "domain": "smart_contracts",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Heimdallr Standardized Benchmarks for Smart Contract Auditing",
        "type": "public",
        "domain": "smart_contracts",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Heimdallr Crowdsourced Contest Findings Dataset",
        "type": "public",
        "domain": "smart_contracts",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Post-June 2025 Real-World Attacks (20 cases)",
        "type": "proprietary",
        "domain": "smart_contracts",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Slither",
        "paper_reference": "[27] (as cited in paper)",
        "metric": "Qualitative and quantitative comparisons (F1, precision/recall, FPR, cost/time)",
        "their_result": "“superior F1 score of 0.62 on real-world datasets” and “at most reduces analysis time by 97.59% and financial costs by 98.77% while boosting detection precision by over 93.66%.”",
        "baseline_result": null
      },
      {
        "method_name": "Mythril",
        "paper_reference": "[38] (as cited in paper)",
        "metric": "Qualitative and quantitative comparisons (F1, precision/recall, FPR, cost/time)",
        "their_result": "“superior F1 score of 0.62 on real-world datasets” and large time/cost reductions while higher precision",
        "baseline_result": null
      },
      {
        "method_name": "Industrial closed-source analyzers (official tools)",
        "paper_reference": null,
        "metric": "Time, cost, precision/recall",
        "their_result": "“at most reduces analysis time by 97.59% and financial costs by 98.77% while boosting detection precision by over 93.66%.”",
        "baseline_result": null
      },
      {
        "method_name": "Existing LLM-based auditing tools (3 tools)",
        "paper_reference": null,
        "metric": "F1 Score; False Positive Rate (FPR)",
        "their_result": "Heimdallr achieves “superior F1 score of 0.62”",
        "baseline_result": "On 80 real-world protocols these tools show “F1 Score < 0.02” or “FPR > 97%”"
      }
    ],
    "performance_metrics_used": [
      "F1 score",
      "Precision",
      "Recall",
      "False Positive Rate (FPR)",
      "Detection rate",
      "Analysis time",
      "Financial cost ($/10K LOC)",
      "Contest ranking/score"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Is it possible to leverage the automation and reasoning capabilities of LLMs, while minimizing false positives/negatives caused by hallucinations, to achieve scalable and highly reliable smart contract audit results?",
        "How to reduce false positives in LLM-based auditing while retaining detection effectiveness?",
        "How to optimize cost-efficiency without compromising detection accuracy?"
      ],
      "gaps_identified": [
        "Manual auditing is expensive and unscalable (e.g., $70,000–$150,000+ for medium DeFi protocols).",
        "Static analyzers have limited scope and high false positives; miss business logic vulnerabilities; detect only ~25% of vulnerabilities across 127 attacks covering $2.3B losses (accounting for only 12% of damages).",
        "Fuzzers struggle to navigate deep logical states in complex systems.",
        "Direct LLM usage suffers from incompleteness (context window limits), usability friction, and non-deterministic outputs.",
        "Existing agent tools raise privacy concerns (closed-source), are hard to deploy, suffer from very high false positive overload (>90%), and incur high operational costs ($15–$50 per 10K LOC)."
      ],
      "limitations": [
        "The audit engine is not open-sourced; access is via API on request.",
        "LLM token limits necessitate batch pruning of generic/common contracts to fit context windows."
      ],
      "future_work": [],
      "motivation": "Enable scalable, precise, and cost-efficient auditing of DeFi smart contracts by overcoming hallucination-driven false positives, context constraints, and dependence on costly proprietary LLMs.",
      "potential_research_ideas": [
        "Integrate formal verification/SMT-based invariant checking to prove or refute LLM hypotheses automatically.",
        "Hybridize with symbolic execution and coverage-guided fuzzing to generate concrete exploits from LLM hypotheses.",
        "Introduce retrieval-augmented auditing using a corpus of prior audit reports and known patterns for stronger context.",
        "Multi-agent specialization (planner, decompiler/summarizer, exploit synthesizer, verifier) with coordination protocols.",
        "Leverage on-chain execution traces and state diffs to ground reasoning and calibrate feasibility checks.",
        "Extend framework to multi-chain ecosystems (EVM variants, non-EVM chains) and cross-chain bridge logic.",
        "Learned embeddings for contract/function clustering to complement Louvain with semantic similarity.",
        "Auto-tuning of verification thresholds to balance precision/recall under different risk appetites.",
        "Active learning loop using contest feedback/ground truth to refine prompts and heuristics.",
        "Benchmark standardization: create task-specific subsets (oracle manipulation, governance, liquidation) with ground-truth exploits."
      ],
      "architectural_improvement_recommendations": [
        "Add a formal SMT-backed verifier stage that encodes detected invariants and checks counterexamples.",
        "Replace or augment Louvain clustering with embedding-based community detection and code graph neural networks for batching.",
        "Introduce a memory/summarization store per batch (function/contract summaries) to reduce token usage and improve cross-batch reasoning.",
        "Exploit caching and deduplication of common library analyses (e.g., ERC standards) to cut cost further.",
        "Integrate an EVM execution client or fast simulators for stateful adversarial testing and exploit reproduction.",
        "Adopt a multi-agent design with clear roles and MCP-based tool orchestration for robust planning/execution.",
        "Implement confidence calibration and selective abstention; route low-confidence findings to heavier verification.",
        "Use toolformer-style function call synthesis to structure solver/verifier tool usage more reliably."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Runs effectively on lightweight open-source LLMs (e.g., GPT-oss-120B). Reported cost: $2.31 per 10K LOC; analysis time reduced by up to 97.59% vs baselines."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Production-ready API; CI/CD integration; supports privacy-preserving local deployment in air-gapped environments with open-source models",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Managing false positives from LLM hallucinations (addressed via cascaded verification).",
        "Privacy concerns with closed-source cloud tools (mitigated via local open-source model support).",
        "Context window/token limits requiring careful batching and pruning."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Heimdallr: a novel agentic, model-agnostic auditing framework combining graph-theoretic profiling with neuro-symbolic reasoning and cascaded verification.",
      "Production-ready auditing service with API; supports privacy-preserving local deployment using open-source models for air-gapped environments.",
      "Comprehensive empirical evaluation vs four SOTA baselines with superior effectiveness: F1=0.62; time cost reduced by up to 97.59% and financial cost by 98.77%; precision improved by >93.66%.",
      "High-fidelity vulnerability benchmarks: constructed and released three datasets spanning zero-day exploits, standardized benchmarks, and crowdsourced contest findings; plus successful reconstruction of 17/20 real-world post-June-2025 attacks and discovery of 4 confirmed zero-days safeguarding $400M TVL."
    ]
  },
  {
    "arxiv_id": "2601.17471v1",
    "title": "PatchIsland: Orchestration of LLM Agents for Continuous Vulnerability Repair",
    "authors": "Wonyoung Kim; Seunggi Min; Minjae Gwon; Dowoo Baik; Haein Lee; Hyeon Heo; Minjae Lee; Min Woo Baek; Yonghwi Jin; Younggi Park; Yunjae Choi; Taesoo Kim; Sangdon Park; Insu Yun",
    "abstract": "Continuous fuzzing platforms such as OSS-Fuzz uncover large numbers of vulnerabilities, yet the subsequent repair process remains largely manual. Unfortunately, existing Automated Vulnerability Repair (AVR) techniques -- including recent LLM-based systems -- are not directly applicable to continuous fuzzing. This is because these systems are designed and evaluated on a static, single-run benchmark setting, making them ill-suited for the diverse, noisy, and failure-prone environments in continuous fuzzing.   To address these issues, we introduce PatchIsland, a system for Continuous Vulnerability Repair (CVR) that tightly integrates with continuous fuzzing pipelines. PatchIsland employs an ensemble of diverse LLM agents. By leveraging multiple LLM agents, PatchIsland can cover a wider range of settings (e.g., different projects, bug types, and programming languages) and also improve operational robustness. In addition, PatchIsland utilizes a two-phase patch-based deduplication to mitigate duplicate crashes and patches, which can be problematic in continuous fuzzing.   In our internal evaluation, PatchIsland repaired 84 of 92 vulnerabilities, demonstrating strong repair capability. In the official AIxCC competition, the system operated with no human intervention in a fully autonomous environment and successfully patched 31 out of 43 vulnerabilities, achieving a repair rate of 72.1\\%.",
    "published_date": "2026-01-24",
    "pdf_link": "https://arxiv.org/pdf/2601.17471v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software/Application Security",
      "subdomain": "Automated Vulnerability Repair (AVR) / Program Repair",
      "specific_problem": "Continuous Vulnerability Repair (CVR) integrated with continuous fuzzing (OSS-Fuzz): orchestrating multiple LLM agents and performing two-phase (crash- and patch-side) deduplication to automatically generate and submit patches",
      "attack_types": [
        "fuzzer-discovered crashes in OSS projects",
        "synthetic vulnerabilities reflecting real-world bugs (AIxCC CPs)",
        "zero-day vulnerabilities (e.g., pdfbox 0-day)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer-based LLM (agentic system)",
        "specific": null,
        "novel_contribution": "Ensemble of diverse LLM agents ('buckets of agents') to broaden patch search space and improve operational robustness across projects, bug types, and languages"
      },
      {
        "type": "primary",
        "category": "Ensemble Methods / Orchestration",
        "specific": "FP2 orchestration (First-come First-served, Preference-based, Provider-aware)",
        "novel_contribution": "Provider-aware parallel scheduling to avoid API throttling; preference-based sequential execution to prioritize agents more likely to produce correct patches; FCFS result selection for robustness"
      },
      {
        "type": "primary",
        "category": "Heuristic + Program Analysis tooling",
        "specific": "Crete framework modules (fault localization, code retrieval via Tree-sitter/ctags, evaluator)",
        "novel_contribution": "Unified framework (Crete) to standardize agent development and enable cache-everywhere and environment pooling for efficient repeated builds/tests"
      }
    ],
    "learning_paradigm": [
      "In-Context Learning (LLM prompting)",
      "Heuristic/Rule-based Orchestration"
    ],
    "datasets": [
      {
        "name": "AIxCC Benchmark / Challenge Projects (CPs)",
        "type": "public",
        "domain": "open_source_codebases (C, Java) with synthetic and real vulnerabilities; fuzz_crashes",
        "link": "https://aicyberchallenge.com/",
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "AIxCC Final Competition Environment (53 CPs incl. openssl, log4j; includes a pdfbox 0-day)",
        "type": "public",
        "domain": "open_source_codebases (C, Java) with synthetic and real vulnerabilities; fuzz_crashes",
        "link": "https://aicyberchallenge.com/",
        "is_new_contribution": false,
        "availability": "available_on_request"
      }
    ],
    "baselines": [
      {
        "method_name": "Buttercup (baseline system provided in AIxCC benchmark)",
        "paper_reference": null,
        "metric": "Vulnerabilities repaired (count/rate)",
        "their_result": "PatchIsland repaired 84/92 vulnerabilities (internal benchmark), and 31/43 (72.1%) in AIxCC final",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "number of vulnerabilities repaired",
      "repair rate / success rate",
      "plausible patch validation (compile, reproduce PoV, pass functional tests)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Existing AVR systems are designed and evaluated for static, single-run benchmarks and are ill-suited for continuous fuzzing at scale",
        "Operational robustness across diverse projects, build configurations, and bug types is not addressed in prior AVR systems",
        "Crash deduplication used by fuzzers and prior research often relies on inaccurate stack-based heuristics or requires hardware/specific fuzzers, limiting applicability",
        "Automated correctness verification for patches in large software is often infeasible; many systems settle for plausibility, risking incorrect patches",
        "Provider-level throttling and failure-prone environments (OOM, network disruptions) are not considered in most AVR designs"
      ],
      "limitations": [
        "The system primarily targets plausibility due to the difficulty of fully-automated correctness verification; plausible but incorrect patches remain possible",
        "Patch-side deduplication and merging can risk creating a 'superman patch' that over-aggregates fixes",
        "Evaluation focuses on AIxCC/OSS-Fuzz-style pipelines (C/Java), leaving generalization to other ecosystems/languages unproven in the text",
        "Dependence on external LLM providers introduces quota/rate-limit constraints and potential variability"
      ],
      "future_work": [],
      "motivation": "Continuous fuzzing (e.g., OSS-Fuzz) finds many vulnerabilities, but post-fuzzing steps like crash triage and patch generation remain manual and resource-intensive. Prior AVR/LLM-based systems lack the robustness and design to operate continuously at scale.",
      "potential_research_ideas": [
        "Automatic semantic equivalence and regression risk assessment for candidate patches using hybrid static-dynamic analysis combined with LLM reasoning",
        "Learning-to-orchestrate: train a meta-controller to adapt agent ordering/preferences based on project/bug features to optimize correctness and latency",
        "Confidence estimation and uncertainty-aware patch submission, combining LLM self-consistency with empirical validation signals",
        "Cross-project patch generalization: maintain a library of validated micro-fixes and retrieve/adapt them via code search and LLM editing",
        "Extend CVR to additional ecosystems (Rust, Go, Python) with language-aware agents and differential testing harnesses",
        "Multi-objective scheduling that jointly optimizes provider quotas, cost, and expected patch correctness/coverage"
      ],
      "architectural_improvement_recommendations": [
        "Introduce a lightweight 'LLM-as-a-judge' or dual-model cross-check gated by cost/latency thresholds for cases where FCFS selections are likely low-quality",
        "Augment two-phase dedup with semantic crash clustering (e.g., coverage/stack similarity plus patch impact graphs) to reduce over-merging risks",
        "Add an active learning loop that updates agent preferences per project based on recent success signals and validation outcomes",
        "Incorporate symbolic execution-guided fault localization to improve candidate patch targeting before LLM editing",
        "Implement provider-quota-aware token budgeting and response-time prediction to dynamically rebalance agent schedules",
        "Add a post-patch differential testcase generation step to uncover overfitting (anti-regression) before final submission"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Custom (Crete framework)",
        "Kubernetes",
        "OSS-Fuzz",
        "Tree-sitter",
        "ctags"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Distributed k8s deployment with coordinator-worker model; multiple parallel workers invoking LLM provider APIs under quota limits; no GPU requirements stated; caching and environment pools to reduce build/validation overhead"
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Cloud (Kubernetes) integrated with OSS-Fuzz in the AIxCC autonomous competition infrastructure",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Provider-level throttling (rate/token quotas)",
        "Out-of-memory and network disruptions",
        "High volume of duplicate crashes",
        "Noisy, failure-prone continuous fuzzing environment",
        "Need for continuous operation without human intervention"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A CVR system (PatchIsland) tightly integrated with continuous fuzzing pipelines to continuously manage crash inflow, deduplicate, and generate patches",
      "Ensemble-based approach using multiple diverse LLM agents to broaden search space and improve operational robustness",
      "Two-phase deduplication (crash-side and patch-side) leveraging patch-based deduplication to mitigate duplicate crashes and patches",
      "FP2 orchestration (FCFS, Preference-based, Provider-aware) for robust and efficient multi-agent scheduling",
      "Crete framework to standardize agent development with shared tooling (fault localization, code retrieval, evaluator) and caching/environment pooling",
      "Empirical results: repaired 84/92 vulnerabilities internally; fully autonomous in AIxCC final, patched 31/43 (72.1%) and generated the largest number of patches among participating systems; produced a patch identical to the maintainer’s for a pdfbox 0-day"
    ]
  },
  {
    "arxiv_id": "2601.16472v1",
    "title": "Secure Intellicise Wireless Network: Agentic AI for Coverless Semantic Steganography Communication",
    "authors": "Rui Meng; Song Gao; Bingxuan Xu; Xiaodong Xu; Jianqiao Chen; Nan Ma; Pei Xiao; Ping Zhang; Rahim Tafazolli",
    "abstract": "Semantic Communication (SemCom), leveraging its significant advantages in transmission efficiency and reliability, has emerged as a core technology for constructing future intellicise (intelligent and concise) wireless networks. However, intelligent attacks represented by semantic eavesdropping pose severe challenges to the security of SemCom. To address this challenge, Semantic Steganographic Communication (SemSteCom) achieves ``invisible'' encryption by implicitly embedding private semantic information into cover modality carriers. The state-of-the-art study has further introduced generative diffusion models to directly generate stega images without relying on original cover images, effectively enhancing steganographic capacity. Nevertheless, the recovery process of private images is highly dependent on the guidance of private semantic keys, which may be inferred by intelligent eavesdroppers, thereby introducing new security threats. To address this issue, we propose an Agentic AI-driven SemSteCom (AgentSemSteCom) scheme, which includes semantic extraction, digital token controlled reference image generation, coverless steganography, semantic codec, and optional task-oriented enhancement modules. The proposed AgentSemSteCom scheme obviates the need for both cover images and private semantic keys, thereby boosting steganographic capacity while reinforcing transmission security. The simulation results on open-source datasets verify that, AgentSemSteCom achieves better transmission quality and higher security levels than the baseline scheme.",
    "published_date": "2026-01-23",
    "pdf_link": "https://arxiv.org/pdf/2601.16472v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Wireless and Network Security",
      "subdomain": "Steganography and Covert Communications for Semantic Communication",
      "specific_problem": "Defending against semantic eavesdropping by coverless semantic steganographic communication without private semantic keys in intellicise wireless networks",
      "attack_types": [
        "eavesdropping",
        "semantic eavesdropping"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Agentic AI / LLM-driven control",
        "specific": "LLM (unspecified) used for public semantic key generation and agent tool-use/orchestration",
        "novel_contribution": "Agentic AI autonomously selects feature extraction strategies and coordinates generation using a digital token; eliminates need for private semantic keys."
      },
      {
        "type": "primary",
        "category": "Diffusion Model (conditional) with ControlNet",
        "specific": "DDIM sampling; invertible EDICT sampling; U-Net noise predictor; ControlNet for structure conditioning",
        "novel_contribution": "Coupled latent trajectories with invertible sampling to eliminate diffusion inversion approximation error and resolve semantic drift; dual-stage digital-token control (seeded initialization + binary mask perturbation)."
      },
      {
        "type": "primary",
        "category": "VAE",
        "specific": "VAE encoder/decoder for latent image representation",
        "novel_contribution": "Used to map images to latent space for coverless stego generation and recovery."
      },
      {
        "type": "primary",
        "category": "JSCC (Deep Joint Source-Channel Coding)",
        "specific": null,
        "novel_contribution": "Integrates a JSCC-based semantic codec to directly map stego images to channel domain for digital/analog SemCom."
      },
      {
        "type": "baseline",
        "category": "Diffusion Model (coverless steganography)",
        "specific": "SemSteDiff",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [],
    "datasets": [
      {
        "name": "UniStega",
        "type": "public",
        "domain": "images (steganography/semantic communication)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SemSteDiff",
        "paper_reference": "[37]",
        "metric": "PSNR",
        "their_result": "“higher Peak Signal-to-Noise Ratio (PSNR) by 14.29%”",
        "baseline_result": "Not reported; paper provides relative improvement only"
      },
      {
        "method_name": "SemSteDiff",
        "paper_reference": "[37]",
        "metric": "SSIM",
        "their_result": "“higher Structural Similarity (SSIM) by 8.88%”",
        "baseline_result": "Not reported; paper provides relative improvement only"
      },
      {
        "method_name": "SemSteDiff",
        "paper_reference": "[37]",
        "metric": "MSE",
        "their_result": "“lower Mean Squared Error (MSE) by 43.75%”",
        "baseline_result": "Not reported; paper provides relative improvement only"
      },
      {
        "method_name": "SemSteDiff",
        "paper_reference": "[37]",
        "metric": "LPIPS",
        "their_result": "“lower Learned Perceptual Image Patch Similarity (LPIPS) by 5.1%”",
        "baseline_result": "Not reported; paper provides relative improvement only"
      }
    ],
    "performance_metrics_used": [
      "PSNR",
      "SSIM",
      "MSE",
      "LPIPS"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to secure semantic communication against semantic eavesdropping without relying on cover images or private semantic keys?",
        "How to generate controllable stego images with high capacity while ensuring accurate invertible recovery at the receiver?",
        "How to mitigate semantic drift from diffusion inversion errors in coverless steganography?",
        "Can a digital token serve as a secure, deterministic control to coordinate reference image generation and perturbation for enhanced security?"
      ],
      "gaps_identified": [
        "Cover-based semantic steganography limits capacity and security due to dependence on cover images.",
        "Prior coverless diffusion approaches (e.g., SemSteDiff) require private semantic keys that can be inferred by intelligent eavesdroppers given semantic background/context.",
        "Diffusion inversion introduces approximation errors causing semantic drift and inaccurate recovery.",
        "Existing methods do not autonomously adapt generative strategies to content/task requirements in SemCom."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Secure semantic communication in 6G intellicise wireless networks faces intelligent semantic eavesdropping; need to eliminate reliance on cover images and private semantic keys while maintaining transmission quality and capacity.",
      "potential_research_ideas": [
        "Develop formal security proofs quantifying the secrecy of digital token–controlled trajectories under various eavesdropper models (with/without model access).",
        "Design token-rotation and multi-token schemes (time-varying seeds) to provide forward secrecy and resilience against token leakage.",
        "Integrate steganalysis-aware training or adversarial training to reduce detectability by state-of-the-art steganalyzers.",
        "Extend to multimodal SemSteCom (text, audio, video) with unified agent policies and cross-modal implicit features.",
        "Explore federated or split learning to train/update components (JSCC, ControlNet adapters) without exposing private data.",
        "Incorporate channel-state-aware adaptive diffusion step scheduling to reduce latency and improve robustness across SNRs.",
        "Create a benchmark for semantic eavesdropping with standardized attacker capabilities and evaluation metrics."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment DDIM/EDICT with exact or higher-order invertible samplers; evaluate consistency models for faster and more stable inversion.",
        "Use lightweight ControlNet adapters or LoRA-tuned adapters to reduce compute while preserving structure conditioning.",
        "Add learnable token-conditioned perturbation generators (rather than fixed binary masks) with cryptographic PRNGs for stronger security guarantees.",
        "Jointly train JSCC encoder/decoder with diffusion latent space (end-to-end) to better align channel distortions with denoising robustness.",
        "Introduce a steganalysis-discriminator head during training to minimize statistical detectability under known steganalyzers.",
        "Adopt error-correcting semantic priors (e.g., diffusion posterior guidance with token-derived codes) for robustness to channel noise."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Simulated wireless channel (quasi-static fading with AWGN) within an intellicise wireless network setting; no production deployment reported",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Key management and secure distribution/storage of digital tokens.",
        "Computational cost and latency of diffusion-based generation/inversion, especially on edge devices.",
        "Robustness under diverse, time-varying wireless channels and imperfect CSI.",
        "Potential detectability by advanced steganalysis tools despite semantic plausibility.",
        "Synchronization requirements for deterministic token-seeded generation at both ends."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces AgentSemSteCom, the first agentic AI–driven coverless semantic steganography scheme for intellicise wireless networks, removing the need for cover images and private semantic keys.",
      "Proposes agent-coordinated public semantic key and implicit feature guidance with invertible sampling (coupled latent trajectories) to resolve semantic drift and enable accurate recovery.",
      "Introduces a digital token–based dual-stage protection (seeded reference generation + binary mask latent perturbation) to coordinate generation and enhance security.",
      "Demonstrates on the open-source UniStega dataset improved quality over SemSteDiff with reported gains: PSNR +14.29%, SSIM +8.88%, MSE −43.75%, LPIPS −5.1%; receiver vs. eavesdropper PSNR 25.37 dB vs. 18.91 dB."
    ]
  },
  {
    "arxiv_id": "2601.16795v1",
    "title": "Building a Robust Risk-Based Access Control System to Combat Ransomware's Capability to Encrypt: A Machine Learning Approach",
    "authors": "Kenan Begovic; Abdulaziz Al-Ali; Qutaibah Malluhi",
    "abstract": "Ransomware core capability, unauthorized encryption, demands controls that identify and block malicious cryptographic activity without disrupting legitimate use. We present a probabilistic, risk-based access control architecture that couples machine learning inference with mandatory access control to regulate encryption on Linux in real time. The system builds a specialized dataset from the native ftrace framework using the function_graph tracer, yielding high-resolution kernel-function execution traces augmented with resource and I/O counters. These traces support both a supervised classifier and interpretable rules that drive an SELinux policy via lightweight booleans, enabling context-sensitive permit/deny decisions at the moment encryption begins. Compared to approaches centered on sandboxing, hypervisor introspection, or coarse system-call telemetry, the function-level tracing we adopt provides finer behavioral granularity than syscall-only telemetry while avoiding the virtualization/VMI overhead of sandbox-based approaches. Our current user-space prototype has a non-trivial footprint under burst I/O; we quantify it and recognize that a production kernel-space solution should aim to address this. We detail dataset construction, model training and rule extraction, and the run-time integration that gates file writes for suspect encryption while preserving benign cryptographic workflows. During evaluation, the two-layer composition retains model-level detection quality while delivering rule-like responsiveness; we also quantify operational footprint and outline engineering steps to reduce CPU and memory overhead for enterprise deployment. The result is a practical path from behavioral tracing and learning to enforceable, explainable, and risk-proportionate encryption control on production Linux systems.",
    "published_date": "2026-01-23",
    "pdf_link": "https://arxiv.org/pdf/2601.16795v1",
    "paper_types": [
      "empirical_analysis",
      "reproducibility",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Endpoint/Host Security",
      "subdomain": "Ransomware Detection",
      "specific_problem": "Real-time detection and prevention of unauthorized encryption on Linux via risk-based access control integrated with SELinux",
      "attack_types": [
        "ransomware",
        "unauthorized encryption"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": "Used as the supervised classifier (E_ML) on kernel function-level tracing features; supports rule extraction for enforcement"
      },
      {
        "type": "primary",
        "category": "Rule-based model",
        "specific": null,
        "novel_contribution": "Interpretable rule layer (E_RULE) derived from features/model to enable low-latency, explainable gating of writes"
      },
      {
        "type": "primary",
        "category": "Feature Selection",
        "specific": "Permutation importance + elbow rule; Chi-squared (χ2) + utility wrapper",
        "novel_contribution": "Two complementary pipelines for robust, defender-centric feature selection from 113 engineered features"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "ftrace function_graph encryption traces (this paper)",
        "type": "public",
        "domain": "kernel_traces",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "RanSAP dataset (Hirano et al.)",
        "type": "public",
        "domain": "storage_io",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Ahmed et al. refined system call trace dataset",
        "type": "private",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Zhuravchak and Dudykevych eBPF telemetry dataset",
        "type": "private",
        "domain": "kernel_telemetry",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Alam et al. time/frequency ransomware dataset",
        "type": "private",
        "domain": "behavioral_time_series",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Chen and Bridges WannaCry dynamic analysis traces",
        "type": "private",
        "domain": "system_calls_and_file_access",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "eBPF-based in-kernel ML detector (Brodzik et al.)",
        "paper_reference": "Brodzik et al. (as cited)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Cuckoo v3.2 + GBDT pipeline",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "F1 score",
      "Precision",
      "Recall",
      "Decision latency",
      "Bytes to first block",
      "CPU utilization",
      "Memory footprint"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to build specialized datasets from Linux ftrace function_graph to train ML models for encryption detection?",
        "Which learning techniques/algorithms are applicable to detecting early-stage encryption activity?",
        "How do extracted rules from the ML model perform compared to using the model directly in a probabilistic ACS?",
        "How to integrate the ACS into the OS (SELinux) for real-time enforcement, and how effective is it in realistic scenarios?"
      ],
      "gaps_identified": [
        "Prior work relies on syscall-only telemetry or sandbox/VMI, lacking fine-grained function-level tracing from ftrace/function_graph",
        "Existing kernel-telemetry detectors often lack OS-native, inline enforcement to gate write/append at encryption onset",
        "Virtualization/sandbox approaches impose overhead; syscall telemetry is coarse for early-block decisions",
        "Limited adoption of probabilistic, risk-based enforcement tied to explainable rules in production-friendly MAC frameworks"
      ],
      "limitations": [
        "Current user-space prototype has non-trivial footprint under burst I/O (RAM residency ~50%, frequent CPU spikes)",
        "Prototype scope excludes kernel compromise, SELinux disablement/permissive mode, or policy reload by privileged adversary",
        "Enforcement applies to processes confined to a designated SELinux subject domain (encryption_t) and labeled assets; deployment requires careful policy transitions",
        "To prevent misuse, trained models and production rule sets are withheld (reproducibility limited to code, harnesses, and raw data)"
      ],
      "future_work": [
        "Engineer a production kernel-space solution to reduce CPU and memory overhead",
        "Harden deployment with secure boot/lockdown, policy immutability, and attestation against stronger adversaries",
        "Refine and optimize collector/feature pipelines and rule latency for enterprise deployment",
        "Broaden evaluations across diverse benign crypto workflows and ransomware families; extend policy whitelisting semantics"
      ],
      "motivation": "Combat unauthorized encryption by ransomware without disrupting legitimate cryptographic use, via probabilistic, risk-based access control coupled with explainable ML and SELinux enforcement.",
      "potential_research_ideas": [
        "Online/streaming learning to adapt to concept drift in encryption behaviors while preserving safety via conservative rules",
        "Cross-host/enterprise-scale coordination (fleet policies, federated learning) for faster adaptation without centralizing sensitive traces",
        "Hybrid telemetry combining ftrace with selective eBPF/kprobes to balance coverage and overhead",
        "Adversarial robustness evaluation and defenses against mimicry/poisoning (e.g., rule-aware evasion)",
        "Generalize beyond Linux to other OSes or kernel versions with portable feature abstractions and symbol resolution",
        "Incorporate provenance/context (user/app/path/type) into joint models for risk calibration and explainability"
      ],
      "architectural_improvement_recommendations": [
        "Move collector and lightweight inference into kernel space with ring-buffer IPC to user space for policy toggles",
        "Implement adaptive sampling and backpressure under burst I/O to bound overhead and tail latency",
        "Replace/augment tree with shallow GBDT or monotonic constraints for calibrated probabilities while retaining interpretability",
        "Employ rule-learning (e.g., RIPPER/SLIPPER) or optimal sparse decision sets for compact E_RULE with bounded evaluation time",
        "Introduce drift detection and guarded model updates with rollback, plus safety filters before flipping SELinux booleans",
        "Leverage per-context (user/app/path/type) calibration and hierarchical policies to reduce false positives in shared environments"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "scikit-learn"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "User-space prototype shows notable overhead under burst I/O (RAM residency ~50%, frequent CPU spikes); early-block decisions in tens of milliseconds; production kernel-space implementation recommended to reduce footprint"
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Linux hosts with SELinux enforcing (enterprise endpoints/servers)",
      "scalability_discussed": true,
      "inference_time": "Targeting first tens of milliseconds (few–tens of kilobytes written before first block)",
      "deployment_challenges": [
        "Non-trivial CPU and memory overhead under burst I/O",
        "SELinux policy/CIL module loading nuances (e.g., Ubuntu 24.04)",
        "Need for careful policy-driven domain transitions to confine untrusted processes",
        "Operational management of SELinux booleans for inline gating"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Dual-layer, risk-based enforcement combining interpretable rules (E_RULE) and a supervised model (E_ML) on the same 36-feature vector",
      "Operationalization of Linux ftrace/function_graph to derive function-level signals and graph metrics for ML-informed access control",
      "Two feature selection pipelines: permutation-importance elbow rule and χ2 + utility wrapper from 113 engineered features",
      "Minimal, auditable SELinux CIL module integrating rule and ML verdicts via booleans to gate write/append",
      "Principled whitelisting semantics (user/app/path/type) for legitimate cryptographic workflows",
      "Early-block strategy focusing on sub-second sampling and high-signal features; logging decision latency and bytes to first block",
      "Evaluation against benign, crypto tools (OpenSSL, GnuPG), and ransomware scenarios with baselines (eBPF-based detector; Cuckoo v3.2 + GBDT)",
      "Operational lessons learned and engineering guidance for reducing CPU/memory overhead; release of automation code and raw dataset (models/rules withheld)"
    ]
  },
  {
    "arxiv_id": "2601.06276v1",
    "title": "Automated Generation of Accurate Privacy Captions From Android Source Code Using Large Language Models",
    "authors": "Vijayanta Jain; Sepideh Ghanavati; Sai Teja Peddinti; Collin McMillan",
    "abstract": "Privacy captions are short sentences that succinctly describe what personal information is used, how it is used, and why, within an app. These captions can be utilized in various notice formats, such as privacy policies, app rationales, and app store descriptions. However, inaccurate captions may mislead users and expose developers to regulatory fines. Existing approaches to generating privacy notices or just privacy captions include using questionnaires, templates, static analysis, or machine learning. However, these approaches either rely heavily on developers' inputs and thus strain their efforts, use limited source code context, leading to the incomplete capture of app privacy behaviors, or depend on potentially inaccurate privacy policies as a source for creating notices. In this work, we address these limitations by developing Privacy Caption Generator (PCapGen), an approach that - i) automatically identifies and extracts large and precise source code context that implements privacy behaviors in an app, ii) uses a Large Language Model (LLM) to describe coarse- and fine-grained privacy behaviors, and iii) generates accurate, concise, and complete privacy captions to describe the privacy behaviors of the app. Our evaluation shows PCapGen generates concise, complete, and accurate privacy captions as compared to the baseline approach. Furthermore, privacy experts choose PCapGen captions at least 71\\% of the time, whereas LLMs-as-judge prefer PCapGen captions at least 76\\% of the time, indicating strong performance of our approach.",
    "published_date": "2026-01-09",
    "pdf_link": "https://arxiv.org/pdf/2601.06276v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Privacy and Data Protection",
      "subdomain": "Mobile App Privacy Compliance",
      "specific_problem": "Automated generation of accurate privacy captions from Android source code",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "GPT-4 (gpt-4-0613)",
        "novel_contribution": "Used with In-Context Learning over large, automatically extracted code context (taint paths across classes/methods/statements) to generate privacy captions"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Claude Opus 4 (claude-opus-4-20250514)",
        "novel_contribution": "Best-performing configuration (PCapGen_Claude) for accuracy, conciseness, and completeness; used with ICL on extracted code context"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "DeepSeek (deepseek-r1-distill-llama-70b)",
        "novel_contribution": "Used as an alternative LLM in the PCapGen pipeline with ICL"
      }
    ],
    "learning_paradigm": [
      "In-Context Learning",
      "Prompt-based generation"
    ],
    "datasets": [
      {
        "name": "Developer-annotated Android source code snippets with privacy captions (shared by authors)",
        "type": "public",
        "domain": "android_source_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "FlowDroid SourcesAndSinks list",
        "type": "public",
        "domain": "security_api_lists",
        "link": "https://tinyurl.com/SourcesAndSinks",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Android apps analyzed for taint paths (500 apps used for evaluation/analysis)",
        "type": "proprietary",
        "domain": "android_apps_source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Developer-curated baseline captions",
        "paper_reference": null,
        "metric": "Expert preference",
        "their_result": "“privacy experts choose PCapGen captions at least 71% of the time”",
        "baseline_result": "29% of the time (complement of 71%)"
      },
      {
        "method_name": "Developer-curated baseline captions",
        "paper_reference": null,
        "metric": "LLM-as-judge preference",
        "their_result": "“LLMs-as-judge prefer PCapGen captions at least 76% of the time”",
        "baseline_result": "24% of the time (complement of 76%)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Conciseness",
      "Completeness",
      "Expert preference (%)",
      "LLM-as-judge preference (%)",
      "Semantic similarity (automated metrics; unspecified)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ 1. Which PCapGen configuration generates better privacy captions as per different quality criteria?",
        "RQ 2. How similar are the PCapGen privacy captions compared to the baseline privacy captions?",
        "RQ 3. Are (best configuration) PCapGen privacy captions better than baseline privacy captions on the quality criteria according to LLM-as-judge models?",
        "RQ 4. Are (best configuration) PCapGen privacy captions better than baseline privacy captions on the quality criteria according to privacy experts?"
      ],
      "gaps_identified": [
        "Existing methods rely heavily on developers’ inputs, increasing burden and risk of inaccuracy",
        "Automated approaches often use limited source code context, missing complete privacy behaviors",
        "Some approaches depend on potentially inaccurate privacy policies as input context",
        "Prior work focuses on specific notice formats, not easily reusable caption-level outputs across formats",
        "Frequent inconsistencies between notices (policies, labels, rationales, descriptions) and actual app behaviors"
      ],
      "limitations": [
        "Modified taint approach is effective mainly for WiFi, network, and account APIs, but not for camera, sensors, and storage APIs",
        "Heuristics-based taint path extraction depends on call-graph bounded depth (depth=6) and may miss flows via components/asynchronous callbacks",
        "Computational demands: 16 GB per app for taint analysis; ~60 hours on one machine for 500 apps",
        "“we do not find a statistically significant difference between the baseline and PCapGen captions based on the privacy experts’ quality ratings”",
        "Validity of taint paths defined with a threshold of at least three nodes could exclude shorter legitimate behaviors"
      ],
      "future_work": [],
      "motivation": "Reduce developer burden and improve accuracy/consistency of privacy notices by automatically generating concise, complete, and accurate privacy captions directly from source code using extended taint analysis plus LLMs.",
      "potential_research_ideas": [
        "Integrate dynamic analysis (runtime tracing, instrumentation) to capture flows through components, callbacks, and asynchronous paths missed by static analysis",
        "Develop a retrieval-augmented generation (RAG) layer that indexes code artifacts (APIs, SDK docs, permissions, manifests) to ground LLM outputs and reduce hallucinations",
        "Fine-tune or instruction-tune smaller open LLMs on the released dataset to create cost-effective, on-prem privacy caption generators",
        "Extend caption generation to structured privacy labels (e.g., Play Store, App Store) and cross-check consistency across multiple notice formats automatically",
        "Automated discrepancy detection between generated captions and existing privacy policies/descriptions to flag compliance risks",
        "Adversarial evaluation of LLM-generated captions (prompt attacks, misleading code patterns) to assess robustness",
        "Multi-lingual caption generation and localization while preserving accuracy of legal/privacy semantics"
      ],
      "architectural_improvement_recommendations": [
        "Augment static taint with inter-component communication (ICC) analysis and Android callback models; combine with selective dynamic traces to enrich sinks",
        "Introduce a verification/discriminator module (LLM or rule-based) to validate captions against extracted facts and reduce over/under-claims",
        "Use structured intermediate representations (e.g., dataflow graphs with typed PII labels) as LLM input instead of raw code blocks to improve scaling and grounding",
        "Prompt-chaining with self-critique and checklist-based scoring for accuracy, conciseness, and completeness before final caption emission",
        "Calibrate LLM outputs with constraint-based decoding guided by policy ontologies (what/how/why schema)"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "FlowDroid",
        "Soot",
        "LLM APIs (OpenAI, Anthropic, DeepSeek)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Taint analysis run with 16 GB memory per app; 500 apps took ~60 hours on one AMD Ryzen 9 CPU machine with 124 GB RAM. Call graph depth capped at 6."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Source code sharing/privacy when using third-party LLM APIs",
        "Static/taint analysis scalability and memory requirements on large apps",
        "Coverage gaps for APIs relying on callbacks/components not captured in call graphs",
        "LLM cost and variability across models/configurations",
        "Integration into CI/CD and mapping captions to multiple notice formats consistently"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Novel framework (PCapGen) combining heuristics-based taint/static analysis with LLM ICL to generate accurate privacy captions",
      "Extended taint analyses to identify taint paths between new source APIs and unknown sinks, extracting associated classes, methods, and statements",
      "Comprehensive evaluation with privacy experts and LLMs-as-judge on accuracy, conciseness, and completeness",
      "Release of a dataset of developer-annotated Android source code snippets with privacy captions, scripts, and a custom annotation tool"
    ]
  },
  {
    "arxiv_id": "2601.14601v1",
    "title": "Holmes: An Evidence-Grounded LLM Agent for Auditable DDoS Investigation in Cloud Networks",
    "authors": "Haodong Chen; Ziheng Zhang; Jinghui Jiang; Qiang Su; Qiao Xiang",
    "abstract": "Cloud environments face frequent DDoS threats due to centralized resources and broad attack surfaces. Modern cloud-native DDoS attacks further evolve rapidly and often blend multi-vector strategies, creating an operational dilemma: defenders need wire-speed monitoring while also requiring explainable, auditable attribution for response. Existing rule-based and supervised-learning approaches typically output black-box scores or labels, provide limited evidence chains, and generalize poorly to unseen attack variants; meanwhile, high-quality labeled data is often difficult to obtain in cloud settings.   We present Holmes (DDoS Detective), an LLM-based DDoS detection agent that reframes the model as a virtual SRE investigator rather than an end-to-end classifier. Holmes couples a funnel-like hierarchical workflow (counters/sFlow for continuous sensing and triage; PCAP evidence collection triggered only on anomaly windows) with an Evidence Pack abstraction that converts binary packets into compact, reproducible, high-signal structured evidence. On top of this evidence interface, Holmes enforces a structure-first investigation protocol and strict JSON/quotation constraints to produce machine-consumable reports with auditable evidence anchors.   We evaluate Holmes on CICDDoS2019 reflection/amplification attacks and script-triggered flooding scenarios. Results show that Holmes produces attribution decisions grounded in salient evidence anchors across diverse attack families, and when errors occur, its audit logs make the failure source easy to localize, demonstrating the practicality of an LLM agent for cost-controlled and traceable DDoS investigation in cloud operations.",
    "published_date": "2026-01-21",
    "pdf_link": "https://arxiv.org/pdf/2601.14601v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "DDoS Detection and Investigation",
      "specific_problem": "Evidence-grounded attribution and investigation of DDoS incidents in cloud networks using an agentic LLM workflow",
      "attack_types": [
        "Reflection/Amplification",
        "Direct Flood (TCP/UDP)",
        "SYN Flood (design label gated for TCP)",
        "ACK Flood (design label gated for TCP)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM Agent",
        "specific": "OpenPangu-7B",
        "novel_contribution": "Agent constrained by a Prompt Contract with Quote Rule, strict JSON schema, and structure-first investigation protocol (Route-1) over Evidence Packs"
      },
      {
        "type": "primary",
        "category": "Prompt Engineering",
        "specific": "Quote-constrained reasoning + strict JSON output schema",
        "novel_contribution": "Mandatory verbatim quotation of substrings from Evidence Pack for every key evidence item to ensure auditability and reduce hallucinations"
      },
      {
        "type": "primary",
        "category": "Agent Framework / Tool-augmented LLM",
        "specific": "LangGraph state machine",
        "novel_contribution": "Hierarchical workflow (monitor → triage → evidence → detective) with on-demand invocation, cooldown/deduplication, and audit logging"
      }
    ],
    "learning_paradigm": [
      "Zero-shot",
      "Tool-augmented LLM (agentic)",
      "Prompt-based (no model training)"
    ],
    "datasets": [
      {
        "name": "CICDDoS2019",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Script-triggered synthetic flooding scenarios (replay-driven simulation)",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "TrafficLLM",
        "paper_reference": "Cui et al. 2025",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "IDS-Agent",
        "paper_reference": "Li et al. 2024",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "ShieldGPT",
        "paper_reference": "Wang et al. 2024",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to bridge the modality gap between high-volume binary network traffic and LLM-based semantic reasoning to yield interpretable evidence?",
        "How to enforce faithful, auditable reasoning by an LLM and prevent security-relevant hallucinations and tool misinterpretation?",
        "How to reconcile wire-speed monitoring requirements with the high latency/cost of LLM inference for practical cloud DDoS operations?"
      ],
      "gaps_identified": [
        "Existing rule-based and supervised-learning approaches output black-box scores/labels with limited evidence chains.",
        "Poor generalization of supervised learning to unseen (zero-day) attack variants.",
        "Scarcity of high-quality labeled data in cloud settings due to privacy and commercial sensitivity.",
        "Always-on LLM use is economically infeasible for high-throughput traffic.",
        "Limited support for multi-stage triage from coarse anomalies to packet-level root causes in prior systems."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Provide cost-controlled, explainable, and auditable DDoS investigation in cloud networks by transforming LLMs into virtual SREs that operate on structured, quotable evidence rather than raw packets or black-box labels.",
      "potential_research_ideas": [
        "Augment Evidence Packs with temporal flow features and sketch-based aggregates to improve discrimination between flash crowds and floods.",
        "Integrate retrieval of protocol specifications and known amplification signatures (e.g., RFC snippets, CVE notes) for citation alongside quoted packet substrings.",
        "Develop adversarial evaluation of the agent (prompt injection via payload text, misleading banners) and defenses such as sanitization and tool-output verification.",
        "Cross-vantage correlation (multi-switch/multi-region) to attribute reflection sources and differentiate multi-vector campaigns via causal graphs.",
        "Distill the LLM agent’s decision policy into a smaller specialized model for lower-latency on-device inference.",
        "Automate closed-loop mitigation by generating safe, auditable playbooks with guardrails and human-in-the-loop approval.",
        "Online continual learning of triage thresholds and routing policies based on post-incident audits to reduce false triggers.",
        "Formal verification of the prompt contract and constrained decoding to guarantee schema conformance and quote-grounding."
      ],
      "architectural_improvement_recommendations": [
        "Add constrained decoding with JSON-schema validation at the token level to reduce post-hoc correction cycles.",
        "Introduce a verifier model (LLM-as-a-judge) to independently check evidence-claim alignment and reject ungrounded conclusions.",
        "Expand Evidence Pack with flow-level temporal summaries (rates, bursts, inter-arrival distributions) and protocol-aware parsers (e.g., DNS/SSDP/NTP) to yield richer anchors.",
        "Implement caching and incident deduplication across windows and vantage points to further reduce repeated LLM calls.",
        "Adopt MoE or distilled domain-specific LLMs for the detective role to cut inference latency while maintaining grounding behavior.",
        "Integrate programmable data plane (P4/eBPF) hooks to compute entropy/anchors in-switch and reduce evidence collection overhead."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "LangGraph",
        "OpenAI-compatible API",
        "tshark"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Detective uses OpenPangu-7B with temperature=0 via API; hierarchical on-demand invocation and budgeted tshark evidence extraction; no training or GPU requirements reported."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Cloud network operations with switch interface counters, sFlow triage, and on-demand PCAP evidence; agent invoked via API.",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Reconciling wire-speed monitoring with high LLM latency/cost.",
        "Preventing unfaithful reasoning and hallucinations in security-critical contexts.",
        "Efficient evidence extraction from large PCAPs under tight budgets.",
        "Robust schema-conformant outputs for downstream automation.",
        "Data privacy and scarcity of labeled datasets for supervised alternatives."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Hierarchical Agent Framework that activates deep LLM investigation only on anomaly windows to meet operational budgets.",
      "Anchor-Based Modality Alignment via Evidence Pack that converts binary packets into compact, quotable, reproducible structured evidence.",
      "Quote-Constrained Reasoning with a structure-first investigation protocol and strict JSON schema for auditable, machine-consumable reports.",
      "Replay-based evaluation on CICDDoS2019 reflection/amplification and synthetic flooding scenarios demonstrating grounded attribution and localized failure audit logs."
    ]
  },
  {
    "arxiv_id": "2601.14299v1",
    "title": "Predicting Tail-Risk Escalation in IDS Alert Time Series",
    "authors": "Ambarish Gurjar; L Jean Camp",
    "abstract": "Network defenders face a steady stream of attacks, observed as raw Intrusion Detection System (IDS) alerts. The sheer volume of alerts demands prioritization, typically based on high-level risk classifications. This work expands the scope of risk measurement by examining alerts not only through their technical characteristics but also by examining and classifying their temporal patterns. One critical issue in responding to intrusion alerts is determining whether an alert is part of an escalating attack pattern or an opportunistic scan. To identify the former, we apply extreme-regime forecasting methods from financial modeling to IDS data. Extreme-regime forecasting is designed to identify likely future high-impact events or significant shifts in system behavior. Using these methods, we examine attack patterns by computing per-minute alert intensity, volatility, and a short-term momentum measure derived from weighted moving averages.   We evaluate the efficacy of a supervised learning model for forecasting future escalation patterns using these derived features. The trained model identifies future high-intensity attacks and demonstrates strong predictive performance, achieving approximately 91\\% accuracy, 89\\% recall, and 98\\% precision. Our contributions provide a temporal measurement framework for identifying future high-intensity attacks and demonstrate the presence of predictive early-warning signals within the temporal structure of IDS alert streams. We describe our methods in sufficient detail to enable reproduction using other IDS datasets. In addition, we make the trained models openly available to support further research. Finally, we introduce an interpretable visualization that enables defenders to generate early predictive warnings of elevated volumetric arrival risk.",
    "published_date": "2026-01-16",
    "pdf_link": "https://arxiv.org/pdf/2601.14299v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Forecasting tail-risk escalation in IDS alert streams to predict near-future high-intensity alert periods",
      "attack_types": [
        "opportunistic scans",
        "coordinated campaigns",
        "general intrusion attempts"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Gradient Boosted Decision Trees",
        "specific": "XGBoost",
        "novel_contribution": "Applies extreme-regime (95th-percentile) forecasting with temporal microstructure features (intensity, volatility, momentum via weighted moving averages) to predict future high-intensity IDS alert regimes; first application of predictive tail conditional expectation to IDS data."
      },
      {
        "type": "primary",
        "category": "Time-series feature engineering",
        "specific": "Intensity, volatility estimators, and momentum (weighted moving averages)",
        "novel_contribution": "Adapts finance-inspired volatility–momentum features to IDS alert arrival processes to capture early warning signals of escalation."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Enterprise Suricata IDS alert logs (public US university)",
        "type": "private",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does the short-term temporal microstructure of IDS alert arrivals contain predictive information about imminent transitions into extreme high-intensity regimes that drive operational risk?"
      ],
      "gaps_identified": [
        "Existing IDS time-series work stops short of predicting transitions into extreme high-intensity regimes most critical for operations.",
        "Extreme-event/tail-risk forecasting methods (finance, physics, actuarial science) have not been adapted to real-time forecasting of IDS alert volumes.",
        "Current security visualization tools lack continuous, quantitative early-warning signals for near-future threat pressure.",
        "Absence of an integrated framework combining temporal modeling, tail-risk prediction, and operational usability for SOC decision-making.",
        "Poisson assumptions often violated; Hawkes/self-exciting models did not generalize well for predictive forecasting across severity strata and scales."
      ],
      "limitations": [
        "Evaluation is on a single enterprise (university) network’s Suricata alerts, which may limit generalizability.",
        "Proof-of-concept visualization without formal user studies.",
        "Stratification relies on severity due to sparsity/imbalance in other categorical fields (e.g., MITRE, protocol), potentially omitting informative multivariate interactions."
      ],
      "future_work": [],
      "motivation": "Operational risk in SOCs is driven by episodic surges in alert volume that overwhelm analysts; predicting imminent transitions into high-intensity regimes can enable proactive capacity planning and prioritization.",
      "potential_research_ideas": [
        "Extend forecasting to multivariate regimes by incorporating protocol, MITRE tactic, and sensor-level context to jointly predict cross-stratum cascades.",
        "Quantile regression and extreme-value-aware models (e.g., EQRN) tailored to IDS for direct high-quantile prediction and calibrated risk estimates.",
        "Online learning and drift-adaptive models to maintain performance under changing attacker behavior and network conditions.",
        "Federated learning across organizations/sensors to learn tail-risk predictors without sharing raw alerts.",
        "Decision-theoretic integration: couple forecasts to SOC queueing/scheduling policies optimized for tail-risk (alert surge) mitigation.",
        "Causal/precursor analysis to identify which temporal signatures precede true escalations versus benign surges (e.g., patch Tuesdays, scans).",
        "Uncertainty quantification (conformal prediction) to produce calibrated risk bands for operational thresholds.",
        "Robustness evaluation against adversarial alert injection aiming to spoof escalation signals."
      ],
      "architectural_improvement_recommendations": [
        "Replace point classifier with quantile regression or tail conditional expectation estimation for direct risk scoring and threshold-free operation.",
        "Augment features with multi-scale volatility/momentum (e.g., realized volatility over multiple windows, spectral features) and cross-stratum interactions.",
        "Use temporal deep models (Temporal CNNs, Transformers) with attention over recent windows for non-linear regime transitions, with monotonic constraints for stability.",
        "Hybrid models: combine self-exciting Hawkes components for burstiness with gradient-boosting/Transformer heads for predictive classification.",
        "Incorporate calibration layers (Platt/Isotonic, conformal) to output calibrated probabilities/quantiles for SOC thresholds.",
        "Implement online/streaming inference with sliding-window feature computation and periodic re-training with drift detection."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "XGBoost"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Generalization from one enterprise network to others may be limited.",
        "Heterogeneous and sparse IDS fields complicate multivariate modeling; severity chosen for completeness.",
        "Operational threshold calibration must match an organization’s risk tolerance.",
        "Model and data drift as attacker behavior and network conditions change.",
        "Integration into SOC tooling and workflows; need user studies to validate utility.",
        "Data sharing/privacy constraints hinder cross-organization training."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Measurement of temporal risk signals in IDS alert streams via intensity, volatility, and momentum features.",
      "Extreme-regime forecasting formulation (predict whether future alert intensity exceeds the empirical 95th percentile).",
      "Interpretable early-warning visualization overlaying predicted tail risk on live alert intensity.",
      "Open availability of trained models to support further research.",
      "Reported performance: \"approximately 91% accuracy, 89% recall, and 98% precision\" for identifying future high-intensity attacks."
    ]
  },
  {
    "arxiv_id": "2601.14595v1",
    "title": "IntelliSA: An Intelligent Static Analyzer for IaC Security Smell Detection Using Symbolic Rules and Neural Inference",
    "authors": "Qiyue Mei; Michael Fu",
    "abstract": "Infrastructure as Code (IaC) enables automated provisioning of large-scale cloud and on-premise environments, reducing the need for repetitive manual setup. However, this automation is a double-edged sword: a single misconfiguration in IaC scripts can propagate widely, leading to severe system downtime and security risks. Prior studies have shown that IaC scripts often contain security smells--bad coding patterns that may introduce vulnerabilities--and have proposed static analyzers based on symbolic rules to detect them. Yet, our preliminary analysis reveals that rule-based detection alone tends to over-approximate, producing excessive false positives and increasing the burden of manual inspection. In this paper, we present IntelliSA, an intelligent static analyzer for IaC security smell detection that integrates symbolic rules with neural inference. IntelliSA applies symbolic rules to over-approximate potential smells for broad coverage, then employs neural inference to filter false positives. While an LLM can effectively perform this filtering, reliance on LLM APIs introduces high cost and latency, raises data governance concerns, and limits reproducibility and offline deployment. To address the challenges, we adopt a knowledge distillation approach: an LLM teacher generates pseudo-labels to train a compact student model--over 500x smaller--that learns from the teacher's knowledge and efficiently classifies false positives. We evaluate IntelliSA against two static analyzers and three LLM baselines (Claude-4, Grok-4, and GPT-5) using a human-labeled dataset including 241 security smells across 11,814 lines of real-world IaC code. Experimental results show that IntelliSA achieves the highest F1 score (83%), outperforming baselines by 7-42%. Moreover, IntelliSA demonstrates the best cost-effectiveness, detecting 60% of security smells while inspecting less than 2% of the codebase.",
    "published_date": "2026-01-21",
    "pdf_link": "https://arxiv.org/pdf/2601.14595v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "DevSecOps / Secure Configuration",
      "specific_problem": "Detection of security smells (misconfiguration-prone patterns) in Infrastructure-as-Code (IaC) scripts",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Knowledge Distillation",
        "specific": null,
        "novel_contribution": "Teacher–student distillation where an LLM teacher generates pseudo-labels to train a compact student classifier that filters false positives from symbolic rule matches in IaC."
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "CodeT5p (student model, 220M parameters)",
        "novel_contribution": "Used as an efficient neural classifier for false-positive filtering; shown to match a 770M variant while being 71% smaller."
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "Claude-4 (teacher/baseline)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "Grok-4",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "GPT-5",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised (pseudo-labels via knowledge distillation)",
      "Knowledge Distillation",
      "Zero-shot prompting (baselines)"
    ],
    "datasets": [
      {
        "name": "Human-labeled IaC dataset (241 security smells; 11,814 LOC; Puppet/Ansible/Chef)",
        "type": "public",
        "domain": "iac_scripts",
        "link": "https://github.com/ColeMei/intellisa",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Oracle dataset from Saavedra et al. (GLITCH paper) – 80 Puppet IaC files labeled by three experts",
        "type": "public",
        "domain": "iac_scripts",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      }
    ],
    "baselines": [
      {
        "method_name": "GLITCH (static analyzer)",
        "paper_reference": "Saavedra et al. [14]",
        "metric": "F1 (preliminary, Puppet oracle set)",
        "their_result": "IntelliSA overall F1 0.83 (Puppet 0.85; Ansible 0.88; Chef 0.77)",
        "baseline_result": "Precision 0.418, Recall 0.938, F1 0.578"
      },
      {
        "method_name": "SLIC (static analyzer)",
        "paper_reference": "Rahman et al. [10]",
        "metric": "F1",
        "their_result": "IntelliSA highest F1 overall (83%), +7–42% over baselines",
        "baseline_result": null
      },
      {
        "method_name": "SLAC (static analyzer)",
        "paper_reference": "Rahman et al. [11]",
        "metric": "F1",
        "their_result": "IntelliSA highest F1 overall (83%), +7–42% over baselines",
        "baseline_result": null
      },
      {
        "method_name": "Claude-4 (LLM, zero-shot baseline and teacher in ablation)",
        "paper_reference": null,
        "metric": "F1 (preliminary, Puppet oracle set)",
        "their_result": "IntelliSA overall F1 0.83 (Puppet 0.85; Ansible 0.88; Chef 0.77)",
        "baseline_result": "Precision 0.500, Recall 0.615, F1 0.552"
      },
      {
        "method_name": "Grok-4 (LLM baseline)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "IntelliSA highest F1 overall (83%), +7–42% over baselines",
        "baseline_result": null
      },
      {
        "method_name": "GPT-5 (LLM baseline)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "IntelliSA highest F1 overall (83%), +7–42% over baselines",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Precision",
      "Recall",
      "F1",
      "Macro-F1",
      "Effort@60%Recall",
      "F1@1%LOC"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "RQ1: How accurate is IntelliSA in detecting security smells in IaC scripts?",
        "RQ2: What is the cost-effectiveness of IntelliSA for locating security smells in IaC scripts?",
        "RQ3: What is the impact of key design choices in IntelliSA on the effectiveness of IaC security smell detection?"
      ],
      "gaps_identified": [
        "Rule-based static analyzers over-approximate and have high false-positive rates.",
        "Off-the-shelf LLMs under-approximate (lower recall) for domain-specific IaC security smell detection.",
        "Reliance on external LLM APIs introduces cost, latency, data governance concerns, and limits reproducibility/offline deployment."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Reduce excessive false positives from rule-based IaC smell detection while avoiding the cost/latency/privacy drawbacks of LLM APIs by combining symbolic rules with an efficient distilled neural classifier.",
      "potential_research_ideas": [
        "Augment the student model with multi-task learning to jointly predict smell category and CWE linkage for better calibration.",
        "Incorporate dataflow/taint analysis over the IR to provide semantic context features to the neural classifier.",
        "Active learning loop where uncertain predictions are prioritized for human labeling to iteratively refine the student.",
        "Contrastive pretraining on large unlabeled IaC corpora (Puppet/Ansible/Chef) to improve code representation quality.",
        "Cross-file and cross-repository context modeling (e.g., Hiera/variables resolution) to reduce context-blind false positives.",
        "Uncertainty calibration and selective prediction to further reduce manual review burden.",
        "Online/continual distillation from evolving LLM teachers to keep the student up-to-date without full retraining."
      ],
      "architectural_improvement_recommendations": [
        "Fuse symbolic features (rule IDs, heuristic matches, IR node types) with code-token embeddings via a lightweight fusion module.",
        "Use graph neural networks over the IaC IR to encode structural relationships among modules/unit blocks/atomic units.",
        "Apply knowledge distillation with soft labels and intermediate feature matching to improve student fidelity.",
        "Leverage instruction-tuned code LLMs (small) as students and add domain adapters (LoRA) for IaC specifics.",
        "Introduce a cascaded filtering system: cheap heuristic filter -> student model -> selective high-confidence LLM calls for hard cases."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/ColeMei/intellisa",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": "Student model CodeT5p 220M parameters (matches 770M variant while 71% smaller); distilled student over 500× smaller than LLM teacher; suitable for offline deployment."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "High cost and latency of relying on external LLM APIs.",
        "Data governance and reproducibility concerns with cloud LLMs.",
        "Excessive false positives from rule-based static analyzers increase manual inspection burden."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduce IntelliSA, integrating symbolic rule matching with neural inference to reduce false positives in IaC security smell detection.",
      "Demonstrate higher accuracy and cost-effectiveness than static analyzers and zero-shot LLM baselines; “IntelliSA achieves the highest F1 score (83%), outperforming baselines by 7–42%.”",
      "Validate design choices: Claude-4 as best teacher (F1 89% for false-positive detection), CodeT5p as most effective student (macro-F1 79%); 220M model matches 770M while being 71% smaller."
    ]
  },
  {
    "arxiv_id": "2601.08328v1",
    "title": "APT-MCL: An Adaptive APT Detection System Based on Multi-View Collaborative Provenance Graph Learning",
    "authors": "Mingqi Lv; Shanshan Zhang; Haiwen Liu; Tieming Chen; Tiantian Zhu",
    "abstract": "Advanced persistent threats (APTs) are stealthy and multi-stage, making single-point defenses (e.g., malware- or traffic-based detectors) ill-suited to capture long-range and cross-entity attack semantics. Provenance-graph analysis has become a prominent approach for APT detection. However, its practical deployment is hampered by (i) the scarcity of APT samples, (ii) the cost and difficulty of fine-grained APT sample labeling, and (iii) the diversity of attack tactics and techniques. Aiming at these problems, this paper proposes APT-MCL, an intelligent APT detection system based on Multi-view Collaborative provenance graph Learning. It adopts an unsupervised learning strategy to discover APT attacks at the node level via anomaly detection. After that, it creates multiple anomaly detection sub-models based on multi-view features and integrates them within a collaborative learning framework to adapt to diverse attack scenarios. Extensive experiments on three real-world APT datasets validate the approach: (i) multi-view features improve cross-scenario generalization, and (ii) co-training substantially boosts node-level detection under label scarcity, enabling practical deployment on diverse attack scenarios.",
    "published_date": "2026-01-13",
    "pdf_link": "https://arxiv.org/pdf/2601.08328v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Host/Endpoint Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Node-level anomaly detection on host provenance graphs for APT detection",
      "attack_types": [
        "Advanced Persistent Threats (multi-stage)",
        "Ransomware",
        "Collection & Exfiltration",
        "Reconnaissance"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": null,
        "novel_contribution": "GNN-based anomaly detection sub-models trained per feature view to capture causal/contextual correlations in provenance graphs"
      },
      {
        "type": "primary",
        "category": "Co-training / Semi-supervised learning",
        "specific": "Collaborative learning with pseudo labels",
        "novel_contribution": "Multi-view collaborative framework that transitions unsupervised sub-models into a semi-supervised setting via pseudo labels to improve generalization under label scarcity"
      },
      {
        "type": "primary",
        "category": "Feature engineering",
        "specific": "Multi-view features",
        "novel_contribution": "Two complementary feature views: (1) structural features from distributions of 21 edge types (in/out) per node; (2) behavioral features as binary indicators of sensitive activities (20-D)"
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GraphSAGE-style (as in ThreaTrace)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph kernel + clustering",
        "specific": "StreamSpot",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph kernel",
        "specific": "Unicorn (WL-kernel-based)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Semi-supervised (via pseudo-label co-training)"
    ],
    "datasets": [
      {
        "name": "DARPA Transparent Computing (DARPA TC)",
        "type": "public",
        "domain": "provenance_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "StreamSpot dataset",
        "type": "public",
        "domain": "provenance_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "RWD (Ransomware Dataset)",
        "type": "proprietary",
        "domain": "provenance_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "ThreaTrace",
        "paper_reference": "[19]",
        "metric": "F1-score",
        "their_result": null,
        "baseline_result": "0.965 (DARPA TC), 0.948 (StreamSpot), 0.242 (RWD) when trained/tested within same dataset"
      },
      {
        "method_name": "StreamSpot",
        "paper_reference": "[20],[38]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Unicorn",
        "paper_reference": "[39]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to detect node-level APT activities from host provenance graphs under scarcity of labeled attack samples?",
        "Can multi-view features improve cross-scenario generalization for diverse APT tactics and techniques?",
        "Can collaborative (co-training) learning boost unsupervised anomaly detection performance under label scarcity?"
      ],
      "gaps_identified": [
        "Scarcity of real APT samples for training",
        "High cost and difficulty of fine-grained labeling of malicious nodes in provenance graphs",
        "Poor cross-domain adaptability of existing models to diverse attack tactics and techniques"
      ],
      "limitations": [
        "Unsupervised models are prone to overfitting across diverse attack scenarios",
        "Fine-grained node-level labeling remains difficult, motivating reliance on pseudo labels (implied)"
      ],
      "future_work": [],
      "motivation": "Single-point detectors miss long-range, cross-entity attack semantics; need a provenance-graph approach that works under label scarcity and across diverse APT tactics.",
      "potential_research_ideas": [
        "Domain adaptation or meta-learning to further improve cross-scenario generalization across heterogeneous hosts and organizations",
        "Self-supervised pretraining on large benign provenance corpora (e.g., contrastive or masked graph modeling) before anomaly detection",
        "Temporal/streaming graph modeling for online APT detection with concept drift handling",
        "Augment behavioral view with ATT&CK-aligned knowledge graphs for more semantic anomaly scoring",
        "Active learning strategies to solicit minimal expert labels to refine pseudo labels and reduce noise",
        "Adversarial robustness evaluation and defenses against log tampering or mimicry attacks",
        "Cross-host correlation (lateral movement) by building inter-host provenance graphs to detect coordinated campaigns"
      ],
      "architectural_improvement_recommendations": [
        "Adopt heterogeneous GNNs (e.g., RGCN/HGT) to explicitly model typed nodes/edges instead of collapsing into counts",
        "Incorporate temporal GNNs or graph transformers to capture sequence and timing of events",
        "Uncertainty-aware pseudo-labeling with confidence calibration and agreement-based filtering in co-training",
        "Multi-task setup that jointly predicts sensitive-behavior tags and anomaly scores to regularize representations",
        "Use learnable embedding of behavioral features instead of binary indicators, possibly via attention over IoC types"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Host OS with provenance/audit logging (e.g., KELLECT-based collection)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Scarcity of labeled APT data for training and evaluation",
        "Diversity of attack tactics/techniques affecting cross-scenario generalization",
        "Risk of overfitting in unsupervised settings across heterogeneous environments"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Unsupervised node-level APT detection from benign provenance graphs via anomaly detection",
      "Design of multi-view (structural and behavioral) features compatible with most APT datasets to cover diverse scenarios",
      "Collaborative learning framework integrating sub-models per view, gradually transitioning to supervised via pseudo labels",
      "Extensive experiments on three real-world APT datasets showing improved generalization and detection stability"
    ]
  },
  {
    "arxiv_id": "2601.16681v1",
    "title": "From Transactions to Exploits: Automated PoC Synthesis for Real-World DeFi Attacks",
    "authors": "Xing Su; Hao Wu; Hanzhong Liang; Yunlin Jiang; Yuxi Cheng; Yating Liu; Fengyuan Xu",
    "abstract": "Blockchain systems are increasingly targeted by on-chain attacks that exploit contract vulnerabilities to extract value rapidly and stealthily, making systematic analysis and reproduction highly challenging. In practice, reproducing such attacks requires manually crafting proofs-of-concept (PoCs), a labor-intensive process that demands substantial expertise and scales poorly. In this work, we present the first automated framework for synthesizing verifiable PoCs directly from on-chain attack executions. Our key insight is that attacker logic can be recovered from low-level transaction traces via trace-driven reverse engineering, and then translated into executable exploits by leveraging the code-generation capabilities of large language models (LLMs). To this end, we propose TracExp, which localizes attack-relevant execution contexts from noisy, multi-contract traces and introduces a novel dual-decompiler to transform concrete executions into semantically enriched exploit pseudocode. Guided by this representation, TracExp synthesizes PoCs and refines them to preserve exploitability-relevant semantics. We evaluate TracExp on 321 real-world attacks over the past 20 months. TracExp successfully synthesizes PoCs for 93% of incidents, with 58.78% being directly verifiable, at an average cost of only \\$0.07 per case. Moreover, TracExp enabled the release of a large number of previously unavailable PoCs to the community, earning a $900 bounty and demonstrating strong practical impact.",
    "published_date": "2026-01-23",
    "pdf_link": "https://arxiv.org/pdf/2601.16681v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "DeFi Security",
      "specific_problem": "Automated synthesis of proof-of-concept exploits directly from on-chain transaction traces for real-world DeFi attacks",
      "attack_types": [
        "flash loan",
        "price manipulation",
        "reentrancy",
        "multi-contract exploit"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer LLM (code generation)",
        "specific": null,
        "novel_contribution": "LLM-guided PoC code synthesis driven by a trace-to-pseudocode pipeline and an exploit-aware refinement loop validated via fund-flow oracles"
      }
    ],
    "learning_paradigm": [
      "Generative (LLM code synthesis)",
      "Prompt-based",
      "Tool-augmented LLM (program analysis + validation-in-the-loop)"
    ],
    "datasets": [
      {
        "name": "321 real-world DeFi attack transactions (20 months)",
        "type": "public",
        "domain": "blockchain_transaction_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "DeFiHackLabs PoC corpus",
        "type": "public",
        "domain": "poc_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "WebkeyDAO attack transaction (example)",
        "type": "public",
        "domain": "blockchain_transaction_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Static EVM decompilers (e.g., SOTA decompiler [22,23])",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Manual expert-created PoCs (community efforts such as DeFiHackLabs)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "PoC synthesis success rate (93%)",
      "Directly verifiable PoC rate (58.78%)",
      "Average runtime (<5 minutes per case)",
      "Average monetary cost (~$0.07 per case)",
      "Number of previously unavailable PoCs contributed (33 within 2 days)",
      "Community bounty earned ($900)",
      "Ranked 1st in monthly submissions (share: 38% of all submissions that month)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can we automatically synthesize verifiable PoC code for real-world DeFi attacks directly from on-chain transactions?",
        "How can attacker logic be recovered from low-level, multi-contract traces via trace-driven reverse engineering?",
        "How can LLMs be leveraged to generate runnable exploits while reducing hallucinations and ensuring semantic exploitability?"
      ],
      "gaps_identified": [
        "Manual PoC construction is labor-intensive and scales poorly; ~50% of incidents lack PoCs.",
        "Execution traces are low-level, verbose, and span many contracts, making attack logic isolation difficult.",
        "Static decompilers are path-insensitive and imprecise for dynamic behaviors (e.g., call args, data flows, fund flows), hindering precise recovery.",
        "LLMs can hallucinate; generic prompts fail to capture domain-specific exploit strategies without tailored guidance and validation."
      ],
      "limitations": [
        "The system does not detect attacks or identify root-cause vulnerabilities; it focuses on PoC synthesis from observed transactions.",
        "Targets EVM-based blockchains; non-EVM ecosystems are out of scope.",
        "Assumes by default that most attacks use adversary-controlled contracts; direct-to-victim interactions require configuration.",
        "Only 58.78% of synthesized PoCs are directly verifiable despite a 93% synthesis rate.",
        "Relies on single concrete execution traces; alternative feasible paths and generalization beyond the observed run may be missed."
      ],
      "future_work": [],
      "motivation": "Close the widening gap between the growing number/complexity of DeFi attacks and the limited availability of expert-crafted PoCs by transforming on-chain execution evidence into reproducible exploit logic automatically.",
      "potential_research_ideas": [
        "Extend the framework beyond EVM to other smart-contract platforms (e.g., Solana, Move-based chains) with analogous trace and fund-flow oracles.",
        "Joint learning of exploit patterns by fine-tuning code LLMs on curated PoC corpora to reduce hallucination and improve attack-specific reasoning.",
        "Integrate symbolic execution or concolic analysis with the trace-driven pipeline to generalize beyond a single concrete trace and infer missing parameters.",
        "Automated multi-transaction exploit reconstruction (sequencing across blocks) for attacks spanning multiple transactions.",
        "Online/real-time PoC synthesis from mempool transactions for proactive incident response and rapid triage.",
        "Standardized benchmark suite for PoC synthesis with ground-truth verifiability labels and cost/runtime tracking."
      ],
      "architectural_improvement_recommendations": [
        "Constrained code generation (e.g., type/state-aware decoding, contract ABI-aware constraints) to reduce syntactic/semantic errors.",
        "Use a domain-adapted retrieval-augmented generation (RAG) layer over protocol ABIs, verified source (when available), and known PoCs to guide LLM synthesis.",
        "Introduce a hybrid validator combining fund-flow oracles with execution-diff checks and invariant assertions to catch subtle semantic deviations.",
        "Employ incremental synthesis with unit-test scaffolding (function-level PoCs) before end-to-end exploit assembly for better controllability.",
        "Leverage multi-agent LLM workflows (planner, coder, verifier) with explicit attack-taxonomy prompts to structure complex exploits."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Foundry",
        "Ethereum client tracing (e.g., Geth debug_traceTransaction)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "<5 minutes per case; ~$0.07 LLM API cost per case; no specialized hardware mentioned"
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "<5 minutes per case",
      "deployment_challenges": [
        "LLM hallucinations causing syntactic or semantic deviations",
        "Complex, noisy, multi-contract traces complicate recovery",
        "Limited to EVM ecosystems and availability of transaction traces",
        "Ensuring semantic exploitability rather than strict trace equivalence"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First automated framework (TracExp) that synthesizes verifiable PoCs directly from on-chain attack transactions, attack-agnostic and source-free.",
      "Trace-driven reverse engineering with a dual decompiler integrating static decompilation and dynamic values to recover concise exploit pseudocode from a single execution.",
      "Exploit-aware validation and refinement mechanism leveraging fund-flow oracles to ensure semantic exploitability and repair deviations.",
      "Large-scale evaluation on 321 real-world attacks: 93% PoC synthesis success, 58.78% directly verifiable, average cost ~$0.07 per case and runtime <5 minutes.",
      "Demonstrated practical impact by contributing 33 previously unavailable PoCs to the community, earning $900 bounty and ranking 1st in monthly submissions."
    ]
  },
  {
    "arxiv_id": "2601.14544v1",
    "title": "AI Agents vs. Human Investigators: Balancing Automation, Security, and Expertise in Cyber Forensic Analysis",
    "authors": "Sneha Sudhakaran; Naresh Kshetri",
    "abstract": "In an era where cyber threats are rapidly evolving, the reliability of cyber forensic analysis has become increasingly critical for effective digital investigations and cybersecurity responses. AI agents are being adopted across digital forensic practices due to their ability to automate processes such as anomaly detection, evidence classification, and behavioral pattern recognition, significantly enhancing scalability and reducing investigation timelines. However, the characteristics that make AI indispensable also introduce notable risks. AI systems, often trained on biased or incomplete datasets, can produce misleading results, including false positives and false negatives, thereby jeopardizing the integrity of forensic investigations. This study presents a meticulous comparative analysis of the effectiveness of the most used AI agent, ChatGPT, and human forensic investigators in the realm of cyber forensic analysis. Our research reveals critical limitations within AI-driven approaches, demonstrating scenarios in which sophisticated or novel cyber threats remain undetected due to the rigid pattern-based nature of AI systems. Conversely, our analysis highlights the crucial role that human forensic investigators play in mitigating these risks. Through adaptive decision-making, ethical reasoning, and contextual understanding, human investigators effectively identify subtle anomalies and threats that may evade automated detection systems. To reinforce our findings, we conducted comprehensive reliability testing of forensic techniques using multiple cyber threat scenarios. These tests confirmed that while AI agents significantly improve the efficiency of routine analyses, human oversight remains crucial in ensuring accuracy and comprehensiveness of the results.",
    "published_date": "2026-01-20",
    "pdf_link": "https://arxiv.org/pdf/2601.14544v1",
    "paper_types": [
      "position",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Digital Forensics",
      "subdomain": "Cyber Forensic Investigation",
      "specific_problem": "Comparative evaluation of AI agents (ChatGPT and ML tools) versus human investigators for reliability in cyber forensic analysis and a proposed hybrid AI–human workflow",
      "attack_types": [
        "malware",
        "phishing",
        "deepfake",
        "insider threat",
        "intrusion"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer/LLM",
        "specific": "ChatGPT",
        "novel_contribution": "Used as the primary AI agent under evaluation in multiple forensic prompts/scenarios; no novel model introduced"
      },
      {
        "type": "baseline",
        "category": "Anomaly Detection",
        "specific": null,
        "novel_contribution": "Unsupervised anomaly detection used as part of AI-driven tools"
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Neural Network",
        "specific": null,
        "novel_contribution": "Generic neural networks for classification; architecture not specified"
      },
      {
        "type": "baseline",
        "category": "Clustering",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "NLP",
        "specific": null,
        "novel_contribution": "NLP models for pattern recognition; specifics not provided"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Curated network intrusion traces",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Curated mobile and desktop memory dumps",
        "type": "private",
        "domain": "memory_dumps",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Curated malware binaries",
        "type": "private",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Curated phishing email corpora",
        "type": "private",
        "domain": "email_corpora",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "false positive rate",
      "false negative rate",
      "accuracy",
      "time efficiency",
      "evidentiary soundness"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How reliable are AI-driven forensic analyses compared to human investigators across diverse cyber threat scenarios?",
        "What are the false positive and false negative rates of AI agents in cyber forensic tasks, and how do they impact evidentiary integrity?",
        "In which scenarios do AI agents fail due to lack of context or bias, and how does human oversight mitigate these failures?",
        "Can a hybrid AI–human forensic workflow improve accuracy and evidentiary soundness while preserving efficiency?"
      ],
      "gaps_identified": [
        "AI models used in forensics can be opaque, biased, and vulnerable to adversarial or novel conditions, leading to false positives/negatives and legal admissibility concerns",
        "Lack of explainability and transparency in AI tools undermines trust by analysts and courts",
        "Insufficient standardization and benchmarking for AI in digital forensics across domains such as memory, malware, network traces, and phishing",
        "Challenges in accountability and privacy when using AI at scale in forensic contexts",
        "Human workload and training burdens when integrating AI tools into forensic practice"
      ],
      "limitations": [
        "Currently, we manually assessed our analysis results for validation as we tested this only on 20 cases or prompts for analysis.",
        "Datasets are described at a high level (curated across multiple domains) without naming specific public benchmarks or providing links/release details.",
        "No quantitative metric values are reported for AI-only vs human-only vs hybrid comparisons; results are qualitative/case-based.",
        "Specific architectures, training regimes, or parameterizations for the ML models are not provided."
      ],
      "future_work": [
        "Expand the number and diversity of prompts/case studies with consultation from forensic researchers and educational integrations.",
        "Further operationalize and evaluate the proposed hybrid framework with reproducible, containerized workflows.",
        "Incorporate explainable AI techniques to improve legal defensibility and analyst trust.",
        "Develop more rigorous benchmarking and standardized evaluation protocols for forensic AI under adversarial and missing-data conditions."
      ],
      "motivation": "To assess and balance the efficiency gains of AI agents in digital forensics with the need for contextual accuracy, ethical judgment, and legal defensibility provided by human investigators, and to propose a hybrid approach that improves overall reliability.",
      "potential_research_ideas": [
        "Create a standardized, publicly available digital forensics benchmark suite with verified ground truth and adversarial/missing-data variants across network, memory, malware, phishing, and multimedia deepfake domains.",
        "Develop uncertainty-aware forensic AI that produces calibrated confidence, selective abstention, and explicit uncertainty markers in timelines and attributions.",
        "Design a retrieval-augmented forensic LLM that grounds every claim in verifiable evidence artifacts (hashes, headers, logs) and preserves chain-of-custody provenance.",
        "Establish human-in-the-loop evaluation protocols that measure inter-rater reliability, error correction rates, and oversight efficacy across AI, human, and hybrid workflows.",
        "Build explainable anomaly detection tailored to memory forensics and network traces with causal or rule-based rationales suitable for court testimony.",
        "Create a robustness evaluation framework for forensic AI under obfuscation, data loss, polymorphic malware, and synthetic deepfake manipulation.",
        "Engineer tool-augmented AI agents that automatically invoke DKIM/SPF/DMARC, hash comparison, YARA, and timeline reconstruction utilities with verifiable outputs.",
        "Develop a legal admissibility scoring model and audit trail generator integrated into forensic pipelines to document interpretability, bias checks, and provenance.",
        "Create bias auditing and dataset curation tools to detect and mitigate demographic or artifact-selection biases in forensic datasets.",
        "Simulate insider threat environments with synthetic but realistic enterprise traces to evaluate hybrid detection and attribution workflows."
      ],
      "architectural_improvement_recommendations": [
        "Integrate an ensemble of classical detectors (SVM/RF/NN/anomaly detection) with an LLM mediator that proposes hypotheses but must cite evidence artifacts (hashes, headers, logs) before emitting conclusions.",
        "Use retrieval-augmented generation with constraint-based decoding that allows only claims backed by retrieved, hashed, and provenance-logged artifacts.",
        "Add calibrated uncertainty estimation (e.g., temperature scaling, conformal prediction) and selective abstention to reduce overconfident misclassifications.",
        "Implement active learning loops where human corrections are fed back to update thresholds, detectors, and LLM prompt templates.",
        "Adopt comprehensive provenance capture (cryptographic hashing, data lineage, containerized environments) to support chain-of-custody and reproducibility.",
        "Standardize structured outputs (JSON schemas for findings, timelines, confidence, evidence references) to enable downstream verification and auditing.",
        "Harden the pipeline against adversarial inputs (sanity checks, ensemble cross-validation, anomaly gating) and incorporate deepfake-specific forensic checks.",
        "Package the hybrid workflow into reproducible Docker images with versioned configs and automated CI tests on synthetic and held-out cases."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Laboratory evaluation with curated datasets; hybrid workflow prototyped with Dockerized containers",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Trust and interpretability of AI outputs for legal admissibility",
        "Bias and data quality issues leading to false positives/negatives",
        "Adversarial robustness under novel/sophisticated threats and data loss",
        "Human training needs and cognitive load when verifying AI outputs",
        "Privacy and accountability concerns in large-scale evidence processing",
        "Risk of over-reliance on automation without adequate oversight"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": true
    },
    "contributions": [
      "Examining the comparative strengths and weaknesses of AI agents and human investigators.",
      "Quantifying the risks of false positives/negatives in AI-based analysis and their impact on forensic integrity.",
      "Proposing a hybrid forensic framework that leverages AI efficiencies while retaining critical human oversight for contextual accuracy."
    ]
  },
  {
    "arxiv_id": "2601.09902v1",
    "title": "A Novel Contrastive Loss for Zero-Day Network Intrusion Detection",
    "authors": "Jack Wilkie; Hanan Hindy; Craig Michie; Christos Tachtatzis; James Irvine; Robert Atkinson",
    "abstract": "Machine learning has achieved state-of-the-art results in network intrusion detection; however, its performance significantly degrades when confronted by a new attack class -- a zero-day attack. In simple terms, classical machine learning-based approaches are adept at identifying attack classes on which they have been previously trained, but struggle with those not included in their training data. One approach to addressing this shortcoming is to utilise anomaly detectors which train exclusively on benign data with the goal of generalising to all attack classes -- both known and zero-day. However, this comes at the expense of a prohibitively high false positive rate. This work proposes a novel contrastive loss function which is able to maintain the advantages of other contrastive learning-based approaches (robustness to imbalanced data) but can also generalise to zero-day attacks. Unlike anomaly detectors, this model learns the distributions of benign traffic using both benign and known malign samples, i.e. other well-known attack classes (not including the zero-day class), and consequently, achieves significant performance improvements. The proposed approach is experimentally verified on the Lycos2017 dataset where it achieves an AUROC improvement of .000065 and .060883 over previous models in known and zero-day attack detection, respectively. Finally, the proposed method is extended to open-set recognition achieving OpenAUC improvements of .170883 over existing approaches.",
    "published_date": "2026-01-14",
    "pdf_link": "https://arxiv.org/pdf/2601.09902v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Zero-day network intrusion detection and open-set recognition for NIDS",
      "attack_types": [
        "zero-day attacks"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Contrastive Learning",
        "specific": "CLAD (Contrastive Learning for Anomaly Detection)",
        "novel_contribution": "A novel contrastive loss that models the benign class as a von-Mises Fisher (vMF) distribution on the unit hypersphere, learning the density ratio P(x|y=0)/P(x|y≠0). The loss uses only benign anchors, squared cosine-distance terms, and treats malicious samples as normalisers, improving zero-day generalisation and robustness to class imbalance."
      },
      {
        "type": "primary",
        "category": "Open-Set Recognition",
        "specific": "CLOSR (Contrastive Learning for Open-Set Recognition)",
        "novel_contribution": "Extends CLAD with class-wise linear projections to model each known class as an independent vMF distribution in distinct subspaces; performs multiclass closed-set classification and unknown-class rejection with an OOD score based on cosine similarity to class centroids."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Lycos2017",
        "type": "",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "AUROC",
      "OpenAUC"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a contrastive loss that explicitly models only the benign distribution (with benign anchors) generalise to zero-day attacks while retaining robustness to class imbalance?",
        "Can the proposed approach be extended to open-set recognition to enable multiclass classification with unknown-class rejection in NIDS?"
      ],
      "gaps_identified": [
        "Supervised NIDS models degrade on unseen (zero-day) attack classes despite strong closed-set performance.",
        "Anomaly detectors trained only on benign data often suffer prohibitively high false positive rates in practice.",
        "Existing open-set recognition methods (e.g., DOC, OpenMax) show substandard performance for zero-day attack detection in NIDS.",
        "Contrastive methods, while robust to imbalance, typically assume symmetry between known and unknown malicious classes and thus struggle with zero-day attacks."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve NIDS robustness to zero-day attacks without incurring high false positive rates typical of anomaly detection, and leverage contrastive learning’s imbalance robustness while breaking the symmetry assumption that harms zero-day generalisation.",
      "potential_research_ideas": [
        "Evaluate CLAD/CLOSR across diverse NIDS datasets (e.g., CIC-IDS2017/2018, UNSW-NB15, Bot-IoT, IoT-23) to assess generality and domain shift robustness.",
        "Extend to streaming/online learning with adaptive centroid updates and concept drift detection for evolving network traffic.",
        "Incorporate self-supervised pretraining on large unlabeled network traffic and fine-tune with CLAD to reduce labeled data requirements.",
        "Model benign traffic as a mixture of vMF components to capture benign submodes and further reduce false positives.",
        "Combine CLAD with calibrated uncertainty estimation or conformal prediction for principled thresholding and alert triage.",
        "Integrate federated learning to train CLAD across multiple organisations while preserving data privacy.",
        "Explore adversarial robustness of hyperspherical/vMF embeddings against evasion attacks tailored to cosine-distance OOD scoring."
      ],
      "architectural_improvement_recommendations": [
        "Learn class-specific concentration parameters κ end-to-end and/or make them sample-dependent via a small gating network.",
        "Adopt a mixture-of-prototypes (multiple centroids) for benign and known classes to capture multimodality.",
        "Introduce a memory bank or queue for more stable contrastive negative sampling beyond mini-batch statistics.",
        "Use transformer-based tabular backbones or feature tokenisation to improve representation capacity for complex flows.",
        "Jointly learn OOD thresholds via differentiable surrogate losses and temperature scaling for better calibration.",
        "Augment training with synthetic near-boundary samples (e.g., mixup/manifold mixup in embedding space) to enlarge margins.",
        "Regularise with hyperspherical uniformity losses to maintain inter-class angular separation in CLOSR."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/jackwilkie/CLOSR",
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A contrastive loss for binary NIDS that exclusively learns the benign distribution while still training on malicious traffic (CLAD).",
      "An extension to open-set recognition enabling multiclass classification with unknown-class rejection via class-wise vMF modelling (CLOSR).",
      "Empirical comparison on Lycos2017 showing AUROC improvement of 0.000065 (known attacks) and 0.060883 (zero-day), and OpenAUC improvement of 0.170883 over prior approaches."
    ]
  },
  {
    "arxiv_id": "2601.09933v1",
    "title": "Malware Classification using Diluted Convolutional Neural Network with Fast Gradient Sign Method",
    "authors": "Ashish Anand; Bhupendra Singh; Sunil Khemka; Bireswar Banerjee; Vishi Singh Bhatia; Piyush Ranjan",
    "abstract": "Android malware has become an increasingly critical threat to organizations, society and individuals, posing significant risks to privacy, data security and infrastructure. As malware continues to evolve in terms of complexity and sophistication, the mitigation and detection of these malicious software instances have become more time consuming and challenging particularly due to the requirement of large number of features to identify potential malware. To address these challenges, this research proposes Fast Gradient Sign Method with Diluted Convolutional Neural Network (FGSM DICNN) method for malware classification. DICNN contains diluted convolutions which increases receptive field, enabling the model to capture dispersed malware patterns across long ranges using fewer features without adding parameters. Additionally, the FGSM strategy enhance the accuracy by using one-step perturbations during training that provides more defensive advantage of lower computational cost. This integration helps to manage high classification accuracy while reducing the dependence on extensive feature sets. The proposed FGSM DICNN model attains 99.44% accuracy while outperforming other existing approaches such as Custom Deep Neural Network (DCNN).",
    "published_date": "2026-01-14",
    "pdf_link": "https://arxiv.org/pdf/2601.09933v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "Android Malware Detection",
      "specific_problem": "Supervised classification of Android apps into malware families/benign using static+dynamic features with a dilated CNN trained with FGSM-generated adversarial samples",
      "attack_types": [
        "Android malware (SMS, BankBot, Airpush)",
        "Evasion/adversarial perturbations (FGSM used during training)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "Dilated Convolutional Neural Network (DI-CNN)",
        "novel_contribution": "Uses dilated (\"diluted\") convolutions to increase receptive field without adding parameters for malware feature patterns spread across long ranges"
      },
      {
        "type": "primary",
        "category": "Adversarial Training",
        "specific": "FGSM (Fast Gradient Sign Method) one-step perturbations",
        "novel_contribution": "Generates adversarial samples during training to improve robustness/generalization at low computational cost"
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "DNN",
        "specific": "Custom Deep Neural Network (DCNN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Selection",
        "specific": "FSSDroid (MI + CFS feature subset selection)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Selection",
        "specific": "MWHFST (Multi-Wrapper Hybrid Feature Selection Technique)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Permission-based/Similarity Learning",
        "specific": "PermGuard (permission-to-exploitation mapping with similarity-based selective training)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "ANN",
        "specific": "Feedforward NN (FNN), CNN, GNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Selection",
        "specific": "RFE (Recursive Feature Elimination) as part of pipeline",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Adversarial training"
    ],
    "datasets": [
      {
        "name": "KronoDroid 2021",
        "type": "public",
        "domain": "android_app_features",
        "link": "https://www.kaggle.com/datasets/dhoogla/kronodroid-2021",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random Forest (RF)",
        "paper_reference": "[16]",
        "metric": "Accuracy",
        "their_result": "99.41",
        "baseline_result": "87.24"
      },
      {
        "method_name": "Random Forest (RF)",
        "paper_reference": "[16]",
        "metric": "Precision",
        "their_result": "99.38",
        "baseline_result": "90.14"
      },
      {
        "method_name": "Random Forest (RF)",
        "paper_reference": "[16]",
        "metric": "Recall",
        "their_result": "99.37",
        "baseline_result": "74.20"
      },
      {
        "method_name": "Random Forest (RF)",
        "paper_reference": "[16]",
        "metric": "F1-Score",
        "their_result": "99.36",
        "baseline_result": "81.39"
      },
      {
        "method_name": "FSSDroid",
        "paper_reference": "[17]",
        "metric": "Accuracy",
        "their_result": "99.41",
        "baseline_result": "98.50"
      },
      {
        "method_name": "FSSDroid",
        "paper_reference": "[17]",
        "metric": "Precision",
        "their_result": "99.38",
        "baseline_result": "98.50"
      },
      {
        "method_name": "FSSDroid",
        "paper_reference": "[17]",
        "metric": "Recall",
        "their_result": "99.37",
        "baseline_result": "98.60"
      },
      {
        "method_name": "MWHFST",
        "paper_reference": "[18]",
        "metric": "Accuracy",
        "their_result": "99.41",
        "baseline_result": "88"
      },
      {
        "method_name": "MWHFST",
        "paper_reference": "[18]",
        "metric": "F1-Score",
        "their_result": "99.36",
        "baseline_result": "88"
      },
      {
        "method_name": "Custom Deep Neural Network (DCNN)",
        "paper_reference": "[19]",
        "metric": "Accuracy",
        "their_result": "99.41",
        "baseline_result": "94"
      },
      {
        "method_name": "PermGuard",
        "paper_reference": "[20]",
        "metric": "Accuracy",
        "their_result": "99.41",
        "baseline_result": "99.33"
      },
      {
        "method_name": "PermGuard",
        "paper_reference": "[20]",
        "metric": "Precision",
        "their_result": "99.38",
        "baseline_result": "99.34"
      },
      {
        "method_name": "PermGuard",
        "paper_reference": "[20]",
        "metric": "Recall",
        "their_result": "99.37",
        "baseline_result": "99.32"
      },
      {
        "method_name": "PermGuard",
        "paper_reference": "[20]",
        "metric": "F1-Score",
        "their_result": "99.36",
        "baseline_result": "99.33"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-Score"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a dilated CNN capture long-range feature dependencies in Android malware to reduce dependence on large feature sets while maintaining high accuracy?",
        "Does integrating FGSM adversarial samples during training improve malware classification accuracy and robustness at low computational cost?"
      ],
      "gaps_identified": [
        "Outdated datasets and concept shift complicate malware classification",
        "Dynamic analysis requires precise environments and is resource-intensive",
        "Existing approaches often require a large number of features for reliable detection"
      ],
      "limitations": [
        "Evaluation restricted to KronoDroid dataset with only three malware categories (SMS, BankBot, Airpush) selected to form balanced subsets",
        "No reported ablation on dilation rates or FGSM epsilon values beyond listing candidates",
        "No explicit robustness evaluation under adversarial attack at test time beyond training with FGSM",
        "No code or detailed hyperparameters disclosed for full reproducibility"
      ],
      "future_work": [
        "Use advanced DL models to defend against non-defensive and non-dilated attacks to improve defensive strength and context modelling, making it more applicable for real-world malware systems"
      ],
      "motivation": "Reduce feature dependence and computational cost while improving accuracy and robustness for Android malware classification amid evolving threats and concept drift",
      "potential_research_ideas": [
        "Evaluate robustness with stronger multi-step adversaries (e.g., PGD) and compare against TRADES/Adversarial Logit Pairing for malware tabular features",
        "Ablation study on dilation schedules, receptive field sizing, and architectural variants (stacked dilated blocks, residual/SE connections)",
        "Cross-dataset generalization to Drebin, AndroZoo, VirusShare-derived corpora; domain adaptation to address concept drift",
        "Online/continual learning pipeline for evolving Android malware families with rehearsal or regularization to counter catastrophic forgetting",
        "Certified or randomized smoothing-based robustness for tabular malware features",
        "Explainability for security analysts (e.g., SHAP on features, saliency over permissions/APIs) and trust calibration",
        "Few-shot/zero-shot family detection via metric learning or prototypical networks for emerging families",
        "Hybrid static-dynamic multi-view fusion with attention over heterogeneous feature groups"
      ],
      "architectural_improvement_recommendations": [
        "Adopt residual dilated convolutional stacks with squeeze-and-excitation or attention to improve feature selection within the network",
        "Use temporal convolutional networks (TCN) or 1D dilated convolutions tailored to ordered feature sequences (e.g., API call sequences)",
        "Incorporate feature-group attention (permissions, intents, API calls, dynamic traces) before the CNN for better modality weighting",
        "Replace FGSM with multi-step PGD adversarial training or TRADES to enhance robustness, with early stopping to control overfitting",
        "Apply mixup/cutmix and label smoothing for improved generalization; calibrate outputs with temperature scaling",
        "Hyperparameter search for dilation rates, kernel sizes, and depth; include dropout and batch norm placements optimized for tabular inputs"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Implemented in Python 3.8 on Intel Core i7-4200U CPU, Windows 10 64-bit, 16GB RAM; 80/20 stratified split; FGSM epsilon tried at 0.01, 0.05, 0.1"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Concept shift complicates sustained performance",
        "Dynamic analysis requires precise controlled environments",
        "Large feature extraction pipelines can be costly; method aims to reduce this dependence"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes FGSM-DICNN: a malware classifier combining dilated convolutional neural networks with FGSM-based adversarial sample generation during training",
      "Uses dilated convolutions to enlarge receptive fields without increasing parameters, aiming to reduce dependence on extensive feature sets",
      "Demonstrates high performance on KronoDroid (Accuracy 99.41%, Precision 99.38%, Recall 99.37%, F1-Score 99.36), outperforming RF, DCNN, FSSDroid, MWHFST, and PermGuard baselines",
      "Provides a preprocessing and feature selection pipeline including normalization, encoding, stratified splitting, and RFE"
    ]
  },
  {
    "arxiv_id": "2601.07305v1",
    "title": "Memory-Based Malware Detection under Limited Data Conditions: A Comparative Evaluation of TabPFN and Ensemble Models",
    "authors": "Valentin Leroy; Shuvalaxmi Dass; Sharif Ullah",
    "abstract": "Artificial intelligence and machine learning have significantly advanced malware research by enabling automated threat detection and behavior analysis. However, the availability of exploitable data is limited, due to the absence of large datasets with real-world data. Despite the progress of AI in cybersecurity, malware analysis still suffers from this data scarcity, which limits model generalization. In order to tackle this difficulty, this workinvestigates TabPFN, a learning-free model designed for low-data regimes. We evaluate its performance against established baselines such as Random Forest, LightGBM and XGBoost, across multiple class configurations. Our experimental results indicate that TabPFN surpasses all other models in low-data regimes, with a 2% to 6% improvement observed across multiple performance metrics. However, this increase in performance has an impact on its computation time in a particular case. These findings highlight both the promise and the practical limitations of integrating TabPFN into cybersecurity workflows.",
    "published_date": "2026-01-12",
    "pdf_link": "https://arxiv.org/pdf/2601.07305v1",
    "paper_types": [
      "empirical_analysis",
      "benchmark"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Memory-based Malware Detection",
      "specific_problem": "Multi-class malware family classification from volatile memory features under limited-data conditions",
      "attack_types": [
        "Trojan",
        "Spyware",
        "Ransomware",
        "Multi-family malware classification"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer (probabilistic; tabular)",
        "specific": "TabPFN",
        "novel_contribution": "First comparative evaluation of TabPFN for memory-based malware family classification under low-data, multi-class settings (3, 10, 15 classes); no hyperparameter tuning as intended usage; analysis of accuracy vs. computational cost."
      },
      {
        "type": "baseline",
        "category": "Tree-based Ensemble",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosted Decision Trees",
        "specific": "LightGBM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosted Decision Trees",
        "specific": "XGBoost",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CIC-MalMem-2022",
        "type": "public",
        "domain": "memory_forensics/tabular_features (Windows processes, volatile memory)",
        "link": "https://www.unb.ca/cic/datasets/malmem-2022.html",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MalDroid-2020",
        "type": "public",
        "domain": "android_malware (largely synthetic)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "EMBER",
        "type": "public",
        "domain": "windows_pe_static_features",
        "link": "https://github.com/endgameinc/ember",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Accuracy (10-class, 250 samples)",
        "their_result": "TabPFN 26.41%",
        "baseline_result": "Random Forest 25.15%"
      },
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Accuracy (10-class, 250 samples)",
        "their_result": "TabPFN 26.41%",
        "baseline_result": "XGBoost 23.53%"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Accuracy (10-class, 1250 samples)",
        "their_result": "TabPFN 41.60%",
        "baseline_result": "Random Forest 38.48%"
      },
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Accuracy (10-class, 1250 samples)",
        "their_result": "TabPFN 41.60%",
        "baseline_result": "XGBoost 36.26%"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Accuracy (15-class, 1250 samples)",
        "their_result": "TabPFN 37.25%",
        "baseline_result": "Random Forest 33.58%"
      },
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Accuracy (15-class, 1250 samples)",
        "their_result": "TabPFN 37.25%",
        "baseline_result": "XGBoost 31.65%"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Accuracy (3-class, 1250 samples)",
        "their_result": "TabPFN 63.86%",
        "baseline_result": "Random Forest 60.24%"
      },
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Accuracy (3-class, 1250 samples)",
        "their_result": "TabPFN 63.86%",
        "baseline_result": "XGBoost 59.49%"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1 score",
      "Training time",
      "Inference time"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does TabPFN maintain strong predictive performance and generalization in low-data regimes for memory-based malware family classification as class granularity increases (3, 10, 15 classes)?",
        "How does TabPFN compare to Random Forest, LightGBM, and XGBoost across multiple training sizes with limited data?",
        "What is the computational efficiency trade-off (training and inference time) of TabPFN versus tree-based baselines under increasing class counts?"
      ],
      "gaps_identified": [
        "Data scarcity and class imbalance limit generalization of malware ML models due to lack of large, real-world datasets.",
        "Prior work focuses largely on binary malware vs. benign detection, offering little insight into multi-family classification.",
        "Heavy reliance on handcrafted features in existing studies reduces robustness and generalization.",
        "Memory-based malware datasets with broad, real-world diversity are scarce; available datasets can be synthetic or limited (e.g., MalDroid-2020 synthetic, EMBER static-only)."
      ],
      "limitations": [
        "Higher computation time for TabPFN, especially in the 15-class setting (tens of seconds slower than fastest baseline).",
        "Evaluation confined to a single dataset (CIC-MalMem-2022); benign samples excluded to focus on families, which may limit external validity for mixed benign/malicious settings.",
        "Small sampled subsets (3,000 from 58,596; training up to 1,250) may not capture full distributional diversity.",
        "Imbalance required data preparation; imbalance handling not fully addressed and deferred to future work.",
        "TabPFN extended version used is under development, potentially impacting timing results.",
        "No real-world deployment or online setting evaluated."
      ],
      "future_work": [
        "Enhance TabPFN for large-scale multiclass classification; explore recent extensions such as AutoTabPFN to improve adaptability and efficiency.",
        "Address class imbalance with advanced rebalancing (focal loss, class-balanced loss), sampling (SMOTE variants), or cost-sensitive training in memory-based malware tasks.",
        "Extend evaluation to mixed benign–malicious settings and additional datasets for external validity.",
        "Optimize computational efficiency of TabPFN for higher class counts; investigate approximate/accelerated inference."
      ],
      "motivation": "Mitigate the impact of limited, imbalanced real-world malware data by evaluating a tabular transformer (TabPFN) designed for low-data regimes on memory forensics features, moving beyond binary detection to multi-family classification while analyzing accuracy–efficiency trade-offs.",
      "potential_research_ideas": [
        "Few-shot and meta-learning for memory-based malware family recognition leveraging episodic training on memory features.",
        "Semi-supervised/self-training on unlabeled memory dumps from enterprise endpoints to alleviate label scarcity.",
        "Data augmentation for memory forensics (feature-level mixup, generative models respecting feature distributions).",
        "Knowledge distillation: distill TabPFN into a lightweight GBDT or shallow MLP for faster inference while retaining accuracy.",
        "Hybrid stacking/ensembling of TabPFN with GBDTs to improve robustness across class granularities.",
        "Calibration and threshold optimization for better decision quality under class imbalance.",
        "Evaluate and harden against distribution shift across machines/OS builds and concept drift in evolving malware.",
        "System-level integration study: online detection from live memory acquisition pipelines with latency constraints."
      ],
      "architectural_improvement_recommendations": [
        "Adopt AutoTabPFN for automated adaptation and potential speed/accuracy trade-offs in multi-class regimes.",
        "Introduce class-weighting or focal loss within TabPFN’s inference/training setup (if fine-tuning is enabled) to mitigate imbalance.",
        "Apply model compression: mixed-precision inference, quantization, and caching of posterior computations per class for speed.",
        "Two-stage cascades: fast GBDT filter followed by TabPFN re-ranking on hard examples to reduce overall latency.",
        "Feature selection/engineering to reduce dimensionality of memory features for TabPFN without losing discriminative power.",
        "Early-exit strategies or smaller TabPFN variants tailored to target class count."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "scikit-learn",
        "XGBoost",
        "LightGBM",
        "PyTorch",
        "TabPFN"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Experiments run on Google Colab with an NVIDIA Tesla T4 GPU; GPU recommended for TabPFN. Training sizes: 250–1250; timing ranges in Table V (e.g., TabPFN 39.55–67.03 s in 15-class setting; XGBoost ~0.31–1.35 s). 5 Stratified Shuffle Split runs per configuration; 500-sample CV for hyperparameter tuning of baselines."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "Timing analysis provided; TabPFN significantly slower in 15-class setting (≈39.55–67.03 s) vs. XGBoost (~0.99–1.35 s).",
      "deployment_challenges": [
        "Computational overhead of TabPFN grows with class count; latency concerns for real-time use.",
        "Data scarcity and class imbalance in operational environments.",
        "GPU dependency for efficient TabPFN inference.",
        "Integration with memory acquisition/forensics pipelines and associated privacy/policy constraints.",
        "Model interpretability for SOC workflows not addressed.",
        "Potential drift as malware evolves requiring continual adaptation."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Comprehensive comparative evaluation of TabPFN versus Random Forest, LightGBM, and XGBoost for memory-based malware family classification under limited data.",
      "Systematic study across class granularities (3, 10, 15 classes) and varying training sizes (250, 500, 750, 1250).",
      "Empirical finding: TabPFN outperforms baselines by approximately 2%–6% in low-data regimes across multiple metrics.",
      "Computational cost analysis showing TabPFN’s overhead, especially in 15-class settings.",
      "Release of detailed experimental setup (stratified splits, tuning strategy, hyperparameters, and timing) to facilitate reproducibility."
    ]
  },
  {
    "arxiv_id": "2601.07122v1",
    "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework",
    "authors": "Yixiao Peng; Hao Hu; Feiyang Li; Xinye Cao; Yingchang Jiang; Jipeng Tang; Guoshun Nan; Yuling Liu",
    "abstract": "While virtualization and resource pooling empower cloud networks with structural flexibility and elastic scalability, they inevitably expand the attack surface and challenge cyber resilience. Reinforcement Learning (RL)-based defense strategies have been developed to optimize resource deployment and isolation policies under adversarial conditions, aiming to enhance system resilience by maintaining and restoring network availability. However, existing approaches lack robustness as they require retraining to adapt to dynamic changes in network structure, node scale, attack strategies, and attack intensity. Furthermore, the lack of Human-in-the-Loop (HITL) support limits interpretability and flexibility. To address these limitations, we propose CyberOps-Bots, a hierarchical multi-agent reinforcement learning framework empowered by Large Language Models (LLMs). Inspired by MITRE ATT&CK's Tactics-Techniques model, CyberOps-Bots features a two-layer architecture: (1) An upper-level LLM agent with four modules--ReAct planning, IPDRR-based perception, long-short term memory, and action/tool integration--performs global awareness, human intent recognition, and tactical planning; (2) Lower-level RL agents, developed via heterogeneous separated pre-training, execute atomic defense actions within localized network regions. This synergy preserves LLM adaptability and interpretability while ensuring reliable RL execution. Experiments on real cloud datasets show that, compared to state-of-the-art algorithms, CyberOps-Bots maintains network availability 68.5% higher and achieves a 34.7% jumpstart performance gain when shifting the scenarios without retraining. To our knowledge, this is the first study to establish a robust LLM-RL framework with HITL support for cloud defense. We will release our framework to the community, facilitating the advancement of robust and autonomous defense in cloud networks.",
    "published_date": "2026-01-12",
    "pdf_link": "https://arxiv.org/pdf/2601.07122v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cloud Security",
      "subdomain": "Autonomous Cyber Defense",
      "specific_problem": "Robust adaptive defense policy optimization to maintain cloud network availability under dynamic topology/scale and evolving multi-stage attacks with HITL support",
      "attack_types": [
        "Port scanning",
        "Service probing",
        "Lateral movement",
        "Container escape",
        "Cloud storage malware",
        "SSRF (Server-Side Request Forgery)",
        "Cloud instance metadata abuse",
        "IAM credential theft",
        "S3 bucket enumeration",
        "Ransomware",
        "DDoS",
        "APT (multi-stage)",
        "Multi-path concurrent attacks"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM Agent",
        "specific": "ReAct-style planning with tool invocation; IPDRR-based perception; long-short term memory",
        "novel_contribution": "Upper-layer LLM agent performs global situational awareness, human intent recognition, tactical planning, and schedules RL agents via tool calls with auditable reasoning chains and HITL support"
      },
      {
        "type": "primary",
        "category": "Multi-Agent Reinforcement Learning",
        "specific": "Heterogeneous separated pre-trained RL expert agents",
        "novel_contribution": "Lower-layer localized RL agents trained offline with specialized rewards to execute atomic defense actions; orchestrated by LLM to avoid retraining under topology/scale/attack shifts"
      },
      {
        "type": "primary",
        "category": "Memory/Retrieval",
        "specific": "Long-short term memory for multi-stage, multi-path attacks",
        "novel_contribution": "Stores and retrieves multiple attack chains via similarity matching to track and defend against concurrent evolving attack paths"
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Multi-Agent RL",
      "Hierarchical RL",
      "LLM-assisted Planning",
      "Offline pre-training (for RL experts)"
    ],
    "datasets": [
      {
        "name": "Real cloud datasets (unspecified)",
        "type": "private",
        "domain": "cloud_network",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Network availability",
      "Jumpstart performance under scenario shift"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How to design a robust cloud network defense framework that adapts without retraining to changes in network structure (A1), node scale (A2), attack policies (A3), and attack intensity (A4)?",
        "How to integrate Human-in-the-Loop (HITL) interpretability and intervention into automated defense for cloud networks?",
        "How to leverage LLMs for global situational awareness and tactical planning while ensuring precise, reliable execution of atomic defense actions?"
      ],
      "gaps_identified": [
        "Existing DRL defenses couple fixed-dimensional state encodings with specific network structures/scales, requiring retraining when environments change (A1/A2)",
        "Training and testing often reuse identical attack strategies, harming generalization to unseen, multi-stage, or intensified attacks (A3/A4)",
        "Lack of HITL support and limited interpretability/auditability in current automated defense approaches",
        "LLMs alone are weak at numerical computation and constrained decision execution in high-dimensional dynamic network states"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Cloud networks are highly dynamic and face evolving multi-stage attacks, but existing RL-based defenses lack robustness to topology/scale/attack changes and do not support HITL, limiting adaptability, interpretability, and flexibility.",
      "potential_research_ideas": [
        "Incorporate graph-structured perception (e.g., GNN-based tool) as an additional tool callable by the LLM to improve reasoning over dynamic topologies while keeping language-based abstraction",
        "Develop automated curriculum generation for heterogeneous RL experts to cover broader attack tactics/techniques with formal guarantees on coverage and transfer",
        "Add formal verification or safety layers for LLM-issued tactical plans to ensure compliance with network policies and avoid harmful actions under uncertainty",
        "Investigate robust training against adaptive attackers that react to defense tactics, using game-theoretic self-play between attacker simulators and the LLM+RL defense",
        "Integrate online meta-RL for rapid adaptation of lower-level agents while preserving the no-retraining guarantee via parameter-efficient adapters"
      ],
      "architectural_improvement_recommendations": [
        "Augment the LLM agent with a structured world model (lightweight graph state store) synchronized with language summaries to reduce reliance on free-text for critical numeric/topological facts",
        "Introduce a tool portfolio including path search/shortest path, blast-radius estimation, and cost-aware actuator selection to mitigate LLM numeric weaknesses",
        "Use parameter-efficient fine-tuning (LoRA/adapters) on the LLM for domain-specific tactical reasoning with safety-tuned refusal policies",
        "Adopt a centralized training, decentralized execution (CTDE) regimen for RL experts with attention-based coordination to reduce interference among heterogeneous agents",
        "Implement uncertainty estimation (e.g., ensemble-based or dropout) on RL experts and expose confidence to the LLM planner for risk-aware orchestration"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Highly dynamic cloud topology and frequent scaling/migration",
        "State space explosion with large node counts",
        "Generalization to unseen multi-stage and intensified attacks",
        "LLM limitations in numeric reasoning and precise command synthesis",
        "Need for HITL oversight and auditable decision logs"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Natural language-based representation of cyber adversarial scenarios to decouple from specific network structure/scale (A1/A2)",
      "Hierarchical LLM+RL decision-making framework with LLM ReAct tactical planning and localized RL execution to mitigate state space explosion (A2)",
      "Heterogeneous separated pre-training to build RL expert agents scheduled by the LLM for adaptability to diverse attack strategies (A3)",
      "Long-short term memory mechanism to track multiple evolving attack chains and handle increased concurrent attack scales (A4)",
      "HITL support with auditable tactical planning reasoning chain for interpretability and flexible expert intervention",
      "Empirical claim: maintains network availability 68.5% higher than SOTA and achieves 34.7% jumpstart performance gain under scenario shift without retraining"
    ]
  },
  {
    "arxiv_id": "2601.14606v1",
    "title": "An LLM Agent-based Framework for Whaling Countermeasures",
    "authors": "Daisuke Miyamoto; Takuji Iimura; Narushige Michishita",
    "abstract": "With the spread of generative AI in recent years, attacks known as Whaling have become a serious threat. Whaling is a form of social engineering that targets important high-authority individuals within organizations and uses sophisticated fraudulent emails. In the context of Japanese universities, faculty members frequently hold positions that combine research leadership with authority within institutional workflows. This structural characteristic leads to the wide public disclosure of high-value information such as publications, grants, and detailed researcher profiles. Such extensive information exposure enables the construction of highly precise target profiles using generative AI. This raises concerns that Whaling attacks based on high-precision profiling by generative AI will become prevalent. In this study, we propose a Whaling countermeasure framework for university faculty members that constructs personalized defense profiles and uses large language model (LLM)-based agents. We design agents that (i) build vulnerability profiles for each target from publicly available information on faculty members, (ii) identify potential risk scenarios relevant to Whaling defense based on those profiles, (iii) construct defense profiles corresponding to the vulnerabilities and anticipated risks, and (iv) analyze Whaling emails using the defense profiles. Furthermore, we conduct a preliminary risk-assessment experiment. The results indicate that the proposed method can produce judgments accompanied by explanations of response policies that are consistent with the work context of faculty members who are Whaling targets. The findings also highlight practical challenges and considerations for future operational deployment and systematic evaluation.",
    "published_date": "2026-01-21",
    "pdf_link": "https://arxiv.org/pdf/2601.14606v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Email Security",
      "subdomain": "Phishing/Whaling Defense",
      "specific_problem": "Personalized, LLM-agent-based defense for whaling targeting university faculty; construction of Personalized Vulnerability Profiles (PVPs), risk scenarios, and Personalized Defense Profiles (PDPs) and use of PDPs for email risk assessment",
      "attack_types": [
        "Whaling",
        "Spear phishing",
        "Phishing (social engineering)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM Agents (Transformer-based LLMs)",
        "specific": null,
        "novel_contribution": "Multi-agent LLM pipeline to generate PVPs from OSINT, derive risk scenarios, construct PDPs, and use PDPs as system prompts for context-aware risk assessment of incoming emails in university whaling settings"
      }
    ],
    "learning_paradigm": [
      "Prompt-based/Zero-shot",
      "Agent-based orchestration"
    ],
    "datasets": [
      {
        "name": "E-PhishGEN generated phishing email datasets",
        "type": "synthetic",
        "domain": "emails/phishing",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can attack-oriented profiling frameworks (e.g., PVPs) be reframed into defensive artifacts (PVPs, risk scenarios, PDPs) for whaling countermeasures?",
        "Can LLM agents construct personalized defense profiles that align with faculty members’ real work context and support risk assessment of whaling emails?",
        "What practical challenges arise when preparing the framework for operational deployment and systematic evaluation in universities?"
      ],
      "gaps_identified": [
        "Traditional pattern-recognition-based phishing defenses rely on large volumes of similar samples; highly personalized whaling emails are few and tailored, undermining data collection and detection.",
        "Existing detectors may miss highly personalized, context-specific whaling emails that evade typical phishing patterns.",
        "Japanese university faculty have unusually high public information exposure (publications, grants, detailed profiles), enabling precise adversarial profiling with generative AI.",
        "Prior research often optimizes on outdated datasets and lacks real-world evaluation settings for evolving phishing threats."
      ],
      "limitations": [
        "Preliminary risk-assessment experiment only; no large-scale or real-world operational deployment reported.",
        "Practical challenges and need for systematic evaluation are acknowledged but not yet resolved.",
        "Specific LLM models, training/fine-tuning details, and quantitative performance metrics are not provided in the available text."
      ],
      "future_work": [
        "“The findings also highlight practical challenges and considerations for future operational deployment and systematic evaluation.”",
        "Section 6 (not included in excerpt) is stated to outline future work."
      ],
      "motivation": "Generative AI enables precise target profiling and fluent multilingual phishing content, increasing the feasibility and scale of whaling; universities expose substantial high-value information on faculty, amplifying risk. The work aims to create personalized, context-aware defenses using LLM agents.",
      "potential_research_ideas": [
        "Develop a standardized benchmark and evaluation protocol for whaling defense using realistic university contexts and red-teamed attacks.",
        "Create a privacy-preserving data pipeline to integrate institutional signals (workflows, roles, access rights) into PDPs without exposing sensitive data.",
        "Design adaptive PDPs that update with time-varying factors (academic calendar, grant cycles) and detect risk spikes tied to these cycles.",
        "Explore human-in-the-loop triage workflows where security staff audit PVPs/risk scenarios/PDPs and calibrate alerts.",
        "Build red-teaming agents that generate targeted whaling campaigns against PDP-protected users to measure robustness.",
        "Investigate cross-lingual defenses for Japanese and English mixed emails, including style-shift and code-switching attacks.",
        "Quantify explainability effectiveness: measure how PDP-grounded explanations affect user decisions and response latency.",
        "Integrate identity and trust signals (DMARC/SPF/DKIM, organizational directory, known correspondent graphs) into the LLM agent’s reasoning.",
        "Construct an open repository of de-identified, context-rich whaling scenarios for research reproducibility.",
        "Evaluate cost-performance tradeoffs of small domain-tuned LLMs vs. large general LLMs for on-prem deployments."
      ],
      "architectural_improvement_recommendations": [
        "Add retrieval-augmented generation (RAG) to ground LLM agents on curated organizational knowledge (policies, workflows, contacts) with guardrails.",
        "Adopt a multi-agent architecture separating OSINT collection, PVP extraction, threat modeling, PDP synthesis, and email risk scoring with explicit schemas and validation.",
        "Introduce structured prediction with JSON schema enforcement and consistency checks across PVP, scenarios, and PDP items.",
        "Fuse technical email authentication and reputation signals (DMARC/SPF/DKIM, sender history) as non-LLM features in a hybrid risk score.",
        "Use a compact, domain-tuned LLM for on-prem inference and a larger LLM for offline PDP generation; distill policies from large to small models.",
        "Implement user-specific contact graph modeling to detect anomalous relationship claims and impersonations.",
        "Incorporate calibration techniques and selective abstention for uncertain cases, triggering human review.",
        "Add policy versioning and drift detection to keep PDPs aligned with changing roles and workflows."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Reframes attack-oriented frameworks (Heiding et al.’s PVPs and Pajola et al.’s E-PhishGEN) into a defensive framework comprising PVPs, risk scenarios, and PDPs for whaling countermeasures.",
      "Designs PVP and PDP item sets tailored to high-value faculty at Japanese universities, embedding public information (positions, research activities, grants, networks).",
      "Presents concrete JSON-based formats consumable by LLM agents for profile construction and analysis.",
      "Combines public information with institution-internal context (roles, decision authority, workflows) to build PDPs and illustrate potential for protecting high-value academic targets.",
      "Conducts a preliminary risk-assessment experiment showing that the method can produce context-consistent judgments with explanatory response policies; identifies practical challenges for deployment and systematic evaluation."
    ]
  },
  {
    "arxiv_id": "2601.07880v1",
    "title": "Sola-Visibility-ISPM: Benchmarking Agentic AI for Identity Security Posture Management Visibility",
    "authors": "Gal Engelberg; Konstantin Koutsyi; Leon Goldberg; Reuven Elezra; Idan Pinto; Tal Moalem; Shmuel Cohen; Yoni Weintrob",
    "abstract": "Identity Security Posture Management (ISPM) is a core challenge for modern enterprises operating across cloud and SaaS environments. Answering basic ISPM visibility questions, such as understanding identity inventory and configuration hygiene, requires interpreting complex identity data, motivating growing interest in agentic AI systems. Despite this interest, there is currently no standardized way to evaluate how well such systems perform ISPM visibility tasks on real enterprise data. We introduce the Sola Visibility ISPM Benchmark, the first benchmark designed to evaluate agentic AI systems on foundational ISPM visibility tasks using a live, production-grade identity environment spanning AWS, Okta, and Google Workspace. The benchmark focuses on identity inventory and hygiene questions and is accompanied by the Sola AI Agent, a tool-using agent that translates natural-language queries into executable data exploration steps and produces verifiable, evidence-backed answers. Across 77 benchmark questions, the agent achieves strong overall performance, with an expert accuracy of 0.84 and a strict success rate of 0.77. Performance is highest on AWS hygiene tasks, where expert accuracy reaches 0.94, while results on Google Workspace and Okta hygiene tasks are more moderate, yet competitive. Overall, this work provides a practical and reproducible benchmark for evaluating agentic AI systems in identity security and establishes a foundation for future ISPM benchmarks covering more advanced identity analysis and governance tasks.",
    "published_date": "2026-01-11",
    "pdf_link": "https://arxiv.org/pdf/2601.07880v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Identity and Access Management",
      "subdomain": "Identity Security Posture Management (ISPM)",
      "specific_problem": "Benchmarking agentic AI for identity inventory and configuration hygiene visibility across AWS, Okta, and Google Workspace",
      "attack_types": [
        "misconfiguration",
        "excessive privileges",
        "weak authentication posture",
        "stale/unmanaged identities"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Agentic LLM",
        "specific": "Sola AI Agent",
        "novel_contribution": "Schema-grounded, tool-using agent that translates natural-language ISPM queries into executable data exploration (SQL/API) over live AWS/Okta/GWS; two execution modes (fast-path and full-path), with evidence aggregation and step journal"
      },
      {
        "type": "primary",
        "category": "Retrieval-Augmented Generation (RAG)",
        "specific": "Schema and example query retrieval",
        "novel_contribution": "Grounds actions to valid tables/fields/relationships by retrieving relevant schemas and reference query patterns to ensure executability"
      },
      {
        "type": "primary",
        "category": "Reasoning/Planning (CoT/ToT)",
        "specific": "Tree-of-Thought–style reasoning",
        "novel_contribution": "Full-path exploration decomposes questions into intermediate steps with success criteria; maintains a structured step journal for verification"
      },
      {
        "type": "primary",
        "category": "Text-to-SQL",
        "specific": null,
        "novel_contribution": "Data-grounded SQL generation and execution across heterogeneous identity platforms for inventory and hygiene questions"
      },
      {
        "type": "baseline",
        "category": "LLM-as-Judge",
        "specific": "Structured chain-of-thought rubric",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "In-context learning",
      "Tool-augmented agentic reasoning"
    ],
    "datasets": [
      {
        "name": "Sola Visibility ISPM Benchmark (77-question set)",
        "type": "proprietary",
        "domain": "identity_posture_benchmark",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Live AWS identity and configuration data",
        "type": "proprietary",
        "domain": "cloud_identity/IAM_configurations",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Live Okta IdP workforce identity and policy data",
        "type": "proprietary",
        "domain": "idp_identity/authentication_policies",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Live Google Workspace identity, permissions, and OAuth configurations",
        "type": "proprietary",
        "domain": "saas_configuration/drive_permissions/oauth_apps",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Expert Accuracy",
      "Strict Success Rate",
      "LLM-as-Judge scoring (structured CoT rubric)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can agentic AI systems accurately perform ISPM visibility tasks (identity inventory and configuration hygiene) over live, enterprise-grade identity environments?",
        "How should we standardize evaluation of agentic AI for ISPM using data-grounded workflows and verifiable evidence?"
      ],
      "gaps_identified": [
        "No standardized benchmark exists to evaluate how well agentic AI systems perform ISPM tasks on real enterprise identity and access data.",
        "Existing cybersecurity benchmarks do not evaluate identity inventory, posture hygiene, cross-platform identity correlation, or posture-aware answers grounded in real organizational datasets."
      ],
      "limitations": [
        "Focus is limited to visibility and hygiene tasks; other ISPM dimensions (behavior analytics, risk scoring, governance alignment, mitigation) are out of scope.",
        "Evaluation environment spans only AWS, Okta, and Google Workspace.",
        "Benchmark is grounded in a live, production-grade enterprise environment that is not openly accessible, limiting external reproducibility on identical data."
      ],
      "future_work": [
        "Extend benchmark to additional ISPM dimensions (risk assessment, governance alignment, behavioral analytics, advanced analytics).",
        "Broaden coverage to more platforms and identity ecosystems beyond AWS, Okta, and Google Workspace.",
        "Refine LLM-as-Judge procedures and expand rubric-driven evaluation for intermediate reasoning quality."
      ],
      "motivation": "Establish a practical and reproducible benchmark to evaluate agentic AI on foundational ISPM visibility tasks over real, multi-platform enterprise identity data.",
      "potential_research_ideas": [
        "Create a publicly available synthetic or de-identified mirror of the ISPM environment with traceable ground truth to enable open benchmarking.",
        "Develop cross-platform identity graph representations and graph reasoning agents for correlated identity risk analysis.",
        "Introduce automated SQL program repair and verification loops specific to IAM/IdP schemas to increase strict success rate.",
        "Benchmark adversarial robustness of ISPM agents against schema drift, deceptive data, and tool failures.",
        "Integrate behavioral telemetry (auth logs, privilege use) and evaluate anomaly detection for identity misuse.",
        "Design baseline agent suites (text-to-SQL, generic RAG agents) to enable comparative evaluation against the Sola AI Agent."
      ],
      "architectural_improvement_recommendations": [
        "Add schema-constrained SQL generation with formal schema typing and integrity constraints to reduce partial correctness.",
        "Incorporate cross-platform identity graph building with entity resolution to improve correlation and hygiene detection.",
        "Implement automatic query repair using execution feedback and unit tests for expected result patterns.",
        "Adopt cost-aware planning that switches between fast-path and full-path based on estimated uncertainty and expected value of computation.",
        "Use retrieval calibration (learning-to-retrieve example queries) to improve grounding on Okta and Google Workspace."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Live, production-grade enterprise identity environment across AWS, Okta, and Google Workspace",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Accessing and normalizing heterogeneous schemas across AWS/Okta/Google Workspace",
        "Ensuring verifiable, evidence-backed answers with executed queries",
        "Handling schema drift and platform-specific nuances in policies and permissions",
        "Cross-platform entity resolution and correlation of identities"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces the Sola Visibility ISPM Benchmark: “the first benchmark designed to evaluate agentic AI systems on foundational ISPM visibility tasks using a live, production-grade identity environment spanning AWS, Okta, and Google Workspace.”",
      "Presents the Sola AI Agent, a tool-using, schema-grounded agent for ISPM question answering with fast-path and full-path execution and evidence-backed outputs.",
      "Defines a data-grounded, multi-artifact evaluation framework with expert panel scoring and LLM-as-Judge rubric.",
      "Reports benchmark results: “Across 77 benchmark questions, the agent achieves strong overall performance, with an expert accuracy of 0.84 and a strict success rate of 0.77.”",
      "Reports platform-specific results: “Performance is highest on AWS hygiene tasks, where expert accuracy reaches 0.94, while results on Google Workspace and Okta hygiene tasks are more moderate, yet competitive.”"
    ]
  },
  {
    "arxiv_id": "2601.07334v1",
    "title": "Examining the Effectiveness of Transformer-Based Smart Contract Vulnerability Scan",
    "authors": "Emre Balci; Timucin Aydede; Gorkem Yilmaz; Ece Gelal Soyak",
    "abstract": "Smart contract technology facilitates self-executing agreements on the blockchain, eliminating dependency on an external trusted authority. However, smart contracts may expose vulnerabilities that can lead to financial losses and disruptions in decentralized applications. In this work, we evaluate deep learning-based approaches for vulnerability scanning of Ethereum smart contracts. We propose VASCOT, a Vulnerability Analyzer for Smart COntracts using Transformers, which performs sequential analysis of Ethereum Virtual Machine (EVM) bytecode and incorporates a sliding window mechanism to overcome input length constraints. To assess VASCOT's detection efficacy, we construct a dataset of 16,469 verified Ethereum contracts deployed in 2022, and annotate it using trace analysis with concrete validation to mitigate false positives. VASCOT's performance is then compared against a state-of-the-art LSTM-based vulnerability detection model on both our dataset and an older public dataset. Our findings highlight the strengths and limitations of each model, providing insights into their detection capabilities and generalizability.",
    "published_date": "2026-01-12",
    "pdf_link": "https://arxiv.org/pdf/2601.07334v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Smart Contract Security",
      "specific_problem": "Detection of trace vulnerabilities in Ethereum smart contracts from EVM bytecode using sequential analysis",
      "attack_types": [
        "greedy (locked funds)",
        "prodigal (leaks funds)",
        "suicidal (arbitrary self-destruct)",
        "race condition (as example under greedy)",
        "out-of-gas / DoS (as example under greedy)",
        "unchecked send (as example under prodigal)",
        "front-running (discussed as trace-based risk)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Custom Transformer encoder with attention pooling",
        "novel_contribution": "Sequential analysis of EVM bytecode with a sliding window mechanism to overcome input length constraints for vulnerability likelihood classification"
      },
      {
        "type": "baseline",
        "category": "LSTM",
        "specific": "State-of-the-art LSTM-based sequential opcode model (as per prior work [9])",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Verified Ethereum Contracts 2022 (16,469) with trace-analysis labels",
        "type": "proprietary",
        "domain": "smart_contracts_evm_bytecode",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Older public dataset (prior work)",
        "type": "public",
        "domain": "smart_contracts_opcodes",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "LSTM-based sequential opcode model",
        "paper_reference": "[9] (the earlier study proposing sequence learning on EVM opcodes with LSTM)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How effective is a Transformer-based sequential analyzer (VASCOT) for detecting vulnerabilities in Ethereum smart contracts from EVM bytecode?",
        "Does a sliding-window Transformer outperform or complement an LSTM-based vulnerability detector?",
        "How do these models generalize across a newly constructed 2022 verified-contract dataset versus an older public dataset?",
        "What strengths and limitations emerge for each model in detecting trace vulnerabilities?"
      ],
      "gaps_identified": [
        "Static and dynamic analysis may miss vulnerabilities that manifest only under specific invocation sequences; symbolic analysis can be time-consuming due to path explosion.",
        "Existing reported high LSTM performance on public datasets does not hold on a verified, recent dataset.",
        "Lack of recent datasets reflecting contemporary Solidity/compiler changes; need for up-to-date, concretely validated labels to reduce false positives from trace analysis.",
        "Many prior ML methods depend on source code or limited vulnerability types; bytecode-only general solutions are needed.",
        "Transformer input length constraints necessitate strategies for very long opcode sequences."
      ],
      "limitations": [
        "Transformer requires a sliding window due to sequence length limits, which may fragment long-range dependencies.",
        "Labels are derived via trace analysis and require concrete validation to mitigate false positives, indicating residual label noise risk.",
        "Generalizability remains challenging across datasets of different eras and characteristics.",
        "Focus is on trace vulnerabilities (greedy, prodigal, suicidal); other vulnerability classes are not the primary target."
      ],
      "future_work": [
        "Mechanisms to improve generalizability of vulnerability scanner models across datasets and contract vintages.",
        "Extend to broader vulnerability taxonomies and multi-label settings.",
        "Explore better long-sequence handling beyond sliding windows."
      ],
      "motivation": "Smart contract vulnerabilities cause significant financial losses, and once deployed, contracts cannot be patched; efficient pre-deployment detection from bytecode is crucial.",
      "potential_research_ideas": [
        "Pretrain opcode/bytecode language models (masked LM) on large unlabeled EVM corpora and fine-tune for vulnerability detection to improve generalization.",
        "Neuro-symbolic hybrid: integrate symbolic execution traces or path summaries as auxiliary inputs to the Transformer.",
        "Hierarchical or long-sequence Transformers (e.g., Longformer/BigBird/Performer) to capture cross-window dependencies without heavy sliding-window heuristics.",
        "Multi-task and multi-label learning across multiple vulnerability categories (trace and non-trace) to share representations.",
        "Graph-augmented models: fuse control/data-flow graphs with sequence encodings via GNN+Transformer fusion.",
        "Curriculum/active learning using uncertain contracts and concrete validation to iteratively refine labels and reduce noise.",
        "Contrastive learning on execution traces (safe vs exploit-triggering) to learn vulnerability-aware representations.",
        "Domain adaptation techniques to mitigate dataset shift between historical public datasets and recent verified contracts."
      ],
      "architectural_improvement_recommendations": [
        "Replace sliding window with long-context Transformers (Longformer, BigBird) or memory-augmented attention to reduce context fragmentation.",
        "Introduce hierarchical pooling: token->basic block->function->contract to capture structure; use relative positional encodings aligned to EVM basic blocks and jumps.",
        "Pretrain opcode embeddings with masked-token objectives on large on-chain bytecode; initialize VASCOT with these embeddings.",
        "Fuse sequence encoder with a GNN over control-flow/data-flow graphs for improved semantics.",
        "Adopt class-imbalance strategies (focal loss, calibrated thresholds) and probability calibration for deployment.",
        "Model operands separately from opcodes (opcode-operand tokenization) and incorporate operand-aware attention.",
        "Move from binary to multi-label outputs for specific vulnerability categories (greedy/prodigal/suicidal and subtypes)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PyTorch"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Handling very long opcode sequences; sliding windows may miss cross-window dependencies.",
        "Label noise and false positives from automated trace analysis necessitate concrete validation.",
        "Generalizability across contract eras, compiler versions, and evolving coding patterns.",
        "Coverage limited to specific trace vulnerabilities; extending coverage increases complexity."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces VASCOT, a Transformer-based vulnerability scanner for EVM bytecode with a sliding-window mechanism for long sequences.",
      "Constructs a recent dataset of 16,469 verified Ethereum contracts (2022) labeled via trace analysis with concrete validation.",
      "Performs comparative evaluation of VASCOT versus a state-of-the-art LSTM model on both the new dataset and an older public dataset, analyzing strengths, limitations, and generalizability."
    ]
  },
  {
    "arxiv_id": "2601.13399v1",
    "title": "QERS: Quantum Encryption Resilience Score for Post-Quantum Cryptography in Computer, IoT, and IIoT Systems",
    "authors": "Jonatan Rassekhnia",
    "abstract": "Post-quantum cryptography (PQC) is becoming essential for securing Internet of Things (IoT) and Industrial IoT (IIoT) systems against quantum-enabled adversaries. However, existing evaluation approaches primarily focus on isolated performance metrics, offering limited support for holistic security and deployment decisions. This paper introduces QERS (Quantum Encryption Resilience Score), a universal measurement framework that integrates cryptographic performance, system constraints, and multi-criteria decision analysis to assess PQC readiness in computer, IoT, and IIoT environments. QERS combines normalized metrics, weighted aggregation, and machine learning-assisted analysis to produce interpretable resilience scores across heterogeneous devices and communication protocols. Experimental results demonstrate how the framework enables comparative evaluation of post-quantum schemes under realistic resource constraints, supporting informed security design and migration planning. This work is presented as a preprint, with extended statistical validation planned as part of ongoing graduate research.",
    "published_date": "2026-01-19",
    "pdf_link": "https://arxiv.org/pdf/2601.13399v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cryptography",
      "subdomain": "Post-Quantum Cryptography (PQC) Evaluation",
      "specific_problem": "Holistic, reproducible assessment of PQC readiness and operational impact on computer, IoT, and IIoT systems",
      "attack_types": [
        "Quantum attacks on public-key cryptography (e.g., Shor's algorithm)",
        "Operational risk from cryptographic overhead on resource-constrained devices"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble/Decision Trees",
        "specific": "Random Forest Regression",
        "novel_contribution": "Used as a complementary estimator to predict/estimate Fusion QERS from noisy or partially observed metrics; improves robustness without replacing QERS equations."
      },
      {
        "type": "baseline",
        "category": "Linear Models",
        "specific": "Linear Regression",
        "novel_contribution": "Proposed as an option to empirically refine or learn weights for QERS criteria."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "ESP32C6 PQC Measurements (Kyber, Dilithium, Falcon, SPHINCS+, NTRU) under Wi‑Fi scenarios",
        "type": "private",
        "domain": "iot_device_metrics",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Synthetic samples matching the statistical distributions of collected ESP32C6 measurements",
        "type": "synthetic",
        "domain": "iot_device_metrics",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Latency (L)",
      "Packet loss (Ploss)",
      "CPU usage (C)",
      "Energy consumption (E)",
      "RSSI / signal strength (R)",
      "Key size / Key bytes (K)",
      "Cryptographic overhead (O / Co: memory/bandwidth/compute)",
      "Jitter (J)",
      "Proven resistance level (Pr) as a security criterion in Fusion"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can a unified and reproducible measurement instrument be designed to evaluate PQC algorithms across Computer Systems, IoT, and IIoT platforms while incorporating latency, memory usage, energy behavior, Key-Bytes, CPU usage, RSSI and packet-level communication characteristics?"
      ],
      "gaps_identified": [
        "Lack of a unified, reproducible measurement instrument to evaluate PQC across multiple operational dimensions on real devices.",
        "Existing work focuses on isolated micro-benchmarks (runtime, memory, throughput) and lacks system-level visibility (latency, packet reliability, CPU, energy, wireless stability).",
        "Difficulty making deployment decisions across diverse hardware and protocol environments due to heterogeneous and non-holistic metrics."
      ],
      "limitations": [
        "Work is a preprint with extended statistical validation planned.",
        "Evaluation performed on ESP32C6 testbed and Wi‑Fi scenarios; broader hardware/protocol coverage is not yet demonstrated.",
        "Dataset and code are not provided; measurements are described but not released.",
        "Synthetic samples are used to stabilize learning, which may introduce distributional assumptions.",
        "Protocol-specific weaknesses and broader security analyses are out of scope."
      ],
      "future_work": [
        "Extended statistical validation of QERS.",
        "Support future PQC testing, comparison, and migration planning in resource-limited environments.",
        "Adapting/learning QERS weights using supervised methods to different IoT/IIoT conditions.",
        "Group-based decision systems with multiple evaluators contributing judgments.",
        "Expanding to additional protocols and deployment environments beyond the current Wi‑Fi scenarios."
      ],
      "motivation": "Enable holistic, interpretable, and reproducible evaluation of PQC impact on constrained computer, IoT, and IIoT systems to inform security design and migration decisions.",
      "potential_research_ideas": [
        "Construct and release a public PQC-on-IoT benchmark suite with standardized traces and QERS annotations across diverse hardware and protocols.",
        "Incorporate uncertainty quantification (e.g., prediction intervals, conformal prediction) for ML‑assisted Fusion estimates and score confidence.",
        "Automated, context-aware weight learning via Bayesian optimization or multi-objective optimization to tailor QERS to deployment goals (latency, energy, reliability).",
        "Extend QERS to end-to-end stacks (TLS/QUIC/DTLS, 5G/B5G slices) including handshake and session resumption impacts of PQC.",
        "Cross-device calibration methods to normalize scores across heterogeneous MCUs/SoCs and radios, enabling fair multi-vendor comparisons.",
        "Integrate causal analysis to disentangle crypto overhead from RF/environmental variability in observed performance.",
        "Add robustness stress-testing scenarios (packet burst loss, mobility, interference) and measure QERS sensitivity."
      ],
      "architectural_improvement_recommendations": [
        "Publish code, datasets, and a reference harness for reproducibility; define fixed normalization bounds per scenario and device class.",
        "Add end-to-end protocol instrumentation (TLS/QUIC/DTLS) and throughput/jitter metrics to complement current indicators.",
        "Implement automated weight-learning with constraints (e.g., monotonicity for cost vs. benefit criteria) and per-profile templates.",
        "Incorporate uncertainty calibration for Random Forest predictions and fallback logic when input metrics are missing.",
        "Introduce device- and protocol-specific calibration factors to improve cross-hardware comparability.",
        "Evaluate QERS under additional radios (BLE, LR‑WiFi, LoRaWAN, 5G NR) and mixed traffic patterns to test generality."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Flask"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "ESP32C6 microcontroller for data collection; Raspberry Pi CM4 for normalization, QERS computation, and dashboard; Random Forest training on small-to-medium datasets; no GPU required."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "IoT/IIoT devices over Wi‑Fi using ESP32C6 and Raspberry Pi CM4",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Resource constraints on CPU, memory, and energy in embedded devices.",
        "Increased latency and packet loss due to cryptographic overhead with large keys.",
        "Wireless stability and variability (RSSI) affecting performance under PQC load.",
        "Trade-offs between security robustness and operational efficiency.",
        "Heterogeneity of hardware and protocols complicating unified evaluation."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A modular scoring instrument (QERS) with Basic, Tuned, and Fusion modes for progressively deeper analysis.",
      "Normalization and weighting methodology integrating latency, CPU usage, signal reliability, key size, packet behavior, and energy into performance and security sub-scores.",
      "A practical implementation on ESP32 hardware for real-world experimentation rather than purely simulated environments.",
      "An empirical evaluation of five PQC algorithms (Kyber, Dilithium, Falcon, SPHINCS+, NTRU) across different wireless scenarios.",
      "A reproducible and extensible framework designed to support PQC testing, comparison, and migration toward quantum-resilient systems in resource-limited environments."
    ]
  },
  {
    "arxiv_id": "2601.15663v1",
    "title": "TempoNet: Learning Realistic Communication and Timing Patterns for Network Traffic Simulation",
    "authors": "Kristen Moore; Diksha Goel; Cody James Christopher; Zhen Wang; Minjune Kim; Ahmed Ibrahim; Ahmad Mohsin; Seyit Camtepe",
    "abstract": "Realistic network traffic simulation is critical for evaluating intrusion detection systems, stress-testing network protocols, and constructing high-fidelity environments for cybersecurity training. While attack traffic can often be layered into training environments using red-teaming or replay methods, generating authentic benign background traffic remains a core challenge -- particularly in simulating the complex temporal and communication dynamics of real-world networks. This paper introduces TempoNet, a novel generative model that combines multi-task learning with multi-mark temporal point processes to jointly model inter-arrival times and all packet- and flow-header fields. TempoNet captures fine-grained timing patterns and higher-order correlations such as host-pair behavior and seasonal trends, addressing key limitations of GAN-, LLM-, and Bayesian-based methods that fail to reproduce structured temporal variation. TempoNet produces temporally consistent, high-fidelity traces, validated on real-world datasets. Furthermore, we show that intrusion detection models trained on TempoNet-generated background traffic perform comparably to those trained on real data, validating its utility for real-world security applications.",
    "published_date": "2026-01-22",
    "pdf_link": "https://arxiv.org/pdf/2601.15663v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Traffic Generation and Simulation",
      "specific_problem": "Generation of realistic benign background network traffic (packet/flow headers) with accurate timing and communication patterns to support IDS evaluation, cyber range training, and protocol stress-testing",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Temporal Point Process + RNN (multi-mark TPP with LSTM encoder)",
        "specific": "LogNormMix temporal point process conditioned on RNN history embedding (LSTM) with multi-task decoders",
        "novel_contribution": "Jointly models inter-arrival times and multiple heterogeneous header fields (numeric + categorical) via a unified multi-task, multi-mark TPP; two-stage generation for NetFlow (temporal communication dynamics then communication characteristics)."
      },
      {
        "type": "primary",
        "category": "Mixture Density Network",
        "specific": "Log-normal mixture for positive continuous variables",
        "novel_contribution": "Applies log-normal mixture not only to inter-arrival times but also to host-dependent numeric fields (size, flow duration) with closed-form likelihood and sampling."
      },
      {
        "type": "primary",
        "category": "Multi-task Learning",
        "specific": null,
        "novel_contribution": "Shared RNN history encoder with task-specific decoders for each header field; equal-weighted losses across tasks."
      },
      {
        "type": "baseline",
        "category": "GAN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM for structured/tabular generation",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Bayesian",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Temporal Point Process",
        "specific": "Prior TPPs limited to 1–2 marks",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Maximum Likelihood (NLL for numeric via log-normal mixture; cross-entropy for categorical)"
    ],
    "datasets": [
      {
        "name": "CIDDS (Coburg Intrusion Detection Data Set) – attack data layered on synthetic benign background",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Unnamed real-world network traces used for validation",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "LANL",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "OpTC",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "GHOSTS",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [
      {
        "method_name": "GAN-based traffic generators",
        "paper_reference": null,
        "metric": null,
        "their_result": "“TempoNet outperforms prior methods across fidelity, diversity, and compliance metrics”",
        "baseline_result": null
      },
      {
        "method_name": "LLM-based structured/tabular generators",
        "paper_reference": null,
        "metric": null,
        "their_result": "“TempoNet outperforms prior methods across fidelity, diversity, and compliance metrics”",
        "baseline_result": null
      },
      {
        "method_name": "Bayesian methods",
        "paper_reference": null,
        "metric": null,
        "their_result": "“TempoNet outperforms prior methods across fidelity, diversity, and compliance metrics”",
        "baseline_result": null
      },
      {
        "method_name": "Prior TPP-based generators (limited marks)",
        "paper_reference": null,
        "metric": null,
        "their_result": "“TempoNet outperforms prior methods across fidelity, diversity, and compliance metrics”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Earth Mover’s Distance (EMD)",
      "Jensen-Shannon Divergence (JSD)",
      "Pairwise Correlation Difference (PCD)",
      "Contingency Matrix Difference (CMD)",
      "Coverage",
      "Density",
      "Membership Disclosure (novelty/privacy check)",
      "Domain Knowledge Check (DKC) for protocol compliance",
      "IDS task performance (trained on synthetic background vs real background) – metric unspecified"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a multi-mark temporal point process with a shared history encoder jointly model inter-arrival times and heterogeneous header fields to generate temporally consistent, realistic network traces?",
        "Does modeling fine-grained timing and higher-order communication patterns (host-pair behavior, seasonality) improve fidelity/diversity/compliance over GAN-, LLM-, and Bayesian-based generators?",
        "Do IDS models trained on TempoNet-generated benign background traffic perform comparably to those trained on real data?"
      ],
      "gaps_identified": [
        "GAN-, LLM-, and Bayesian-based methods fail to reproduce structured temporal variation and long-range dependencies in network traffic.",
        "Existing TPP-based generators typically model only one or two event attributes (marks), insufficient for full-field network traffic simulation.",
        "Access to real network traces is limited due to privacy, proprietary, and operational security constraints; replaying traces is brittle and risks metadata leakage."
      ],
      "limitations": [
        "Focuses on header-only generation and does not generate payload contents.",
        "Evaluation mentions real-world datasets and an IDS task with CIDDS attack overlay, but specific dataset details and broad cross-domain generalization evidence are not provided in the excerpt."
      ],
      "future_work": [],
      "motivation": "Realistic benign background traffic is hard to obtain yet critical for credible IDS evaluation, cyber range training, and deception; need to capture complex temporal and communication dynamics while avoiding privacy risks of real trace replay.",
      "potential_research_ideas": [
        "Extend TempoNet to jointly model packet payload semantics with protocol-aware tokenization while preserving privacy (e.g., content-style disentanglement).",
        "Introduce conditional control variables (scenario, diurnal intensity, host roles) for controllable traffic generation to match specific environments.",
        "Incorporate principled privacy guarantees (e.g., differential privacy) during training to bound membership disclosure risk.",
        "Online/continual adaptation of the TPP to evolving network baselines using streaming fine-tuning with drift detection.",
        "Graph-based extensions that use GNNs to model host embeddings and dynamic communication graphs jointly with the TPP.",
        "Adversarial evaluation: train IDS under distribution shifts and adversarially optimized benign backgrounds to probe robustness.",
        "Benchmark creation: standardized temporal-structure benchmarks and protocol compliance suites for synthetic network traffic.",
        "Hybrid diffusion-TPP model for high-fidelity multi-field tabular generation with efficient sampling for timing."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment the LSTM history encoder with a temporal Transformer with relative positional encodings to better capture long-range seasonality.",
        "Model host-pair dependencies via a learned graph (GNN) and condition the TPP on dynamic node/edge embeddings.",
        "Use normalizing flow decoders (e.g., NSF/MAF) for numeric fields to capture complex conditional distributions beyond log-normal mixtures.",
        "Employ hierarchical categorical modeling (protocol → service → port) with label smoothing and class-grouping for high-cardinality ports/IPs.",
        "Add explicit seasonal features (Fourier terms) and learned time-of-week embeddings to strengthen periodicity modeling.",
        "Introduce curriculum or task-uncertainty weighting instead of equal loss weights to stabilize multi-task optimization.",
        "Calibrate sampling via temperature/mixture sharpening and constraint-satisfaction decoding guided by protocol validators.",
        "Explore Neural ODE-based TPPs or Hawkes variants with closed-form likelihood approximations when self-excitation is prominent."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Cyber range training and IDS evaluation environments; header-only traces (PCAP/NetFlow)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Access to representative benign background traffic is limited due to privacy/operational constraints.",
        "Replay-based approaches risk metadata leakage and weak temporal realism.",
        "High-cardinality categorical spaces (IPs/ports) and seasonality require careful conditioning and efficient sampling.",
        "Payload content is not modeled, which may limit some IDS use cases."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Integrated generative model: multi-task, multi-mark TPP that jointly models inter-arrival times and packet/flow header fields; captures structured temporal patterns (daily/weekly seasonality).",
      "Comprehensive empirical evaluation: first rigorous comparison across GAN-, LLM-, Bayesian-, and TPP-based approaches on temporal and higher-order communication dynamics; superior fidelity, diversity, and compliance.",
      "Real-world security application: IDS models trained on TempoNet-generated background traffic perform comparably to those trained on real data (CIDDS attack overlay)."
    ]
  },
  {
    "arxiv_id": "2601.13681v1",
    "title": "ORCA - An Automated Threat Analysis Pipeline for O-RAN Continuous Development",
    "authors": "Felix Klement; Alessandro Brighente; Michele Polese; Mauro Conti; Stefan Katzenbeisser",
    "abstract": "The Open-Radio Access Network (O-RAN) integrates numerous software components in a cloud-like deployment, opening the radio access network to previously unconsidered security threats. With the ever-evolving threat landscape, integrating security practices through a DevSecOps approach is essential for fast and secure releases. Current vulnerability assessment practices often rely on manual, labor-intensive, and subjective investigations, leading to inconsistencies in the threat analysis. To mitigate these issues, we establish an automated pipeline that leverages Natural Language Processing (NLP) to minimize human intervention and associated biases. By mapping real-world vulnerabilities to predefined threat lists with a standardized input format, our approach is the first to enable iterative, quantitative, and efficient assessments, generating reliable threat scores for both individual vulnerabilities and entire system components within O-RAN. We illustrate the effectiveness of our framework through an example implementation for O-RAN, showcasing how continuous security testing can integrate into automated testing pipelines to address the unique security challenges of this paradigm shift in telecommunications.",
    "published_date": "2026-01-20",
    "pdf_link": "https://arxiv.org/pdf/2601.13681v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Network Security",
      "subdomain": "Threat Modeling and Risk Assessment",
      "specific_problem": "Automated NLP-driven mapping of O-RAN threat descriptions to MITRE ATT&CK tactics and CAPEC attack patterns with quantitative threat scoring for CI/CD",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Sentence Transformer (embedding-based)",
        "novel_contribution": "Dual-branch mapping (Threat-to-Techniques and Threat-to-CAPEC) driven by sentence embeddings with cosine-similarity, enabling end-to-end automated scoring from threat text via ATT&CK/CAPEC→CWE→CVE"
      },
      {
        "type": "primary",
        "category": "Information Retrieval / Similarity",
        "specific": "Cosine similarity over text embeddings",
        "novel_contribution": "Ensembles of multiple NLP models to aggregate candidate tactics; parameterizable thresholds and mapping consolidation for stable, repeatable outputs"
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "O-RAN Alliance Technical Specification Threat Data",
        "type": "public",
        "domain": "threat_descriptions",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "MITRE ATT&CK",
        "type": "public",
        "domain": "threat_knowledge_base",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MITRE CAPEC",
        "type": "public",
        "domain": "attack_patterns",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MITRE CWE",
        "type": "public",
        "domain": "software_weaknesses",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NIST NVD (CVE)",
        "type": "public",
        "domain": "vulnerabilities",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MITRE FiGHT",
        "type": "public",
        "domain": "telecommunications_threats",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "cosine similarity (for mapping)",
      "threat scores per threat/component",
      "CVE-derived severity metrics (e.g., CVSS)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Threat analysis is largely manual, labor-intensive, and subjective, hindering repeatability and speed in dynamic O-RAN environments",
        "Lack of comprehensive automated assessments mapping real vulnerabilities to predefined generic threat lists",
        "Existing tools are application-specific and require manual steps; limited flexibility for fine-tuning",
        "MITRE ATT&CK techniques do not always link to CAPECs, leaving assessment gaps"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "O-RAN’s rapid, software-driven evolution expands the attack surface and demands DevSecOps-aligned, automated, repeatable threat assessments; manual practices are slow, subjective, and hard to iterate.",
      "potential_research_ideas": [
        "Create and release a labeled benchmark for O-RAN threat→ATT&CK/CAPEC mapping to enable comparative research",
        "Supervised or weakly-supervised fine-tuning of sentence encoders using CVE→ATT&CK/CAPEC annotations to improve mapping accuracy",
        "Human-in-the-loop active learning to iteratively refine mappings and thresholds on ambiguous threats",
        "Integrate SBOMs and dependency graphs to weight CVE evidence by actual component exposure and versioning",
        "Construct a knowledge graph unifying ATT&CK, FiGHT, CAPEC, CWE, CVE and O-RAN components for graph-based reasoning and scoring",
        "Calibrate and validate threat scores against expert ratings; add uncertainty estimates for decision thresholds in CI/CD gates",
        "Adversarial robustness evaluation against perturbed threat descriptions; develop defenses (e.g., augmentation, smoothing)",
        "Extend pipeline to runtime telemetry (logs/alerts) for continuous assurance and drift detection",
        "Develop explainability modules that highlight text spans driving mappings and evidence chains (Threat→Technique→CAPEC→CWE→CVE)",
        "Cross-encoder or reranking models on top of embedding retrieval for higher-precision mapping"
      ],
      "architectural_improvement_recommendations": [
        "Two-stage retrieval: BM25/vector recall followed by cross-encoder reranking for both TTM and TCM branches",
        "Confidence calibration and dynamic thresholding per tactic/category using Platt or temperature scaling",
        "Vector database integration with incremental index updates for CAPEC/CVE corpora; cache mappings for CI speed",
        "Knowledge-graph fusion layer to enforce hierarchical constraints (tactic→technique→sub-technique) and propagate evidence",
        "Domain-adaptive fine-tuning of sentence transformers on telecom/O-RAN corpora",
        "Automated parameter sweeps with validation sets to lock stable configs for CI/CD reproducibility",
        "Support multi-lingual threat inputs via multilingual sentence transformers",
        "Add an evidence aggregation policy that weights CVEs by recency, exploit maturity, and EPSS-like signals"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "O-RAN CI/CD/CT pipeline within SMO/O-Cloud (integration via O1/O2 interfaces)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires standardized, well-structured threat inputs (JSON/CSV) and preprocessing/enrichment",
        "Gaps between ATT&CK techniques and CAPEC coverage necessitate dual-branch logic",
        "Tooling flexibility and fine-tuning for different application contexts"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Novel NLP-based methodology mapping threat descriptions to ATT&CK tactics and CAPEC attack patterns to reduce manual subjectivity and quantify risk",
      "End-to-end automated pipeline (ORCA) suitable for CI/CD, producing iterative, repeatable threat and component-level scores",
      "Dual-branch design: Threat-to-Techniques (TTM) and Threat-to-CAPEC (TCM) to mitigate coverage gaps in MITRE frameworks",
      "Evidence chaining from CAPEC→CWE→CVE with severity-based scoring; ability to produce tactic-phase heatmaps for components",
      "Demonstrated example implementation and testing on O-RAN, analyzing tunable parameters and resulting scores; integration path into automated testing pipelines"
    ]
  },
  {
    "arxiv_id": "2601.14614v1",
    "title": "Towards Cybersecurity Superintelligence: from AI-guided humans to human-guided AI",
    "authors": "Víctor Mayoral-Vilches; Stefan Rass; Martin Pinzger; Endika Gil-Uriarte; Unai Ayucar-Carbajo; Jon Ander Ruiz-Alcalde; Maite del Mundo de Torres; Luis Javier Navarrete-Lozano; María Sanz-Gómez; Francesco Balassone; Cristóbal R. J. Veas-Chavez; Vanesa Turiel; Alfonso Glera-Picón; Daniel Sánchez-Prieto; Yuri Salvatierra; Paul Zabalegui-Landa; Ruffino Reydel Cabrera-Álvarez; Patxi Mayoral-Pizarroso",
    "abstract": "Cybersecurity superintelligence -- artificial intelligence exceeding the best human capability in both speed and strategic reasoning -- represents the next frontier in security. This paper documents the emergence of such capability through three major contributions that have pioneered the field of AI Security. First, PentestGPT (2023) established LLM-guided penetration testing, achieving 228.6% improvement over baseline models through an architecture that externalizes security expertise into natural language guidance. Second, Cybersecurity AI (CAI, 2025) demonstrated automated expert-level performance, operating 3,600x faster than humans while reducing costs 156-fold, validated through #1 rankings at international competitions including the $50,000 Neurogrid CTF prize. Third, Generative Cut-the-Rope (G-CTR, 2026) introduces a neurosymbolic architecture embedding game-theoretic reasoning into LLM-based agents: symbolic equilibrium computation augments neural inference, doubling success rates while reducing behavioral variance 5.2x and achieving 2:1 advantage over non-strategic AI in Attack & Defense scenarios.   Together, these advances establish a clear progression from AI-guided humans to human-guided game-theoretic cybersecurity superintelligence.",
    "published_date": "2026-01-21",
    "pdf_link": "https://arxiv.org/pdf/2601.14614v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Offensive and Defensive Security",
      "subdomain": "Penetration Testing and Red/Blue Team Operations",
      "specific_problem": "Designing LLM-based cybersecurity agents that achieve superhuman performance by adding game-theoretic strategic reasoning to agentic penetration testing and attack/defense workflows",
      "attack_types": [
        "reverse engineering",
        "pwn/binary exploitation",
        "web exploitation",
        "cryptography challenges",
        "forensics",
        "robotics/OT challenges"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM-based Agent (Transformer LLM)",
        "specific": "PentestGPT-style Reasoning/Generation/Parsing modules; CAI multi-agent framework",
        "novel_contribution": "Architectural separation of reasoning vs. execution with a Penetration Testing Task Tree (PTT) for global context; fully automated agent orchestration (CAI) with tools, handoffs, and patterns"
      },
      {
        "type": "primary",
        "category": "Neurosymbolic",
        "specific": "Generative Cut-the-Rope (G-CTR)",
        "novel_contribution": "Embedding game-theoretic equilibrium computations (CTR) into LLM agents via strategic digests; closed-loop attack graph generation -> Nash equilibrium -> prompt injection to steer actions"
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "GPT-3.5 (baseline for PentestGPT)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM Agents (non-strategic)",
        "specific": "LLM-only agentic approaches without game-theoretic guidance",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "N/A (inference-time prompting and tool-augmented agents, no model training)"
    ],
    "datasets": [
      {
        "name": "CAIBench-Jeopardy CTFs (Cybench)",
        "type": "public",
        "domain": "ctf_jeopardy",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CAIBench-Jeopardy CTFs (Base)",
        "type": "public",
        "domain": "ctf_jeopardy",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "54 CTF challenges (CAI vs Human evaluation)",
        "type": "proprietary",
        "domain": "ctf_mixed_categories",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "44 cyber-range penetration tests (G-CTR evaluation)",
        "type": "proprietary",
        "domain": "penetration_tests",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GPT-3.5 (baseline for PentestGPT)",
        "paper_reference": null,
        "metric": "Aggregate improvement across 182 penetration testing sub-tasks",
        "their_result": "PentestGPT achieved “228.6% improvement over baseline models”",
        "baseline_result": "Baseline GPT-3.5 performance (numerical baseline not provided)"
      },
      {
        "method_name": "Human experts (benchmarking against CAI on 54 CTF challenges)",
        "paper_reference": null,
        "metric": "Speed (time), cost, category-wise comparisons",
        "their_result": "Overall ~11× faster on average; up to 3,600× faster on specific tasks; $109 API cost total",
        "baseline_result": "$17,218 equivalent human labor; humans faster in pwn (0.77× CAI) and crypto (0.47× CAI)"
      },
      {
        "method_name": "LLM-only agents (no game-theoretic guidance)",
        "paper_reference": null,
        "metric": "Success rate, cost-per-success, behavioral variance",
        "their_result": "G-CTR doubled success rate (20.0% → 42.9%), reduced cost-per-success 2.7× ($0.32 → $0.12), reduced behavioral variance 5.2×",
        "baseline_result": "Non-strategic LLM agent metrics before G-CTR augmentation"
      },
      {
        "method_name": "Non-strategic AI teams in Attack & Defense",
        "paper_reference": null,
        "metric": "Win ratio in Attack & Defense scenarios",
        "their_result": "G-CTR configuration defeated LLM-only baselines 2:1; outperformed independently-guided dual teams 3.7:1",
        "baseline_result": "1:2 vs G-CTR; 1:3.7 vs G-CTR for independently-guided dual teams"
      },
      {
        "method_name": "CAI vs CAI + G-CTR on CAIBench-Jeopardy CTFs (Base)",
        "paper_reference": null,
        "metric": "Success Rate (n=23 challenges, pass@3)",
        "their_result": "CAI + G-CTR: 100% success",
        "baseline_result": "CAI: 82.6% success; PentestGPT: 47.8% success"
      }
    ],
    "performance_metrics_used": [
      "success rate",
      "pass@3",
      "time to solve (seconds/minutes/days)",
      "API cost ($)",
      "speedup ratio (×)",
      "cost reduction ratio (×)",
      "cost-per-success",
      "behavioral variance",
      "competition rank/flags",
      "equilibrium success probability (game-theoretic)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How should we architect AI systems to reach the threshold of cybersecurity superintelligence (speed plus strategic reasoning)?",
        "Can game-theoretic guidance (symbolic equilibrium reasoning) augment LLM-based agents to surpass non-strategic AI and match or exceed human strategic capability?",
        "What are the limits of current LLM agents across security disciplines and difficulty levels, and where do they fail (e.g., long-horizon planning, novel attack synthesis)?"
      ],
      "gaps_identified": [
        "LLMs fail at coherent multi-step strategies due to context loss, recency bias, and hallucinations",
        "Human-in-the-loop execution is a bottleneck for throughput and scalability (addressed by CAI)",
        "Agentic LLMs can match/exceed human speed but lack strategic/game-theoretic reasoning",
        "LLM agents underperform humans in pwn and crypto where creative exploitation and mathematical insight are critical",
        "Benchmarks show signs of saturation; need more challenging, strategically rich evaluations"
      ],
      "limitations": [
        "Attack graph generation achieves 70–90% node correspondence with expert annotations; residual inaccuracies remain",
        "CAI approaches parity with humans at higher difficulty levels; underperforms in pwn and crypto",
        "Reported G-CTR advantages validated on 44 cyber-range tests; broader generalization to diverse real-world environments not yet demonstrated",
        "Metrics and budgets are constrained by API cost/time caps (e.g., 245 minutes and $40 per challenge)"
      ],
      "future_work": [],
      "motivation": "Document and analyze the progression from AI-guided humans to human-guided, game-theoretic AI and demonstrate a path toward cybersecurity superintelligence.",
      "potential_research_ideas": [
        "Train or fine-tune LLMs with curricula derived from game-theoretic equilibria to internalize strategic priors beyond prompt-time guidance",
        "Extend G-CTR to blue-team incident response playbooks with live telemetry-driven graph updates and real-time equilibrium recomputation",
        "Integrate formal verification of attack graph extraction and equilibrium computations to guarantee safety-critical correctness",
        "Develop dynamic benchmark suites that adapt to agent performance with adversarial task generation to avoid saturation",
        "Hybridize symbolic planners (e.g., PDDL/HTN) with G-CTR to improve long-horizon planning and reduce reliance on CoT alone",
        "Incorporate uncertainty-aware reasoning (e.g., POMDPs) to handle partial observability and noisy evidence in real environments",
        "Design robust tool-use policies that minimize prompt injection/tool output poisoning when building attack graphs from untrusted logs"
      ],
      "architectural_improvement_recommendations": [
        "Add confidence/uncertainty estimates to attack graph nodes/edges and propagate through equilibrium computations to create risk-aware strategic digests",
        "Introduce a verifier LLM or rule-based checker that cross-validates strategic digest recommendations against constraints and tool outputs",
        "Use retrieval-augmented generation with domain-specific exploit knowledge bases to improve pwn/crypto performance before equilibrium computation",
        "Implement hierarchical agent control: top-level strategic agent (G-CTR) supervising specialized tactical sub-agents with explicit handoff protocols",
        "Cache and reuse equilibrium computations across similar topologies (memoization) to reduce overhead and enable near-real-time guidance",
        "Adopt safe action filters and sandboxing policies to mitigate harmful or unsound actions recommended by agents under adversarial conditions"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Benchmark runs capped at 300 agent interactions, 245 minutes compute per challenge, and $40 API budget; evaluations use pass@3; typical agent cycle ≈70s with game-theoretic guidance ≈50s (per Figure 3)."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "CTF platforms and cyber ranges (Attack & Defense scenarios); competitive CTFs in 2025",
      "scalability_discussed": true,
      "inference_time": "Agentic loop timings shown: ≈70s for CAI agent; Game-theoretic guidance pipeline ≈50s; sub-steps range from <5ms to ≈28.3s per Figure 3.",
      "deployment_challenges": [
        "Automation vs autonomy gap and need for human supervisory oversight",
        "Potential bottlenecks in organizational workflows due to AI operating far faster than human processes",
        "Strategic reliability depends on accurate attack graph extraction from noisy/untrusted sources",
        "Benchmark saturation limits external validation; need harder, more representative tasks"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "PentestGPT: Introduced LLM-guided penetration testing with modular architecture (Reasoning/Generation/Parsing) and PTT global context; “228.6% improvement over baseline models.”",
      "Cybersecurity AI (CAI): Automated expert-level agent framework with end-to-end tool execution and coordination, achieving dramatic speed and cost improvements (up to 3,600× faster; 156× cheaper) and top rankings in international CTFs.",
      "Generative Cut-the-Rope (G-CTR): Neurosymbolic architecture embedding game-theoretic reasoning (CTR equilibrium) into LLM agents via strategic digest injection, doubling success rates, reducing variance 5.2×, and delivering 2:1 advantages in Attack & Defense.",
      "Demonstrated progression from AI-guided humans to game-theoretic AI agents, achieving 100% success on CAIBench-Jeopardy CTFs (Base) with CAI + G-CTR vs. 82.6% (CAI) and 47.8% (PentestGPT)."
    ]
  },
  {
    "arxiv_id": "2601.14343v1",
    "title": "Rethinking On-Device LLM Reasoning: Why Analogical Mapping Outperforms Abstract Thinking for IoT DDoS Detection",
    "authors": "William Pan; Guiran Liu; Binrong Zhu; Qun Wang; Yingzhou Lu; Beiyu Lin; Rose Qingyang Hu",
    "abstract": "The rapid expansion of IoT deployments has intensified cybersecurity threats, notably Distributed Denial of Service (DDoS) attacks, characterized by increasingly sophisticated patterns. Leveraging Generative AI through On-Device Large Language Models (ODLLMs) provides a viable solution for real-time threat detection at the network edge, though limited computational resources present challenges for smaller ODLLMs. This paper introduces a novel detection framework that integrates Chain-of-Thought (CoT) reasoning with Retrieval-Augmented Generation (RAG), tailored specifically for IoT edge environments. We systematically evaluate compact ODLLMs, including LLaMA 3.2 (1B, 3B) and Gemma 3 (1B, 4B), using structured prompting and exemplar-driven reasoning strategies. Experimental results demonstrate substantial performance improvements with few-shot prompting, achieving macro-average F1 scores as high as 0.85. Our findings highlight the significant advantages of incorporating exemplar-based reasoning, underscoring that CoT and RAG approaches markedly enhance small ODLLMs' capabilities in accurately classifying complex network attacks under stringent resource constraints.",
    "published_date": "2026-01-20",
    "pdf_link": "https://arxiv.org/pdf/2601.14343v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "On-device LLM-based detection and classification of IoT DDoS attack types from network flow features",
      "attack_types": [
        "ICMP flood",
        "UDP flood",
        "TCP SYN flood",
        "TCP PSH/ACK flood",
        "TCP RST/FIN flood"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "LLaMA 3.2 (1B, 3B) and Gemma 3 (1B, 4B)",
        "novel_contribution": "Use of compact on-device LLMs with exemplar-driven reasoning for IoT DDoS detection under resource constraints"
      },
      {
        "type": "primary",
        "category": "Retrieval-Augmented Generation",
        "specific": "Probability-guided RAG with XGBoost (Prob-RAG)",
        "novel_contribution": "Compact RAG optimized for small ODLLMs; retrieval over 9D flow features using Euclidean distance and/or XGBoost class-probabilities as semantic signatures; few-shot exemplar block concatenated with CoT template"
      },
      {
        "type": "primary",
        "category": "Chain-of-Thought",
        "specific": null,
        "novel_contribution": "Rule-based CoT template distilled from traffic-engineering heuristics; teacher LLM generates step-by-step CoT reports to populate a domain KB for demonstrations; enforced single final answer format"
      },
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost",
        "novel_contribution": "Serves dual role as supervised classifier (coarse prediction) and as embedding/signature for retrieval; specific hyperparameters reported (max_depth=6, learning_rate=0.1, n_estimators=100, multi:softmax)"
      },
      {
        "type": "baseline",
        "category": "Sentence Embedding Model",
        "specific": "bge-base-en-v1.5 (BAAI General Embedding)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": null,
        "novel_contribution": "Task-specific embedding model (16-D latent) trained with cross-entropy and label smoothing for improved separability vs general-purpose embeddings"
      },
      {
        "type": "baseline",
        "category": "Prompting",
        "specific": "Zero-shot, One-shot, Few-shot prompting variants",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "In-context learning (few-shot/one-shot)",
      "Zero-shot",
      "Retrieval-Augmented Generation"
    ],
    "datasets": [
      {
        "name": "CICIOT 2023",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CoT Knowledge Base for IoT DDoS (constructed from historical attack data)",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Few-Shot RAG (Llama 3.2 1B) vs No KB (Llama 3.2 1B)",
        "paper_reference": null,
        "metric": "Macro-F1",
        "their_result": "0.50",
        "baseline_result": "0.05"
      },
      {
        "method_name": "Few-Shot RAG (Gemma 3 1B) vs CoT (Gemma 3 1B)",
        "paper_reference": null,
        "metric": "Macro-F1",
        "their_result": "0.48",
        "baseline_result": "0.13"
      },
      {
        "method_name": "Few-Shot RAG (Llama 3.2 3B) vs Few-Shot RAG (Llama 3.2 1B)",
        "paper_reference": null,
        "metric": "Macro-F1",
        "their_result": "0.75",
        "baseline_result": "0.50"
      },
      {
        "method_name": "Few-Shot RAG (Gemma 3 4B) vs Few-Shot RAG (Gemma 3 1B)",
        "paper_reference": null,
        "metric": "Macro-F1",
        "their_result": "0.77",
        "baseline_result": "0.48"
      },
      {
        "method_name": "Short KB (Gemma 3 1B) vs No KB (Gemma 3 1B)",
        "paper_reference": null,
        "metric": "Macro-F1",
        "their_result": "0.36",
        "baseline_result": "0.34"
      }
    ],
    "performance_metrics_used": [
      "Macro-F1",
      "Per-class F1",
      "Per-class Precision"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can exemplar-based, analogical reasoning (few-shot RAG) enable small on-device LLMs to accurately classify IoT DDoS attacks under tight resource constraints?",
        "How should CoT and RAG be integrated for ODLLMs to overcome limited context and reasoning capability in edge settings?",
        "Which retriever (BGE embeddings, MLP, XGBoost-based) best supports RAG for tabular IoT traffic features?"
      ],
      "gaps_identified": [
        "Cloud LLMs raise privacy and latency concerns for real-time IoT threat detection at the edge.",
        "Small ODLLMs struggle on multi-attack classification without tailored knowledge support.",
        "General-purpose text embedding retrievers (e.g., BGE) fail to separate fine-grained TCP flood subtypes in this tabular feature space.",
        "CoT alone can induce confident but incorrect reasoning (‘protocol blindness’ and numeric misinterpretation), harming performance."
      ],
      "limitations": [
        "Zero-shot prompting leads to mode collapse on traffic data for small ODLLMs.",
        "CoT without exemplars often degrades performance (e.g., Gemma 3 1B macro-F1=0.13) due to hallucinated reasoning.",
        "Results are reported on selected balanced subsets (6 classes x 500 samples), primarily from CICIOT 2023; broader generalization not demonstrated in the text.",
        "No evaluation against adversarial/poisoning or concept drift scenarios is reported."
      ],
      "future_work": [],
      "motivation": "Enable accurate, low-latency, privacy-preserving IoT DDoS detection at the edge by boosting small ODLLM reasoning via CoT-guided, RAG-based exemplar prompting and compact retrieval over flow features.",
      "potential_research_ideas": [
        "Jointly learn the retriever and prompting policy (e.g., train a lightweight metric network or learnable Mahalanobis space for 9D features) to optimize end-to-end macro-F1.",
        "Lightweight verifier or self-consistency modules to filter hallucinated CoT steps; integrate uncertainty calibration for abstention on low-confidence flows.",
        "Distill few-shot competence into small ODLLMs via supervised finetuning on teacher-generated rationales and labels (rationale-augmented distillation).",
        "Online/continual learning to handle traffic drift and emerging DDoS variants while preserving on-device constraints.",
        "Hybrid neuro-symbolic approach: fuse rule-based TCP flag logic with LLM outputs via constrained decoding or structured output heads.",
        "Explore graph-based flow aggregation (e.g., GNN over host/port graphs) to provide richer context to the retriever without increasing token budgets.",
        "Energy-aware retrieval and prompt compression (template pruning, selective exemplar routing) for strict edge power envelopes."
      ],
      "architectural_improvement_recommendations": [
        "Replace Euclidean retrieval with a learned metric (e.g., prototypical networks or LMNN) over standardized 9D features; compare cosine vs Mahalanobis.",
        "Augment retrieval signature with XGBoost class probabilities concatenated to normalized features; re-rank by a small MLP scorer.",
        "Introduce a small verifier model to check CoT rationales against simple, differentiable checks (e.g., protocol consistency, flag thresholds) before finalizing label.",
        "Prompt optimization/AutoPrompt to refine CoT templates and exemplar formatting for minimal tokens and maximal accuracy.",
        "Use mixture-of-experts or LoRA adapters in ODLLMs specialized per attack family; route via retriever to the best expert.",
        "Quantize and compile ODLLMs with int4/int8 plus speculative decoding to reduce latency on edge hardware."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Ollama",
        "XGBoost",
        "Hugging Face Transformers"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Evaluated locally via Ollama on a desktop with NVIDIA RTX 4090 GPU and Intel i9-13900KF CPU."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "IoT edge device setting (on-device LLM inference; offline evaluation)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "On-device constraints: limited compute, memory, and token budgets for ODLLMs.",
        "Zero-shot failure/mode collapse on tabular traffic without exemplars.",
        "Designing compact yet effective retrieval and prompts under tight context windows.",
        "Need for high-quality exemplars/KB construction from historical data."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes an ODLLM-based IoT DDoS detection framework integrating rule-based CoT prompting with compact RAG tailored for edge devices.",
      "Designs a probability-guided RAG using standardized 9D flow features and XGBoost outputs as retrieval signatures; compares BGE, MLP, and XGBoost retrievers.",
      "Introduces a teacher-student style knowledge base: large LLM generates CoT rationales offline to populate a domain-specific KB for small ODLLM inference.",
      "Systematically evaluates compact LLMs (LLaMA 3.2 1B/3B, Gemma 3 1B/4B) with zero/one/few-shot prompting; shows exemplar-driven reasoning markedly outperforms abstract CoT.",
      "Reports substantial gains with few-shot RAG, with macro-average F1 up to 0.85 (and text-reported examples: Llama 3.2 1B from 0.05 to 0.50; Gemma 3 1B from 0.13 to 0.48; Gemma 3 4B few-shot ~0.77; Llama 3.2 3B few-shot ~0.75)."
    ]
  },
  {
    "arxiv_id": "2601.12716v1",
    "title": "CellularSpecSec-Bench: A Staged Benchmark for Evidence-Grounded Interpretation and Security Reasoning over 3GPP Specifications",
    "authors": "Ke Xie; Xingyi Zhao; Yiwen Hu; Shuhan Yuan; Tian Xie",
    "abstract": "Cellular networks are critical infrastructure supporting billions of worldwide users and safety- and mission-critical services. Vulnerabilities in cellular networks can therefore cause service disruption, privacy breaches, and broad societal harm, motivating growing efforts to analyze 3GPP specifications that define required device and operator behavior. While large language models (LLMs) have demonstrated the capability for reading technical documents, cellular specifications impose unique challenges: faithful interpretation of normative language, reasoning across cross-referenced clauses, and verifiable conclusions grounded in multimodal evidence such as tables and figures. To address these challenges, we propose CellSpecSec-ARI, a unified Adapt-Retrieve-Integrate framework for systematic understanding and standard-driven security analysis of 3GPP specifications; CellularSpecSec-Bench, a staged benchmark, containing newly constructed high-quality datasets with expert-verified and corrected subsets from prior open-source resources. Together, they establish an accessible and reproducible foundation for quantifying progress in specification understanding and security reasoning in the cellular network security domain.",
    "published_date": "2026-01-19",
    "pdf_link": "https://arxiv.org/pdf/2601.12716v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Cellular Network Security",
      "specific_problem": "Evidence-grounded interpretation and security reasoning over 3GPP (4G/5G) control-plane specifications",
      "attack_types": [
        "downgrade attacks",
        "replay attacks",
        "denial-of-service",
        "missing integrity protection",
        "ambiguous normative requirements"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Retrieval-Augmented Generation (RAG)",
        "specific": "SpecRAG: hybrid BM25 + TF-IDF with truncated SVD dense vectors",
        "novel_contribution": "Task-tailored hybrid retrieval over multimodal specification components (text, tables, figures) with evidence-citation for grounding"
      },
      {
        "type": "primary",
        "category": "Knowledge Graph Reasoning",
        "specific": "Taxonomy-based knowledge graph over 3GPP entities/relations",
        "novel_contribution": "Transforms retrieved multimodal evidence into a structured, interlinked KG that captures procedural and security relations; KG blocks used as additional retrievable context"
      },
      {
        "type": "primary",
        "category": "Multimodal Document Processing",
        "specific": "SpecFusion: table/figure-to-structured-JSON then textual serialization for adaptation",
        "novel_contribution": "Unifies text, tables, and figures from 3GPP specs into a common textual representation to adapt LLMs to specification style and multimodal content"
      }
    ],
    "learning_paradigm": [
      "Prompt-based inference",
      "Retrieval-Augmented Generation",
      "Knowledge-graph-enhanced reasoning"
    ],
    "datasets": [
      {
        "name": "CellularSpecSec-Bench (overall benchmark)",
        "type": "unknown",
        "domain": "standards_documents (3GPP specifications)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_specified"
      },
      {
        "name": "CellularSpecSec-Bench: Core 3GPP control-plane corpus (Release-17 TS 24/38 series)",
        "type": "unknown",
        "domain": "standards_documents (3GPP specs: NAS/RRC)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_specified"
      },
      {
        "name": "CellularSpecSec-Bench: Security reasoning dataset (43 real-world vulnerabilities)",
        "type": "unknown",
        "domain": "standards_documents + security_reasoning over 3GPP",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_specified"
      },
      {
        "name": "TeleQnA (expert-verified/corrected subset within CellularSpecSec-Bench)",
        "type": "public",
        "domain": "standards_documents (telecom/3GPP QA)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Telco-DPR (integrated subset)",
        "type": "public",
        "domain": "standards_documents (telecom retrieval QA)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "TSpec-LLM (integrated subset)",
        "type": "public",
        "domain": "standards_documents (3GPP corpus & QA)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Tele-LLMs / Tele-Data (integrated subset)",
        "type": "public",
        "domain": "standards_documents (telecom QA for domain adaptation)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SPEC5G (5G security classification)",
        "type": "public",
        "domain": "standards_documents + security_text_classification",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ConTester (semantic-equivalence sentence pairs, 4G)",
        "type": "public",
        "domain": "standards_documents (NLI over 3GPP sentences)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CellularLint (NLI-style sentence pairs, 4G/5G)",
        "type": "public",
        "domain": "standards_documents (NLI over 3GPP sentences)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can LLM-based systems faithfully interpret normative language, reason across cross-referenced 3GPP clauses, and produce verifiable, evidence-grounded conclusions over multimodal content (text, tables, figures)?",
        "How to design a unified, reproducible methodology and benchmark for specification understanding and security reasoning in cellular network standards?"
      ],
      "gaps_identified": [
        "Lack of a comprehensive, reproducible benchmark for 3GPP specification understanding and security reasoning.",
        "Existing datasets largely rely on LLM-generated entries without expert validation, limiting reliability for safety-critical evaluation.",
        "Prior work focuses on sentence-/paragraph-level tasks and does not capture procedural semantics or cross-clause dependencies critical for security outcomes.",
        "LLMs misinterpret specification-specific terminology and mishandle tables/figures; RAG alone may miss cross-clause dependencies.",
        "Limited explicit evaluation of evidence-grounded performance in existing resources."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Establish an accessible, reproducible foundation and methodology to systematically evaluate and improve LLMs’ capabilities for 3GPP specification interpretation and security reasoning in cellular networks.",
      "potential_research_ideas": [
        "Develop end-to-end multimodal encoders for tables and signaling figures (e.g., table transformers, diagram parsers) and compare against the current JSON-serialization approach.",
        "Learned cross-document procedural graphs using GNNs over the taxonomy-based KG to improve multi-step, multi-spec reasoning.",
        "Automatic evidence verification and citation consistency checking to penalize unsupported or partially supported answers.",
        "Temporal/version-aware reasoning that adapts to evolving 3GPP releases and tracks changes impacting security properties.",
        "Integrate formal methods (model checking or protocol verification) with the KG to validate inferred security properties.",
        "Robustness evaluation under retrieval noise and incomplete evidence; design retrieval-robust prompting and aggregation.",
        "Active-learning pipelines where experts validate a small set of contentious items to maximize dataset reliability with minimal effort."
      ],
      "architectural_improvement_recommendations": [
        "Replace TF-IDF+SVD dense vectors with domain-adapted bi-encoders (e.g., Contriever or ColBERT-style retrievers) fine-tuned on verified spec QA for better semantic recall.",
        "Add a table-aware and figure-aware encoder branch; fuse it with text via cross-attention rather than only textual serialization.",
        "Use graph neural networks over the taxonomy-based KG to perform neural message passing for procedural/state-machine reasoning.",
        "Introduce explicit citation planning in the decoder (constrained decoding with clause/table/figure IDs) to enforce evidence grounding.",
        "Adopt iterative retrieval-generation with self-reflection to resolve cross-clause dependencies (e.g., multi-hop retrieval controller).",
        "Implement clause segmentation tuned to 3GPP structure (subclause-aware chunking) and dynamic k selection based on query complexity."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Scaling retrieval over thousands of pages and many specifications",
        "Maintaining accurate cross-document linking and evidence grounding",
        "Handling multimodal content (tables, figures) in a reliable, verifiable manner"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces CellSpecSec-ARI, a unified Adapt–Retrieve–Integrate framework for systematic understanding and security analysis of 3GPP specifications.",
      "Presents CellularSpecSec-Bench, a staged benchmark with newly constructed datasets and expert-verified/corrected subsets from prior resources, covering Release-17 core specs with multimodal content.",
      "Applies CellSpecSec-ARI to CellularSpecSec-Bench to provide baseline results and discuss strengths and remaining challenges of LLM-based standards analysis."
    ]
  },
  {
    "arxiv_id": "2601.06768v1",
    "title": "ALFA: A Safe-by-Design Approach to Mitigate Quishing Attacks Launched via Fancy QR Codes",
    "authors": "Muhammad Wahid Akram; Keshav Sood; Muneeb Ul Hassan; Dhananjay Thiruvady",
    "abstract": "Phishing with Quick Response (QR) codes is termed as Quishing. The attackers exploit this method to manipulate individuals into revealing their confidential data. Recently, we see the colorful and fancy representations of QR codes, the 2D matrix of QR codes which does not reflect a typical mixture of black-white modules anymore. Instead, they become more tempting as an attack vector for adversaries which can evade the state-of-the-art deep learning visual-based and other prevailing countermeasures. We introduce \"ALFA\", a safe-by-design approach, to mitigate Quishing and prevent everyone from accessing the post-scan harmful payload of fancy QR codes. Our method first converts a fancy QR code into the replica of binary grid and then identify the erroneous representation of modules in that grid. Following that, we present \"FAST\" method which can conveniently recover erroneous modules from that binary grid. Afterwards, using this binary grid, our solution extracts the structural features of fancy QR code and predicts its legitimacy using a pre-trained model. The effectiveness of our proposal is demonstrated by the experimental evaluation on a synthetic dataset (containing diverse variations of fancy QR codes) and achieve a FNR of 0.06% only. We also develop the mobile app to test the practical feasibility of our solution and provide a performance comparison of the app with the real-world QR readers. This comparison further highlights the classification reliability and detection accuracy of this solution in real-world environments.",
    "published_date": "2026-01-11",
    "pdf_link": "https://arxiv.org/pdf/2601.06768v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Social Engineering Defense",
      "subdomain": "Anti-phishing",
      "specific_problem": "Pre-scan legitimacy classification of fancy (custom-shaped) QR codes to mitigate quishing",
      "attack_types": [
        "QR-based phishing (Quishing)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Algorithmic pre-processing",
        "specific": "FAST (Finder, Alignment, Separators, Timing) module-recovery method",
        "novel_contribution": "Recover mislabeled modules in the binary replica using standard QR structural patterns to improve downstream classification"
      },
      {
        "type": "primary",
        "category": "Feature-based supervised classifier",
        "specific": null,
        "novel_contribution": "Classification using 24 structural features extracted from a recovered binary grid of fancy QR codes with a pre-trained model"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Synthetic Fancy QR Codes Dataset (this paper)",
        "type": "synthetic",
        "domain": "qr_images",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Existing URLs dataset [14]",
        "type": "public",
        "domain": "urls",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Real-world QR reader apps (Play Store/App Store)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "URL-driven approaches",
        "paper_reference": "[23]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Visual deep learning methods trained on black-white QR codes",
        "paper_reference": "[23,20]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "False Negative Rate (FNR)",
      "Accuracy",
      "Latency",
      "Resource usage",
      "Robustness"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can fancy (custom-shaped) QR codes be classified as phishing or legitimate via structural analysis without accessing the encoded payload?",
        "Can mislabeled modules in fancy QR codes be reliably recovered to form an accurate binary grid suitable for classification?"
      ],
      "gaps_identified": [
        "Existing works focus on generating aesthetic/fancy QR codes and improving scan robustness, not on quishing defense.",
        "Visual deep learning approaches are trained on black-white QR codes and may not generalize to diverse fancy patterns.",
        "URL-driven methods cannot determine QR legitimacy before payload access and can be unsafe in mobile webviews.",
        "Prior structural analyses target standard black-white QR codes and lack mechanisms to recover erroneous module labels in fancy codes."
      ],
      "limitations": [
        "Evaluation primarily on a synthetic dataset of fancy QR codes; real-world generalization is not fully established.",
        "Classifier model type and training details are not specified, limiting reproducibility.",
        "Heuristic intensity thresholds (e.g., 189/238) for module binarization may be sensitive to imaging conditions and very small modules.",
        "Dataset construction relies on 11 public generators and an external URLs list; coverage of the fancy QR design space is unclear."
      ],
      "future_work": [],
      "motivation": "Provide a safe-by-design, on-device method to detect quishing using structural properties of fancy QR codes without exposing users to potentially harmful payloads.",
      "potential_research_ideas": [
        "Create and release a large-scale, labeled benchmark of fancy QR codes spanning diverse patterns, colors, ECC levels, print/scan conditions, and real quishing campaigns.",
        "Develop adaptive, learning-based module segmentation to replace fixed intensity thresholds and improve robustness to lighting and print distortions.",
        "Integrate content-agnostic anomaly detection on structural feature distributions to flag novel or out-of-distribution fancy designs.",
        "Joint optimization of module-recovery (FAST-like) and classifier via end-to-end differentiable pipelines using synthetic-to-real domain adaptation.",
        "Augment with lightweight on-device URL risk scoring guarded by strict isolation to study combined structural+payload risk under privacy constraints."
      ],
      "architectural_improvement_recommendations": [
        "Replace fixed dual-threshold binarization with adaptive thresholding (e.g., local adaptive/Otsu-per-cell) or a tiny CNN for per-module intensity estimation.",
        "Use a probabilistic module confidence map and error-correcting decoding to guide FAST recovery iteratively.",
        "Employ an interpretable tree ensemble (e.g., gradient boosting) over the 24 structural features and conduct feature importance analysis for explainability.",
        "Incorporate data augmentation that simulates print/scan, blur, illumination changes, and occlusions to harden both FAST and the classifier.",
        "Add an OOD detector (e.g., Mahalanobis distance over feature space) to abstain on unseen fancy styles."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Flutter"
      ],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Smartphone (Android/iOS), fully on-device processing",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Wide variability in fancy module shapes, colors, and embedded logos/backgrounds",
        "Handling inverted layouts and small modules affecting intensity estimates",
        "Recovering correct QR version and format bits under noise and distortions",
        "Dependence on ECC levels and printing/scanning quality in the wild"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "ALFA: a safe-by-design structural analysis approach for classifying fancy QR codes against quishing without accessing payload.",
      "FAST method to identify and recover mislabeled modules in the binary replica using standard QR patterns.",
      "End-to-end pipeline to infer QR version, build a binary grid, extract 24 structural features, and classify with a pre-trained model.",
      "A mobile app (Flutter) demonstrating on-device feasibility with comparison to real-world QR readers.",
      "Experimental evaluation on a synthetic fancy QR dataset reporting “a FNR of 0.06% only.”"
    ]
  },
  {
    "arxiv_id": "2601.12311v1",
    "title": "Cross-reality Location Privacy Protection in 6G-enabled Vehicular Metaverses: An LLM-enhanced Hybrid Generative Diffusion Model-based Approach",
    "authors": "Xiaofeng Luo; Jiayi He; Jiawen Kang; Ruichen Zhang; Zhaoshui He; Ekram Hossain; Dong In Kim",
    "abstract": "The emergence of 6G-enabled vehicular metaverses enables Autonomous Vehicles (AVs) to operate across physical and virtual spaces through space-air-ground-sea integrated networks. The AVs can deploy AI agents powered by large AI models as personalized assistants, on edge servers to support intelligent driving decision making and enhanced on-board experiences. However, such cross-reality interactions may cause serious location privacy risks, as adversaries can infer AV trajectories by correlating the location reported when AVs request LBS in reality with the location of the edge servers on which their corresponding AI agents are deployed in virtuality. To address this challenge, we design a cross-reality location privacy protection framework based on hybrid actions, including continuous location perturbation in reality and discrete privacy-aware AI agent migration in virtuality. In this framework, a new privacy metric, termed cross-reality location entropy, is proposed to effectively quantify the privacy levels of AVs. Based on this metric, we formulate an optimization problem to optimize the hybrid action, focusing on achieving a balance between location protection, service latency reduction, and quality of service maintenance. To solve the complex mixed-integer problem, we develop a novel LLM-enhanced Hybrid Diffusion Proximal Policy Optimization (LHDPPO) algorithm, which integrates LLM-driven informative reward design to enhance environment understanding with double Generative Diffusion Models-based policy exploration to handle high-dimensional action spaces, thereby enabling reliable determination of optimal hybrid actions. Extensive experiments on real-world datasets demonstrate that the proposed framework effectively mitigates cross-reality location privacy leakage for AVs while maintaining strong user immersion within 6G-enabled vehicular metaverse scenarios.",
    "published_date": "2026-01-18",
    "pdf_link": "https://arxiv.org/pdf/2601.12311v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Vehicular Network Security",
      "subdomain": "Location Privacy",
      "specific_problem": "Protecting cross-reality location privacy for autonomous vehicles by jointly perturbing reported physical locations and migrating AI agents across edge servers in a 6G-enabled vehicular metaverse",
      "attack_types": [
        "cross-reality linkage attack",
        "trajectory inference",
        "collusive inference attack",
        "service-migration-based location inference"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": "Proximal Policy Optimization (PPO) variant",
        "novel_contribution": "LHDPPO: LLM-enhanced Hybrid Diffusion PPO to solve a mixed-integer hybrid-action MDP for joint continuous location perturbation and discrete agent migration"
      },
      {
        "type": "primary",
        "category": "Diffusion Model",
        "specific": "Generative Diffusion Models (double GDM-based policy exploration)",
        "novel_contribution": "Double GDMs for policy exploration tailored to high-dimensional hybrid action spaces, decoupling continuous and discrete decisions"
      },
      {
        "type": "primary",
        "category": "Large Language Model",
        "specific": null,
        "novel_contribution": "LLM-driven informative reward design to enhance environment understanding and reduce reward misspecification"
      },
      {
        "type": "baseline",
        "category": "Differential Privacy Mechanism",
        "specific": "Planar Laplacian mechanism for ε-geo-indistinguishability",
        "novel_contribution": "Used as the continuous action mechanism for location perturbation (not the core algorithmic novelty)"
      }
    ],
    "learning_paradigm": [
      "Reinforcement Learning",
      "Deep Reinforcement Learning"
    ],
    "datasets": [
      {
        "name": "Real-world taxi mobility dataset",
        "type": "",
        "domain": "mobility_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Base station dataset",
        "type": "",
        "domain": "base_station_locations",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "cross-reality location entropy (new metric)",
      "service response latency",
      "Quality of Service (QoS) loss"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to protect AVs’ cross-reality location privacy when adversaries correlate physical LBS-request locations with virtual AI agent server locations?",
        "How to jointly optimize continuous location perturbation and discrete AI agent migration to balance privacy protection, latency reduction, and QoS maintenance?",
        "How to quantify cross-reality location privacy with a metric that captures physical–virtual linkability under inference attacks?",
        "How to efficiently solve the resulting mixed-integer, hybrid-action optimization problem in high-dimensional action spaces?"
      ],
      "gaps_identified": [
        "Existing anonymity-based schemes degrade in low-traffic environments and fail to meet stringent AV privacy requirements.",
        "Most location privacy metrics are single-domain (typically physical space) and cannot capture cross-reality privacy leakage.",
        "Encryption-based approaches impose heavy computational overhead unsuitable for real-time 6G vehicular metaverse services.",
        "Prior GDM-based RL methods struggle with hybrid action modeling and rely entirely on manually crafted reward functions that can miss important components in complex cross-reality environments."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Cross-reality interactions in 6G-enabled vehicular metaverses introduce severe location privacy risks via linkage of physical LBS locations and virtual AI agent server locations; there is a need for a comprehensive protection mechanism, metric, and efficient optimization under latency/QoS constraints.",
      "potential_research_ideas": [
        "Provide formal privacy guarantees that jointly account for both physical perturbation and virtual agent migration (e.g., a unified cross-reality differential privacy framework).",
        "Extend to multi-agent coordination where multiple AVs cooperatively select perturbation/migration to amplify privacy while controlling network load.",
        "Incorporate adversarial modeling with stronger collusion assumptions (malicious LBS providers and edge providers) and design robust policies via adversarial RL.",
        "Investigate constrained or risk-sensitive RL to explicitly enforce latency/QoS constraints while optimizing privacy (CMDP formulation).",
        "Develop online adaptation/meta-RL to rapidly retune policies across cities or changing base-station deployments.",
        "Use graph neural networks to model edge-server topology and mobility patterns for improved migration decision quality.",
        "Explore trajectory-level diffusion or decision-transformer-based sequence modeling as an alternative to PPO for hybrid actions.",
        "Integrate federated or on-device learning to reduce data exposure while training privacy policies.",
        "Add causal inference to decouple confounders between mobility patterns and server placement, improving reward design and policy generalization."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a hierarchical RL architecture: upper-level discrete agent migration planner and lower-level continuous perturbation controller to stabilize training.",
        "Formulate and solve the problem as a constrained MDP with Lagrangian methods to guarantee latency/QoS constraints.",
        "Augment policy with a GNN encoder over RSU/LEO graph topology and dynamic load states to better inform migration decisions.",
        "Replace manual LLM prompting with a learned reward model (RLAIF/RLHF-style) to systematize reward design and reduce drift.",
        "Incorporate uncertainty estimation (e.g., ensemble critics) to modulate exploration with diffusion policies safely.",
        "Leverage model-based RL for fast planning and counterfactual evaluation of hybrid actions, reducing sample complexity.",
        "Introduce curriculum learning over attack strengths and traffic sparsity to improve robustness and convergence."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Edge servers (RSUs and LEO satellite nodes) in a 6G-enabled vehicular metaverse; evaluated with real-world mobility and base-station datasets in simulation",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Balancing privacy protection with service latency and QoS to maintain user immersion",
        "High-dimensional hybrid action optimization with moving AVs and dynamic edge coverage",
        "Potential computational overhead at edge for diffusion-based exploration and RL updates"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "A cross-reality location privacy protection framework for 6G-enabled vehicular metaverses using hybrid actions (continuous location perturbation in reality and discrete privacy-aware AI agent migration in virtuality).",
      "A new privacy metric, cross-reality location entropy, to quantify AV privacy under cross-reality inference attacks.",
      "A mixed-integer optimization problem formulation balancing privacy, service latency, and QoS under hybrid actions.",
      "A novel LLM-enhanced Hybrid Diffusion PPO (LHDPPO) algorithm that couples LLM-driven informative reward design with double GDM-based policy exploration for hybrid action spaces.",
      "Extensive experiments on real-world taxi mobility and base-station datasets demonstrating effective mitigation of cross-reality location privacy leakage while maintaining immersive user experience."
    ]
  },
  {
    "arxiv_id": "2601.11996v1",
    "title": "MongoDB Injection Query Classification Model using MongoDB Log files as Training Data",
    "authors": "Shaunak Perni; Minal Shirodkar; Ramdas Karmalli",
    "abstract": "NoSQL Injection attacks are a class of cybersecurity attacks where an attacker sends a specifically engineered query to a NoSQL database which then performs an unauthorized operation. To defend against such attacks, rule based systems were initially developed but then were found to be ineffective to innovative injection attacks hence a model based approach was developed. Most model based detection systems, during testing gave exponentially positive results but were trained only on the query statement sent to the server. However due to the scarcity of data and class imbalances these model based systems were found to be not effective against all attacks in the real world. This paper explores classifying NoSQL injection attacks sent to a MongoDB server based on Log Data, and other extracted features excluding raw query statements. The log data was collected from a simulated attack on an empty MongoDB server which was then processed and explored. A discriminant analysis was carried out to determine statistically significant features to discriminate between injection and benign queries resulting in a dataset of significant features. Several Machine learning based classification models using an AutoML library, \"FLAML\", as well as 6 manually programmed models were trained on this dataset , which were then trained on 50 randomized samples of data, cross validated and evaluated. The study found that the best model was the \"FLAML\" library's \"XGBoost limited depth\" model with an accuracy of 71%.",
    "published_date": "2026-01-17",
    "pdf_link": "https://arxiv.org/pdf/2601.11996v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Application Security",
      "subdomain": "Web Application Security",
      "specific_problem": "Detection of NoSQL/MongoDB injection attacks using MongoDB server log features (excluding raw query text)",
      "attack_types": [
        "NoSQL injection (MongoDB)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost (limited depth via FLAML)",
        "novel_contribution": "Applies supervised classification on engineered MongoDB server log features (excluding raw query strings) to detect injection queries"
      },
      {
        "type": "baseline",
        "category": "AutoML",
        "specific": "FLAML",
        "novel_contribution": "Used to select and tune the best-performing model; identified XGBoost limited depth as best"
      },
      {
        "type": "baseline",
        "category": "Feature Selection/Statistical Test",
        "specific": "Mann-Whitney U test-based discriminant analysis",
        "novel_contribution": "Used to identify statistically significant numerical features differentiating injection vs benign queries"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Generated MongoDB Log Feature Dataset (this paper)",
        "type": "synthetic",
        "domain": "log_files",
        "link": "https://github.com/ShaunakPerniUniGoa/NoSQLInjectionDetection",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "The MongoDB Injection Dataset",
        "type": "public",
        "domain": "payload_text",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Ul Islam et al. (2019) labeled NoSQL injection dataset",
        "type": "public",
        "domain": "payload_text",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can NoSQL/MongoDB injection attacks be classified using MongoDB server log data and engineered features excluding the raw query statements?",
        "Which log-derived features statistically discriminate between injection and benign queries?"
      ],
      "gaps_identified": [
        "Scarcity of publicly available labeled datasets for NoSQL injection detection, especially log-based data",
        "Class imbalance in available datasets",
        "Existing model-based systems trained only on raw query statements may not generalize well to real-world attacks"
      ],
      "limitations": [
        "Dataset generated on an empty MongoDB server; may not reflect production workloads",
        "Excludes raw query text from modeling, potentially limiting discriminative power",
        "Moderate best accuracy of 71% indicates room for improvement",
        "Some constant columns required manual removal after automated processing"
      ],
      "future_work": [],
      "motivation": "Improve robustness of NoSQL injection detection by moving beyond raw query-string-based models to log-derived features and provide an openly available dataset and code.",
      "potential_research_ideas": [
        "Collect and release a real-world MongoDB log corpus with diverse workloads and labeled injection events to improve generalization",
        "Build a multimodal model that jointly uses log-derived metadata and sanitized query text features",
        "Sequence modeling of query sessions (e.g., Transformers on ordered log lines) to capture temporal behavioral patterns of attacks",
        "Unsupervised or semi-supervised anomaly detection on long-term log baselines to detect novel injections",
        "Adversarial evaluation and hard-negative mining using tools like Nosqlmap to improve robustness",
        "Active learning with human-in-the-loop labeling on ambiguous log events",
        "Cross-database generalization: train on MongoDB logs and test transfer to other NoSQL systems (CouchDB, Cassandra)"
      ],
      "architectural_improvement_recommendations": [
        "Replace single-instance tabular models with gradient-boosted trees plus calibrated probability outputs and cost-sensitive training for imbalance",
        "Introduce feature learning with tabular deep learning (e.g., TabNet) and compare with GBDTs",
        "Incorporate session-level features (counts, rates, bursts, operator diversity) and temporal context windows",
        "Use SHAP-based feature attribution to guide iterative feature engineering and improve interpretability",
        "Apply ensemble stacking of heterogeneous models (GBDT + linear + tree) tuned via FLAML",
        "Data augmentation with realistic background traffic and noise injection to mimic production logging variability"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/ShaunakPerniUniGoa/NoSQLInjectionDetection",
      "frameworks": [
        "FLAML",
        "XGBoost"
      ],
      "reproducibility_score": "high",
      "computational_requirements": "Fedora 39, MongoDB 6.0.15 with profiling level 2, mongosh 2.25; AMD Ryzen 7 5700U CPU, 8 GiB RAM, 1TB HDD. Training performed via CPU; dataset is small."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Scarcity of labeled real-world log data",
        "Class imbalance",
        "Generalization gap from simulated empty-server environment to production systems",
        "Potential variability across MongoDB versions and logging configurations"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a log-based approach for classifying MongoDB NoSQL injection attacks using engineered features while excluding raw query statements",
      "Creates and releases a synthetic dataset of MongoDB log-derived features and labels; provides full code and notebooks",
      "Performs discriminant analysis to identify statistically significant features separating injection and benign queries",
      "Evaluates multiple ML models, including AutoML (FLAML), and reports: \"The study found that the best model was the 'FLAML' library’s 'XGBoost limited depth' model with an accuracy of 71%\""
    ]
  },
  {
    "arxiv_id": "2601.06948v1",
    "title": "Operational Runtime Behavior Mining for Open-Source Supply Chain Security",
    "authors": "Zhuoran Tan; Ke Xiao; Jeremy Singer; Christos Anagnostopoulos",
    "abstract": "Open-source software (OSS) is a critical component of modern software systems, yet supply chain security remains challenging in practice due to unavailable or obfuscated source code. Consequently, security teams often rely on runtime observations collected from sandboxed executions to investigate suspicious third-party components. We present HeteroGAT-Rank, an industry-oriented runtime behavior mining system that supports analyst-in-the-loop supply chain threat investigation. The system models execution-time behaviors of OSS packages as lightweight heterogeneous graphs and applies attention-based graph learning to rank behavioral patterns that are most relevant for security analysis. Rather than aiming for fully automated detection, HeteroGAT-Rank surfaces actionable runtime signals - such as file, network, and command activities - to guide manual investigation and threat hunting. To operate at ecosystem scale, the system decouples offline behavior mining from online analysis and integrates parallel graph construction for efficient processing across multiple ecosystems. An evaluation on a large-scale OSS execution dataset shows that HeteroGAT-Rank effectively highlights meaningful and interpretable behavioral indicators aligned with real-world vulnerability and attack trends, supporting practical security workflows under realistic operational constraints.",
    "published_date": "2026-01-11",
    "pdf_link": "https://arxiv.org/pdf/2601.06948v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Supply Chain Security",
      "subdomain": "Open-Source Ecosystem Security",
      "specific_problem": "Analyst-in-the-loop ranking of runtime behavioral indicators (files, network, commands, DNS) from sandboxed OSS package executions to support threat investigation when source code is unavailable/obfuscated",
      "attack_types": [
        "software supply chain attacks",
        "malicious OSS packages exhibiting runtime behaviors"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN (Heterogeneous)",
        "specific": "HeteroConv + GATv2Conv (type-aware GATv2)",
        "novel_contribution": "HeteroGAT-Rank: heterogeneous, type-aware attention for subgraph classification with extracted node/edge attentions for ranking actionable runtime behaviors"
      },
      {
        "type": "primary",
        "category": "Attention Pooling",
        "specific": null,
        "novel_contribution": "Two-stage attention-based pooling with top-k evidence selection tailored to 1-hop heterogeneous runtime graphs for compact, interpretable subgraph embeddings"
      },
      {
        "type": "primary",
        "category": "Contrastive Learning",
        "specific": null,
        "novel_contribution": "Composite loss includes a contrastive term to improve cross-ecosystem robustness and embedding separability"
      },
      {
        "type": "primary",
        "category": "Attribution/Explainability",
        "specific": "Attention-based saliency + Grad-CAM-inspired gradient magnitude ranking",
        "novel_contribution": "Dual attention extraction (attention coefficients and gradient-based influence) to rank nodes/edges as actionable indicators"
      },
      {
        "type": "primary",
        "category": "Embedding/Feature Encoding",
        "specific": "Categorical encoders + lightweight transformer-based token/value encoders",
        "novel_contribution": "Normalization and semantic embedding of runtime tokens (paths, domains, commands) to reduce sparsity across ecosystems"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Self-supervised (auxiliary contrastive regularization)"
    ],
    "datasets": [
      {
        "name": "OSPtrack (cross-ecosystem runtime-trace dataset) built from OpenSSF Package Analysis",
        "type": "public",
        "domain": "runtime_traces (file I/O, sockets, DNS, commands) across OSS ecosystems (PyPI, NPM, RubyGems, Packagist, crates.io)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Extended OSPTrack malicious subset (authors’ extension)",
        "type": "proprietary",
        "domain": "runtime_traces (augmented malicious instances via replay of OpenSSF pipeline)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Static analysis and code-centric methods are limited when source code is unavailable, incomplete, or obfuscated",
        "Many supply chain attacks only manifest at runtime (multi-stage, environment-dependent), requiring dynamic observation",
        "Existing online feature selection often treats data as flat features and is weak at reasoning over structured runtime behaviors",
        "Differential analysis typically needs paired versions/baselines and does not directly scale to ecosystem-level aggregation",
        "Per-sample dynamic simulations/fuzzing limit scalability in large ecosystems",
        "Label imbalance across ecosystems can bias models; need cross-ecosystem learning without ecosystem-specific shortcuts"
      ],
      "limitations": [
        "Label imbalance across ecosystems in the dataset",
        "Highly skewed per-instance edge cardinalities (e.g., Action edges up to 128,781) make naive loading and dense tensorization impractical",
        "One-hop star-shaped graphs capture direct interactions but omit multi-hop/control-flow context",
        "Ecosystem identifiers are excluded from features to mitigate bias, potentially discarding useful domain context"
      ],
      "future_work": [],
      "motivation": "Enable operational understanding of OSS runtime behavior for supply chain security when source code may be unavailable/obfuscated; surface actionable, interpretable runtime signals at ecosystem scale to guide analyst threat hunting under realistic constraints.",
      "potential_research_ideas": [
        "Incorporate limited multi-hop context (e.g., short path expansions or session-level temporal sequencing) to capture higher-order behaviors without losing interpretability",
        "Fuse static and dynamic signals (when available) with modality-specific encoders to improve coverage of attacks that partially manifest in code",
        "Online/streaming adaptation to continuously ingest new package runs and update rankings with concept drift detection",
        "Human-in-the-loop learning: use analyst feedback on ranked indicators to refine attention distributions via preference learning or RLHF-like objectives",
        "Robustness to manipulation: study adversarial perturbations of runtime traces and develop regularizers/augmentations that stabilize explanations",
        "Uncertainty-aware ranking: calibrate scores and provide confidence intervals or risk tiers for surfaced behaviors",
        "Cross-ecosystem domain adaptation with invariant risk minimization to further reduce ecosystem-specific shortcuts",
        "Develop benchmark tasks for explainable runtime behavior mining, including human-evaluation protocols and downstream hunting success metrics"
      ],
      "architectural_improvement_recommendations": [
        "Add lightweight temporal encoders to model order/frequency of events within the 1-hop schema (e.g., per-entity event histograms or small Transformers over per-entity sequences)",
        "Introduce relation-specific gating or sparse mixtures-of-experts for heavy edge types (e.g., Action) to handle skew efficiently",
        "Use adaptive top-k pooling conditioned on graph size to maintain a consistent evidence budget across instances",
        "Incorporate attention-faithfulness constraints (e.g., deletion/insertion tests on edges) to align attention with causal importance",
        "Apply cost-aware loss that penalizes selecting indicators that are hard to verify or operationalize for analysts",
        "Leverage graph sampling and mini-batching strategies (e.g., neighbor sampling per relation) to handle extreme-degree nodes",
        "Add curriculum learning where models first train on balanced or synthetic hard cases before full-scale data"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "PyTorch",
        "PyTorch Geometric (PyG)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Graph construction CPU/RAM intensive; training GPU intensive. Dataset scale ~10M+ nodes and 54M+ edges with skewed edge counts (Action edges up to ~128k per instance). Small batch sizes; pipeline decouples offline graph construction from online training; artifacts include hardware/container details."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Sandbox-based OSS package execution analysis pipeline; offline behavior mining with online analysis for analyst-in-the-loop workflows",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Large volumes of noisy runtime events requiring prioritization",
        "Ecosystem-scale processing across multiple package ecosystems",
        "Imbalanced labels and potential ecosystem-specific shortcuts",
        "Host/GPU memory constraints due to graph size and skew",
        "Need for operationally interpretable outputs for analysts"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Industry-oriented framework for mining actionable runtime behavioral indicators from sandboxed executions of OSS to support supply chain security analysis",
      "Scalable cross-ecosystem pipeline transforming dynamic execution data into heterogeneous graphs for behavioral analysis",
      "HeteroGAT-Rank: attention-based heterogeneous graph learning system that prioritizes runtime behaviors for analyst-in-the-loop investigation under operational constraints",
      "Empirical evaluation and case studies showing that ranked behavioral indicators align with real-world vulnerability and attack trends and support practical threat hunting"
    ]
  },
  {
    "arxiv_id": "2601.07654v1",
    "title": "Towards Automating Blockchain Consensus Verification with IsabeLLM",
    "authors": "Elliot Jones; William Knottenbelt",
    "abstract": "Consensus protocols are crucial for a blockchain system as they are what allow agreement between the system's nodes in a potentially adversarial environment. For this reason, it is paramount to ensure their correct design and implementation to prevent such adversaries from carrying out malicious behaviour. Formal verification allows us to ensure the correctness of such protocols, but requires high levels of effort and expertise to carry out and thus is often omitted in the development process. In this paper, we present IsabeLLM, a tool that integrates the proof assistant Isabelle with a Large Language Model to assist and automate proofs. We demonstrate the effectiveness of IsabeLLM by using it to develop a novel model of Bitcoin's Proof of Work consensus protocol and verify its correctness. We use the DeepSeek R1 API for this demonstration and found that we were able to generate correct proofs for each of the non-trivial lemmas present in the verification.",
    "published_date": "2026-01-12",
    "pdf_link": "https://arxiv.org/pdf/2601.07654v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain Security",
      "subdomain": "Consensus Protocol Verification",
      "specific_problem": "Automated formal verification of Bitcoin Proof-of-Work consensus (common prefix property) using an Isabelle+LLM workflow",
      "attack_types": [
        "51% attack",
        "double-spend"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM-assisted theorem proving / Code generation",
        "specific": "DeepSeek R1 (via OpenRouter API)",
        "novel_contribution": "IsabeLLM: an integration of Isabelle with an LLM for iterative proof synthesis and repair, orchestrating LLM proposals with Isabelle’s Sledgehammer, automated error handling, and prompt management."
      }
    ],
    "learning_paradigm": [],
    "datasets": [
      {
        "name": "IsarStep",
        "type": "public",
        "domain": "proof_assistant_proofs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PISA",
        "type": "public",
        "domain": "proof_assistant_proofs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "LeanDojo",
        "type": "public",
        "domain": "proof_assistant_proofs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "GamePad",
        "type": "public",
        "domain": "proof_assistant_proofs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CoqGym",
        "type": "public",
        "domain": "proof_assistant_proofs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "number of successful proof attempts (out of 10)",
      "average iterations per successful attempt",
      "Lines of Proof (LoP)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Formal verification requires high effort and expertise and is often omitted in blockchain development.",
        "AI for formal verification of blockchain is sparse; prior work largely limited to extracting smart contract specs from natural language.",
        "Consensus protocol changes are hard to patch (hard forks); correctness-by-construction is needed, increasing the value of automation.",
        "Sledgehammer (as used via Isabelle2022/remote calls) can fail on intermediate steps and does not surface counterexamples (nitpick) to the LLM workflow.",
        "LLMs can hallucinate Isabelle facts/methods and produce syntax errors; current tooling requires handling these failure modes."
      ],
      "limitations": [
        "Used DeepSeek R1 via free OpenRouter API: slow latency and occasional empty outputs.",
        "LLM hallucinations and Isabelle syntax errors sometimes required manual intervention.",
        "Runs on Isabelle2022; misses improvements in later Isabelle/Sledgehammer versions (e.g., Isabelle2025 solved steps that failed on 2022).",
        "Remote Sledgehammer calls did not generate counterexamples (nitpick), wasting time on impossible proof steps.",
        "Observed looping behavior where the LLM fixates on a failing step without progressing.",
        "Success rates dropped for larger proofs (e.g., branch height, bounded check); intermediate steps were hard for Sledgehammer to discharge."
      ],
      "future_work": [
        "Make IsabeLLM compatible with newer Isabelle releases to benefit from improved Sledgehammer.",
        "Integrate counterexample generation (e.g., nitpick) in the remote workflow to prune impossible goals.",
        "Mitigate API latency/unreliability by using a higher-throughput API tier or running models locally.",
        "Generalize and evaluate beyond PoW: extend to other consensus protocols and more properties (e.g., chain quality)."
      ],
      "motivation": "Reduce the effort and expertise required to formally verify blockchain consensus protocols by leveraging LLMs to automate proof development in Isabelle, improving assurance where patching is costly or infeasible.",
      "potential_research_ideas": [
        "Benchmark IsabeLLM across multiple consensus protocols (PoS, BFT variants) and properties (common prefix, chain quality, liveness).",
        "Train or fine-tune an LLM on Isabelle/AFP/Isar corpora to reduce hallucinations and improve proof-step validity.",
        "Incorporate retrieval-augmented generation from AFP/theory context to ground proofs and suggest relevant lemmas.",
        "Use planning/reflective agents (multi-step decomposition, proof sketches) to reduce looping on hard steps.",
        "Reinforcement learning from proof feedback (success/failure signals from Isabelle/Sledgehammer) to adapt prompting and tactic choices.",
        "Create a standardized benchmark suite for blockchain protocol verification tasks in Isabelle to measure progress and reproducibility.",
        "Integrate symbolic search (e.g., best-first/beam over tactic sequences) guided by the LLM to complement Sledgehammer.",
        "Extend automation to verification of smart contracts and cross-chain bridge protocols with mechanized models."
      ],
      "architectural_improvement_recommendations": [
        "Upgrade compatibility to Isabelle2025+ and exploit improved Sledgehammer/Nitpick.",
        "Add nitpick counterexample detection before invoking ATPs; feed counterexamples back to the LLM.",
        "Implement step decomposition heuristics: automatically split failing steps into smaller subgoals for Sledgehammer.",
        "Cache Sledgehammer results and avoid re-solving identical subgoals across iterations.",
        "Dynamic prover/tactic portfolio selection based on goal features (metis, blast, simp, auto).",
        "Structured prompting with proof-state summaries and lemma inventories; enforce strict output formatting/validators for Isar syntax.",
        "Introduce loop breakers (e.g., edit-distance checks on successive proofs) and adaptive temperature/beam-size control.",
        "Local LLM inference or higher-throughput API with retries/backoff to reduce latency and empty responses.",
        "Add proof-repair passes (tactic substitution, lemma instantiation) before re-querying the LLM."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "Scala",
        "Python",
        "Isabelle",
        "Scala-Isabelle",
        "openai Python library"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "LLM API latency and occasional empty outputs via OpenRouter.",
        "LLM hallucinations (non-existent facts/methods) and Isabelle syntax errors.",
        "Proof tactic timeouts/hangs (e.g., metis, blast).",
        "Remote Sledgehammer lacks counterexample generation; wasted effort on impossible goals.",
        "Version compatibility (Isabelle2022) limits solver capabilities.",
        "LLM fixation loops on failing steps without global progress."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "IsabeLLM: a general-purpose interface between Isabelle and LLM APIs for assisting and automating proofs (architecture and implementation).",
      "A novel mechanised n-ary tree model of Bitcoin’s PoW consensus with correctness (common prefix) proven using IsabeLLM.",
      "Empirical analysis of IsabeLLM on 16 lemmas: success rates, average iterations, and pain points; demonstrates correct proofs for each non-trivial lemma using DeepSeek R1."
    ]
  },
  {
    "arxiv_id": "2601.12866v1",
    "title": "PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection",
    "authors": "Sharmila S P",
    "abstract": "The increasing prevalence of malicious Portable Document Format (PDF) files necessitates robust and comprehensive feature extraction techniques for effective detection and analysis. This work presents a unified framework that integrates graph-based, structural, and metadata-driven analysis to generate a rich feature representation for each PDF document. The system extracts text from PDF pages and constructs undirected graphs based on pairwise word relationships, enabling the computation of graph-theoretic features such as node count, edge density, and clustering coefficient. Simultaneously, the framework parses embedded metadata to quantify character distributions, entropy patterns, and inconsistencies across fields such as author, title, and producer. Temporal features are derived from creation and modification timestamps to capture behavioral signatures, while structural elements including, object streams, fonts, and embedded images, are quantified to reflect document complexity. Boolean flags for potentially malicious PDF constructs (e.g., JavaScript, launch actions) are also extracted. Together, these features form a high-dimensional vector representation (170 dimensions) that is well-suited for downstream tasks such as malware classification, anomaly detection, and forensic analysis. The proposed approach is scalable, extensible, and designed to support real-world PDF threat intelligence workflows.6",
    "published_date": "2026-01-19",
    "pdf_link": "https://arxiv.org/pdf/2601.12866v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Document Malware Detection",
      "specific_problem": "Static detection of malicious PDF documents via unified feature extraction (graph-based, structural, metadata, temporal, and flags)",
      "attack_types": [
        "PDF JavaScript execution (/JavaScript, /JS)",
        "OpenAction triggers (/OpenAction, /AA)",
        "Launch actions (/Launch)",
        "External links/URI abuse (/URI)",
        "Rich media embedding (/RichMedia)",
        "Form/external architecture abuse (/AcroForm, /XFA)",
        "Embedded files (/EmbeddedFile)",
        "Encryption/obfuscation misuse (/Encrypt)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Feature Engineering / Static Analysis",
        "specific": "Unified 170-dim PDF feature vector: word co-occurrence graphs (graph-theoretic metrics), metadata statistics/entropy, temporal deltas, structural counts, PDF keyword flags, image features",
        "novel_contribution": "Integration of graph-based, structural, metadata-driven, temporal, and image-derived features into a single high-dimensional representation for PDF malware detection"
      },
      {
        "type": "baseline",
        "category": "Ensemble Trees",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": "RBF-kernel SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feedforward Neural Network",
        "specific": "Multilayer Perceptron (ANN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Kolmogorov–Arnold Networks",
        "specific": "KAN (4-layer)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Proposed PDFInspect dataset (170-dim features)",
        "type": "proprietary",
        "domain": "pdf_documents",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "VirusTotal (malicious PDFs)",
        "type": "public",
        "domain": "pdf_documents",
        "link": "https://www.virustotal.com/",
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "VirusShare (malicious PDFs)",
        "type": "public",
        "domain": "pdf_documents",
        "link": "https://virusshare.com/",
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "MalwareBazaar (abuse.ch)",
        "type": "public",
        "domain": "pdf_documents",
        "link": "https://bazaar.abuse.ch/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "URLHaus (abuse.ch)",
        "type": "public",
        "domain": "pdf_documents",
        "link": "https://urlhaus.abuse.ch/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Canadian Institute for Cybersecurity (CIC) PDF data",
        "type": "public",
        "domain": "pdf_documents",
        "link": "https://www.unb.ca/cic/datasets/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Contagio PDF malware set",
        "type": "public",
        "domain": "pdf_documents",
        "link": "https://contagiodump.blogspot.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PDFRep [16]",
        "type": "public",
        "domain": "pdf_documents",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "Feature engineered metadata dataset [21]",
        "type": "public",
        "domain": "pdf_documents",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      },
      {
        "name": "Benign public documents (gov publications, academic papers, e-books, open-source archives)",
        "type": "proprietary",
        "domain": "pdf_documents",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Baseline 1 (Structural features only) + Random Forest",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "97.5",
        "baseline_result": "96.1"
      },
      {
        "method_name": "Baseline 2 (Metadata + JS flags) + Random Forest",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "97.5",
        "baseline_result": "91.2"
      },
      {
        "method_name": "Baseline 1 (Structural features only) + XGBoost",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "98.1",
        "baseline_result": "90.3"
      },
      {
        "method_name": "Baseline 2 (Metadata + JS flags) + XGBoost",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "98.1",
        "baseline_result": "92.8"
      },
      {
        "method_name": "Baseline 1 (Structural features only) + SVM (RBF)",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "97.9",
        "baseline_result": "95.3"
      },
      {
        "method_name": "Baseline 2 (Metadata + JS flags) + SVM (RBF)",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "97.9",
        "baseline_result": "97.1"
      },
      {
        "method_name": "Baseline 1 (Structural features only) + Feedforward ANN",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "97.8",
        "baseline_result": "95.5"
      },
      {
        "method_name": "Baseline 2 (Metadata + JS flags) + Feedforward ANN",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "97.8",
        "baseline_result": "91.9"
      },
      {
        "method_name": "Baseline 1 (Structural features only) + KAN",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "99.3",
        "baseline_result": "96.4"
      },
      {
        "method_name": "Baseline 2 (Metadata + JS flags) + KAN",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "99.3",
        "baseline_result": "96.6"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-Score",
      "AUC-ROC",
      "PR Curve",
      "Cohen’s Kappa"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does integrating graph-theoretic text features with metadata, temporal, structural, and flag-based features improve malicious PDF detection over structural or metadata-only baselines?",
        "Can a unified, extensible feature extraction pipeline support multiple downstream tasks (classification, anomaly detection, forensics) efficiently at scale?"
      ],
      "gaps_identified": [
        "Traditional approaches often analyze content extraction, metadata, and low-level structure in isolation, missing multifaceted PDF threats.",
        "ML models in prior work often treat features independently, failing to capture deeper structural and relational patterns in text or objects.",
        "Overlooked latent structural information in document content, such as relationships between tokens and sequences of actions encoded in object references."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "PDFs are frequently abused via JavaScript, launch actions, and metadata manipulation; existing static analyses in isolation are insufficient. A unified, interpretable, and scalable feature extraction approach is needed to capture multifaceted malicious behaviors.",
      "potential_research_ideas": [
        "Integrate dynamic analysis signals (e.g., JavaScript execution traces, sandbox behaviors) with the static feature vector for hybrid detection.",
        "Apply graph neural networks directly to word co-occurrence or PDF object graphs to learn richer relational features end-to-end.",
        "Self-supervised pretraining on large corpora of PDFs to learn document structure embeddings, then fine-tune for malware detection.",
        "Leverage LLMs or transformer-based models to encode semantic cues from extracted text and metadata fields alongside static features.",
        "Online/continual learning to handle concept drift in evolving PDF malware campaigns.",
        "Automated explainability (e.g., SHAP on feature blocks, subgraph explanations) tailored to PDF structures for analyst trust.",
        "Adversarial robustness evaluation and defenses (feature smoothing, adversarial training) against obfuscation strategies.",
        "Family-level multiclass classification and open-set recognition to flag novel or zero-day samples."
      ],
      "architectural_improvement_recommendations": [
        "Replace aggregated graph statistics with learned representations via GNNs on per-page co-occurrence graphs and/or PDF object-reference graphs.",
        "Fuse heterogeneous modalities with a multimodal network: tabular static features + text encoder + graph encoder, trained jointly.",
        "Introduce feature selection or sparsity-inducing regularization to reduce redundancy in the 170-dim vector and improve generalization.",
        "Calibrate models and add conformal prediction for reliable uncertainty estimates in deployment.",
        "Implement robust preprocessing against text extraction failures and encrypted/embedded streams (fallback OCR, deobfuscation)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Python 3.10",
        "PyMuPDF",
        "PyPDF2",
        "NetworkX",
        "scikit-learn",
        "XGBoost",
        "pandas",
        "NumPy"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Intel Core i7 (11th Gen), 32 GB RAM, Ubuntu 22.04; ~0.1 s feature extraction per PDF; end-to-end processing under 1 s per PDF; 5-fold CV; KAN 4 layers."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "Feature extraction ~0.1 s per PDF; full pipeline under 1 s per PDF",
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Unified feature extraction framework combining graph-based text features, metadata/statistical analysis, temporal signals, structural counts, PDF flags, and image features.",
      "Introduces a 170-dimensional feature vector per PDF suitable for classification, anomaly detection, and forensics.",
      "Curates a large dataset of 262,113 PDFs (128,876 malicious; 133,237 benign) from multiple real-world sources.",
      "Demonstrates efficiency and scalability: ~0.1 s feature extraction and under 1 s end-to-end processing per PDF on CPU.",
      "Empirical evaluation across multiple supervised models (RF, XGBoost, SVM, MLP, KAN) showing consistent gains over two baseline feature sets.",
      "Reports best performance with KAN: “accuracy of 99.3%, an F1-score of 99.3%, and an AUC of 0.993.”"
    ]
  },
  {
    "arxiv_id": "2601.08725v1",
    "title": "Malware Detection based on API Calls: A Reproducibility Study",
    "authors": "Juhani Merilehto",
    "abstract": "This study independently reproduces the malware detection methodology presented by Felli cious et al. [7], which employs order-invariant API call frequency analysis using Random Forest classification. We utilized the original public dataset (250,533 training samples, 83,511 test samples) and replicated four model variants: Unigram, Bigram, Trigram, and Combined n gram approaches. Our reproduction successfully validated all key findings, achieving F1-scores that exceeded the original results by 0.99% to 2.57% across all models at the optimal API call length of 2,500. The Unigram model achieved F1=0.8717 (original: 0.8631), confirming its ef fectiveness as a lightweight malware detector. Across three independent experimental runs with different random seeds, we observed remarkably consistent results with standard deviations be low 0.5%, demonstrating high reproducibility. This study validates the robustness and scientific rigor of the original methodology while confirming the practical viability of frequency-based API call analysis for malware detection.",
    "published_date": "2026-01-13",
    "pdf_link": "https://arxiv.org/pdf/2601.08725v1",
    "paper_types": [
      "empirical_analysis",
      "reproducibility"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection (Dynamic Analysis)",
      "specific_problem": "Windows malware detection using order-invariant API call frequency features",
      "attack_types": [
        "Windows malware",
        "Evasion via API call reordering"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Random Forest",
        "specific": "scikit-learn RandomForestClassifier",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Feature Engineering",
        "specific": "Unigram API call frequency (bag-of-words over 59 ntdll.dll APIs)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Feature Engineering",
        "specific": "Bigram API call frequency",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Feature Engineering",
        "specific": "Trigram API call frequency",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Feature Engineering",
        "specific": "Concatenated Unigram+Bigram+Trigram (Combined)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "API Traces Malware Detection Dataset (Zenodo DOI: 10.5281/zenodo.11079764)",
        "type": "public",
        "domain": "api_call_traces",
        "link": "https://doi.org/10.5281/zenodo.11079764",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Drebin (Android malware)",
        "type": "public",
        "domain": "android_apps",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "EMBER (Windows PE dataset)",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusTotal submissions (referenced)",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "available_on_request"
      }
    ],
    "baselines": [
      {
        "method_name": "Original Unigram (Fellicious et al.)",
        "paper_reference": "Fellicious et al. [7]",
        "metric": "F1-score at 2,500 API calls",
        "their_result": "0.8717",
        "baseline_result": "0.8631"
      },
      {
        "method_name": "Original Bigram (Fellicious et al.)",
        "paper_reference": "Fellicious et al. [7]",
        "metric": "F1-score at 2,500 API calls",
        "their_result": "0.8660",
        "baseline_result": "0.8546"
      },
      {
        "method_name": "Original Trigram (Fellicious et al.)",
        "paper_reference": "Fellicious et al. [7]",
        "metric": "F1-score at 2,500 API calls",
        "their_result": "0.7064",
        "baseline_result": "0.6887"
      },
      {
        "method_name": "Original Combined (Fellicious et al.)",
        "paper_reference": "Fellicious et al. [7]",
        "metric": "F1-score at 2,500 API calls",
        "their_result": "0.8529",
        "baseline_result": "0.8325"
      }
    ],
    "performance_metrics_used": [
      "F1-score",
      "Accuracy",
      "Precision",
      "Recall",
      "ROC-AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Validate the core finding that order-invariant API call frequency analysis achieves high malware detection accuracy (F1>0.85 for optimal models)",
        "Confirm the optimal configuration identified in the original work: 2,500 API calls as the threshold balancing detection accuracy and early detection capability",
        "Verify the performance hierarchy among n-gram models (Unigram, Bigram, Trigram, Combined)",
        "Assess the reproducibility of results across multiple independent experimental runs",
        "Provide an independent baseline for future research building upon this methodology"
      ],
      "gaps_identified": [
        "Reproducibility crisis in ML and cybersecurity necessitates independent validation of results",
        "Large-scale public datasets with raw API call traces are rare",
        "Sequence-based API analysis methods can be vulnerable to evasion via API call reordering"
      ],
      "limitations": [
        "Evaluation limited to order-invariant frequency features (unigram/bigram/trigram) replicated from the original methodology",
        "Only RandomForestClassifier with default hyperparameters was used",
        "Results may vary due to software/hardware environment differences and dataset sampling differences",
        "Severe class imbalance (~97% malware, 3% benign) constrains evaluation dynamics",
        "Did not incorporate parameter-augmented API features (arguments/return values) discussed in related work"
      ],
      "future_work": [],
      "motivation": "Independently reproduce and validate Fellicious et al.'s API-call frequency-based malware detection to assess robustness and reproducibility, given the importance of reproducible results in security-critical ML.",
      "potential_research_ideas": [
        "Adversarial robustness evaluation against API reordering, insertion, and mimicry attacks on frequency-based detectors",
        "Augment frequency features with API arguments/return values and assess trade-offs in dimensionality and overfitting",
        "Systematic hyperparameter optimization and model comparison (e.g., Gradient Boosted Trees, LightGBM, XGBoost) versus Random Forest",
        "Calibrated thresholding and cost-sensitive learning to handle extreme class imbalance and deployment risk profiles",
        "Online/streaming detection that updates decisions as API calls arrive, optimizing for early detection",
        "Cross-dataset and temporal generalization studies (train/test on different collection periods or malware families)",
        "Feature hashing or dimensionality reduction to compress bigram/trigram spaces while preserving performance",
        "Model ensembling across n-gram granularities with learned weighting to surpass simple concatenation",
        "Hardware-aware implementations for endpoint deployment, profiling CPU and memory footprints with different feature cutoffs",
        "Explainability techniques for frequency-based models (e.g., SHAP on feature importances) to aid analyst trust"
      ],
      "architectural_improvement_recommendations": [
        "Replace or complement Random Forest with gradient-boosted decision trees (LightGBM/XGBoost) and tune hyperparameters",
        "Introduce class-imbalance strategies (class weights, focal loss via compatible models, or balanced subsampling)",
        "Use learned feature weighting across unigram/bigram/trigram instead of raw concatenation (e.g., stacking or attention over feature groups)",
        "Apply feature hashing to n-grams to control sparsity and memory while enabling higher-order n-grams",
        "Incorporate API argument semantics via lightweight embedding or categorical encoding with regularization",
        "Add calibration (Platt scaling/Isotonic regression) for reliable decision thresholds in production"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "scikit-learn"
      ],
      "reproducibility_score": "high",
      "computational_requirements": "Dataset size 572 GB (uncompressed API traces); models trained across 4 variants × 14 lengths × 3 seeds; RandomForestClassifier with default settings."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Adversarial setting where disclosure of detection methods may enable evasion",
        "Severe class imbalance (~97% malware, 3% benign) impacting operating thresholds",
        "Large data volume (572 GB) for storage and processing of API traces"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Independent validation of the original API-call frequency-based malware detection results with 1–2.5% performance improvements",
      "Reproducibility assessment via three runs with different random seeds and low variance (<0.5% std dev)",
      "Scientific confirmation of the robustness and practicality of order-invariant frequency-based detection",
      "Transparent reporting of methodology, deviations, and detailed comparisons to facilitate future reproductions",
      "Provision of an independent baseline for subsequent research on API-call-based malware detection"
    ]
  },
  {
    "arxiv_id": "2601.15697v1",
    "title": "Balancing Security and Privacy: The Pivotal Role of AI in Modern Healthcare Systems",
    "authors": "Binu V P; Deepthy K Bhaskar; Minimol B",
    "abstract": "As digital threats continue to grow, organizations must find ways to enhance security while protecting user privacy. This paper explores how artificial intelligence (AI) plays a crucial role in achieving this balance. AI technologies can improve security by detecting threats, monitoring systems, and automating responses. However, using AI also raises privacy concerns that need careful consideration.We examine real-world examples from the healthcare sector to illustrate how organizations can implement AI solutions that strengthen security without compromising patient privacy. Additionally, we discuss the importance of creating transparent AI systems and adhering to privacy regulations.Ultimately, this paper provides insights and recommendations for integrating AI into healthcare security practices, helping organizations navigate the challenges of modern management while keeping patient data safe.",
    "published_date": "2026-01-22",
    "pdf_link": "https://arxiv.org/pdf/2601.15697v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "survey"
    ],
    "security_domain": {
      "primary": "Healthcare Security",
      "subdomain": "Privacy-Preserving Machine Learning",
      "specific_problem": "Privacy-preserving diabetes prediction using federated learning with differential privacy and encrypted model updates",
      "attack_types": [
        "cyber-attacks",
        "data breaches",
        "unauthorized access",
        "fraud (healthcare billing/insurance)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "Simulated cross-silo FL with 3 clients; weighted aggregation by F1-score and data size",
        "novel_contribution": "Combines FL with encrypted parameter sharing and output-level differential privacy; aggregation weighted by client F1 and data size"
      },
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost classifier",
        "novel_contribution": "Used as the client-side model within a privacy-preserving FL pipeline for healthcare tabular data"
      },
      {
        "type": "primary",
        "category": "Differential Privacy",
        "specific": "Output perturbation (noise added to predictions)",
        "novel_contribution": "Applies DP at prediction time to protect individual patients while maintaining performance (~2% accuracy drop reported)"
      },
      {
        "type": "primary",
        "category": "Symmetric Encryption",
        "specific": "Fernet",
        "novel_contribution": "Encrypts client model parameters before transmission to the aggregator to protect updates in transit"
      },
      {
        "type": "baseline",
        "category": "Data Resampling",
        "specific": "SMOTE (Synthetic Minority Over-sampling Technique)",
        "novel_contribution": "Used to handle class imbalance on each client locally"
      },
      {
        "type": "baseline",
        "category": "Non-private centralized model",
        "specific": null,
        "novel_contribution": "Used as a comparative baseline (\"Non-private Model\")"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Federated Learning"
    ],
    "datasets": [
      {
        "name": "Pima Indians Diabetes Dataset",
        "type": "public",
        "domain": "healthcare_tabular",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Non-private Model",
        "paper_reference": null,
        "metric": "Accuracy, F1 Score",
        "their_result": "Global federated model: Accuracy 0.8312 (reported also as ~84%), F1 0.82",
        "baseline_result": "Non-private Model: Accuracy 0.71, F1 0.62"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1 Score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Regulations for AI are still developing, even in advanced regions.",
        "There is a need for better standards for testing and validating AI technologies to ensure they are safe and effective.",
        "Using AI raises concerns about privacy, including how data is used and the transparency of AI decisions."
      ],
      "limitations": [],
      "future_work": [
        "Utilize federated learning to train on decentralized healthcare data",
        "Adopt advanced encryption such as homomorphic encryption for processing on encrypted data",
        "Develop and adopt explainable AI (XAI) for better understanding of AI decisions",
        "Explore blockchain to enhance data security and integrity",
        "Train healthcare staff to use AI tools effectively"
      ],
      "motivation": "Balance improved security through AI with stringent privacy protection for sensitive patient data in modern healthcare systems.",
      "potential_research_ideas": [
        "Evaluate end-to-end privacy budgets by moving from output perturbation to DP during training (e.g., DP-SGD or DP-enabled boosting) and compare utility-privacy trade-offs in healthcare tabular data.",
        "Design and test secure aggregation protocols (e.g., MPC-based) for federated XGBoost to remove the need for decrypting updates at the server.",
        "Study heterogeneity and non-IID effects in cross-silo healthcare FL with hospital-specific distributions; develop personalization or domain adaptation methods.",
        "Integrate membership inference and model inversion attack evaluations to quantify actual privacy leakage in the proposed pipeline.",
        "Benchmark different tree-based learners (XGBoost, LightGBM, CatBoost) and tabular DL models under identical FL+DP+encryption settings.",
        "Prototype homomorphic encryption-based inference for tree ensembles and quantify latency/accuracy trade-offs for clinical settings."
      ],
      "architectural_improvement_recommendations": [
        "Apply differential privacy during training with gradient clipping and per-round noise (DP-SGD or DP boosting) rather than only at prediction time.",
        "Adopt secure aggregation (e.g., Bonawitz-style) so the server never sees individual client updates in the clear.",
        "Use formal privacy accounting to report (epsilon, delta) and clipping norms; calibrate noise to target privacy budgets.",
        "Replace ad-hoc F1/data-size aggregation with standard FedAvg or performance-aware aggregation validated against non-IID splits.",
        "Harden the pipeline against poisoning/evasion via robust aggregation (e.g., median, trimmed mean) and anomaly detection on updates.",
        "Incorporate explainability for tabular models (e.g., SHAP) and log explanations for auditability in clinical workflows."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Regulatory and compliance requirements (HIPAA, GDPR, national policies like DISHA/NDHB)",
        "Need for explainable AI to support clinical decision-making",
        "Security management for data in transit and at rest (encryption overheads)",
        "Training and upskilling healthcare staff to use AI tools",
        "Secure data sharing and interoperability across institutions"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Survey/positioning of AI’s role in balancing security and privacy in modern healthcare, including regulatory and ethical context.",
      "Case study implementing a privacy-preserving pipeline combining federated learning, encryption (Fernet), and differential privacy on the Pima Indians Diabetes Dataset.",
      "Demonstration that differential privacy at prediction slightly reduces accuracy (~2%) while maintaining strong performance.",
      "Empirical results showing the global federated model achieves Accuracy ≈0.8312 (≈84%) and F1 ≈0.82, outperforming a non-private baseline (Accuracy 0.71, F1 0.62)."
    ]
  },
  {
    "arxiv_id": "2601.16463v1",
    "title": "Cutting the Gordian Knot: Detecting Malicious PyPI Packages via a Knowledge-Mining Framework",
    "authors": "Wenbo Guo; Chengwei Liu; Ming Kang; Yiran Zhang; Jiahui Wu; Zhengzi Xu; Vinay Sachidananda; Yang Liu",
    "abstract": "The Python Package Index (PyPI) has become a target for malicious actors, yet existing detection tools generate false positive rates of 15-30%, incorrectly flagging one-third of legitimate packages as malicious. This problem arises because current tools rely on simple syntactic rules rather than semantic understanding, failing to distinguish between identical API calls serving legitimate versus malicious purposes. To address this challenge, we propose PyGuard, a knowledge-driven framework that converts detection failures into useful behavioral knowledge by extracting patterns from existing tools' false positives and negatives. Our method utilizes hierarchical pattern mining to identify behavioral sequences that distinguish malicious from benign code, employs Large Language Models to create semantic abstractions beyond syntactic variations, and combines this knowledge into a detection system that integrates exact pattern matching with contextual reasoning. PyGuard achieves 99.50% accuracy with only 2 false positives versus 1,927-2,117 in existing tools, maintains 98.28% accuracy on obfuscated code, and identified 219 previously unknown malicious packages in real-world deployment. The behavioral patterns show cross-ecosystem applicability with 98.07% accuracy on NPM packages, demonstrating that semantic understanding enables knowledge transfer across programming languages.",
    "published_date": "2026-01-23",
    "pdf_link": "https://arxiv.org/pdf/2601.16463v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Supply Chain Security",
      "subdomain": "Open-Source Package Ecosystem Malware Detection",
      "specific_problem": "Detecting malicious PyPI packages with low false positives using semantic behavior pattern mining and LLM-based contextual reasoning; transfer to NPM",
      "attack_types": [
        "typosquatting",
        "dependency_confusion",
        "code_injection",
        "data_exfiltration",
        "command_and_control",
        "obfuscation/evasion"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Sequential Pattern Mining",
        "specific": "PrefixSpan",
        "novel_contribution": "Hierarchical mining with deterministic (exclusive) and justifiable (biased) patterns using progressively decreasing support and a greedy merge to reduce redundancy"
      },
      {
        "type": "primary",
        "category": "LLM/RAG",
        "specific": "Retrieval-Augmented Generation with code-focused LLMs (model unspecified)",
        "novel_contribution": "LLMs generate semantic behavioral abstractions (“cards”), resolve obfuscation, and support context-aware reasoning via dual-layer knowledge (pattern knowledge + case knowledge)"
      },
      {
        "type": "primary",
        "category": "Vector Retrieval/Embeddings",
        "specific": "Vector store similarity retrieval",
        "novel_contribution": "Similarity-based retrieval over semantic behavior summaries to provide contextual evidence for classification"
      },
      {
        "type": "primary",
        "category": "Program Analysis",
        "specific": "Context extraction with LLM assistance",
        "novel_contribution": "LLM-guided extraction of data/control dependencies to build action sequences mapped to a behavioral taxonomy"
      },
      {
        "type": "baseline",
        "category": "Static Rule-based Analysis",
        "specific": "Bandit4Mal, GuardDog, OSSGadget, PyPI Malware Checks",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Dynamic Analysis",
        "specific": "DySec",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Traditional ML",
        "specific": "PypiGuard (metadata + API behaviors)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Knowledge-driven/Rule-based",
      "LLM-assisted"
    ],
    "datasets": [
      {
        "name": "PyPI Study Dataset (18,137 packages; ~50% benign / ~50% malicious)",
        "type": "private",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Suspicious Code Snippets and Behavioral Taxonomy (2,283 unique malicious snippets; 327 behavior categories)",
        "type": "private",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Obfuscated PyPI Variants (for robustness evaluation)",
        "type": "synthetic",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "NPM Cross-ecosystem Test Set",
        "type": "private",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Real-world Deployment Findings (219 newly identified malicious PyPI packages)",
        "type": "private",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Bandit4Mal",
        "paper_reference": null,
        "metric": "false positives (count)",
        "their_result": "“only 2 false positives”",
        "baseline_result": null
      },
      {
        "method_name": "GuardDog",
        "paper_reference": null,
        "metric": "false positives (count)",
        "their_result": "“only 2 false positives”",
        "baseline_result": null
      },
      {
        "method_name": "OSSGadget",
        "paper_reference": null,
        "metric": "false positives (count)",
        "their_result": "“only 2 false positives”",
        "baseline_result": null
      },
      {
        "method_name": "PyPI Malware Checks",
        "paper_reference": null,
        "metric": "false positives (count)",
        "their_result": "“only 2 false positives”",
        "baseline_result": null
      },
      {
        "method_name": "Existing PyPI detection systems (aggregate)",
        "paper_reference": null,
        "metric": "false positive rate",
        "their_result": "“only 2 false positives”",
        "baseline_result": "“false positive rates of 15-30%” and “1,927–2,117” FPs (range across existing tools)"
      },
      {
        "method_name": "DySec (dynamic analysis)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "“99.50% accuracy” (PyGuard)",
        "baseline_result": "“95.99% accuracy”"
      },
      {
        "method_name": "PypiGuard (ML method)",
        "paper_reference": null,
        "metric": "accuracy",
        "their_result": "“99.50% accuracy” (PyGuard)",
        "baseline_result": "“98.43% accuracy”"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "false positives (count)",
      "false positive rate",
      "accuracy under obfuscation",
      "cross-ecosystem accuracy"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "High false positive rates (15–30%) from reliance on coarse syntactic rules",
        "Inability to distinguish identical API sequences serving benign vs. malicious intents",
        "Lack of semantic understanding and contextual reasoning in existing tools",
        "Evasion via obfuscation (alias imports, dynamic imports, nested calls)",
        "Limited cross-ecosystem generalization across programming languages"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Reduce prohibitively high false positives in PyPI malicious package detection by converting detection failures into semantic behavioral knowledge using LLMs and hierarchical pattern mining.",
      "potential_research_ideas": [
        "Incorporate dynamic runtime traces (sandboxed execution) to augment semantic patterns and resolve ambiguous justifiable patterns",
        "Develop a language-agnostic intermediate representation and evaluate transfer beyond Python/JavaScript (e.g., Rust, Go) for broader ecosystem coverage",
        "Active learning loop where human analyst feedback on borderline cases updates the taxonomy and pattern store",
        "Adversarial evaluation and training against targeted evasion (e.g., semantics-preserving transformations) to harden the RAG reasoning",
        "Integrate package-level provenance/signing (SBOM, Sigstore) with behavior patterns for supply-chain risk scoring",
        "Use graph neural networks over AST/CFG/PDG to learn embeddings that better capture control/data-flow semantics feeding the retrieval module",
        "Automate continuous pattern maintenance to handle concept drift as attacker TTPs evolve"
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment PrefixSpan with discriminative sequential pattern mining (e.g., CM-SPAM, cSPADE) and classifier-guided pattern selection",
        "Fine-tune a code LLM on the curated behavior cards/taxonomy to reduce reliance on prompting and improve deobfuscation fidelity",
        "Adopt a language-agnostic IR (e.g., code property graphs) and apply GNNs for robust action-sequence extraction",
        "Calibrate decision thresholds with conformal prediction to control false positives with statistical guarantees",
        "Implement robust semantic hashing of patterns to deduplicate and compress the knowledge base for scalable deployment",
        "Add provenance-aware features (maintainer history, release anomalies) as auxiliary signals in the RAG decision"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Three-stage, knowledge-driven framework (study of detection failures, LLM-based knowledge extraction, RAG-enhanced detection)",
      "Hierarchical behavior pattern mining yielding 304 discriminative behavioral patterns",
      "LLM-driven semantic abstraction to construct a behavioral taxonomy (327 categories) and resolve obfuscation",
      "RAG-enhanced detection achieving “99.50% accuracy with only 2 false positives versus 1,927–2,117 in existing tools”",
      "Robustness and generalization: “98.28% accuracy on obfuscated code” and “98.07% accuracy on NPM packages”",
      "Real-world impact: “identified 219 previously unknown malicious packages in real-world deployment”"
    ]
  },
  {
    "arxiv_id": "2601.13197v1",
    "title": "Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification",
    "authors": "Aravind B; Anirud R. S.; Sai Surya Teja N; Bala Subrahmanya Sriranga Navaneeth A; Karthika R; Mohankumar N",
    "abstract": "Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than oth- ers, leading to biased model performance. Class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation is ad- dressed in this paper. Our approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. For the minority classes that have smaller samples, synthetic samples were generated and merged with the original dataset. The augmented training data enables an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. These results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.",
    "published_date": "2026-01-19",
    "pdf_link": "https://arxiv.org/pdf/2601.13197v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Addressing class imbalance for DoS/DDoS attack classification via diffusion-based tabular data augmentation on CIC-IDS2017",
      "attack_types": [
        "DoS Hulk",
        "DDoS",
        "DoS GoldenEye",
        "DoS Slowloris",
        "DoS SlowHttpTest"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Diffusion Model",
        "specific": "TabDDPM (Tabular Denoising Diffusion Probabilistic Model)",
        "novel_contribution": "Per-class diffusion models for minority classes; targeted class-conditional sampling to rebalance classes; domain-specific validation focusing on class-wise recall/F1 in intrusion detection"
      },
      {
        "type": "primary",
        "category": "Feedforward Neural Network (MLP/DNN)",
        "specific": "4-layer ANN (256→128→64→32) with ReLU, BatchNorm, Dropout 0.3; Adam optimizer; Cross-Entropy Loss",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Oversampling",
        "specific": "SMOTE",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "CIC-IDS2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICDDoS2019",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CTU",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "USTC-TFC",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ISAC",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UJS-IDS2024",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "No Augmentation (Baseline ANN)",
        "paper_reference": null,
        "metric": "Macro F1-score",
        "their_result": "0.989 (Diffusion-based augmentation)",
        "baseline_result": "0.86 (No augmentation)"
      },
      {
        "method_name": "SMOTE Oversampling + ANN",
        "paper_reference": null,
        "metric": "Macro F1-score",
        "their_result": "0.989 (Diffusion-based augmentation)",
        "baseline_result": "0.89 (SMOTE)"
      },
      {
        "method_name": "No Augmentation (Baseline ANN)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "0.9889 (Diffusion-based augmentation)",
        "baseline_result": "0.9547 (No augmentation)"
      },
      {
        "method_name": "SMOTE Oversampling + ANN",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "0.9889 (Diffusion-based augmentation)",
        "baseline_result": "0.9658 (SMOTE)"
      },
      {
        "method_name": "Class-wise F1 (DoS GoldenEye)",
        "paper_reference": null,
        "metric": "F1-score (class-wise)",
        "their_result": "0.9892 (Diffusion-based augmentation)",
        "baseline_result": "0.453 (No augmentation); 0.780 (SMOTE)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision (macro)",
      "Recall (macro)",
      "F1-score (macro)",
      "Confusion Matrix",
      "t-SNE visualization"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can per-class diffusion-based tabular data augmentation mitigate class imbalance and improve minority-class detection (recall/F1) for DoS/DDoS on CIC-IDS2017?",
        "How does diffusion-based augmentation compare to SMOTE and no augmentation in terms of classification performance and training time?",
        "Does diffusion-based generation produce diverse, privacy-preserving samples that improve generalization without overlap with real samples?"
      ],
      "gaps_identified": [
        "SMOTE’s linear interpolation can create unrealistic feature combinations in high-dimensional network traffic and limit diversity.",
        "GANs suffer from mode collapse and training instability for rare attack pattern generation.",
        "VAEs can produce overly smooth samples that miss sharp distribution boundaries between attack types.",
        "Persistent challenges in the field include outdated datasets and lack of real-time adaptability (from surveyed literature)."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Severe class imbalance in network intrusion datasets biases classifiers against minority DoS/DDoS attacks; prior augmentation approaches (SMOTE, GANs, VAEs) have limitations. Diffusion models offer stable training and fine-grained control, motivating their use for tabular cybersecurity data augmentation.",
      "potential_research_ideas": [
        "Extend to streaming/online intrusion detection with incremental or continual diffusion-based augmentation.",
        "Cross-dataset validation and domain adaptation to evaluate generalization across multiple IDS corpora (e.g., CICDDoS2019, CTU).",
        "Investigate privacy formally (e.g., membership inference, nearest-neighbor distance tests) for diffusion-generated samples in IDS data.",
        "Adversarial robustness: evaluate whether diffusion-augmented training improves resilience to evasion attacks; combine with adversarial training.",
        "Conditional or guided diffusion using protocol/flow metadata (e.g., ports, flags) to precisely target underrepresented subtypes.",
        "Active learning + diffusion augmentation loop to selectively synthesize samples for uncertain regions of the decision boundary."
      ],
      "architectural_improvement_recommendations": [
        "Replace per-class separate TabDDPMs with a single conditional diffusion model (class embeddings) to share statistical strength and reduce training cost.",
        "Explore tabular transformers or MLP-Mixers as the denoising network for better mixed-type feature modeling.",
        "Test alternative noise schedules (cosine, sigmoid), and classifier-free guidance to control sample fidelity/diversity trade-offs.",
        "Incorporate calibration-aware training (e.g., focal loss, class-balanced loss) in the ANN to complement augmentation.",
        "Add feature-constraint regularizers to ensure protocol-consistent synthetic samples (e.g., maintain feasible ranges, invariants).",
        "Pipeline optimization for deployment: quantization/pruning of ANN and cached synthetic pools for periodic refresh."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": "Training conducted on NVIDIA RTX 3050 (4GB VRAM), CUDA 11.7; seeds fixed (42). Training times: baseline 38m52.8s, SMOTE 9m10.2s, diffusion-based 17m10.5s. Diffusion: 500 steps (β from 1e-4 to 0.02), 50 epochs; ANN: 20 epochs, batch size 128."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Diffusion augmentation has higher training time than SMOTE (≈1.9× slower).",
        "GPU recommended/used for feasible training (RTX 3050)."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Demonstrates diffusion-based tabular data augmentation (TabDDPM) effectively addresses class imbalance for DoS/DDoS classification.",
      "Introduces per-class diffusion models and targeted sampling to generate high-fidelity minority-class samples.",
      "Domain-specific validation with class-wise metrics showing near-perfect recall/F1 for minority attacks on CIC-IDS2017.",
      "Computational efficiency analysis comparing baseline, SMOTE, and diffusion augmentation training times.",
      "Detailed training pipeline and hyperparameters enabling reproducibility (e.g., seeds, noise schedule, epochs)."
    ]
  },
  {
    "arxiv_id": "2601.06241v1",
    "title": "Agentic AI Microservice Framework for Deepfake and Document Fraud Detection in KYC Pipelines",
    "authors": "Chandra Sekhar Kubam",
    "abstract": "The rapid proliferation of synthetic media, presentation attacks, and document forgeries has created significant vulnerabilities in Know Your Customer (KYC) workflows across financial services, telecommunications, and digital-identity ecosystems. Traditional monolithic KYC systems lack the scalability and agility required to counter adaptive fraud. This paper proposes an Agentic AI Microservice Framework that integrates modular vision models, liveness assessment, deepfake detection, OCR-based document forensics, multimodal identity linking, and a policy driven risk engine. The system leverages autonomous micro-agents for task decomposition, pipeline orchestration, dynamic retries, and human-in-the-loop escalation. Experimental evaluations demonstrate improved detection accuracy, reduced latency, and enhanced resilience against adversarial inputs. The framework offers a scalable blueprint for regulated industries seeking robust, real-time, and privacy-preserving KYC verification.",
    "published_date": "2026-01-09",
    "pdf_link": "https://arxiv.org/pdf/2601.06241v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Identity and Access Management",
      "subdomain": "KYC/Identity Proofing",
      "specific_problem": "Agentic microservice framework for liveness, deepfake, and document fraud detection with multimodal identity linking and risk scoring in KYC pipelines",
      "attack_types": [
        "Presentation attacks",
        "Deepfakes",
        "Face swaps",
        "Replay attacks",
        "Synthetic/AI-generated identity documents",
        "Document forgery/tampering"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": null,
        "novel_contribution": "Used in the fraud-risk scoring engine as part of a policy-driven, agent-orchestrated pipeline"
      },
      {
        "type": "primary",
        "category": "CNN",
        "specific": null,
        "novel_contribution": "Deepfake classifiers for facial forgery detection integrated as modular microservices"
      },
      {
        "type": "primary",
        "category": "Temporal modeling",
        "specific": null,
        "novel_contribution": "Passive liveness via temporal inconsistency and eye-blink modeling for presentation attack detection"
      },
      {
        "type": "primary",
        "category": "OCR",
        "specific": null,
        "novel_contribution": "Document OCR with template verification and forensic artifact checks for identity document authenticity"
      },
      {
        "type": "primary",
        "category": "Anomaly Detection",
        "specific": null,
        "novel_contribution": "Anomaly escalation via agentic controller to trigger human-in-the-loop review"
      },
      {
        "type": "primary",
        "category": "Metric Learning/Embeddings",
        "specific": null,
        "novel_contribution": "Face embeddings and multimodal consistency checks in the identity linking engine"
      },
      {
        "type": "primary",
        "category": "Rule-based/Ensemble",
        "specific": null,
        "novel_contribution": "Policy-driven risk engine combining rules with model outputs; agent selects model variants for latency/accuracy trade-offs"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Rule-based",
      "Multimodal fusion",
      "Hybrid"
    ],
    "datasets": [
      {
        "name": "Selfie and Deepfake KYC Dataset (unnamed)",
        "type": "private",
        "domain": "face_images_video",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "ID Document Authentic/Synthetic Dataset (unnamed)",
        "type": "private",
        "domain": "identity_documents",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Equal Error Rate (EER)",
      "False Positive Rate (FPR)",
      "Latency",
      "OCR extraction accuracy",
      "Template deviation score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can an agentic AI microservice architecture improve detection accuracy, latency, and resilience for KYC fraud detection compared to monolithic systems?",
        "How can multimodal identity artifacts (selfies/videos, ID documents, metadata) be linked to yield a unified, policy-driven risk score in real time?",
        "How should autonomous agents orchestrate task decomposition, model selection, retries, and human-in-the-loop escalations in dynamic KYC pipelines?"
      ],
      "gaps_identified": [
        "Monolithic KYC systems lack modularity and agility to integrate new fraud detection capabilities quickly",
        "Static rule-based or single-model approaches struggle against adaptive deepfakes and synthetic documents",
        "Siloed processing of modalities (face, document, metadata) limits comprehensive identity risk assessment",
        "Limited scalability and single points of failure hinder high-throughput onboarding",
        "Need for auditability, transparency, and policy compliance (GDPR/AML/CTF) in automated verification"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "The rise of synthetic media and document forgeries has increased KYC fraud risk while legacy monolithic systems remain rigid, non-scalable, and slow to adapt; the paper motivates a modular, agent-orchestrated approach to improve robustness, latency, and compliance.",
      "potential_research_ideas": [
        "Develop adversarially trained deepfake and document forgery detectors tailored to KYC-specific threat models",
        "Federated learning for privacy-preserving KYC models across institutions without sharing raw PII",
        "Continual learning pipelines to rapidly adapt detectors to new attack patterns and document templates",
        "Explainable risk scoring with quantifiable uncertainty (e.g., conformal prediction) for human review",
        "Benchmark creation for multimodal KYC fraud with standardized protocols, metrics, and adversarial stress tests",
        "Evaluate and harden against adaptive attackers using red-teaming and attack simulation for KYC flows",
        "Edge/offline inference for low-connectivity onboarding with secure synchronization",
        "Graph-based identity linking (knowledge graphs) across modalities and historical interactions"
      ],
      "architectural_improvement_recommendations": [
        "Use video transformers or temporal CNNs for liveness/deepfake to capture fine-grained temporal cues",
        "Adopt layout-aware document models (e.g., Layout-aware transformers) for OCR + template/forensic validation",
        "Add uncertainty estimation and calibration to model outputs to inform escalation thresholds",
        "Implement feature stores and a model registry for consistent multimodal feature management and controlled rollouts",
        "Integrate differential privacy for training pipelines and encrypted processing (e.g., TEE) for sensitive PII",
        "Introduce active challenge–response liveness (behavioral prompts) coordinated by the agentic controller",
        "Policy-as-code with formal verification to guarantee jurisdictional compliance in orchestration paths",
        "Autoscaling policies with adaptive model selection (fast/light vs accurate/heavy) based on workload and risk"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Evaluated on a GPU cluster in a Kubernetes environment; microservices communicate over REST/gRPC with event bus (Kafka/NATS)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Kubernetes GPU cluster (cloud-native microservices)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Data privacy and GDPR/AML/CTF compliance",
        "Integration with legacy KYC systems and vendor APIs",
        "Handling adaptive/adversarial inputs at scale",
        "Human-in-the-loop case management and auditability",
        "Maintaining low latency under peak onboarding loads"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": true,
      "fairness_bias": true
    },
    "contributions": [
      "Proposes an agentic AI microservice framework for KYC that integrates liveness, deepfake detection, OCR-based document forensics, multimodal identity linking, and a policy-driven risk engine",
      "Introduces an agentic orchestration layer (task decomposition, model selection, failure recovery, anomaly escalation, policy compliance) communicating via event bus",
      "Demonstrates scalability and resilience with cloud-native deployment (Kubernetes, REST/gRPC, Kafka/NATS) and GPU-backed inference",
      "Reports experimental evaluation on mixed selfie/deepfake and document datasets with metrics including EER, FPR, latency, OCR accuracy, and template deviation",
      "Provides a blueprint emphasizing regulatory alignment, auditability, and human-in-the-loop escalation for regulated industries"
    ]
  },
  {
    "arxiv_id": "2601.10865v1",
    "title": "Multi-Agent Taint Specification Extraction for Vulnerability Detection",
    "authors": "Jonah Ghebremichael; Saastha Vasan; Saad Ullah; Greg Tystahl; David Adei; Christopher Kruegel; Giovanni Vigna; William Enck; Alexandros Kapravelos",
    "abstract": "Static Application Security Testing (SAST) tools using taint analysis are widely viewed as providing higher-quality vulnerability detection results compared to traditional pattern-based approaches. However, performing static taint analysis for JavaScript poses two major challenges. First, JavaScript's dynamic features complicate data flow extraction required for taint tracking. Second, npm's large library ecosystem makes it difficult to identify relevant sources/sinks and establish taint propagation across dependencies. In this paper, we present SemTaint, a multi-agent system that strategically combines the semantic understanding of Large Language Models (LLMs) with traditional static program analysis to extract taint specifications, including sources, sinks, call edges, and library flow summaries tailored to each package. Conceptually, SemTaint uses static program analysis to calculate a call graph and defers to an LLM to resolve call edges that cannot be resolved statically. Further, it uses the LLM to classify sources and sinks for a given CWE. The resulting taint specification is then provided to a SAST tool, which performs vulnerability analysis. We integrate SemTaint with CodeQL, a state-of-the-art SAST tool, and demonstrate its effectiveness by detecting 106 of 162 vulnerabilities previously undetectable by CodeQL. Furthermore, we find 4 novel vulnerabilities in 4 popular npm packages. In doing so, we demonstrate that LLMs can practically enhance existing static program analysis algorithms, combining the strengths of both symbolic reasoning and semantic understanding for improved vulnerability detection.",
    "published_date": "2026-01-15",
    "pdf_link": "https://arxiv.org/pdf/2601.10865v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Static Application Security Testing (SAST) / Taint Analysis",
      "specific_problem": "LLM-augmented extraction of taint specifications (sources, sinks, call edges, and dependency flow summaries) for JavaScript/npm packages to enable vulnerability detection with CodeQL",
      "attack_types": [
        "Cross-Site Scripting (XSS)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM Agent System",
        "specific": null,
        "novel_contribution": "Multi-agent orchestration (Source/Sink Agent, CallGraph Agent, Flow Summary Agent) that interleaves code exploration with tool use to propose sources/sinks, repair call graphs, and validate dependency flow summaries"
      },
      {
        "type": "primary",
        "category": "LLM",
        "specific": null,
        "novel_contribution": "Taint-Informed Callee Resolution (TICR): selectively query LLM to resolve only unresolved calls that lie on potential vulnerability paths for a target CWE"
      },
      {
        "type": "primary",
        "category": "LLM",
        "specific": null,
        "novel_contribution": "Demand-driven dependency modeling via candidate flow summaries refined by the Flow Summary Agent only for paths reported by the SAST tool"
      },
      {
        "type": "baseline",
        "category": "Traditional Static Analysis",
        "specific": "CodeQL (JavaScript taint-tracking queries)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Prompt-based LLM inference (no additional training)"
    ],
    "datasets": [
      {
        "name": "Brito et al. curated dataset of npm package vulnerabilities (957 vulnerabilities)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Evaluation subset from Brito et al.: 172 instances with artifacts (162 for main evaluation; 10 reserved for validation)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Case study: 10 open-source npm packages (used to discover 4 novel vulnerabilities)",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CodeQL (stock JavaScript taint-tracking queries)",
        "paper_reference": "CodeQL [11]; evaluation context: vulnerabilities previously undetectable by CodeQL",
        "metric": "Recall on the 162-instance subset previously undetectable by CodeQL",
        "their_result": "65.43% recall (\"SemTaint identified the vulnerability in 106 instances, which represents a recall of 65.43% of vulnerabilities previously undetectable by CodeQL.\")",
        "baseline_result": "0% recall on that subset (by construction, these 162 were \"previously undetectable by CodeQL\")"
      },
      {
        "method_name": "CodeQL on full Brito et al. dataset (context from prior work)",
        "paper_reference": "Brito et al. [18]",
        "metric": "Overall recall across 957 vulnerabilities",
        "their_result": null,
        "baseline_result": "31.3% (\"CodeQL outperformed all other tools, yet detected only 31.3% of the vulnerabilities.\")"
      }
    ],
    "performance_metrics_used": [
      "recall",
      "count of vulnerabilities detected"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can LLMs practically enhance existing static program analysis by repairing unresolved call edges and inferring package/CWE-specific sources and sinks to improve JavaScript vulnerability detection?",
        "Can demand-driven, agentic LLM analysis model third-party dependencies at npm scale without prohibitive inference cost while maintaining precision?"
      ],
      "gaps_identified": [
        "Static call graph construction for JavaScript has fundamental recall gaps due to dynamic features (e.g., prototype-based inheritance, eval, computed property dispatch).",
        "SAST tools exclude or under-model third-party dependencies; manually maintained specifications cannot keep pace with npm’s scale.",
        "Prior LLM-SAST approaches (e.g., IRIS, QLPro) rely on existing static call graphs and treat LLMs as stateless classifiers, limiting effectiveness when inter-procedural edges are unresolved and when API surfaces are large.",
        "Even state-of-the-art tools like CodeQL achieve only 31.3% recall on known npm package vulnerabilities in prior evaluation."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Combine the semantic understanding of LLMs with static program analysis to overcome JavaScript’s dynamic features and npm-scale dependency challenges, enabling improved taint-based vulnerability detection.",
      "potential_research_ideas": [
        "Extend SemTaint to other highly dynamic ecosystems (e.g., Python, Ruby) and compare cross-language effectiveness.",
        "Integrate lightweight dynamic traces (e.g., test or fuzz-driven execution) to guide TICR and reduce remaining unresolved edges.",
        "Continual learning of reusable taint specifications and flow summaries across packages to build a shared knowledge base.",
        "LLM specialization or fine-tuning for program analysis tasks (callee resolution, sanitization recognition) to reduce inference cost and improve accuracy.",
        "Incorporate retrieval-augmented prompting with repository-wide context and historical advisories to improve source/sink identification.",
        "Formal consistency checks or SMT-backed validation for LLM-proposed edges and summaries to prevent unsound specifications.",
        "Cost-aware agent planning (budgeted inference) and caching to improve scalability on large dependency graphs."
      ],
      "architectural_improvement_recommendations": [
        "Add a retrieval layer that indexes package code and known specs; use RAG to supply only relevant snippets to each agent step.",
        "Introduce an active-learning loop where uncertain edges/summaries are prioritized for confirmation via targeted queries or tests.",
        "Cache and canonicalize validated flow summaries per library version for reuse across analyses to amortize cost.",
        "Hybridize TICR with static pointer/shape analysis to pre-prune infeasible callees before LLM resolution.",
        "Use structured output constraints (e.g., JSON schemas) and programmatic feedback to reduce LLM hallucinations in taint facts.",
        "Parallelize agent steps over independent call sites and dependency modules with batching strategies to reduce latency."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Open-source npm packages (integration with CodeQL for SAST workflows)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Large number of unresolved calls in real-world JavaScript leading to high potential LLM query cost (addressed by TICR).",
        "npm-scale dependency modeling; state explosion if naively analyzing all transitive dependencies.",
        "Stochasticity of LLM outputs necessitating multi-run aggregation and validation against CodeQL dataflow nodes."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "SemTaint: a multi-agent system that combines LLM semantic reasoning with static analysis to extract taint specifications (sources, sinks, call edges, and flow summaries) tailored to each package/CWE.",
      "Taint-Informed Callee Resolution (TICR) to scale LLM-based repair of unresolved call edges by focusing on potential vulnerability paths.",
      "Demand-driven dependency modeling via candidate flow summaries, refined only for paths surfaced by the SAST tool.",
      "Modular taint-spec integration with CodeQL using external predicates, enabling iterative refinement and reuse across analyses.",
      "Empirical results: \"detecting 106 of 162 vulnerabilities previously undetectable by CodeQL\" (65.43% recall on that subset) and discovery of 4 novel vulnerabilities in popular npm packages."
    ]
  },
  {
    "arxiv_id": "2601.09129v1",
    "title": "KryptoPilot: An Open-World Knowledge-Augmented LLM Agent for Automated Cryptographic Exploitation",
    "authors": "Xiaonan Liu; Zhihao Li; Xiao Lan; Hao Ren; Haizhou Wang; Xingshu Chen",
    "abstract": "Capture-the-Flag (CTF) competitions play a central role in modern cybersecurity as a platform for training practitioners and evaluating offensive and defensive techniques derived from real-world vulnerabilities. Despite recent advances in large language models (LLMs), existing LLM-based agents remain ineffective on high-difficulty cryptographic CTF challenges, which require precise cryptanalytic knowledge, stable long-horizon reasoning, and disciplined interaction with specialized toolchains. Through a systematic exploratory study, we show that insufficient knowledge granularity, rather than model reasoning capacity, is a primary factor limiting successful cryptographic exploitation: coarse or abstracted external knowledge often fails to support correct attack modeling and implementation. Motivated by this observation, we propose KryptoPilot, an open-world knowledge-augmented LLM agent for automated cryptographic exploitation. KryptoPilot integrates dynamic open-world knowledge acquisition via a Deep Research pipeline, a persistent workspace for structured knowledge reuse, and a governance subsystem that stabilizes reasoning through behavioral constraints and cost-aware model routing. This design enables precise knowledge alignment while maintaining efficient reasoning across heterogeneous subtasks. We evaluate KryptoPilot on two established CTF benchmarks and in six real-world CTF competitions. KryptoPilot achieves a complete solve rate on InterCode-CTF, solves between 56 and 60 percent of cryptographic challenges on the NYU-CTF benchmark, and successfully solves 26 out of 33 cryptographic challenges in live competitions, including multiple earliest-solved and uniquely-solved instances. These results demonstrate the necessity of open-world, fine-grained knowledge augmentation and governed reasoning for scaling LLM-based agents to real-world cryptographic exploitation.",
    "published_date": "2026-01-14",
    "pdf_link": "https://arxiv.org/pdf/2601.09129v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cryptography",
      "subdomain": "Cryptanalysis / CTF Crypto",
      "specific_problem": "Automated cryptographic exploitation in CTF challenges via knowledge-augmented LLM agents",
      "attack_types": [
        "RSA vulnerabilities",
        "Algebraic attacks",
        "Hidden Number Problem (HNP)",
        "Learning With Errors (LWE)",
        "Protocol-level weaknesses",
        "Parameter degeneration",
        "Elliptic-curve structural vulnerabilities",
        "Lattice-based cryptanalysis"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM Agent / Tool-augmented Reasoning",
        "specific": "KryptoPilot controlled central reasoning unit with tool execution",
        "novel_contribution": "Modular agent that externalizes knowledge acquisition, execution environments, and governance to stabilize long-horizon reasoning for crypto exploitation"
      },
      {
        "type": "primary",
        "category": "Retrieval-Augmented Generation / Open-world Retrieval",
        "specific": "Deep Research (DR) pipeline",
        "novel_contribution": "Dynamic open-world acquisition of fine-grained, long-form cryptanalytic knowledge beyond conventional, static RAG"
      },
      {
        "type": "primary",
        "category": "Memory / Knowledge Management",
        "specific": "Persistent workspace for structured knowledge reuse",
        "novel_contribution": "Structured, persistent knowledge artifacts to reuse precise, executable cryptanalytic insights across subtasks"
      },
      {
        "type": "primary",
        "category": "Agent Governance / Prompting",
        "specific": "Behavioral governance with constraints",
        "novel_contribution": "Prompt-level behavioral constraints to stabilize long-horizon, tool-augmented reasoning and reduce drift"
      },
      {
        "type": "primary",
        "category": "Model Routing",
        "specific": "Dynamic Model Routing (MR)",
        "novel_contribution": "Cost-aware, capability-aware routing of subtasks to different LLMs to balance efficiency and effectiveness"
      },
      {
        "type": "baseline",
        "category": "Transformer LLM",
        "specific": "ChatGPT-5.1 single-round prompting",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM Agent",
        "specific": "CTFAgent",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM Agent",
        "specific": "Plain-Agent",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "In-context learning",
      "Tool-augmented agent",
      "Open-world retrieval",
      "RAG"
    ],
    "datasets": [
      {
        "name": "InterCode-CTF",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NYU-CTF benchmark (Crypto category)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Six real-world CTF competitions (live, cryptographic challenges)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Check-in (DubheCTF’24)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "LinearCasino (AliyunCTF’25)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MyCurveErrorLearn (XiHuLunJian’22)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "DangerLeak (0xGame’23)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "babyrsa (Qiangwang Cup’23)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "recovery (Qiangwang Cup’23)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "1515 (Qiangwang Cup’23)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "tss2 (angstromCTF’24)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Not an active field for a reason (DeadSecCTF’24)",
        "type": "public",
        "domain": "ctf_crypto",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CTFAgent",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Plain-Agent",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "ChatGPT-5.1 single-round (no external knowledge) vs with full paper (exploratory study, babyrsa challenge)",
        "paper_reference": null,
        "metric": "Code Correctness Rate (CCR)",
        "their_result": "83% (\"RC✓, CCR 83%\" with full paper)",
        "baseline_result": "0% (\"RC×, CCR 0%\" with no external knowledge)"
      }
    ],
    "performance_metrics_used": [
      "Solve rate (complete solve rate)",
      "Reasoning Correctness (RC)",
      "Code Correctness Rate (CCR)",
      "Earliest-solved count",
      "Uniquely-solved count"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Is insufficient knowledge granularity the primary bottleneck in LLM-based cryptographic CTF solving, rather than model reasoning capacity?",
        "Can open-world, fine-grained knowledge acquisition (Deep Research) improve reasoning correctness and exploit implementation?",
        "Can governance and cost-aware model routing stabilize long-horizon reasoning while maintaining efficiency?",
        "Are high-capability models necessary for all subtasks in cryptographic exploitation pipelines?"
      ],
      "gaps_identified": [
        "Closed and static local knowledge bases built from compressed summaries or write-ups misalign with cryptographic reasoning requirements.",
        "Conventional RAG pipelines are inadequate for high-difficulty cryptographic exploitation due to insufficient knowledge granularity.",
        "Lack of domain-specific cryptographic execution environments (e.g., lattice solvers, specialized libraries) leads to subtle but fatal implementation errors.",
        "Uniformly invoking high-capability models across all subtasks yields inefficiency without consistent gains."
      ],
      "limitations": [
        "Even with full-paper inputs, code correctness can remain limited for some challenges due to the tendency to reimplement complex cryptographic algorithms instead of reusing validated implementations (e.g., \"tss2\" and \"1515\").",
        "Abstract-level knowledge may actively mislead reasoning (e.g., \"recovery\" challenge) leading to misdirection and wasted compute.",
        "Precise details of deployment and reproducibility (e.g., tooling stacks, runtime specs) are not fully specified in the provided content."
      ],
      "future_work": [
        "Extend the knowledge-externalized and governed agent paradigm to other security domains beyond cryptography.",
        "Improve integration with domain-specific, verified cryptographic toolchains to minimize reimplementation errors.",
        "Refine dynamic model routing strategies for finer-grained task capability matching and cost control."
      ],
      "motivation": "Existing LLM-based agents fail on high-difficulty cryptographic CTF tasks primarily due to insufficient knowledge granularity and unstable long-horizon reasoning; enabling precise, executable knowledge alignment and governed reasoning can scale agents to real-world cryptographic exploitation.",
      "potential_research_ideas": [
        "Develop a verified-crypto-toolchain integration layer that automatically detects when to call established libraries (e.g., lattice solvers, ECC toolkits) instead of reimplementing algorithms.",
        "Design an open-world retrieval planner that uses citation graphs and section-level indexing to target formal derivations and parameter constraints in cryptanalysis papers.",
        "Incorporate formal-methods support (SMT solvers, proof assistants) to validate cryptographic derivations before code generation.",
        "Learn a policy (bandits/RL) for dynamic model routing and tool selection based on subtask difficulty signals and uncertainty.",
        "Create a standardized benchmark and evaluation protocol for open-world crypto exploitation with metrics on knowledge granularity and executability.",
        "Augment the agent with a self-critique layer that detects potential mathematical inconsistencies or implementation drift via unit tests and symbolic checks.",
        "Pretrain or continue-train LLMs on curated cryptanalysis corpora and high-quality CTF write-ups emphasizing derivations and executable detail."
      ],
      "architectural_improvement_recommendations": [
        "Add a library-aware code generation component that prefers calls to vetted cryptographic libraries and solvers, with automatic parameter validation.",
        "Introduce a formal-spec module where the agent translates problem statements into typed mathematical specifications checked by an SMT solver.",
        "Enhance Deep Research with multi-hop retrieval guided by citation networks and section-level embeddings for fine-grained knowledge targeting.",
        "Upgrade model routing with uncertainty estimation and cost-performance Pareto optimization; cache intermediate results in the persistent workspace.",
        "Implement strict test harnesses with property-based tests and differential testing against known-good implementations to catch subtle math bugs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Live CTF competition environments (multiple real-world events) and established CTF benchmarks",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Need for fine-grained, executable cryptanalytic knowledge acquisition",
        "Long-horizon reasoning stability and prevention of reasoning drift",
        "Reliable integration with specialized mathematical toolchains (lattice solvers, PQC libraries)",
        "Cost and latency management via model routing",
        "Avoiding early-modeling errors that propagate across steps"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Identify insufficient knowledge granularity as the primary bottleneck for LLM-based cryptographic CTF solving.",
      "Propose KryptoPilot: an open-world, knowledge-augmented LLM agent with Deep Research, persistent workspace, and governance subsystem.",
      "Introduce cost-aware dynamic model routing to allocate capability across heterogeneous subtasks efficiently.",
      "Demonstrate strong results: \"100% solve rate on InterCode-CTF,\" \"56–60% on the NYU-CTF benchmark (Crypto),\" and \"26/33 solves in six live CTF competitions,\" including earliest- and uniquely-solved instances.",
      "Show, via an exploratory study, that full-length primary cryptanalysis sources significantly improve reasoning and code correctness over abstract-level knowledge."
    ]
  },
  {
    "arxiv_id": "2601.00384v1",
    "title": "Engineering Attack Vectors and Detecting Anomalies in Additive Manufacturing",
    "authors": "Md Mahbub Hasan; Marcus Sternhagen; Krishna Chandra Roy",
    "abstract": "Additive manufacturing (AM) is rapidly integrating into critical sectors such as aerospace, automotive, and healthcare. However, this cyber-physical convergence introduces new attack surfaces, especially at the interface between computer-aided design (CAD) and machine execution layers. In this work, we investigate targeted cyberattacks on two widely used fused deposition modeling (FDM) systems, Creality's flagship model K1 Max, and Ender 3. Our threat model is a multi-layered Man-in-the-Middle (MitM) intrusion, where the adversary intercepts and manipulates G-code files during upload from the user interface to the printer firmware. The MitM intrusion chain enables several stealthy sabotage scenarios. These attacks remain undetectable by conventional slicer software or runtime interfaces, resulting in structurally defective yet externally plausible printed parts. To counter these stealthy threats, we propose an unsupervised Intrusion Detection System (IDS) that analyzes structured machine logs generated during live printing. Our defense mechanism uses a frozen Transformer-based encoder (a BERT variant) to extract semantic representations of system behavior, followed by a contrastively trained projection head that learns anomaly-sensitive embeddings. Later, a clustering-based approach and a self-attention autoencoder are used for classification. Experimental results demonstrate that our approach effectively distinguishes between benign and compromised executions.",
    "published_date": "2026-01-01",
    "pdf_link": "https://arxiv.org/pdf/2601.00384v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cyber-Physical Systems Security",
      "subdomain": "Intrusion Detection for Additive Manufacturing",
      "specific_problem": "Detecting stealthy G-code-level manipulations in FDM 3D printers via log-based anomaly detection without golden STL/G-code",
      "attack_types": [
        "Man-in-the-Middle (MitM) intrusion",
        "G-code manipulation",
        "Under-extrusion",
        "Over-extrusion",
        "Noisy G-code injection",
        "Dimensionality change/manipulation",
        "Internal cavity insertion",
        "Execution-phase tampering",
        "Deferred print exploit",
        "Access-jammed G-code swap",
        "Credential brute-force/dictionary compromise",
        "Intellectual property (IP) theft"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "MiniLM (BERT variant, frozen encoder)",
        "novel_contribution": "Uses a frozen MiniLM encoder on structured printer logs with a contrastively trained projection head to learn anomaly-sensitive embeddings without labeled attacks or golden references."
      },
      {
        "type": "primary",
        "category": "Contrastive Learning",
        "specific": null,
        "novel_contribution": "Projection head trained self-supervised on benign logs to shape a discriminative latent space for anomaly separation."
      },
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "K-Means",
        "novel_contribution": "Used to segment embedding space and confirm benign vs anomalous separation as part of hybrid evaluation."
      },
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": "Self-attention autoencoder",
        "novel_contribution": "Trained on benign embeddings; anomalies flagged via high reconstruction loss for fine-grained detection."
      },
      {
        "type": "baseline",
        "category": "Dimensionality Reduction",
        "specific": "PCA",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Dimensionality Reduction",
        "specific": "UMAP",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Self-supervised"
    ],
    "datasets": [
      {
        "name": "Structured printer logs from Creality K1 Max (Klipper/Moonraker) and Creality Ender 3 (OctoPrint) experiments",
        "type": "private",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can stealthy G-code-level sabotage in FDM printers be detected in real time using only runtime machine logs, without golden STL/G-code references?",
        "Can transformer-based log embeddings with contrastive learning separate benign from compromised executions in an unsupervised setting?"
      ],
      "gaps_identified": [
        "Most prior approaches rely on predefined attacker models, static analysis, or access to a golden reference model (STL), leaving a gap for real-time detection at the G-code execution layer.",
        "Existing slicers/runtime interfaces fail to detect subtle G-code manipulations that yield structurally defective yet externally plausible parts."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "AM systems in critical sectors are vulnerable to stealthy G-code-level manipulations that evade conventional checks; need a non-invasive, real-time IDS without reliance on golden models.",
      "potential_research_ideas": [
        "Create and release a standardized AM log anomaly benchmark with diverse printers, firmware, and attack taxonomies to enable fair comparison.",
        "Investigate multi-modal fusion (logs + acoustic/power/EM sensors) for higher detection fidelity and robustness to evasion.",
        "Develop online streaming detection with concept drift handling to support long prints and changing conditions.",
        "Explore cross-printer/domain adaptation to generalize embeddings across firmware (Klipper, Marlin), slicers, and materials.",
        "Evaluate robustness against adaptive adversaries that target the detector (e.g., mimic benign log statistics) and design adversarial training defenses.",
        "Incorporate explainability methods to localize anomalous commands/layers and map detections back to G-code segments for forensics.",
        "Study low-resource edge deployment (quantization, pruning) on embedded controllers for in-printer IDS.",
        "Extend to predictive maintenance by distinguishing malicious anomalies from mechanical faults (nozzle clogging, stepper skips)."
      ],
      "architectural_improvement_recommendations": [
        "Domain-adaptive pretraining or continued pretraining of MiniLM on large corpora of AM logs instead of keeping the encoder fully frozen.",
        "Use temporal transformers or sequence models with explicit time/position embeddings to capture long-range dependencies across layers.",
        "Adopt deep one-class objectives (Deep SVDD, hypersphere loss) or energy-based models directly on embeddings as anomaly scorers.",
        "Replace K-Means with density-based clustering (HDBSCAN) and/or isolation-based methods to better handle non-convex clusters.",
        "Leverage self-supervised log augmentations (masking, span deletion, time jitter) to strengthen contrastive learning.",
        "Integrate metric-learning heads (ArcFace/CosFace) to sharpen decision boundaries for normality.",
        "Add calibration and thresholding strategies (e.g., EVT tails) for principled anomaly score selection.",
        "Jointly train autoencoder on raw token sequences rather than only embeddings to preserve information lost in projection."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Laboratory networked FDM printers: Creality K1 Max (Klipper + Moonraker via Mainsail/Fluidd) and Creality Ender 3 (OctoPrint on Raspberry Pi)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Constructed multiple realistic stealthy G-code attack scenarios (Under-/Over-extrusion, Noise Injection, Dimensionality Change, Internal Cavity Insertion) via a rogue web interface enabling MitM manipulations.",
      "Proposed a non-invasive, log-centric unsupervised IDS for AM using structured machine logs produced during live printing.",
      "Employed a pretrained and frozen MiniLM transformer encoder with a contrastively trained projection head to learn anomaly-sensitive embeddings without labeled attacks or golden models.",
      "Hybrid evaluation pipeline combining clustering-based separation (PCA/UMAP visualization, K-Means) and a self-attention autoencoder with reconstruction loss for anomaly detection.",
      "Demonstrated feasibility across two distinct FDM platforms (Creality K1 Max with Klipper/Moonraker; Ender 3 with OctoPrint), indicating cross-platform generalizability."
    ]
  },
  {
    "arxiv_id": "2601.14305v1",
    "title": "An Optimized Decision Tree-Based Framework for Explainable IoT Anomaly Detection",
    "authors": " Ashikuzzaman; Md. Shawkat Hossain; Jubayer Abdullah Joy; Md Zahid Akon; Md Manjur Ahmed; Md. Naimul Islam",
    "abstract": "The increase in the number of Internet of Things (IoT) devices has tremendously increased the attack surface of cyber threats thus making a strong intrusion detection system (IDS) with a clear explanation of the process essential towards resource-constrained environments. Nevertheless, current IoT IDS systems are usually traded off with detection quality, model elucidability, and computational effectiveness, thus the deployment on IoT devices. The present paper counteracts these difficulties by suggesting an explainable AI (XAI) framework based on an optimized Decision Tree classifier with both local and global importance methods: SHAP values that estimate feature attribution using local explanations, and Morris sensitivity analysis that identifies the feature importance in a global view. The proposed system attains the state of art on the test performance with 99.91% accuracy, F1-score of 99.51% and Cohen Kappa of 0.9960 and high stability is confirmed by a cross validation mean accuracy of 98.93%. Efficiency is also enhanced in terms of computations to provide faster inferences compared to those that are generalized in ensemble models. SrcMac has shown as the most significant predictor in feature analyses according to SHAP and Morris methods. Compared to the previous work, our solution eliminates its major drawback lack because it allows us to apply it to edge devices and, therefore, achieve real-time processing, adhere to the new regulation of transparency in AI, and achieve high detection rates on attacks of dissimilar classes. This combination performance of high accuracy, explainability, and low computation make the framework useful and reliable as a resource-constrained IoT security problem in real environments.",
    "published_date": "2026-01-18",
    "pdf_link": "https://arxiv.org/pdf/2601.14305v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Explainable anomaly-based IDS for IoT network traffic on resource-constrained edge devices (multiclass: Normal, Spoofing, Data Alteration)",
      "attack_types": [
        "Spoofing",
        "Data alteration"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": "Optimized Decision Tree",
        "novel_contribution": "Optimized for high accuracy and low computational cost; paired with local (SHAP) and global (Morris) explainability"
      },
      {
        "type": "primary",
        "category": "XAI/Feature Attribution",
        "specific": "SHAP",
        "novel_contribution": "Provides local and aggregated global explanations of feature contributions for the DT classifier"
      },
      {
        "type": "primary",
        "category": "Sensitivity Analysis",
        "specific": "Morris method",
        "novel_contribution": "Global sensitivity analysis to identify most influential features"
      },
      {
        "type": "primary",
        "category": "Feature Selection",
        "specific": "Recursive Feature Elimination (with cross-validation)",
        "novel_contribution": "Used to select key features to improve accuracy and efficiency"
      },
      {
        "type": "primary",
        "category": "Statistical Test",
        "specific": "Chi-square test of independence",
        "novel_contribution": "Filter to drop features with p-value > 0.05 relative to target"
      },
      {
        "type": "primary",
        "category": "Statistical Test",
        "specific": "Pearson correlation with Bonferroni correction",
        "novel_contribution": "Ranked features by absolute correlation; retained features with adjusted p < 0.05"
      },
      {
        "type": "primary",
        "category": "Data Augmentation",
        "specific": "Gaussian noise injection",
        "novel_contribution": "0-mean noise with std = 15% of each feature’s std injected to simulate real-world variability"
      },
      {
        "type": "primary",
        "category": "Resampling",
        "specific": "Random oversampling",
        "novel_contribution": "Balanced minority classes to majority class size for training"
      },
      {
        "type": "baseline",
        "category": "Tree-based Ensemble",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "KNN",
        "specific": "k-Nearest Neighbors (k=5)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "MLP",
        "specific": "1 hidden layer (128 units)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting",
        "specific": "CatBoost",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "WUSTL IoT dataset (Normal/Spoofing/Data Alteration)",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Test Accuracy",
        "their_result": "0.9991",
        "baseline_result": "0.9940"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Test F1-score",
        "their_result": "0.9951",
        "baseline_result": "0.9905"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Cohen Kappa (test)",
        "their_result": "0.9960",
        "baseline_result": "0.9954"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "Test Accuracy",
        "their_result": "0.9991",
        "baseline_result": "0.9938"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "Test F1-score",
        "their_result": "0.9951",
        "baseline_result": "0.9902"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "Cohen Kappa (test)",
        "their_result": "0.9960",
        "baseline_result": "0.9950"
      },
      {
        "method_name": "MLP",
        "paper_reference": null,
        "metric": "Test Accuracy",
        "their_result": "0.9991",
        "baseline_result": "0.9935"
      },
      {
        "method_name": "MLP",
        "paper_reference": null,
        "metric": "Test F1-score",
        "their_result": "0.9951",
        "baseline_result": "0.9900"
      },
      {
        "method_name": "MLP",
        "paper_reference": null,
        "metric": "Cohen Kappa (test)",
        "their_result": "0.9960",
        "baseline_result": "0.9943"
      },
      {
        "method_name": "CatBoost",
        "paper_reference": null,
        "metric": "Test Accuracy",
        "their_result": "0.9991",
        "baseline_result": "0.9931"
      },
      {
        "method_name": "CatBoost",
        "paper_reference": null,
        "metric": "Test F1-score",
        "their_result": "0.9951",
        "baseline_result": "0.9897"
      },
      {
        "method_name": "CatBoost",
        "paper_reference": null,
        "metric": "Cohen Kappa (test)",
        "their_result": "0.9960",
        "baseline_result": "0.9940"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "Cohen Kappa",
      "ROC-AUC",
      "PR-AUC",
      "5-fold cross-validation mean accuracy",
      "Cross-validation standard deviation"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Explainability often increases computational overhead, limiting real-time use on resource-constrained IoT devices",
        "Generalization across diverse and evolving IoT data is underexplored and often validated only on small benchmarks",
        "Scalability and edge deployment challenges for deep learning, ensembles, and blockchain-based methods",
        "Active learning not tested in large-scale streaming contexts",
        "One-class models susceptible to performance degradation under concept drift; need adaptive, resource-efficient, and scalable IDS"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Build a lightweight, accurate, and transparent IDS suitable for resource-constrained IoT devices by optimizing a Decision Tree and integrating XAI (SHAP and Morris) to achieve high detection rates and regulatory transparency.",
      "potential_research_ideas": [
        "Evaluate the framework across multiple IoT intrusion datasets (e.g., BoT-IoT, UNSW-NB15 IoT subsets, TON_IoT) to assess cross-dataset generalization",
        "Develop an online/streaming variant using incremental or Hoeffding trees to handle concept drift in IoT networks",
        "Integrate active learning to minimize labeling effort in streaming settings while maintaining high detection performance",
        "Study adversarial and poisoning robustness of interpretable tree-based IDS and design defenses",
        "Federated or split learning across edge devices to preserve data privacy while training/updating the IDS",
        "Energy/latency profiling and hardware-in-the-loop deployments on actual edge hardware (e.g., Raspberry Pi, microcontrollers)",
        "Augment explainability with counterfactual explanations and rule extraction to aid operator response",
        "Domain adaptation/transfer learning to adapt the IDS across different IoT environments and device mixes",
        "Uncertainty estimation and calibration to improve decision thresholds under class imbalance and noise",
        "Automated feature engineering and selection pipelines tailored for IoT network telemetry"
      ],
      "architectural_improvement_recommendations": [
        "Adopt online/streaming trees (Hoeffding trees) with concept-drift detectors (e.g., ADWIN) for real-time updates",
        "Replace random oversampling with cost-sensitive learning or SMOTE variants to reduce overfitting and improve minority class recall",
        "Apply minimal cost-complexity pruning and Bayesian hyperparameter optimization for the Decision Tree",
        "Ensemble of shallow trees distilled into a single surrogate tree or rule list to preserve explainability with boosted accuracy",
        "Add monotonic constraints where domain knowledge applies (e.g., rate/jitter) to improve generalization",
        "Calibrate outputs (e.g., Platt scaling or isotonic regression) for better thresholding and operational use",
        "Incorporate robust preprocessing (IQR with Winsorization) and feature stability analysis under noise and drift",
        "Optimize for edge deployment using model export (ONNX) and runtime accelerators (e.g., TVM) to minimize inference latency",
        "Integrate uncertainty-aware decision logic to trigger deeper analysis only when confidence is low"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Edge resource constraints limit heavy ensemble/deep models",
        "Generalization to diverse, evolving IoT environments",
        "Handling streaming data and concept drift",
        "Class imbalance and label noise in real telemetry",
        "Requirement for transparency and regulatory compliance"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A preprocessing pipeline for IoT traffic, including normalization, noise reduction, and class imbalance handling",
      "Recursive Feature Elimination with cross-validation to select key features and enhance accuracy/efficiency",
      "An optimized Decision Tree classifier achieving high accuracy with low computational cost for real-time IoT deployment",
      "Integration of XAI techniques (SHAP and Morris sensitivity analysis) for transparent, trustworthy decisions",
      "Validation on a benchmark IoT intrusion dataset with improved accuracy, interpretability, and reduced resource consumption",
      "Reported SOTA results: 99.91% accuracy, 99.51% F1-score, and Cohen Kappa 0.9960; stable 5-fold CV mean accuracy 98.93% (std 0.0003)"
    ]
  },
  {
    "arxiv_id": "2601.09157v1",
    "title": "Deep Learning-based Binary Analysis for Vulnerability Detection in x86-64 Machine Code",
    "authors": "Mitchell Petingola",
    "abstract": "While much of the current research in deep learning-based vulnerability detection relies on disassembled binaries, this paper explores the feasibility of extracting features directly from raw x86-64 machine code. Although assembly language is more interpretable for humans, it requires more complex models to capture token-level context. In contrast, machine code may enable more efficient, lightweight models and preserve all information that might be lost in disassembly. This paper approaches the task of vulnerability detection through an exploratory study on two specific deep learning model architectures and aims to systematically evaluate their performance across three vulnerability types. The results demonstrate that graph-based models consistently outperform sequential models, emphasizing the importance of control flow relationships, and that machine code contains sufficient information for effective vulnerability discovery.",
    "published_date": "2026-01-14",
    "pdf_link": "https://arxiv.org/pdf/2601.09157v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Binary Analysis and Vulnerability Detection",
      "specific_problem": "Detect memory-corruption-related vulnerabilities directly from x86-64 machine code",
      "attack_types": [
        "Null Pointer Dereference (CWE-476)",
        "Improper Validation of Array Index (CWE-129)",
        "Integer Overflow or Wraparound (CWE-190)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN + Attention",
        "specific": "1D-CNN with Multi-Head Self-Attention aggregator",
        "novel_contribution": "Sequential program model operating on tokens derived directly from x86-64 machine code (operand bytes omitted), with hierarchical embeddings (instruction -> function -> program) and self-attention over functions."
      },
      {
        "type": "primary",
        "category": "GNN",
        "specific": "GCN (Kipf & Welling) with attention-based Top-K pooling",
        "novel_contribution": "Graph-based model over function-level CFGs built from machine code tokens; uses 1D-CNN for basic-block embeddings, GCN layers for control-flow propagation, attention-score Top-K pooling of CFG nodes, and self-attention over functions."
      },
      {
        "type": "primary",
        "category": "Embedding/Representation",
        "specific": "Instruction token embeddings from raw x86-64 bytes",
        "novel_contribution": "Machine-code tokenization that omits displacement/immediate operand bytes while retaining prefix, opcode, ModR/M, and SIB bytes to reduce vocabulary and preserve control/data-flow cues."
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "FormAI-v2 (LLM-generated C programs, verified with ESBMC) — subsets for CWE-476/129/190 and compiled to x86-64",
        "type": "synthetic",
        "domain": "binary_executables",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      },
      {
        "name": "Juliet Test Suite (CWE-labeled C/C++ test cases)",
        "type": "synthetic",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can deep learning models trained directly on x86-64 machine code achieve comparable or superior accuracy to assembly-based approaches for vulnerability detection?",
        "How do different model architectures (sequential vs. graph-based) and hyperparameters affect performance across specific vulnerability types (CWE-476, CWE-129, CWE-190)?",
        "Which vulnerability types benefit most from machine code–level analysis?",
        "Is raw machine code sufficient for effective vulnerability discovery without disassembly?"
      ],
      "gaps_identified": [
        "Assembly-based analysis often requires complex NLP-like models and may introduce information loss or inaccuracies due to disassembly heuristics.",
        "Direct deep learning on raw machine code for vulnerability detection is relatively unexplored.",
        "Existing works frequently operate on disassembled or IR forms rather than preserving full machine-code information."
      ],
      "limitations": [
        "Not all control flow can be represented statically (e.g., return addresses and indirect jump targets computed at runtime), limiting CFG completeness.",
        "Padding/truncation at instruction, basic-block, function, and program levels is required to fit fixed tensor shapes.",
        "Class imbalance in the underlying dataset necessitated grouping and balancing."
      ],
      "future_work": [],
      "motivation": "Explore whether operating directly on raw machine code can avoid disassembly-induced errors, enable lighter models, preserve all information, and effectively detect vulnerabilities.",
      "potential_research_ideas": [
        "Integrate data-flow graphs with CFGs to jointly model control and data dependencies from machine code.",
        "Pretrain instruction and block embeddings on large unlabeled binary corpora via self-supervised objectives (e.g., masked byte/token modeling or contrastive function similarity) before fine-tuning for vulnerability detection.",
        "Model operand displacement/immediate bytes with quantization or learned bucketing to recover lost numeric semantics without exploding vocabulary.",
        "Extend to multi-architecture vulnerability detection (e.g., ARM64, RISC-V) with shared or adapter-based embeddings for cross-ISA generalization.",
        "Incorporate dynamic analysis signals (e.g., lightweight instrumentation traces) to resolve indirect control flow and improve CFG fidelity.",
        "Adopt multi-task learning across many CWE types to share representations and improve minority-class performance."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment GCN with more expressive graph encoders (e.g., GAT, GraphSAGE, GIN) and hierarchical graph pooling (e.g., DiffPool, SAGPool).",
        "Introduce positional/structural encodings for basic blocks within CFGs and functions to better capture ordering and structural roles.",
        "Leverage byte-level Transformers with local attention over instruction windows, combined with graph modules for control flow.",
        "Use relational edges (e.g., call edges, different branch types) and model a program-level heterogeneous graph (functions, blocks) with message passing.",
        "Calibrate attention-based Top-K pooling with temperature annealing and curriculum K-schedules to stabilize training and improve selection.",
        "Adopt hard negative mining and focal losses to handle residual class imbalance and ambiguous non-vulnerable samples."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Static CFG construction from binaries cannot capture all dynamic control flow (e.g., indirect jumps/returns).",
        "Padding/truncation to fixed sizes may omit relevant long-range context or dilute signals."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a machine-code-first tokenization strategy for x86-64 that omits displacement/immediate bytes while preserving prefix, opcode, ModR/M, and SIB information.",
      "Proposes and evaluates two deep learning architectures on machine code: a sequential 1D-CNN + self-attention model and a CFG-based GCN model with attention Top-K pooling.",
      "Defines hierarchical embeddings from instruction to function to program levels, with self-attention to identify salient functions.",
      "Empirical study across three vulnerability types (CWE-476, CWE-129, CWE-190) using compiled binaries from FormAI-v2.",
      "Finds that graph-based models consistently outperform sequential models, highlighting the importance of control-flow relationships and sufficiency of machine code for vulnerability discovery."
    ]
  },
  {
    "arxiv_id": "2601.06708v1",
    "title": "Behavioral Analytics for Continuous Insider Threat Detection in Zero-Trust Architectures",
    "authors": "Gaurav Sarraf",
    "abstract": "Insider threats are a particularly tricky cybersecurity issue, especially in zero-trust architectures (ZTA) where implicit trust is removed. Although the rule of thumb is never trust, always verify, attackers can still use legitimate credentials and impersonate the standard user activity. In response, behavioral analytics with machine learning (ML) can help monitor the user activity continuously and identify the presence of anomalies. This introductory framework makes use of the CERT Insider Threat Dataset for data cleaning, normalization, and class balance using the Synthetic Minority Oversampling Technique (SMOTE). It also employs Principal Component Analysis (PCA) for dimensionality reduction. Several benchmark models, including Support Vector Machine (SVM), Artificial Neural Network (ANN), and Bayesian Network (Bayes Net), were used to develop and evaluate the AdaBoost classifier. Compared to SVM (90.1%), ANN (94.7%), and Bayes Net (94.9), AdaBoost achieved higher performance with a 98.0% ACC, 98.3% PRE, 98.0% REC, and F1-score (F1). The Receiver Operating Characteristic (ROC) study, which provided further confirmation of its strength, yielded an Area Under the Curve (AUC) of 0.98. These results prove the effectiveness and dependability of AdaBoost-based behavioral analytics as a solution to reinforcing continuous insider threat detection in zero-trust settings.",
    "published_date": "2026-01-10",
    "pdf_link": "https://arxiv.org/pdf/2601.06708v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Insider Threats",
      "subdomain": "User and Entity Behavior Analytics (UEBA)",
      "specific_problem": "Continuous insider threat detection in zero-trust architectures using behavioral analytics",
      "attack_types": [
        "malicious_insider_activity",
        "credential_misuse/impersonation",
        "behavioral_anomalies"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble (Boosting)",
        "specific": "AdaBoost (small decision trees as weak learners)",
        "novel_contribution": "Integrates SMOTE + Min-max normalization + PCA with an AdaBoost classifier for behavioral analytics on the CERT insider threat dataset in a zero-trust context; achieves higher accuracy than SVM/ANN/Bayes Net."
      },
      {
        "type": "primary",
        "category": "Dimensionality Reduction",
        "specific": "PCA",
        "novel_contribution": "Used to reduce dimensionality of high-dimensional behavioral features before classification."
      },
      {
        "type": "primary",
        "category": "Data Resampling",
        "specific": "SMOTE (k=3)",
        "novel_contribution": "Applied to address severe class imbalance (minority insider class)."
      },
      {
        "type": "primary",
        "category": "Preprocessing",
        "specific": "Min-max normalization",
        "novel_contribution": "Feature scaling to standardize variables across 830 features."
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Artificial Neural Network",
        "specific": "ANN/MLP (unspecified architecture)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Probabilistic Graphical Model",
        "specific": "Bayesian Network (Bayes Net)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CERT Insider Threat Dataset",
        "type": "public",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "98.0%",
        "baseline_result": "90.1%"
      },
      {
        "method_name": "Artificial Neural Network (ANN)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "98.0%",
        "baseline_result": "94.7%"
      },
      {
        "method_name": "Bayesian Network (Bayes Net)",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "98.0%",
        "baseline_result": "94.9%"
      }
    ],
    "performance_metrics_used": [
      "Accuracy (ACC)",
      "Precision (PRE)",
      "Recall (REC)",
      "F1-score",
      "ROC-AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can behavioral analytics with ML enable continuous insider threat detection within zero-trust architectures?",
        "How do preprocessing steps (SMOTE for class imbalance, normalization, PCA) affect detection performance on high-dimensional insider threat data?",
        "Does an AdaBoost-based classifier outperform common baselines (SVM, ANN, Bayes Net) for insider threat classification on CERT data?"
      ],
      "gaps_identified": [
        "Traditional IAM systems fail to detect subtle behavioral deviations.",
        "Insider threat datasets are highly imbalanced, complicating supervised learning.",
        "Behavioral data is high-dimensional, increasing computational cost and risking degraded performance.",
        "Zero-trust deployments face scalability, legacy integration, and usability-security trade-off challenges."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Rising insider threats in zero-trust settings require continuous monitoring. Traditional IAM lacks sensitivity to subtle behavioral anomalies; datasets are imbalanced and high-dimensional. The study seeks to improve detection accuracy and reliability via behavioral analytics with ML.",
      "potential_research_ideas": [
        "Sequence-aware modeling of user behavior (e.g., LSTM/Temporal Convolution/Transformer) to capture temporal patterns beyond static features.",
        "Online/streaming learning with concept-drift detection for continuous insider threat monitoring in ZTA.",
        "Self-supervised or contrastive representation learning on enterprise logs to reduce reliance on manual features.",
        "Graph-based UEBA (heterogeneous graphs of users-devices-resources) with GNNs for relational anomaly detection.",
        "Multi-modal fusion of endpoint, network, IAM, and biometric signals for stronger context-aware detection.",
        "Federated or privacy-preserving learning across business units without centralizing sensitive logs.",
        "Explainability for analyst triage (e.g., SHAP for boosted trees) to reduce alert fatigue and support investigations.",
        "Adversarial robustness studies against mimicry/poisoning attacks in insider settings.",
        "Cost-sensitive learning and calibrated probabilities to optimize for low false positives in SOC workflows."
      ],
      "architectural_improvement_recommendations": [
        "Replace or complement AdaBoost with modern gradient boosting (XGBoost/LightGBM/CatBoost) and perform systematic hyperparameter tuning.",
        "Introduce feature selection or autoencoder-based dimensionality reduction instead of (or alongside) PCA and compare.",
        "Adopt a hybrid pipeline: unsupervised anomaly detector (e.g., Isolation Forest/One-Class SVM) to pre-filter events, followed by supervised boosting for classification.",
        "Implement time-windowed feature engineering (sessionization, deltas, burstiness) and sliding-window inference.",
        "Use class-weighted losses or balanced bagging/boosting to reduce over-reliance on SMOTE and mitigate potential synthetic overfitting.",
        "Calibrate output scores (Platt/Isotonic) and add threshold optimization for operational deployment.",
        "Integrate explainability (TreeSHAP) and risk scoring aligned with zero-trust policies for actionable outputs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Balancing security and usability in zero-trust deployments.",
        "Integration with legacy systems.",
        "Processing large volumes of access and activity data at scale.",
        "Avoiding performance bottlenecks in continuous monitoring."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a behavioral analytics framework for continuous insider threat detection in zero-trust architectures.",
      "Uses the CERT Insider Threat Dataset (693,649 records; 830 features) with data cleaning and consistency checks.",
      "Addresses class imbalance via SMOTE (k=3).",
      "Applies Min-max normalization and PCA for dimensionality reduction.",
      "Develops an AdaBoost-based classifier and benchmarks against SVM, ANN, and Bayesian Network.",
      "Reports performance: ACC 98.0%, PRE 98.3%, REC 98.0%, F1 (not numerically specified), ROC-AUC 0.98; outperforming SVM (90.1%), ANN (94.7%), Bayes Net (94.9%)."
    ]
  },
  {
    "arxiv_id": "2601.09035v1",
    "title": "A Decompilation-Driven Framework for Malware Detection with Large Language Models",
    "authors": "Aniesh Chawla; Udbhav Prasad",
    "abstract": "The parallel evolution of Large Language Models (LLMs) with advanced code-understanding capabilities and the increasing sophistication of malware presents a new frontier for cybersecurity research. This paper evaluates the efficacy of state-of-the-art LLMs in classifying executable code as either benign or malicious. We introduce an automated pipeline that first decompiles Windows executable into a C code using Ghidra disassembler and then leverages LLMs to perform the classification. Our evaluation reveals that while standard LLMs show promise, they are not yet robust enough to replace traditional anti-virus software. We demonstrate that a fine-tuned model, trained on curated malware and benign datasets, significantly outperforms its vanilla counterpart. However, the performance of even this specialized model degrades notably when encountering newer malware. This finding demonstrates the critical need for continuous fine-tuning with emerging threats to maintain model effectiveness against the changing coding patterns and behaviors of malicious software.",
    "published_date": "2026-01-14",
    "pdf_link": "https://arxiv.org/pdf/2601.09035v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection",
      "specific_problem": "Binary classification of Windows executables (malware vs benign) using decompiled C code and LLMs",
      "attack_types": [
        "Backdoor",
        "Stealer (e.g., LummaStealer, SalatStealer)",
        "RAT (e.g., AsyncRAT, ValleyRAT)",
        "Keylogger (e.g., SnakeKeylogger)",
        "CoinMiner",
        "Worm (e.g., XWorm)",
        "AgentTesla",
        "Nebula",
        "GCleaner"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Gemini 2.5 Pro (fine-tuned)",
        "novel_contribution": "Automated decompilation-driven pipeline (Ghidra -> C) with LLM-based classification; supervised fine-tuning on curated malware/benign C code."
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Gemini 2.5 Pro (vanilla)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Llama 3.3 70B",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Codestral",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Claude 3.7 Sonnet",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost",
        "novel_contribution": "Trained on static analysis features from baseline dataset (1,200 samples)."
      }
    ],
    "learning_paradigm": [
      "Zero-shot prompting",
      "Supervised",
      "Supervised fine-tuning",
      "Transfer learning"
    ],
    "datasets": [
      {
        "name": "Malware Data Science book dataset (2017 VirusTotal Windows executables)",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MalwareBazaar 2025 malware subset (120 samples, 49 families)",
        "type": "public",
        "domain": "malware_binaries",
        "link": "https://malwarebazaar.com",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Contemporary 2025 benign system drivers and low-level utilities (28 executables)",
        "type": "private",
        "domain": "software_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Static analysis feature set derived from baseline dataset (1,200 samples) for XGBoost",
        "type": "private",
        "domain": "static_features",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "XGBoost (static features)",
        "paper_reference": null,
        "metric": "Accuracy on 2017 dataset",
        "their_result": "Gemini 2.5 Pro (vanilla): 80.1%",
        "baseline_result": "XGBoost: 98.5%"
      },
      {
        "method_name": "XGBoost (static features)",
        "paper_reference": null,
        "metric": "Precision/Recall/F1 on 2017 dataset",
        "their_result": "Gemini 2.5 Pro (vanilla): P=83.5%, R=74.4%, F1=78.7%",
        "baseline_result": "XGBoost: P=95.6%, R=100%, F1=97.7%"
      },
      {
        "method_name": "Claude 3.7 Sonnet (vanilla)",
        "paper_reference": null,
        "metric": "Accuracy on 2017 dataset",
        "their_result": "Gemini 2.5 Pro (vanilla): 80.1%",
        "baseline_result": "Claude 3.7 Sonnet: 62.2%"
      },
      {
        "method_name": "Llama 3.3 70B (vanilla)",
        "paper_reference": null,
        "metric": "Accuracy on 2017 dataset",
        "their_result": "Gemini 2.5 Pro (vanilla): 80.1%",
        "baseline_result": "Llama 3.3 70B: 48.1%"
      },
      {
        "method_name": "Codestral (vanilla)",
        "paper_reference": null,
        "metric": "Accuracy on 2017 dataset",
        "their_result": "Gemini 2.5 Pro (vanilla): 80.1%",
        "baseline_result": "Codestral: 58.1%"
      },
      {
        "method_name": "XGBoost (static features)",
        "paper_reference": null,
        "metric": "Accuracy on 2025 dataset",
        "their_result": "Gemini 2.5 Pro (fine-tuned): 83.2%",
        "baseline_result": "XGBoost: 74.3%"
      },
      {
        "method_name": "XGBoost (static features)",
        "paper_reference": null,
        "metric": "Precision/Recall/F1 on 2025 dataset",
        "their_result": "Gemini 2.5 Pro (fine-tuned): P=94.4%, R=84.2%, F1=89.0%",
        "baseline_result": "XGBoost: P=81.5%, R=88.3%, F1=84.8%"
      },
      {
        "method_name": "Gemini 2.5 Pro (vanilla)",
        "paper_reference": null,
        "metric": "Accuracy/Precision/Recall/F1 on 2025 dataset",
        "their_result": "Gemini 2.5 Pro (fine-tuned): Acc=83.2%, P=94.4%, R=84.2%, F1=89.0%",
        "baseline_result": "Gemini 2.5 Pro (vanilla): Acc=64.2%, P=94.7%, R=59.1%, F1=72.8%"
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall",
      "F1-score",
      "confusion matrix"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How effective are state-of-the-art LLMs at classifying decompiled executable code as benign or malicious?",
        "Does supervised fine-tuning on curated malware/benign code improve LLM performance for malware detection?",
        "How well do LLMs (vanilla vs. fine-tuned) generalize to newer, contemporary malware families?",
        "What are practical constraints (e.g., context windows, cost) and operational needs (e.g., continuous fine-tuning) for deployment?"
      ],
      "gaps_identified": [
        "Prior work often used hypothetical data or lacked real-world applicability for malware classification with LLMs.",
        "Industry byte-level transformer approaches lack methodological transparency and independent validation.",
        "LLMs face context window limits and non-determinism; high costs and reliance on prompt engineering impede scalability.",
        "Explainability/interpretability remains a key challenge for security adoption."
      ],
      "limitations": [
        "Token/context limits forced use of only smaller decompiled samples; subset selection varied across LLMs.",
        "Standard (vanilla) LLMs underperform compared to traditional ML on known (2017) data.",
        "Even fine-tuned LLM performance degrades on newer malware, requiring continuous updates.",
        "Context window limitations (“lost-in-the-middle”) affect long code analysis.",
        "Cost and practical constraints for long-context processing and frequent fine-tuning."
      ],
      "future_work": [
        "Integrate dynamic execution traces, sandbox results, and provenance metadata into a hybrid analysis with cross-modal fusion.",
        "Develop efficient long-context processing (hierarchical chunking, adaptive attention, memory-augmented architectures).",
        "Pursue domain-adaptive pretraining/PEFT on curated cybersecurity corpora.",
        "Explore end-to-end LLM-based decompilation to replace Ghidra in the pipeline.",
        "Improve explainability to support analyst trust and compliance."
      ],
      "motivation": "Bridge reverse engineering and LLM code understanding to enable practical malware classification using real-world datasets, and assess whether fine-tuned LLMs can complement or replace traditional approaches.",
      "potential_research_ideas": [
        "Continual/online fine-tuning with concept drift detection for evolving malware families.",
        "Hybrid static+dynamic multimodal classifier combining decompiled code, PE metadata, API call graphs, and sandbox IOCs.",
        "Function-level or module-level multi-instance learning to aggregate local decisions for large binaries.",
        "Program-structure aware prompting using AST/CFG/DFG extracted from decompilation to guide LLM attention.",
        "Memory-augmented retrieval over decompiled chunks with iterative summarization and verification.",
        "Adversarial robustness evaluation against obfuscation, packing, and prompt-based evasion; robust training strategies.",
        "Lightweight, on-edge distilled models for triage with server-side escalation.",
        "Weak supervision via YARA/rules to scale labels for SFT/RLHF.",
        "Secure tool-use agents that invoke reverse-engineering tools (e.g., Ghidra scripts) during reasoning."
      ],
      "architectural_improvement_recommendations": [
        "Hierarchical chunking with progressive summarization and context propagation across code sections.",
        "Adaptive attention that prioritizes high-salience regions (e.g., suspicious APIs, encryption routines).",
        "Fusion model combining LLM embeddings of code with classical static features (ensemble or late fusion).",
        "Parameter-efficient fine-tuning (LoRA/IA3) on continuously curated malware corpora to reduce cost.",
        "Graph-enhanced encoding of AST/CFG/DFG to inform the LLM via structured prompts or GNN-LLM hybrids.",
        "Calibrated decision thresholds with uncertainty estimation and abstention for analyst-in-the-loop workflows."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Ghidra",
        "Google Vertex AI",
        "XGBoost"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Supervised fine-tuning of Gemini 2.5 Pro on Google Cloud Vertex AI over 40 epochs; constrained by LLM token limits; specific hardware/costs not reported."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Context window/token limits for long decompiled code.",
        "Need for continuous fine-tuning to handle evolving malware.",
        "Cost of long-context processing and model tuning.",
        "Explainability and analyst trust/regulatory requirements.",
        "Operational safety: malware handling and quarantining procedures."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a decompilation-driven pipeline (Ghidra to C) for LLM-based malware vs. benign classification.",
      "Empirical evaluation of multiple vanilla LLMs (Gemini 2.5 Pro, Llama 3.3 70B, Codestral, Claude 3.7 Sonnet) against a traditional XGBoost baseline.",
      "Demonstrates significant gains from supervised fine-tuning of Gemini 2.5 Pro on curated malware/benign code.",
      "Shows degradation on newer malware and argues for continuous fine-tuning to track evolving threats.",
      "Standardized zero-shot prompt and evaluation protocol; use of real malware from MalwareBazaar and benign system drivers for practical relevance.",
      "Operational handling guidance for malware (quarantining, isolated VMs) for safe experimentation."
    ]
  },
  {
    "arxiv_id": "2601.09029v1",
    "title": "Proactively Detecting Threats: A Novel Approach Using LLMs",
    "authors": "Aniesh Chawla; Udbhav Prasad",
    "abstract": "Enterprise security faces escalating threats from sophisticated malware, compounded by expanding digital operations. This paper presents the first systematic evaluation of large language models (LLMs) to proactively identify indicators of compromise (IOCs) from unstructured web-based threat intelligence sources, distinguishing it from reactive malware detection approaches. We developed an automated system that pulls IOCs from 15 web-based threat report sources to evaluate six LLM models (Gemini, Qwen, and Llama variants). Our evaluation of 479 webpages containing 2,658 IOCs (711 IPv4 addresses, 502 IPv6 addresses, 1,445 domains) reveals significant performance variations. Gemini 1.5 Pro achieved 0.958 precision and 0.788 specificity for malicious IOC identification, while demonstrating perfect recall (1.0) for actual threats.",
    "published_date": "2026-01-13",
    "pdf_link": "https://arxiv.org/pdf/2601.09029v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Threat Intelligence",
      "subdomain": "CTI automation and IOC extraction/classification",
      "specific_problem": "Proactive identification and binary classification of Indicators of Compromise (IPv4, IPv6, domains) from unstructured web-based threat reports using LLMs with full-page context",
      "attack_types": [
        "malware infrastructure",
        "command-and-control (C2) indicators",
        "general cyber threats"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Prompting / Instruction-following",
        "specific": "Zero-shot binary classification with a constrained True/False prompt over full webpage context",
        "novel_contribution": "Systematic evaluation setup that feeds the entire scraped webpage text as context and constrains output to True/False for IOC classification"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Gemini 1.5 Pro",
        "novel_contribution": "Evaluated for IOC detection; reported precision 0.958, specificity 0.788, recall 1.0 for malicious IOCs"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Gemini 2.0 Flash-Lite",
        "novel_contribution": "Evaluated for IOC detection; confusion matrix reported"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Qwen3 30B",
        "novel_contribution": "Evaluated for IOC detection; confusion matrix reported"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Qwen3 32B",
        "novel_contribution": "Evaluated for IOC detection; confusion matrix reported; described as worst performance among tested models"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Llama 8B",
        "novel_contribution": "Evaluated for IOC detection; confusion matrix reported"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Llama 70B",
        "novel_contribution": "Evaluated for IOC detection; confusion matrix reported"
      }
    ],
    "learning_paradigm": [
      "Zero-shot",
      "In-context learning",
      "Prompt-based inference"
    ],
    "datasets": [
      {
        "name": "Web Threat Report Corpus (15 sources; 479 webpages; 2,658 IOCs: 711 IPv4, 502 IPv6, 1,445 domains)",
        "type": "private",
        "domain": "threat_intel_webpages",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Evaluation subset (303 indicators: 116 IPv4, 187 domains; 251 malicious)",
        "type": "private",
        "domain": "threat_intel_webpages",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "MITRE ATT&CK STIX 2.0 Knowledge Base",
        "type": "public",
        "domain": "tactics_techniques",
        "link": "https://attack.mitre.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Abuse.ch RSS feed (example source)",
        "type": "public",
        "domain": "threat_intel_feeds",
        "link": "https://abuse.ch/rss",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusTotal (used for maliciousness verification)",
        "type": "public",
        "domain": "malware_reputation",
        "link": "https://www.virustotal.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Gemini 2.0 Flash-Lite",
        "paper_reference": null,
        "metric": "Confusion matrix (TP, FP, TN, FN); precision/recall/specificity qualitative",
        "their_result": "Gemini 1.5 Pro: \"0.958 precision\"; \"0.788 specificity\"; \"perfect recall (1.0)\"; Confusion matrix TP=251, FP=11, TN=41, FN=0",
        "baseline_result": "Gemini 2.0 Flash-Lite: Confusion matrix TP=246, FP=16, TN=36, FN=5"
      },
      {
        "method_name": "Qwen3 30B",
        "paper_reference": null,
        "metric": "Confusion matrix (TP, FP, TN, FN)",
        "their_result": "Gemini 1.5 Pro: TP=251, FP=11, TN=41, FN=0",
        "baseline_result": "Qwen3 30B: TP=170, FP=31, TN=21, FN=81"
      },
      {
        "method_name": "Qwen3 32B",
        "paper_reference": null,
        "metric": "Confusion matrix (TP, FP, TN, FN); F1-score qualitative",
        "their_result": "Gemini 1.5 Pro: TP=251, FP=11, TN=41, FN=0",
        "baseline_result": "Qwen3 32B: TP=239, FP=51, TN=1, FN=12; described as having \"low F1-score\""
      },
      {
        "method_name": "Llama 8B",
        "paper_reference": null,
        "metric": "Confusion matrix (TP, FP, TN, FN)",
        "their_result": "Gemini 1.5 Pro: TP=251, FP=11, TN=41, FN=0",
        "baseline_result": "Llama 8B: TP=214, FP=23, TN=29, FN=37"
      },
      {
        "method_name": "Llama 70B",
        "paper_reference": null,
        "metric": "Confusion matrix (TP, FP, TN, FN); recall qualitative",
        "their_result": "Gemini 1.5 Pro: TP=251, FP=11, TN=41, FN=0",
        "baseline_result": "Llama 70B: TP=251, FP=18, TN=34, FN=0; text notes higher false negatives on non-malicious class"
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall",
      "specificity",
      "F1-score",
      "confusion matrix (TP, FP, TN, FN)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can pre-trained LLMs proactively identify IOCs from unstructured web-based threat intelligence by using full-page context?",
        "How do different LLM architectures (Gemini, Qwen, Llama) compare on precision, recall, specificity and error profiles for IOC classification?",
        "What types of indicators (IP vs. domains) and contextual patterns lead to false positives/negatives in LLM-based IOC detection?",
        "Can an automated multi-source pipeline scale to aggregate and parse heterogeneous CTI webpages for LLM-based classification?"
      ],
      "gaps_identified": [
        "Lack of Proactive Detection: Most approaches operate reactively i.e. detecting threats after compromise.",
        "Limited Multi-Source Integration: Systems typically process single source types, lacking unified approaches for diverse threat intelligence.",
        "Inadequate Context-Aware Classification: Methods struggle with contextual understanding needed to distinguish malicious from benign indicators.",
        "Evaluation Limitations: Limited systematic evaluation across multiple LLM architectures and real-world sources.",
        "Scalability Challenges: Manual processes that do not scale to modern threat intelligence volume."
      ],
      "limitations": [
        "Models were constrained to rely solely on parsed webpage text; no external tools or lookups during inference.",
        "Focus on IP addresses and domains; hashes largely ignored due to near-zero false positives.",
        "Models often misclassify domain-type indicators due to name semantics and registrar mentions.",
        "False positives from context such as examples, registrar references, and 'Further Reading' sections.",
        "No fine-tuning was performed; all models used as pre-trained zero-shot classifiers.",
        "Heterogeneous, non-standardized CTI webpages complicate parsing and ground-truthing.",
        "Dataset and code are not released, limiting independent replication."
      ],
      "future_work": [
        "Extend parsing beyond HTML to PDF, Microsoft Word, and RTF.",
        "Add image analysis to extract indicators from screenshots (e.g., Wireshark).",
        "Expand to additional indicator types (TTPs, groups, nation states, filenames, versions, registry keys, mutexes).",
        "Fine-tune models to better distinguish benign registrar context and example strings from true IOCs."
      ],
      "motivation": "Escalating enterprise malware threats and costs; need to transition from reactive malware detection to proactive IOC identification using AI/LLMs across diverse, unstructured web CTI sources.",
      "potential_research_ideas": [
        "Fine-tune a domain-specific CTI LLM for IOC extraction/classification with curated negative examples (registrars, examples, references).",
        "RAG-enhanced IOC classification using external CTI KBs (MITRE ATT&CK, AbuseIPDB, VT) to reduce context-induced false positives.",
        "Multi-task learning for joint IOC typing (IP/domain/hash/etc.) and maliciousness classification with hierarchical labels.",
        "Active learning with analyst-in-the-loop to iteratively reduce false positives on domains and benign-context strings.",
        "Contrastive learning or weak supervision to disambiguate example text vs. actual IOCs within webpages.",
        "Evaluate robustness to prompt injection and adversarial CTI content poisoning in web pages.",
        "Multimodal pipeline that fuses OCR/image models with text LLMs for screenshot-derived indicators.",
        "Cross-source deduplication and consensus scoring of IOCs aggregated from multiple reports.",
        "Temporal modeling of IOC lifecycles to prioritize fresh, likely-active indicators."
      ],
      "architectural_improvement_recommendations": [
        "Two-stage system: (1) NER-style IOC candidate extraction with pattern+ML, (2) context-aware LLM classifier with calibrated thresholding.",
        "RAG with tool access (reputation APIs: VirusTotal/AbuseIPDB/Whois) to augment context and verify suspicious domains.",
        "Structured decoding or function calling to output IOC type, location in text, supporting evidence spans, and confidence.",
        "Model ensembling (vendor/model diversity) with disagreement-based triage to analysts.",
        "Domain-aware negative mining (registrars, example tokens, code blocks, 'Further Reading') during fine-tuning.",
        "Chunking and retrieval of webpage sections to avoid spurious context (e.g., references) influencing classification."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Non-standardized CTI webpage formats; variable indicator presentations (images, code blocks, defanged text).",
        "Fragmented STIX/TAXII adoption and redundancy across providers.",
        "High false positives on domains and benign-context strings (registrars, examples, references).",
        "Necessity to process high-volume, diverse sources reliably.",
        "Limited modality coverage (text-only) omits indicators embedded in images/PDFs."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Automated multi-source pipeline to crawl CTI RSS feeds, parse webpages, regex-extract IOC candidates, enrich with MITRE ATT&CK entities, and index data.",
      "First systematic evaluation of multiple LLMs (Gemini, Qwen, Llama variants) for proactive IOC identification from unstructured web CTI.",
      "New corpus assembled from 15 providers (479 webpages; 2,658 IOCs) and evaluated subset (303 indicators).",
      "Reported detailed confusion matrices for six LLMs and key metrics; e.g., \"Gemini 1.5 Pro achieved 0.958 precision and 0.788 specificity ... perfect recall (1.0).\"",
      "Empirical analysis of common error modes, especially domain-type misclassifications and context-induced false positives.",
      "Outlined future work for multimodal parsing and expansion to richer IOC types."
    ]
  },
  {
    "arxiv_id": "2601.11447v1",
    "title": "IMS: Intelligent Hardware Monitoring System for Secure SoCs",
    "authors": "Wadid Foudhaili; Aykut Rencber; Anouar Nechi; Rainer Buchty; Mladen Berekovic; Andres Gomez; Saleh Mulhem",
    "abstract": "In the modern Systems-on-Chip (SoC), the Advanced eXtensible Interface (AXI) protocol exhibits security vulnerabilities, enabling partial or complete denial-of-service (DoS) through protocol-violation attacks. The recent countermeasures lack a dedicated real-time protocol semantic analysis and evade protocol compliance checks. This paper tackles this AXI vulnerability issue and presents an intelligent hardware monitoring system (IMS) for real-time detection of AXI protocol violations. IMS is a hardware module leveraging neural networks to achieve high detection accuracy. For model training, we perform DoS attacks through header-field manipulation and systematic malicious operations, while recording AXI transactions to build a training dataset. We then deploy a quantization-optimized neural network, achieving 98.7% detection accuracy with <=3% latency overhead, and throughput of >2.5 million inferences/s. We subsequently integrate this IMS into a RISC-V SoC as a memory-mapped IP core to monitor its AXI bus. For demonstration and initial assessment for later ASIC integration, we implemented this IMS on an AMD Zynq UltraScale+ MPSoC ZCU104 board, showing an overall small hardware footprint (9.04% look-up-tables (LUTs), 0.23% DSP slices, and 0.70% flip-flops) and negligible impact on the overall design's achievable frequency. This demonstrates the feasibility of lightweight, security monitoring for resource-constrained edge environments.",
    "published_date": "2026-01-16",
    "pdf_link": "https://arxiv.org/pdf/2601.11447v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "SoC/On-chip Interconnect Security",
      "specific_problem": "Real-time detection of AXI protocol-violation attacks that cause availability/DoS in SoCs using a lightweight ML hardware monitor",
      "attack_types": [
        "Denial-of-Service (DoS)",
        "Resource starvation",
        "Protocol-level violations (AXI)",
        "Illegal burst length (AWLEN > 15)",
        "Transaction ID reuse (ARID duplication)",
        "QoS signal flooding (AWQOS = 0xF)",
        "Invalid AWSIZE",
        "ARRPROT violation",
        "Mixed attack patterns"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "MLP (Fully Connected Neural Network)",
        "specific": "Two hidden layers (32 neurons each, ReLU) with sigmoid output",
        "novel_contribution": "Quantization-aware and sparsity-pruned MLP deployed as an on-chip AXI monitor with AXI-Stream integration via HLS4ML for real-time inference on FPGA/SoC"
      },
      {
        "type": "primary",
        "category": "Quantization-aware training",
        "specific": "QKeras <8,5> weights",
        "novel_contribution": "Maintains or slightly improves detection vs Float32 while drastically reducing DSP usage (99.5% reduction)"
      },
      {
        "type": "primary",
        "category": "Model compression / pruning",
        "specific": "80% sparsity pruning",
        "novel_contribution": "Reduces hardware resources without degrading recall (100% reported for selected quantization setting)"
      },
      {
        "type": "baseline",
        "category": "MLP (Float32)",
        "specific": "Unquantized baseline model",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Dimensionality reduction",
        "specific": "PCA (4/6/8 components for 90/95/97% variance)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Data preprocessing",
        "specific": "Correlation analysis for feature selection (52 → 22 features)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Data augmentation / class balancing",
        "specific": "SMOTE",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "IMS AXI bus header transactions dataset",
        "type": "public",
        "domain": "axi_bus_transactions",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "IMS (Baseline Float32 MLP) vs IMS (Quantized <8,5>)",
        "paper_reference": null,
        "metric": "Accuracy (%)",
        "their_result": "99.1 (Quantized <8,5>)",
        "baseline_result": "98.9 (Float32)"
      },
      {
        "method_name": "IMS (Baseline Float32 MLP) vs IMS (Quantized <8,5>)",
        "paper_reference": null,
        "metric": "Precision (%)",
        "their_result": "95.8",
        "baseline_result": "94.9"
      },
      {
        "method_name": "IMS (Baseline Float32 MLP) vs IMS (Quantized <8,5>)",
        "paper_reference": null,
        "metric": "Recall (%)",
        "their_result": "99.99",
        "baseline_result": "99.99"
      },
      {
        "method_name": "IMS (Baseline Float32 MLP) vs IMS (Quantized <8,5>)",
        "paper_reference": null,
        "metric": "F1 (%)",
        "their_result": "97.9",
        "baseline_result": "97.4"
      },
      {
        "method_name": "Quantization level comparison",
        "paper_reference": null,
        "metric": "Accuracy/Precision/Recall/F1 (%)",
        "their_result": "See Table II: <8,5>=Acc 99.1, Pr 95.8, R 99.99, F1 97.9; <8,3>=98.7/94.2/99.99/97.0; <8,1>=97.3/91.8/99.99/95.7; <2,0>=85.2/78.9/92.1/85.0",
        "baseline_result": "Float32=Acc 98.9, Pr 94.9, R 99.99, F1 97.4"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "AUC-ROC",
      "Latency overhead (%)",
      "Inference latency (ms)",
      "Throughput (inferences/s)",
      "FPGA resource utilization (LUTs/DSP/FF/BRAM)",
      "Clock frequency (MHz)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can an ML-based hardware monitor detect AXI protocol-violation DoS attacks in real time on-chip with low latency overhead?",
        "What feature engineering and model optimizations (PCA, quantization, pruning) enable high detection accuracy with minimal FPGA/SoC resource usage?",
        "Is it feasible to integrate a neural anomaly detector as a memory-mapped IP core in a RISC-V SoC with negligible performance impact?"
      ],
      "gaps_identified": [
        "Existing countermeasures lack dedicated real-time protocol semantic analysis and evade protocol compliance checks.",
        "Access control and MPU-based approaches cannot detect malicious behavior that uses legitimate access patterns to violate protocol semantics.",
        "Absence of publicly available AXI security datasets and benchmarks for protocol-level security research in SoC environments."
      ],
      "limitations": [
        "Focus limited to availability-violation threats (DoS) rather than confidentiality or integrity attacks.",
        "Evaluation scoped to AXI protocol and a finite set of synthesized attack scenarios (e.g., AWLEN overflow, ARID duplication, AWQOS flooding).",
        "Demonstration on FPGA (ZCU104) with initial assessment for later ASIC integration; no ASIC implementation yet.",
        "Generalization to different AXI interconnect implementations and SoC platforms not empirically validated."
      ],
      "future_work": [
        "Initial assessment for later ASIC integration suggests a path to ASIC implementation.",
        "Expanding datasets and benchmarks for protocol-level security in SoC environments (implied by releasing the dataset to address the gap)."
      ],
      "motivation": "AXI protocol implementation flaws enable protocol-level DoS that evade current MPU/ACP protections; a lightweight, real-time, protocol-aware ML monitor deployed in hardware can close this gap.",
      "potential_research_ideas": [
        "Extend detection to confidentiality/integrity violations (e.g., unauthorized data access patterns, payload manipulations) alongside availability attacks.",
        "Develop temporal/sequential models (RNNs, Temporal CNNs, Transformers) to capture cross-transaction dependencies and timing anomalies on AXI channels.",
        "Investigate unsupervised/one-class anomaly detection to detect novel protocol abuses without labeled attacks.",
        "Cross-protocol generalization to AXI3/ACE/CHI and vendor-specific interconnects; build multi-protocol training datasets.",
        "Design active response/mitigation strategies (rate limiting, dynamic isolation, on-chip reconfiguration) co-designed with the monitor.",
        "Adversarial robustness analysis against ML evasion on structured tabular bus features; certify via formal robustness or randomized smoothing.",
        "Federated or continual learning across devices to adapt to workload drift while preserving on-chip privacy.",
        "Combine protocol semantics with on-chip performance counters for multi-sensor fusion to improve precision and reduce false alarms."
      ],
      "architectural_improvement_recommendations": [
        "Incorporate temporal context via sliding windows and sequence encoders (e.g., lightweight GRU or Temporal Convolution) while preserving HLS synthesizeability.",
        "Adopt mixed-precision quantization (per-layer or per-channel) to push below <8,5> while retaining accuracy; explore integer-only inference.",
        "Embed feature extraction in hardware (on-the-fly PCA or learned linear projection) to reduce preprocessing overhead and latency.",
        "Pipeline parallelism and tiling in HLS with pragmatic reuse factors to trade LUT/FF usage for higher throughput under peak loads.",
        "Implement on-chip calibration and threshold adaptation to handle workload drift and different SoC fabrics.",
        "Integrate explainability hooks (e.g., feature attribution via gradient-free methods compatible with quantized models) to aid validation and debugging."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "TensorFlow/Keras",
        "QKeras",
        "hls4ml",
        "Vivado HLS",
        "Vivado ILA",
        "scikit-learn (PCA)",
        "imbalanced-learn (SMOTE)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "FPGA: AMD Zynq UltraScale+ MPSoC ZCU104 at 250 MHz; inference latency ~1.523–1.612 ms per sample (reported) with throughput ~2.45–2.57 million inferences/s; resource usage (Quantized model): 9.04% LUTs, 0.23% DSPs (4/1728), 0.70% FFs, 2.56% BRAM."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "RISC-V SoC on AMD Zynq UltraScale+ MPSoC ZCU104 FPGA; integrated as AXI-Stream, memory-mapped IP core",
      "scalability_discussed": true,
      "inference_time": "1.523–1.612 ms per inference (reported) with >2.44M inferences/s throughput across 10–100% AXI bus load",
      "deployment_challenges": [
        "Maintaining low resource footprint and latency overhead on resource-constrained edge SoCs",
        "Generalizing across different AXI interconnect implementations and workloads",
        "Transitioning from FPGA prototype to ASIC integration",
        "Ensuring coverage of diverse protocol-violation patterns beyond synthesized scenarios"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces IMS: an intelligent hardware monitoring system for real-time detection of AXI protocol violations causing DoS.",
      "Builds a labeled AXI bus header transactions dataset (19,625 transactions: 16,383 normal, 3,242 malicious) and releases it publicly.",
      "Quantization-optimized neural network achieving “98.7% detection accuracy with <=3% latency overhead, and throughput of >2.5 million inferences/s.”",
      "Deploys IMS as a memory-mapped IP in a RISC-V SoC; demonstrates FPGA implementation on ZCU104 with small footprint: “9.04% LUTs, 0.23% DSP slices, and 0.70% flip-flops” and negligible frequency impact (250 MHz).",
      "Demonstrates high attack-specific detection (e.g., AWLEN overflow 100% detection; mixed patterns >98%).",
      "Provides a complete methodology: signal encoding, correlation-based feature selection (52→22), PCA (4/6/8 components for 90/95/97% variance), supervised MLP training, QAT with QKeras, 80% sparsity pruning, and HLS4ML deployment."
    ]
  },
  {
    "arxiv_id": "2601.01054v1",
    "title": "Out-of-Band Power Side-Channel Detection for Semiconductor Supply Chain Integrity at Scale",
    "authors": "Rajiv Thummala; Katherine Winton; Luke Flores; Elizabeth Redmond; Gregory Falco",
    "abstract": "Out-of-band screening of microcontrollers is a major gap in semiconductor supply chain security. High-assurance techniques such as X-ray and destructive reverse engineering are accurate but slow and expensive, hindering comprehensive detection for hardware Trojans or firmware tampering. Consequently, there has been increased interest in applying machine learning techniques to automate forensic examination, enabling rapid, large-scale inspection of components without manual oversight. We introduce a non-destructive screening method that uses power side-channel measurements and generative modeling to detect tampering in commodity microcontrollers without trusted hardware. As a proof-of-concept, differential power analysis (DPA) traces are collected from the ChipWhisperer and a generative adversarial network (GAN) is trained only on benign measurements to learn nominal power behavior. The trained discriminator then serves as a one-class anomaly detector. We report detection performance on multiple tampering scenarios and discuss how this technique can serve as an intermediate screening tier between basic functional tests and high-cost forensic analysis. The proposed method is evaluated in the context of semiconductor supply chain practice and policy to assess its suitability as an intermediate assurance mechanism.",
    "published_date": "2026-01-03",
    "pdf_link": "https://arxiv.org/pdf/2601.01054v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Supply Chain / Counterfeit and Trojan Detection",
      "specific_problem": "Non-destructive, out-of-band screening of commodity microcontrollers using power side-channel measurements to detect hardware Trojans and firmware tampering without trusted hardware",
      "attack_types": [
        "hardware_trojan_insertion",
        "firmware_tampering",
        "counterfeit_or_remarked_components"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GAN",
        "specific": null,
        "novel_contribution": "Train GAN only on benign power traces; use the trained discriminator as a one-class anomaly detector for supply-chain screening of microcontrollers"
      },
      {
        "type": "primary",
        "category": "One-class anomaly detection",
        "specific": "Discriminator-as-detector",
        "novel_contribution": "One-class detection on power side-channel traces to flag deviations from learned nominal behavior"
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "One-class",
      "Anomaly Detection"
    ],
    "datasets": [
      {
        "name": "ChipWhisperer-lite power side-channel traces of a commodity microcontroller executing a standardized workload (benign vs tampered scenarios)",
        "type": "private",
        "domain": "side_channel_power_traces",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can power side-channel measurements modeled with a GAN trained only on benign traces detect tampering in commodity microcontrollers without trusted hardware?",
        "Can such an approach serve as an intermediate, non-destructive screening tier between functional tests and high-cost forensic analysis in semiconductor supply chains?",
        "How does one-class generative modeling perform across multiple tampering scenarios for screening applications?"
      ],
      "gaps_identified": [
        "Lack of scalable, non-destructive screening methods for unit-level component integrity prior to integration",
        "High-assurance imaging/destructive methods are accurate but slow and expensive, limiting comprehensive screening",
        "Standard acceptance testing provides negligible protection against integrity modifications that preserve I/O behavior",
        "Existing side-channel detection literature often relies on EM measurements with repeatability challenges and on supervised learning that requires malicious labels",
        "Limited exploration of generative or one-class models for side-channel-based integrity verification"
      ],
      "limitations": [
        "The work is presented as a proof-of-concept using ChipWhisperer-collected traces; broader deployment conditions and large-scale variability are not detailed in the provided text"
      ],
      "future_work": [],
      "motivation": "Bridge the assurance discontinuity by providing a fast, non-destructive, design-agnostic screening mechanism that operates at supply-chain scale to flag potential hardware or firmware tampering.",
      "potential_research_ideas": [
        "Create a public benchmark of power side-channel traces across device families, lots, and environmental conditions for supply-chain screening",
        "Study cross-device and cross-lot generalization using domain adaptation or meta-learning for one-class side-channel detectors",
        "Evaluate robustness to workload variation; develop standardized screening workloads that maximize sensitivity to hidden Trojans/firmware changes",
        "Integrate multi-sensor fusion (power + EM) with calibration to improve detection while maintaining throughput",
        "Develop uncertainty-aware scoring and calibration (e.g., EVT-based thresholds) for operational decision-making and auditability",
        "Model adaptive adversaries that shape power signatures; use adversarial training or worst-case perturbation analysis to harden detectors",
        "Explore alternative generative models (VAE, normalizing flows, diffusion) and forecasting-based self-supervised objectives for time-series power traces",
        "Investigate explainability tools mapping anomaly scores to time-localized trace segments to aid triage and forensic follow-up"
      ],
      "architectural_improvement_recommendations": [
        "Adopt stabilized GAN variants (e.g., WGAN-GP) with 1D temporal CNN/ResNet discriminators for power time-series",
        "Combine reconstruction and discrimination (e.g., f-AnoGAN/AnoGAN) to use both residual and latent-space distances as anomaly scores",
        "Use temporal models (TCN or Transformer encoders) to capture longer-range dependencies in power traces",
        "Apply domain-adversarial training to learn device-invariant features for cross-device screening",
        "Implement robust preprocessing: trace alignment, normalization, filtering, and spectral features; consider DTW-based alignment",
        "Calibrate decision thresholds with Extreme Value Theory and per-lot/device normalization to control false positives",
        "Augment training with environmental/process noise models to improve robustness to PVT variations"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Incoming inspection, procurement, and depot workflows for semiconductor supply chains",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Must work on unmodified commercial devices without trusted features",
        "Time-per-unit must be compatible with manufacturing and maintenance throughput",
        "Requires auditable outputs that tie to risk decisions for compliance and policy",
        "Measurement repeatability and standardized workloads for consistent screening results"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a non-destructive power side-channel screening method for commodity microcontrollers using generative modeling without trusted hardware",
      "Trains a GAN solely on benign power traces and uses the discriminator as a one-class anomaly detector",
      "Collects DPA traces via ChipWhisperer-lite under a standardized workload and evaluates multiple tampering scenarios",
      "Positions and evaluates the method as an intermediate assurance tier between functional tests and high-cost forensic analysis within supply-chain practice and policy contexts"
    ]
  },
  {
    "arxiv_id": "2601.05988v1",
    "title": "CyberGFM: Graph Foundation Models for Lateral Movement Detection in Enterprise Networks",
    "authors": "Isaiah J. King; Bernardo Trindade; Benjamin Bowman; H. Howie Huang",
    "abstract": "Representing networks as a graph and training a link prediction model using benign connections is an effective method of anomaly-based intrusion detection. Existing works using this technique have shown great success using temporal graph neural networks and skip-gram-based approaches on random walks. However, random walk-based approaches are unable to incorporate rich edge data, while the GNN-based approaches require large amounts of memory to train. In this work, we propose extending the original insight from random walk-based skip-grams--that random walks through a graph are analogous to sentences in a corpus--to the more modern transformer-based foundation models. Using language models that take advantage of GPU optimizations, we can quickly train a graph foundation model to predict missing tokens in random walks through a network of computers. The graph foundation model is then finetuned for link prediction and used as a network anomaly detector. This new approach allows us to combine the efficiency of random walk-based methods and the rich semantic representation of deep learning methods. This system, which we call CyberGFM, achieved state-of-the-art results on three widely used network anomaly detection datasets, delivering a up to 2$\\times$ improvement in average precision. We found that CyberGFM outperforms all prior works in unsupervised link prediction for network anomaly detection, using the same number of parameters, and with equal or better efficiency than the previous best approaches.",
    "published_date": "2026-01-09",
    "pdf_link": "https://arxiv.org/pdf/2601.05988v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Unsupervised lateral movement detection via link prediction on enterprise network graphs",
      "attack_types": [
        "Lateral Movement",
        "Active Directory ESC1 certificate abuse (as contextual example)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT (bidirectional encoder)",
        "novel_contribution": "Pretraining a graph foundation model using scheduled masked token prediction on random walks (nodes and edge-feature tokens) for anomaly-based link prediction; then unsupervised fine-tuning (link prediction- or classification-based) for lateral movement detection"
      },
      {
        "type": "primary",
        "category": "Graph Foundation Model",
        "specific": null,
        "novel_contribution": "Extends DeepWalk’s sentence analogy to modern LLMs; treats random walks with edge-feature tokens as sequences for FM pretraining, enabling GPU-accelerated training and inference"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "GPT (causal decoder)",
        "novel_contribution": "Evaluated as an alternative to BERT; paper reports bidirectional attention from BERT is more beneficial than causal GPT for this task"
      },
      {
        "type": "baseline",
        "category": "Shallow embedding (skip-gram)",
        "specific": "word2vec/DeepWalk-style",
        "novel_contribution": "Referenced as prior approach using random walks with skip-gram; cannot incorporate rich edge data"
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": null,
        "novel_contribution": "Temporal/distributed GNNs from prior work used for link prediction but are memory intensive and often CPU-distributed, limiting GPU acceleration"
      }
    ],
    "learning_paradigm": [
      "Self-supervised",
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "LANL dataset",
        "type": "public",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Average Precision (AP)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How can graph analysis take advantage of recent advances in NLP?"
      ],
      "gaps_identified": [
        "Random walk skip-gram approaches cannot incorporate rich edge data",
        "GNN-based approaches require large memory and are often CPU-distributed, incurring communication overhead and missing GPU acceleration",
        "Prior GFM pretraining often uses expensive subgraph sampling; random walks are more efficient and scalable"
      ],
      "limitations": [
        "Timestamps are not tokenized as edge features to avoid a token explosion, potentially limiting explicit modeling of absolute time",
        "Direct node-ID tokenization is used for graphs under ~20k nodes; larger graphs may require multi-token schemes"
      ],
      "future_work": [],
      "motivation": "Detect lateral movement early by leveraging efficient random-walk sampling with rich contextual modeling from transformer-based FMs to improve anomaly-based link prediction while remaining GPU-efficient.",
      "potential_research_ideas": [
        "Incorporate explicit temporal encodings (e.g., relative/absolute time or time2vec) into tokens or positional encodings to better capture temporal dynamics without token explosion",
        "Pretrain a single GFM across multiple heterogeneous enterprise datasets (multi-tenant FM) and evaluate cross-domain transfer for lateral movement",
        "Introduce contrastive/self-distillation objectives alongside masked token prediction to improve robustness and representation quality",
        "Heterogeneous-entity modeling: add user, process, service, and file nodes with relation types and evaluate multi-relation lateral movement chains",
        "Online/streaming continual learning to adapt the GFM to evolving network baselines with drift detection",
        "Adversarial training or randomized smoothing against manipulation of edge features by attackers",
        "Explainability: attention- or path-based explanations for flagged anomalous edges to support SOC investigations"
      ],
      "architectural_improvement_recommendations": [
        "Add relative temporal position encodings between tokens within a walk and time-aware attention biases",
        "Use a dedicated edge-feature encoder (MLP or transformer) with feature-wise gating before fusion with node embeddings",
        "Employ longer-context efficient transformers (e.g., Performer/FlashAttention/linear attention) to capture longer walks or multi-walk contexts",
        "Multi-walk aggregation: attend across sets of walks anchored at the same node/edge to stabilize predictions",
        "Hybrid local-global modeling: lightweight GNN message passing over small temporal neighborhoods feeding the transformer encoder",
        "Curriculum masking schedules that emphasize rare protocols/ports/edge contexts to focus the model on suspicious patterns"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/cybermonic/CyberGFM",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Designed for GPU acceleration; avoids CPU-based distributed GNN training and multiprocessing"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Massive size of network data necessitates efficient sampling and GPU-friendly training/inference",
        "Prior GNN approaches suffer memory and CPU communication overhead; model addresses this but large graphs may still challenge tokenization and sequence lengths"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A novel LLM-based system (CyberGFM) that models lateral movement detection as next/masked token prediction on random walks with node and edge-feature tokens",
      "State-of-the-art anomaly detection: fine-tuned GFM outperforms four recent systems on three datasets; achieves 0.76 AP on LANL and up to 2x improvement in average precision",
      "Efficient GFM pretraining on random walks enabling GPU acceleration; shows finetuned pretrained models outperform training directly on the fine-tuning task"
    ]
  },
  {
    "arxiv_id": "2601.08959v1",
    "title": "Integrating APK Image and Text Data for Enhanced Threat Detection: A Multimodal Deep Learning Approach to Android Malware",
    "authors": "Md Mashrur Arifin; Maqsudur Rahman; Nasir U. Eisty",
    "abstract": "As zero-day Android malware attacks grow more sophisticated, recent research highlights the effectiveness of using image-based representations of malware bytecode to detect previously unseen threats. However, existing studies often overlook how image type and resolution affect detection and ignore valuable textual data in Android Application Packages (APKs), such as permissions and metadata, limiting their ability to fully capture malicious behavior. The integration of multimodality, which combines image and text data, has gained momentum as a promising approach to address these limitations. This paper proposes a multimodal deep learning framework integrating APK images and textual features to enhance Android malware detection. We systematically evaluate various image types and resolutions across different Convolutional Neural Networks (CNN) architectures, including VGG, ResNet-152, MobileNet, DenseNet, EfficientNet-B4, and use LLaMA-2, a large language model, to extract and annotate textual features for improved analysis. The findings demonstrate that RGB images at higher resolutions (e.g., 256x256, 512x512) achieve superior classification performance, while the multimodal integration of image and text using the CLIP model reveals limited potential. Overall, this research highlights the importance of systematically evaluating image attributes and integrating multimodal data to develop effective malware detection for Android systems.",
    "published_date": "2026-01-13",
    "pdf_link": "https://arxiv.org/pdf/2601.08959v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Mobile Malware Detection",
      "specific_problem": "Android APK malware detection via image-based and multimodal (image + text) deep learning, binary classification of benign vs malicious apps",
      "attack_types": [
        "Adware",
        "Scareware",
        "Banking malware",
        "SMS malware"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Multimodal Contrastive Model",
        "specific": "CLIP (zero-shot, no fine-tuning)",
        "novel_contribution": "Proposed framework integrating APK images with prompt-generated textual annotations and assessing CLIP for multimodal malware detection"
      },
      {
        "type": "primary",
        "category": "LLM",
        "specific": "LLaMA-2-7b-chat (metallama/Llama-2-7b-chat-hf)",
        "novel_contribution": "Used to extract and annotate APK textual features (permissions, strings, manifest) via prompts to create multimodal annotations"
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "VGG-16",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "VGG-19",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet-50",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet-101",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "ResNet-152",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN (Mobile)",
        "specific": "MobileNetV2",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "DenseNet-169",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": "EfficientNet-B4",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Transfer Learning",
      "Zero-shot"
    ],
    "datasets": [
      {
        "name": "CIC-AndMal2017",
        "type": "public",
        "domain": "android_apk_packages",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICMalDroid 2020",
        "type": "public",
        "domain": "android_apk_packages",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Multimodal APK images + LLaMA-2 text annotations (limited dataset)",
        "type": "proprietary",
        "domain": "malware_images_and_text_annotations",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "ResNet-50 (RGB, 512x512)",
        "paper_reference": null,
        "metric": "Accuracy / ROC AUC",
        "their_result": "96% accuracy; ROC AUC 0.9906",
        "baseline_result": null
      },
      {
        "method_name": "ResNet-101 (RGB, 512x512)",
        "paper_reference": null,
        "metric": "Accuracy / ROC AUC",
        "their_result": "97% accuracy; ROC AUC 0.9919",
        "baseline_result": null
      },
      {
        "method_name": "ResNet-152 (RGB, 512x512)",
        "paper_reference": null,
        "metric": "Accuracy / ROC AUC",
        "their_result": "96% accuracy; ROC AUC 0.9920",
        "baseline_result": null
      },
      {
        "method_name": "EfficientNet-B4 (RGB, 512x512)",
        "paper_reference": null,
        "metric": "Accuracy / ROC AUC",
        "their_result": "97% accuracy; ROC AUC 0.9949",
        "baseline_result": null
      },
      {
        "method_name": "CLIP multimodal (images + LLaMA-2 annotations, zero-shot)",
        "paper_reference": null,
        "metric": "Accuracy; class-wise Precision/Recall/F1",
        "their_result": "Accuracy 0.50; Benignware: Precision 0.50, Recall 1.00, F1 0.67; Malware: Precision 0.00, Recall 0.00, F1 0.00",
        "baseline_result": "Best image-only model ≥96–97% accuracy (e.g., ResNet-101/EfficientNet-B4)"
      },
      {
        "method_name": "HYDRA (text + image features, from prior work)",
        "paper_reference": "[8]",
        "metric": "Accuracy",
        "their_result": "This paper's best image-only accuracy: up to 97%",
        "baseline_result": "HYDRA reported >99% accuracy (dataset unspecified in this paper)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "ROC AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: How do different image processing techniques and resolutions (e.g., RGB vs. grayscale) impact the effectiveness of distinguishing between benign and malicious Android applications?",
        "RQ2: How does integrating image and textual data in a multimodal framework affect the performance of Android malware detection systems?"
      ],
      "gaps_identified": [
        "Existing studies often overlook how image type and resolution affect detection performance.",
        "Textual data in APKs (permissions, manifest, metadata) is frequently ignored by image-only approaches.",
        "The synergistic potential of combining image and text modalities for Android malware detection remains underexplored."
      ],
      "limitations": [
        "Multimodal experiment used a very limited dataset (34 images and 34 text annotations).",
        "CLIP was used without fine-tuning (nearly zero-shot), leading to poor malware detection (recall 0.00 for malware).",
        "No direct head-to-head comparison with prior state-of-the-art multimodal systems under identical datasets/splits.",
        "Availability and scale of the new multimodal dataset are currently limited."
      ],
      "future_work": [
        "Grow and enhance the multimodal dataset of APK images and textual annotations.",
        "Refine or fine-tune multimodal models (e.g., CLIP or alternatives) with sufficient domain data.",
        "Further empirical evaluation of image attributes and multimodal fusion strategies under varied resource constraints."
      ],
      "motivation": "Improve Android malware detection beyond traditional static/dynamic analysis and obfuscation resilience by systematically evaluating image attributes and exploring multimodal integration of APK images with textual metadata.",
      "potential_research_ideas": [
        "Create and release a large-scale, labeled multimodal APK dataset (images + rich textual features) to enable robust multimodal training and benchmarking.",
        "Train/fine-tune multimodal transformers (e.g., CLIP variants, BLIP-2, ViLT) specifically on APK image-text pairs to learn security-domain alignment.",
        "Explore fusion architectures (late fusion, cross-attention, gated fusion) combining CNN/Vision Transformer encoders with text encoders (LLM/BERT) for malware detection.",
        "Contrastive self-supervised pretraining on unlabeled APK corpora to align bytecode images with textual/metadata signals.",
        "Extend from binary detection to family/type classification (Adware/Banking/SMS/etc.) and multi-task setups (detection + family).",
        "Robustness studies against obfuscation/packing and adversarial perturbations on both image and text channels; develop defenses.",
        "On-device deployment via model compression/distillation from heavy multimodal models to lightweight MobileNet/ViT-tiny backbones.",
        "Ablations on image rendering schemes (e.g., different byte-to-pixel mappings, entropy/texture maps, multi-scale tiling) and text feature engineering (permissions/APIs/intent filters).",
        "Integrate static program analysis signals (CFG/call graph, API sequence embeddings) as a third modality for tri-modal fusion.",
        "Explainability tooling (e.g., attention heatmaps over image regions and salient permission/API terms) to aid analyst validation."
      ],
      "architectural_improvement_recommendations": [
        "Fine-tune CLIP (or similar multimodal encoders) on domain-specific APK image–text pairs instead of zero-shot usage.",
        "Adopt a late-fusion classifier trained over concatenated or cross-attended image and text embeddings rather than relying solely on CLIP similarity scores.",
        "Replace CNN backbones with Vision Transformers or hybrid CNN-Transformer backbones to capture long-range bytecode image patterns.",
        "Use a dedicated text encoder (e.g., a small BERT trained on manifest/permission sequences) instead of LLM-generated summaries for more stable supervised training.",
        "Employ class-balanced sampling, focal loss, or reweighting to address class-wise failure modes observed in multimodal results.",
        "Leverage multi-scale image inputs and attention pooling to capture both global structure and local byte patterns.",
        "Introduce data augmentation for both modalities (image jitter/tiling; text paraphrasing/noise) to improve generalization."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Hugging Face Transformers",
        "PyTorch",
        "PIL",
        "APKtools"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Training performed on a GPU; batch size 32; up to 20 epochs with early stopping (patience=5); Adam optimizer."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Resource constraints on edge/mobile environments motivate lower-resolution or lightweight models.",
        "Obfuscation in Android malware can challenge static/image-only features.",
        "Limited availability of large, labeled multimodal datasets hinders robust multimodal training."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Systematic evaluation of RGB vs. grayscale images at 128x128, 256x256, and 512x512 across eight CNN architectures for Android malware detection.",
      "A novel multimodal framework combining APK images with prompt-generated text annotations and evaluating CLIP for image–text classification.",
      "Provision of a limited multimodal dataset pairing attributed APK images with corresponding textual annotations.",
      "Empirical finding that higher-resolution RGB images (256x256, 512x512) generally outperform grayscale and that the zero-shot CLIP multimodal approach shows limited potential without fine-tuning and more data."
    ]
  },
  {
    "arxiv_id": "2601.06213v1",
    "title": "Cyber Threat Detection and Vulnerability Assessment System using Generative AI and Large Language Model",
    "authors": "Keerthi Kumar. M; Swarun Kumar Joginpelly; Sunil Khemka; Lakshmi. S R; Navin Chhibber",
    "abstract": "Background: Cyber-attacks have evolved rapidly in recent years, many individuals and business owners have been affected by cyber-attacks in various ways. Cyber-attacks include various threats such as ransomware, malware, phishing, and Denial of Service (DoS)-related attacks. Challenges: Traditional models such as Generative Artificial Intelligence (AI) and Security Bidirectional Encoder Representations from Transformers (BERT) were implemented to detect cyber threats. However, the existing Security BERT model has a limited contextual understanding of text data, which has less impact on detecting cyber-attacks. Proposed Methodology: To overcome the above-mentioned challenges, Robustly Optimized Bidirectional Encoder Representations from Transformers Pretraining Approach (RoBERTa) model is proposed which consists of diverse words of vocabulary understanding. Initially, data are extracted from a Packet Capture (PCAP) file and encrypted using Fully Harmonic Encryption (FHE). Subsequently, a Byte-level and Byte Pair Encoding (BBPE) tokenizer was used to generate tokens and help maintain the vocabulary for the encrypted values. Then, these values are applied to the RoBERTa model of the transformer with extensive training. Finally, Softmax is used for the detection and classification of attacks. The proposed RoBERTa model achieved better results than the existing BERT model in terms of accuracy (0.99), recall (0.91), and precision (0.89) respectively.",
    "published_date": "2026-01-08",
    "pdf_link": "https://arxiv.org/pdf/2601.06213v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT/IIoT Security",
      "subdomain": "Network Intrusion Detection",
      "specific_problem": "Multiclass detection and classification of 15 network-based cyber-attacks from IIoT PCAP traffic",
      "attack_types": [
        "Denial of Service (HTTP flood)",
        "Denial of Service (UDP flood)",
        "Denial of Service (TCP SYN flood)",
        "Denial of Service (ICMP flood)",
        "Man-in-the-Middle (DNS spoofing)",
        "Man-in-the-Middle (ARP spoofing)",
        "Information gathering (OS fingerprinting)",
        "Information gathering (Port scanning)",
        "Information gathering (Vulnerability scanning)",
        "Injection (SQL injection)",
        "Injection (File upload)",
        "Injection (Cross-site scripting, XSS)",
        "Malware (Ransomware)",
        "Malware (Backdoor)",
        "Malware (Password cracker)",
        "Benign/Normal traffic"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "RoBERTa",
        "novel_contribution": "Applies RoBERTa to BBPE-tokenized, FHE-encrypted PCAP-derived features for cyber threat detection; custom 4-encoder-layer configuration with Softmax for 15-class classification"
      },
      {
        "type": "primary",
        "category": "Tokenization/Preprocessing",
        "specific": "Byte-level Byte Pair Encoding (HuggingFace ByteLevel BPE)",
        "novel_contribution": "Maintains vocabulary for encrypted values to enable NLP processing of transformed PCAP features"
      },
      {
        "type": "primary",
        "category": "Privacy-preserving preprocessing",
        "specific": "Fully Harmonic Encryption (FHE)",
        "novel_contribution": "Transforms numeric features into textual representations prior to tokenization to preserve privacy and make inputs compatible with RoBERTa"
      },
      {
        "type": "primary",
        "category": "Embeddings",
        "specific": "word2vec",
        "novel_contribution": "Used as word embedding step before transformer encoding as described by authors"
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "ChatGPT 3.5-turbo (16k context)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "Falcon",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM (fine-tuned)",
        "specific": "Alpaca-LoRA",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Security BERT / BERT",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "Edge Industrial Internet of Things (Edge IIoT) dataset",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CVEfixes",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VCMatch",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Custom phishing email dataset (725k legit and phishing emails)",
        "type": "proprietary",
        "domain": "email_corpus",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "SoC security coding problems dataset (156 problems, Verilog/functional tasks)",
        "type": "proprietary",
        "domain": "hardware_design_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "ChatGPT 3.5-turbo (16k context)",
        "paper_reference": null,
        "metric": "Accuracy / Precision / Recall",
        "their_result": "0.99 / 0.91 / 0.89 (Proposed RoBERTa)",
        "baseline_result": "0.90 / 0.95 / 0.82"
      },
      {
        "method_name": "Falcon",
        "paper_reference": null,
        "metric": "Accuracy / Precision / Recall",
        "their_result": "0.99 / 0.91 / 0.89 (Proposed RoBERTa)",
        "baseline_result": "0.92 / 0.81 / 0.85"
      },
      {
        "method_name": "Alpaca-LoRA",
        "paper_reference": null,
        "metric": "Accuracy / Precision / Recall",
        "their_result": "0.99 / 0.91 / 0.89 (Proposed RoBERTa)",
        "baseline_result": "0.94 / 0.89 / 0.79"
      },
      {
        "method_name": "Security BERT / BERT",
        "paper_reference": "[11]",
        "metric": "Accuracy / Precision / Recall",
        "their_result": "0.99 / 0.91 / 0.89 (Proposed RoBERTa)",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy",
      "precision",
      "recall"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Existing Security BERT model has limited contextual understanding of text data, reducing impact on detecting cyber-attacks.",
        "Some LLMs are trained for a fixed period and are not up-to-date, making it difficult to detect phishing and non-phishing sites.",
        "PPFLE in prior work is a weak technique that can be used only by hackers (as critiqued in related work).",
        "Prior neural network approaches simply classify benign vs malicious without detecting specific threats."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve cyber threat detection accuracy and robustness over prior BERT/LLM approaches by addressing contextual understanding and privacy via FHE+BBPE and a RoBERTa-based architecture.",
      "potential_research_ideas": [
        "Evaluate the proposed pipeline across multiple public intrusion detection datasets (e.g., CIC-IDS, UNSW-NB15, BoT-IoT) for cross-dataset generalization.",
        "Ablation studies to quantify the contribution of FHE, BBPE, and each preprocessing step (text normalization, frequency filtering) to detection performance.",
        "Extend to multimodal fusion of packet payload bytes and flow-level statistical features using hybrid transformer–tabular architectures.",
        "Incorporate temporal/sequential modeling of session flows with transformer encoders over time windows to detect low-and-slow attacks.",
        "Integrate explainability (e.g., token/feature attributions) to highlight contributing fields/packets for analyst triage.",
        "Assess and harden adversarial robustness against evasion and poisoning tailored to the tokenized/encoded representation.",
        "Explore privacy guarantees with formal analysis or replacement of FHE variant with standard homomorphic encryption libraries and/or differential privacy training.",
        "Online/streaming inference with concept drift detection and continual learning for evolving IIoT threat landscapes."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment word2vec with RoBERTa’s native learned embeddings; fine-tune a domain-adapted RoBERTa on large unlabeled PCAP-derived corpora (masked language modeling) before supervised fine-tuning.",
        "Adopt hierarchical modeling: per-packet tokenization to per-flow aggregation using attention pooling or transformers over flows.",
        "Use tabular-transformer or hybrid networks that natively handle numeric/categorical features to avoid lossy encryption-to-text conversion.",
        "Introduce class-imbalance handling (focal loss, class weights) and calibrated decision thresholds; report per-class metrics.",
        "Leverage lightweight adapters/LoRA for efficient fine-tuning and enable model updating without full retraining.",
        "Add contrastive/self-supervised objectives (e.g., SimCLR-style on flows) to improve representation learning under limited labels.",
        "Model compression (quantization, pruning, distillation) for real-time IIoT deployment on edge GPUs/CPUs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "TensorFlow",
        "PyTorch"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Intel i7 CPU, ≥16 GB RAM, NVIDIA GTX 1080 GPU; Python with TensorFlow and PyTorch"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a RoBERTa-based cyber threat detection model trained on IIoT PCAP-derived features to classify 15 attack types plus benign traffic.",
      "Applies Fully Harmonic Encryption (FHE) to transform numeric/categorical PCAP features into textual representations for NLP tokenization.",
      "Uses Byte-level Byte Pair Encoding (BBPE) tokenizer to encode/decode encrypted values and maintain an effective vocabulary.",
      "Defines a preprocessing pipeline (padding, text normalization, tokenization, frequency filtering, vocabulary creation) to stabilize training.",
      "Reports improved performance over baseline LLMs (ChatGPT 3.5-turbo, Falcon, Alpaca-LoRA) with Accuracy 0.99, Precision 0.91, Recall 0.89 on Edge IIoT dataset."
    ]
  },
  {
    "arxiv_id": "2601.04486v1",
    "title": "Decision-Aware Trust Signal Alignment for SOC Alert Triage",
    "authors": "Israt Jahan Chowdhury; Md Abu Yousuf Tanvir",
    "abstract": "Detection systems that utilize machine learning are progressively implemented at Security Operations Centers (SOCs) to help an analyst to filter through high volumes of security alerts. Practically, such systems tend to reveal probabilistic results or confidence scores which are ill-calibrated and hard to read when under pressure. Qualitative and survey based studies of SOC practice done before reveal that poor alert quality and alert overload greatly augment the burden on the analyst, especially when tool outputs are not coherent with decision requirements, or signal noise. One of the most significant limitations is that model confidence is usually shown without expressing that there are asymmetric costs in decision making where false alarms are much less harmful than missed attacks. The present paper presents a decision-sensitive trust signal correspondence scheme of SOC alert triage. The framework combines confidence that has been calibrated, lightweight uncertainty cues, and cost-sensitive decision thresholds into coherent decision-support layer, instead of making changes to detection models. To enhance probabilistic consistency, the calibration is done using the known post-hoc methods and the uncertainty cues give conservative protection in situations where model certainty is low. To measure the model-independent performance of the suggested model, we apply the Logistic Regression and the Random Forest classifiers to the UNSW-NB15 intrusion detection benchmark. According to simulation findings, false negatives are greatly amplified by the presence of misaligned displays of confidence, whereas cost weighted loss decreases by orders of magnitude between models with decision aligned trust signals. Lastly, we describe a human-in-the-loop study plan that would allow empirically assessing the decision-making of the analysts with aligned and misaligned trust interfaces.",
    "published_date": "2026-01-08",
    "pdf_link": "https://arxiv.org/pdf/2601.04486v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "SOC alert triage decision support via decision-aware trust signal alignment (calibrated confidence, uncertainty cues, cost-sensitive thresholds)",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Cost-sensitive classification / Decision theory",
        "specific": "Decision-aware threshold t* = CFP / (CFP + CFN)",
        "novel_contribution": "Maps calibrated confidence and uncertainty cues to an explicit cost-sensitive decision policy with a safety override for high-uncertainty alerts"
      },
      {
        "type": "primary",
        "category": "Calibration",
        "specific": "Platt scaling (sigmoid) for Logistic Regression",
        "novel_contribution": "Uses post-hoc calibration as a trust-signal layer without modifying the underlying detector"
      },
      {
        "type": "primary",
        "category": "Calibration",
        "specific": "Isotonic Regression for Random Forest",
        "novel_contribution": "Improves probabilistic consistency used by the decision layer"
      },
      {
        "type": "primary",
        "category": "Uncertainty Estimation",
        "specific": "Distance-to-threshold banding (High: [0.45,0.55], Medium: [0.35,0.45)∪(0.55,0.65], Low: otherwise) on calibrated probabilities",
        "novel_contribution": "Lightweight uncertainty cues with a conservative safety rule to escalate high-uncertainty alerts even below the threshold"
      },
      {
        "type": "baseline",
        "category": "Linear Model",
        "specific": "Logistic Regression (probabilistic classifier)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble Trees",
        "specific": "Random Forest (probabilistic classifier)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "KDD99",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-IDS",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "C0 Default Threshold Interface (p ≥ 0.5)",
        "paper_reference": null,
        "metric": "False negatives (FN), False positives (FP), cost-weighted loss",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "C1 Misaligned Trust Interface (uncalibrated confidence; p ≥ 0.7 escalation)",
        "paper_reference": null,
        "metric": "False negatives",
        "their_result": "“misaligned confidence displays significantly increase false negatives”",
        "baseline_result": null
      },
      {
        "method_name": "C1 vs C2 (Proposed Aligned Trust)",
        "paper_reference": null,
        "metric": "Cost-weighted loss",
        "their_result": "“cost weighted loss decreases by orders of magnitude between models with decision aligned trust signals”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "False negatives (FN)",
      "False positives (FP)",
      "Cost-weighted loss (expected decision cost under CFN, CFP)",
      "Decision-aware threshold value (t* = CFP / (CFP + CFN))",
      "Reliability diagrams (qualitative calibration assessment)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does aligning trust signals (calibrated confidence, uncertainty cues) to asymmetric decision costs improve SOC alert triage outcomes?",
        "How do misaligned confidence displays affect false negatives and expected cost when underlying detection models are kept constant?"
      ],
      "gaps_identified": [
        "“The majority of the IDS studies focus on enhancing the accuracy of models at the model level, detection rate, or AUC… But the directions never seem to be united in a decision centric SOC setting.”",
        "“trust signals (confidence, calibration, uncertainty) are scarcely studied as modifying the triage decision and there is little empirical work on the existing systems that match the presented trust displays with actual cost models of missed attacks and false alarms.”",
        "Cost-sensitive reasoning is rarely manifested in trust indicators presented to users; thresholds are typically implicit rather than an explicit decision-support interface."
      ],
      "limitations": [
        "Evaluation is simulation-based on UNSW-NB15; no real SOC deployment or live analyst study yet.",
        "Only numerical features retained from UNSW-NB15 to minimize confounders.",
        "Underlying detectors limited to Logistic Regression and Random Forest; results may vary with other models.",
        "A fixed illustrative cost ratio (CFN=10, CFP=1) is used; organizational costs may differ."
      ],
      "future_work": [
        "“We also give out a human-in-the-loop study protocol so that future analyst assessment of SOC such as triage tasks can be made.”",
        "Extend the framework to arbitrary cost structures and organizational risk tolerances.",
        "Combine with model-agnostic explanations (e.g., SHAP/LIME) as supplementary context."
      ],
      "motivation": "Reduce analyst burden and missed attacks by aligning trust signals (confidence, calibration, uncertainty) with asymmetric SOC decision costs, addressing alert overload and miscalibrated outputs.",
      "potential_research_ideas": [
        "Personalized, dynamic cost modeling that adapts CFN/CFP per incident type, asset criticality, and analyst role.",
        "Integrate conformal prediction or selective classification to provide coverage guarantees and abstain/escale options.",
        "Online calibration under distribution shift (e.g., temperature scaling with drift detection) tailored to SOC streams.",
        "Learning-to-triage policies that incorporate analyst feedback via contextual bandits or reinforcement learning.",
        "Evaluate the framework with deep IDS models (e.g., GNNs, Transformers) and multi-modal telemetry.",
        "A/B test different uncertainty cue designs and visual encodings to measure impact on analyst decisions and workload.",
        "Adversarial robustness of calibration and uncertainty cues against manipulation of model scores."
      ],
      "architectural_improvement_recommendations": [
        "Replace fixed uncertainty bands with Bayesian uncertainty (e.g., MC dropout) or conformal p-values for principled uncertainty.",
        "Calibrate using temperature scaling or ensemble calibration and measure ECE/ACE to select calibrators per model.",
        "Implement selective classification with a reject option tied to cost-aware abstention thresholds.",
        "Learn decision thresholds from data under a cost-sensitive risk minimization rather than using a fixed analytic t*.",
        "Add drift detection and periodic re-calibration to maintain alignment under changing traffic/attack distributions.",
        "Integrate explanation panels (SHAP/LIME) contextually triggered only for high-uncertainty or borderline cases."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Defining and validating organization-specific cost models (CFN/CFP) for escalation decisions",
        "Integrating calibrated probabilities and uncertainty cues into existing SOC triage interfaces",
        "Maintaining calibration under distribution shift and evolving attack patterns",
        "Need for human-in-the-loop evaluation with analysts to validate decision impact"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A decision-aware trust signal alignment framework for SOC alert triage that ties trust signals to operational decision costs.",
      "Demonstrates that misaligned confidence displays can significantly increase false negatives even with fixed detection models.",
      "Proposes a cost-sensitive alignment mechanism using post-hoc calibration and uncertainty-sensitive safeguards for escalation decisions.",
      "Model-agnostic empirical validation on Logistic Regression and Random Forest using the UNSW-NB15 benchmark.",
      "Outlines a human-in-the-loop evaluation protocol for future analyst studies in SOC-style triage."
    ]
  },
  {
    "arxiv_id": "2601.06419v1",
    "title": "Lightweight Yet Secure: Secure Scripting Language Generation via Lightweight LLMs",
    "authors": "Keyang Zhang; Zeyu Chen; Xuan Feng; Dongliang Fang; Yaowen Zheng; Zhi Li; Limin Sun",
    "abstract": "The security of scripting languages such as PowerShell is critical given their powerful automation and administration capabilities, often exercised with elevated privileges. Today, securing these languages still demands substantial human effort to craft and enforce rules, imposing heavy burdens on typical administrators and creating critical production risks (e.g., misoperations that shut down servers).Large language models (LLMs) have demonstrated strong capabilities in code generation, vulnerability detection, and automated repair for languages like Python and JavaScript. However, their ability to assist with generating secure scripting-language code remains largely underexplored. In this paper, we present SecGenEval-PS, a benchmark designed to systematically evaluate LLMs on secure scripting generation, security analysis, and automated repair. Our results show that both proprietary and open-source models fall short in these areas. For instance, over 60% of PowerShell scripts produced by GPT-4o and o3-mini are insecure without structured guidance.To bridge this gap, we propose PSSec, a framework that combines data synthesis with fine-tuning to enhance model security capabilities. We develop a self-debugging agent that integrates static analyzers with the reasoning abilities of advanced LLMs to synthesize large-scale structured triplets of insecure scripts, violation analyses, and corresponding repairs. We then fine-tune lightweight LLMs (as small as 1.7B parameters) using supervised fine-tuning (SFT) and reinforcement learning (RL), enabling security-aware reasoning and the generation of secure PowerShell code.Across multiple LLM families, including GPT and Qwen, \\textit{PSSec}-trained models match or surpass general-purpose large models on PowerShell security tasks while reducing inference cost by more than an order of magnitude.",
    "published_date": "2026-01-10",
    "pdf_link": "https://arxiv.org/pdf/2601.06419v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software and Application Security",
      "subdomain": "Secure Code Generation and Analysis",
      "specific_problem": "Secure PowerShell scripting: generation, security auditing, and automated repair using LLMs",
      "attack_types": [
        "command injection",
        "unsafe deserialization",
        "plaintext credential handling",
        "privilege escalation risk",
        "remote code execution risk",
        "platform/API misuse",
        "insecure defaults and missing confirmations"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Qwen (e.g., Qwen-1.7B, Qwen-8B; Qwen3 series referenced)",
        "novel_contribution": "Security-aware fine-tuning for PowerShell via PSSec using structured triplets (insecure code, violation analysis, repair) to internalize PowerShell-specific security semantics"
      },
      {
        "type": "primary",
        "category": "Reinforcement Learning",
        "specific": "On-policy RL with static-analysis feedback",
        "novel_contribution": "Model learns from its own synthesized rollouts with rule-based/static-analyzer-guided rewards to improve secure-code reasoning and repair"
      },
      {
        "type": "primary",
        "category": "Agentic tool-use / Self-debugging",
        "specific": "Self-debugging agent integrating PSScriptAnalyzer with advanced LLM reasoning",
        "novel_contribution": "Automated synthesis of large-scale structured triplets of insecure scripts, violation analyses, and corresponding repairs"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "GPT-4o",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "o3-mini",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Qwen2.5 (baseline variants)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "DeepSeek (variants)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Reinforcement Learning"
    ],
    "datasets": [
      {
        "name": "SecGenEval-PS",
        "type": "public",
        "domain": "source_code (PowerShell)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "The Stack (PowerShell subset)",
        "type": "public",
        "domain": "source_code (PowerShell)",
        "link": "https://huggingface.co/datasets/bigcode/the-stack",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PSSec synthetic triplets (insecure script, analysis, repair)",
        "type": "synthetic",
        "domain": "source_code (PowerShell)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GPT-4o",
        "paper_reference": null,
        "metric": "Security Compliance (SRate) on CodeGen",
        "their_result": null,
        "baseline_result": "Over 60% of generated PowerShell scripts were insecure without structured guidance (SRate < 40%)."
      },
      {
        "method_name": "o3-mini",
        "paper_reference": null,
        "metric": "Security Compliance (SRate) on CodeGen",
        "their_result": null,
        "baseline_result": "Over 60% of generated PowerShell scripts were insecure without structured guidance (SRate < 40%)."
      },
      {
        "method_name": "Qwen2.5 (baseline open-source models)",
        "paper_reference": null,
        "metric": "Functional correctness and security metrics across tasks",
        "their_result": null,
        "baseline_result": "Smaller open models perform substantially worse in functionality without offering any security advantage."
      },
      {
        "method_name": "DeepSeek (variants)",
        "paper_reference": null,
        "metric": "Functional correctness and security metrics across tasks",
        "their_result": null,
        "baseline_result": "Evaluated under unified setup; tended to produce fluent but often insecure code similar to other general models."
      }
    ],
    "performance_metrics_used": [
      "Functional Correctness (FRate)",
      "Security Compliance (SRate)",
      "Binary Accuracy (Is_secure)",
      "Rule-level Success@1",
      "Issue-level Success@1",
      "Rule Identification F1 Score",
      "Issue Localization F1 Score",
      "Fix Success Rate (FSucRate)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How well do existing LLMs perform on secure PowerShell script generation, security analysis, and automated repair?",
        "Can lightweight LLMs, when fine-tuned with security-guided data (PSSec), match or surpass large general-purpose models on PowerShell security tasks while reducing inference cost?"
      ],
      "gaps_identified": [
        "LLMs for secure scripting-language code (e.g., PowerShell) remain underexplored compared to general-purpose languages.",
        "Security-conscious patterns are underrepresented in pretraining corpora (approximately 50% of PowerShell code in The Stack is insecure).",
        "Existing benchmarks are largely single-stage and do not reflect the full secure-development cycle (generation, analysis, repair).",
        "Frontier and open models generate fluent but frequently insecure PowerShell code and show weaknesses in context localization, rule disambiguation, and multi-rule reasoning."
      ],
      "limitations": [
        "Annotations are derived from static analysis (PSScriptAnalyzer), excluding runtime-dependent flaws (e.g., privilege escalation, dynamic payload execution, environment-specific misconfiguration).",
        "Line-level annotations do not capture inter-procedural or dataflow semantics.",
        "Benchmark runnable script references are limited due to environmental dependencies; many real scripts rely on unavailable modules or privileged contexts.",
        "Coverage is bounded by rule sets and static tool accuracy, which may include false positives/negatives."
      ],
      "future_work": [
        "Extend benchmark and methods to include dynamic analysis and runtime validation.",
        "Incorporate richer semantic tracing and inter-procedural/dataflow reasoning.",
        "Support multi-file and environment/context-aware evaluation.",
        "Broaden to other scripting ecosystems (e.g., Bash, VBA) and OS-level semantics."
      ],
      "motivation": "Securing powerful scripting languages like PowerShell currently requires heavy manual rule crafting and enforcement, creating operational risk; LLMs could help but lack security-aware reasoning for scripting environments.",
      "potential_research_ideas": [
        "Integrate dynamic sandbox execution and privilege propagation tracking into the reward/evaluation loop to capture runtime-only issues.",
        "Extend PSSec to Bash/VBA with OS/context simulators to generalize security-aware scripting across platforms.",
        "Develop a retrieval-augmented security assistant that grounds generation in official PowerShell documentation and enterprise policy baselines.",
        "Design multi-agent co-auditing systems where independent analyzers cross-verify findings and propose diverse repairs.",
        "Investigate uncertainty estimation and risk-aware decoding to abstain or request confirmation on high-risk operations.",
        "Explore curriculum RL that progressively introduces harder multi-rule, multi-file cases with long-range dependencies.",
        "Study adversarial prompting and jailbreak-like scenarios specific to secure scripting to harden against misuse."
      ],
      "architectural_improvement_recommendations": [
        "Add toolformer-style tool-use with PSScriptAnalyzer and other static analyzers during both training and inference to close the loop.",
        "Use rule-conditioned rewards (RLAIF-style) combining static-analysis scores with constraint satisfaction for RL training.",
        "Incorporate constrained decoding and policy shaping (e.g., deny lists/requirement templates) for high-risk operations (credential handling, invocation of external commands).",
        "Adopt hierarchical planning: first predict security plan and applicable rules, then generate code/repairs conditioned on the plan.",
        "Augment with AST-aware encoders or GNNs over PowerShell AST to improve localization and multi-rule reasoning.",
        "Employ retrieval-augmented generation from PowerShell docs and organizational security policies to improve rule disambiguation.",
        "Introduce a mixture-of-experts with a security-specialist expert activated by detected rule contexts to reduce compute while improving precision."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Trains and serves lightweight LLMs as small as 1.7B parameters; PSSec-trained models reduce inference cost by more than an order of magnitude compared to large general-purpose models."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Static-analysis-bound coverage may miss runtime/environment-specific risks, limiting trust for production deployment.",
        "Potential overfitting to specific rule sets and tool idiosyncrasies (false positives/negatives).",
        "Handling of external dependencies, privileged operations, and environment assumptions common in real PowerShell workflows.",
        "Maintaining up-to-date security rules and platform APIs over time.",
        "Balancing security compliance with functional correctness to avoid overly conservative repairs."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces SecGenEval-PS, a unified benchmark for PowerShell secure script generation (CodeGen), security auditing (CodeAnalysis), and automated repair (CodeFix) with structured annotations across 28 security-relevant rules.",
      "Provides comprehensive evaluation and diagnostics across multiple proprietary and open-source LLMs (e.g., GPT-4o, o3-mini, Qwen2.5, DeepSeek variants), revealing frequent insecurity and weaknesses in multi-rule reasoning.",
      "Proposes PSSec, a framework combining data synthesis via a self-debugging agent (static analyzer + LLM reasoning) with supervised fine-tuning and on-policy RL to train lightweight, security-aware LLMs.",
      "Demonstrates that PSSec-trained lightweight models (as small as 1.7B parameters) match or surpass large general-purpose models on PowerShell security tasks while reducing inference cost by over an order of magnitude.",
      "Identifies that roughly 50% of PowerShell code in The Stack is insecure, highlighting a critical data quality issue for pretraining and prompting."
    ]
  },
  {
    "arxiv_id": "2601.00389v1",
    "title": "NOS-Gate: Queue-Aware Streaming IDS for Consumer Gateways under Timing-Controlled Evasion",
    "authors": "Muhammad Bilal; Omer Tariq; Hasan Ahmed",
    "abstract": "Timing and burst patterns can leak through encryption, and an adaptive adversary can exploit them. This undermines metadata-only detection in a stand-alone consumer gateway. Therefore, consumer gateways need streaming intrusion detection on encrypted traffic using metadata only, under tight CPU and latency budgets. We present a streaming IDS for stand-alone gateways that instantiates a lightweight two-state unit derived from Network-Optimised Spiking (NOS) dynamics per flow, named NOS-Gate. NOS-Gate scores fixed-length windows of metadata features and, under a $K$-of-$M$ persistence rule, triggers a reversible mitigation that temporarily reduces the flow's weight under weighted fair queueing (WFQ). We evaluate NOS-Gate under timing-controlled evasion using an executable 'worlds' benchmark that specifies benign device processes, auditable attacker budgets, contention structure, and packet-level WFQ replay to quantify queue impact. All methods are calibrated label-free via burn-in quantile thresholding. Across multiple reproducible worlds and malicious episodes, at an achieved $0.1%$ false-positive operating point, NOS-Gate attains 0.952 incident recall versus 0.857 for the best baseline in these runs. Under gating, it reduces p99.9 queueing delay and p99.9 collateral delay with a mean scoring cost of ~ 2.09 μs per flow-window on CPU.",
    "published_date": "2026-01-01",
    "pdf_link": "https://arxiv.org/pdf/2601.00389v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Streaming metadata-only IDS for encrypted traffic on consumer gateways under timing-controlled evasion, with queue-aware mitigation via WFQ weight gating",
      "attack_types": [
        "timing-controlled evasion on encrypted traffic",
        "evasive command-and-control (C2) traffic shaping",
        "queue-tail harm under contention"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Spiking/dynamical unit for anomaly detection",
        "specific": "Network-Optimised Spiking (NOS) two-state unit adapted as NOS-Gate",
        "novel_contribution": "Lightweight two-state NOS dynamics per flow with bounded excitability and recovery state, calibrated label-free via burn-in high-quantile thresholds, combined with K-of-M persistence and direct action hook to WFQ deprioritisation"
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Online/Streaming"
    ],
    "datasets": [
      {
        "name": "worlds benchmark",
        "type": "synthetic",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Best baseline (unspecified)",
        "paper_reference": null,
        "metric": "Incident recall at achieved 0.1% false-positive operating point",
        "their_result": "0.952",
        "baseline_result": "0.857"
      }
    ],
    "performance_metrics_used": [
      "achieved false-positive rate (FPR)",
      "incident recall",
      "time-to-detect (TTD)",
      "p99 queueing delay",
      "p99.9 queueing delay",
      "collateral delay (on benign flows)",
      "mean scoring cost per flow-window (CPU)",
      "feasibility rates under (Rmin, ε, δq) budgets"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a stand-alone consumer gateway detect quickly enough to act, at a low false-alarm rate, using only metadata, against timing-shaped adversaries?",
        "What detection-and-action trade-off can be achieved when coupling streaming detection to WFQ weight gating under explicit timing-control budgets?"
      ],
      "gaps_identified": [
        "Existing encrypted-traffic works typically do not evaluate the full gateway action loop (detection → mitigation → queue impact) under explicit timing-control budgets.",
        "Lack of a standardised stand-alone, label-free calibration protocol for consumer gateways.",
        "Public IoT corpora/botnet traces provide limited coverage of timing-controlled evasion and rarely link attacker constraints to auditable queue-level harm at the gateway."
      ],
      "limitations": [
        "No payload inspection or DPI; metadata-only features.",
        "Does not claim deployment in ISP-grade firmware.",
        "Synthetic worlds are not intended to reproduce any single public dataset."
      ],
      "future_work": [
        "Extend the falsifiable protocol by adding new worlds, attacker budgets, and contention structures to test generality and expose failure modes.",
        "Optional inclusion and evaluation of DNS/TLS side-channel constraints when uniformly available."
      ],
      "motivation": "Encrypted traffic limits payload inspection at consumer gateways; attackers can shape timing and bursts to evade metadata-only detectors. There is a need for a lightweight, streaming, label-free IDS that operates under tight CPU/latency budgets and ties detection to a safe, reversible action with measurable queue impact.",
      "potential_research_ideas": [
        "Augment worlds with real-hardware-in-the-loop traces and mixed benign/malicious process libraries to stress-test timing-control feasibility and collateral impacts.",
        "Explore learned representations (e.g., lightweight SSL or autoencoding) as inputs to NOS-Gate while preserving label-free quantile calibration.",
        "Investigate multi-scale windowing and hierarchical persistence rules to balance rapid detection with low false alarms under timing-shaped evasion.",
        "Study coupled NOS units (g>0) over contention graphs to exploit cross-flow signals without violating stand-alone calibration.",
        "Integrate adaptive or EVT-based tail modeling for per-flow thresholds instead of fixed high-quantiles to improve calibration stability.",
        "Evaluate additional mitigation levers (e.g., per-flow token bucket shaping) and joint control with WFQ weights for better queue-tail outcomes."
      ],
      "architectural_improvement_recommendations": [
        "Add multi-scale temporal features and a hierarchical K-of-M persistence to capture both bursty and slowly persistent deviations.",
        "Replace fixed quantile thresholds with adaptive/EVT tail estimators per flow to stabilise FPR under nonstationarity.",
        "Leverage lightweight coupling across contention cliques (nonzero g with learned or estimated wij) to incorporate neighbourhood evidence.",
        "Incorporate optional DNS/TLS handshake side-channel constraints as auxiliary inputs when uniformly present, with feature gating to ensure contract consistency.",
        "Implement dynamic quarantine durations Tg and weight schedules ω− based on alarm persistence to better trade off collateral delay.",
        "Add online concept-drift detection to trigger threshold re-calibration while maintaining label-free operation."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "high",
      "computational_requirements": "Mean scoring cost ≈ 2.09 μs per flow-window on CPU; streaming per-flow updates and WFQ replay used for evaluation."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Stand-alone consumer gateway with WFQ scheduling",
      "scalability_discussed": true,
      "inference_time": "~2.09 μs per flow-window (CPU)",
      "deployment_challenges": [
        "Reliance on metadata-only features; no DPI.",
        "Requires WFQ or compatible scheduler to enact weight gating.",
        "Needs sufficient benign burn-in per flow to estimate high-quantile thresholds.",
        "Uniform availability of DNS/TLS handshake fields cannot be assumed; feature contract must be fixed per run.",
        "Potential collateral delay to benign flows if gating is overly aggressive; mitigated via persistence and reversible weights."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes NOS-Gate, a streaming metadata-only IDS with a lightweight two-state NOS-derived unit per flow, calibrated label-free with K-of-M persistence, and directly coupled to WFQ weight gating.",
      "Introduces a reproducible executable worlds benchmark with published contention structure, auditable attacker budgets (Rmin, ε, δq), and packet-level WFQ replay to quantify queue and collateral impacts.",
      "Standardises a stand-alone calibration/operating protocol using burn-in quantile thresholding and persistence; reports achieved FPR, incident recall, TTD, and queue-tail metrics under identical calibration across methods."
    ]
  },
  {
    "arxiv_id": "2601.03013v3",
    "title": "LLMs, You Can Evaluate It! Design of Multi-perspective Report Evaluation for Security Operation Centers",
    "authors": "Hiroyuki Okada; Tatsumi Oba; Naoto Yanai",
    "abstract": "Security operation centers (SOCs) often produce analysis reports on security incidents, and large language models (LLMs) will likely be used for this task in the near future. We postulate that a better understanding of how veteran analysts evaluate reports, including their feedback, can help produce analysis reports in SOCs. In this paper, we aim to leverage LLMs for analysis reports. To this end, we first construct a Analyst-wise checklist to reflect SOC practitioners' opinions for analysis report evaluation through literature review and user study with SOC practitioners. Next, we design a novel LLM-based conceptual framework, named MESSALA, by further introducing two new techniques, granularization guideline and multi-perspective evaluation. MESSALA can maximize report evaluation and provide feedback on veteran SOC practitioners' perceptions. When we conduct extensive experiments with MESSALA, the evaluation results by MESSALA are the closest to those of veteran SOC practitioners compared with the existing LLM-based methods. We then show two key insights. We also conduct qualitative analysis with MESSALA, and then identify that MESSALA can provide actionable items that are necessary for improving analysis reports.",
    "published_date": "2026-01-06",
    "pdf_link": "https://arxiv.org/pdf/2601.03013v3",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Security Operations",
      "subdomain": "SOC Reporting and Incident Response",
      "specific_problem": "LLM-based evaluation and feedback for SOC analysis reports",
      "attack_types": []
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM-as-a-judge / Prompting",
        "specific": "MESSALA (Multi-perspective Evaluation System for Security Analysis using LLM Assistance)",
        "novel_contribution": "Introduces granularization guideline and multi-perspective evaluation to guide LLMs to emulate veteran SOC practitioners' cognition for report evaluation and feedback."
      },
      {
        "type": "baseline",
        "category": "LLM-as-a-judge",
        "specific": "GPTScore",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM-as-a-judge",
        "specific": "G-Eval",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Prompt-based",
      "LLM-as-a-judge"
    ],
    "datasets": [
      {
        "name": "Real-world SOC analysis reports (used for quantitative and qualitative evaluation)",
        "type": "proprietary",
        "domain": "security_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GPTScore",
        "paper_reference": "[25]",
        "metric": null,
        "their_result": "\"the evaluation results by MESSALA are the closest to those of veteran SOC practitioners compared with the existing LLM-based methods\"",
        "baseline_result": null
      },
      {
        "method_name": "G-Eval",
        "paper_reference": "[49]",
        "metric": null,
        "their_result": "\"the evaluation results by MESSALA are the closest to those of veteran SOC practitioners compared with the existing LLM-based methods\"",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Agreement/closeness to veteran SOC practitioners' ratings on evaluation criteria",
      "Qualitative actionability and specificity of feedback comments"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: What are the evaluation criteria that guarantee the quality of analysis reports from SOC practitioners’ knowledge?",
        "RQ2: Can LLMs quantitatively evaluate the quality of analysis reports from the perspective of SOC practitioners under the defined evaluation criteria?",
        "RQ3: Can LLMs qualitatively evaluate the quality of analysis reports with feedback from the perspective of SOC practitioners under the defined evaluation criteria?"
      ],
      "gaps_identified": [
        "Lack of concrete evaluation criteria tailored to SOC analysis reports; existing guidelines are abstract and fail to capture veteran practitioners’ perspectives.",
        "Current LLM-based report generation/evaluation suffers from hallucinations and misalignment with domain-specific context.",
        "Existing report-generation tools lack explicit mechanisms for evaluating analysis reports."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Reduce SOC workload and improve quality of analysis reports by enabling LLMs to evaluate reports using criteria that reflect veteran SOC practitioners’ knowledge; address the absence of adequate evaluation criteria and LLM hallucination/misalignment.",
      "potential_research_ideas": [
        "Create and release a public benchmark/dataset of SOC analysis reports with veteran annotations for evaluation alignment research.",
        "Investigate preference learning or RLHF using veteran analysts’ ratings and feedback to train an LLM judge specialized for SOC reporting.",
        "Integrate retrieval-augmented evaluation (e.g., link to evidence/logs and guidelines) to reduce hallucinations in judgments and feedback.",
        "Extend MESSALA to multilingual SOC report evaluation and cross-domain (IT/OT/ICS) contexts with domain-adaptive criteria.",
        "Study reliability/uncertainty estimation for LLM judges (e.g., confidence scoring, abstention) in SOC evaluations.",
        "Design adversarial robustness tests for report evaluators (prompt injections, misleading context) and develop defenses.",
        "Automate feedback-to-rewrite loops: use MESSALA’s feedback to guide iterative report improvement and measure gains."
      ],
      "architectural_improvement_recommendations": [
        "Calibrate scores via rater-model ensembles and majority/weighted voting across multiple LLMs to improve robustness.",
        "Incorporate structured scoring rubrics mapped directly to the Analyst-wise Checklist with JSON outputs for auditability.",
        "Use few-shot, chain-of-thought, and rubric-grounded exemplars per criterion to enhance reasoning fidelity.",
        "Add retrieval components that ground evaluations in cited evidence from the report and linked artifacts (logs, tickets).",
        "Train a lightweight reward/scoring model (e.g., pairwise ranking) on veteran ratings to distill MESSALA into a cheaper evaluator.",
        "Implement uncertainty estimation and consistency checks (self-critique, cross-check between perspectives) before finalizing scores.",
        "Introduce criterion-level granularization controllers to dynamically adjust the depth of evaluation based on report complexity."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Security Operation Centers across IT and OT/ICS contexts",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "LLM hallucinations leading to inadequate or incorrect evaluations.",
        "Aligning evaluations with domain-specific context and veteran analyst expectations.",
        "Lack of publicly available datasets of SOC reports for benchmarking and calibration."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Designed the Analyst-wise Checklist of concrete evaluation criteria for SOC analysis reports via literature review and interviews with 15 SOC practitioners (13 public guidelines reviewed).",
      "Proposed MESSALA, an LLM-based multi-perspective evaluation framework with granularization guideline to emulate veteran SOC practitioners’ cognition and provide actionable feedback.",
      "Demonstrated, via quantitative experiments on real reports, that MESSALA’s ratings are closest to veteran SOC practitioners compared to GPTScore and G-Eval.",
      "Conducted qualitative analysis showing MESSALA provides more actionable and specific feedback for improving analysis reports."
    ]
  },
  {
    "arxiv_id": "2601.07019v1",
    "title": "Zer0n: An AI-Assisted Vulnerability Discovery and Blockchain-Backed Integrity Framework",
    "authors": "Harshil Parmar; Pushti Vyas; Prayers Khristi; Priyank Panchal",
    "abstract": "As vulnerability research increasingly adopts generative AI, a critical reliance on opaque model outputs has emerged, creating a \"trust gap\" in security automation. We address this by introducing Zer0n, a framework that anchors the reasoning capabilities of Large Language Models (LLMs) to the immutable audit trails of blockchain technology. Specifically, we integrate Gemini 2.0 Pro for logic-based vulnerability detection with the Avalanche C-Chain for tamper-evident artifact logging. Unlike fully decentralized solutions that suffer from high latency, Zer0n employs a hybrid architecture: execution remains off-chain for performance, while integrity proofs are finalized on-chain. Our evaluation on a dataset of 500 endpoints reveals that this approach achieves 80% detection accuracy with only a marginal 22.9% overhead, effectively demonstrating that decentralized integrity can coexist with high-speed security workflows.",
    "published_date": "2026-01-11",
    "pdf_link": "https://arxiv.org/pdf/2601.07019v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Application Security",
      "subdomain": "Vulnerability Discovery and Assessment",
      "specific_problem": "AI-assisted vulnerability detection with blockchain-backed integrity and provenance for analysis artifacts",
      "attack_types": [
        "Business logic vulnerabilities",
        "Web application vulnerabilities (general)",
        "Smart contract reentrancy"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM (Transformer)",
        "specific": "Gemini 2.0 Pro",
        "novel_contribution": "Hybrid architecture that anchors LLM-generated vulnerability analysis artifacts to on-chain integrity proofs (Avalanche C-Chain) while keeping computation off-chain; deterministic prompting with low temperature and structured chain-of-thought."
      },
      {
        "type": "primary",
        "category": "Prompting",
        "specific": "Chain-of-thought prompting; temperature=0.2",
        "novel_contribution": "Configured to minimize hallucinations and improve determinism of vulnerability classifications."
      }
    ],
    "learning_paradigm": [
      "In-context learning",
      "Prompt-based (chain-of-thought)"
    ],
    "datasets": [
      {
        "name": "500 web application endpoints",
        "type": "proprietary",
        "domain": "web_application_endpoints",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "OWASP Juice Shop",
        "type": "public",
        "domain": "web_application (intentionally vulnerable)",
        "link": "https://owasp.org/www-project-juice-shop/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SWC Registry smart contract samples",
        "type": "public",
        "domain": "smart_contracts",
        "link": "https://swcregistry.io/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "100 smart contract samples (from SWC Registry)",
        "type": "public",
        "domain": "smart_contracts",
        "link": "https://swcregistry.io/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Baseline vulnerability analysis (no blockchain integrity logging)",
        "paper_reference": null,
        "metric": "Total Workflow Time (s)",
        "their_result": "15.23",
        "baseline_result": "12.39"
      },
      {
        "method_name": "Baseline vulnerability analysis (no blockchain integrity logging)",
        "paper_reference": null,
        "metric": "Overhead (%)",
        "their_result": "22.9",
        "baseline_result": "–"
      },
      {
        "method_name": "Slither",
        "paper_reference": "[15]",
        "metric": "Qualitative reentrancy case study",
        "their_result": "Zer0n (Gemini 2.0 Pro) identified the multi-step attack vector and suggested Checks-Effects-Interactions.",
        "baseline_result": "Slither flagged reentrancy with a generic warning based on state mutability."
      },
      {
        "method_name": "Mythril",
        "paper_reference": "[16]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "ContractFuzzer",
        "paper_reference": "[3]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "OWASP ZAP",
        "paper_reference": null,
        "metric": "Feature comparison (AI/Integrity logging)",
        "their_result": "Zer0n: AI/LLM=Yes; Integrity Logging=Yes",
        "baseline_result": "OWASP ZAP: AI/LLM=No; Integrity Logging=No"
      },
      {
        "method_name": "Burp Suite",
        "paper_reference": null,
        "metric": "Feature comparison (AI/Integrity logging)",
        "their_result": "Zer0n: AI/LLM=Yes; Integrity Logging=Yes",
        "baseline_result": "Burp Suite: AI/LLM=No; Integrity Logging=No"
      },
      {
        "method_name": "AICyber-Chain",
        "paper_reference": "[1]",
        "metric": "Scope/Focus (Table 1)",
        "their_result": "Zer0n focus: Vulnerability logic; Integrity: Yes; AI: Yes",
        "baseline_result": "AICyber-Chain focus: IoT data; Integrity: Yes; AI: Yes"
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall",
      "F1-score",
      "accuracy",
      "analysis execution time (s)",
      "report generation time (ms)",
      "total workflow time (s)",
      "overhead (%)",
      "SHA-256 hash computation latency (ms)",
      "transaction construction time (ms)",
      "transaction signing time (ms)",
      "network propagation latency (ms)",
      "block confirmation time (ms)",
      "verification time (ms)",
      "tamper detection accuracy (%)",
      "false positive rate (%)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can blockchain-backed integrity logging be integrated into AI-assisted vulnerability discovery workflows without prohibitive overhead?",
        "Does a hybrid architecture (off-chain analysis, on-chain integrity proofs) preserve performance while providing tamper-evident auditability?",
        "Can LLM reasoning improve detection and contextualization of complex logic vulnerabilities beyond static analyzers?"
      ],
      "gaps_identified": [
        "Lack of verifiable provenance and immutable records for AI-generated security analyses (the 'trust gap').",
        "Existing blockchain approaches often prioritize data privacy over workflow integrity or incur prohibitive latency via decentralized storage.",
        "Static and symbolic analysis tools struggle with complex business logic vulnerabilities requiring semantic understanding.",
        "LLMs can be manipulated or hallucinate, risking untrustworthy analyses without provenance."
      ],
      "limitations": [
        "Prototype does not provide comprehensive vulnerability coverage.",
        "No evaluation of large-scale deployment or production-scale scalability.",
        "Blockchain integration introduces operational complexity and latency; may be unsuitable for time-critical environments.",
        "Automated remediation and exploit execution are out of scope.",
        "Threat model excludes blockchain consensus compromise and ledger DoS; assumes trusted execution up to hash generation."
      ],
      "future_work": [
        "Multi-agent analysis orchestration.",
        "Reputation-based contributor scoring tied to on-chain history.",
        "Automated incentive/payment mechanisms.",
        "Continuous large-scale scanning pipelines.",
        "Decentralized marketplace of trusted security auditors leveraging on-chain provenance."
      ],
      "motivation": "Bridge the trust gap in AI-driven vulnerability discovery by cryptographically binding LLM outputs to an immutable ledger, ensuring integrity and provenance without sacrificing performance.",
      "potential_research_ideas": [
        "Design multi-agent, heterogeneous LLM ensembles with on-chain consensus/commit-reveal to improve reliability and reduce hallucinations.",
        "Use zero-knowledge proofs to attest to properties of the off-chain report (e.g., certain checks executed) without revealing sensitive content.",
        "Integrate static/symbolic analyzers with LLMs via toolformer/function-calling to ground reasoning in executable facts.",
        "Uncertainty calibration for LLM-based findings with selective abstention and human-in-the-loop verification tied to on-chain provenance.",
        "Cross-chain integrity anchoring (e.g., periodic Bitcoin/Ethereum checkpoints) for stronger security assumptions.",
        "Privacy-preserving storage of artifacts via content-addressed stores (IPFS/Filecoin) with encrypted blobs and on-chain hash commitments.",
        "Adversarial robustness evaluation against prompt injection and data poisoning in vulnerability discovery pipelines.",
        "Active learning loop that prioritizes ambiguous cases for manual review; feedback logged on-chain to build auditor reputation.",
        "Automated CVSS scoring and SBOM linkage for findings, with on-chain attestations to support supply-chain audits."
      ],
      "architectural_improvement_recommendations": [
        "Batch and Merkle-aggregate multiple report hashes per transaction to reduce on-chain costs and latency.",
        "Add zero-knowledge proofs or verifiable computation (e.g., zk-SNARKs) for selective attestation about analyses performed.",
        "Introduce TEEs (e.g., SGX) or remote attestation for the Node.js backend to strengthen trust up to hash generation.",
        "Employ multi-model ensembles (LLM + static/symbolic) with adjudication; log model votes and rationales off-chain with on-chain commitments.",
        "Implement robust prompt hardening and input sanitization to mitigate LLM prompt injection risks; log prompt templates with hashes.",
        "Use structured outputs (JSON schemas) from the LLM to simplify verification and reduce ambiguity.",
        "Asynchronous, retry-aware transaction queue with backpressure control; support multi-network failover.",
        "Add differential privacy or redactable commitments for sensitive artifacts while preserving verifiability."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "Node.js",
        "Express",
        "React",
        "Vite",
        "Puppeteer",
        "scikit-learn",
        "web3.py",
        "hashlib (SHA-256)",
        "Solidity",
        "Remix IDE",
        "Avalanche C-Chain (Fuji testnet)",
        "Gemini 2.0 Pro API"
      ],
      "reproducibility_score": "low",
      "computational_requirements": "Workstation: Intel Core i7-12700H (14 cores), 32 GB RAM, 1 TB NVMe SSD, Windows 11 Pro. No GPU required; LLM via API. Average block confirmation ~14.2s (Fuji)."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Off-chain Node.js backend with React frontend; Avalanche C-Chain (Fuji testnet) for on-chain logging.",
      "scalability_discussed": true,
      "inference_time": "Analysis execution: 12.89±1.35 s (with Zer0n). Verification: ~90 ms.",
      "deployment_challenges": [
        "Blockchain operational complexity and latency management.",
        "Dependence on third-party LLM API (availability, cost, rate limits).",
        "Trust assumptions for the off-chain environment up to hash generation.",
        "Potential unsuitability for strict real-time/time-critical workflows.",
        "Handling large-scale continuous scanning and transaction batching."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Hybrid trust architecture decoupling AI reasoning from integrity enforcement, enabling independent scaling.",
      "Tamper-evident artifact logging via Solidity smart contracts on Avalanche C-Chain for immutable audit trails.",
      "Empirical feasibility analysis showing 80% F1 with 22.9% overhead and practical latency when using asynchronous on-chain logging.",
      "Prototype implementation integrating Gemini 2.0 Pro with blockchain-backed integrity and a web-based coordination layer."
    ]
  },
  {
    "arxiv_id": "2601.02624v1",
    "title": "LAsset: An LLM-assisted Security Asset Identification Framework for System-on-Chip (SoC) Verification",
    "authors": "Md Ajoad Hasan; Dipayan Saha; Khan Thamid Hasan; Nashmin Alam; Azim Uddin; Sujan Kumar Saha; Mark Tehranipoor; Farimah Farahmandi",
    "abstract": "The growing complexity of modern system-on-chip (SoC) and IP designs is making security assurance difficult day by day. One of the fundamental steps in the pre-silicon security verification of a hardware design is the identification of security assets, as it substantially influences downstream security verification tasks, such as threat modeling, security property generation, and vulnerability detection. Traditionally, assets are determined manually by security experts, requiring significant time and expertise. To address this challenge, we present LAsset, a novel automated framework that leverages large language models (LLMs) to identify security assets from both hardware design specifications and register-transfer level (RTL) descriptions. The framework performs structural and semantic analysis to identify intra-module primary and secondary assets and derives inter-module relationships to systematically characterize security dependencies at the design level. Experimental results show that the proposed framework achieves high classification accuracy, reaching up to 90% recall rate in SoC design, and 93% recall rate in IP designs. This automation in asset identification significantly reduces manual overhead and supports a scalable path forward for secure hardware development.",
    "published_date": "2026-01-06",
    "pdf_link": "https://arxiv.org/pdf/2601.02624v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Hardware Security",
      "subdomain": "Pre-silicon Security Verification",
      "specific_problem": "Automated security asset identification from SoC/IP specifications and RTL",
      "attack_types": [
        "side-channel",
        "fault injection",
        "secure-to-nonsecure information leakage",
        "unauthorized access",
        "privilege escalation",
        "hardware Trojan",
        "denial-of-service"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM/Transformer",
        "specific": "OpenAI GPT-5 (in-context learning)",
        "novel_contribution": "Agentic multi-stage pipeline for asset identification aligned to SA-EDI/IEEE P3164, including conceptual-to-structural mapping, attack-scenario synthesis, CWE-based validation, and self-critique."
      },
      {
        "type": "primary",
        "category": "Retrieval-Augmented Generation (RAG)",
        "specific": "FAISS + text-embedding-ada-002 embeddings",
        "novel_contribution": "RAG used to build module-specific technical summaries from SoC specification for LLM prompting, with chunking (1000 chars, 200 overlap) and top-20 retrieval."
      },
      {
        "type": "primary",
        "category": "Prompt Engineering / Few-shot In-context Learning",
        "specific": null,
        "novel_contribution": "Few-shot exemplars for CIA-focused asset reasoning across typical IPs (e.g., AES, GPIO, Gaussian Noise Generator); structured, stepwise reasoning prompts for asset generation and refinement."
      },
      {
        "type": "primary",
        "category": "Agentic LLM System",
        "specific": null,
        "novel_contribution": "Three-agent flow: Input Pre-processing, Asset Generation, Asset Refinement; includes self-consistency checks and DoI computation from RTL connectivity."
      }
    ],
    "learning_paradigm": [
      "Few-shot In-context Learning",
      "Retrieval-Augmented Generation",
      "Prompt-based"
    ],
    "datasets": [
      {
        "name": "NEORV32 RISC-V SoC RTL repository",
        "type": "public",
        "domain": "hardware_rtl",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "OpenTitan HMAC IP",
        "type": "public",
        "domain": "hardware_rtl",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "AES IP (case study)",
        "type": "public",
        "domain": "hardware_rtl",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "GPIO IP (case study)",
        "type": "public",
        "domain": "hardware_rtl",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Gaussian Noise Generator IP (case study)",
        "type": "public",
        "domain": "hardware_rtl",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MITRE CWE Database",
        "type": "public",
        "domain": "vulnerability_database",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SAIF tool",
        "paper_reference": "[16] (as cited in the paper)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "LASHED flow",
        "paper_reference": "[17] (as cited in the paper)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Naming-convention/pattern-matching method",
        "paper_reference": "[18] (as cited in the paper)",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "recall",
      "classification accuracy",
      "true positives (TP)",
      "false negatives (FN)",
      "false positives (FP)",
      "Degree of Influence (DoI)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: How can we determine which elements are considered security-relevant assets within a given hardware design architecture?",
        "RQ2: Can we develop an end-to-end automated methodology for reliably identifying security assets across diverse SoC and IP designs?",
        "RQ3: How can we validate that an identified asset is really an asset?"
      ],
      "gaps_identified": [
        "Asset identification is traditionally manual, time-consuming, error-prone, and not scalable for large SoCs.",
        "Existing tools (e.g., SAIF, LASHED) identify assets only after analyzing vulnerabilities; asset identification should be the primary step.",
        "Heuristic/naming-based RTL approaches fail to generalize and provide little reasoning or justification.",
        "Rule-based methods lack semantic understanding of specs/RTL and cannot provide contextual, explainable justifications aligned with standards."
      ],
      "limitations": [
        "LLMs tend to over-include candidates (false positives), requiring multi-stage refinement.",
        "Token limitations and constrained long-context retention can lead to hallucinations; mitigated by pre-processing and RAG.",
        "CWE database is large; careful, staged mapping needed to avoid overwhelming the LLM."
      ],
      "future_work": [],
      "motivation": "Enable scalable, early-stage, standards-aligned security asset identification to support downstream pre-silicon security verification tasks.",
      "potential_research_ideas": [
        "Develop an open-source, on-prem model fine-tuned on hardware-security corpora to replace closed LLMs and improve reproducibility/privacy.",
        "Integrate formal verification or information-flow tracking to automatically validate LLM-identified assets and reduce false positives.",
        "Construct a labeled benchmark dataset of RTL/spec-asset pairs for supervised fine-tuning and fair comparison across methods.",
        "Extend LAsset to automatically generate SA-EDI JSON artifacts and propagate assets into threat models and security property generation.",
        "Incorporate uncertainty estimation and confidence calibration for asset predictions to guide human-in-the-loop review.",
        "Evaluate and harden the system against prompt-injection or adversarial spec/RTL perturbations.",
        "Generalize to post-silicon validation (e.g., DfT/DFD artefacts) and firmware/hardware co-verification."
      ],
      "architectural_improvement_recommendations": [
        "Add a graph-based RTL representation (e.g., netlist graph) and use a graph encoder alongside the LLM for structural reasoning.",
        "Introduce a retrieval policy that mixes spec, RTL snippets, and prior verified asset patterns via hybrid dense+BM25 retrieval.",
        "Implement a multi-agent debate/consensus phase before refinement to reduce hallucinations and improve precision.",
        "Augment CWE mapping with structured program analysis to auto-extract CWE preconditions from RTL.",
        "Cache and reuse module-level summaries and partial results to reduce cost/latency; add batching for multi-module runs.",
        "Add a human-in-the-loop triage UI with active learning to collect corrections and continuously fine-tune prompts/models."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": "https://github.com/Ajoad/LAsset-Security-Assets",
      "frameworks": [
        "FAISS",
        "OpenAI API"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Pre-silicon hardware design/verification for SoC/IP RTL and specifications",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "LLM token limits and long-context retention constraints",
        "Potential LLM hallucinations without careful prompting/refinement",
        "Cost/latency of LLM inference at SoC scale",
        "Dependence on closed models (reproducibility/IP concerns)",
        "Large CWE corpus requires careful filtering/mapping"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First LLM-assisted automated framework (LAsset) for security asset identification from SoC/IP specifications and RTL.",
      "Works with spec+RTL or RTL-only; supports Verilog, SystemVerilog, and VHDL; applicable to IP and full SoCs.",
      "Associates each asset with threat modeling details and security justifications; aligns with SA-EDI and IEEE P3164.",
      "Multi-stage refinement via attack-scenario analysis, CWE mapping, and self-critique to improve fidelity.",
      "Introduces Degree of Influence (DoI) metric using RTL connectivity to quantify secondary asset influence.",
      "Experimental results: up to 90% recall on SoC and 93% recall on IP designs; demonstrated on NEORV32 and multiple IPs."
    ]
  },
  {
    "arxiv_id": "2601.06219v1",
    "title": "AI-Powered Algorithms for the Prevention and Detection of Computer Malware Infections",
    "authors": "Rakesh Keshava; Sathish Kuppan Pandurangan; M. Sakthivanitha; Sankaranainar Parmsivan; Goutham Sunkara; R. Maruthi",
    "abstract": "The rise in frequency and complexity of malware attacks are viewed as a major threat to modern digital infrastructure, which means that traditional signature-based detection methods are becoming less effective. As cyber threats continue to evolve, there is a growing need for intelligent systems to accurately and proactively identify and prevent malware infections. This study presents a new hybrid context-aware malware detection framework(HCAMDF) based on artificial intelligence (AI), which combines static file analysis, dynamic behavioural analysis, and contextual metadata to provide more accurate and timely detection. HCADMF has a multi-layer architecture, which consists of lightweight static classifiers such as Long Short Term Memory (LSTM) for real-time behavioral analysis, and an ensemble risk scoring through the integration of multiple layers of prediction. Experimental evaluations of the new/methodology with benchmark datasets, EMBER and CIC-MalMem2022, showed that the new approach provides superior performances with an accuracy of 97.3%, only a 1.5% false positive rate and minimal detection delay compared to several existing machine learning(ML) and deep learning(DL) established methods in the same fields. The results show strong evidence that hybrid AI can detect both existing and novel malware variants, and lay the foundation on intelligent security systems that can enable real-time detection and adapt to a rapidly evolving threat landscape.",
    "published_date": "2026-01-09",
    "pdf_link": "https://arxiv.org/pdf/2601.06219v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Malware Analysis",
      "subdomain": "Malware Detection",
      "specific_problem": "Hybrid context-aware malware detection combining static, dynamic behavioral, and contextual metadata for real-time detection with low false positives",
      "attack_types": [
        "zero-day malware",
        "polymorphic malware",
        "general malware infections"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Ensemble (stacking/meta-learning)",
        "specific": "Three-stage hybrid pipeline with meta-learner",
        "novel_contribution": "Hybrid Context-Aware Malware Detection Framework (HCAMDF): static lightweight classifier -> behavioral sequence model -> context-aware ensemble risk scoring"
      },
      {
        "type": "primary",
        "category": "Ensemble Tree",
        "specific": "Random Forest",
        "novel_contribution": "Used as Stage-1 lightweight static classifier for fast triage"
      },
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "LightGBM",
        "novel_contribution": "Alternative Stage-1 lightweight static classifier (speed-focused)"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": "Stage-2 behavior-based deep sequence model over dynamic API/registry/network sequences for real-time behavioral analysis"
      },
      {
        "type": "primary",
        "category": "Gradient Boosted Trees",
        "specific": "XGBoost",
        "novel_contribution": "Stage-3 context-aware meta-learner fusing Stage-1/2 outputs with contextual metadata to produce final risk score"
      },
      {
        "type": "primary",
        "category": "Data Resampling",
        "specific": "SMOTE",
        "novel_contribution": "Used to address class imbalance in training"
      },
      {
        "type": "primary",
        "category": "Model Evaluation",
        "specific": "Stratified cross-validation",
        "novel_contribution": "Used to ensure balanced evaluation across classes"
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "EMBER",
        "type": "public",
        "domain": "malware_binaries_static_features",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIC-MalMem2022",
        "type": "public",
        "domain": "memory_forensics_dynamic_behavior",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VirusShare",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Malicia",
        "type": "public",
        "domain": "malware_binaries",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Cuckoo Sandbox dynamic logs (generated)",
        "type": "synthetic",
        "domain": "dynamic_behavior_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Windows Event Logs",
        "type": "proprietary",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Linux audit logs",
        "type": "proprietary",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "VirusTotal labels (multi-AV consensus)",
        "type": "public",
        "domain": "threat_intel_labels",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CJDS (Cryptojacking Dataset)",
        "type": "private",
        "domain": "cryptojacking_behavior",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "accuracy",
      "false positive rate",
      "detection delay/response time"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What are the best ways to develop AI-hybrid algorithms that can detect and prevent computer malware infections with high accuracy, low false positives and in real-time?"
      ],
      "gaps_identified": [
        "Traditional signature-based detection is declining in effectiveness, especially for zero-day and polymorphic malware.",
        "Most prior studies use either static or behavioral analysis alone, limiting real-world detection capability for hybrid attacks.",
        "Existing models often suffer high false positive rates and poor generalization to novel variants.",
        "Lack of deployable systems, accurate generalizability, or strong benchmarks in the literature.",
        "Datasets are often limited; some approaches demand excessive computation.",
        "Insufficient attention to practical cloud/edge integration, scalability, interpretability, and real-world validation."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Build an intelligent, adaptive malware detection system that combines static, dynamic, and contextual signals to achieve accurate, low-FPR, real-time detection in evolving threat landscapes.",
      "potential_research_ideas": [
        "Self-supervised pretraining on unlabeled system-call and registry sequences to improve generalization to novel malware.",
        "Adversarially robust training and evaluation against packing/obfuscation and API-call perturbations.",
        "Federated learning for privacy-preserving collaborative model training across endpoints/organizations.",
        "Concept drift and online/continual learning to adapt to evolving malware behaviors in production.",
        "Cross-attention multimodal fusion of static, dynamic, and context features instead of simple concatenation.",
        "Robust benchmark design that unifies static, dynamic, and contextual modalities with time-split evaluation to emulate zero-day settings.",
        "Explainability methods tailored to malware (e.g., SHAP for static features and attention visualization for sequences) to aid analyst trust.",
        "Edge/cloud co-design with model distillation for lightweight on-endpoint inference and heavy analysis offloaded to cloud.",
        "Graph-based modeling of program behavior (API-call graphs) with GNNs for better structural understanding of malware.",
        "Memory forensics integration to detect fileless/in-memory threats at runtime."
      ],
      "architectural_improvement_recommendations": [
        "Replace or complement LSTM with Transformer-based sequence models (e.g., Temporal Transformers) for long-range dependencies in behavior logs.",
        "Use cross-attention or gated fusion networks for context-aware fusion rather than simple concatenation followed by XGBoost.",
        "Introduce hierarchical modeling: per-process sequences -> host-level aggregator to capture multi-process malware behaviors.",
        "Incorporate uncertainty estimation (e.g., MC Dropout or deep ensembles) to calibrate risk scores for automated response policies.",
        "Apply feature-store and drift monitoring in production to trigger model retraining and maintain performance over time.",
        "Adopt metric learning/contrastive objectives to separate benign/malicious sequences in embedding space.",
        "Leverage AutoML/hyperparameter optimization for Stage-1/3 tree models to maximize speed-accuracy tradeoff.",
        "Knowledge distillation to produce a lightweight on-device model from the full hybrid pipeline for real-time constraints."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "Minimal detection delay (no exact figure reported)",
      "deployment_challenges": [
        "Limited details on real-world deployment; evaluation primarily on benchmarks (EMBER, CIC-MalMem2022).",
        "Dynamic analysis (sandboxing) can introduce overhead and operational complexity.",
        "Related work notes high compute demands for some DL approaches; resource constraints on endpoints are likely.",
        "Literature gap on practical cloud/edge integration and interpretability remains."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a Hybrid Context-Aware Malware Detection Framework (HCAMDF) combining static, dynamic behavioral, and contextual metadata.",
      "Designs a multi-stage pipeline: Stage-1 lightweight static classifier (e.g., Random Forest/LightGBM), Stage-2 LSTM for behavioral analysis, Stage-3 context-aware ensemble (e.g., XGBoost) for final risk scoring.",
      "Uses stratified cross-validation and SMOTE for training/evaluation robustness.",
      "Describes a real-time monitoring agent concept for prevention/response, including in-memory observation for fileless threats.",
      "Empirical evaluation on EMBER and CIC-MalMem2022 reporting 97.3% accuracy, 1.5% false positive rate, and minimal detection delay, outperforming unspecified existing ML/DL methods."
    ]
  },
  {
    "arxiv_id": "2601.06779v1",
    "title": "CyberLLM-FINDS 2025: Instruction-Tuned Fine-tuning of Domain-Specific LLMs with Retrieval-Augmented Generation and Graph Integration for MITRE Evaluation",
    "authors": "Vasanth Iyer; Leonardo Bobadilla; S. S. Iyengar",
    "abstract": "Large Language Models (LLMs) such as Gemma-2B have shown strong performance in various natural language processing tasks. However, general-purpose models often lack the domain expertise required for cybersecurity applications. This work presents a methodology to fine-tune the Gemma-2B model into a domain-specific cybersecurity LLM. We detail the processes of dataset preparation, fine-tuning, and synthetic data generation, along with implications for real-world applications in threat detection, forensic investigation, and attack analysis.   Experiments highlight challenges in prompt length distribution during domain-specific fine-tuning. Uneven prompt lengths limit the model's effective use of the context window, constraining local inference to 200-400 tokens despite hardware support for longer sequences. Chain-of-thought styled prompts, paired with quantized weights, yielded the best performance under these constraints. To address context limitations, we employed a hybrid strategy using cloud LLMs for synthetic data generation and local fine-tuning for deployment efficiency.   To extend the evaluation, we introduce a Retrieval-Augmented Generation (RAG) pipeline and graph-based reasoning framework. This approach enables structured alignment with MITRE ATT&CK techniques through STIX-based threat intelligence, enhancing recall in multi-hop and long-context scenarios. Graph modules encode entity-neighborhood context and tactic chains, helping mitigate the constraints of short prompt windows. Results demonstrate improved model alignment with tactic, technique, and procedure (TTP) coverage, validating the utility of graph-augmented LLMs in cybersecurity threat intelligence applications.",
    "published_date": "2026-01-11",
    "pdf_link": "https://arxiv.org/pdf/2601.06779v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Threat Intelligence",
      "subdomain": "Cyber Threat Intelligence (CTI)",
      "specific_problem": "Fine-tuning a small LLM for MITRE ATT&CK-aligned threat reasoning with Retrieval-Augmented Generation and graph integration to improve TTP mapping and multi-hop recall",
      "attack_types": [
        "T1059 - Command and Scripting Interpreter",
        "T1059.001 - PowerShell",
        "T1566 - Phishing",
        "T1566.001 - Spearphishing Attachment",
        "T1021.001 - Remote Desktop Protocol (Lateral Movement)",
        "T1003.001 - LSASS Dumping",
        "Execution",
        "Persistence",
        "Lateral Movement"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Gemma-2B (instruction-tuned)",
        "novel_contribution": "Domain-specific instruction tuning for cybersecurity using chain-of-thought styled prompts under strict token limits and quantized weights"
      },
      {
        "type": "primary",
        "category": "Retrieval-Augmented Generation",
        "specific": "RAG over STIX/MITRE sources",
        "novel_contribution": "Structured alignment with MITRE ATT&CK techniques using STIX-based threat intelligence to improve recall in multi-hop and long-context scenarios"
      },
      {
        "type": "primary",
        "category": "GNN",
        "specific": null,
        "novel_contribution": "GraphRAG + lightweight GNN node scoring to encode entity-neighborhood context and tactic chains for improved retrieval and TTP mapping"
      },
      {
        "type": "baseline",
        "category": "Retrieval-Augmented Generation",
        "specific": "Pure RAG",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Graph + LLM",
        "specific": "Graph traversal + LLM without GNN scoring",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Parameter-Efficient Fine-Tuning",
        "specific": "QLoRA-style quantized fine-tuning (4-bit)",
        "novel_contribution": "Used to fit fine-tuning on 24GB GPU with small context windows"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Transfer Learning",
      "Instruction Tuning",
      "Synthetic Data Generation"
    ],
    "datasets": [
      {
        "name": "Domain-specific MITRE ATT&CK instruction dataset (2,398 prompt–response pairs)",
        "type": "synthetic",
        "domain": "threat_intelligence",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "MITRE GNN Analysis evaluation set (LLM Judge + MITRE queries)",
        "type": "public",
        "domain": "threat_intelligence",
        "link": "https://github.com/viyer-research/mitre-gnn-analysis",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "MITRE ATT&CK knowledge base",
        "type": "public",
        "domain": "threat_intelligence",
        "link": "https://attack.mitre.org/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "STIX-based threat intelligence graph (constructed from public CTI sources)",
        "type": "public",
        "domain": "threat_intelligence",
        "link": "https://oasis-open.github.io/cti-documentation/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Pure RAG",
        "paper_reference": null,
        "metric": "LLM Judge Avg. Score (0–10) on MITRE queries",
        "their_result": "8.00 (GraphRAG+GNN)",
        "baseline_result": "7.87 (Pure RAG)"
      },
      {
        "method_name": "Graph + LLM",
        "paper_reference": null,
        "metric": "LLM Judge Avg. Score (0–10) on MITRE queries",
        "their_result": "8.00 (GraphRAG+GNN)",
        "baseline_result": "7.16 (Graph + LLM)"
      }
    ],
    "performance_metrics_used": [
      "LLM Judge: relevance",
      "LLM Judge: completeness",
      "LLM Judge: accuracy",
      "LLM Judge: specificity",
      "LLM Judge: clarity",
      "LLM Judge: average score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can a small open LLM (Gemma-2B) be instruction-tuned into a domain-specific cybersecurity model for MITRE ATT&CK-aligned reasoning?",
        "How do prompt length distributions and hardware limits constrain effective context window usage, and what prompting/quantization strategies mitigate this?",
        "Does integrating RAG with graph-based reasoning and GNN node scoring improve retrieval quality and TTP alignment on MITRE-style queries?"
      ],
      "gaps_identified": [
        "\"In cybersecurity, high-quality labeled data is scarce, often sensitive, and typically imbalanced toward benign activity.\"",
        "\"Uneven prompt lengths complicate the model’s ability to optimize its context window usage, effectively constraining local inference to 200–400 tokens—despite support for 2048.\"",
        "\"baseline accuracy of models under 2 billion parameters... remained below 20%\""
      ],
      "limitations": [
        "\"token length of 397... enabled stable training across all epochs\" (24GB GPU, batch size 4), limiting 1–2 shot prompting",
        "Maximum output length configured to 200 tokens during inference",
        "Evaluation so far limited; authors plan broader comparisons against standard LLM baselines",
        "Reliance on cloud LLMs (>175B) to generate synthetic data due to small-model accuracy constraints",
        "No evidence of testing on real enterprise SOC data; datasets primarily synthetic or knowledge-base derived"
      ],
      "future_work": [
        "Compare the fine-tuned model against other standard LLM baselines using an automated LLM-based judge framework",
        "Comprehensive assessment across more tasks and datasets beyond illustrative 1–2 shot scenarios",
        "Expand long-context and multi-hop reasoning evaluations with larger token windows and memory-efficient methods"
      ],
      "motivation": "General-purpose LLMs lack deep cybersecurity domain expertise; aim to create a domain-adapted, efficient local LLM with improved MITRE ATT&CK alignment using RAG and graph reasoning under resource constraints.",
      "potential_research_ideas": [
        "Release and expand the 2,398-sample instruction dataset; add real, de-identified SOC logs to reduce domain shift and evaluate generalization.",
        "Distill a large cloud LLM (teacher) into the fine-tuned 2B model with supervised contrastive alignment on MITRE TTP labels.",
        "Adversarially evaluate and train the system against prompt injection, retrieval poisoning, and red-team perturbations for CTI tasks.",
        "Integrate heterogeneous-graph GNNs (e.g., metapath/relational GNN) and knowledge graph embeddings for richer TTP retrieval and reasoning.",
        "Train a reranker (cross-encoder) or use fusion-in-decoder to improve retrieval grounding before generation.",
        "Add uncertainty estimation and hallucination detection calibrated to ATT&CK taxonomy (e.g., abstain when low confidence).",
        "Evaluate multi-agent or tool-augmented ReAct-style strategies to run IOC lookups and sandbox queries during reasoning."
      ],
      "architectural_improvement_recommendations": [
        "Adopt long-context techniques (RoPE scaling, ALiBi, FlashAttention-2) to raise effective context beyond 397 tokens on 24GB GPUs.",
        "Use QLoRA with higher LoRA rank search and paged optimizers to improve small-model capacity without exceeding memory.",
        "Train a retrieval-aware generator (RAT/RAG-end2end) with supervised signals on relevant chunk selection from MITRE/CTI sources.",
        "Replace generic GNN with a heterogeneous/relational GNN over STIX object types; pretrain with link prediction and TTP-path supervision.",
        "Introduce a cross-encoder reranker between retriever and generator; fine-tune on LLM-judged pairwise preferences for MITRE relevance.",
        "Perform curriculum training from CoT to instruction-level prompts with gradually increasing context and multi-hop complexity.",
        "Use parameter-efficient adapters for modality-specific inputs (logs, alerts) and platform-specific ATT&CK variants (Windows/Linux/macOS)."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/viyer-research/mitre-gnn-analysis",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Fine-tuning on a single 24GB GPU with 4-bit quantized weights (QLoRA-style), batch size 4, token length 397, dynamic padding; inference max output 200 tokens."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Local/on-prem deployment on 24GB GPU; resource-efficient small LLM",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Context window effectively constrained to ~200–400 tokens despite larger nominal support",
        "Parser errors at default token lengths (1024–2048) with given batch size on 24GB GPU",
        "Small-model baseline accuracy (<2B params) below 20% without synthetic data support",
        "Dependence on cloud LLMs to generate synthetic training data",
        "Limited to 1–2 shot prompting under current memory constraints"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Methodology to instruction-tune Gemma-2B into a domain-specific cybersecurity LLM with chain-of-thought styled prompts and quantized weights.",
      "Synthetic data generation framework aligned to MITRE ATT&CK, producing instruction-format samples and synthetic logs.",
      "Hybrid strategy: cloud LLMs for synthetic data generation; local fine-tuning for efficient deployment.",
      "Integration of RAG and graph-based reasoning with STIX-based threat intelligence for structured MITRE alignment.",
      "GraphRAG + GNN architecture that improves LLM Judge average score over Pure RAG and Graph+LLM on MITRE-style queries.",
      "Empirical analysis of prompt length distribution constraints and practical fine-tuning configurations on 24GB GPUs."
    ]
  },
  {
    "arxiv_id": "2601.03287v1",
    "title": "Automated Post-Incident Policy Gap Analysis via Threat-Informed Evidence Mapping using Large Language Models",
    "authors": "Huan Lin Oh; Jay Yong Jun Jie; Mandy Lee Ling Siu; Jonathan Pan",
    "abstract": "Cybersecurity post-incident reviews are essential for identifying control failures and improving organisational resilience, yet they remain labour-intensive, time-consuming, and heavily reliant on expert judgment. This paper investigates whether Large Language Models (LLMs) can augment post-incident review workflows by autonomously analysing system evidence and identifying security policy gaps. We present a threat-informed, agentic framework that ingests log data, maps observed behaviours to the MITRE ATT&CK framework, and evaluates organisational security policies for adequacy and compliance. Using a simulated brute-force attack scenario against a Windows OpenSSH service (MITRE ATT&CK T1110), the system leverages GPT-4o for reasoning, LangGraph for multi-agent workflow orchestration, and LlamaIndex for traceable policy retrieval. Experimental results indicate that the LLM-based pipeline can interpret log-derived evidence, identify insufficient or missing policy controls, and generate actionable remediation recommendations with explicit evidence-to-policy traceability. Unlike prior work that treats log analysis and policy validation as isolated tasks, this study integrates both into a unified end-to-end proof-of-concept post-incident review framework. The findings suggest that LLM-assisted analysis has the potential to improve the efficiency, consistency, and auditability of post-incident evaluations, while highlighting the continued need for human oversight in high-stakes cybersecurity decision-making.",
    "published_date": "2026-01-04",
    "pdf_link": "https://arxiv.org/pdf/2601.03287v1",
    "paper_types": [
      "position",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Governance, Risk, and Compliance (GRC)",
      "subdomain": "Policy Compliance and Post-Incident Review",
      "specific_problem": "Automated post-incident policy gap analysis by mapping log-derived evidence to MITRE ATT&CK and evaluating organisational security policies",
      "attack_types": [
        "Brute Force (MITRE ATT&CK T1110)",
        "Credential Access"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM",
        "specific": "GPT-4o",
        "novel_contribution": "Used as the core reasoning engine in an agentic, threat-informed pipeline that links logs to ATT&CK techniques and evaluates policies with explicit evidence-to-policy traceability."
      },
      {
        "type": "primary",
        "category": "Retrieval-Augmented Generation (RAG)",
        "specific": "LlamaIndex semantic retrieval with line-level metadata",
        "novel_contribution": "Traceable policy retrieval to support auditable evidence-to-policy mapping."
      },
      {
        "type": "primary",
        "category": "Agent Framework / Orchestration",
        "specific": "LangGraph multi-agent workflow",
        "novel_contribution": "Modular multi-agent pipeline for log interpretation, threat attribution, policy retrieval, and gap analysis with persistent state for traceability."
      },
      {
        "type": "primary",
        "category": "Prompt Engineering / Controlled Decoding",
        "specific": null,
        "novel_contribution": "Role-specific, constrained prompts and fixed temperature to reduce variability and discourage unsupported conclusions."
      }
    ],
    "learning_paradigm": [
      "Prompt-based in-context learning",
      "Retrieval-Augmented Generation (RAG)",
      "Agentic multi-step reasoning"
    ],
    "datasets": [
      {
        "name": "Simulated Windows Event Logs (EVTX) for brute-force attack on OpenSSH",
        "type": "synthetic",
        "domain": "log_files (Windows Event Logs)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Organisational Security Policies (PDF corpus)",
        "type": "proprietary",
        "domain": "policy_documents",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "NIST SP 800-53 (baseline controls referenced)",
        "type": "public",
        "domain": "policy_documents",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ISO/IEC 27001 (baseline controls referenced)",
        "type": "public",
        "domain": "policy_documents",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CIS Critical Security Controls (baseline controls referenced)",
        "type": "public",
        "domain": "policy_documents",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can an LLM-driven, agentic workflow autonomously analyse system evidence (logs), map behaviours to MITRE ATT&CK, and identify gaps in organisational security policies?",
        "Can such a workflow produce interpretable, auditable, evidence-grounded outputs suitable for post-incident governance and compliance review?",
        "Does the approach improve efficiency and consistency of post-incident evaluations while preserving human oversight?"
      ],
      "gaps_identified": [
        "Existing work treats log analysis, threat detection, and policy compliance as isolated tasks rather than an integrated end-to-end post-incident workflow.",
        "Document-centric compliance tools rarely incorporate post-incident technical evidence.",
        "Lack of explicit, traceable linkage between analytical conclusions, verifiable log evidence, and specific policy clauses.",
        "Adoption barriers due to hallucination, limited context windows, and insufficient traceability in audit-critical environments."
      ],
      "limitations": [
        "Single simulated scenario (Windows OpenSSH brute-force) and a single evidence source (Windows Event Logs).",
        "Relies on a single LLM (no cross-model benchmarking); output variability remains despite prompt controls.",
        "Quality depends on completeness/clarity of ingested policy documents; ambiguous/outdated policies can degrade retrieval and assessment.",
        "No quantitative performance evaluation or timing comparison versus human analysts.",
        "Operational deployment concerns around data governance, privacy, and secure handling of sensitive logs/policies with external model APIs."
      ],
      "future_work": [
        "Evaluate across more scenarios, including multi-stage attacks and heterogeneous evidence sources (network, endpoint, cloud audit logs) with cross-system correlation.",
        "Benchmark multiple LLMs/configurations for reasoning consistency, reliability, and cost-performance; explore ensembles, deterministic decoding, and verification-based prompting.",
        "Introduce quantitative metrics (analyst time savings, consistency across runs, agreement with expert assessments).",
        "Explore secure on-premise/private-cloud deployments, access control mechanisms, and human-in-the-loop validation frameworks."
      ],
      "motivation": "Post-incident reviews are manual, time-consuming, and expert-heavy; need to connect technical evidence with policy evaluation in a traceable, auditable way and assess adequacy of controls under real attack conditions.",
      "potential_research_ideas": [
        "Generalize the framework to multi-source, multi-stage incidents with automated correlation (SIEM/EDR/cloud logs) and evaluate end-to-end effectiveness.",
        "Integrate a verification layer (self-consistency, multi-agent debate, chain-of-verification) to reduce hallucinations and improve audit trustworthiness.",
        "Develop a policy knowledge graph/ontology that aligns organisational clauses with ATT&CK techniques, NIST/ISO/CIS controls for structured mapping and gap reasoning.",
        "Automate policy remediation synthesis: generate draft policy updates and control configurations conditioned on evidence and baseline frameworks.",
        "Design a synthetic log/evidence generator for controlled stress-testing of the pipeline across attack techniques and noise levels.",
        "Evaluate and optimize cost-latency trade-offs using smaller/open models with retrieval and tool-use, and hybrid routing (open-source local for sensitive data).",
        "Add uncertainty quantification and calibration for finding-level confidence with empirical validation against expert labels."
      ],
      "architectural_improvement_recommendations": [
        "Adopt hybrid retrieval (BM25 + embeddings) with vector DB and line/section-level citations to improve grounding.",
        "Implement structured outputs with schemas and guardrails (Pydantic/JSON schema) and function/tool calling for deterministic reasoning steps.",
        "Introduce a chain-of-verification/reflection agent and ensemble-of-reasoners to cross-check evidence-to-policy mappings.",
        "Maintain an evidence graph (events, ATT&CK techniques, policies, controls) to support explainability and cross-evidence correlation.",
        "Support on-prem LLM inference and data redaction/pseudonymization to address privacy/governance constraints.",
        "Add evaluation harness with scenario libraries and golden labels to measure consistency, precision of mappings, and reviewer time savings."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "LangGraph",
        "LlamaIndex",
        "OpenAI GPT-4o",
        "Python"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "No model training; API-based inference with GPT-4o. Deterministic Python preprocessing from EVTX->XML->CSV. Commodity compute sufficient for orchestration."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Laboratory simulation using Windows OpenSSH brute-force scenario; LLM inference via external API.",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Model hallucination and variability across runs in audit-critical contexts.",
        "Limited context windows and need for strong traceability.",
        "Data governance and privacy when sending sensitive logs/policies to external APIs.",
        "Dependence on policy document quality for accurate retrieval and assessment."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "An end-to-end, agentic post-incident review workflow integrating log analysis, threat attribution, and policy gap identification.",
      "Threat-informed evidence-to-policy mapping grounded in the MITRE ATT&CK framework (T1110).",
      "Interpretable and auditable workflow design with explicit evidence-to-policy traceability.",
      "Proof-of-concept showing LLMs can interpret log-derived evidence, identify missing/insufficient controls, and generate remediation recommendations.",
      "Implementation with GPT-4o for reasoning, LangGraph for orchestration, and LlamaIndex for traceable policy retrieval."
    ]
  },
  {
    "arxiv_id": "2601.06553v1",
    "title": "A Bayesian Network-Driven Zero Trust Model for Cyber Risk Quantification in Small-Medium Businesses",
    "authors": "Ahmed M. Abdelmagid; Barry C. Ezell; Michael McShane",
    "abstract": "Small-Medium Businesses (SMBs) are essential to global economies yet remain highly vulnerable to cyberattacks due to limited budgets, inadequate cybersecurity expertise, and underestimation of cyber risks. Their increasing reliance on digital infrastructures has expanded their attack surfaces, exposing them to sophisticated and evolving threats. Consequently, implementing proactive, adaptive security measures has become imperative. This research investigates the effectiveness of Zero Trust Architecture (ZTA) as a sustainable cybersecurity solution tailored to SMBs. While ZTA adoption has been examined broadly, the specific financial, organizational, and capability constraints of SMBs remain underexplored. This study develops an integrated predictive model to assess both the feasibility and risk-mitigation potential of ZTA implementation. The model consists of two sub-models. The first sub-model evaluates the probability of successful ZTA adoption considering implied barriers, and the second tests the effectiveness of ZTA in responding to prevalent cyberattacks. The integrated model predicts the risk level in the presence of ZTA and quantifies the uncertainty of the extent to which ZTA can enhance SMBs' cyber resilience, contributing novel insights for practitioners and stakeholders seeking to enhance compliance with policies, risk, and governance activities in SMBs.",
    "published_date": "2026-01-10",
    "pdf_link": "https://arxiv.org/pdf/2601.06553v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Risk Management",
      "subdomain": "Zero Trust Architecture (ZTA) adoption and assessment",
      "specific_problem": "Quantifying SMB cyber risk and feasibility/effectiveness of ZTA adoption using Bayesian Networks",
      "attack_types": [
        "ransomware",
        "phishing",
        "malware",
        "data breach"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Probabilistic Graphical Model",
        "specific": "Bayesian Network",
        "novel_contribution": "Two interlinked BN sub-models: (1) ZTA adoption success probability given financial/organizational barriers; (2) ZTA effectiveness against prevalent attacks; integrated to predict risk levels and quantify uncertainty for SMBs."
      }
    ],
    "learning_paradigm": [
      "Probabilistic modeling",
      "Bayesian inference",
      "Simulation"
    ],
    "datasets": [
      {
        "name": "Unknown (real-world cyberattack incidents dataset referenced by [22])",
        "type": "proprietary",
        "domain": "incident_reports",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "probability of ZTA adoption success",
      "probability of data breach",
      "risk level/magnitude under ZTA",
      "uncertainty quantification of outcomes"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1: What is the impact of the financial and organizational barriers of ZTA on its adoption success?",
        "RQ2: What are the relevant ZT security pillars and the associated security measures that could enhance SMBs' cybersecurity against certain cyber risks?",
        "RQ3: How effective is the adoption of ZT security tools in the context of SMBs in reducing the magnitude of risk?",
        "RQ4: How do various ZT controls affect the likelihood of data breach incidents in SMBs adopting ZTA?",
        "RQ5: Which attack vectors pose the highest probability of a data breach incident, leading to the highest overall cyber risk level?"
      ],
      "gaps_identified": [
        "Absence of standardized, evidence-based frameworks and benchmarks guiding ZTA implementation, especially for SMBs.",
        "Limited research on how SMB-specific financial, organizational, and capability constraints affect ZTA implementation success.",
        "Unclear ROI and lack of standardized cost frameworks for ZTA.",
        "Challenges integrating ZTA with legacy systems and multi-vendor environments.",
        "Conceptual ambiguities in ZTA guidance (e.g., levels of trust, component interactions) leading to subjective implementations.",
        "Lack of structured methodologies to translate ZTA concepts into actionable decisions for SMB leadership."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Provide a risk-informed, evidence-based decision model to assess ZTA feasibility and its cyber risk reduction potential for SMBs under financial and organizational constraints.",
      "potential_research_ideas": [
        "Learn BN structure from data and combine with expert elicitation to reduce modeling bias; compare with manually engineered BN.",
        "Extend to Dynamic Bayesian Networks to capture temporal attack progression and the evolving impact of ZT controls.",
        "Integrate explicit MITRE ATT&CK tactic/technique nodes and map ZT controls to them for fine-grained what-if analysis.",
        "Develop a standardized ZTA cost/ROI submodel linked to risk reduction to support investment optimization for SMBs.",
        "Cross-sector and cross-region validation to assess generalizability and calibrate priors using sector-specific incident statistics.",
        "Counterfactual and causal inference analysis to estimate the effect of individual ZT controls on breach likelihood.",
        "Robustness analysis under data shift and sparse data regimes; evaluate sensitivity to prior assumptions.",
        "Decision-support tool with interactive scenario analysis for SMB stakeholders; conduct user studies on decision quality."
      ],
      "architectural_improvement_recommendations": [
        "Adopt a hierarchical BN separating People–Process–Technology layers with subgraphs for specific ZTA pillars.",
        "Upgrade to a Dynamic BN to model sequences of attacker actions and control activations over time.",
        "Fuse BN with attack graphs or kill-chain models for richer causal pathways and path-dependent risk.",
        "Calibrate and validate priors with Bayesian hierarchical modeling using sector-specific incident rates.",
        "Incorporate a cost–effectiveness/ROI node and multi-objective decision nodes (risk vs. cost vs. usability).",
        "Automate parameter learning from SIEM/log data where available, with expert priors as regularization."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "SMB enterprise IT environments (general)",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Financial constraints and unclear ROI for ZTA investments",
        "Legacy system integration and interoperability across vendors",
        "Limited cybersecurity expertise and staffing in SMBs",
        "Organizational resistance to change and user friction (e.g., MFA, continuous monitoring)",
        "Configuration complexity and increased operational burden",
        "Supply chain risk and alignment with partner ecosystems"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Integrated predictive model with two interlinked Bayesian Network sub-models to assess ZTA adoption feasibility and effectiveness against cyberattacks for SMBs.",
      "Risk-informed decision-making framework that quantifies uncertainty and predicts risk levels under ZTA.",
      "Operationalization of People–Process–Technology pillars within the ZTA risk model, including insider behavior, organizational/financial barriers, and technological enablers.",
      "Application of BN modeling to simulate cyberattack scenarios and evaluate ZT control impacts tailored to SMB constraints."
    ]
  },
  {
    "arxiv_id": "2601.06690v1",
    "title": "S-DAPT-2026: A Stage-Aware Synthetic Dataset for Advanced Persistent Threat Detection",
    "authors": "Saleem Ishaq Tijjani; Bogdan Ghita; Nathan Clarke; Matthew Craven",
    "abstract": "The detection of advanced persistent threats (APTs) remains a crucial challenge due to their stealthy, multistage nature and the limited availability of realistic, labeled datasets for systematic evaluation. Synthetic dataset generation has emerged as a practical approach for modeling APT campaigns; however, existing methods often rely on computationally expensive alert correlation mechanisms that limit scalability. Motivated by these limitations, this paper presents a near realistic synthetic APT dataset and an efficient alert correlation framework. The proposed approach introduces a machine learning based correlation module that employs K Nearest Neighbors (KNN) clustering with a cosine similarity metric to group semantically related alerts within a temporal context. The dataset emulates multistage APT campaigns across campus and organizational network environments and captures a diverse set of fourteen distinct alert types, exceeding the coverage of commonly used synthetic APT datasets. In addition, explicit APT campaign states and alert to stage mappings are defined to enable flexible integration of new alert types and support stage aware analysis. A comprehensive statistical characterization of the dataset is provided to facilitate reproducibility and support APT stage predictions.",
    "published_date": "2026-01-10",
    "pdf_link": "https://arxiv.org/pdf/2601.06690v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection / APT Detection",
      "specific_problem": "Stage-aware APT campaign modeling and efficient alert correlation for multi-stage APT detection",
      "attack_types": [
        "Advanced Persistent Threat (multi-stage)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "K-Nearest Neighbors (KNN) with cosine similarity within temporal window",
        "novel_contribution": "Machine-learning-based alert correlation that uses KNN with cosine similarity to group semantically related alerts within a temporal context, reducing computational cost versus prior correlation mechanisms."
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "S-DAPT-2026",
        "type": "synthetic",
        "domain": "network_traffic + host_logs + security_alerts",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "DARPA 1998/1999",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "KDD Cup 1999",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ISCXIDS2012",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MAWI",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NGIDS-DS",
        "type": "public",
        "domain": "network_traffic + host_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "TRAbID",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Ghafir-2019 (APT multi-stage dataset)",
        "type": "public",
        "domain": "network_traffic + host_logs + security_alerts",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "DAPT 2020",
        "type": "public",
        "domain": "network_flows + system_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Unraveled",
        "type": "public",
        "domain": "network_traffic + host_logs + security_alerts",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS (APT-IIoT)",
        "type": "public",
        "domain": "network_traffic (IIoT testbed)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "HERITRIX",
        "type": "public",
        "domain": "unknown",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Absence of standardized evaluation methodologies and realistic, stage-aware APT datasets.",
        "Existing datasets are outdated, overly anonymized, or fail to capture the dynamic multi-phase nature of modern APT campaigns.",
        "Over 85% of intrusion detection research relies on legacy datasets (e.g., NSL-KDD, DARPA 1998) that do not reflect current threat landscapes.",
        "Existing synthetic APT datasets often rely on computationally expensive alert correlation mechanisms that limit scalability.",
        "Many datasets lack contextual information about defender response and lack explicit stage-aware annotations needed for modeling APT campaigns."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Detecting APTs is challenging due to their stealthy, multi-stage nature and the limited availability of realistic labeled datasets; existing synthetic approaches also suffer from computationally expensive alert correlation, motivating a stage-aware synthetic dataset and an efficient KNN-based correlation framework.",
      "potential_research_ideas": [
        "Evaluate and compare the proposed KNN-based alert correlation with graph-based correlation (e.g., temporal heterogeneous graphs, GNNs) for improved semantic grouping.",
        "Augment S-DAPT-2026 with explicit defender response labels and counterfactual attacker adaptations to study adversarial dynamics.",
        "Introduce online/streaming alert correlation to handle real-time APT detection with concept drift handling.",
        "Integrate richer semantic embeddings (e.g., sentence-transformer embeddings of alert text) before KNN to improve similarity beyond cosine on sparse features.",
        "Extend the dataset with cross-domain telemetry (EDR events, DNS logs, cloud audit logs) to model hybrid on-prem/cloud APTs.",
        "Benchmark stage prediction models (sequence models, TCNs, Transformers) on S-DAPT-2026 to establish reference baselines."
      ],
      "architectural_improvement_recommendations": [
        "Replace pure KNN-based clustering with density-based clustering (e.g., HDBSCAN) on learned embeddings to automatically discover variable-sized alert groups.",
        "Learn alert embeddings via contrastive/self-supervised objectives that incorporate temporal proximity and shared campaign labels, then perform KNN on embeddings.",
        "Incorporate temporal decay kernels and sliding-window graph construction to better respect alert chronology.",
        "Add multi-source data fusion and attention over modalities (network, host logs, alerts) for correlation decisions.",
        "Implement scalable approximate nearest neighbor search (e.g., FAISS) for large-scale alert streams."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Emulated campus and organizational network environments",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Correlating malicious events in distributed/cloud environments is complicated, enabling APTs to evade detection.",
        "High computational cost of traditional alert correlation approaches limits scalability; addressed here with KNN-based correlation."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Near-realistic synthetic APT dataset (S-DAPT-2026) emulating multi-stage attacks with 14 distinct alert types across campus and organizational network settings.",
      "Definition of explicit APT campaign states and alert-to-stage mappings to enable dynamic integration of new alert types and stage-aware analysis.",
      "Machine learning-based alert correlation using KNN with cosine similarity within a temporal window to group semantically related alerts efficiently.",
      "Comprehensive statistical characterization of the dataset to facilitate reproducibility and support APT stage prediction tasks."
    ]
  },
  {
    "arxiv_id": "2601.12426v1",
    "title": "Graph Attention Networks with Physical Constraints for Anomaly Detection",
    "authors": "Mohammadhossein Homaei; Iman Khazrak; Ruben Molano; Andres Caro; Mar Avila",
    "abstract": "Water distribution systems (WDSs) face increasing cyber-physical risks, which make reliable anomaly detection essential. Many data-driven models ignore network topology and are hard to interpret, while model-based ones depend strongly on parameter accuracy. This work proposes a hydraulic-aware graph attention network using normalized conservation law violations as features. It combines mass and energy balance residuals with graph attention and bidirectional LSTM to learn spatio-temporal patterns. A multi-scale module aggregates detection scores from node to network level. On the BATADAL dataset, it reaches $F1=0.979$, showing $3.3$pp gain and high robustness under $15\\%$ parameter noise.",
    "published_date": "2026-01-18",
    "pdf_link": "https://arxiv.org/pdf/2601.12426v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Critical Infrastructure Security",
      "subdomain": "ICS/SCADA Security",
      "specific_problem": "Anomaly detection in water distribution systems (WDS) SCADA data",
      "attack_types": [
        "data manipulation",
        "actuator control",
        "pump shutdown",
        "flow setpoint manipulation",
        "sensor spoofing"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "GNN",
        "specific": "Graph Attention Network (GAT)",
        "novel_contribution": "Hydraulic-aware GAT using normalized conservation law violations (mass and energy balance residuals) as node features with adaptive multi-scale fusion"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "Bidirectional LSTM",
        "novel_contribution": "Temporal fusion of GAT spatial embeddings over a 24-hour window to capture bidirectional temporal dependencies"
      },
      {
        "type": "primary",
        "category": "Custom Loss/Regularization",
        "specific": null,
        "novel_contribution": "Composite loss with physics regularizer that penalizes conservation law violations during normal operation and a spatio-temporal consistency term"
      },
      {
        "type": "primary",
        "category": "Pooling/Fusion",
        "specific": "Adaptive multi-scale (micro/meso/macro) fusion with Louvain clustering and attention pooling",
        "novel_contribution": "Hierarchical score aggregation with learnable scale weights for node-, cluster-, and network-level anomaly detection"
      },
      {
        "type": "baseline",
        "category": "RNN",
        "specific": "BiLSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Autoencoder",
        "specific": "CVAE",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GCN + BiLSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "GraphSAGE + BiLSTM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Graph Transformer",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Model-based residual analysis",
        "specific": "EPANET residuals with thresholds (BATADAL winner)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Classical ML",
        "specific": "Random Forest, SVM",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "BATADAL (C-Town)",
        "type": "public",
        "domain": "water_distribution_scada",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "D-Town (from 2024 Multi-Network Cyber-Physical Dataset)",
        "type": "public",
        "domain": "water_distribution_scada",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "L-Town (from 2024 Multi-Network Cyber-Physical Dataset)",
        "type": "public",
        "domain": "water_distribution_scada",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Modena network (from 2024 Multi-Network Cyber-Physical Dataset)",
        "type": "public",
        "domain": "water_distribution_scada",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Synthetic network (N≈500) for inference-time scaling analysis",
        "type": "synthetic",
        "domain": "water_distribution_scada",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "BiLSTM",
        "paper_reference": "[9]",
        "metric": "F1",
        "their_result": "0.979",
        "baseline_result": "0.906"
      },
      {
        "method_name": "BiLSTM",
        "paper_reference": "[9]",
        "metric": "TTD (hours)",
        "their_result": "1.44",
        "baseline_result": "1.85"
      },
      {
        "method_name": "CVAE",
        "paper_reference": "[5]",
        "metric": "F1",
        "their_result": "0.979",
        "baseline_result": "0.938"
      },
      {
        "method_name": "CVAE",
        "paper_reference": "[5]",
        "metric": "TTD (hours)",
        "their_result": "1.44",
        "baseline_result": "1.72"
      },
      {
        "method_name": "GCN + BiLSTM",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.979",
        "baseline_result": "0.941"
      },
      {
        "method_name": "GCN + BiLSTM",
        "paper_reference": null,
        "metric": "TTD (hours)",
        "their_result": "1.44",
        "baseline_result": "1.69"
      },
      {
        "method_name": "GraphSAGE + BiLSTM",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.979",
        "baseline_result": "0.948"
      },
      {
        "method_name": "GraphSAGE + BiLSTM",
        "paper_reference": null,
        "metric": "TTD (hours)",
        "their_result": "1.44",
        "baseline_result": "1.63"
      },
      {
        "method_name": "Graph Transformer",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.979",
        "baseline_result": "0.952"
      },
      {
        "method_name": "Graph Transformer",
        "paper_reference": null,
        "metric": "TTD (hours)",
        "their_result": "1.44",
        "baseline_result": "1.58"
      },
      {
        "method_name": "B1 (Model-Based EPANET residuals, BATADAL winner)",
        "paper_reference": "[7]",
        "metric": "F1",
        "their_result": "0.979",
        "baseline_result": "0.946"
      },
      {
        "method_name": "B1 (Model-Based EPANET residuals, BATADAL winner)",
        "paper_reference": "[7]",
        "metric": "TTD (hours)",
        "their_result": "1.44",
        "baseline_result": "1.61"
      },
      {
        "method_name": "B1 vs Physics-GAT under ±15% Hazen–Williams parameter error",
        "paper_reference": "[7]",
        "metric": "F1",
        "their_result": "0.954",
        "baseline_result": "0.819"
      },
      {
        "method_name": "Zero-shot transfer (avg across D-Town, L-Town, Modena)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "0.925",
        "baseline_result": "0.805"
      }
    ],
    "performance_metrics_used": [
      "F1-score",
      "Time-to-Detection (TTD, hours)",
      "95% Confidence Intervals (bootstrap)",
      "Cohen's d (effect size)",
      "Spearman correlation (attention alignment with hydraulic paths)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can a GNN that uses physics violation and topology improve anomaly detection in WDSs, with better robustness and explainability?"
      ],
      "gaps_identified": [
        "Dependency on uncertain parameters in model-based methods",
        "Deep models that ignore hydraulic topology",
        "Missing explicit use of conservation (mass/energy) features",
        "Lack of multi-scale detection for fault localization"
      ],
      "limitations": [
        "Mass-balance feature depends on estimated demand, retaining epistemic uncertainty",
        "GAT complexity hampers scaling when N > 500 unless mini-batch inference is used",
        "Resistance to adaptive adversarial attacks not evaluated",
        "In 2 of 14 attacks, attention scattered across disconnected subgraphs (need attention supervision)"
      ],
      "future_work": [
        "Test multiple network topologies (broader than those used) and study adversarial robustness against advanced cyber-physical attacks",
        "Introduce attention supervision to reduce scattered attention",
        "Mini-batch/streaming inference for very large graphs (N ≥ 1000)",
        "Further evaluate robustness under varied sensor outages and demand uncertainties"
      ],
      "motivation": "Bridge physics-based and data-driven approaches to achieve accurate, interpretable, and robust anomaly detection in water distribution systems that respects topology and physical conservation laws.",
      "potential_research_ideas": [
        "Adversarially robust training for cyber-physical attacks (e.g., PGD on time series and topology-aware perturbations) to harden anomaly detection",
        "Self-supervised pretraining on normal operations (contrastive forecasting or masked sensor modeling) to improve zero-shot transfer",
        "Causal discovery over hydraulic graphs to distinguish causal propagation from spurious correlations",
        "Active sensor placement optimization guided by GAT attention/uncertainty to maximize detection/localization",
        "Domain adaptation/meta-learning across heterogeneous WDS topologies for rapid fine-tuning",
        "Uncertainty-aware anomaly scoring (Bayesian GNNs or deep ensembles) for calibrated alerts",
        "Differentiable physics integration (e.g., differentiable EPANET surrogate) to refine conservation residuals end-to-end",
        "Attack taxonomy-aware multi-task learning (detection + localization + attack type classification)"
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment BiLSTM with temporal convolution or transformer-based temporal encoders (Temporal Convolutional Networks, Temporal Graph Transformers)",
        "Edge-enhanced GAT using explicit edge features for energy gradients and hydraulic distances",
        "Add attention supervision/regularization loss using hydraulic path priors to stabilize attention",
        "Self-supervised contrastive graph pretraining on normal data before supervised fine-tuning",
        "Hierarchical pooling with learned coarsening beyond Louvain for better meso/macro representations",
        "Heterogeneous GNN modeling different node/edge types (junctions, tanks, pumps; pipes, valves) with type-specific parameters",
        "Uncertainty-aware layers (MC Dropout/ensembles) and post-hoc calibration for anomaly scores",
        "Streaming mini-batch inference with neighborhood sampling for large-scale deployments"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/Homaei/Physics-GAT",
      "frameworks": [
        "PyTorch",
        "PyTorch Geometric"
      ],
      "reproducibility_score": "high",
      "computational_requirements": "Trained with Adam (lr=1e-3, batch=32), 3 GAT layers (8 heads, 128 hidden), 24h window. Inference on NVIDIA RTX A2000: C-Town (N=128) ~48 ms; L-Town (N=334) ~127 ms; synthetic (N=500) ~294 ms; extrapolated N~1000 ~680 ms. Complexity O(LK(|V|d^2 + |E|d))."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Water utility ICS/SCADA for water distribution networks",
      "scalability_discussed": true,
      "inference_time": "≈48 ms (N=128), 127 ms (N=334), 294 ms (N=500) on RTX A2000; extrapolated ≈680 ms for N=1000",
      "deployment_challenges": [
        "Scaling GAT to very large networks without mini-batch/streaming inference",
        "Epistemic uncertainty in demand estimates affecting mass-balance features",
        "Generalization to networks with different topology and parameter ranges",
        "Handling sensor outages and missing data in real time",
        "Unknown robustness to adaptive adversarial attacks"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduce Physics-GAT: a physics-aware GAT with BiLSTM for WDS anomaly detection using normalized conservation law violations as features",
      "Propose adaptive multi-scale detection (micro/meso/macro) with Louvain clustering and learnable fusion",
      "Design composite training loss with physics regularization and spatio-temporal consistency",
      "Demonstrate SOTA performance on BATADAL (F1=0.979; TTD=1.44h), +3.3pp over model-based baseline; significant effect size and non-overlapping CIs",
      "Show robustness to ±15% hydraulic parameter uncertainty (<3% F1 drop) and resilience to sensor outages",
      "Provide explainability through attention paths aligned with hydraulic flow (ρ≈0.81) and attribution to mass/energy violations",
      "Validate multi-network transfer (zero-shot and fine-tuned) across D-Town, L-Town, Modena",
      "Release code and replication files"
    ]
  },
  {
    "arxiv_id": "2601.00783v1",
    "title": "Improving Router Security using BERT",
    "authors": "John Carter; Spiros Mancoridis; Pavlos Protopapas; Brian Mitchell; Benji Lilley",
    "abstract": "Previous work on home router security has shown that using system calls to train a transformer-based language model built on a BERT-style encoder using contrastive learning is effective in detecting several types of malware, but the performance remains limited at low false positive rates. In this work, we demonstrate that using a high-fidelity eBPF-based system call sensor, together with contrastive augmented learning (which introduces controlled mutations of negative samples), improves detection performance at a low false positive rate. In addition, we introduce a network packet abstraction language that enables the creation of a pipeline similar to network packet data, and we show that network behavior provides complementary detection signals-yielding improved performance for network-focused malware at low false positive rates. Lastly, we implement these methods in an online router anomaly detection framework to validate the approach in an Internet of Things (IoT) deployment environment.",
    "published_date": "2026-01-02",
    "pdf_link": "https://arxiv.org/pdf/2601.00783v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Anomaly Detection",
      "specific_problem": "Router-level behavioral malware detection at low false positive rates using system calls and network packet behavior",
      "attack_types": [
        "malware",
        "network-focused malware",
        "zero-day style behavior"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "BERT-style encoder (trained from scratch)",
        "novel_contribution": "Contrastive augmented learning with controlled mutations of negative samples to improve robustness at low false positive rates"
      },
      {
        "type": "primary",
        "category": "Representation Learning",
        "specific": "Triplet loss (margin-based contrastive loss)",
        "novel_contribution": "Triplet construction with temporally adjacent positives and future-window negatives mutated at 10–20% token rate"
      },
      {
        "type": "primary",
        "category": "Embedding",
        "specific": "sys2vec",
        "novel_contribution": "Used with a high-fidelity eBPF syscall sensor; integrated into BERT via projection to 768-dim space"
      },
      {
        "type": "primary",
        "category": "Embedding",
        "specific": "net2vec (Word2Vec in Gensim)",
        "novel_contribution": "New packet abstraction language tokens embedded into 64-d vectors for packet-sequence modeling"
      },
      {
        "type": "primary",
        "category": "Anomaly Detection",
        "specific": "Isolation Forest",
        "novel_contribution": "Trained on benign embeddings (pairwise cosine features for syscalls per [2], raw embeddings for packets) to convert representation to anomaly scores"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "BERT with standard contrastive learning (no mutation)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Mining Strategy",
        "specific": "Hard-negative mining (sample 50 candidates; pick max distance)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Embedding",
        "specific": "Fixed random embeddings (ablation vs net2vec)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised (contrastive)",
      "Unsupervised (anomaly detection via Isolation Forest)"
    ],
    "datasets": [
      {
        "name": "Home router system call traces (replicated environment from Carter et al. [2])",
        "type": "private",
        "domain": "system_calls",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Home router network packet abstraction sequences",
        "type": "private",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Standard contrastive learning (no mutation)",
        "paper_reference": null,
        "metric": "Detection performance at low false positive rate",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Hard-negative mining (replication of prior SOTA in [2])",
        "paper_reference": "Carter et al. [2]",
        "metric": "Detection performance at low false positive rate",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "Fixed random embeddings (vs net2vec)",
        "paper_reference": null,
        "metric": "Stability across contamination rates / detection performance",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "False Positive Rate (FPR)",
      "True Positive Rate (TPR) at low FPR",
      "Isolation Forest contamination (target FPR proxy)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does a high-fidelity eBPF-based system call sensor improve low-FPR malware detection versus generic tracers?",
        "Can contrastive augmented learning with controlled negative mutations improve robustness at low false positive rates compared to standard contrastive learning?",
        "Does a network packet abstraction language provide complementary detection signals to system-call–based models, especially for network-focused malware?",
        "Can the proposed methods operate online on routers without PID filtering using smoothing (EMA)?"
      ],
      "gaps_identified": [
        "Prior syscall-based BERT anomaly detection exhibited limited robustness at low false positive rates for always-on router deployments",
        "Limited exploration of LLM-style sequence modeling for machine-generated languages like system calls and packet abstractions in router contexts",
        "Lack of online, deployable anomaly detection frameworks tailored to router environments"
      ],
      "limitations": [
        "Offline evaluation isolates malware by PID filtering; deployment must operate without PID filtering and relies on EMA smoothing",
        "No public release of data; evaluation depends on a replicated lab environment",
        "Quantitative details for all attack families and operating points are not included in the provided text"
      ],
      "future_work": [],
      "motivation": "Improve practical, low-FPR behavioral malware detection on home/IoT routers by enhancing data fidelity, training robustness, and incorporating complementary network behavior, and validate in an online deployment scenario.",
      "potential_research_ideas": [
        "Joint multi-modal modeling of syscalls and packet abstractions with cross-attention or late fusion to further reduce low-FPR misses",
        "Self-supervised pretraining (e.g., masked language modeling) on large-scale benign router traffic prior to contrastive fine-tuning",
        "Continual/online learning on-device with drift detection to adapt benign profiles while avoiding catastrophic forgetting",
        "Harder negative generation using semantics-preserving augmentations (e.g., packet-level flow shuffles, syscall template substitutions) guided by domain knowledge",
        "Adversarial robustness evaluation and defenses against mimicry attacks that craft sequences resembling benign behavior",
        "Explainability methods (e.g., token/segment attribution) to highlight influential syscall/packet tokens for operator trust",
        "Federated training across routers to improve generalization without sharing raw traffic for privacy"
      ],
      "architectural_improvement_recommendations": [
        "Unified transformer with two input streams (syscalls and packets) and cross-attention fusion; compare to score-level ensembling",
        "Dynamic windowing via learned segmenters or sliding windows with overlap and attention pooling to better capture variable-length behaviors",
        "Replace triplet loss with InfoNCE or supervised contrastive loss variants and temperature scaling for more stable training",
        "Learned negative sampling (semi-hard mining) plus curriculum on mutation rates to avoid over/under-difficulty",
        "Incorporate flow-level features (e.g., inter-arrival times, burstiness) as positional or side-channel embeddings for packets",
        "Calibration of IF scores and thresholding with conformal prediction for reliable low-FPR operation",
        "Resource-aware distillation or pruning of BERT encoders for router-class hardware"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "HuggingFace Transformers",
        "Gensim (Word2Vec)",
        "scikit-learn (Isolation Forest)",
        "eBPF"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Home/IoT router (edge) with online anomaly detection framework",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Lack of PID filtering in deployment; mitigated by EMA smoothing of anomaly scores",
        "Need for high-fidelity, low-overhead data capture; generic tracers (e.g., ftrace) can drop events under load",
        "Operating at very low FPRs to be viable for always-on router deployments"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduce a high-fidelity eBPF-based system call sensor tailored for ML tokenization/embedding to improve data quality",
      "Propose contrastive augmented learning by mutating negative samples, improving detection at low false positive rates",
      "Introduce a network packet abstraction language and net2vec embeddings enabling a parallel pipeline to syscalls",
      "Demonstrate complementary detection signals from network behavior and recommend concurrent deployment of syscall and packet detectors",
      "Implement and validate an online router anomaly detection framework suitable for IoT deployment with EMA smoothing"
    ]
  },
  {
    "arxiv_id": "2601.06838v1",
    "title": "CHASE: LLM Agents for Dissecting Malicious PyPI Packages",
    "authors": "Takaaki Toda; Tatsuya Mori",
    "abstract": "Modern software package registries like PyPI have become critical infrastructure for software development, but are increasingly exploited by threat actors distributing malicious packages with sophisticated multi-stage attack chains. While Large Language Models (LLMs) offer promising capabilities for automated code analysis, their application to security-critical malware detection faces fundamental challenges, including hallucination and context confusion, which can lead to missed detections or false alarms. We present CHASE (Collaborative Hierarchical Agents for Security Exploration), a high-reliability multi-agent architecture that addresses these limitations through a Plan-and-Execute coordination model, specialized Worker Agents focused on specific analysis aspects, and integration with deterministic security tools for critical operations. Our key insight is that reliability in LLM-based security analysis emerges not from improving individual model capabilities but from architecting systems that compensate for LLM weaknesses while leveraging their semantic understanding strengths. Evaluation on a dataset of 3,000 packages (500 malicious, 2,500 benign) demonstrates that CHASE achieves 98.4% recall with only 0.08% false positive rate, while maintaining a practical median analysis time of 4.5 minutes per package, making it suitable for operational deployment in automated package screening. Furthermore, we conducted a survey with cybersecurity professionals to evaluate the generated analysis reports, identifying their key strengths and areas for improvement. This work provides a blueprint for building reliable AI-powered security tools that can scale with the growing complexity of modern software supply chains. Our project page is available at https://t0d4.github.io/CHASE-AIware25/",
    "published_date": "2026-01-11",
    "pdf_link": "https://arxiv.org/pdf/2601.06838v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Supply Chain Security",
      "subdomain": "Malicious Package Detection in Package Repositories",
      "specific_problem": "Detecting and dissecting malicious Python (PyPI) packages with multi-stage payloads while minimizing false positives for automated screening",
      "attack_types": [
        "typosquatting malware",
        "install-time code execution (setup.py)",
        "import-time code execution (__init__.py)",
        "downloader/staged payloads",
        "encrypted/obfuscated payloads (e.g., Fernet, base64, JJEncode-like)",
        "credential theft (e.g., AWS credential stealing)",
        "cryptomining",
        "supply-chain compromise of legitimate packages"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM Agent (Multi-agent Architecture)",
        "specific": "Plan-and-Execute Supervisor–Worker agents with state-based coordination and deterministic tool integration",
        "novel_contribution": "Reliability-oriented design: centralized state instead of message history to prevent context confusion, budget-aware planning to avoid loops, minimal and composite tools to reduce hallucination on high-entropy data, and tight integration with deterministic security tools"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Qwen3:32B (Supervisor)",
        "novel_contribution": "Used as high-reasoning orchestrator with large context for maintaining global analysis state across complex investigations"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Qwen3:8B (Worker agents)",
        "novel_contribution": "Smaller, faster workers for focused tasks (e.g., deobfuscation, web research) to improve throughput while preserving quality"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Gemma3:4B (structured output conversion)",
        "novel_contribution": "Reliable conversion of free-form analysis into JSON with minimal latency"
      }
    ],
    "learning_paradigm": [
      "Zero-shot",
      "Agentic/Tool-augmented inference"
    ],
    "datasets": [
      {
        "name": "pypi malregistry (malicious packages subset)",
        "type": "public",
        "domain": "software_packages",
        "link": "https://github.com/lxyeternal/pypi malregistry",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Random benign PyPI packages (Jul–Sep 2025)",
        "type": "public",
        "domain": "software_packages",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "recall",
      "false positive rate (FPR)",
      "median analysis time per package",
      "qualitative human evaluation (survey of cybersecurity professionals)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a reliability-oriented multi-agent LLM architecture with Plan-and-Execute and deterministic tool integration mitigate hallucination and context confusion in security-critical malware analysis?",
        "Can such an agentic system achieve high recall with extremely low false positive rate suitable for operational deployment in automated PyPI package screening?",
        "Do the generated analysis reports meet the needs of cybersecurity professionals?"
      ],
      "gaps_identified": [
        "Single LLM agents suffer from hallucination and context confusion, undermining reliability for security-critical tasks.",
        "Static analysis struggles with dynamic code construction; dynamic analysis faces resource constraints and evasion (e.g., time-delayed payloads).",
        "LLM-enhanced detection in prior work often fails to reveal complete attack chains, final malicious objectives, and IoCs.",
        "Repository operators require exceptionally low false positive rates, which is a barrier for automated scanners."
      ],
      "limitations": [
        "Analysis scope limited to setup.py, __init__.py, and Python files imported by __init__.py due to computational constraints.",
        "20-minute timeout per package; retries were needed for timeout cases to improve recall.",
        "Evaluation used packages that contain both setup.py and __init__.py, which may bias coverage.",
        "Single-GPU (1× NVIDIA H100 NVL) setup; analyzing all files in large packages is computationally prohibitive in the current implementation.",
        "Local LLMs can degrade with too many tools or very long contexts; system mitigates via minimal toolset but may miss rare behaviors requiring additional tools."
      ],
      "future_work": [],
      "motivation": "Build a reliable AI-powered system that can scale to modern software supply chains where malicious PyPI packages use multi-stage, obfuscated payloads, while meeting the exceptionally low false positive requirements for operational deployment.",
      "potential_research_ideas": [
        "Extend CHASE to cover full-package analysis (beyond entry points) with adaptive file prioritization guided by static call-graph heuristics.",
        "Incorporate dynamic sandbox execution with fine-grained telemetry (system/API calls, network traces) and LLM-guided hypothesis testing to capture time-delayed or environment-conditioned payloads.",
        "Develop a lightweight verifier model (e.g., fine-tuned small LLM or classifier) to cross-check agent conclusions and reduce residual hallucinations (self-consistency/critic framework).",
        "Generalize to multiple ecosystems (npm, RubyGems, crates.io) with ecosystem-specific tools and detectors, enabling cross-language threat correlation.",
        "Integrate code property graphs and data-flow taint tracking as deterministic tools callable by agents to improve reasoning about sensitive data exfiltration paths.",
        "Add uncertainty estimation and abstention mechanisms so the system can defer uncertain cases rather than risk false positives.",
        "Build a curated benchmark with fully resolved attack chains and IoCs to standardize evaluation of agentic malware analysis systems."
      ],
      "architectural_improvement_recommendations": [
        "Introduce a sandbox/VM Worker with controlled network egress and time-travel capabilities to trigger delayed payloads and collect runtime IoCs.",
        "Add a retrieval-augmented memory of known malicious patterns (TTPs, IoCs) and package-level metadata (maintainer history, release diffs) to inform planning.",
        "Implement ensemble planning: multiple Supervisor drafts with self-consistency voting to reduce planning errors on complex chains.",
        "Train or fine-tune a small verifier/critic to audit Worker outputs for high-entropy string handling and tool-call sanity checks.",
        "Adopt graph-based intermediate representations (AST/CFG/CPG) as shared state artifacts for consistent cross-agent reasoning.",
        "Introduce adaptive tool-loading so Workers dynamically request tools to minimize overhead while retaining coverage of rare obfuscation schemes.",
        "Add rate-limit and error-handling policies for external services (e.g., VirusTotal/Tavily) and caching to improve reliability and throughput."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "SGLang"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Experiments on 1× NVIDIA H100 NVL; 20-minute per-package timeout; median analysis time 4.5 minutes/package; local LLMs Qwen3:32B (Supervisor), Qwen3:8B (Workers), Gemma3:4B (JSON conversion)."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "Median 4.5 minutes per package",
      "deployment_challenges": [
        "Operational need for exceptionally low false positive rates in package registries",
        "High token and compute costs for agentic analysis at registry scale",
        "Evasion tactics such as time-delayed or environment-sensitive payloads",
        "Context management and potential hallucinations in long, multi-step analyses",
        "Reliance on external services (e.g., VirusTotal, web search) with rate limits and availability constraints",
        "Safe execution requirements for deobfuscation and dynamic code handling"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Identify and characterize challenges of applying autonomous LLM agents to malware analysis, focusing on hallucination and context confusion.",
      "Design and implement CHASE: a high-reliability multi-agent architecture combining Plan-and-Execute coordination, specialized Worker agents, and deterministic security tools.",
      "Reliability-oriented coordination: centralized state to preserve context integrity, budget-aware planning to prevent loops, and minimal/composite tool design to reduce hallucination.",
      "Demonstrate high operational effectiveness on 3,000 packages (500 malicious, 2,500 benign): 98.4% recall and 0.08% false positive rate with median 4.5 minutes per package; retries further improved recall.",
      "Human factors evaluation: survey with cybersecurity professionals assessing generated analysis reports and identifying strengths/areas for improvement.",
      "Provide a blueprint for building reliable AI-powered security tools that scale with modern software supply chain complexity."
    ]
  },
  {
    "arxiv_id": "2601.03504v1",
    "title": "Full-Stack Knowledge Graph and LLM Framework for Post-Quantum Cyber Readiness",
    "authors": "Rasmus Erlemann; Charles Colyer Morris; Sanjyot Sathe",
    "abstract": "The emergence of large-scale quantum computing threatens widely deployed public-key cryptographic systems, creating an urgent need for enterprise-level methods to assess post-quantum (PQ) readiness. While PQ standards are under development, organizations lack scalable and quantitative frameworks for measuring cryptographic exposure and prioritizing migration across complex infrastructures. This paper presents a knowledge graph based framework that models enterprise cryptographic assets, dependencies, and vulnerabilities to compute a unified PQ readiness score. Infrastructure components, cryptographic primitives, certificates, and services are represented as a heterogeneous graph, enabling explicit modeling of dependency-driven risk propagation. PQ exposure is quantified using graph-theoretic risk functionals and attributed across cryptographic domains via Shapley value decomposition. To support scalability and data quality, the framework integrates large language models with human-in-the-loop validation for asset classification and risk attribution. The resulting approach produces explainable, normalized readiness metrics that support continuous monitoring, comparative analysis, and remediation prioritization.",
    "published_date": "2026-01-07",
    "pdf_link": "https://arxiv.org/pdf/2601.03504v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cryptography",
      "subdomain": "Post-Quantum Readiness and Crypto Agility",
      "specific_problem": "Enterprise post-quantum (PQ) readiness scoring via knowledge graph modeling of cryptographic assets and dependencies with LLM-assisted validation and risk attribution",
      "attack_types": [
        "Quantum-enabled cryptanalysis (e.g., Shor’s algorithm impact on RSA/ECC/DH)",
        "Dependency-driven risk propagation across services and infrastructure"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM",
        "specific": "Google Gemma 3 (12B) via Ollama (local, air-gapped)",
        "novel_contribution": "Domain-specialized, prompt-engineered validation of graph nodes/edges and estimation of PQ resistance and business weights with human-in-the-loop disagreement handling"
      },
      {
        "type": "primary",
        "category": "Explainability/Attribution",
        "specific": "Shapley value decomposition",
        "novel_contribution": "Attribution of overall PQ exposure across cryptographic domains to provide transparent, domain-level explanations of readiness scores"
      },
      {
        "type": "primary",
        "category": "Graph analytics",
        "specific": null,
        "novel_contribution": "Graph-theoretic risk functionals and dependency-driven risk propagation over a heterogeneous enterprise knowledge graph"
      },
      {
        "type": "baseline",
        "category": "Ensemble/Heuristics",
        "specific": "Majority voting across LLM validation passes + rule-based validators",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Zero-shot LLM inference",
      "Human-in-the-loop",
      "Rule-based",
      "Graph-based analytics"
    ],
    "datasets": [
      {
        "name": "Enterprise external asset discovery scan data (DNS, ports, services, crypto configs)",
        "type": "proprietary",
        "domain": "asset_inventory",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Certificate Transparency logs",
        "type": "public",
        "domain": "certificate_logs",
        "link": "https://crt.sh/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "DNS records (A/AAAA/MX/TXT/NS with DNSSEC validation)",
        "type": "public",
        "domain": "dns_records",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Nmap-based port/service scans with CPE matching (collected by authors)",
        "type": "proprietary",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "TLS/SSL and SSH configuration analysis results (collected by authors)",
        "type": "proprietary",
        "domain": "cryptographic_configurations",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "CISA Known Exploited Vulnerabilities (KEV)",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://www.cisa.gov/known-exploited-vulnerabilities-catalog",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NIST National Vulnerability Database (NVD)",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://nvd.nist.gov",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CVE-Search/CIRCL",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://www.circl.lu/services/cve-search/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Exploit Prediction Scoring System (EPSS)",
        "type": "public",
        "domain": "threat_intelligence",
        "link": "https://www.first.org/epss/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Open Source Vulnerabilities (OSV)",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://osv.dev/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "GitHub Security Advisories",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://github.com/advisories",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Vulners",
        "type": "public",
        "domain": "vulnerability_database",
        "link": "https://vulners.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Local CVE database (enterprise mirror/aggregation)",
        "type": "proprietary",
        "domain": "vulnerability_database",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Validity rate of validated relationships",
      "Average LLM confidence score",
      "Disagreement rate requiring human review"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How can a heterogeneous enterprise knowledge graph be used to compute a unified, explainable post-quantum readiness score?",
        "How should dependency-driven PQ exposure propagate across assets, services, certificates, and keys in an enterprise-scale graph?",
        "Can large language models, combined with human-in-the-loop oversight, scalably validate asset/relationship data and assign PQ resistance and business weights with sufficient accuracy for continuous monitoring?",
        "How can Shapley value decomposition attribute PQ exposure across cryptographic domains to support remediation prioritization?"
      ],
      "gaps_identified": [
        "Organizations lack scalable and quantitative frameworks for measuring PQ cryptographic exposure across complex infrastructures.",
        "Cyber-risk scoring and maturity assessment approaches are largely pre-quantum and fail to capture systemic dependencies between assets, protocols, and cryptographic domains.",
        "Lack of standardized, interoperable datasets for modeling organizational exposure.",
        "Relational data models struggle to represent multi-dimensional relationships among assets, vulnerabilities, and attack vectors.",
        "Need for interpretability and resilience in security analytics for enterprise decision support."
      ],
      "limitations": [
        "Model selection trade-offs for local LLM inference: “Initial testing with the 4b model revealed validation inconsistencies that were eliminated when migrating to the 12b configuration. We additionally evaluated the 27b model but observed no accuracy improvements over 12b while experiencing significantly longer per-node processing times.”",
        "Residual need for human oversight despite high validation accuracy (e.g., a disagreement threshold with manual review queues and crown-jewel safeguards)."
      ],
      "future_work": [],
      "motivation": "The emergence of quantum computing threatens widely deployed public-key cryptography, yet enterprises lack scalable, quantitative, and explainable methods to assess PQ readiness and prioritize migration across complex, dependency-heavy infrastructures.",
      "potential_research_ideas": [
        "Create an open, de-identified benchmark for PQ readiness graphs (schema, sample scans, crypto configurations) to standardize evaluation of PQ risk scoring methods.",
        "Develop graph learning models (e.g., GNNs with edge weights) to learn dependency-driven PQ risk propagation and compare against rule-based graph-theoretic functionals.",
        "Calibrate LLM-derived resistance and business weights using Bayesian calibration or conformal prediction to improve reliability of confidence scores.",
        "Incorporate streaming change detection for continuous PQ exposure monitoring (e.g., nonparametric change-point detection on readiness scores).",
        "Study adversarial robustness of the LLM validation pipeline (prompt injection, data poisoning of discovery feeds) and design defenses.",
        "Integrate causal modeling (structural causal models) to distinguish correlation vs. causal impact of cryptographic dependencies on business risk.",
        "Design active-learning loops that prioritize human review for edges with highest expected information gain or business impact."
      ],
      "architectural_improvement_recommendations": [
        "Adopt retrieval-augmented generation with a curated cryptographic standards corpus (NIST PQC, RFCs) to ground LLM validation and resistance estimation.",
        "Constrain LLM outputs via structured decoding (JSON schemas) and rule-grounded checking to reduce stochastic errors in edge and attribute validation.",
        "Introduce uncertainty quantification and calibration (temperature scaling, isotonic regression) for LLM confidence scores used in auto-approval thresholds.",
        "Add a learned risk propagation component (e.g., message-passing over the graph) to complement rule-based functionals and enable data-driven weighting.",
        "Implement vector-embedding deduplication for asset identity resolution to reduce false merges/splits during ETL.",
        "Batch and cache validation intelligently (content-addressed caching) to minimize redundant LLM calls; expand majority voting to include diverse model families when permissible.",
        "GPU-accelerate the validation workers and graph analytics where applicable, and use asynchronous I/O for scanner modules to improve throughput."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Python",
        "Ollama",
        "Google Gemma 3 (LLM)",
        "Neo4j",
        "MongoDB Atlas",
        "PostgreSQL",
        "Flask",
        "nmap"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Local, air-gapped LLM inference via Ollama (Gemma 3:12B selected for production; 4B inconsistent; 27B slower without accuracy gains). Scanner framework uses ThreadPoolExecutor (e.g., 50 concurrent workers for certificate extraction, 25 for vulnerability scanning). ValidationScheduler runs every 30 seconds."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Enterprise attack surface discovery and PQ readiness analytics; on-prem/air-gapped local LLM; integrated with vulnerability intel sources",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Data sensitivity requiring air-gapped, local LLM inference",
        "Integration of heterogeneous discovery sources and identity resolution",
        "Need for human-in-the-loop review for disagreements and crown jewels",
        "Compliance constraints (privacy-by-design, GDPR) and audit logging",
        "Horizontal scaling of scanning and validation queues"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "End-to-end, knowledge graph–based framework for enterprise PQ readiness scoring that models assets, cryptographic primitives, certificates, services, and dependencies.",
      "Graph-theoretic risk functionals with dependency-driven risk propagation and weakest-link resistance modeling.",
      "Shapley value decomposition to attribute PQ exposure across cryptographic domains for explainable readiness metrics.",
      "LLM-assisted validation and attribute estimation with human-in-the-loop oversight, using specialized prompts for 10 relationship types and auto-approval thresholds.",
      "Production deployment results: “the system validated nearly 4000 relationships with a 99.6% validity rate, 94.6% average confidence, and 0.4% disagreement rate requiring human review.”",
      "ProtocolResistanceRegistry, EdgeProbabilityCalculator, and CrownJewelIdentifier components to estimate resistance, exploitability, and business weights.",
      "Scalable external asset discovery system with 18 specialized scanner modules, message-queue decoupling, and integration of eight vulnerability sources with reliability weighting and CVSS normalization.",
      "Privacy- and compliance-aware architecture (air-gapped LLM, exclusion of PII, encryption in transit/at rest, RBAC, audit logging)."
    ]
  },
  {
    "arxiv_id": "2601.06177v1",
    "title": "AutoVulnPHP: LLM-Powered Two-Stage PHP Vulnerability Detection and Automated Localization",
    "authors": "Zhiqiang Wang; Yizhong Ding; Zilong Xiao; Jinyu Lu; Yan Jia; Yanjun Li",
    "abstract": "PHP's dominance in web development is undermined by security challenges: static analysis lacks semantic depth, causing high false positives; dynamic analysis is computationally expensive; and automated vulnerability localization suffers from coarse granularity and imprecise context. Additionally, the absence of large-scale PHP vulnerability datasets and fragmented toolchains hinder real-world deployment.   We present AutoVulnPHP, an end-to-end framework coupling two-stage vulnerability detection with fine-grained automated localization. SIFT-VulMiner (Structural Inference for Flaw Triage Vulnerability Miner) generates vulnerability hypotheses using AST structures enhanced with data flow. SAFE-VulMiner (Semantic Analysis for Flaw Evaluation Vulnerability Miner) verifies candidates through pretrained code encoder embeddings, eliminating false positives. ISAL (Incremental Sequence Analysis for Localization) pinpoints root causes via syntax-guided tracing, chain-of-thought LLM inference, and causal consistency checks to ensure precision.   We contribute PHPVD, the first large-scale PHP vulnerability dataset with 26,614 files (5.2M LOC) across seven vulnerability types. On public benchmarks and PHPVD, AutoVulnPHP achieves 99.7% detection accuracy, 99.5% F1 score, and 81.0% localization rate. Deployed on real-world repositories, it discovered 429 previously unknown vulnerabilities, 351 assigned CVE identifiers, validating its practical effectiveness.",
    "published_date": "2026-01-07",
    "pdf_link": "https://arxiv.org/pdf/2601.06177v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Web/Application Security",
      "subdomain": "Vulnerability Detection and Repair",
      "specific_problem": "PHP source code vulnerability detection and automated vulnerability localization",
      "attack_types": [
        "seven types (unspecified)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "AST-based classifier",
        "specific": null,
        "novel_contribution": "SIFT-VulMiner: structural hypothesis generation using AST structures enhanced with data-flow and LLM-guided structural scoring as a high-recall first stage"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "CodeBERT",
        "novel_contribution": "SAFE-VulMiner: semantic verification with pretrained code encoder embeddings and risk-biased attention applied only to candidates from Stage I"
      },
      {
        "type": "primary",
        "category": "LLM",
        "specific": "Chain-of-Thought prompted LLM",
        "novel_contribution": "ISAL: syntax-guided tracing + CoT inference + causal consistency checks within template-guarded constraints for fine-grained vulnerability localization"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Prompted LLM (CoT)",
      "Heuristic/Rule-based (constraint templates for localization)"
    ],
    "datasets": [
      {
        "name": "PHPVD",
        "type": "public",
        "domain": "source_code (PHP)",
        "link": null,
        "is_new_contribution": true,
        "availability": ""
      },
      {
        "name": "public benchmarks (unspecified)",
        "type": "public",
        "domain": "source_code (PHP)",
        "link": null,
        "is_new_contribution": false,
        "availability": ""
      }
    ],
    "baselines": [
      {
        "method_name": "HiddenCPG",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "RecurScan",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "RIPS (static analyzer)",
        "paper_reference": null,
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1 score",
      "Localization rate"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "How to achieve high-precision PHP vulnerability detection without prohibitive computational cost?",
        "How to integrate structural priors and semantic reasoning to reduce false positives and false negatives in PHP code?",
        "How to perform reliable, fine-grained automated vulnerability localization while mitigating LLM hallucination risk?",
        "How to construct a large-scale, high-quality PHP vulnerability dataset to enable training and evaluation?"
      ],
      "gaps_identified": [
        "Absence of high-quality, large-scale PHP vulnerability datasets with ground-truth labels",
        "Static analysis lacks semantic depth and yields high false positives",
        "Dynamic analysis (fuzzing/symbolic execution) is computationally expensive and scales poorly",
        "Existing detection methods are semantically blind to complex data flows and context in PHP",
        "Fragmented toolchains: detection rarely integrates with localization",
        "LLM-based localization prone to hallucinations without constraints",
        "Integration of detection confidence with localization strategies largely unexplored"
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "PHP is widely used in web applications but suffers from security vulnerabilities and a lack of large-scale datasets; existing static/dynamic and ML approaches trade off precision and scalability and struggle with semantic nuances and reliable localization.",
      "potential_research_ideas": [
        "Extend AutoVulnPHP to multi-language settings (e.g., JavaScript in full-stack PHP apps) with cross-language data/taint flow modeling",
        "Augment PHPVD with labeled root-cause spans and patch metadata to enable supervised localization training and evaluation",
        "Develop adversarial evaluation for vulnerability detectors and localizers (e.g., obfuscations, code transformations) and robust training methods",
        "Incorporate repository-level context via retrieval-augmented LLM localization (RAG over project APIs, configs, and sanitization utilities)",
        "Leverage path-sensitive static analysis or lightweight concolic execution to enrich candidate generation before semantic verification",
        "Active learning or self-training loops that mine hard negatives from large-scale repositories to continually improve precision",
        "Human-in-the-loop triage interfaces that surface CoT rationales and constraint checks for auditor validation, improving trust and feedback signals",
        "CVE-aware continual learning to adapt detectors to emerging PHP-specific vulnerability patterns (e.g., type juggling, magic hash issues)"
      ],
      "architectural_improvement_recommendations": [
        "Replace or ensemble CodeBERT with stronger code encoders (e.g., CodeLlama/StarCoder2/UniXcoder) with risk-biased attention retained",
        "Introduce a CPG/GNN branch in Stage I for richer flow/context features and fuse with AST features via calibrated score fusion",
        "Use retrieval-augmented generation in ISAL to ground LLM reasoning on project-specific sanitizers and frameworks",
        "Adopt self-consistency and verifiable program analysis checks in ISAL (multiple CoT samples + constraint solver) to reduce hallucinations",
        "Tighten coupling between detection confidence and localization priors (confidence-weighted span proposals)",
        "Integrate concolic feedback or dynamic traces into SAFE-VulMiner for ambiguous candidates to reduce residual FPs/FNs"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Large-scale scanning of real-world open-source PHP repositories (e.g., GitHub and similar sources)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Balancing computational efficiency with detection precision at scale",
        "Mitigating LLM hallucinations during localization",
        "Handling PHP-specific dynamic features and complex taint propagation"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Two-stage vulnerability detection framework: SIFT-VulMiner for structural hypothesis generation and SAFE-VulMiner for semantic verification with calibrated score fusion",
      "ISAL: a constraint-aware, template-guarded, CoT-LLM-based automated vulnerability localization system",
      "PHPVD: first large-scale PHP vulnerability dataset (26,614 files, 5.2M LOC) across seven vulnerability types",
      "Empirical validation with 99.7% detection accuracy, 99.5% F1, and 81.0% localization rate; real-world deployment discovered 429 unknown vulnerabilities with 351 CVE assignments"
    ]
  },
  {
    "arxiv_id": "2601.00372v1",
    "title": "LLM-Powered Analysis of IoT User Reviews: Tracking and Ranking Security and Privacy Concerns",
    "authors": "Taufiq Islam Protick; Sai Teja Peddinti; Nina Taft; Anupam Das",
    "abstract": "Being able to understand the security and privacy (S&P) concerns of IoT users brings benefits to both developers and users. To learn about users' views, we examine Amazon IoT reviews - one of the biggest IoT markets. This work presents a state-of-the-art methodology to identify and categorize reviews in which users express S&P concerns. We developed an automated pipeline by fine-tuning GPT-3.5-Turbo to build two models: the Classifier-Rationalizer-Categorizer and the Thematic Mapper. By leveraging dynamic few-shot prompting and the model's large context size, our pipeline achieved over 97% precision and recall, significantly outperforming keyword-based and classical ML methods. We applied our pipeline to 91K Amazon reviews about fitness trackers, smart speakers and cameras, over multiple years. We found that on average 5% contained S&P concerns, while security camera exhibited the highest prevalence at 10%. Our method detected significantly more S&P-relevant reviews than prior works: 15x more for fitness trackers, 29% more for smart speakers, and 70% more for cameras. Our longitudinal analysis reveals that concerns like surveillance and data control have persisted for years, suggesting limited industry progress. We demonstrate that across all device types, users consistently demand more precise control over what data is collected and shared. We uncover challenges in multi-user and multi-device interactions, identifying two previously unreported themes concerning inadequate controls for account separation and data access. These findings, ranging from broad persistent trends to specific instances of customer loss, offer actionable insights for developers to improve user satisfaction and trust.",
    "published_date": "2026-01-01",
    "pdf_link": "https://arxiv.org/pdf/2601.00372v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "User feedback mining and privacy risk analysis",
      "specific_problem": "Automatic detection, categorization, and thematic mapping of security and privacy concerns in IoT product reviews",
      "attack_types": [
        "surveillance",
        "unauthorized data access",
        "excessive data collection/sharing",
        "insufficient data control/consent",
        "account separation failures (multi-user)",
        "inadequate data access controls (multi-device/multi-user)",
        "eavesdropping/always-listening microphones"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer (LLM)",
        "specific": "GPT-3.5-Turbo (OpenAI) fine-tuned",
        "novel_contribution": "Two-task pipeline with supervised fine-tuning and dynamic few-shot prompting for CRC (classification, rationale generation, low-level issue categorization) and TM (thematic mapping to 28 IoT S&P themes)"
      },
      {
        "type": "primary",
        "category": "Prompt Engineering",
        "specific": "Dynamic few-shot prompting",
        "novel_contribution": "Nearest-neighbor example retrieval (via BERT embeddings) to populate 16K context with semantically close positive/negative examples per input"
      },
      {
        "type": "primary",
        "category": "Transformer embeddings",
        "specific": "BERT embeddings (Kenton and Toutanova 2019)",
        "novel_contribution": "Used to select closest and second-closest examples with opposing labels for dynamic few-shot prompting"
      },
      {
        "type": "baseline",
        "category": "Keyword lexicon",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Classical ML",
        "specific": "SVM, Logistic Regression, LDA topic modeling (from prior literature)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (Encoder-Decoder)",
        "specific": "T5 (from prior works on app reviews)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (LLM)",
        "specific": "Vanilla GPT-3.5-Turbo (non-fine-tuned)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Few-shot"
    ],
    "datasets": [
      {
        "name": "Wild Review Dataset (W) of Amazon IoT product reviews",
        "type": "public",
        "domain": "user_reviews",
        "link": "https://anonymous.4open.science/r/IoT-Products-SecurityAndPrivacy-5F5D/README.md",
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "Qualitative labeled IoT S&P review dataset (from Protick et al. 2024)",
        "type": "public",
        "domain": "user_reviews",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Transformed labeled dataset for CRC (2,454 reviews, balanced)",
        "type": "unknown",
        "domain": "user_reviews",
        "link": null,
        "is_new_contribution": true,
        "availability": "available_on_request"
      }
    ],
    "baselines": [
      {
        "method_name": "Keyword-based filtering",
        "paper_reference": null,
        "metric": "Precision, Recall (CRC detection)",
        "their_result": "CRC achieves over 97% precision and recall on a human-annotated validation set; macro-averaged precision 88.7% and recall 93.4% on real-world data",
        "baseline_result": null
      },
      {
        "method_name": "Classical ML/NLP (SVM, Logistic Regression, LDA)",
        "paper_reference": "Nguyen et al. 2019; Mukherjee et al. 2020; Vetrivel et al. 2023",
        "metric": "Relative detection quality/coverage",
        "their_result": "Outperforms classical ML/NLP methods",
        "baseline_result": null
      },
      {
        "method_name": "Baseline LLM (vanilla GPT-3.5-Turbo)",
        "paper_reference": null,
        "metric": "Precision/Recall and adherence to structured outputs",
        "their_result": "Fine-tuned models outperform baseline LLM; base model shows inconsistent responses and format noncompliance",
        "baseline_result": null
      },
      {
        "method_name": "T5-based pipelines (apps domain)",
        "paper_reference": "Harkous et al. 2022; Akgul et al. 2024",
        "metric": "Reported detection/coverage in prior domain",
        "their_result": "First to leverage fine-tuned LLMs for IoT reviews; demonstrates better accuracy than classical methods",
        "baseline_result": null
      },
      {
        "method_name": "IoT cameras prevalence vs. prior LDA pipeline",
        "paper_reference": "Vetrivel et al. 2023",
        "metric": "Prevalence of S&P concerns in camera reviews",
        "their_result": "10.07%",
        "baseline_result": "5.9%"
      },
      {
        "method_name": "Smart speakers prevalence vs. keyword study",
        "paper_reference": "Fruchter and Liccardi 2018",
        "metric": "Relative detection coverage",
        "their_result": "29% more S&P-relevant reviews detected than prior work",
        "baseline_result": "2.04% (reported by prior work)"
      },
      {
        "method_name": "Fitness trackers prevalence vs. keyword/manual study",
        "paper_reference": "van der Linden Dirk et al. 2020",
        "metric": "Relative detection coverage",
        "their_result": "15x more S&P-relevant reviews detected than prior work",
        "baseline_result": "0.14% (reported by prior work)"
      }
    ],
    "performance_metrics_used": [
      "Precision",
      "Recall",
      "F1-score",
      "Micro-averaged precision/recall/F1",
      "Macro-averaged precision/recall",
      "Prevalence (%) of S&P concerns in reviews"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "RQ1: What level of quality can be achieved for LLM-based detectors aimed at extracting S&P reviews from a large corpus of IoT reviews?",
        "RQ2: What is the prevalence of S&P concerns in IoT product reviews, and how does prevalence vary across device categories?",
        "RQ3: What are users’ S&P concerns and how do they rank relative to one another?"
      ],
      "gaps_identified": [
        "Prior IoT review analyses rely heavily on keyword-based filtering, missing semantically similar concerns and suffering high false positives/negatives.",
        "Existing studies often focus on mobile app reviews rather than IoT devices with diverse modalities.",
        "Previous pipelines required multiple models/steps; lack of streamlined, high-accuracy methods tied to vetted taxonomies.",
        "Limited insights into multi-user/multi-device privacy challenges (account separation and data access) in IoT.",
        "Shopping assistants lack focused S&P extraction and summarization capabilities."
      ],
      "limitations": [
        "For transforming labels and generating rationales, a single author performed manual conversion; no inter-annotator agreement computed for these components.",
        "Negative samples were manually selected from the crawled dataset, potentially introducing selection bias.",
        "Dependence on Amazon’s mechanisms to mitigate fake reviews.",
        "Closed-source model fine-tuning via API hinders full reproducibility and transparency.",
        "Scope limited to three IoT device categories (trackers, speakers, cameras) and Amazon reviews."
      ],
      "future_work": [],
      "motivation": "To accurately identify and categorize security and privacy concerns expressed by IoT users in product reviews, informing developers, enhancing user decision-making, and improving AI shopping assistants’ handling of S&P issues.",
      "potential_research_ideas": [
        "Open-source replications using fine-tuned LLaMA/Mistral-class models for reproducibility and cost control.",
        "Cross-lingual expansion to non-English reviews with multilingual LLMs and machine translation for global S&P perspective.",
        "Adversarial and robustness evaluation (prompt attacks, paraphrasing, obfuscation, sarcasm) for detector hardening.",
        "Active learning loop that solicits human validation on low-confidence outputs to improve label quality over time.",
        "RAG-enhanced classification using product documentation, privacy policies, and firmware notes as context.",
        "Temporal drift analysis and continual learning to adapt to evolving IoT features and policy changes.",
        "Multimodal fusion incorporating product images/specs with text to better detect device-specific S&P issues.",
        "Benchmark creation: standardized IoT S&P review datasets with agreed taxonomies for fair comparison across methods."
      ],
      "architectural_improvement_recommendations": [
        "Replace BERT embeddings with strong sentence-transformers and use approximate nearest neighbor retrieval to scale dynamic few-shot selection.",
        "Multi-task fine-tuning where CRC and TM share a backbone with task-specific heads to reduce error propagation.",
        "Calibrate outputs (temperature scaling or conformal prediction) and report confidence/coverage for safer deployment.",
        "Distill the fine-tuned LLM into a smaller open model for on-prem or edge inference.",
        "Add retrieval of product metadata (ASIN, vendor, device capabilities) to condition classification and theming.",
        "Introduce weak supervision (data programming) to generate more high-quality negatives and diverse edge cases.",
        "Implement structured output enforcement (JSON schema constraints) to eliminate format deviations."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "OpenAI API",
        "HuggingFace Transformers (for BERT embeddings, implied)",
        "Selenium",
        "BeautifulSoup"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Linux machine with 16 GB RAM; NVIDIA RTX-3070-M GPU used for BERT embeddings; OpenAI GPT-3.5-Turbo SFT via API (3 epochs, temperature=0 best, learning rate multiplier=2); context window 16K; OpenAI throughput up to 1M tokens/min and 100M tokens/day (Tier-4)."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Dependency on closed-source API and potential model updates/drift",
        "API cost/throughput limitations for large-scale processing",
        "Mitigating hallucinations and output format inconsistency",
        "Data access constraints due to platform policy changes (Amazon review scraping limits)",
        "Presence of fake/inauthentic reviews impacting signal quality"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a fine-tuned LLM pipeline (CRC and TM) that achieves over 97% precision and recall on validation and strong macro/micro metrics on real-world data.",
      "Demonstrates significant coverage gains over prior IoT review analyses, including 10.07% S&P prevalence for cameras vs. 5.9% in prior work.",
      "Unifies eight IoT S&P taxonomies into 28 high-level themes enabling nuanced categorization and ranking.",
      "Conducts longitudinal analysis across 91K Amazon IoT reviews, revealing persistent concerns (e.g., surveillance, data control).",
      "Identifies two previously unreported themes: inadequate controls for account separation and data access in multi-user/multi-device settings.",
      "Prepares and will release a cleaned wild review dataset (91,749 crawled -> 91,749 processed; 91,149 after negative sampling removal) to support future research."
    ]
  },
  {
    "arxiv_id": "2601.05887v1",
    "title": "Cybersecurity AI: A Game-Theoretic AI for Guiding Attack and Defense",
    "authors": "Víctor Mayoral-Vilches; María Sanz-Gómez; Francesco Balassone; Stefan Rass; Lidia Salas-Espejo; Benjamin Jablonski; Luis Javier Navarrete-Lozano; Maite del Mundo de Torres; Cristóbal R. J. Veas Chavez",
    "abstract": "AI-driven penetration testing now executes thousands of actions per hour but still lacks the strategic intuition humans apply in competitive security. To build cybersecurity superintelligence --Cybersecurity AI exceeding best human capability-such strategic intuition must be embedded into agentic reasoning processes. We present Generative Cut-the-Rope (G-CTR), a game-theoretic guidance layer that extracts attack graphs from agent's context, computes Nash equilibria with effort-aware scoring, and feeds a concise digest back into the LLM loop \\emph{guiding} the agent's actions. Across five real-world exercises, G-CTR matches 70--90% of expert graph structure while running 60--245x faster and over 140x cheaper than manual analysis. In a 44-run cyber-range, adding the digest lifts success from 20.0% to 42.9%, cuts cost-per-success by 2.7x, and reduces behavioral variance by 5.2x. In Attack-and-Defense exercises, a shared digest produces the Purple agent, winning roughly 2:1 over the LLM-only baseline and 3.7:1 over independently guided teams. This closed-loop guidance is what produces the breakthrough: it reduces ambiguity, collapses the LLM's search space, suppresses hallucinations, and keeps the model anchored to the most relevant parts of the problem, yielding large gains in success rate, consistency, and reliability.",
    "published_date": "2026-01-09",
    "pdf_link": "https://arxiv.org/pdf/2601.05887v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Offensive Security",
      "subdomain": "Penetration Testing Automation",
      "specific_problem": "Closed-loop game-theoretic guidance for LLM-based pentesting via automatic attack-graph extraction and Nash equilibrium digests",
      "attack_types": [
        "Shellshock (CVE-2014-6271)",
        "Attack-and-Defense CTF scenarios",
        "Advanced Persistent Threat modeling (via attack graphs)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Large Language Model (LLM) agent",
        "specific": null,
        "novel_contribution": "LLM parses AI pentesting logs to automatically extract attack graphs; digest from Nash equilibria guides the agent’s ReAct loop"
      },
      {
        "type": "primary",
        "category": "Game-theoretic modeling",
        "specific": "Cut-the-Rope (CTR) -> Generative CTR (G-CTR)",
        "novel_contribution": "Extends CTR with automated LLM-driven graph generation and an effort-aware scoring function enabling equilibrium computation over LLM-inferred graphs"
      },
      {
        "type": "baseline",
        "category": "Large Language Model (LLM) agent",
        "specific": "LLM-only (no game-theoretic digest)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Agentic planning (ReAct)",
      "Unsupervised information extraction (LLM parsing)"
    ],
    "datasets": [
      {
        "name": "Five real-world security exercises (LLM-generated attack graphs vs expert annotations)",
        "type": "private",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "44-run cyber-range on Shellshock (CVE-2014-6271)",
        "type": "private",
        "domain": "operation_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Attack-and-Defense CTF exercises (pingpong, cowsay)",
        "type": "private",
        "domain": "operation_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Expert-annotated attack graphs (two external professionals; Appendix B)",
        "type": "private",
        "domain": "attack_graphs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "LLM-only baseline (no game-theoretic digest)",
        "paper_reference": null,
        "metric": "Success rate (cyber-range; Shellshock)",
        "their_result": "42.9% (with digest)",
        "baseline_result": "20.0% (without digest)"
      },
      {
        "method_name": "LLM-only baseline (no digest)",
        "paper_reference": null,
        "metric": "Cost-per-success",
        "their_result": "$0.12",
        "baseline_result": "$0.32"
      },
      {
        "method_name": "LLM-only baseline (no digest)",
        "paper_reference": null,
        "metric": "Tool-use behavioral variance",
        "their_result": "5.2× reduction (with digest)",
        "baseline_result": "Higher variance (reference: 1×)"
      },
      {
        "method_name": "LLM-only baseline in A&D (pingpong)",
        "paper_reference": null,
        "metric": "Win rate",
        "their_result": "52.4% (Purple G-CTR merged)",
        "baseline_result": "28.6% (LLM-only)"
      },
      {
        "method_name": "Independently guided dual teams (separate red/blue digests) in A&D (cowsay)",
        "paper_reference": null,
        "metric": "Win rate",
        "their_result": "55% (Purple G-CTR merged)",
        "baseline_result": "15% (independent dual guidance)"
      },
      {
        "method_name": "Manual expert analysis (attack graph construction)",
        "paper_reference": null,
        "metric": "Graph node correspondence and efficiency",
        "their_result": "70–90% node correspondence; 60–245× faster; >140× cheaper",
        "baseline_result": "Expert-constructed graphs (slower, costlier)"
      }
    ],
    "performance_metrics_used": [
      "success rate",
      "cost-per-success",
      "variance of tool usage (behavioral variance)",
      "node correspondence to expert graph",
      "time speedup",
      "cost reduction",
      "win rate ratio"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "RQ1: can we make Cybersecurity AI agents more effective by guiding them strategically with game theory?"
      ],
      "gaps_identified": [
        "Limited scalability of attack graphs; manual/static methods do not scale to modern dynamic environments.",
        "Lack of comprehensive evaluation and benchmarks for LLMs in cybersecurity (no standardized gold-standard datasets).",
        "Insufficient integration of game-theoretic models with AI automation in practical tooling.",
        "Gap between fast-evolving AI capabilities and human annotation workflows."
      ],
      "limitations": [
        "LLM-generated graphs may include cycles and structural inconsistencies; requires post-processing to prune cycles and non-vulnerable leaves.",
        "LLM outputs vary across runs due to probabilistic behavior; can introduce variability in graph structure.",
        "Effort-based scoring substitutes for true probabilistic estimates; may not reflect real-world exploitation probabilities.",
        "No standardized public dataset provided for external replication; evaluations rely on private exercises and ranges."
      ],
      "future_work": [],
      "motivation": "Bridge fast AI-driven pentesting with strategic defense planning by automatically turning AI logs into attack graphs and using game-theoretic equilibria to guide red/blue operations.",
      "potential_research_ideas": [
        "Create a public benchmark of cybersecurity exercise logs with ground-truth attack graphs and defense outcomes for evaluating LLM-based graph generation and game-theoretic guidance.",
        "Quantify and calibrate the effort-based scoring against real exploitation difficulty metrics (e.g., time-to-exploit, required privileges) and human expert judgments.",
        "Compare multiple LLMs and structured decoders (e.g., constrained decoding/grammars) for reliable, cycle-free attack graph extraction.",
        "Incorporate uncertainty estimation for LLM-extracted graphs and propagate it into the equilibrium computation (robust or Bayesian game formulations).",
        "Develop interactive human-in-the-loop tooling to edit/approve graphs and update equilibria incrementally during live operations.",
        "Extend to multi-attacker/multi-defender settings with partial observability (POMDPs) and evaluate in larger enterprise-like networks.",
        "Adversarially evaluate robustness to prompt injection, tool-output poisoning, and deceptive logs that could skew graph extraction.",
        "Integrate learning-to-rank or bandit methods for tool selection guided by the digest, optimizing exploration-exploitation during pentesting."
      ],
      "architectural_improvement_recommendations": [
        "Use constrained JSON schema/grammar-guided decoding for graph extraction to eliminate cycles and enforce DAG structure.",
        "Adopt incremental/eager equilibrium computation to update digests as new nodes/edges stream in, reducing recomputation latency.",
        "Replace or augment effort scoring with empirical features (e.g., tool execution cost, observed failure rates) and learned calibrators.",
        "Add uncertainty-aware digests (confidence scores for paths/nodes) and filter low-confidence guidance.",
        "Introduce a retrieval-augmented memory of past graphs and attack outcomes to warm-start equilibrium computation on similar targets.",
        "Evaluate GNN-based graph refinement as a post-processing step to de-noise LLM graphs before game-theoretic analysis."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/aliasrobotics/cai",
      "frameworks": [
        "Python",
        "NetworkX",
        "CAI (Cybersecurity AI) framework",
        "ReAct (agent pattern)"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Closed-loop operates with Phases 1–2 ≈50s per cycle in parallel to ≈70s agent execution; digest triggered every ~5 interactions (~80 tool calls); uses NetworkX for path processing. Reported components show sub-10ms steps for some phases and ≈20–30s for LLM/digest-related computations."
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "Cyber-range and Attack-and-Defense CTF exercises integrated into CAI pentesting operations",
      "scalability_discussed": true,
      "inference_time": "Phases 1–2 ≈50s parallel to ≈70s agent cycle; selected sub-steps reported <10ms to ≈28s",
      "deployment_challenges": [
        "Ensuring reliability of LLM-extracted graphs under variable outputs and potential hallucinations.",
        "Integrating guidance with live operations without overwhelming operators; balancing frequency of digest updates.",
        "Cost and latency management for LLM calls during continuous operations.",
        "Trust and validation of automated strategic guidance in mission-critical environments."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces Generative Cut-The-Rope (G-CTR), extending CTR with LLM-driven attack graph extraction and effort-aware scoring.",
      "Presents a strategic digest pipeline that converts Nash equilibria into actionable guidance for both attackers and defenders.",
      "Demonstrates automated attack-graph generation matching 70–90% of expert node structure while running 60–245× faster and >140× cheaper.",
      "In a 44-run Shellshock range, digest lifts success from 20.0% to 42.9%, cuts cost-per-success by 2.7× (from $0.32 to $0.12), and reduces behavioral variance by 5.2×.",
      "Introduces the Purple G-CTR merged configuration (shared graph for red/blue) winning 52.4% vs 28.6% (~1.8:1) over LLM-only and 55% vs 15% (~3.7:1) over independently guided teams.",
      "Integrates game-theoretic analysis with agentic LLM operations in a closed-loop architecture with minimal overhead."
    ]
  },
  {
    "arxiv_id": "2601.04443v1",
    "title": "Large Language Models for Detecting Cyberattacks on Smart Grid Protective Relays",
    "authors": "Ahmad Mohammad Saber; Saeed Jafari; Zhengmao Ouyang; Paul Budnarain; Amr Youssef; Deepa Kundur",
    "abstract": "This paper presents a large language model (LLM)-based framework for detecting cyberattacks on transformer current differential relays (TCDRs), which, if undetected, may trigger false tripping of critical transformers. The proposed approach adapts and fine-tunes compact LLMs such as DistilBERT to distinguish cyberattacks from actual faults using textualized multidimensional TCDR current measurements recorded before and after tripping. Our results demonstrate that DistilBERT detects 97.6% of cyberattacks without compromising TCDR dependability and achieves inference latency below 6 ms on a commercial workstation. Additional evaluations confirm the framework's robustness under combined time-synchronization and false-data-injection attacks, resilience to measurement noise, and stability across prompt formulation variants. Furthermore, GPT-2 and DistilBERT+LoRA achieve comparable performance, highlighting the potential of LLMs for enhancing smart grid cybersecurity. We provide the full dataset used in this study for reproducibility.",
    "published_date": "2026-01-07",
    "pdf_link": "https://arxiv.org/pdf/2601.04443v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "ICS/SCADA Security",
      "subdomain": "Smart Grid Protection",
      "specific_problem": "Detection of false data injection attacks on transformer current differential relays (TCDRs) using textualized current measurements",
      "attack_types": [
        "false data injection (FDIA)",
        "replay attack",
        "time-synchronization attack (combined with FDIA)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer (encoder)",
        "specific": "DistilBERT (distilbert-base-uncased) fine-tuned for sequence classification",
        "novel_contribution": "Textualization of six-channel TCDR current waveforms into compact prompts within 512-token limits; fine-tuned DistilBERT used for cyberattack vs fault classification with attention-based interpretability"
      },
      {
        "type": "baseline",
        "category": "Transformer (decoder)",
        "specific": "GPT-2 (fine-tuned)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer (encoder) with PEFT",
        "specific": "DistilBERT + LoRA",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "CNN",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN (LSTM)",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "RNN (GRU)",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Support Vector Machine",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting",
        "specific": "XGBoost",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "K-Nearest Neighbors",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Naive Bayes",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "LLMSmartGridTCDR dataset (IEEE PSRC D6-HYPERSIM TCDR current measurements)",
        "type": "synthetic",
        "domain": "power_system_measurements (smart_grid_relay_measurements)",
        "link": "https://github.com/jaafaris/LLMSmartGridTCDR",
        "is_new_contribution": true,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GPT-2",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "99.20"
      },
      {
        "method_name": "DistilBERT+LoRA",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "97.86"
      },
      {
        "method_name": "CNN",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "99.03"
      },
      {
        "method_name": "LSTM",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "98.43"
      },
      {
        "method_name": "GRU",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "99.17"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "98.82"
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "97.61"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "97.85"
      },
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "98.57"
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "89.92"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "98.75"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "F1-Score (%)",
        "their_result": "99.36 (DistilBERT)",
        "baseline_result": "66.22"
      },
      {
        "method_name": "GPT-2",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "97.06"
      },
      {
        "method_name": "DistilBERT+LoRA",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "92.31"
      },
      {
        "method_name": "CNN",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "96.48"
      },
      {
        "method_name": "GRU",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "96.98"
      },
      {
        "method_name": "LSTM",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "94.35"
      },
      {
        "method_name": "Random Forest",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "95.73"
      },
      {
        "method_name": "SVM",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "92.34"
      },
      {
        "method_name": "XGBoost",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "94.85"
      },
      {
        "method_name": "KNN",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "95.60"
      },
      {
        "method_name": "Decision Tree",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "93.59"
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "68.22"
      },
      {
        "method_name": "Naive Bayes",
        "paper_reference": null,
        "metric": "Cyberattack Detection Rate (%)",
        "their_result": "97.62 (DistilBERT)",
        "baseline_result": "69.85"
      }
    ],
    "performance_metrics_used": [
      "Cyberattack Detection Rate (True Positive Rate)",
      "Accuracy",
      "Precision (macro-averaged)",
      "Recall (macro-averaged)",
      "Specificity (True Negative Rate)",
      "F1-Score (macro-averaged)",
      "Inference latency"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can fine-tuned compact LLMs (e.g., DistilBERT) distinguish cyberattacks from true faults on transformer current differential relays using textualized current measurements?",
        "Can lightweight LLMs meet the strict real-time constraints of protective relays for local (on-prem) deployment?",
        "Do attention mechanisms provide transparent, operator-usable interpretability for cyberattack detection on TCDRs?",
        "How robust is the LLM-based detector under combined time-synchronization and FDIA attacks, measurement noise, and prompt formulation variants?"
      ],
      "gaps_identified": [
        "Prior work does not address detecting FDIAs against TCDRs in substation protection.",
        "LLM use on high-resolution, multi-channel numerical time series under tight token limits has not been explored for this protection task.",
        "Existing approaches often rely on cloud-based models; locally deployable LLMs for substations are under-explored.",
        "Need for transparent, interpretable detection for protection engineers rather than black-box models."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Prevent false tripping of critical transformers by detecting cyberattack-manipulated TCDR measurements without compromising fault detection, using locally deployable and interpretable LLMs.",
      "potential_research_ideas": [
        "Extend to multi-relay and multi-modal inputs (add voltages, phasors, breaker statuses) for more robust cyberattack/fault discrimination.",
        "Self-supervised pretraining on large unlabeled power system waveforms to improve robustness and reduce labeled data needs.",
        "Domain adaptation and federated learning across substations/utilities to handle distribution shift without sharing raw data.",
        "Evaluate and harden against adaptive adversaries (gradient-based or model-aware FDIAs) and develop certified robust detection bounds.",
        "Online/continual learning to handle changing operating conditions, equipment aging, and seasonal patterns (concept drift).",
        "Generalize the textualization approach to other grid protection devices (distance relays, busbar protection) and to non-IEC-61850 protocols.",
        "Investigate numeric-aware tokenization or hybrid encoders (time-series Transformer + text encoder) to reduce token budget while preserving fidelity.",
        "Calibrated uncertainty with abstention and human-in-the-loop triage to reduce false blocking of legitimate trips.",
        "Compress/quantize models (INT8, per-channel quantization) and distill to micro-controllers for in-relay deployment.",
        "Explainability beyond attention (e.g., token-to-signal attribution bridges, counterfactuals) for operator trust and compliance."
      ],
      "architectural_improvement_recommendations": [
        "Replace general-purpose LLM with a time-series Transformer encoder with numeric-aware tokenization to reduce prompt overhead and latency.",
        "Use multi-head hierarchical encoding: per-phase temporal encoder + cross-phase fusion to better model spatial-temporal relations.",
        "Incorporate PEFT methods (LoRA, adapters) with selective unfreezing to regain LoRA accuracy while keeping compute low.",
        "Add adversarial training with physically-constrained perturbations (FDIA threat models, time-sync shifts) to increase robustness.",
        "Use ensemble or Bayesian last-layer for calibrated probabilities and thresholding tuned to relay dependability/security trade-offs.",
        "Integrate a pre-filter (classical protection features) to reduce sequence length before LLM encoding, improving latency.",
        "Leverage mixed-precision inference and operator-specific pruning for substation hardware targets."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": "https://github.com/jaafaris/LLMSmartGridTCDR",
      "frameworks": [
        "Hugging Face Transformers",
        "PyTorch",
        "scikit-learn",
        "XGBoost"
      ],
      "reproducibility_score": "high",
      "computational_requirements": "Fine-tuning DistilBERT: ~1 hour on Google Colab A100 40GB GPU, 12×6-core Intel Xeon CPUs (2.20 GHz), 83.5 GB RAM; hyperparameters: 10 epochs, Adam lr=2e-5, batch size 16, weight decay 0.01; average input length ~512 tokens; inference latency <6 ms on a commercial workstation."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Digital substation environment (local/on-prem relay protection system within IEC-61850 setting)",
      "scalability_discussed": true,
      "inference_time": "< 6 ms per event on a commercial workstation",
      "deployment_challenges": [
        "Strict real-time constraints of protective relays",
        "Integration with IEC-61850 data paths and relay tripping logic (blocking commands)",
        "Managing token budget vs. fidelity of high-resolution waveforms",
        "Model maintenance under changing operating conditions (concept drift)",
        "On-prem hardware variability and need for efficient inference"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "\"We develop a method to convert current measurements (from all six input and output phases) into structured text prompts.\"",
      "\"We prove that lightweight LLMs (DistilBERT, GPT-2) can be deployed locally within digital substations... operate in less than 6 ms on standard commercial hardware.\"",
      "\"We introduce a transparent detection method for False Data Injection Attacks (FDIAs) using the model’s self-attention mechanism.\"",
      "\"DistilBERT detects 97.6% of cyberattacks without compromising TCDR dependability and achieves inference latency below 6 ms on a commercial workstation.\"",
      "Robustness shown under combined time-synchronization + FDIA attacks, measurement noise, and prompt variants; dataset provided publicly for reproducibility."
    ]
  },
  {
    "arxiv_id": "2601.01184v1",
    "title": "SecureCodeRL: Security-Aware Reinforcement Learning for Code Generation with Partial-Credit Rewards",
    "authors": "Suryansh Singh Sijwali; Suman Saha",
    "abstract": "Large Language Models (LLMs) can generate plausible code, but in settings that require exact stdin/stdout behavior they frequently produce programs that compile yet fail tests, and in some cases they introduce security-sensitive patterns. This paper presents SecureCodeRL, a reinforcement learning (RL) pipeline for security-aware code generation that optimizes a combined reward R = αRfunc + \\b{eta}Rsec. The key idea is a partial-credit functional reward that assigns intermediate scores for syntactic validity, successful execution, and producing output, reducing reward sparsity that otherwise stalls learning on competitive programming style tasks. I evaluate supervised fine-tuning (SFT) and PPO variants on a small held-out prompt set from APPS+ and observe that PPO with partial credit (using a continued-training variant) improves syntax validity from 45% (SFT) to 60% and achieves the only non-zero test success signal in this pilot evaluation (5% at-least-one-test-pass), while remaining 100% clean under Bandit static analysis. Although Bandit findings were absent in this small evaluation, the security term is integrated into training to discourage insecure shortcuts when they appear.",
    "published_date": "2026-01-03",
    "pdf_link": "https://arxiv.org/pdf/2601.01184v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Secure Coding / Code Generation Safety",
      "specific_problem": "Security-aware code generation that optimizes for functional correctness under strict stdin/stdout tests while discouraging insecure coding patterns flagged by static analysis (Bandit)",
      "attack_types": [
        "use of eval",
        "unsafe subprocess usage",
        "weak cryptography",
        "risky API usage"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Reinforcement Learning (Policy Gradient)",
        "specific": "PPO (Proximal Policy Optimization), PPO-continue variant",
        "novel_contribution": "Partial-credit functional reward shaping tailored to stdin/stdout code tasks combined with a security penalty/bonus term from Bandit in a joint objective R = α R_func + β R_sec"
      },
      {
        "type": "primary",
        "category": "Reward Shaping",
        "specific": "Staged partial-credit R_func (syntax → executes → produces stdout → partial/full test pass)",
        "novel_contribution": "Design of a staged execution-based reward that reduces sparsity by awarding intermediate milestones before full test success"
      },
      {
        "type": "baseline",
        "category": "Supervised Fine-Tuning",
        "specific": "SFT with LoRA on DeepSeek-Coder-1.3B-Instruct",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning (Policy Gradient)",
        "specific": "PPO-simple",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Reinforcement Learning (Policy Gradient)",
        "specific": "PPO-fresh (PPO initialized fresh from SFT)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer LLM (decoder-only)",
        "specific": "DeepSeek-Coder-1.3B-Instruct as base policy",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Reinforcement Learning"
    ],
    "datasets": [
      {
        "name": "APPS+ (APPS_Plus / APPS Plus)",
        "type": "public",
        "domain": "competitive_programming_problems (stdin/stdout unit tests)",
        "link": "https://github.com/Ablustrund/APPS Plus",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "APPS+ direct data file (used in pipeline)",
        "type": "public",
        "domain": "competitive_programming_problems (stdin/stdout unit tests)",
        "link": "https://raw.githubusercontent.com/Ablustrund/APPS Plus/refs/heads/main/data/v1/data.json",
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "SFT Baseline",
        "paper_reference": null,
        "metric": "Syntax %",
        "their_result": "60.0",
        "baseline_result": "45.0"
      },
      {
        "method_name": "SFT Baseline",
        "paper_reference": null,
        "metric": "≥1 Test Pass %",
        "their_result": "5.0",
        "baseline_result": "0.0"
      },
      {
        "method_name": "SFT Baseline",
        "paper_reference": null,
        "metric": "Security %",
        "their_result": "100.0",
        "baseline_result": "100.0"
      },
      {
        "method_name": "SFT Baseline",
        "paper_reference": null,
        "metric": "Mean R",
        "their_result": "0.41",
        "baseline_result": "0.40"
      },
      {
        "method_name": "PPO-simple",
        "paper_reference": null,
        "metric": "Syntax %",
        "their_result": "60.0",
        "baseline_result": "15.0"
      },
      {
        "method_name": "PPO-simple",
        "paper_reference": null,
        "metric": "≥1 Test Pass %",
        "their_result": "5.0",
        "baseline_result": "0.0"
      },
      {
        "method_name": "PPO-simple",
        "paper_reference": null,
        "metric": "Security %",
        "their_result": "100.0",
        "baseline_result": "100.0"
      },
      {
        "method_name": "PPO-simple",
        "paper_reference": null,
        "metric": "Mean R",
        "their_result": "0.41",
        "baseline_result": "0.40"
      },
      {
        "method_name": "PPO-fresh",
        "paper_reference": null,
        "metric": "Syntax %",
        "their_result": "60.0",
        "baseline_result": "25.0"
      },
      {
        "method_name": "PPO-fresh",
        "paper_reference": null,
        "metric": "≥1 Test Pass %",
        "their_result": "5.0",
        "baseline_result": "0.0"
      },
      {
        "method_name": "PPO-fresh",
        "paper_reference": null,
        "metric": "Security %",
        "their_result": "100.0",
        "baseline_result": "100.0"
      },
      {
        "method_name": "PPO-fresh",
        "paper_reference": null,
        "metric": "Mean R",
        "their_result": "0.41",
        "baseline_result": "0.40"
      },
      {
        "method_name": "DeepSeek-6.7B (benchmark pre-training models)",
        "paper_reference": "[3]",
        "metric": "All-tests-pass %",
        "their_result": null,
        "baseline_result": "14.3"
      },
      {
        "method_name": "DeepSeek-6.7B (benchmark pre-training models)",
        "paper_reference": "[3]",
        "metric": "Syntax Valid %",
        "their_result": null,
        "baseline_result": "83.4"
      },
      {
        "method_name": "DeepSeek-6.7B (benchmark pre-training models)",
        "paper_reference": "[3]",
        "metric": "Security Clean %",
        "their_result": null,
        "baseline_result": "96.3"
      },
      {
        "method_name": "CodeLlama-7B (benchmark pre-training models)",
        "paper_reference": "[4]",
        "metric": "All-tests-pass %",
        "their_result": null,
        "baseline_result": "7.6"
      },
      {
        "method_name": "CodeLlama-7B (benchmark pre-training models)",
        "paper_reference": "[4]",
        "metric": "Syntax Valid %",
        "their_result": null,
        "baseline_result": "48.9"
      },
      {
        "method_name": "CodeLlama-7B (benchmark pre-training models)",
        "paper_reference": "[4]",
        "metric": "Security Clean %",
        "their_result": null,
        "baseline_result": "99.5"
      },
      {
        "method_name": "StarCoder2-7B (benchmark pre-training models)",
        "paper_reference": "[5]",
        "metric": "All-tests-pass %",
        "their_result": null,
        "baseline_result": "1.3"
      },
      {
        "method_name": "StarCoder2-7B (benchmark pre-training models)",
        "paper_reference": "[5]",
        "metric": "Syntax Valid %",
        "their_result": null,
        "baseline_result": "20.2"
      },
      {
        "method_name": "StarCoder2-7B (benchmark pre-training models)",
        "paper_reference": "[5]",
        "metric": "Security Clean %",
        "their_result": null,
        "baseline_result": "99.7"
      }
    ],
    "performance_metrics_used": [
      "Syntax Valid %",
      "At-least-one-test-pass %",
      "Security Clean %",
      "Mean R",
      "All-tests-pass %",
      "Mean R_func",
      "Mean R_sec"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "If the reward is 'all tests pass', how does an RL system learn anything when almost nothing passes?",
        "Can a combined reward optimize for both functional correctness and security to discourage insecure shortcuts during code generation?"
      ],
      "gaps_identified": [
        "Sparse binary rewards in code generation tasks with strict unit tests hinder learning",
        "Lack of security-aware training signals in code generation (models may introduce insecure patterns and risky APIs)",
        "Benchmark gap between syntactic validity and full test success",
        "Limited sensitivity of binary metrics to early learning progress"
      ],
      "limitations": [
        "Small evaluation set (20 prompts) with high variance; 5% ≥1 test pass corresponds to 1/20 prompts",
        "Security findings were absent under Bandit in the pilot, so the security term did not differentiate models",
        "Competitive-programming bias (stdin/stdout) may not transfer to general coding tasks",
        "Missing ablations to isolate effects of partial credit vs binary reward and the security term",
        "Did not compare against inference-time selection baselines (e.g., best-of-k with test-based selection)"
      ],
      "future_work": [
        "Scale evaluation to hundreds of prompts with difficulty stratification on APPS+",
        "Add uncertainty estimates (bootstrap CIs) for Syntax % and test success",
        "Run controlled ablations: PPO with binary vs partial-credit rewards; with/without security term",
        "Include stronger functionality baselines (e.g., best-of-k sampling with test-based selection)",
        "Expand security coverage with additional static analyzers or a curated vulnerability suite",
        "Provide qualitative paired examples showing how reward shaping changes outputs (fixes missing print, formatting, timeouts; cases where R_sec prevents risky shortcuts)"
      ],
      "motivation": "Reduce reward sparsity in RL for code generation under strict stdin/stdout tests and integrate security-aware penalties to avoid insecure shortcuts.",
      "potential_research_ideas": [
        "Learned reward models for partial credit that predict fine-grained execution outcomes rather than rule-based staging",
        "Curriculum or self-play style RL that gradually increases test difficulty/strictness to ease exploration",
        "Integrate dynamic analyses (coverage-guided fuzzing, taint analysis) to enrich security/correctness rewards beyond Bandit",
        "Cross-language generalization: extend partial-credit reward to C/C++/Java with compiler/runtime stages and language-specific static analyzers",
        "Hybrid training with program repair: use repair suggestions to generate intermediate targets and shape rewards",
        "Multi-objective optimization tracking Pareto fronts over correctness, security, and efficiency (runtime/memory)",
        "On-policy/off-policy mix: collect large replay buffers of executions to stabilize learning in sparse regimes",
        "Augment tasks with unit-test generation and co-training to reduce cases of 'no output' and wrong formatting"
      ],
      "architectural_improvement_recommendations": [
        "Tune PPO hyperparameters and advantage normalization; compare PPO-clip variants and KL penalties tailored to LLM RL",
        "Use multi-sample rollouts per prompt with group-based updates to better exploit partial-credit signals",
        "Incorporate rejection sampling or best-of-n during training (RL with reranking) to improve sample efficiency",
        "Apply parameter-efficient RL fine-tuning (e.g., LoRA layers on attention/output heads only) with targeted adapters for I/O handling",
        "Add a security-aware constraint via Lagrangian methods to adaptively weight R_sec vs R_func during training",
        "Introduce a formatting-aware tokenizer/prompting scaffold to stabilize stdin/stdout parsing and printing behaviors"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": "https://github.com/SuryanshSS1011/basic-rl-feedback-workflow",
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Evidence-driven motivation via benchmarking multiple open code models on APPS+ highlighting gap between syntactic validity and full test success",
      "Joint objective for correctness and security: R = α R_func + β R_sec with Bandit-derived security term",
      "Partial-credit functional reward shaping that distinguishes syntax validity, execution, stdout production, and partial/full test pass",
      "Pilot RL results: PPO with partial credit (continued training) improves syntax validity to 60% and achieves 5% ≥1 test pass while remaining 100% Bandit-clean",
      "Release of a public codebase for the SecureCodeRL pipeline"
    ]
  },
  {
    "arxiv_id": "2601.03304v1",
    "title": "AI-Driven Cybersecurity Threats: A Survey of Emerging Risks and Defensive Strategies",
    "authors": "Sai Teja Erukude; Viswa Chaitanya Marella; Suhasnadh Reddy Veluru",
    "abstract": "Artificial Intelligence's dual-use nature is revolutionizing the cybersecurity landscape, introducing new threats across four main categories: deepfakes and synthetic media, adversarial AI attacks, automated malware, and AI-powered social engineering. This paper aims to analyze emerging risks, attack mechanisms, and defense shortcomings related to AI in cybersecurity. We introduce a comparative taxonomy connecting AI capabilities with threat modalities and defenses, review over 70 academic and industry references, and identify impactful opportunities for research, such as hybrid detection pipelines and benchmarking frameworks. The paper is structured thematically by threat type, with each section addressing technical context, real-world incidents, legal frameworks, and countermeasures. Our findings emphasize the urgency for explainable, interdisciplinary, and regulatory-compliant AI defense systems to maintain trust and security in digital ecosystems.",
    "published_date": "2026-01-06",
    "pdf_link": "https://arxiv.org/pdf/2601.03304v1",
    "paper_types": [
      "survey"
    ],
    "security_domain": {
      "primary": "Multiple (AI-enabled Cyber Threats)",
      "subdomain": "Deepfakes; Adversarial ML; Malware; Phishing & Social Engineering",
      "specific_problem": "Survey of AI-driven cybersecurity threats and defenses across deepfakes/synthetic media, adversarial attacks on ML, automated/polymorphic malware, and AI-powered phishing/social engineering, including legal and regulatory context",
      "attack_types": [
        "Deepfakes (video, audio, image, text)",
        "Voice cloning",
        "Face swaps",
        "Text-to-video fakes",
        "Adversarial examples/evasion attacks (FGSM, PGD, C&W)",
        "Data poisoning",
        "Polymorphic/metamorphic malware",
        "Ransomware",
        "Botnets",
        "Phishing (LLM-generated)",
        "Business Email Compromise (BEC)",
        "Deepfake video conferencing fraud",
        "Social engineering automation"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "Generative Adversarial Networks",
        "specific": "GAN-based deepfake generation",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Voice Cloning",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Deepfake Generation",
        "specific": "Face swaps; Text-to-video",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Adversarial Attack",
        "specific": "FGSM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Adversarial Attack",
        "specific": "PGD",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Adversarial Attack",
        "specific": "Carlini & Wagner (C&W)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Defense",
        "specific": "Adversarial training",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Defense",
        "specific": "Defensive distillation",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Defense",
        "specific": "Gradient masking",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Defense",
        "specific": "Certified robustness",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Feature Engineering",
        "specific": "Wavelet-transformed feature extraction for deepfake detection",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Explainable AI",
        "specific": "Weighted n-gram analysis for phishing detection",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Security Analytics",
        "specific": "AI-based behavior monitoring in EDR/XDR",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Anomaly Detection",
        "specific": "UEBA (User and Entity Behavior Analytics)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [],
    "datasets": [
      {
        "name": "Deepfake-Eval-2024",
        "type": "public",
        "domain": "synthetic_media (video, audio, image)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "AUC"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "What emerging risks arise from AI's dual-use nature across deepfakes, adversarial attacks, automated malware, and AI-powered social engineering?",
        "What are the attack mechanisms and tooling enabling these AI-driven threats?",
        "Where do current defenses fall short in robustness, generalization, and real-world deployment?",
        "How are legal and regulatory frameworks responding across jurisdictions (e.g., India, EU, US, South Korea)?",
        "What research opportunities can strengthen defenses (e.g., hybrid detection pipelines, benchmarking frameworks)?"
      ],
      "gaps_identified": [
        "“Benchmarks such as the ‘Deepfake-Eval-2024’ exhibit significant drops in the AUC score for video (50%), audio (48%), and image (45%) in uncontrolled, real-world conditions [4].”",
        "Many deepfake detectors rely on surface artifacts/background cues; are brittle to context, lighting, or language changes; detectors are often black-box and vulnerable to adversarial spoofing.",
        "Lack of multi-modal approaches and systematic enforcement enables zero-day manipulations and societal harm.",
        "No standardized approach to defend against adversarial ML attacks; adversarial training is expensive and non-scalable.",
        "Defensive distillation/gradient masking offer lightweight protection but have known vulnerabilities to adaptive attacks.",
        "Regulatory/legal gaps: “there have been no global laws governing adversarial AI”; partial/uneven deepfake laws; India lacks AI-specific cyber risk legislation.",
        "Polymorphic/metamorphic malware increasingly bypasses signature-based detection; need for robust behavior-based detection.",
        "Trust and explainability remain unresolved in AI-driven detection pipelines."
      ],
      "limitations": [],
      "future_work": [
        "Multi-Modal Explainable Detection Pipelines",
        "Adaptive Threat Simulation and Benchmarking Platforms",
        "Cross-Jurisdictional AI Risk Governance"
      ],
      "motivation": "AI’s dual-use nature is introducing scalable, intelligent, and personalized cyber threats. The paper seeks to analyze risks, map AI capabilities to threats/defenses via a taxonomy, contextualize legal frameworks, and surface urgent research needs for explainable, robust, and compliant defenses.",
      "potential_research_ideas": [
        "Design a multi-modal deepfake defense pipeline that jointly reasons over audio, video, image, and text with human-in-the-loop triage and XAI modules.",
        "Develop an open, continuously updated AI threat simulation and benchmarking platform that spans deepfakes, adversarial ML, malware, and phishing, including real-world noise and distribution shift.",
        "Create certified robustness toolkits tailored for security-critical systems (e.g., CAVs, healthcare) with measurable guarantees against common attack classes.",
        "Investigate watermarking, provenance, and liveness verification protocols for voice/video to mitigate real-time deepfake conference fraud.",
        "Integrate UEBA-driven anomaly detection with EDR/XDR telemetry and LLM-based triage to catch polymorphic malware and automated scams.",
        "Construct datasets and evaluation protocols for AI-powered social engineering (pig-butchering, CEO fraud), including multi-modal, conversational, and temporal dynamics.",
        "Model-centric + data-centric defense co-design: robust training with adversarial/data poisoning defenses plus data provenance/validation pipelines.",
        "Policy-aware AI defenses that encode jurisdiction-specific compliance checks and evidence capture for law enforcement."
      ],
      "architectural_improvement_recommendations": [
        "Implement a hybrid architecture combining wavelet-based features with deep neural backbones for deepfake detection, augmented by attention-based XAI for inspector feedback.",
        "Combine adversarial training with certified defenses and adversarial input detectors to provide layered robustness; include confidence/uncertainty gating for human review.",
        "Fuse weighted n-gram XAI phishing filters with voice biometrics and caller-ID verification to counter multimodal scam vectors.",
        "Deploy multi-sensor liveness detection (blink/eye-gaze/micro-expression + audio spectral features) for real-time meeting deepfake defense.",
        "Unify EDR/XDR telemetry, UEBA features, and graph-based correlation to detect multi-stage malware campaigns; trigger automated response playbooks.",
        "Introduce provenance and watermark verification services into media ingestion pipelines and conferencing platforms."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Arms race dynamics between attackers and defenders in adversarial ML and malware.",
        "Weak generalization of deepfake detectors to real-world, uncontrolled conditions.",
        "Brittleness of defenses (e.g., gradient masking, distillation) under adaptive attacks.",
        "Polymorphic/metamorphic malware evades signature-based tools; need behavior-based analytics.",
        "Automation at scale of scams via LLMs/voice cloning; low user vigilance.",
        "Liveness cues can be faked in real-time video conferencing deepfakes.",
        "Regulatory fragmentation and enforcement gaps across jurisdictions.",
        "Explainability and trust deficits hinder adoption of AI-driven defenses."
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": true,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a comparative taxonomy mapping AI-driven threats to attack modalities and defensive strategies.",
      "Comprehensive survey of 70+ academic, industry, and regulatory sources (2017–2025).",
      "Synthesis of real-world incidents across deepfakes, adversarial ML, malware, and AI-enabled scams.",
      "Analysis of legal and regulatory perspectives across jurisdictions (e.g., India, EU, US, South Korea).",
      "Identification of research opportunities, including hybrid multi-modal detection pipelines and benchmarking frameworks.",
      "Consolidated recommendations table summarizing threats, gaps, and interventions."
    ]
  },
  {
    "arxiv_id": "2601.06914v1",
    "title": "Towards Compositional Generalization in LLMs for Smart Contract Security: A Case Study on Reentrancy Vulnerabilities",
    "authors": "Ying Zhou; Jiacheng Wei; Yu Qi; Faguo Wu; Xiao Zhang",
    "abstract": "Large language models (LLMs) demonstrate remarkable capabilities in natural language understanding and generation. Despite being trained on large-scale, high-quality data, LLMs still fail to outperform traditional static analysis tools in specialized domains like smart contract vulnerability detection. To address this issue, this paper proposes a post-training algorithm based on atomic task decomposition and fusion. This algorithm aims to achieve combinatorial generalization under limited data by decomposing complex reasoning tasks. Specifically, we decompose the reentrancy vulnerability detection task into four linearly independent atomic tasks: identifying external calls, identifying state updates, identifying data dependencies between external calls and state updates, and determining their data flow order. These tasks form the core components of our approach. By training on synthetic datasets, we generate three compiler-verified datasets. We then employ the Slither tool to extract structural information from the control flow graph and data flow graph, which is used to fine-tune the LLM's adapter. Experimental results demonstrate that low-rank normalization fusion with the LoRA adapter improves the LLM's reentrancy vulnerability detection accuracy to 98.2%, surpassing state-of-the-art methods. On 31 real-world contracts, the algorithm achieves a 20% higher recall than traditional analysis tools.",
    "published_date": "2026-01-11",
    "pdf_link": "https://arxiv.org/pdf/2601.06914v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Blockchain/Smart Contract Security",
      "subdomain": "Vulnerability Detection",
      "specific_problem": "Reentrancy vulnerability detection in Ethereum smart contracts",
      "attack_types": [
        "Reentrancy"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": null,
        "novel_contribution": "Compositional fusion of factor-specific adapters (CompFuse) for reentrancy detection using a task-aware gating network and linear head"
      },
      {
        "type": "primary",
        "category": "Adapter/LoRA",
        "specific": "LoRA",
        "novel_contribution": "Factor-specific LoRA adapters trained on compiler-verified datasets for external-call, data-dependency, and ordering factors; base model represents state-update factor"
      },
      {
        "type": "primary",
        "category": "Mixture-of-Experts",
        "specific": "Task-aware gating",
        "novel_contribution": "Adaptive convex fusion of branch features with temperature-controlled softmax routing aligned via Jacobian-based sensitivity"
      },
      {
        "type": "primary",
        "category": "Regularization/Loss",
        "specific": "Jacobian alignment loss",
        "novel_contribution": "KL divergence between gating distribution and Jacobian-based sensitivity target to align routing with functional relevance"
      },
      {
        "type": "primary",
        "category": "Other",
        "specific": "Sigmoid relaxation",
        "novel_contribution": "Differentiable relaxation of discrete ordering factor and log-sum-exp scoring for end-to-end training"
      },
      {
        "type": "baseline",
        "category": "Adapter/LoRA",
        "specific": "Single-task LoRA",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "External Call Dataset",
        "type": "synthetic",
        "domain": "smart_contract_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Data-Dependency Dataset",
        "type": "synthetic",
        "domain": "smart_contract_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Ordering Dataset",
        "type": "synthetic",
        "domain": "smart_contract_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Real-World Reentrancy Evaluation Set (31 contracts)",
        "type": "public",
        "domain": "smart_contract_code",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Single-task LoRA baseline",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "94.7% F1",
        "baseline_result": "77.9% F1 (−16.8 pp)"
      },
      {
        "method_name": "Single-task LoRA baseline",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "98.2% ACC",
        "baseline_result": "92.5% ACC (−5.7 pp)"
      },
      {
        "method_name": "Slither (traditional static analyzer)",
        "paper_reference": null,
        "metric": "Recall (on 31 real contracts)",
        "their_result": "87.1% recall",
        "baseline_result": "≈63.3% recall (−23.77 pp)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1",
      "Recall",
      "AUROC",
      "AUPRC"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can atomic task decomposition and fusion enable compositional generalization for reentrancy vulnerability detection under limited data?",
        "How to robustly recombine factor-level reasoning (external-call, state-update, dependency, ordering) into end-to-end reentrancy detection for LLMs?",
        "Do compiler-verified, CFG/DFG-augmented synthetic datasets improve LLM-based detection compared to fine-tuned LLM baselines and traditional static analysis tools?"
      ],
      "gaps_identified": [
        "LLMs fail to outperform static analysis tools in specialized domains like smart contract vulnerability detection despite large-scale pretraining.",
        "Lack of factor-level datasets with semantic granularity (most are only binary labels) impedes compositional reasoning.",
        "Existing works insufficiently address stability and efficiency when models face novel tasks.",
        "Little research examines compositional generalization of LLMs in specialized vertical domains such as code vulnerability detection.",
        "Traditional tools rely on syntactic heuristics and often miss ERC-standard API patterns and complex control/data flows."
      ],
      "limitations": [],
      "future_work": [],
      "motivation": "Improve LLM performance on smart contract reentrancy detection by enabling compositional generalization under data scarcity; reentrancy is security-critical and structurally dependent on external calls, state updates, dependencies, and order.",
      "potential_research_ideas": [
        "Extend compositional factorization to additional vulnerability classes (e.g., access control, integer overflow, unchecked return values) and multi-label joint detection.",
        "Incorporate dynamic execution traces or symbolic execution signals to complement CFG/DFG cues for dependency and ordering factors.",
        "Generalize to EVM bytecode and other languages (Vyper, Move, Solidity versions) with cross-language factor adapters.",
        "Develop automated, verifiable data generation with stronger correctness guarantees and broader ERC interface coverage.",
        "Explore retrieval-augmented factor adapters that condition on similar contract patterns from large corpora."
      ],
      "architectural_improvement_recommendations": [
        "Add a graph encoder (e.g., GNN/Graph Transformer) over CFG/DFG to produce structure-aware features before fusion.",
        "Upgrade the fusion to a sparse Mixture-of-Experts with learned routing conditioned on program structure.",
        "Introduce multi-task intermediate supervision on factor predictions with consistency constraints shared with the final head.",
        "Jointly fine-tune adapters and a small number of backbone layers for harder factors while retaining low-rank efficiency.",
        "Use contrastive objectives to better separate positive/negative dependency pairs and mitigate shortcut learning."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": []
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Post-training algorithm leveraging atomic task decomposition and fusion to realize compositional out-of-distribution generalization under limited data.",
      "Instantiation for reentrancy detection with decomposition into external-call, state-update, dependency, and ordering factors; factor-specific adapter training and fusion.",
      "Three compiler-verified factor datasets (~2.5k cases each) with CFG/DFG cues and semantic refinement, plus 31 real vulnerable contracts for evaluation.",
      "Achieves 98.2% accuracy and 94.7% F1 on reentrancy detection; recall 87.1% on 31 real contracts; surpasses fine-tuned and rule-based baselines and exceeds the best traditional analyzer by 23.77% recall on the real set."
    ]
  },
  {
    "arxiv_id": "2601.04243v1",
    "title": "Integrating Multi-Agent Simulation, Behavioral Forensics, and Trust-Aware Machine Learning for Adaptive Insider Threat Detection",
    "authors": "Firdous Kausar; Asmah Muallem; Naw Safrin Sattar; Mohamed Zakaria Kurdi",
    "abstract": "We present a hybrid framework for adaptive insider-threat detection that tightly integrates multi-agent simulation (MAS), layered Security Information and Event Management (SIEM) correlation, behavioral and communication forensics, trust-aware machine learning, and Theory-of-Mind (ToM) reasoning. Intelligent agents operate in a simulated enterprise environment, generating both behavioral events and cognitive intent signals that are ingested by a centralized SIEM. We evaluate four system variants: a Layered SIEM-Core (LSC) baseline, a Cognitive-Enriched SIEM (CE-SIEM) incorporating ToM and communication forensics, an Evidence-Gated SIEM (EG-SIEM) introducing precision-focused validation mechanisms, and an Enron-enabled EG-SIEM (EG-SIEM-Enron) that augments evidence gating with a pretrained email forensics module calibrated on Enron corpora. Across ten simulation runs involving eight malicious insiders, CE-SIEM achieves perfect recall (1.000) and improves actor-level F1 from 0.521 (LSC) to 0.774. EG-SIEM raises actor-level F1 to 0.922 and confirmed-alert precision to 0.997 while reducing false positives to 0.2 per run. EG-SIEM-Enron preserves high precision (1.000 confirmed-alert precision; 0.0 false positives per run), slightly improves actor-level F1 to 0.933, and reduces detection latency (average TTD 10.26 steps versus 15.20 for EG-SIEM). These results demonstrate that cognitive context improves sensitivity, evidence-gated validation enables high-precision, low-noise detection, and pretrained communication calibration can further accelerate high-confidence insider threat identification.",
    "published_date": "2026-01-06",
    "pdf_link": "https://arxiv.org/pdf/2601.04243v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Insider Threat Security",
      "subdomain": "User and Entity Behavior Analytics (UEBA) / SIEM Correlation",
      "specific_problem": "Adaptive insider threat detection via multi-agent simulation, cognitive (ToM) context, trust-aware thresholds, and evidence-gated SIEM fusion",
      "attack_types": [
        "data exfiltration",
        "stealthy insider activity",
        "account takeover",
        "staging exfiltration",
        "email leakage",
        "privilege escalation",
        "collusion with external parties"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Rule/Statistical + ML Fusion",
        "specific": "Layered SIEM with policy rules, EWMA baseline, trust-adaptive thresholds, online LR, Isolation Forest",
        "novel_contribution": "Tight integration of trust-adaptive thresholds and multi-evidence gating with ML anomaly scores within a SIEM pipeline"
      },
      {
        "type": "primary",
        "category": "Graphical/Logical Reasoning",
        "specific": "Abductive Theory-of-Mind (TomAbd) reasoning",
        "novel_contribution": "Use of ToM intent inferences as cognitive meta-features for SIEM correlation"
      },
      {
        "type": "primary",
        "category": "NLP Classifier",
        "specific": "Phishing/spam classifier trained on Enron Spam dataset",
        "novel_contribution": "Pretrained email forensics module calibrated on Enron to provide phishing likelihood and stylistic deviation features to SIEM (EG-SIEM-Enron)"
      },
      {
        "type": "primary",
        "category": "Stylometry/Forensics",
        "specific": "Authorship/style consistency, lexical statistics, AI-likeness indicator",
        "novel_contribution": "Fusion of content-based NLP and authorship/style-based features into unified cognitive vectors for SIEM risk scoring"
      },
      {
        "type": "baseline",
        "category": "Statistical",
        "specific": "EWMA (Exponentially Weighted Moving Average) behavioral baselining",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Model",
        "specific": "Online Logistic Regression (warm-up on benign data + analyst-ranked online updates)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Anomaly Detection",
        "specific": "Isolation Forest (per user-role)",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Anomaly Detection",
        "specific": "EnhancedRoleAnomalyModel (planned)",
        "novel_contribution": "Richer temporal features (bursts, time-of-day ratios, action velocity), per-role models, adversary-taint exclusion (planned upgrade)"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Unsupervised",
      "Online Learning"
    ],
    "datasets": [
      {
        "name": "Enron Email Dataset",
        "type": "public",
        "domain": "email_corpus",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Enron Spam Dataset",
        "type": "public",
        "domain": "email_corpus",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "MAS Synthetic Enterprise Logs",
        "type": "synthetic",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Synthetic Suspicious Emails (generated)",
        "type": "synthetic",
        "domain": "email_corpus",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "LSC (Layered SIEM-Core) vs CE-SIEM",
        "paper_reference": null,
        "metric": "Actor-level F1",
        "their_result": "0.774 (CE-SIEM)",
        "baseline_result": "0.521 (LSC)"
      },
      {
        "method_name": "LSC (Layered SIEM-Core) vs CE-SIEM",
        "paper_reference": null,
        "metric": "Recall",
        "their_result": "1.000 (CE-SIEM)",
        "baseline_result": null
      },
      {
        "method_name": "LSC (Layered SIEM-Core) vs EG-SIEM",
        "paper_reference": null,
        "metric": "Actor-level F1",
        "their_result": "0.922 (EG-SIEM)",
        "baseline_result": "0.521 (LSC)"
      },
      {
        "method_name": "EG-SIEM vs EG-SIEM-Enron",
        "paper_reference": null,
        "metric": "Actor-level F1",
        "their_result": "0.933 (EG-SIEM-Enron)",
        "baseline_result": "0.922 (EG-SIEM)"
      },
      {
        "method_name": "EG-SIEM vs EG-SIEM-Enron",
        "paper_reference": null,
        "metric": "Confirmed-alert precision",
        "their_result": "1.000 (EG-SIEM-Enron)",
        "baseline_result": "0.997 (EG-SIEM)"
      },
      {
        "method_name": "EG-SIEM vs EG-SIEM-Enron",
        "paper_reference": null,
        "metric": "False positives per run",
        "their_result": "0.0 (EG-SIEM-Enron)",
        "baseline_result": "0.2 (EG-SIEM)"
      },
      {
        "method_name": "EG-SIEM vs EG-SIEM-Enron",
        "paper_reference": null,
        "metric": "Average Time-To-Detection (TTD)",
        "their_result": "10.26 steps (EG-SIEM-Enron)",
        "baseline_result": "15.20 steps (EG-SIEM)"
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall",
      "F1",
      "confirmed-alert precision",
      "false positives per run",
      "time-to-detection (TTD)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Does adding cognitive context (ToM and communication forensics) improve insider detection sensitivity?",
        "Can evidence-gated validation reduce false positives and increase confirmed-alert precision in SIEM pipelines?",
        "Does a pretrained, Enron-calibrated email forensics module accelerate high-confidence insider identification (lower TTD) while maintaining precision?"
      ],
      "gaps_identified": [
        "Traditional ML/SIEM approaches neglect human factors such as intent, trust, and communication context.",
        "Prior works do not unify multi-agent systems (MAS) and anomaly-based ML within a single adaptive model.",
        "Existing methods often yield high false positives or are brittle under noisy conditions."
      ],
      "limitations": [
        "Evaluation is performed in a MAS-driven synthetic environment; no real enterprise deployment or real-world logs evaluated.",
        "Current SIEM scoring is primarily feature-driven; ToM intent signals are not yet fully integrated into the alert scoring model.",
        "EnhancedRoleAnomalyModel is presented as a planned upgrade and not evaluated in reported results.",
        "No discussion of hyperparameters/training settings for classifiers beyond high-level description; code and data releases are not indicated."
      ],
      "future_work": [
        "Integrate ToM intent signals directly into alert models to flag coordinated or subtle attacks.",
        "Implement and evaluate the EnhancedRoleAnomalyModel with richer temporal features and per-role specialization.",
        "Leverage SIEM analyst feedback loops to continually refine AI-text forensics and classification models.",
        "Scale MAS scenarios and evaluate against real organizational SIEM/email logs for external validity."
      ],
      "motivation": "Reduce false positives and improve adaptive sensitivity in insider threat detection by fusing behavioral analytics, ToM cognitive context, communication forensics, and trust-aware thresholds within a layered SIEM.",
      "potential_research_ideas": [
        "Evaluate the framework on real enterprise SIEM/email datasets to assess generalization and operational impact.",
        "Incorporate graph-based models (e.g., GNNs) over user-resource-email interaction graphs to capture coordinated insider behavior.",
        "Adversarial simulation of insiders using reinforcement learning to stress-test evidence gating and trust calibration.",
        "Bayesian or conformal risk calibration for user-specific thresholds with uncertainty estimates.",
        "Federated or privacy-preserving training for the email forensics component to mitigate data governance concerns.",
        "Integrate sequence models (Transformers) for multi-modal event streams (logs + comms) to predict intent and TTD.",
        "Formal verification of evidence-gating logic to minimize escalation errors and ensure auditability."
      ],
      "architectural_improvement_recommendations": [
        "Replace/augment online logistic regression with calibrated models (e.g., Platt scaling, isotonic) and feature interactions.",
        "Fuse ToM intent signals via probabilistic graphical models or attention over event sequences in the SIEM scorer.",
        "Adopt a unified multi-modal encoder (logs + emails + ToM features) with late fusion and uncertainty estimation.",
        "Deploy per-role, per-entity Isolation Forests or one-class deep SVDD with drift detection for online adaptation.",
        "Use a graph-based anomaly detector over user-resource-email graphs to capture relational anomalies.",
        "Introduce active learning to prioritize analyst labeling for ambiguous alerts and improve online model updates."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "Mesa",
        "TomAbd"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "Simulated enterprise SIEM environment (MAS-generated events and emails)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Bridging from simulation to production SIEMs and enterprise email systems.",
        "Maintaining low false positives while adapting thresholds and trust over time (drift, concept shift).",
        "Privacy and compliance concerns when analyzing email content and authorship/style signals.",
        "Calibration of user-specific trust to avoid bias and over/under-sensitivity.",
        "Operationalizing multi-evidence gating without delaying urgent detections."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Hybrid framework integrating MAS, layered SIEM, behavioral and communication forensics, trust-aware ML, and ToM reasoning.",
      "Implementation of a detailed MAS insider simulation using Mesa producing behavioral events and cognitive intent signals.",
      "Multi-layer SIEM architecture: policy/rule filters, EWMA baseline, trust-adaptive thresholds, online logistic regression, Isolation Forest.",
      "Email forensics pipeline combining NLP (NER, phishing/spam classification) with authorship/style consistency and AI-likeness indicators; Enron-calibrated pretrained module option.",
      "Evidence-gated SIEM (EG-SIEM) enabling high precision through multi-condition confirmation gates and evidence accumulation.",
      "Empirical evaluation across four system variants (LSC, CE-SIEM, EG-SIEM, EG-SIEM-Enron) with reported gains in actor-level F1, confirmed-alert precision, false positives per run, and reduced TTD."
    ]
  },
  {
    "arxiv_id": "2601.06466v1",
    "title": "SecureDyn-FL: A Robust Privacy-Preserving Federated Learning Framework for Intrusion Detection in IoT Networks",
    "authors": "Imtiaz Ali Soomro; Hamood Ur Rehman; S. Jawad Hussain ID; Adeel Iqbal; Waqas Khalid; Heejung Yu ID",
    "abstract": "The rapid proliferation of Internet of Things (IoT) devices across domains such as smart homes, industrial control systems, and healthcare networks has significantly expanded the attack surface for cyber threats, including botnet-driven distributed denial-of-service (DDoS), malware injection, and data exfiltration. Conventional intrusion detection systems (IDS) face critical challenges like privacy, scalability, and robustness when applied in such heterogeneous IoT environments. To address these issues, we propose SecureDyn-FL, a comprehensive and robust privacy-preserving federated learning (FL) framework tailored for intrusion detection in IoT networks. SecureDyn-FL is designed to simultaneously address multiple security dimensions in FL-based IDS: (1) poisoning detection through dynamic temporal gradient auditing, (2) privacy protection against inference and eavesdropping attacks through secure aggregation, and (3) adaptation to heterogeneous non-IID data via personalized learning. The framework introduces three core contributions: (i) a dynamic temporal gradient auditing mechanism that leverages Gaussian mixture models (GMMs) and Mahalanobis distance (MD) to detect stealthy and adaptive poisoning attacks, (ii) an optimized privacy-preserving aggregation scheme based on transformed additive ElGamal encryption with adaptive pruning and quantization for secure and efficient communication, and (iii) a dual-objective personalized learning strategy that improves model adaptation under non-IID data using logit-adjusted loss. Extensive experiments on the N-BaIoT dataset under both IID and non-IID settings, including scenarios with up to 50% adversarial clients, demonstrate that SecureDyn-FL consistently outperforms state-of-the-art FL-based IDS defenses.",
    "published_date": "2026-01-10",
    "pdf_link": "https://arxiv.org/pdf/2601.06466v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Privacy-preserving and poisoning-resilient federated learning IDS for heterogeneous (non-IID) IoT networks with efficient communication",
      "attack_types": [
        "model_poisoning",
        "label_flipping",
        "Byzantine attacks",
        "inference attacks (model inversion, membership inference)",
        "eavesdropping/MITM"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Federated Learning",
        "specific": "Personalized FL with shared feature extractor and personalized classifier; dual-objective training",
        "novel_contribution": "Model decoupling for personalization plus joint mini-batch logit-adjusted and cross-entropy loss to improve adaptation under non-IID data"
      },
      {
        "type": "primary",
        "category": "Clustering/Outlier Detection",
        "specific": "Gaussian Mixture Models (GMM) on temporal gradients",
        "novel_contribution": "Dynamic temporal gradient auditing using GMM and Mahalanobis distance to detect stealthy/adaptive poisoning"
      },
      {
        "type": "primary",
        "category": "Distance-based Detection",
        "specific": "Mahalanobis distance",
        "novel_contribution": "Used over temporal gradient features to score and filter malicious client updates before aggregation"
      },
      {
        "type": "primary",
        "category": "Loss Engineering",
        "specific": "Logit-adjusted loss + cross-entropy (dual-objective)",
        "novel_contribution": "Improves class-imbalance handling and non-IID adaptation in client personalization"
      },
      {
        "type": "primary",
        "category": "Model Compression",
        "specific": "Adaptive quantization and dynamic unstructured pruning",
        "novel_contribution": "Reduce communication overhead while maintaining accuracy and privacy"
      },
      {
        "type": "baseline",
        "category": "Robust FL Defense",
        "specific": "FLTrust",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Robust FL Defense",
        "specific": "ShieldFL",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Robust FL Defense",
        "specific": "FL-Defender",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Federated Learning",
      "Supervised",
      "Unsupervised",
      "Personalized"
    ],
    "datasets": [
      {
        "name": "N-BaIoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "TON_IoT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "FLTrust",
        "paper_reference": null,
        "metric": "Accuracy, F1-score, Attack Success Rate",
        "their_result": "“It achieves up to 99.01% detection accuracy, a 98.9% F1-score … while maintaining strong robustness across all attack settings, consistently outperforming state-of-the-art defenses.”",
        "baseline_result": null
      },
      {
        "method_name": "ShieldFL",
        "paper_reference": "[43]",
        "metric": "Accuracy, F1-score, Attack Success Rate",
        "their_result": "“consistently outperforming state-of-the-art FL-based IDS defenses … such as … Shield FL …”",
        "baseline_result": null
      },
      {
        "method_name": "FL-Defender",
        "paper_reference": "[47]",
        "metric": "Accuracy, F1-score, Attack Success Rate",
        "their_result": "“consistently outperforming state-of-the-art FL-based IDS defenses … such as … FL-Defender.”",
        "baseline_result": null
      },
      {
        "method_name": "TrustFL",
        "paper_reference": "[36]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "SafeFL",
        "paper_reference": "[37]",
        "metric": null,
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "F1-score",
      "Attack Success Rate",
      "Computation time",
      "Communication cost",
      "Resource utilization"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "How to detect stealthy and adaptive poisoning attacks in FL-based IDS while preserving privacy of client updates?",
        "How to protect against inference and eavesdropping attacks via secure aggregation compatible with constrained IoT devices?",
        "How to adapt and personalize models under heterogeneous non-IID client data to maintain high IDS performance?",
        "How to reduce communication/computation overhead (e.g., via pruning and quantization) without degrading privacy or accuracy?"
      ],
      "gaps_identified": [
        "Vulnerability of FL to poisoning and inference attacks in IoT IDS",
        "Poor adaptation to non-IID data and limited generalization to unseen intrusions",
        "Communication inefficiencies unsuitable for resource-constrained devices",
        "Many poisoning defenses require gradient access, risking data leakage; existing methods struggle against encrypted poisoning attacks",
        "Existing frameworks either rely on TEEs (TrustFL) or incur high computational overhead (SafeFL); DP can degrade accuracy; SMC/HE often heavy for IoT"
      ],
      "limitations": [
        "Threat model excludes user-user collusion; assumes no collusion among malicious clients",
        "Server-client collusion and sophisticated adaptive attacks are out of scope",
        "Focuses on conventional model poisoning for consistency with prior work",
        "Assumes honest-but-curious server (no fully malicious server considered beyond inference attempts)"
      ],
      "future_work": [
        "Extend to complex collusion scenarios (user-user and server-client) and auditor threats",
        "Handle more sophisticated adaptive poisoning strategies beyond conventional model poisoning"
      ],
      "motivation": "Provide a comprehensive, robust, and efficient privacy-preserving FL framework for IDS in heterogeneous IoT networks that withstands poisoning and inference attacks while adapting to non-IID data.",
      "potential_research_ideas": [
        "Design collusion-resistant secure aggregation and auditing (multi-server or threshold schemes) compatible with encrypted gradient verification",
        "Adaptive/online auditor that models temporal gradients with Bayesian GMM or RNNs to track evolving adversaries",
        "Unified defense against backdoor and model poisoning under encryption, including trigger-agnostic detection on encrypted updates",
        "Incorporate differential privacy calibrated to non-IID settings alongside AHE to balance privacy-utility with formal guarantees",
        "Asynchronous and partial participation FL with robust encrypted auditing to reflect real IoT conditions",
        "Zero-shot or open-set intrusion generalization leveraging semantic relations to detect novel attacks without labeled data",
        "Hardware-accelerated HE/secure aggregation (e.g., GPU/FPGA) for on-device feasibility in low-power IoT gateways"
      ],
      "architectural_improvement_recommendations": [
        "Augment temporal gradient auditing with sequence models (e.g., GRU/LSTM) or attention over rounds to capture long-term poisoning patterns",
        "Combine robust aggregators (Trimmed Mean, Median, Bulyan, Krum) with the proposed encrypted auditing for layered defense",
        "Bayesian GMM with online updating and uncertainty scoring to reduce false positives under distribution drift",
        "Learned quantization and sparsification policies conditioned on gradient statistics to further cut communication",
        "Multi-server secure aggregation (e.g., split trust) to mitigate honest-but-curious single server assumption",
        "Stronger formal privacy analysis (composition over rounds) and bounds on inference leakage under transformed additive ElGamal"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "IoT networks with FL server–client architecture (resource-constrained devices)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Resource constraints on IoT devices (compute, memory, energy)",
        "Communication bandwidth limitations",
        "Non-IID data heterogeneity and concept drift",
        "Cryptographic overhead for privacy-preserving aggregation",
        "Balancing privacy, robustness, and accuracy in dynamic attack settings"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": true,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes SecureDyn-FL integrating dynamic auditing, encryption, and personalization for FL-based IDS",
      "Develops a GMM + Mahalanobis distance temporal gradient auditing mechanism to detect stealthy/adaptive poisoning",
      "Designs a privacy-preserving aggregation scheme using transformed additive ElGamal with adaptive pruning and quantization",
      "Introduces a dual-objective personalized learning strategy using logit-adjusted loss for non-IID adaptation",
      "Demonstrates cross-dataset generalization across N-BaIoT and TON_IoT benchmarks",
      "Reports up to 99.01% accuracy and 0.9893 F1 on N-BaIoT under same-model poisoning with robustness up to 50% adversarial clients, outperforming SOTA defenses (FLTrust, ShieldFL, FL-Defender)"
    ]
  },
  {
    "arxiv_id": "2601.05022v1",
    "title": "Knowledge-to-Data: LLM-Driven Synthesis of Structured Network Traffic for Testbed-Free IDS Evaluation",
    "authors": "Konstantinos E. Kampourakis; Vyron Kampourakis; Efstratios Chatzoglou; Georgios Kambourakis; Stefanos Gritzalis",
    "abstract": "Realistic, large-scale, and well-labeled cybersecurity datasets are essential for training and evaluating Intrusion Detection Systems (IDS). However, they remain difficult to obtain due to privacy constraints, data sensitivity, and the cost of building controlled collection environments such as testbeds and cyber ranges. This paper investigates whether Large Language Models (LLMs) can operate as controlled knowledge-to-data engines for generating structured synthetic network traffic datasets suitable for IDS research. We propose a methodology that combines protocol documentation, attack semantics, and explicit statistical rules to condition LLMs without fine-tuning or access to raw samples. Using the AWID3 IEEE~802.11 benchmark as a demanding case study, we generate labeled datasets with four state-of-the-art LLMs and assess fidelity through a multi-level validation framework including global similarity metrics, per-feature distribution testing, structural comparison, and cross-domain classification. Results show that, under explicit constraints, LLM-generated datasets can closely approximate the statistical and structural characteristics of real network traffic, enabling gradient-boosting classifiers to achieve F1-scores up to 0.956 when evaluated on real samples. Overall, the findings suggest that constrained LLM-driven generation can facilitate on-demand IDS experimentation, providing a testbed-free, privacy-preserving alternative that overcomes the traditional bottlenecks of physical traffic collection and manual labeling.",
    "published_date": "2026-01-08",
    "pdf_link": "https://arxiv.org/pdf/2601.05022v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Testbed-free synthetic generation of Wi‑Fi (IEEE 802.11) network traffic for IDS training/evaluation",
      "attack_types": [
        "impersonation",
        "injection",
        "flooding",
        "deauthentication"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM (Transformer)",
        "specific": "ChatGPT-5",
        "novel_contribution": "Constrained, ruleset- and knowledge-conditioned LLM generation of structured IEEE 802.11 traffic without fine-tuning; two-phase pipeline (hard-coded statistical rules then descriptive+statistical hybrid)."
      },
      {
        "type": "primary",
        "category": "LLM (Transformer)",
        "specific": "Gemini 2.5 Pro",
        "novel_contribution": "Same methodology as above; evaluated as a generator under identical constraints."
      },
      {
        "type": "primary",
        "category": "LLM (Transformer)",
        "specific": "Claude Opus 4.1",
        "novel_contribution": "Same methodology as above; evaluated as a generator under identical constraints."
      },
      {
        "type": "primary",
        "category": "LLM (Transformer)",
        "specific": "Qwen3-Max",
        "novel_contribution": "Same methodology as above; evaluated as a generator under identical constraints."
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting",
        "specific": "LightGBM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "MLP (Feedforward)",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Generative (prompt/rule-conditioned)"
    ],
    "datasets": [
      {
        "name": "AWID3 (Aegean Wi-Fi Intrusion Dataset 3)",
        "type": "public",
        "domain": "network_traffic (IEEE 802.11 Wi‑Fi)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Synthetic AWID3-like dataset (Phase 2) generated by ChatGPT-5",
        "type": "synthetic",
        "domain": "network_traffic (IEEE 802.11 Wi‑Fi)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Synthetic AWID3-like dataset (Phase 2) generated by Gemini 2.5 Pro",
        "type": "synthetic",
        "domain": "network_traffic (IEEE 802.11 Wi‑Fi)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Synthetic AWID3-like dataset (Phase 2) generated by Claude Opus 4.1",
        "type": "synthetic",
        "domain": "network_traffic (IEEE 802.11 Wi‑Fi)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Synthetic AWID3-like dataset (Phase 2) generated by Qwen3-Max",
        "type": "synthetic",
        "domain": "network_traffic (IEEE 802.11 Wi‑Fi)",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "ChatGPT-5 vs Qwen3-Max (generator comparison)",
        "paper_reference": null,
        "metric": "Euclidean Distance (mean) between real and synthetic feature spaces",
        "their_result": "1005.85",
        "baseline_result": "1051.06"
      },
      {
        "method_name": "ChatGPT-5 vs Claude Opus 4.1 (generator comparison)",
        "paper_reference": null,
        "metric": "Cosine Similarity (mean) between real and synthetic feature spaces",
        "their_result": "0.97937",
        "baseline_result": "0.97678"
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall",
      "F1-score",
      "accuracy",
      "confusion matrix",
      "cosine similarity",
      "Euclidean distance",
      "Kolmogorov–Smirnov (KS) statistic",
      "PCA (structural comparison)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "To what extent can LLM-generated synthetic data faithfully preserve the statistical, structural, and semantic characteristics of real network traffic, thereby serving as a reliable substitute for real-world datasets in intrusion detection research?"
      ],
      "gaps_identified": [
        "Realistic, large-scale, well-labeled cybersecurity datasets are hard to obtain due to privacy constraints, data sensitivity, and high cost of testbeds/cyber ranges.",
        "Traditional synthetic generation (simulators, probabilistic models, replay) struggles to jointly capture inter-feature dependencies, protocol constraints, and high-level behavioral semantics."
      ],
      "limitations": [
        "Method requires manually crafted/descriptive rulesets and explicit statistical constraints; purely NL descriptions were inadequate.",
        "Statistical rules were empirically derived from a 100k-sample from AWID3 to capture ranges/dependencies.",
        "Evaluation centers on a single benchmark domain (AWID3 IEEE 802.11).",
        "Phase 1 results (hard-coded rules) are omitted; only Phase 2 is reported.",
        "Models are not fine-tuned; generation depends on prompt/ruleset quality."
      ],
      "future_work": [],
      "motivation": "Enable privacy-preserving, on-demand IDS experimentation by replacing costly, sensitive, testbed-based traffic collection with controlled LLM-driven synthetic data that retains statistical and semantic fidelity.",
      "potential_research_ideas": [
        "Extend constrained LLM synthesis to other network/security domains (e.g., ICS, IoT, enterprise NetFlow/PCAP, logs) and multi-protocol scenarios.",
        "Incorporate temporal/sequential structure (flow/session and burst patterns) via programmatic constraints or hybrid LLM+time-series simulators.",
        "Closed-loop generation with discriminators/critics (e.g., train a validator to reject/regenerate samples until KS/MMD targets are met).",
        "Combine LLM with probabilistic/graphical models or diffusion/VAEs for better global-local distribution matching.",
        "Privacy auditing of generated data (membership inference, nearest-neighbor leakage) with formal DP or PATE-style summaries.",
        "Automatic rule induction from documentation/standards via retrieval-augmented generation and grammar-constrained decoding.",
        "Evaluate robustness under distribution shift (new attack variants, unseen channels) and adversarially optimized traffic."
      ],
      "architectural_improvement_recommendations": [
        "Use grammar/JSON-schema constrained decoding to hard-enforce IEEE 802.11 feature validity and dependencies.",
        "Add rejection sampling and iterative self-consistency checks driven by KS thresholds per feature and cosine similarity targets globally.",
        "Introduce retrieval-augmented grounding from protocol specs and attack libraries; cache feature constraints per subtype.",
        "Hybrid generator: LLM proposes structured skeletons; probabilistic calibrators adjust marginals/joint dependencies (e.g., copulas).",
        "Integrate temporal generators (HMM/RNN/transformer) for sequence-aware fields; enforce cross-packet constraints (sequence numbers, timing).",
        "Calibrate class imbalance with cost-sensitive quotas and dynamic resampling; validate via multi-metric Pareto optimization."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "LightGBM"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Requires manual construction of statistical rulesets and protocol constraints.",
        "Ensuring strict IEEE 802.11 compliance across features and dependencies.",
        "Validation overhead to monitor quotas, distributions, and dependencies at scale.",
        "Handling severe class imbalance consistent with AWID3 ratios."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Introduces a controlled methodology to use LLMs as knowledge-to-data engines for structured network traffic generation without fine-tuning or raw data access.",
      "Combines protocol documentation, attack semantics, and explicit statistical rules into a two-phase generation pipeline (hard-coded stats → descriptive+statistical hybrid).",
      "Implements a multi-level validation framework: global similarity (cosine, Euclidean), per-feature KS tests, PCA structural comparison, and cross-domain classification.",
      "Demonstrates feasibility on AWID3 (IEEE 802.11) with four LLMs (ChatGPT-5, Gemini 2.5 Pro, Claude Opus 4.1, Qwen3-Max), achieving gradient-boosting F1 up to 0.956 on real samples.",
      "Positions LLM-driven synthesis as a testbed-free, privacy-preserving alternative for IDS experimentation."
    ]
  },
  {
    "arxiv_id": "2601.13003v1",
    "title": "PrivFly: A Privacy-Preserving Self-Supervised Framework for Rare Attack Detection in IoFT",
    "authors": "Safaa Menssouri; El Mehdi Amhoud",
    "abstract": "The Internet of Flying Things (IoFT) plays a vital role in modern applications such as aerial surveillance and smart mobility. However, it remains highly vulnerable to cyberattacks that threaten the confidentiality, integrity, and availability of sensitive data. Developing effective intrusion detection systems (IDS) for IoFT networks faces key challenges, including data imbalance, privacy concerns, and the limited capability of traditional models to detect rare but potentially damaging cyber threats. In this work, we propose PrivFly, a privacy-preserving IDS framework that integrates self-supervised representation learning and differential privacy (DP) to enhance detection performance in imbalanced IoFT network traffic. We propose a masked feature reconstruction module for self-supervised pretraining, improving feature representations and boosting rare-class detection. Differential privacy is applied during training to protect sensitive information without significantly compromising model performance. In addition, we conduct a SHapley additive explanations (SHAP)-based analysis to evaluate the impact of DP on feature importance and model behavior. Experimental results on the ECU-IoFT dataset show that PrivFly achieves up to 98% accuracy and 99% F1-score, effectively balancing privacy and detection performance for secure IoFT systems.",
    "published_date": "2026-01-19",
    "pdf_link": "https://arxiv.org/pdf/2601.13003v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Privacy-preserving rare attack detection for multiclass IDS in IoFT network traffic",
      "attack_types": [
        "Wi-Fi deauthentication",
        "WPA2-PSK cracking",
        "Tello API exploit"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Self-supervised learning",
        "specific": "VIME-style masked feature reconstruction (zero-masking only)",
        "novel_contribution": "Simplified VIME pretext task using zero-masking without marginal-value imputation; decoupled SSL pretraining from semi-supervised fine-tuning to supply embeddings to a privacy-aware classifier"
      },
      {
        "type": "primary",
        "category": "Deep Neural Network",
        "specific": "Feed-forward DNN classifier",
        "novel_contribution": "Trained with DP-SGD as a privacy-aware IDS backend using SSL-pretrained representations"
      },
      {
        "type": "primary",
        "category": "Privacy mechanism",
        "specific": "Differentially Private SGD (DP-SGD) with gradient clipping and Gaussian noise",
        "novel_contribution": "Systematic exploration of privacy–utility trade-off in IoFT IDS and SHAP-based analysis of how DP alters feature attributions"
      },
      {
        "type": "primary",
        "category": "Data augmentation",
        "specific": "SMOTE",
        "novel_contribution": "Used to expand rare attack class from 10 to 500 instances to mitigate extreme imbalance under DP training"
      },
      {
        "type": "primary",
        "category": "Generative model",
        "specific": "CTGAN",
        "novel_contribution": "Used for tabular synthetic minority oversampling to address rare-class sparsity under DP constraints"
      },
      {
        "type": "primary",
        "category": "Explainability",
        "specific": "SHAP (Shapley Additive Explanations)",
        "novel_contribution": "Assessed DP’s impact on global and class-specific feature importance for IDS decisions"
      },
      {
        "type": "baseline",
        "category": "Logistic Regression",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "SVM",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Deep Neural Network",
        "specific": "Non-private DNN",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Deep Neural Network",
        "specific": "DP-DNN (vanilla DP-SGD)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Loss function variant",
        "specific": "Focal loss (with DP-DNN)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Cost-sensitive learning",
        "specific": "Class weights (with DP-DNN)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Self-supervised",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "ECU-IoFT",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "DP-DNN (noise=5, ε≈0.18)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "92% (PrivFly + SMOTE); 91% (PrivFly + CTGAN)",
        "baseline_result": "69%"
      },
      {
        "method_name": "DP-DNN (noise=3, ε≈0.5)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "94% (PrivFly + SMOTE or CTGAN)",
        "baseline_result": "70%"
      },
      {
        "method_name": "DP-DNN (noise=1, ε≈1.41)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "95% (PrivFly + SMOTE or CTGAN)",
        "baseline_result": "71%"
      },
      {
        "method_name": "DP-DNN (noise=0.5, ε≈11.17)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "99% (PrivFly + SMOTE); 95% (PrivFly + CTGAN)",
        "baseline_result": "73%"
      },
      {
        "method_name": "DP-DNN (noise=0.2, ε≈219.11)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "99% (PrivFly + SMOTE); 95% (PrivFly + CTGAN)",
        "baseline_result": "74%"
      },
      {
        "method_name": "DP-DNN + VIME (noise=0.5)",
        "paper_reference": null,
        "metric": "F1-score (macro)",
        "their_result": "99% (PrivFly (SMOTE+VIME)); 95% (PrivFly (CTGAN+VIME))",
        "baseline_result": "74%"
      },
      {
        "method_name": "DP-DNN + CTGAN (noise=0.5)",
        "paper_reference": null,
        "metric": "F1-score (macro)",
        "their_result": "99% (PrivFly (SMOTE+VIME))",
        "baseline_result": "95%"
      },
      {
        "method_name": "DP-DNN + SMOTE (noise=0.5)",
        "paper_reference": null,
        "metric": "F1-score (macro)",
        "their_result": "99% (PrivFly (SMOTE+VIME))",
        "baseline_result": "95%"
      },
      {
        "method_name": "DP-DNN (focal loss) (noise=0.5)",
        "paper_reference": null,
        "metric": "F1-score (macro)",
        "their_result": "99% (PrivFly (SMOTE+VIME))",
        "baseline_result": "73%"
      },
      {
        "method_name": "DP-DNN (+ class weights) (noise=0.5)",
        "paper_reference": null,
        "metric": "F1-score (macro)",
        "their_result": "99% (PrivFly (SMOTE+VIME))",
        "baseline_result": "73%"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Lack of real-world IoFT datasets encompassing diverse attack types",
        "Severe class imbalance with rare but critical threats underrepresented",
        "Absence of privacy-preserving mechanisms for sensitive aerial traffic data in IDS",
        "Prior works often limited to binary classification and do not handle rare attacks in IoFT",
        "Limited interpretability/analysis of how privacy mechanisms affect model behavior"
      ],
      "limitations": [
        "DP reduces sensitivity to minority/rare-class patterns, harming rare attack detection at stronger privacy",
        "Potential overfitting to environment-specific identifiers (static MAC/IP) in non-private models, risking poor generalization",
        "Evaluation limited to a single dataset (ECU-IoFT) and controlled setting",
        "No robustness evaluation against adversarial manipulations/attacks",
        "No assessment of cross-device/domain generalization across different UAV models or network environments"
      ],
      "future_work": [
        "Extend PrivFly to distributed learning scenarios",
        "Assess robustness against adversarial threats for practical deployment in IoFT environments"
      ],
      "motivation": "Provide a privacy-preserving, interpretable IDS that can effectively detect rare but damaging cyber threats in imbalanced IoFT network traffic.",
      "potential_research_ideas": [
        "Federated or decentralized PrivFly with secure aggregation and per-client DP to protect site-level data while learning across multiple UAV fleets",
        "Domain generalization and transfer learning to handle diverse UAV models, Wi-Fi environments, and dynamic identifiers",
        "Contrastive self-supervised objectives for tabular data (e.g., TabContrast) combined with masked reconstruction to improve rare-class separability under DP",
        "DP-aware synthetic data generation (e.g., PATE-GAN or DP-CTGAN) to augment rare classes without leaking privacy",
        "Out-of-distribution and few-shot rare attack detection tailored to new/unknown UAV-specific exploits",
        "Active learning under DP to prioritize labeling of uncertain rare samples with privacy accounting",
        "Real-time on-drone or edge IDS with lightweight SSL embeddings and calibrated DP noise for streaming traffic",
        "Evaluation across multi-modal telemetry (network + RF/PHY-layer features) to reduce reliance on static identifiers",
        "Certified robustness or adversarial training compatible with DP to withstand evasion/poisoning attempts",
        "Membership inference and attribute inference auditing to empirically validate privacy guarantees in IDS models"
      ],
      "architectural_improvement_recommendations": [
        "Replace MLP with modern tabular transformers (TabTransformer, FT-Transformer) and train under DP-SGD",
        "Adopt hybrid SSL losses (masking + contrastive) with stochastic feature masking schedules to improve invariant representations",
        "Use class-conditional or difficulty-aware oversampling (e.g., ADASYN) and combine with logit-adjusted or re-weighted losses that remain stable under DP",
        "Tune DP-SGD with advanced privacy accountants (RDP/PRV) and per-layer clipping to improve utility for the same privacy budget",
        "Knowledge distillation from a strong non-private or weakly private teacher into a smaller student trained with stronger DP",
        "Calibrate model predictions (temperature scaling) and uncertainty estimation to support thresholding for rare event alerts",
        "Incorporate graph-based features (e.g., communication graphs) and GNN backends if available, trained with DP-SGD",
        "Automate hyperparameter search for masking probability, clipping norm, and noise multiplier under privacy constraints"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "UAV (Ryze Tello) Wi-Fi network traffic in IoFT; offline IDS evaluation",
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Privacy–utility trade-off: stronger DP noise reduces rare-class detection",
        "Risk of overfitting to static device/IP identifiers impacting generalization",
        "Severe class imbalance typical in IoFT traffic",
        "Lack of evaluation across heterogeneous UAV platforms and live deployments"
      ]
    },
    "concerns": {
      "explainability": true,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "Proposed PrivFly: first unified framework combining self-supervised learning and differential privacy for rare attack detection in IoFT",
      "Introduced masked feature reconstruction SSL module (VIME-inspired with zero-masking) and synthetic oversampling (SMOTE/CTGAN) to improve rare-class detection",
      "Applied DP-SGD to protect sensitive information during training while exploring privacy–utility trade-offs",
      "Conducted SHAP-based explainability analysis to study DP’s impact on feature importance and model behavior",
      "Achieved up to 98% accuracy and 99% F1-score at moderate privacy; maintained robust performance (e.g., up to 92% F1) under stricter privacy settings"
    ]
  },
  {
    "arxiv_id": "2601.02237v1",
    "title": "Quantum AI for Cybersecurity: A hybrid Quantum-Classical models for attack path analysis",
    "authors": "Jessica A. Sciammarelli; Waqas Ahmed",
    "abstract": "Modern cyberattacks are increasingly complex, posing significant challenges to classical machine learning methods, particularly when labeled data is limited and feature interactions are highly non-linear. In this study we investigates the potential of hybrid quantum-classical learning to enhance feature representations for intrusion detection and explore possible quantum advantages in cybersecurity analytics. Using the UNSW-NB15 dataset, network traffic is transformed into structured feature vectors through classical preprocessing and normalization. Classical models, including Logistic Regression and Support Vector Machines with linear and RBF kernels, are evaluated on the full dataset to establish baseline performance under large-sample conditions. Simultaneously, a quantum-enhanced pipeline maps classical features into variational quantum circuits via angle encoding and entangling layers, executed on a CPU-based quantum simulator, with resulting quantum embeddings classified using a classical SVM. Experiments show that while classical models achieve higher overall accuracy with large datasets, quantum-enhanced representations demonstrate superior attack recall and improved class separability when data is scarce, suggesting that quantum feature spaces capture complex correlations inaccessible to shallow classical models. These results highlight the potential of quantum embeddings to improve generalization and representation quality in cybersecurity tasks and provide a reproducible framework for evaluating quantum advantages as quantum hardware and simulators continue to advance.",
    "published_date": "2026-01-05",
    "pdf_link": "https://arxiv.org/pdf/2601.02237v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Binary intrusion detection for attack path analysis using hybrid quantum-classical embeddings on UNSW-NB15",
      "attack_types": [
        "Attacks (aggregate)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Variational Quantum Circuit (QML)",
        "specific": "8-qubit VQC with angle (RY) encoding, StronglyEntanglingLayers, depth=2; Pauli-Z expectation readout; embeddings classified by SVM",
        "novel_contribution": "Hybrid pipeline using quantum embeddings for attack path analysis under small-data constraints; graph-inspired feature abstraction mapped to quantum feature space"
      },
      {
        "type": "baseline",
        "category": "Support Vector Machine",
        "specific": "Linear SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Support Vector Machine",
        "specific": "RBF kernel SVM",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Generalized Linear Model",
        "specific": "Logistic Regression",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Linear SVM",
        "paper_reference": null,
        "metric": "Accuracy (%) on small-data subset (n=200, 80/20 split)",
        "their_result": "64.0 (Quantum Embedding + SVM)",
        "baseline_result": "80.0"
      },
      {
        "method_name": "RBF SVM",
        "paper_reference": null,
        "metric": "Accuracy (%) on small-data subset (n=200, 80/20 split)",
        "their_result": "64.0 (Quantum Embedding + SVM)",
        "baseline_result": "80.0"
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "Accuracy (%) on small-data subset (n=200, 80/20 split)",
        "their_result": "64.0 (Quantum Embedding + SVM)",
        "baseline_result": "72.5"
      },
      {
        "method_name": "Linear SVM",
        "paper_reference": null,
        "metric": "Accuracy (%) on full dataset",
        "their_result": null,
        "baseline_result": "69.1"
      },
      {
        "method_name": "RBF SVM",
        "paper_reference": null,
        "metric": "Accuracy (%) on full dataset",
        "their_result": null,
        "baseline_result": "68.9"
      },
      {
        "method_name": "Logistic Regression",
        "paper_reference": null,
        "metric": "Accuracy (%) on full dataset",
        "their_result": null,
        "baseline_result": "68.8"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "Confusion Matrix"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can hybrid quantum-classical models demonstrably outperform purely classical approaches for attack path analysis, especially when training data is limited?"
      ],
      "gaps_identified": [
        "Limited empirical validation of quantum-enhanced learning for attack path analysis and security-relevant graph problems",
        "Classical attack graph analytics face scaling challenges and struggle with highly non-linear patterns",
        "Most quantum-cybersecurity works focus on generic graph benchmarks rather than attack graphs or security structures",
        "Prior studies often rely on ideal simulated environments and overlook practical constraints (noise, qubit limits, integration)"
      ],
      "limitations": [
        "Quantum experiments restricted to CPU-based simulation and small subset (200 samples)",
        "Only eight features used to match qubit count; potential under-representation of traffic nuances",
        "Trade-offs in benign class detection; class imbalance issues",
        "Limited circuit expressivity (depth=2) and simple angle encoding may cap performance",
        "No evaluation on real quantum hardware; no explicit construction of full attack graphs",
        "Binary classification only; no per-attack-type analysis"
      ],
      "future_work": [
        "Optimize circuit expressivity and manage class imbalance",
        "Evaluate on real quantum hardware and under noise with error mitigation",
        "Extend to explicit attack graph construction and quantum graph learning",
        "Scale to larger datasets and explore quantum advantages with improved simulators/hardware"
      ],
      "motivation": "Investigate whether quantum feature spaces can capture complex correlations and improve generalization for cybersecurity tasks (attack path analysis) under limited labeled data.",
      "potential_research_ideas": [
        "Quantum graph kernels or quantum walk-based circuits applied to explicit attack graphs derived from enterprise networks",
        "Hardware-efficient VQCs co-designed with noise-aware training and error mitigation for IDS use-cases",
        "Meta-learning or few-shot quantum-classical models for rapid adaptation to novel attacks with scarce labels",
        "Multi-task or multi-class quantum embeddings to detect specific attack families in UNSW-NB15 (and beyond)",
        "Active learning with quantum uncertainty measures to prioritize labeling scarce cybersecurity data",
        "Knowledge distillation: transfer quantum embedding benefits into compact classical models for deployment"
      ],
      "architectural_improvement_recommendations": [
        "Adopt richer feature maps (e.g., data re-uploading, ZZFeatureMap) and deeper but regularized VQCs",
        "Try quantum kernels (QSVM) and compare against the current VQC-embedding + classical SVM",
        "Incorporate cost-sensitive learning and rebalancing (e.g., focal loss, class weights) to improve benign recall",
        "Explore entanglement topologies matched to feature dependencies and measure multiple observables beyond Pauli-Z",
        "End-to-end differentiable training (parameter-shift) with validation-based early stopping and hyperparameter search",
        "Integrate explicit graph construction and hybrid GNN+QML pipelines for attack path reasoning"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "PennyLane"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "CPU-only quantum simulation (PennyLane default.qubit); 8 qubits, depth=2; small subset of 200 samples for quantum runs due to simulation cost"
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Quantum hardware noise and limited qubit counts",
        "Integration with classical security infrastructure",
        "Simulation cost limiting dataset size and throughput",
        "Class imbalance and benign recall trade-offs",
        "Unclear real-time performance characteristics"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A five-step hybrid quantum–classical pipeline that maps curated flow features to quantum embeddings for attack path analysis",
      "Empirical comparison of classical baselines vs. quantum-enhanced representations under data-rich and data-scarce regimes",
      "Finding: classical models achieve ~69% accuracy on full UNSW-NB15; quantum embeddings show superior attack recall (claimed 100% in low-data) with trade-offs in benign detection",
      "Practical implementation guidelines using free-tier quantum simulation tools (PennyLane default.qubit) to enable reproducibility"
    ]
  },
  {
    "arxiv_id": "2601.02941v1",
    "title": "SastBench: A Benchmark for Testing Agentic SAST Triage",
    "authors": "Jake Feiglin; Guy Dar",
    "abstract": "SAST (Static Application Security Testing) tools are among the most widely used techniques in defensive cybersecurity, employed by commercial and non-commercial organizations to identify potential vulnerabilities in software. Despite their great utility, they generate numerous false positives, requiring costly manual filtering (aka triage). While LLM-powered agents show promise for automating cybersecurity tasks, existing benchmarks fail to emulate real-world SAST finding distributions. We introduce SastBench, a benchmark for evaluating SAST triage agents that combines real CVEs as true positives with filtered SAST tool findings as approximate false positives. SastBench features an agent-agnostic design. We evaluate different agents on the benchmark and present a comparative analysis of their performance, provide a detailed analysis of the dataset, and discuss the implications for future development.",
    "published_date": "2026-01-06",
    "pdf_link": "https://arxiv.org/pdf/2601.02941v1",
    "paper_types": [
      "benchmark",
      "empirical_analysis",
      "new_dataset"
    ],
    "security_domain": {
      "primary": "Application Security",
      "subdomain": "Static Analysis (SAST)",
      "specific_problem": "Automated triage of SAST findings: classifying findings as true positives vs false positives",
      "attack_types": [
        "web vulnerabilities (various CWEs)",
        "memory safety issues",
        "logic flaws"
      ]
    },
    "ml_techniques": [
      {
        "type": "baseline",
        "category": "LLM Agent",
        "specific": "ReAct",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Prompting",
        "specific": "Chain-of-Thought",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM Agent",
        "specific": "OpenHands (generalist agent)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM Agent",
        "specific": "mini-SWE-agent (generalist agent)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "Gemini 2.5 Pro",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "Gemini 2.5 Flash",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "Claude Sonnet 4.5",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "GPT-OSS 120B",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "DeepSeek R1",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "Qwen3 Coder 480B",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "Llama 4 Maverick 17B",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Zero-shot evaluation",
      "Prompting-based reasoning",
      "Tool-augmented agentic planning (ReAct)"
    ],
    "datasets": [
      {
        "name": "SASTBENCH (v0.1; SASTBENCH-v<number>@<start_date>-<end_date>)",
        "type": "public",
        "domain": "SAST_findings_from_source_code_repositories",
        "link": null,
        "is_new_contribution": true,
        "availability": "publicly_available"
      },
      {
        "name": "NVD CVE database (post-knowledge-cutoff CVEs)",
        "type": "public",
        "domain": "vulnerability_database",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "semgrep (free edition) findings on pre-fix repositories",
        "type": "synthetic",
        "domain": "SAST_findings_from_source_code_repositories",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Juliet",
        "type": "public",
        "domain": "synthetic_code_vulnerabilities",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CASTLE",
        "type": "public",
        "domain": "source_code_vulnerability_dataset",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Devign",
        "type": "public",
        "domain": "source_code_vulnerabilities (detection/classification)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CVEFixes",
        "type": "public",
        "domain": "CVE-linked code fixes",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "PrimeVul",
        "type": "public",
        "domain": "paired vulnerable/fixed code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "DiverseVul",
        "type": "public",
        "domain": "source_code_vulnerabilities (diverse languages)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ReposVul",
        "type": "public",
        "domain": "repository-level vulnerabilities (limited languages)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CleanVul",
        "type": "public",
        "domain": "cleaned vulnerability dataset",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "VulEval",
        "type": "public",
        "domain": "vulnerability evaluation benchmark",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "JitVul",
        "type": "public",
        "domain": "paired vulnerable/fixed code (just-in-time)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "eyeballvul",
        "type": "public",
        "domain": "manually curated vulnerability examples",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "D2A",
        "type": "public",
        "domain": "SAST-based vulnerability dataset",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Draper",
        "type": "public",
        "domain": "SAST-derived vulnerability dataset (uses SAST as ground truth)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "SWE-Bench",
        "type": "public",
        "domain": "software_engineering_agentic_benchmark",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Terminal-Bench",
        "type": "public",
        "domain": "agentic_terminal_interaction_benchmark",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "LiveBench",
        "type": "public",
        "domain": "continually_updated_evaluation_benchmark",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Gemini 2.5 Pro - Improved ReAct",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "0.148",
        "baseline_result": null
      },
      {
        "method_name": "Claude Sonnet 4.5 - Improved ReAct",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "0.110",
        "baseline_result": null
      },
      {
        "method_name": "Claude Sonnet 4.5 - Simple ReAct",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "0.096",
        "baseline_result": null
      },
      {
        "method_name": "Gemini 2.5 Pro - Mini SWE-Agent",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "0.092",
        "baseline_result": null
      },
      {
        "method_name": "Gemini 2.5 Pro - Simple ReAct",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "0.084",
        "baseline_result": null
      },
      {
        "method_name": "GPT-OSS 120B - Simple ReAct",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "0.083",
        "baseline_result": null
      },
      {
        "method_name": "Gemini 2.5 Pro - No Tools (CoT)",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "0.072",
        "baseline_result": null
      },
      {
        "method_name": "Gemini 2.5 Pro - OpenHands",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "0.047",
        "baseline_result": null
      },
      {
        "method_name": "DeepSeek R1 - Simple ReAct",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "0.042",
        "baseline_result": null
      },
      {
        "method_name": "Gemini 2.5 Flash - Simple ReAct",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "0.007",
        "baseline_result": null
      },
      {
        "method_name": "Qwen3 Coder 480B - Simple ReAct",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "-0.011",
        "baseline_result": null
      },
      {
        "method_name": "Llama 4 Maverick 17B - Simple ReAct",
        "paper_reference": null,
        "metric": "MCC",
        "their_result": "-0.020",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "MCC",
      "accuracy",
      "precision",
      "recall",
      "F1",
      "F2"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Existing benchmarks fail to emulate real-world SAST false positive distributions for triage.",
        "Limited scale/scope in many datasets due to manual curation or few repositories.",
        "Insufficient language diversity; many benchmarks omit languages common in real-world vulnerable systems (e.g., PHP, JavaScript/TypeScript, Go).",
        "Lack of agentic benchmark design and consideration of data leakage from model parametric knowledge.",
        "Paired setups can bias false positives and may leak fix hints; SAST-based setups sometimes use SAST as ground truth or aggressive heuristics."
      ],
      "limitations": [
        "Negative class is composed of filtered semgrep (free edition) findings which are 'mostly' real false positives; some true positives may remain.",
        "Use of a simple SAST tool configuration rather than deep semantic SAST may bias negatives.",
        "One run per model-architecture pair due to cost constraints.",
        "Infrastructure constraints led to non-simple experiments mostly employing Gemini models.",
        "Commit/CWE grouping and function-level filtering are heuristic and may not capture all edge cases."
      ],
      "future_work": [
        "Continuously update the benchmark via versioned windows aligned to model knowledge cutoffs.",
        "Further community evaluations with diverse agent designs, models, and tools.",
        "Extend dataset and analysis as part of ongoing releases (agent-agnostic, updatable framework)."
      ],
      "motivation": "Create a realistic, agent-agnostic benchmark to evaluate automated SAST triage, minimizing the simulation-reality gap and enabling fair comparison of agents/models while integrating smoothly with existing industry pipelines.",
      "potential_research_ideas": [
        "Construct a human-verified subset to precisely characterize false positives and calibrate model precision-recall trade-offs.",
        "Augment negatives using multiple SAST tools and intersection/union heuristics to better approximate real false positive distributions.",
        "Incorporate dynamic analysis (DAST/IAST) or test-case generation to validate exploitability and reduce ambiguity in labels.",
        "Develop per-CWE specialized agents with toolkits (e.g., taint/DFG analyzers) and evaluate routing strategies across CWEs.",
        "Study knowledge cutoff contamination systematically with rolling windows and live updates, including defenses against parametric leakage.",
        "Active learning loop: use uncertain cases to request human labels and efficiently expand high-quality data.",
        "Graph/code-structure aware agents leveraging AST/CFG/PDG for deeper reasoning about data/control flow.",
        "Calibrated, cost-sensitive decision-making tuned for different deployment contexts (high-recall vs high-precision)."
      ],
      "architectural_improvement_recommendations": [
        "Integrate static analysis tools (taint tracking, dataflow) as first-class tools in ReAct to ground reasoning in code semantics.",
        "Use retrieval-augmented code context builders (per-commit symbol graphs, call graphs) to reduce context fragmentation.",
        "Implement commit-level preprocessing artifacts (symbol indices, CWE-to-pattern maps) to speed instance runs and improve consistency.",
        "Adopt self-consistency or committee-of-agents voting to improve robustness under class imbalance.",
        "Train small verifier models (calibrators) on SASTBENCH features to post-hoc filter LLM decisions for higher precision.",
        "Per-CWE prompt specialization and tool routing with automatic tool selection learned from prior runs."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "DSPy",
        "Docker",
        "semgrep"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Single pass per model-architecture due to cost; commit-level preprocessing supported; evaluation relies on API-accessible LLMs."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Severe class imbalance with hard negatives mimicking SAST workloads.",
        "Potential data leakage from model parametric knowledge if knowledge cutoff is not enforced.",
        "Balancing precision vs recall depending on organizational risk tolerance and analyst capacity."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Introduce SASTBENCH, an agent-agnostic benchmark for SAST triage combining real CVEs (TPs) with filtered semgrep findings (approximate FPs).",
      "Design a realistic, agentic evaluation setup with Dockerized, REST-exposed agents operating on full repositories and returning binary triage decisions.",
      "Versioned curation methodology with knowledge-cutoff windows to reduce contamination and enable continuous updates.",
      "Open-source code and data with detailed dataset statistics (2737 samples; 299 TPs; 2438 FPs; 38 languages; 139 unique CWEs; 8.15:1 imbalance).",
      "Comparative evaluation of multiple agent paradigms and state-of-the-art LLMs; detailed analysis of performance and trade-offs."
    ]
  },
  {
    "arxiv_id": "2601.12634v1",
    "title": "The Cost of Convenience: Identifying, Analyzing, and Mitigating Predatory Loan Applications on Android",
    "authors": "Olawale Amos Akanji; Manuel Egele; Gianluca Stringhini",
    "abstract": "Digital lending applications, commonly referred to as loan apps, have become a primary channel for microcredit in emerging markets. However, many of these apps demand excessive permissions and misuse sensitive user data for coercive debt-recovery practices, including harassment, blackmail, and public shaming that affect both borrowers and their contacts.   This paper presents the first cross-country measurement of loan app compliance against both national regulations and Google's Financial Services Policy. We analyze 434 apps drawn from official registries and app markets from Indonesia, Kenya, Nigeria, Pakistan, and the Philippines. To operationalize policy requirements at scale, we translate policy text into testable permission checks using LLM-assisted policy-to-permission mapping and combine this with static and dynamic analyses of loan apps' code and runtime behavior.   Our findings reveal pervasive non-compliance among approved apps: 141 violate national regulatory policy and 147 violate Google policy. Dynamic analysis further shows that several apps transmit sensitive data (contacts, SMS, location, media) before user signup or registration, undermining informed consent and enabling downstream harassment of borrowers and third parties. Following our disclosures, Google removed 93 flagged apps from Google Play, representing over 300M cumulative installs.   We advocate for adopting our methodology as a proactive compliance-monitoring tool and offer targeted recommendations for regulators, platforms, and developers to strengthen privacy protections. Overall, our results highlight the need for coordinated enforcement and robust technical safeguards to ensure that digital lending supports financial inclusion without compromising user privacy or safety.",
    "published_date": "2026-01-19",
    "pdf_link": "https://arxiv.org/pdf/2601.12634v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Mobile Security",
      "subdomain": "App Privacy and Compliance Auditing",
      "specific_problem": "Detecting and measuring policy non-compliance and privacy-violating data access/transmission by Android digital lending (loan) apps across countries",
      "attack_types": [
        "privacy leakage",
        "data exfiltration",
        "coercive debt collection",
        "harassment",
        "blackmail"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "LLM",
        "specific": "GPT-4o Mini",
        "novel_contribution": "LLM-assisted policy-to-permission mapping to translate regulatory text into testable Android permission checks"
      },
      {
        "type": "primary",
        "category": "LLM",
        "specific": "Claude Sonnet 4",
        "novel_contribution": "Used jointly with GPT-4o Mini; union of outputs (validated by experts) forms country-specific prohibited-permission sets"
      },
      {
        "type": "baseline",
        "category": "LLM",
        "specific": "Grok3",
        "novel_contribution": "Evaluated for mapping but omitted several entries and was not used for final sets"
      },
      {
        "type": "primary",
        "category": "Program Analysis",
        "specific": "Static analysis (manifest/bytecode), FlowDroid taint analysis",
        "novel_contribution": "Integrated into LoanWatch pipeline to detect prohibited permissions, sensitive API usage, and potential data flows"
      },
      {
        "type": "primary",
        "category": "Dynamic Instrumentation",
        "specific": "Frida-based hooking/tracing",
        "novel_contribution": "Semi-automated pre-registration interaction to confirm runtime access and transmission timing (e.g., launch-time exfiltration)"
      }
    ],
    "learning_paradigm": [
      "LLM zero-shot prompting",
      "Rule-based compliance checks",
      "Static and dynamic program analysis"
    ],
    "datasets": [
      {
        "name": "LoanWatch Loan Apps Dataset (435 Android loan apps from Indonesia, Kenya, Nigeria, Pakistan, Philippines)",
        "type": "proprietary",
        "domain": "android_apks",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "AndroZoo",
        "type": "public",
        "domain": "android_apks",
        "link": "https://androzoo.uni.lu/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Google Play Store (approved apps source)",
        "type": "public",
        "domain": "android_apks",
        "link": "https://play.google.com/store",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "APKCombo",
        "type": "public",
        "domain": "android_apks",
        "link": "https://apkcombo.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "APKMonk",
        "type": "public",
        "domain": "android_apks",
        "link": "https://www.apkmonk.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "APKPure",
        "type": "public",
        "domain": "android_apks",
        "link": "https://apkpure.com/",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Nigeria FCCPC digital lending registry",
        "type": "public",
        "domain": "regulatory_registry",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Pakistan national regulator registry (digital lending)",
        "type": "public",
        "domain": "regulatory_registry",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Philippines national regulator registry (digital lending)",
        "type": "public",
        "domain": "regulatory_registry",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Indonesia digital lending registry (approved apps)",
        "type": "public",
        "domain": "regulatory_registry",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Kenya digital lending registry (approved apps)",
        "type": "public",
        "domain": "regulatory_registry",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Number of violating apps against national regulations",
      "Number of violating apps against Google’s Financial Services Policy",
      "Number of apps removed from Google Play after disclosure",
      "Cumulative installs of removed/flagged apps",
      "Number of apps transmitting sensitive data before signup/registration",
      "Presence of prohibited permissions in manifests",
      "Observation of sensitive sources-to-network sinks (taint analysis)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "To what extent do loan apps targeting Indonesia, Kenya, Nigeria, Pakistan, and the Philippines comply with national regulations and Google’s Financial Services Policy, and what misalignments or exploitable gaps exist between these policy regimes?",
        "How do non-compliant loan apps access, collect, and transmit sensitive user data, and what evidence confirms these data exfiltrations that may facilitate malicious activities such as threats and harassment?",
        "What regulatory measures, technical controls, and industry-wide best practices could help mitigate non-compliance, strengthen oversight, and safeguard user privacy and security in digital lending services?"
      ],
      "gaps_identified": [
        "Significant gaps between policy intent and enforcement reality across national regulations and Google’s FSP",
        "Prior work largely qualitative; lack of quantitative, technical compliance assessments for loan apps",
        "Misalignment between national regulations and Google’s FSP creates exploitable loopholes",
        "Lack of scalable, automated compliance monitoring tools adopted by regulators/platforms",
        "Some countries lack public registries of delisted apps, hindering oversight"
      ],
      "limitations": [
        "Study limited to five countries (Indonesia, Kenya, Nigeria, Pakistan, Philippines) due to lack of publicly accessible registries for India and Thailand at data collection time",
        "Static analysis focuses on unconditional prohibitions; conditional prohibitions require dynamic evaluation and may be partially uncovered",
        "Dynamic testing is semi-automated and restricted to pre-registration interactions (launch and permission dialogs), not full end-to-end onboarding",
        "Android-only focus; iOS ecosystem not analyzed"
      ],
      "future_work": [
        "Adopt the methodology as a proactive compliance-monitoring tool by regulators and platforms",
        "Expand Google’s prohibited-permissions list to align with national regulations",
        "Deploy automated pre-approval and periodic audits by regulators",
        "Public release of regulatory text-to-permission mappings, LLM prompts, and analysis scripts to support further research and enforcement"
      ],
      "motivation": "Widespread reports of predatory loan app practices, including privacy-violating data collection and coercive debt-recovery tactics, persist despite national regulations and Google FSP; there is a need for cross-country, technical compliance measurement and actionable enforcement recommendations.",
      "potential_research_ideas": [
        "Develop an end-to-end continuous compliance scanner integrated into app-store submission pipelines with automated regression checks on permission changes over app updates",
        "Train a behavioral classifier (static+dynamic features, network indicators) to predict predatory risk and likely harassment tooling in loan apps, complementing rule-based checks",
        "Automate consent-timing verification via large-scale UI automation to detect permission requests and data transmissions prior to meaningful consent across diverse devices/locales",
        "Extend the framework to iOS and alternative Android app markets, comparing policy ecosystems and evasion patterns",
        "Design network-side detectors for early exfiltration of contacts/SMS/media using on-device VPNs or enterprise MDM telemetry with privacy-preserving aggregation",
        "Formalize policy-to-permission mapping as executable compliance rules (e.g., using a policy DSL) with verifiable provenance and versioning"
      ],
      "architectural_improvement_recommendations": [
        "Augment dynamic analysis with automated UI exploration (e.g., Android UIAutomator/Appium) to cover onboarding/KYC flows and capture conditional prohibitions at scale",
        "Incorporate network traffic classification (TLS SNI, JA3/JA4, content-type heuristics, DPIs where lawful) to corroborate taint findings with concrete exfiltration endpoints",
        "Add differential analysis across app versions to detect permission creep and policy regression",
        "Use multi-LLM consensus and self-consistency prompting to reduce missed mappings and provide rationales with uncertainty scores in policy-to-permission outputs",
        "Implement a policy rule engine (DSL) that unifies Google FSP and country rules with provenance and temporal validity, enabling reproducible audits"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": true,
      "code_link": null,
      "frameworks": [
        "FlowDroid",
        "Frida",
        "AOSP permission/manifest analysis"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "App-store and regulator compliance monitoring for Android loan apps",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Heterogeneous and incomplete public registries across countries",
        "Apps distributed via third-party markets complicate coverage and takedown",
        "Evasion through delayed permission requests and dynamic behaviors",
        "Dynamic instrumentation and UI interactions require device/emulator orchestration"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "“We present the first data-driven measurement of loan app compliance with both national regulations (Indonesia, Kenya, Nigeria, Pakistan, and the Philippines) and Google’s Financial Services Policy.”",
      "“We apply our methodology to 435 loan apps and uncover widespread non-compliance: 141 approved apps violate national regulatory policies, and 147 breach Google’s Financial Services Policy, with combined downloads exceeding 300 million. Following our disclosure, Google removed 93 of the flagged apps. Notably, we identify 37 apps that access and transmit sensitive user data immediately upon launch, before any user interaction or registration.”",
      "“We provide actionable recommendations… We will publicly release our regulatory text-to-permission mappings, LLM prompts, and analysis scripts to support further research, enforcement, and policy reform.”"
    ]
  },
  {
    "arxiv_id": "2601.01134v1",
    "title": "AI-Powered Hybrid Intrusion Detection Framework for Cloud Security Using Novel Metaheuristic Optimization",
    "authors": "Maryam Mahdi Alhusseini; Alireza Rouhi; Mohammad-Reza Feizi-Derakhshi",
    "abstract": "Cybersecurity poses considerable problems to Cloud Computing (CC), especially regarding Intrusion Detection Systems (IDSs), facing difficulties with skewed datasets and suboptimal classification model performance. This study presents the Hybrid Intrusion Detection System (HyIDS), an innovative IDS that employs the Energy Valley Optimizer (EVO) for Feature Selection (FS). Additionally, it introduces a novel technique for enhancing the cybersecurity of cloud computing through the integration of machine learning methodologies with the EVO Algorithm. The Energy Valley Optimizer (EVO) effectively diminished features in the CIC-DDoS2019 dataset from 88 to 38 and in the CSE-CIC-IDS2018 data from 80 to 43, significantly enhancing computing efficiency. HyIDS incorporates four Machine Learning (ML) models: Support Vector Machine (SVM), Random Forest (RF), Decision Tree (D_Tree), and K-Nearest Neighbors (KNN). The proposed HyIDS was assessed utilizing two real-world intrusion datasets, CIC-DDoS2019 and CSE-CIC-IDS2018, both distinguished by considerable class imbalances. The CIC-DDoS2019 dataset has a significant imbalance between DDoS assault samples and legal traffic, while the CSE-CIC-IDS2018 dataset primarily comprises benign traffic with insufficient representation of attack types, complicating the detection of minority attacks. A downsampling technique was employed to balance the datasets, hence improving detection efficacy for both benign and malicious traffic. Twenty-four trials were done, revealing substantial enhancements in categorization accuracy, precision, and recall. Our suggested D_TreeEVO model attained an accuracy rate of 99.13% and an F1 score of 98.94% on the CIC-DDoS2019 dataset, and an accuracy rate of 99.78% and an F1 score of 99.70% on the CSE-CIC-IDS2018 data. These data demonstrate that EVO significantly improves cybersecurity in Cloud Computing (CC).",
    "published_date": "2026-01-03",
    "pdf_link": "https://arxiv.org/pdf/2601.01134v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Cloud Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Hybrid IDS with metaheuristic feature selection for network intrusion detection in cloud environments under class imbalance",
      "attack_types": [
        "DDoS",
        "General network intrusions (multi-class)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Metaheuristic Optimizer (Feature Selection)",
        "specific": "Energy Valley Optimizer (EVO)",
        "novel_contribution": "Applied EVO for feature selection within a hybrid IDS (HyIDS) on cloud intrusion datasets; reduced features (CIC-DDoS2019: 88→38, CSE-CIC-IDS2018: 80→43) and improved performance"
      },
      {
        "type": "primary",
        "category": "Decision Tree",
        "specific": null,
        "novel_contribution": "D_TreeEVO: Decision Tree trained on EVO-selected features achieved best reported results"
      },
      {
        "type": "baseline",
        "category": "Random Forest",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Support Vector Machine",
        "specific": null,
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "K-Nearest Neighbors",
        "specific": null,
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised"
    ],
    "datasets": [
      {
        "name": "CIC-DDoS2019",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CSE-CIC-IDS2018",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "GOA-GA Random Forest on CIC-DDoS2019",
        "paper_reference": "Bakro et al. [26]",
        "metric": "Accuracy",
        "their_result": "99.13% (accuracy), 98.94% (F1) on CIC-DDoS2019 with D_TreeEVO",
        "baseline_result": "99.97% (accuracy)"
      },
      {
        "method_name": "CFS-DE + Weighted Stacking (HyIDS variant)",
        "paper_reference": "Zhao et al. [10]",
        "metric": "Accuracy",
        "their_result": "99.78% (accuracy), 99.70% (F1) on CSE-CIC-IDS2018 with D_TreeEVO",
        "baseline_result": "RF=98.00%, KNN=98.89%, XGBoost=99.05% on CSE-CIC-IDS2018"
      },
      {
        "method_name": "CNN/BiLSTM/CNN-BiLSTM-Attention on CIC-DDoS2019",
        "paper_reference": "H. Xu et al. [29]",
        "metric": "Accuracy",
        "their_result": "99.13% (accuracy) on CIC-DDoS2019 with D_TreeEVO",
        "baseline_result": "Reported accuracies around 80.73%–88.36% (per table)"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1 score",
      "False Positive Rate (FPR)",
      "Computational efficiency"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Imbalanced intrusion datasets cause biased classification and poor minority attack detection",
        "High-dimensional feature spaces increase computational cost and degrade model efficacy",
        "Existing IDS models often degrade in practical scenarios; need robust hybrid approaches",
        "Trade-off between dimensionality reduction and detection accuracy needs better optimization"
      ],
      "limitations": [
        "EVO has computational complexity (noted by authors as mitigated by modern hardware/software)",
        "Use of downsampling may discard informative samples and affect generalization (class imbalance handling by reduction)"
      ],
      "future_work": [
        "Combine EVO with other metaheuristics (e.g., SNAKE) to optimize hyperparameters such as learning rate and number of neurons in DL-based IDSs"
      ],
      "motivation": "Improve cloud IDS performance under class imbalance and high dimensionality by integrating a novel metaheuristic feature selection (EVO) with machine learning classifiers.",
      "potential_research_ideas": [
        "Cost-sensitive or focal-loss classifiers to handle imbalance without downsampling on CIC-DDoS2019 and CSE-CIC-IDS2018",
        "Multi-objective feature selection optimizing accuracy, F1, FPR, and feature count simultaneously",
        "Online/streaming HyIDS with concept drift detection for cloud environments",
        "Adversarially robust HyIDS with adversarial training and attack-aware feature selection",
        "Explainable HyIDS using SHAP/feature attribution to validate EVO-selected features",
        "Cross-dataset generalization studies (train on one dataset, test on another) to assess robustness",
        "Privacy-preserving training (federated learning) for cross-tenant cloud IDS"
      ],
      "architectural_improvement_recommendations": [
        "Replace downsampling with class weighting, SMOTE/ADASYN, or ensemble methods focused on minority classes",
        "Adopt gradient boosting (XGBoost/LightGBM) and stacking ensembles on EVO-selected features",
        "Use nested cross-validation and time-based splits to avoid leakage and assess feature stability",
        "Implement multi-objective EVO variant to jointly minimize features and FPR while maximizing F1",
        "Automated hyperparameter optimization (e.g., Bayesian optimization) for DT/RF/SVM/KNN on reduced features",
        "Pipeline standardization: scaling where appropriate (for SVM/KNN), feature selection within CV folds"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Severe class imbalance in real traffic",
        "High-dimensional features leading to computational overhead",
        "Computational cost of metaheuristic feature selection"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Hybrid method employing EVO for feature selection to better represent data",
      "HyIDS framework integrating EVO with ML models (SVM, RF, DT, KNN) for cloud cybersecurity",
      "Novel application of EVO for feature reduction (CSE-CIC-IDS2018: 80→43; CIC-DDoS2019: 88→38)",
      "Downsampling to balance CIC-DDoS2019 and CSE-CIC-IDS2018",
      "Evaluation of SVM, RF, D_Tree, and KNN within IDS",
      "Performance enhancement of ML models using EVO to increase detection accuracy and resilience",
      "Comparison against existing studies demonstrating performance improvements"
    ]
  },
  {
    "arxiv_id": "2601.00509v1",
    "title": "Improving LLM-Assisted Secure Code Generation through Retrieval-Augmented-Generation and Multi-Tool Feedback",
    "authors": "Vidyut Sriram; Sawan Pandita; Achintya Lakshmanan; Aneesh Shamraj; Suman Saha",
    "abstract": "Large Language Models (LLMs) can generate code but often introduce security vulnerabilities, logical inconsistencies, and compilation errors. Prior work demonstrates that LLMs benefit substantially from structured feedback, static analysis, retrieval augmentation, and execution-based refinement. We propose a retrieval-augmented, multi-tool repair workflow in which a single code-generating LLM iteratively refines its outputs using compiler diagnostics, CodeQL security scanning, and KLEE symbolic execution. A lightweight embedding model is used for semantic retrieval of previously successful repairs, providing security-focused examples that guide generation. Evaluated on a combined dataset of 3,242 programs generated by DeepSeek-Coder-1.3B and CodeLlama-7B, the system demonstrates significant improvements in robustness. For DeepSeek, security vulnerabilities were reduced by 96%. For the larger CodeLlama model, the critical security defect rate was decreased from 58.55% to 22.19%, highlighting the efficacy of tool-assisted self-repair even on \"stubborn\" models.",
    "published_date": "2026-01-01",
    "pdf_link": "https://arxiv.org/pdf/2601.00509v1",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Secure Code Generation / Automated Program Repair",
      "specific_problem": "Reducing vulnerabilities and errors in LLM-generated C/C++ code via retrieval-augmented, multi-tool iterative self-repair",
      "attack_types": [
        "memory-safety violations",
        "buffer overflows (e.g., CodeQL cpp/unbounded-write)",
        "unchecked input flows",
        "integer overflows",
        "cryptographic misuse"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Retrieval-Augmented LLM",
        "specific": "Single LLM with RAG and iterative tool-guided self-repair",
        "novel_contribution": "Tight integration of retrieval-augmented context with compiler (GCC), CodeQL static analysis, and KLEE symbolic execution in a single-LLM, inference-time repair loop; successful repairs are fed back into RAG memory"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "DeepSeek-Coder-1.3B",
        "novel_contribution": "Used as the code-generating LLM within the proposed multi-tool feedback workflow"
      },
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "CodeLlama-7B",
        "novel_contribution": "Used as the code-generating LLM within the proposed multi-tool feedback workflow; exhibits a 'stubborn model' phenomenon mitigated by the workflow"
      },
      {
        "type": "primary",
        "category": "Sentence Embedding Model",
        "specific": "all-MiniLM-L6-v2",
        "novel_contribution": "Lightweight embedding for semantic retrieval of previously successful, security-focused repairs to guide generation"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "Single-pass LLM generation (no RAG, no tool-feedback loop)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "In-context Learning"
    ],
    "datasets": [
      {
        "name": "DeepSeek-Coder-1.3B generated C/C++ programs (1,522 samples)",
        "type": "synthetic",
        "domain": "source_code_c_cpp",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "CodeLlama-7B generated C/C++ programs (1,720 samples)",
        "type": "synthetic",
        "domain": "source_code_c_cpp",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Combined dataset of 3,242 LLM-generated programs (DeepSeek + CodeLlama)",
        "type": "synthetic",
        "domain": "source_code_c_cpp",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Baseline (single-pass DeepSeek-Coder-1.3B)",
        "paper_reference": null,
        "metric": "Compilation error rate",
        "their_result": "20.43%",
        "baseline_result": "39.79%"
      },
      {
        "method_name": "Baseline (single-pass DeepSeek-Coder-1.3B)",
        "paper_reference": null,
        "metric": "Security error rate (CodeQL critical defects)",
        "their_result": "1.45%",
        "baseline_result": "36.35%"
      },
      {
        "method_name": "Baseline (single-pass DeepSeek-Coder-1.3B)",
        "paper_reference": null,
        "metric": "Semantic error rate (KLEE failures)",
        "their_result": "5.72%",
        "baseline_result": "60.09%"
      },
      {
        "method_name": "Baseline (single-pass CodeLlama-7B)",
        "paper_reference": null,
        "metric": "Compilation error rate",
        "their_result": "28.72%",
        "baseline_result": "49.71%"
      },
      {
        "method_name": "Baseline (single-pass CodeLlama-7B)",
        "paper_reference": null,
        "metric": "Security error rate (CodeQL critical defects)",
        "their_result": "22.19%",
        "baseline_result": "58.55%"
      },
      {
        "method_name": "Baseline (single-pass CodeLlama-7B)",
        "paper_reference": null,
        "metric": "Semantic error rate (KLEE failures)",
        "their_result": "12.18%",
        "baseline_result": "19.98%"
      }
    ],
    "performance_metrics_used": [
      "Compilation error rate (GCC diagnostics)",
      "Security error rate (CodeQL critical security issues)",
      "Security-clean rate",
      "Semantic error rate (KLEE-based semantic checks)",
      "Percentage point reduction in error rates"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Single-pass LLM output is rarely sufficient for correctness or robustness; external tools are needed",
        "LLMs replicate insecure patterns from training data without explicit safety mechanisms",
        "Prior APR systems show the benefit of tool augmentation (static analyzers, execution engines, retrieval), but tight integration for security has been limited"
      ],
      "limitations": [
        "Evaluation limited to short C/C++ programs from competitive-programming style tasks; may not generalize to large industrial codebases",
        "Coverage limits of CodeQL rules and KLEE path exploration; undetected bugs such as side-channel leaks or concurrency issues are out of scope",
        "Repair loop capped at three iterations; more steps could improve results but increase latency and compute",
        "RAG retrieval is simple (all-MiniLM-L6-v2) and not conditioned on vulnerability type or program structure",
        "Offline evaluation on static benchmarks; no user studies to assess developer impact (trust, usability, debugging time)"
      ],
      "future_work": [
        "Reinforcement learning for adaptive repair policies using GCC/KLEE/CodeQL signals and iteration penalties",
        "Agentic extensions and multi-model scaling for multi-file, real-world repositories under strict tool constraints",
        "Extend evaluation to multi-file, multi-language codebases",
        "Integrate additional analyses such as dynamic fuzzing and taint tracking",
        "Learn adaptive repair policies that select tools and prompts based on error type",
        "Run user studies within real developer workflows",
        "Tighter integration between retrieval and static analysis"
      ],
      "motivation": "LLM-generated code is often uncompilable and insecure; integrating retrieval with compiler, static analysis, and symbolic execution in an iterative loop can guide a single LLM to self-repair toward secure, correct code without fine-tuning or multiple agents.",
      "potential_research_ideas": [
        "Vulnerability-type-aware retrieval that conditions examples on CodeQL alert classes and program structure",
        "Learn a memory ranking model to prioritize repairs that generalize across tasks and vulnerability patterns",
        "Multi-objective reinforcement learning controller to select tools, edit magnitude, and termination based on diagnostic signals",
        "Integrate dynamic fuzzing (e.g., libFuzzer/AFL) and taint tracking into the feedback loop with unified reward shaping",
        "AST-level edit models that enforce minimal, verifiable patches with structured diff prompts",
        "Graph-based retrieval using code property graphs or program dependence graphs to improve semantic matching",
        "Concurrency- and side-channel-aware analysis by incorporating thread sanitizers and side-channel detectors",
        "Scale to multi-file repositories with constrained agents for repository navigation and change planning under verification gates"
      ],
      "architectural_improvement_recommendations": [
        "Add a lightweight classifier to predict vulnerability type and route retrieval/prompting accordingly",
        "Use a bandit/RL-based orchestration module to adaptively choose the next tool (GCC, KLEE, CodeQL, fuzzing) and iteration budget",
        "Adopt structured patch prompts (edit-insert/diff) to constrain the LLM toward minimal, safe changes",
        "Cache and reuse diagnostics and successful patches via embedding-based nearest-neighbor to reduce latency",
        "Incorporate program slicing to localize edits and reduce context length",
        "Leverage AST/IR representations in prompts to improve semantic guidance from tools",
        "Implement uncertainty-aware early stopping based on stability of diagnostics across iterations"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Tool coverage gaps (static rules, path exploration limits) may miss real vulnerabilities",
        "Latency/compute overhead from multi-iteration loops",
        "Generalization from short C/C++ snippets to large, multi-file repositories",
        "RAG quality and retrieval relevance affect guidance effectiveness",
        "Integration into developer workflows and handling false positives/negatives from tools",
        "Multi-language support and dependency management in real projects"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Proposes a retrieval-augmented, multi-tool iterative self-repair workflow for secure code generation using a single LLM",
      "Integrates compiler diagnostics (GCC), CodeQL security scanning, and KLEE symbolic execution for verification and feedback",
      "Employs a lightweight embedding model (all-MiniLM-L6-v2) to retrieve security-focused successful repairs into context",
      "Stores successful repairs back into the RAG memory for future guidance",
      "Demonstrates large error reductions on 3,242 LLM-generated C/C++ programs (1,522 DeepSeek; 1,720 CodeLlama)",
      "Achieves 98.6% security-clean rate for DeepSeek (security error 1.45%), and reduces CodeLlama’s critical security defects from 58.55% to 22.19%",
      "Highlights a 'stubborn model' phenomenon where larger models retain higher residual security error post-repair"
    ]
  },
  {
    "arxiv_id": "2601.01673v1",
    "title": "Exposing Hidden Interfaces: LLM-Guided Type Inference for Reverse Engineering macOS Private Frameworks",
    "authors": "Arina Kharlamova; Youcheng Sun; Ting Yu",
    "abstract": "Private macOS frameworks underpin critical services and daemons but remain undocumented and distributed only as stripped binaries, complicating security analysis. We present MOTIF, an agentic framework that integrates tool-augmented analysis with a finetuned large language model specialized for Objective-C type inference. The agent manages runtime metadata extraction, binary inspection, and constraint checking, while the model generates candidate method signatures that are validated and refined into compilable headers. On MOTIF-Bench, a benchmark built from public frameworks with groundtruth headers, MOTIF improves signature recovery from 15% to 86% compared to baseline static analysis tooling, with consistent gains in tool-use correctness and inference stability. Case studies on private frameworks show that reconstructed headers compile, link, and facilitate downstream security research and vulnerability studies. By transforming opaque binaries into analyzable interfaces, MOTIF establishes a scalable foundation for systematic auditing of macOS internals.",
    "published_date": "2026-01-04",
    "pdf_link": "https://arxiv.org/pdf/2601.01673v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software and Systems Security",
      "subdomain": "Reverse Engineering",
      "specific_problem": "Objective-C type inference and API/interface reconstruction for undocumented macOS private frameworks (Mach-O binaries)",
      "attack_types": [
        "privilege escalation",
        "policy bypass",
        "SIP bypass",
        "process injection"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer",
        "specific": "Finetuned small LLM distilled from large-model interaction traces for Objective-C type inference",
        "novel_contribution": "Domain-specialized LLM for type inference in macOS frameworks; optimized for local deployment and efficient signature recovery"
      },
      {
        "type": "primary",
        "category": "Tool-Augmented Agent",
        "specific": "ReAct-style loop with external tools (disassemblers, metadata extraction) and a semantic linter",
        "novel_contribution": "Iterative, constraint-guided refinement with a domain-specific Objective-C semantic linter to validate and refine LLM-generated signatures into compilable headers"
      },
      {
        "type": "primary",
        "category": "Knowledge Distillation",
        "specific": null,
        "novel_contribution": "Distillation from large-model interaction traces to create a smaller, specialized model (MOTIF-MODEL)"
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Distillation",
      "Tool-augmented prompting"
    ],
    "datasets": [
      {
        "name": "MOTIF-Bench",
        "type": "public",
        "domain": "macos_framework_binaries",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Baseline static analysis tooling (e.g., class-dump/metadata-derived headers from disassemblers)",
        "paper_reference": null,
        "metric": "signature recovery rate",
        "their_result": "86%",
        "baseline_result": "15%"
      }
    ],
    "performance_metrics_used": [
      "signature recovery rate",
      "tool-use correctness",
      "inference stability",
      "compilation success (headers compile/link)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can LLMs, when combined with program-analysis tools, autonomously recover accurate method signatures and interface definitions in undocumented macOS frameworks?"
      ],
      "gaps_identified": [
        "Existing methods struggle with complex object-oriented binaries and dynamic dispatch in Objective-C",
        "Rule-based systems are brittle against evolving compiler idioms",
        "Purely static analyses are incomplete without broader semantic understanding",
        "Learning-based efforts focus on general binary analysis rather than macOS framework reconstruction",
        "LLM application to binary analysis remains largely unexplored",
        "Sparse type encodings and incomplete disassembly metadata hinder recovery",
        "Absence of ground-truth evaluation for macOS private framework type inference"
      ],
      "limitations": [
        "Focus on Objective-C frameworks with runtime metadata; non-Objective-C code (pure C/C++) is not directly exposed via ObjC metadata",
        "Assumes presence of Objective-C runtime metadata (class names, selectors) in Mach-O sections",
        "Dynamic dispatch and pervasive use of 'id' erase static constraints, complicating recovery",
        "Evaluation benchmark is constructed from public frameworks; generalization to all private frameworks may vary",
        "Blocks/closures and anonymous structs add complexity and may remain hard cases"
      ],
      "future_work": [],
      "motivation": "Private macOS frameworks underpin critical services but ship as stripped, undocumented binaries, creating barriers to security analysis; accurate type inference transforms opaque binaries into analyzable interfaces to support systematic auditing and vulnerability research.",
      "potential_research_ideas": [
        "Extend the approach to recover C/C++ function signatures and types within the same frameworks by integrating demangling, ABI-aware dataflow, and symbolic execution",
        "Incorporate dynamic tracing (e.g., DTrace/instrumentation) to collect runtime argument types and refine static inferences in a hybrid static-dynamic loop",
        "Leverage retrieval-augmented generation over public Apple SDK headers to provide stronger priors for analogous private APIs",
        "Apply graph neural networks over control-flow and call graphs to propagate constraints and calibrate LLM outputs",
        "Use reinforcement learning from compiler/linter feedback (RLHF/RLAIF) where successful compilation and semantic checks provide reward signals",
        "Calibrate confidence estimates for each inferred type/signature to guide human-in-the-loop validation and triage",
        "Develop cross-binary consistency checking to reconcile type inferences across framework versions and client apps"
      ],
      "architectural_improvement_recommendations": [
        "Integrate an SMT-based constraint solver to reason about ABI, pointer aliasing, and struct layout consistency alongside the linter",
        "Add a compile-in-the-loop mechanism using Clang with targeted stubs/mocks to validate linkage and catch subtle signature mismatches",
        "Introduce retrieval augmentation of semantically similar public headers/selectors to ground LLM proposals",
        "Implement multi-hypothesis decoding with beam/MCTS and constraint scoring to select the most consistent signature set",
        "Cache and reuse inferred types across related classes/selectors to enforce global consistency within a framework",
        "Enhance tool inventory with robust disassembly (e.g., multiple backends) and runtime probes to reduce tool brittleness"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": "Not specified; authors state a small LLM specialized for local deployment"
    },
    "practical_aspects": {
      "real_world_tested": true,
      "deployment_environment": "macOS reverse-engineering setting; reconstructed headers compile and link against private frameworks",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Objective-C dynamic dispatch and sparse type encodings complicate static recovery",
        "Dependence on the presence and correctness of Objective-C runtime metadata",
        "Toolchain integration (disassemblers, metadata extractors, linters) and iterative loops may be brittle across binaries",
        "Non-ObjC components require different analysis paths"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "MOTIF-AGENT: An LLM-guided reverse engineering pipeline orchestrating external tools and a semantic linter to recover Objective-C method signatures from stripped binaries",
      "MOTIF-BENCH: A benchmark dataset built from public macOS frameworks with ground-truth headers for quantitative evaluation",
      "MOTIF-MODEL: A small finetuned/distilled LLM specialized for Objective-C type inference and local deployment",
      "Quantitative gains: \"MOTIF improves signature recovery from 15% to 86% compared to baseline static analysis tooling\" on MOTIF-Bench",
      "Case studies on private frameworks show reconstructed headers compile, link, and facilitate downstream security research and vulnerability studies",
      "Demonstrates consistent gains in tool-use correctness and inference stability; establishes a scalable foundation for systematic auditing of macOS internals"
    ]
  },
  {
    "arxiv_id": "2601.01183v1",
    "title": "Comparative Evaluation of VAE, GAN, and SMOTE for Tor Detection in Encrypted Network Traffic",
    "authors": "Saravanan A; Aswani Kumar Cherukuri",
    "abstract": "Encrypted network traffic poses significant challenges for intrusion detection due to the lack of payload visibility, limited labeled datasets, and high class imbalance between benign and malicious activities. Traditional data augmentation methods struggle to preserve the complex temporal and statistical characteristics of real network traffic. To address these issues, this work explores the use of Generative AI (GAI) models to synthesize realistic and diverse encrypted traffic traces. We evaluate three approaches: Variational Autoencoders (VAE), Generative Adversarial Networks (GAN), and SMOTE (Synthetic Minority Over-sampling Technique), each integrated with a preprocessing pipeline that includes feature selection and class balancing. The UNSW NB-15 dataset is used as the primary benchmark, focusing on Tor traffic as anomalies. We analyze statistical similarity between real and synthetic data, and assess classifier performance using metrics such as Accuracy, F1-score, and AUC-ROC. Results show that VAE-generated data provides the best balance between privacy and performance, while GANs offer higher fidelity but risk overfitting. SMOTE, though simple, enhances recall but may lack diversity. The findings demonstrate that GAI methods can significantly improve encrypted traffic detection when trained with privacy-preserving synthetic data.",
    "published_date": "2026-01-03",
    "pdf_link": "https://arxiv.org/pdf/2601.01183v1",
    "paper_types": [
      "empirical_analysis"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Encrypted traffic anomaly detection with focus on Tor traffic using synthetic data augmentation",
      "attack_types": [
        "Tor traffic detection",
        "Anomaly detection in encrypted network flows"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Autoencoder",
        "specific": "Variational Autoencoder (VAE)",
        "novel_contribution": "Applied for tabular encrypted flow features with a 16-dimensional latent space; label-conditioned decoding; evaluated for privacy-utility trade-off"
      },
      {
        "type": "primary",
        "category": "GAN",
        "specific": "Conditional GAN for tabular data",
        "novel_contribution": "Adapted GAN with label conditioning for tabular encrypted traffic features; evaluated for fidelity vs privacy leakage"
      },
      {
        "type": "baseline",
        "category": "Resampling",
        "specific": "SMOTE",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Ensemble Tree",
        "specific": "Random Forest",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Gradient Boosting",
        "specific": "XGBoost",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Unsupervised",
      "Supervised"
    ],
    "datasets": [
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "VAE synthetic data (Random Forest) vs Real data baseline",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "99.20%",
        "baseline_result": "98.79%"
      },
      {
        "method_name": "GAN synthetic data (Random Forest) vs Real data baseline",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "99.16%",
        "baseline_result": "98.79%"
      },
      {
        "method_name": "SMOTE synthetic data (Random Forest) vs Real data baseline",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "99.23%",
        "baseline_result": "98.79%"
      },
      {
        "method_name": "VAE synthetic data (XGBoost) vs Real data baseline",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "99.23%",
        "baseline_result": "98.77%"
      },
      {
        "method_name": "GAN synthetic data (XGBoost) vs Real data baseline",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "99.17%",
        "baseline_result": "98.77%"
      },
      {
        "method_name": "SMOTE synthetic data (XGBoost) vs Real data baseline",
        "paper_reference": null,
        "metric": "Accuracy",
        "their_result": "99.21%",
        "baseline_result": "98.77%"
      },
      {
        "method_name": "VAE vs Real (Random Forest)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "99%",
        "baseline_result": "98%"
      },
      {
        "method_name": "GAN vs Real (Random Forest)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "99%",
        "baseline_result": "98%"
      },
      {
        "method_name": "SMOTE vs Real (Random Forest)",
        "paper_reference": null,
        "metric": "F1-score",
        "their_result": "99%",
        "baseline_result": "98%"
      },
      {
        "method_name": "VAE vs GAN",
        "paper_reference": null,
        "metric": "MIA AUC (privacy)",
        "their_result": "0.612 (95% CI [0.599–0.626])",
        "baseline_result": "0.824 (95% CI [0.810–0.837])"
      },
      {
        "method_name": "VAE vs SMOTE",
        "paper_reference": null,
        "metric": "MIA AUC (privacy)",
        "their_result": "0.612 (95% CI [0.599–0.626])",
        "baseline_result": "0.588 (95% CI [0.574–0.601])"
      },
      {
        "method_name": "GAN vs VAE",
        "paper_reference": null,
        "metric": "Fidelity (JS Divergence; lower is better)",
        "their_result": "0.188",
        "baseline_result": "0.213"
      }
    ],
    "performance_metrics_used": [
      "Accuracy",
      "Precision",
      "Recall",
      "F1-score",
      "AUC-ROC",
      "Confusion Matrix",
      "MIA AUC (Membership Inference Attack AUC)",
      "Membership inference attacker Accuracy/Precision/Recall",
      "Jensen-Shannon Divergence (fidelity)",
      "Sample generation time",
      "Memory usage"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Conduct an evaluation of VAE, GAN, and SMOTE across multiple dimensions: data quality, privacy guarantees, computational efficiency, and downstream classification performance"
      ],
      "gaps_identified": [
        "Absence of direct comparison of VAE, GAN, and SMOTE on identical encrypted traffic data with uniform evaluation measures",
        "Severe class imbalance and scarcity of high-quality labeled encrypted traffic datasets",
        "Privacy leakage risks in generative models, especially GANs; need for privacy-aware training"
      ],
      "limitations": [
        "Evaluation restricted to a single dataset (UNSW-NB15) and a single minority class (Tor anomalies)",
        "Tabular, flow-level features only; temporal sequence characteristics not explicitly modeled",
        "Visual distribution comparisons used alongside quantitative metrics; potential subjectivity remains",
        "No public code reported; hyperparameters and full training details not exhaustively specified",
        "GAN shows risks of overfitting/memorization; SMOTE lacks diversity; VAE has slight performance drop vs real data"
      ],
      "future_work": [],
      "motivation": "Address challenges of encrypted traffic intrusion detection under payload invisibility, dataset scarcity, and class imbalance by leveraging generative models for privacy-preserving synthetic data.",
      "potential_research_ideas": [
        "Incorporate differentially private training (e.g., DP-SGD) for VAE/GAN to quantify privacy-utility trade-offs under formal privacy budgets",
        "Evaluate diffusion-based generative models for tabular network flows and compare against VAE/GAN/SMOTE on privacy, fidelity, and utility",
        "Model temporal dependencies using sequence models (RNN/Transformer/Temporal CNN) or session-level synthesis rather than per-flow tabular features",
        "Cross-dataset generalization: train synthetic generators on one dataset and test NIDS on others to assess transferability",
        "Expand privacy auditing beyond MIA to attribute inference and data extraction attacks; calibrate generators against these attacks",
        "Introduce tabular-specialized generators (e.g., CTGAN, TVAE, TabDDPM) as additional baselines in encrypted traffic contexts",
        "Calibrated anomaly detection combining synthetic augmentation with out-of-distribution detection and confidence calibration in NIDS",
        "Synthetic data governance: methods to detect and prevent memorization in generators during training (e.g., early-stopping via privacy risk monitors)"
      ],
      "architectural_improvement_recommendations": [
        "Use β-VAE/InfoVAE or class-conditional VAE with disentanglement constraints to improve diversity while preserving privacy",
        "Adopt WGAN-GP or spectral normalization for more stable GAN training and reduced mode collapse",
        "Apply DP-SGD or PATE-like mechanisms during generator training to mitigate membership inference risk",
        "Leverage tabular-specific generators (CTGAN/TVAE) and compare to the current GAN/VAE implementations",
        "Integrate temporal encoders (Transformer/TCN) to capture inter-arrival and burst patterns prior to generation",
        "Enhance evaluation with coverage/precision for generative models (e.g., PRD metrics) and calibration/error analysis for classifiers",
        "Use stronger downstream baselines (e.g., TabTransformer, LightGBM) and perform hyperparameter optimization for fair comparison"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [
        "scikit-learn",
        "XGBoost"
      ],
      "reproducibility_score": "medium",
      "computational_requirements": "Reported generation/training costs: SMOTE ~0.8 sec and 0.6 GB; VAE ~18 min and 4.2 GB; GAN ~42 min and 8.1 GB (Table 4). Final preprocessed dataset shape (410,929 x 27) with 26 selected features and balanced classes."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Managing increased false positives when training solely on GAN data (~3x FP vs real-data-trained model)",
        "Privacy leakage risk for GAN (MIA AUC 0.824; attacker precision 92.6%)",
        "GAN training instability and potential overfitting/memorization",
        "Computational cost for GAN vs VAE/SMOTE (longer training time and higher memory)",
        "Need to maintain class balance while preserving real-world distributions"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": true,
      "fairness_bias": false
    },
    "contributions": [
      "First comprehensive empirical comparison of VAE, GAN, and SMOTE for privacy-preserving Tor anomaly synthesis in encrypted NIDS",
      "Preprocessing pipeline with feature selection (26 features), normalization, and class balancing applied to UNSW-NB15",
      "Multi-dimensional evaluation including statistical similarity, downstream classification (Accuracy, F1, AUC-ROC), privacy via membership inference (AUC with 95% CI), and computational efficiency (time, memory)",
      "Operational guidance: VAE provides the best privacy-utility balance; GAN offers highest fidelity but severe privacy risk; SMOTE is efficient with limited diversity",
      "Recommendation that combining real + VAE-generated data yields the most balanced results for robustness without compromising privacy"
    ]
  },
  {
    "arxiv_id": "2601.06734v1",
    "title": "Deep Recurrent Hidden Markov Learning Framework for Multi-Stage Advanced Persistent Threat Prediction",
    "authors": "Saleem Ishaq Tijjani; Bogdan Ghita; Nathan Clarke; Matthew Craven",
    "abstract": "Advanced Persistent Threats (APTs) represent hidden, multi\\-stage cyberattacks whose long term persistence and adaptive behavior challenge conventional intrusion detection systems (IDS). Although recent advances in machine learning and probabilistic modeling have improved APT detection performance, most existing approaches remain reactive and alert\\-centric, providing limited capability for stage-aware prediction and principled inference under uncertainty, particularly when observations are sparse or incomplete. This paper proposes E\\-HiDNet, a unified hybrid deep probabilistic learning framework that integrates convolutional and recurrent neural networks with a Hidden Markov Model (HMM) to allow accurate prediction of the progression of the APT campaign. The deep learning component extracts hierarchical spatio\\-temporal representations from correlated alert sequences, while the HMM models latent attack stages and their stochastic transitions, allowing principled inference under uncertainty and partial observability. A modified Viterbi algorithm is introduced to handle incomplete observations, ensuring robust decoding under uncertainty. The framework is evaluated using a synthetically generated yet structurally realistic APT dataset (S\\-DAPT\\-2026). Simulation results show that E\\-HiDNet achieves up to 98.8\\-100\\% accuracy in stage prediction and significantly outperforms standalone HMMs when four or more observations are available, even under reduced training data scenarios. These findings highlight that combining deep semantic feature learning with probabilistic state\\-space modeling enhances predictive APT stage performance and situational awareness for proactive APT defense.",
    "published_date": "2026-01-11",
    "pdf_link": "https://arxiv.org/pdf/2601.06734v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Network Security",
      "subdomain": "Intrusion Detection",
      "specific_problem": "Multi-stage APT stage prediction and attack path forecasting under partial observability",
      "attack_types": [
        "Advanced Persistent Threat (APT)",
        "Initial compromise",
        "Command and Control (C2)",
        "Privilege escalation",
        "Asset/Data discovery",
        "Data exfiltration",
        "Spear-phishing",
        "Domain flux",
        "TOR exfiltration",
        "Scanning"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "CNN",
        "specific": "1D-CNN",
        "novel_contribution": "Used to extract spatial features from correlated alert sequences within the hybrid CNN–RNN–HMM framework (E-HiDNet)"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "LSTM",
        "novel_contribution": "Captures long-term temporal dependencies in alert sequences for stage-aware emissions in the hybrid framework"
      },
      {
        "type": "primary",
        "category": "RNN",
        "specific": "GRU",
        "novel_contribution": "Alternative recurrent unit for temporal modeling within the hybrid CNN–RNN–HMM"
      },
      {
        "type": "primary",
        "category": "HMM",
        "specific": null,
        "novel_contribution": "Models latent APT stages and stochastic transitions; integrated with deep emissions for principled inference under uncertainty"
      },
      {
        "type": "primary",
        "category": "Decoding Algorithm",
        "specific": "Modified Viterbi with Chapman–Kolmogorov-based transition handling",
        "novel_contribution": "Enhanced Viterbi decoding to handle missing and partially observed alert sequences"
      },
      {
        "type": "baseline",
        "category": "HMM",
        "specific": "Standalone HMM (conventional Viterbi)",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Probabilistic"
    ],
    "datasets": [
      {
        "name": "S-DAPT-2026",
        "type": "synthetic",
        "domain": "log_files",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "DARPA 2000 MSA",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Standalone HMM",
        "paper_reference": "[23]",
        "metric": "stage prediction accuracy",
        "their_result": "“E-HiDNet achieves up to 98.8–100% accuracy in stage prediction and significantly outperforms standalone HMMs when four or more observations are available.”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "accuracy"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "Can a unified hybrid deep probabilistic model accurately predict the progression of multi-stage APT campaigns under sparse or incomplete observations?",
        "Does combining deep semantic feature learning (CNN–RNN) with probabilistic state-space modeling (HMM) improve stage-aware APT prediction compared to standalone HMMs?",
        "Can an enhanced Viterbi algorithm enable robust decoding with missing or partially observed alert sequences?"
      ],
      "gaps_identified": [
        "“Most existing approaches remain reactive and alert-centric, providing limited capability for stage-aware prediction and principled inference under uncertainty, particularly when observations are sparse or incomplete.”",
        "Lack of explicit modeling of the attack life-cycle; alerts treated as independent events rather than correlated sequences.",
        "Standard Viterbi decoding assumes complete and continuous observations, limiting robustness in real APT settings.",
        "High false positives and brittleness of simple anomaly detectors under workload changes or rare benign behaviors."
      ],
      "limitations": [
        "Evaluation performed on a synthetically generated APT dataset (S-DAPT-2026) rather than real-world enterprise traces.",
        "No reported real-world deployment or at-scale evaluation.",
        "Limited reported metrics (primarily accuracy); lack of detailed comparative quantitative baselines in the provided text."
      ],
      "future_work": [],
      "motivation": "APTs are stealthy, multi-stage, and adaptive; defenders need stage-aware, predictive inference that is robust to uncertainty, missing observations, and sparse data by fusing deep representation learning with probabilistic state-space models.",
      "potential_research_ideas": [
        "Evaluate E-HiDNet on real-world SOC alert streams and multi-source telemetry (e.g., EDR, NetFlow, DNS, authentication logs) to validate generalizability.",
        "Incorporate online/continual learning to adapt transition dynamics and emissions to evolving APT tactics and concept drift.",
        "Augment the model with graph-based components (e.g., GNNs over hosts, users, processes) for entity-relationship reasoning during lateral movement.",
        "Uncertainty-aware decision support: calibrate probabilities (e.g., temperature scaling, Bayesian layers) and integrate with risk-based response policies.",
        "Adversarial robustness studies (evasion/poisoning on alert streams) and robust training (e.g., adversarial training, randomized smoothing) for resilience.",
        "Explainable stage prediction via attention over alerts or post-hoc methods (e.g., SHAP on emissions) for analyst trust and auditing.",
        "Extend to POMDP or differentiable state-space models to jointly optimize prediction and response policies.",
        "Data-efficient learning via self-supervised pretraining on unlabeled alerts and few-shot transfer to new environments.",
        "Temporal point process or HSMM to model variable dwell times per stage and predict time-to-next-stage.",
        "Benchmark creation: release and standardize synthetic-to-real APT datasets with common splits and protocols."
      ],
      "architectural_improvement_recommendations": [
        "Replace or augment CNN–RNN with Transformer-based sequence encoders for longer-range dependencies and multi-head attention over heterogeneous alerts.",
        "Adopt Hierarchical or Hidden semi-Markov Models (HSMM) to explicitly model stage durations and variable dwell times.",
        "Neuralized HMM (neural emissions and transitions) with end-to-end training and differentiable Viterbi/forward-backward for tighter integration.",
        "Multi-source fusion: late or cross-attention fusion of alerts, host context, and threat intel features before HMM decoding.",
        "Calibrated, Bayesian or ensemble emissions to quantify uncertainty and improve decision thresholds.",
        "Missingness modeling: use masked modeling or variational imputation to better handle gaps before decoding.",
        "CTC-style or weakly supervised training to leverage partially labeled sequences common in SOC settings."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": false,
      "inference_time": null,
      "deployment_challenges": [
        "Privacy and data governance constraints in operational environments.",
        "Streaming or transmission latency considerations for online inference.",
        "Need for interpretable and auditable decisions for analysts.",
        "Handling missing or partially observed alert sequences in practice."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "A hybrid deep probabilistic architecture (E-HiDNet) that combines CNN–RNN feature learning with HMM state-space modeling for multistage APT prediction.",
      "An enhanced Viterbi decoding mechanism leveraging Chapman–Kolmogorov-based transitions to handle missing and partially observed alert sequences.",
      "Support for dynamic APT stage prediction and forecasting of likely future attack paths to enable proactive defense.",
      "Synthetic, structurally realistic APT dataset (S-DAPT-2026) for evaluation.",
      "Empirical results showing up to 98.8–100% stage prediction accuracy and significant gains over standalone HMMs with four or more observations, including under reduced training data scenarios."
    ]
  },
  {
    "arxiv_id": "2601.12978v1",
    "title": "Reproducibility in Event-Log Research: A Parametrised Generator and Benchmark for Event-based Signatures",
    "authors": "Saad Khan; Simon Parkinson; Monika Roopak",
    "abstract": "Event-based datasets are crucial for cybersecurity analysis. A key use case is detecting event-based signatures, which represent attacks spanning multiple events and can only be understood once the relevant events are identified and linked. Analysing event datasets is essential for monitoring system security, but their growing volume and frequency create significant scalability and processing difficulties. Researchers rely on these datasets to develop and test techniques for automatically identifying signatures. However, because real datasets are security-sensitive and rarely shared, it becomes difficult to perform meaningful comparative evaluation between different approaches. This work addresses this evaluation limitation by offering a systematic method for generating event logs with known ground truth, enabling reproducible and comparable research. We present a novel parametrised generation technique capable of producing synthetic event datasets that contain event-based signatures for discovery. To demonstrate the capabilities of the technique, we provide a benchmark in signature detection. Our benchmarking demonstrated the suitability of DBSCAN, achieving a score greater than 0.95 Adjusted Rand Index on most generated datasets. This work enhances the ability of researchers to develop and benchmark new cybersecurity techniques, ultimately contributing to more robust and effective cybersecurity measures.",
    "published_date": "2026-01-19",
    "pdf_link": "https://arxiv.org/pdf/2601.12978v1",
    "paper_types": [
      "new_dataset",
      "empirical_analysis",
      "benchmark",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Security Operations and Monitoring",
      "subdomain": "Event Log Analysis / Event Correlation",
      "specific_problem": "Reproducible benchmarking for event-based signature detection via parametrised synthetic event-log generation with ground-truth",
      "attack_types": [
        "multi-step attack signatures",
        "account creation/modification/deletion misuse (Windows event sequence)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Clustering",
        "specific": "DBSCAN",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Synthetic Data Generation",
        "specific": "Parametrised event-log generator",
        "novel_contribution": "Configurable generator producing event-based signatures with complete ground truth across seven parameters (e.g., number of signatures, events per signature, similarity, objects, noise) for reproducible benchmarking"
      }
    ],
    "learning_paradigm": [
      "Unsupervised"
    ],
    "datasets": [
      {
        "name": "Parametrised Synthetic Event-Log Datasets (this paper)",
        "type": "synthetic",
        "domain": "event_logs",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      },
      {
        "name": "Multilog",
        "type": "public",
        "domain": "system_logs, network_logs, file_monitoring",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "WAF log",
        "type": "public",
        "domain": "web_application_firewall_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "ARCS (enterprise Windows security events)",
        "type": "public",
        "domain": "windows_security_event_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "CFDR Blue (Blue Gene/P RAS logs)",
        "type": "public",
        "domain": "ras_system_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Loghub",
        "type": "public",
        "domain": "system_logs (Windows, Linux, Mac OS, OpenSSH, HDFS, Spark, OpenStack, Blue Gene/L, etc.)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "LANL unified dataset",
        "type": "public",
        "domain": "host_event_logs and network_flows",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IoT-23",
        "type": "public",
        "domain": "network_traffic (IoT)",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "NSL-KDD",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "CICIDS-2017",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "UNSW-NB15",
        "type": "public",
        "domain": "network_traffic",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Air traffic proprietary log data (Cinque et al. 2020)",
        "type": "private",
        "domain": "application_logs, system_logs (air-traffic control)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Road Traffic Fines event log (De Leoni et al. 2015)",
        "type": "public",
        "domain": "information_system_event_logs (business process)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Hospital ERP financial modules event log (Mannhardt 2017)",
        "type": "public",
        "domain": "enterprise_resource_planning_event_logs (healthcare)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Building permit event logs (Buijs 2014)",
        "type": "public",
        "domain": "business_process_event_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Volvo IT incident/problem management logs (Steeman 2013)",
        "type": "private",
        "domain": "it_service_management_event_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Sepsis Cases event log (Mannhardt 2016)",
        "type": "public",
        "domain": "clinical_process_event_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Host event logs (Turcotte et al. 2019)",
        "type": "public",
        "domain": "host_event_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Decentralised blockchain-based application datasets (Alzhrani et al. 2023)",
        "type": "public",
        "domain": "application_event_logs (blockchain)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Network and host-based event logs (Spaček et al. 2022)",
        "type": "public",
        "domain": "network_and_host_event_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Real cyber attack on a Microsoft system logs (Kara et al. 2021)",
        "type": "private",
        "domain": "windows_system_and_application_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Various system logs (Zhu et al. 2023)",
        "type": "public",
        "domain": "system_logs (various)",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      },
      {
        "name": "Real and synthetic network event logs (Flynn & Olukoya 2025)",
        "type": "unknown",
        "domain": "network_event_logs",
        "link": null,
        "is_new_contribution": false,
        "availability": "not_available"
      }
    ],
    "baselines": [],
    "performance_metrics_used": [
      "Adjusted Rand Index (ARI)",
      "runtime"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [],
      "gaps_identified": [
        "Real-world event datasets are security-sensitive and rarely shared, preventing comparative evaluation.",
        "Lack of event-level ground truth about which events belong to the same activity/user/application across sources.",
        "Public datasets often target anomaly detection, not event-based signature extraction with controllable variation.",
        "Existing synthetic generators are business-process centric and fail to capture security event semantics and cross-source linkage.",
        "No systematic, parametrised method to generate event datasets with configurable event-based signatures and complete ground truth."
      ],
      "limitations": [
        "Generator realism validation versus real-world logs is not yet performed; authors note future incorporation of statistical fidelity checks.",
        "Assumes availability of an object-centric (key-value) representation; parsing/normalizing heterogeneous logs is out of scope.",
        "Density-based clustering (e.g., DBSCAN) has theoretical limitations in high-dimensional event–object spaces; observed failure cases align with this.",
        "Details of competing clustering baselines and full parameterizations are not reported in the provided text."
      ],
      "future_work": [
        "Incorporate realism validation by comparing statistical characteristics of generated data with real-world datasets.",
        "Adopt fidelity evaluation techniques from prior work to assess the realism of synthetic logs.",
        "Further analyse and address failure modes of density-based clustering in high-dimensional spaces.",
        "Extend benchmarking to additional algorithms and parameter settings; explore broader parameter sweeps and scenarios."
      ],
      "motivation": "Enable reproducible and comparable research on event-based signature detection by providing a parametrised synthetic event-log generator with ground truth and a benchmark to evaluate clustering-based detection.",
      "potential_research_ideas": [
        "Learn generator parameters from real corpora to auto-calibrate distributions (timestamps, object frequencies, co-occurrence) for higher realism.",
        "Incorporate cross-source causal semantics (user–process–host–network) and TTP injection to simulate multi-stage attacks with controllable tactics/techniques.",
        "Introduce temporal-causal constraints and graph-based structure in both data generation and detection (e.g., activity graphs) to improve evaluation of correlation methods.",
        "Benchmark representation learning (e.g., log/key-value embedding, graph embeddings) followed by clustering vs. raw object-based clustering.",
        "Evaluate robustness to noise, missingness, and heterogeneity; design adversarial corruptions (e.g., object obfuscation) and measure method resilience.",
        "Release a standardized benchmark suite with fixed train/test splits, scenario tags, and evaluation harness to foster fair comparison.",
        "Use LLM-based log parsing into object-centric schemas and study impact of parsing quality on downstream signature detection.",
        "Add privacy-preserving synthetic generation (e.g., DP mechanisms) to enable safe sharing while retaining utility for correlation tasks."
      ],
      "architectural_improvement_recommendations": [
        "Augment DBSCAN with HDBSCAN or density-adaptive methods; perform automated hyperparameter selection via k-distance or mutual reachability.",
        "Precede clustering with dimensionality reduction/representation learning (e.g., autoencoders, contrastive learning, graph embeddings) to mitigate high-dimensionality issues.",
        "Adopt graph clustering on event–object bipartite or heterogeneous graphs using GNNs or community detection to capture object co-occurrence structure.",
        "Model temporal order explicitly with sequence-aware similarity (DTW, time-decayed co-occurrence) or sequence encoders prior to clustering.",
        "Parameterize generator with pluggable modules for source schemas (Windows/Syslog/EDR), noise models, and TTP libraries; expose seeds for full reproducibility.",
        "Provide evaluation harness reporting ARI, NMI, AMI, homogeneity/completeness, and runtime with confidence intervals across random seeds."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "low",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "Preprocessing heterogenous log formats into an object-centric schema.",
        "High-dimensional event–object spaces affecting clustering quality.",
        "Obtaining and sharing real logs with ground truth due to sensitivity and privacy."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Parametrised event-log generation technique producing synthetic datasets with configurable event-based signatures and complete ground truth.",
      "Benchmarking study across >12,000 generated datasets for clustering-based signature detection; DBSCAN achieved >0.95 ARI on most datasets.",
      "Analysis of how dataset characteristics influence clustering performance and discussion of density-based clustering limitations in high-dimensional spaces."
    ]
  },
  {
    "arxiv_id": "2601.02438v2",
    "title": "Focus on What Matters: Fisher-Guided Adaptive Multimodal Fusion for Vulnerability Detection",
    "authors": "Yun Bian; Yi Chen; HaiQuan Wang; ShiHao Li; Zhe Cui",
    "abstract": "Software vulnerability detection can be formulated as a binary classification problem that determines whether a given code snippet contains security defects. Existing multimodal methods typically fuse Natural Code Sequence (NCS) representations extracted by pretrained models with Code Property Graph (CPG) representations extracted by graph neural networks, under the implicit assumption that introducing an additional modality necessarily yields information gain. Through empirical analysis, we demonstrate the limitations of this assumption: pretrained models already encode substantial structural information implicitly, leading to strong overlap between the two modalities; moreover, graph encoders are generally less effective than pretrained language models in feature extraction. As a result, naive fusion not only struggles to obtain complementary signals but can also dilute effective discriminative cues due to noise propagation. To address these challenges, we propose a task-conditioned complementary fusion strategy that uses Fisher information to quantify task relevance, transforming cross-modal interaction from full-spectrum matching into selective fusion within a task-sensitive subspace. Our theoretical analysis shows that, under an isotropic perturbation assumption, this strategy significantly tightens the upper bound on the output error. Based on this insight, we design the TaCCS-DFA framework, which combines online low-rank Fisher subspace estimation with an adaptive gating mechanism to enable efficient task-oriented fusion. Experiments on the BigVul, Devign, and ReVeal benchmarks demonstrate that TaCCS-DFA delivers up to a 6.3-point gain in F1 score with only a 3.4% increase in inference latency, while maintaining low calibration error.",
    "published_date": "2026-01-05",
    "pdf_link": "https://arxiv.org/pdf/2601.02438v2",
    "paper_types": [
      "empirical_analysis",
      "new_technique"
    ],
    "security_domain": {
      "primary": "Software Security",
      "subdomain": "Static Source Code Vulnerability Detection",
      "specific_problem": "Binary classification of code snippets/functions to detect vulnerabilities using multimodal fusion of Natural Code Sequences and Code Property Graphs",
      "attack_types": [
        "Use-After-Free (UAF)",
        "Buffer Overflow"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Attention/Fusion",
        "specific": "Dynamic Fisher Attention (DFA)",
        "novel_contribution": "Task-conditioned query generation and complementary subspace attention using Fisher principal subspace to filter auxiliary CPG features"
      },
      {
        "type": "primary",
        "category": "Subspace Estimation",
        "specific": "Online low-rank Fisher subspace estimation via Oja’s rule (Incremental PCA)",
        "novel_contribution": "Efficient O(dk) update and O(dk) space to track Fisher principal directions without constructing full FIM"
      },
      {
        "type": "primary",
        "category": "Gating Network",
        "specific": "Adaptive gating mechanism",
        "novel_contribution": "Sample-wise adaptive fusion ratio conditioned on structural complexity"
      },
      {
        "type": "primary",
        "category": "Contrastive Learning",
        "specific": "InfoNCE with cross-batch memory (XBM)",
        "novel_contribution": "Stage I cross-modal alignment to map NCS and CPG into a shared metric space"
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "CodeBERT",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Transformer",
        "specific": "CodeT5",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "GNN",
        "specific": "RGCN (Relational Graph Convolutional Network)",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Attention",
        "specific": "Naive cross-attention",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Linear Fusion",
        "specific": "Feature concatenation",
        "novel_contribution": null
      }
    ],
    "learning_paradigm": [
      "Supervised",
      "Self-supervised (contrastive alignment)",
      "Transfer Learning (pretrained language models)"
    ],
    "datasets": [
      {
        "name": "BigVul",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Devign",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "ReVeal",
        "type": "public",
        "domain": "source_code",
        "link": null,
        "is_new_contribution": false,
        "availability": "publicly_available"
      }
    ],
    "baselines": [
      {
        "method_name": "CodeBERT (NCS only)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": null,
        "baseline_result": "“exceeds an F1 score of 0.63” (BigVul)"
      },
      {
        "method_name": "RGCN (CPG only)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": null,
        "baseline_result": "“achieves an F1 score below 0.20” (BigVul)"
      },
      {
        "method_name": "Simple concatenation (NCS+CPG)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": null,
        "baseline_result": "“yields only a 5.8-point F1 improvement over using CodeBERT alone” (BigVul)"
      },
      {
        "method_name": "Previous best method on BigVul (unspecified)",
        "paper_reference": null,
        "metric": "F1",
        "their_result": "“TaCCS-DFA achieves an F1-score of 87.80%, outperforming the previous best method by 6.3 percentage points”",
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "F1 score",
      "Calibration error (ECE or similar)",
      "CKA similarity",
      "Inference latency (%)"
    ],
    "claims_sota": true,
    "research_scope": {
      "research_questions": [
        "Can Fisher information identify task-relevant subspaces to enable effective, noise-robust multimodal fusion for vulnerability detection?",
        "How much redundancy exists between NCS (pretrained model) and CPG (GNN) representations and how does it affect fusion?",
        "Can adaptive, task-conditioned fusion improve F1 and calibration with minimal latency overhead?"
      ],
      "gaps_identified": [
        "Implicit assumption that adding a modality (CPG) always provides information gain does not always hold due to substantial overlap with NCS features.",
        "Graph encoders are generally less effective than pretrained language models in feature extraction on CPGs (modality asymmetry).",
        "Naive fusion (concatenation or generic cross-attention) can propagate noise and dilute discriminative cues."
      ],
      "limitations": [
        "Theoretical analysis and error bound tightening rely on an isotropic perturbation assumption."
      ],
      "future_work": [],
      "motivation": "Automated vulnerability detection in large codebases suffers from diminishing returns with existing multimodal fusion. The paper aims to selectively fuse only task-relevant structural information using Fisher information to overcome redundancy and modality asymmetry while maintaining efficiency.",
      "potential_research_ideas": [
        "Pretrain stronger graph encoders (e.g., Graph Transformers with relational biases) on large CPG corpora and plug into TaCCS-DFA.",
        "Estimate Fisher subspaces per-layer or per-head to capture hierarchical task sensitivity and study layer-wise fusion benefits.",
        "Uncertainty-aware gating that conditions fusion on predictive entropy or calibration metrics for safer integration of CPG signals.",
        "Extend Fisher-guided fusion to additional modalities such as dynamic execution traces or dataflow summaries.",
        "Investigate alternative second-order approximations (e.g., K-FAC/Kronecker factored Fisher) for faster or more accurate Fisher subspace tracking.",
        "Automated selection of subspace dimension k via information criteria or validation-driven schedules.",
        "Domain adaptation across repositories/languages using Fisher-aligned contrastive objectives to reduce modality/mismatch shifts."
      ],
      "architectural_improvement_recommendations": [
        "Replace RGCN with a relational Graph Transformer or HGT to reduce the representation bottleneck on complex program graphs.",
        "Incorporate multi-scale graph pooling (e.g., DiffPool/ASAP) so the CPG encoder exposes both local and global structural cues to DFA.",
        "Use per-head Fisher priors and head-specific subspaces to diversify complementary attention patterns.",
        "Adopt K-FAC or block-diagonal Fisher approximations to trade off accuracy and speed in Fisher estimation.",
        "Jointly pretrain NCS and CPG encoders with cross-modal masked modeling to strengthen Stage I alignment before DFA.",
        "Learn a dynamic k (Fisher subspace rank) conditioned on sample complexity to balance noise suppression vs. information loss."
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": "Naive FIM is prohibitive (O(d^2) to form, O(d^3) eigendecomposition); proposed Oja’s update yields O(dk) per step and O(dk) memory; ~3.4% increase in inference latency."
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": null,
      "scalability_discussed": true,
      "inference_time": "3.4% increase in inference latency",
      "deployment_challenges": [
        "Full Fisher matrix computation is computationally prohibitive without approximation.",
        "Modality asymmetry can inject noise if naively fused.",
        "Highly imbalanced BigVul dataset poses practical training and calibration challenges."
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "Problem analysis and fusion formulation using Fisher information as a task-relevance measure to transform full-spectrum matching into selective subspace fusion.",
      "Theoretical analysis: under an isotropic perturbation assumption, restricting attention to a k-dimensional Fisher subspace tightens the output error bound to O(sqrt(k/d)·ε).",
      "Framework design (TaCCS-DFA) with online low-rank Fisher subspace estimation and adaptive gating, yielding up to +6.3 F1 on benchmarks with only 3.4% latency increase and low calibration error."
    ]
  },
  {
    "arxiv_id": "2601.00559v1",
    "title": "Cracking IoT Security: Can LLMs Outsmart Static Analysis Tools?",
    "authors": "Jason Quantrill; Noura Khajehnouri; Zihan Guo; Manar H. Alalfi",
    "abstract": "Smart home IoT platforms such as openHAB rely on Trigger Action Condition (TAC) rules to automate device behavior, but the interplay among these rules can give rise to interaction threats, unintended or unsafe behaviors emerging from implicit dependencies, conflicting triggers, or overlapping conditions. Identifying these threats requires semantic understanding and structural reasoning that traditionally depend on symbolic, constraint-driven static analysis. This work presents the first comprehensive evaluation of Large Language Models (LLMs) across a multi-category interaction threat taxonomy, assessing their performance on both the original openHAB (oHC/IoTB) dataset and a structurally challenging Mutation dataset designed to test robustness under rule transformations. We benchmark Llama 3.1 8B, Llama 70B, GPT-4o, Gemini-2.5-Pro, and DeepSeek-R1 across zero-, one-, and two-shot settings, comparing their results against oHIT's manually validated ground truth. Our findings show that while LLMs exhibit promising semantic understanding, particularly on action- and condition-related threats, their accuracy degrades significantly for threats requiring cross-rule structural reasoning, especially under mutated rule forms. Model performance varies widely across threat categories and prompt settings, with no model providing consistent reliability. In contrast, the symbolic reasoning baseline maintains stable detection across both datasets, unaffected by rule rewrites or structural perturbations. These results underscore that LLMs alone are not yet dependable for safety critical interaction-threat detection in IoT environments. We discuss the implications for tool design and highlight the potential of hybrid architectures that combine symbolic analysis with LLM-based semantic interpretation to reduce false positives while maintaining structural rigor.",
    "published_date": "2026-01-02",
    "pdf_link": "https://arxiv.org/pdf/2601.00559v1",
    "paper_types": [
      "empirical_analysis",
      "benchmark"
    ],
    "security_domain": {
      "primary": "IoT Security",
      "subdomain": "Smart Home Automation Security",
      "specific_problem": "Detection and validation of Rule Interaction Threats (RITs) in openHAB Trigger-Action-Condition (TAC) rules",
      "attack_types": [
        "Action Contradiction (AC)",
        "Weak Action Contradiction (WAC)",
        "Strong Action Contradiction (SAC)",
        "Trigger Cascade (TC)",
        "Weak Trigger Cascade (WTC)",
        "Strong Trigger Cascade (STC)",
        "Condition Cascade (CC)",
        "Weak Condition Cascade (WCC)",
        "Strong Condition Cascade (SCC)"
      ]
    },
    "ml_techniques": [
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "GPT-4o",
        "novel_contribution": "Used as a contextual validator within a hybrid reconciliation pipeline to reduce false positives on complex RIT categories"
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Llama 3.1 8B",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Llama 3.1 70B",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "Gemini-2.5-Pro",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Transformer LLM",
        "specific": "DeepSeek-R1",
        "novel_contribution": null
      },
      {
        "type": "baseline",
        "category": "Symbolic/Constraint-based Static Analysis",
        "specific": "oHIT",
        "novel_contribution": null
      },
      {
        "type": "primary",
        "category": "Hybrid (Symbolic + LLM)",
        "specific": null,
        "novel_contribution": "Reconciliation & Validation pipeline: symbolic detection for recall + LLM 'Common Sense & Intentionality Check' to confirm/refute complex threats"
      }
    ],
    "learning_paradigm": [
      "In-context Learning",
      "Zero-shot",
      "One-shot",
      "Two-shot"
    ],
    "datasets": [
      {
        "name": "openHAB Community (oHC)",
        "type": "public",
        "domain": "iot_automation_rules",
        "link": "https://github.com/JasonQuantrill/llm-v-static-results",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "IoTBench (IoTB) curated openHAB rules",
        "type": "public",
        "domain": "iot_automation_rules",
        "link": "https://github.com/JasonQuantrill/llm-v-static-results",
        "is_new_contribution": false,
        "availability": "publicly_available"
      },
      {
        "name": "Mutation dataset (synthetically mutated openHAB RITs)",
        "type": "synthetic",
        "domain": "iot_automation_rules",
        "link": null,
        "is_new_contribution": true,
        "availability": "not_available"
      }
    ],
    "baselines": [
      {
        "method_name": "Hybrid (Symbolic + LLM) vs oHIT static analysis",
        "paper_reference": null,
        "metric": "WTC precision",
        "their_result": "83%",
        "baseline_result": "17%"
      },
      {
        "method_name": "oHIT static analysis baseline",
        "paper_reference": null,
        "metric": "Robustness to rule rewrites/structural perturbations",
        "their_result": null,
        "baseline_result": null
      },
      {
        "method_name": "LLM-only (GPT-4o, Llama 3.1 8B/70B, Gemini-2.5-Pro, DeepSeek-R1)",
        "paper_reference": null,
        "metric": "Accuracy across threat categories; robustness on Mutation dataset",
        "their_result": null,
        "baseline_result": null
      }
    ],
    "performance_metrics_used": [
      "precision",
      "recall",
      "F1-score",
      "accuracy",
      "per-category performance (by RIT type)"
    ],
    "claims_sota": false,
    "research_scope": {
      "research_questions": [
        "RQ1 (Baseline Capability): How effective can pre-trained LLMs validate and classify Rule Interaction Threats (RITs) in real-world openHAB datasets?",
        "RQ2 (Model Scaling Effect): How does LLM parameter size (e.g., Llama 3.1 8B vs 70B) influence contextual validation accuracy and reasoning consistency for RITs?",
        "RQ3 (Scalability and Generalizability): Does performance hold on a large-scale mutation-based dataset where all instances are true vulnerabilities?",
        "RQ4 (Hybrid Effectiveness): To what extent does integrating symbolic analysis with LLM-based validation improve precision and reduce false positives compared to symbolic-only and LLM-only approaches?"
      ],
      "gaps_identified": [
        "LLMs struggle with cross-rule structural reasoning and multi-rule dependencies",
        "LLM accuracy degrades under mutated/rewritten rule forms",
        "Model performance varies widely across threat categories and prompt settings; no consistently reliable model",
        "Symbolic tools (oHIT) produce false positives on complex, context-dependent threats like WAC and WTC",
        "Real-world datasets underrepresent CC and TC threats, hindering balanced evaluation",
        "Static analysis scalability and adaptability to large, dynamic rulebases are challenging"
      ],
      "limitations": [
        "Evaluation limited to openHAB TAC rules; generalizability to other IoT platforms not demonstrated",
        "Mutation dataset is synthetic; fidelity to diverse real-world edge cases may vary",
        "Closed-source LLMs and API-based inference impede full reproducibility",
        "Results sensitive to prompt design; no fine-tuning conducted",
        "Some Mutation dataset statistics marked as pending completion",
        "No real-world deployment; offline evaluation only"
      ],
      "future_work": [
        "Develop and evaluate hybrid neurosymbolic systems that systematically combine symbolic structure with LLM semantics",
        "Create standardized, publicly released benchmarks for RIT detection with balanced coverage across all RIT types",
        "Explore LLM fine-tuning or adapters on TAC rule corpora to improve structural reasoning",
        "Extend evaluation to other smart home platforms and automation languages",
        "Integrate stronger formal validation (e.g., SMT solving) post-LLM validation to guarantee safety"
      ],
      "motivation": "Assess whether modern LLMs can reliably detect and validate IoT rule interaction threats, and whether hybridizing LLM semantics with symbolic rigor can improve precision while maintaining recall.",
      "potential_research_ideas": [
        "Fine-tune a domain-specific LLM on TAC/openHAB rules and RIT annotations to enhance structural reasoning",
        "Represent rules and interactions as graphs and apply neuro-symbolic GNN + LLM co-reasoning",
        "Program-of-thought or chain-of-thought with constrained decoding aligned to RIT grammars",
        "Active learning pipeline where LLM disagreements with symbolic analysis guide data labeling",
        "RAG with device ontologies and rule templates to ground LLMs in domain semantics",
        "Adversarial transformation benchmark (systematic rule rewrites) to stress-test LLM robustness and improve training"
      ],
      "architectural_improvement_recommendations": [
        "Integrate a constraint solver/SMT checker after LLM validation to ensure structural consistency",
        "Construct a structured IR from static analysis (rule graphs, trigger-condition-action facts) and prompt LLMs over this IR",
        "Use toolformer-style function calling so LLMs can query static analysis facts during reasoning",
        "Adopt dynamic few-shot selection with category-specific exemplars for each RIT type",
        "Incorporate uncertainty estimation and abstention; escalate uncertain cases to symbolic re-checking",
        "Employ self-consistency and debate among multiple LLM samples to improve reliability on complex cases"
      ],
      "ease_of_improvement": "medium"
    },
    "implementation": {
      "code_available": false,
      "code_link": null,
      "frameworks": [],
      "reproducibility_score": "medium",
      "computational_requirements": null
    },
    "practical_aspects": {
      "real_world_tested": false,
      "deployment_environment": "openHAB smart home platforms (conceptual evaluation only)",
      "scalability_discussed": true,
      "inference_time": null,
      "deployment_challenges": [
        "LLM reliability varies by category and prompt; insufficient consistency for safety-critical detection",
        "Sensitivity to rule rewrites and structural perturbations",
        "False positives from symbolic analysis on context-dependent threats",
        "Potential cost and latency for LLM inference at scale",
        "Closed-model dependence and reproducibility constraints"
      ]
    },
    "concerns": {
      "explainability": false,
      "adversarial_robustness": false,
      "privacy_preserving": false,
      "fairness_bias": false
    },
    "contributions": [
      "First comprehensive evaluation of multiple LLMs on a multi-category IoT rule interaction threat taxonomy",
      "Benchmarking across real-world oHC/IoTB datasets and a structurally challenging Mutation dataset",
      "Evidence that LLMs show promise on action-/condition-related threats but degrade on cross-rule structural reasoning and under mutated rule forms",
      "Demonstration that symbolic baseline (oHIT) maintains stable detection unaffected by rule rewrites",
      "Hybrid reconciliation pipeline that uses LLMs for contextual validation, improving precision (e.g., WTC precision from 17% to 83%)"
    ]
  }
]